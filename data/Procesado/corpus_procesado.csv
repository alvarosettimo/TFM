paperId,title,abstract,year,authors,openAccessPdf,processed_text,pdf_url
4dc2617f15847af822d1f89c2e5cca39c8cdb7ad,Effect of a Machine Learning Recommender System and Viral Peer Marketing Intervention on Smoking Cessation,This randomized clinical trial investigates the effect of a machine learning recommender messaging system and viral peer recruitment tool kit on a smoking-cessation intervention.,2023,"[{'authorId': '39230104', 'name': 'Jamie M. Faro'}, {'authorId': '2144135133', 'name': 'Jinying Chen'}, {'authorId': '7329456', 'name': 'J. Flahive'}, {'authorId': '66898610', 'name': 'Catherine S. Nagawa'}, {'authorId': '19227131', 'name': 'E. Orvek'}, {'authorId': '2085692', 'name': 'T. Houston'}, {'authorId': '2067667039', 'name': 'Jeroan J Allison'}, {'authorId': '2074564881', 'name': 'Sharina D Person'}, {'authorId': '2149788742', 'name': 'Bridget M Smith'}, {'authorId': '9638357', 'name': 'A. Blok'}, {'authorId': '2297708', 'name': 'R. Sadasivam'}]","{'url': 'https://jamanetwork.com/journals/jamanetworkopen/articlepdf/2800273/faro_2023_oi_221444_1672346528.6646.pdf', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9856644, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",effect of a machine learning recommender system and viral peer marketing intervention on smoking cessation,https://jamanetwork.com/journals/jamanetworkopen/articlepdf/2800273/faro_2023_oi_221444_1672346528.6646.pdf
9778a564510da05080f978fcff23928ead0f1db9,A Machine Learning Recommender System to Tailor Preference Assessments to Enhance Person-Centered Care Among Nursing Home Residents,"Background and Objectives
Nursing homes (NHs) using the Preferences for Everyday Living Inventory (PELI-NH) to assess important preferences and provide person-centered care find the number of items (72) to be a barrier to using the assessment.


Research Design and Methods
Using a sample of n = 255 NH resident responses to the PELI-NH, we used the 16 preference items from the MDS 3.0 Section F to develop a machine learning recommender system to identify additional PELI-NH items that may be important to specific residents. Much like the Netflix recommender system, our system is based on the concept of collaborative filtering whereby insights and predictions (e.g., filters) are created using the interests and preferences of many users. The algorithm identifies multiple sets of ""you might also like"" patterns called association rules, based upon responses to the 16 MDS preferences that recommends an additional set of preferences with a high likelihood of being important to a specific resident.


Results
In the evaluation of the combined apriori and logistic regression approach, we obtained a high recall performance (i.e., the ratio of correctly predicted preferences compared with all predicted preferences and nonpreferences) and high precision (i.e., the ratio of correctly predicted rules with respect to the rules predicted to be true) of 80.2% and 79.2%, respectively.


Discussion and Implications
The recommender system successfully provides guidance on how to best tailor the preference items asked of residents and can support preference capture in busy clinical environments, contributing to the feasibility of delivering person-centered care.",2019,"[{'authorId': '2509884', 'name': 'G. Gannod'}, {'authorId': '40523263', 'name': 'K. Abbott'}, {'authorId': '4463282', 'name': 'K. Van Haitsma'}, {'authorId': '41154196', 'name': 'Nathan Martindale'}, {'authorId': '41154596', 'name': 'A. Heppner'}]","{'url': 'https://academic.oup.com/gerontologist/article-pdf/59/1/167/27456534/gny056.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/geront/gny056?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/geront/gny056, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background and objectives nursing homes (nhs) using the preferences for everyday living inventory (peli-nh) to assess important preferences and provide person-centered care find the number of items (72) to be a barrier to using the assessment. research design and methods using a sample of n = 255 nh resident responses to the peli-nh, we used the 16 preference items from the mds 3.0 section f to develop a machine learning recommender system to identify additional peli-nh items that may be important to specific residents. much like the netflix recommender system, our system is based on the concept of collaborative filtering whereby insights and predictions (e.g., filters) are created using the interests and preferences of many users. the algorithm identifies multiple sets of ""you might also like"" patterns called association rules, based upon responses to the 16 mds preferences that recommends an additional set of preferences with a high likelihood of being important to a specific resident. results in the evaluation of the combined apriori and logistic regression approach, we obtained a high recall performance (i.e., the ratio of correctly predicted preferences compared with all predicted preferences and nonpreferences) and high precision (i.e., the ratio of correctly predicted rules with respect to the rules predicted to be true) of 80.2% and 79.2%, respectively. discussion and implications the recommender system successfully provides guidance on how to best tailor the preference items asked of residents and can support preference capture in busy clinical environments, contributing to the feasibility of delivering person-centered care.",https://academic.oup.com/gerontologist/article-pdf/59/1/167/27456534/gny056.pdf
6a8a21cab225a428c41e3f8c38e18535f68ffacf,A Machine Learning Recommender System Based on Collaborative Filtering Using Gaussian Mixture Model Clustering,"Changing and moving toward online shopping has made it necessary to
customize customers’ needs and provide them more selective options. The
buyers search the products’ features before deciding to purchase items.
The recommender systems facilitate the searching task for customers via
narrowing down the search space within the specific products that align
the customer needs. Clustering, as a typical machine learning approach,
is applied in recommender systems. As an information filtering method, a
recommender system clusters user’s data to indicate the required factors
for more accurate predictions by calculating the similarity between
members of a cluster. In this study, using the Gaussian mixture model
clustering and considering the scores distance and the value of scores
in the Pearson correlation coefficient, a new method is introduced for
predicting scores in machine learning recommender systems. To study the
proposed method’s performance, a Movie Lens data set is evaluated, and
the results are compared to some other recommender systems, including
the Pearson correlation coefficients similarity criteria, K-means, and
fuzzy C-means algorithms. The simulation results indicate that our
method has less error than others by increasing the number of neighbors.
The results also illustrate that when the number of users increases, the
proposed method’s accuracy will increase. The reason is that the
Gaussian mixture clustering chooses similar users and considers the
scores distance in choosing similar neighbors to the active user.",2020,"[{'authorId': '2172517066', 'name': 'Delshad Mohammad Shakoor'}, {'authorId': '1905450', 'name': 'Vafa Maihami'}, {'authorId': '2438471', 'name': 'R. Maihami'}]","{'url': 'https://doi.org/10.22541/au.160897179.93005705/v1', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.22541/au.160897179.93005705/v1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.22541/au.160897179.93005705/v1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","changing and moving toward online shopping has made it necessary to customize customers’ needs and provide them more selective options. the buyers search the products’ features before deciding to purchase items. the recommender systems facilitate the searching task for customers via narrowing down the search space within the specific products that align the customer needs. clustering, as a typical machine learning approach, is applied in recommender systems. as an information filtering method, a recommender system clusters user’s data to indicate the required factors for more accurate predictions by calculating the similarity between members of a cluster. in this study, using the gaussian mixture model clustering and considering the scores distance and the value of scores in the pearson correlation coefficient, a new method is introduced for predicting scores in machine learning recommender systems. to study the proposed method’s performance, a movie lens data set is evaluated, and the results are compared to some other recommender systems, including the pearson correlation coefficients similarity criteria, k-means, and fuzzy c-means algorithms. the simulation results indicate that our method has less error than others by increasing the number of neighbors. the results also illustrate that when the number of users increases, the proposed method’s accuracy will increase. the reason is that the gaussian mixture clustering chooses similar users and considers the scores distance in choosing similar neighbors to the active user.",https://doi.org/10.22541/au.160897179.93005705/v1
fc88d1692a0f53f2821499fa8b8f4d049775585f,Matrix Factorization Collaborative-Based Recommender System for Riyadh Restaurants: Leveraging Machine Learning to Enhance Consumer Choice,"Saudi Arabia’s tourism sector has recently started to play a significant role as an economic driver. The restaurant industry in Riyadh has experienced rapid growth in recent years, making it increasingly challenging for customers to choose from the large number of restaurants available. This paper proposes a matrix factorization collaborative-based recommender system for Riyadh city restaurants. The system leverages user reviews and ratings to predict users’ preferences and recommend restaurants likely to be of interest to them. The system incorporates three different approaches, namely, non-negative matrix factorization (NMF), singular value decomposition (SVD), and optimized singular value decomposition (SVD++). To the best of our knowledge, this is the first recommender system specifically designed for Riyadh restaurants. A comprehensive dataset of restaurants in Riyadh was collected, scraped from Foursquare.com, which includes a wide range of restaurant features and attributes. The dataset is publicly available, enabling other researchers to replicate the experiments and build upon the work. The performance of the system was evaluated using a real-world dataset, and its effectiveness was demonstrated by comparing it to a state-of-the-art recommender system. The evaluation results showed that SVD and NMF are effective methods for generating recommendations, with SVD performing slightly better in terms of RMSE and NMF performing slightly better in terms of MAE. Overall, the findings suggest that the collaborative-based approach using matrix factorization algorithms is an effective way to capture the complex relationships between users and restaurants.",2023,"[{'authorId': '2787898', 'name': 'Reham Alabduljabbar'}]","{'url': 'https://www.mdpi.com/2076-3417/13/17/9574/pdf?version=1692870311', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app13179574?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app13179574, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","saudi arabia’s tourism sector has recently started to play a significant role as an economic driver. the restaurant industry in riyadh has experienced rapid growth in recent years, making it increasingly challenging for customers to choose from the large number of restaurants available. this paper proposes a matrix factorization collaborative-based recommender system for riyadh city restaurants. the system leverages user reviews and ratings to predict users’ preferences and recommend restaurants likely to be of interest to them. the system incorporates three different approaches, namely, non-negative matrix factorization (nmf), singular value decomposition (svd), and optimized singular value decomposition (svd++). to the best of our knowledge, this is the first recommender system specifically designed for riyadh restaurants. a comprehensive dataset of restaurants in riyadh was collected, scraped from foursquare.com, which includes a wide range of restaurant features and attributes. the dataset is publicly available, enabling other researchers to replicate the experiments and build upon the work. the performance of the system was evaluated using a real-world dataset, and its effectiveness was demonstrated by comparing it to a state-of-the-art recommender system. the evaluation results showed that svd and nmf are effective methods for generating recommendations, with svd performing slightly better in terms of rmse and nmf performing slightly better in terms of mae. overall, the findings suggest that the collaborative-based approach using matrix factorization algorithms is an effective way to capture the complex relationships between users and restaurants.",https://www.mdpi.com/2076-3417/13/17/9574/pdf?version=1692870311
9998dc44714a0721caa671243391c1ed5ecfa222,Smart Crop Recommender System-A Machine Learning Approach,"Machine learning has proven its efficacy in solving agricultural problems in the recent years such as crop recommendation, crop yield prediction, and many such. With the advancement in the sub-domain of machine learning i.e., deep learning, multiple problems are minutely solved in agricultural sector. This paper focuses on recommending 22 types of crops with the aid of correlation analysis, distribution analysis, ensembling, and majority voting. A three-tiered framework is proposed in order to implement the crop recommendation problem. It includes data preprocessing, classification, and performance evaluation modules. The feature analysis is done through correlation plots and density distribution followed by classification using ensembling techniques. Finally, performance evaluation is performed using majority voting technique. This article further uses ensembling with base learners i.e., decision trees, random forest, Naïve Bayes, and support vector machines using majority voting. Further, majority voting is used to decide the final performance metrics. The practical visualization of the correlation plot, density-histogram distribution plots, confusion matrices, and performance plot are presented. The accuracy achieved post implementation is 99.54& by using Naïve Bayes classifier. The majority voting ensembler has not shown much accuracy i.e., 98.52&. Thus, Naïve Bayes classifier is proved to be the best fit for this problem statement. Some challenges and future research directions are also epitomized in this article.",2022,"[{'authorId': '90015202', 'name': 'R. K. Ray'}, {'authorId': '1720951783', 'name': 'Saneev Kumar Das'}, {'authorId': '1825671308', 'name': 'S. Chakravarty'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/Confluence52989.2022.9734173?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/Confluence52989.2022.9734173, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","machine learning has proven its efficacy in solving agricultural problems in the recent years such as crop recommendation, crop yield prediction, and many such. with the advancement in the sub-domain of machine learning i.e., deep learning, multiple problems are minutely solved in agricultural sector. this paper focuses on recommending 22 types of crops with the aid of correlation analysis, distribution analysis, ensembling, and majority voting. a three-tiered framework is proposed in order to implement the crop recommendation problem. it includes data preprocessing, classification, and performance evaluation modules. the feature analysis is done through correlation plots and density distribution followed by classification using ensembling techniques. finally, performance evaluation is performed using majority voting technique. this article further uses ensembling with base learners i.e., decision trees, random forest, naïve bayes, and support vector machines using majority voting. further, majority voting is used to decide the final performance metrics. the practical visualization of the correlation plot, density-histogram distribution plots, confusion matrices, and performance plot are presented. the accuracy achieved post implementation is 99.54& by using naïve bayes classifier. the majority voting ensembler has not shown much accuracy i.e., 98.52&. thus, naïve bayes classifier is proved to be the best fit for this problem statement. some challenges and future research directions are also epitomized in this article.",
f2e5aafc4d9d479ec48ba159ceb0749a9643f3cc,Crop Recommender System Using Machine Learning Approach,"Agriculture and its allied sectors are undoubtedly the largest providers of livelihoods in rural India. The agriculture sector is also a significant contributor factor to the country’s Gross Domestic Product (GDP). Blessing to the country is the overwhelming size of the agricultural sector. However, regrettable is the yield per hectare of crops in comparison to international standards. This is one of the possible causes for a higher suicide rate among marginal farmers in India. This paper proposes a viable and user-friendly yield prediction system for the farmers. The proposed system provides connectivity to farmers via a mobile application. GPS helps to identify the user location. The user provides the area & soil type as input. Machine learning algorithms allow choosing the most profitable crop list or predicting the crop yield for a user-selected crop. To predict the crop yield, selected Machine Learning algorithms such as Support Vector Machine (SVM), Artificial Neural Network (ANN), Random Forest (RF), Multivariate Linear Regression (MLR), and K-Nearest Neighbour (KNN) are used. Among them, the Random Forest showed the best results with 95% accuracy. Additionally, the system also suggests the best time to use the fertilizers to boost up the yield.",2021,"[{'authorId': '2004796561', 'name': 'S. Pande'}, {'authorId': '2005323891', 'name': 'Prem Kumar Ramesh'}, {'authorId': '2246927238', 'name': 'Anmol Anmol'}, {'authorId': '2310088601', 'name': 'B. R. Aishwarya'}, {'authorId': '2089477183', 'name': 'Karuna Rohilla'}, {'authorId': '83232609', 'name': 'Kumar Shaurya'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCMC51019.2021.9418351?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCMC51019.2021.9418351, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","agriculture and its allied sectors are undoubtedly the largest providers of livelihoods in rural india. the agriculture sector is also a significant contributor factor to the country’s gross domestic product (gdp). blessing to the country is the overwhelming size of the agricultural sector. however, regrettable is the yield per hectare of crops in comparison to international standards. this is one of the possible causes for a higher suicide rate among marginal farmers in india. this paper proposes a viable and user-friendly yield prediction system for the farmers. the proposed system provides connectivity to farmers via a mobile application. gps helps to identify the user location. the user provides the area & soil type as input. machine learning algorithms allow choosing the most profitable crop list or predicting the crop yield for a user-selected crop. to predict the crop yield, selected machine learning algorithms such as support vector machine (svm), artificial neural network (ann), random forest (rf), multivariate linear regression (mlr), and k-nearest neighbour (knn) are used. among them, the random forest showed the best results with 95% accuracy. additionally, the system also suggests the best time to use the fertilizers to boost up the yield.",
646cd9d8aefc610e73258bcab7371ee2293bfed5,Using LinkedIn Endorsements to Reinforce an Ontology and Machine Learning-Based Recommender System to Improve Professional Skills,"Nowadays, social networks have become highly relevant in the professional field, in terms of the possibility of sharing profiles, skills and jobs. LinkedIn has become the social network par excellence, owing to its content in professional and training information and where there are also endorsements, which are validations of the skills of users that can be taken into account in the recruitment process, as well as in the recommender system. In order to determine how endorsements influence Lifelong Learning course recommendations for professional skills development and enhancement, a new version of our Lifelong Learning course recommendation system is proposed. The recommender system is based on ontology, which allows modelling the data of knowledge areas and job performance sectors to represent professional skills of users obtained from social networks. Machine learning techniques are applied to group entities in the ontology and make predictions of new data. The recommender system has a semantic core, content-based filtering, and heuristics to perform the formative suggestion. In order to validate the data model and test the recommender system, information was obtained from web-based lifelong learning courses and information was collected from LinkedIn professional profiles, incorporating the skills endorsements into the user profile. All possible settings of the system were tested. The best result was obtained in the setting based on the spatial clustering algorithm based on the density of noisy applications. An accuracy of 94% and 80% recall was obtained.",2022,"[{'authorId': '2129176248', 'name': 'María Cora Urdaneta-Ponte'}, {'authorId': '1409467565', 'name': 'Ibon Oleagordia-Ruíz'}, {'authorId': '1402098961', 'name': 'A. Méndez-Zorrilla'}]","{'url': 'https://www.mdpi.com/2079-9292/11/8/1190/pdf?version=1649673673', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/electronics11081190?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/electronics11081190, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","nowadays, social networks have become highly relevant in the professional field, in terms of the possibility of sharing profiles, skills and jobs. linkedin has become the social network par excellence, owing to its content in professional and training information and where there are also endorsements, which are validations of the skills of users that can be taken into account in the recruitment process, as well as in the recommender system. in order to determine how endorsements influence lifelong learning course recommendations for professional skills development and enhancement, a new version of our lifelong learning course recommendation system is proposed. the recommender system is based on ontology, which allows modelling the data of knowledge areas and job performance sectors to represent professional skills of users obtained from social networks. machine learning techniques are applied to group entities in the ontology and make predictions of new data. the recommender system has a semantic core, content-based filtering, and heuristics to perform the formative suggestion. in order to validate the data model and test the recommender system, information was obtained from web-based lifelong learning courses and information was collected from linkedin professional profiles, incorporating the skills endorsements into the user profile. all possible settings of the system were tested. the best result was obtained in the setting based on the spatial clustering algorithm based on the density of noisy applications. an accuracy of 94% and 80% recall was obtained.",https://www.mdpi.com/2079-9292/11/8/1190/pdf?version=1649673673
7edec896d2fdd465366c0d1c121f704799424129,E-Learning Recommender System for Learners: A Machine Learning based Approach,"Web mining procedure helps the surfers to get the required information but finding the exact information is as good as finding a needle in a haystack. In this work, an intelligent prediction model using Tensor Flow environment for Graphics Processing Unit (GPU) devices has been designed to meet the challenges of speed and accuracy. The proposed approach is isolated into two stages: pre-processing and prediction. In the first phase, the procedure starts via looking through the URLs of various e-learning sites particular to computer science subjects. At that point, the content of looked through URLs are perused and after that from their keywords are produced identified with a particular subject in the wake of playing out the pre-processing of the content. Second phase is prediction that predicts query specific links of e-learning website. The proposed Intelligent E-learning through Web (IEW) has content mining, lexical analysis, classification and machine learning based prediction as its key features. Algorithms like SVM, Naïve Bayes, K-Nearest Neighbor, and Random Forest were tested and it was found that Random Forest gave an accuracy of 98.98%, SVM 42%, KNN 63% and Naïve Bayes 66%. Based on the results IEW uses Random forest for prediction.",2019,"[{'authorId': '152728429', 'name': 'Kamika Chaudhary'}, {'authorId': '145370046', 'name': 'Neena Gupta'}]","{'url': 'https://doi.org/10.33889/ijmems.2019.4.4-076', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.33889/IJMEMS.2019.4.4-076?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.33889/IJMEMS.2019.4.4-076, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","web mining procedure helps the surfers to get the required information but finding the exact information is as good as finding a needle in a haystack. in this work, an intelligent prediction model using tensor flow environment for graphics processing unit (gpu) devices has been designed to meet the challenges of speed and accuracy. the proposed approach is isolated into two stages: pre-processing and prediction. in the first phase, the procedure starts via looking through the urls of various e-learning sites particular to computer science subjects. at that point, the content of looked through urls are perused and after that from their keywords are produced identified with a particular subject in the wake of playing out the pre-processing of the content. second phase is prediction that predicts query specific links of e-learning website. the proposed intelligent e-learning through web (iew) has content mining, lexical analysis, classification and machine learning based prediction as its key features. algorithms like svm, naïve bayes, k-nearest neighbor, and random forest were tested and it was found that random forest gave an accuracy of 98.98%, svm 42%, knn 63% and naïve bayes 66%. based on the results iew uses random forest for prediction.",https://doi.org/10.33889/ijmems.2019.4.4-076
6ea5796868aa574370e0064c1cbee9a4e8af9f03,Recommender system for health care analysis using machine learning technique: a review,"Abstract Recommender systems use different techniques of machine learning (ML) to suggest users and recommend service or entity in various field of application such as in health care recommender system (HRS). Due to the vast count of algorithms shown in the literature, HRS and various application sectors are now utilizing ML algorithms from the area of artificial intelligence. However, selecting an appropriate ML algorithm in the case of a health recommender system seems to be a time-consuming task. However the development of recommender system in different service domain faces problems of algorithms selection for better accuracy. This article examined the usage of ML techniques in recommender systems for health applications through a survey of the literature. The objectives of this article are (i) recognize the literature review finding of recommender system in health applications using ML and deep learning algorithms. (ii) Assist new researchers with the help of gap in previous research. The results of this study is to proposed new recommender system in health application of mosquito borne disease by using hybrid approach of ML technique.",2022,"[{'authorId': '2163423815', 'name': 'Salim G. Shaikh'}, {'authorId': '2136226819', 'name': 'B. Suresh Kumar'}, {'authorId': '3316574', 'name': 'Geetika Narang'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/1463922X.2022.2061078?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/1463922X.2022.2061078, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract recommender systems use different techniques of machine learning (ml) to suggest users and recommend service or entity in various field of application such as in health care recommender system (hrs). due to the vast count of algorithms shown in the literature, hrs and various application sectors are now utilizing ml algorithms from the area of artificial intelligence. however, selecting an appropriate ml algorithm in the case of a health recommender system seems to be a time-consuming task. however the development of recommender system in different service domain faces problems of algorithms selection for better accuracy. this article examined the usage of ml techniques in recommender systems for health applications through a survey of the literature. the objectives of this article are (i) recognize the literature review finding of recommender system in health applications using ml and deep learning algorithms. (ii) assist new researchers with the help of gap in previous research. the results of this study is to proposed new recommender system in health application of mosquito borne disease by using hybrid approach of ml technique.",
d28b89d803928023a4fe7720e89d17c18c15a393,A Machine Learning-based Course Enrollment Recommender System,": As an integral component of human society, higher education has been undergoing a transformation in multiple aspects, such as administrative reorganization, pedagogical reform, and technological innovation. To line up with the latest trends, many institutions constantly update their curriculum, which poses challenges to students and their advisors. This paper proposes a machine learning-based course enrollment recommender system that aims to make personalized suggestions to students who expect to take classes in the upcoming semester. Using matrix factorization as the core algorithm, the model exploits several available types of information, including student course enrollment history and other contextual features, such as prerequisite restrictions, course meeting times, instructional methods, and course instructors. The system not only helps students but also facilitates their advisors’ work. Our experimental results show that the recommended courses were highly relevant while providing plenty of options to students.",2022,"[{'authorId': '2108197727', 'name': 'Xiwei Wang'}, {'authorId': '1738724485', 'name': 'Longyin Cui'}, {'authorId': '2164598982', 'name': 'Muhammad Bangash'}, {'authorId': '2120355905', 'name': 'M. Bilal'}, {'authorId': '2164599124', 'name': 'Luis Rosales'}, {'authorId': '2164592765', 'name': 'Wali Chaudhry'}]","{'url': 'https://doi.org/10.5220/0011109100003182', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5220/0011109100003182?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5220/0011109100003182, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",": as an integral component of human society, higher education has been undergoing a transformation in multiple aspects, such as administrative reorganization, pedagogical reform, and technological innovation. to line up with the latest trends, many institutions constantly update their curriculum, which poses challenges to students and their advisors. this paper proposes a machine learning-based course enrollment recommender system that aims to make personalized suggestions to students who expect to take classes in the upcoming semester. using matrix factorization as the core algorithm, the model exploits several available types of information, including student course enrollment history and other contextual features, such as prerequisite restrictions, course meeting times, instructional methods, and course instructors. the system not only helps students but also facilitates their advisors’ work. our experimental results show that the recommended courses were highly relevant while providing plenty of options to students.",https://doi.org/10.5220/0011109100003182
c1fef078b99d7f60f82d9bc86533fe60e780b723,A Recommender System for Predicting Students' Admission to a Graduate Program using Machine Learning Algorithms,"In the 21st century, University educations are becoming a key pillar of social and economic life. It plays a major role not only in the educational process but also in the ensuring of two important things which are a prosperous career and financial security. However, predicting university admission can be especially difficult because the students are not aware of admission requirements. For that reason, the main purpose of this research work is to provide a recommender system for early predicting university admission based on four Machine Learning algorithms namely Linear Regression, Decision Tree, Support Vector Regression, and Random Forest Regression. The experimental results showed that the Random Forest Regression is the most suitable Machine Learning algorithm for predicting university admission. Also, the Cumulative Grade Point Average (CGPA) is the most important parameter that influences the chance of admission.",2021,"[{'authorId': '3467029', 'name': 'Inssaf El Guabassi'}, {'authorId': '1968472', 'name': 'Zakaria Bousalem'}, {'authorId': '30895548', 'name': 'Rim Marah'}, {'authorId': '9116747', 'name': 'Aimad Qazdar'}]","{'url': 'https://online-journals.org/index.php/i-joe/article/download/20049/8735', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3991/ijoe.v17i02.20049?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3991/ijoe.v17i02.20049, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the 21st century, university educations are becoming a key pillar of social and economic life. it plays a major role not only in the educational process but also in the ensuring of two important things which are a prosperous career and financial security. however, predicting university admission can be especially difficult because the students are not aware of admission requirements. for that reason, the main purpose of this research work is to provide a recommender system for early predicting university admission based on four machine learning algorithms namely linear regression, decision tree, support vector regression, and random forest regression. the experimental results showed that the random forest regression is the most suitable machine learning algorithm for predicting university admission. also, the cumulative grade point average (cgpa) is the most important parameter that influences the chance of admission.",https://online-journals.org/index.php/i-joe/article/download/20049/8735
23d50866ae5bcf58c3fc9f12a48b840d0408c811,Recommender System for Sentiment Analysis using Machine Learning Models,"In recent years, with the rapid growth of Internet technology, online shopping has become a rapid way for users to purchase and consume desired products. Large volume of user-generated content on social media sites like twitter has resulted in tweet sentiment analysis. Sentiment analysis supports as base for decision support systems and recommendation systems and it becomes an essential tool on online platforms to extract the information on user emotional state to improve user satisfaction. This paper proposes an effective sentiment analysis recommender system framework using machine learning models.",2021,"[{'authorId': '2064282165', 'name': 'A. Naresh'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.17762/TURCOMAT.V12I10.4216?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.17762/TURCOMAT.V12I10.4216, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent years, with the rapid growth of internet technology, online shopping has become a rapid way for users to purchase and consume desired products. large volume of user-generated content on social media sites like twitter has resulted in tweet sentiment analysis. sentiment analysis supports as base for decision support systems and recommendation systems and it becomes an essential tool on online platforms to extract the information on user emotional state to improve user satisfaction. this paper proposes an effective sentiment analysis recommender system framework using machine learning models.",
b21756b3a11aadce9ef0048d2eb8a0085f5fe7e3,A Machine Learning-Based Recommender System for Improving Students Learning Experiences,"Outcome-based education (OBE) is a well-proven teaching strategy based upon a predefined set of expected outcomes. The components of OBE are Program Educational Objectives (PEOs), Program Outcomes (POs), and Course Outcomes (COs). These latter are assessed at the end of each course and several recommended actions can be proposed by faculty members’ to enhance the quality of courses and therefore the overall educational program. Considering a large number of courses and the faculty members’ devotion, bad actions could be recommended and therefore undesirable and inappropriate decisions may occur. In this paper, a recommender system, using different machine learning algorithms, is proposed for predicting suitable actions based on course specifications, academic records, and course learning outcomes’ assessments. We formulated the problem as a multi-label multi-class binary classification problem and the dataset was translated into different problem transformation and adaptive methods such as one-vs.-all, binary relevance, label powerset, classifier chain, and ML-KNN adaptive classifier. As a case study, the proposed recommender system is applied to the college of Computer and Information Sciences, Jouf University, Kingdom of Saudi Arabia (KSA) for helping academic staff improving the quality of teaching strategies. The obtained results showed that the proposed recommender system presents more recommended actions for improving students’ learning experiences.",2020,"[{'authorId': '3188825', 'name': 'Nacim Yanes'}, {'authorId': '2079185743', 'name': 'A. M. Mostafa'}, {'authorId': '40229054', 'name': 'M. Ezz'}, {'authorId': '66460668', 'name': 'S. Almuayqil'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09249379.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2020.3036336?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2020.3036336, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","outcome-based education (obe) is a well-proven teaching strategy based upon a predefined set of expected outcomes. the components of obe are program educational objectives (peos), program outcomes (pos), and course outcomes (cos). these latter are assessed at the end of each course and several recommended actions can be proposed by faculty members’ to enhance the quality of courses and therefore the overall educational program. considering a large number of courses and the faculty members’ devotion, bad actions could be recommended and therefore undesirable and inappropriate decisions may occur. in this paper, a recommender system, using different machine learning algorithms, is proposed for predicting suitable actions based on course specifications, academic records, and course learning outcomes’ assessments. we formulated the problem as a multi-label multi-class binary classification problem and the dataset was translated into different problem transformation and adaptive methods such as one-vs.-all, binary relevance, label powerset, classifier chain, and ml-knn adaptive classifier. as a case study, the proposed recommender system is applied to the college of computer and information sciences, jouf university, kingdom of saudi arabia (ksa) for helping academic staff improving the quality of teaching strategies. the obtained results showed that the proposed recommender system presents more recommended actions for improving students’ learning experiences.",https://ieeexplore.ieee.org/ielx7/6287639/8948470/09249379.pdf
44e60dff7afd5bccdfb297da8b15ef2b1b97f8f8,Probabilistic Unsupervised Machine Learning Approach for a Similar Image Recommender System for E-Commerce,"The recommender system is the most profound research area for e-commerce product recommendations. Currently, many e-commerce platforms use a text-based product search, which has limitations to fetch the most similar products. An image-based similarity search for recommendations had considerable gains in popularity for many areas, especially for the e-commerce platforms giving a better visual search experience by the users. In our research work, we proposed a machine-learning-based approach for a similar image-based recommender system. We applied a dimensionality reduction technique using Principal Component Analysis (PCA) through Singular Value Decomposition (SVD) for transforming the extracted features into lower-dimensional space. Further, we applied the K-Means++ clustering approach for the possible cluster identification for a similar group of products. Later, we computed the Manhattan distance measure for the input image to the target clusters set for fetching the top-N similar products with low distance measure. We compared our approach with five different unsupervised clustering algorithms, namely Minibatch, K-Mediod, Agglomerative, Brich, and the Gaussian Mixture Model (GMM), and used the 40,000 fashion product image dataset from the Kaggle web platform for the product recommendation process. We computed various cluster performance metrics on K-means++ and achieved a Silhouette Coefficient (SC) of 0.1414, a Calinski-Harabasz (CH) index score of 669.4, and a Davies–Bouldin (DB) index score of 1.8538. Finally, our proposed PCA-SVD transformed K-mean++ approach showed superior performance compared to the other five clustering approaches for similar image product recommendations.",2020,"[{'authorId': '102525451', 'name': 'S. K. Addagarla'}, {'authorId': '3266446', 'name': 'Anthoniraj Amalanathan'}]","{'url': 'https://www.mdpi.com/2073-8994/12/11/1783/pdf?version=1604401126', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/sym12111783?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/sym12111783, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the recommender system is the most profound research area for e-commerce product recommendations. currently, many e-commerce platforms use a text-based product search, which has limitations to fetch the most similar products. an image-based similarity search for recommendations had considerable gains in popularity for many areas, especially for the e-commerce platforms giving a better visual search experience by the users. in our research work, we proposed a machine-learning-based approach for a similar image-based recommender system. we applied a dimensionality reduction technique using principal component analysis (pca) through singular value decomposition (svd) for transforming the extracted features into lower-dimensional space. further, we applied the k-means++ clustering approach for the possible cluster identification for a similar group of products. later, we computed the manhattan distance measure for the input image to the target clusters set for fetching the top-n similar products with low distance measure. we compared our approach with five different unsupervised clustering algorithms, namely minibatch, k-mediod, agglomerative, brich, and the gaussian mixture model (gmm), and used the 40,000 fashion product image dataset from the kaggle web platform for the product recommendation process. we computed various cluster performance metrics on k-means++ and achieved a silhouette coefficient (sc) of 0.1414, a calinski-harabasz (ch) index score of 669.4, and a davies–bouldin (db) index score of 1.8538. finally, our proposed pca-svd transformed k-mean++ approach showed superior performance compared to the other five clustering approaches for similar image product recommendations.",https://www.mdpi.com/2073-8994/12/11/1783/pdf?version=1604401126
f6185f9fa3383569bd8c4853db09928155f2a546,Machine learning-based book recommender system: a survey and new perspectives,"The exponential growth of recommender systems research has drawn the attention of the scientific community recently. These systems are very useful in reducing information overload and providing users with the items of their need. The major areas where recommender systems have contributed significantly include e-commerce, online auction, and books and conference recommendation for academia and industrialists. Book recommender systems suggest books of interest to users according to their preferences and requirements. In this article, we have surveyed machine learning techniques which have been used in book recommender systems. Moreover, evaluation metrics applied to evaluate recommendation techniques is also studied. Six categories for book recommendation techniques have been identified and discussed which would enable the scientific community to lay a foundation of research in the concerned field. We have also proposed future perspectives to improve recommender system. We hope that researchers exploring recommendation technology in general and book recommendation in particular will be finding this work highly beneficial.",2020,"[{'authorId': '2070424552', 'name': 'Khalid Anwar'}, {'authorId': '3065624', 'name': 'Jamshed Siddiqui'}, {'authorId': '32036584', 'name': 'S. Sohail'}]","{'url': 'https://doi.org/10.1504/ijiids.2020.10031604', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1504/ijiids.2020.10031604?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1504/ijiids.2020.10031604, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the exponential growth of recommender systems research has drawn the attention of the scientific community recently. these systems are very useful in reducing information overload and providing users with the items of their need. the major areas where recommender systems have contributed significantly include e-commerce, online auction, and books and conference recommendation for academia and industrialists. book recommender systems suggest books of interest to users according to their preferences and requirements. in this article, we have surveyed machine learning techniques which have been used in book recommender systems. moreover, evaluation metrics applied to evaluate recommendation techniques is also studied. six categories for book recommendation techniques have been identified and discussed which would enable the scientific community to lay a foundation of research in the concerned field. we have also proposed future perspectives to improve recommender system. we hope that researchers exploring recommendation technology in general and book recommendation in particular will be finding this work highly beneficial.",https://doi.org/10.1504/ijiids.2020.10031604
dcc98e17aebb605194959424be1c35ed10d4a174,Design of an Unsupervised Machine Learning-Based Movie Recommender System,"This research aims to determine the similarities in groups of people to build a film recommender system for users. Users often have difficulty in finding suitable movies due to the increasing amount of movie information. The recommender system is very useful for helping customers choose a preferred movie with the existing features. In this study, the recommender system development is established by using several algorithms to obtain groupings, such as the K-Means algorithm, birch algorithm, mini-batch K-Means algorithm, mean-shift algorithm, affinity propagation algorithm, agglomerative clustering algorithm, and spectral clustering algorithm. We propose methods optimizing K so that each cluster may not significantly increase variance. We are limited to using groupings based on Genre and Tags for movies. This research can discover better methods for evaluating clustering algorithms. To verify the quality of the recommender system, we adopted the mean square error (MSE), such as the Dunn Matrix and Cluster Validity Indices, and social network analysis (SNA), such as Degree Centrality, Closeness Centrality, and Betweenness Centrality. We also used average similarity, computational time, association rule with Apriori algorithm, and clustering performance evaluation as evaluation measures to compare method performance of recommender systems using Silhouette Coefficient, Calinski-Harabaz Index, and Davies–Bouldin Index.",2020,"[{'authorId': '121560883', 'name': 'Debby Cintia Ganesha Putri'}, {'authorId': '143798885', 'name': 'Jenq-Shiou Leu'}, {'authorId': '31138553', 'name': 'Pavel Seda'}]","{'url': 'https://www.mdpi.com/2073-8994/12/2/185/pdf?version=1580474828', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.20944/preprints202001.0124.v1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.20944/preprints202001.0124.v1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this research aims to determine the similarities in groups of people to build a film recommender system for users. users often have difficulty in finding suitable movies due to the increasing amount of movie information. the recommender system is very useful for helping customers choose a preferred movie with the existing features. in this study, the recommender system development is established by using several algorithms to obtain groupings, such as the k-means algorithm, birch algorithm, mini-batch k-means algorithm, mean-shift algorithm, affinity propagation algorithm, agglomerative clustering algorithm, and spectral clustering algorithm. we propose methods optimizing k so that each cluster may not significantly increase variance. we are limited to using groupings based on genre and tags for movies. this research can discover better methods for evaluating clustering algorithms. to verify the quality of the recommender system, we adopted the mean square error (mse), such as the dunn matrix and cluster validity indices, and social network analysis (sna), such as degree centrality, closeness centrality, and betweenness centrality. we also used average similarity, computational time, association rule with apriori algorithm, and clustering performance evaluation as evaluation measures to compare method performance of recommender systems using silhouette coefficient, calinski-harabaz index, and davies–bouldin index.",https://www.mdpi.com/2073-8994/12/2/185/pdf?version=1580474828
51379d0a583bd2e11b9b355d117a99f44e5e211e,Tourism Recommender System using Machine Learning Based on User's Public Instagram Photos,"In the past decade, recommender systems have become an essential part of online services such as NetFlix, YouTube, online shopping, etc. The tourism agencies such as TripAdvisor or Expedia also apply the recommender system to their services. For Thailand, the tourism industry is one of the most important revenues of the country. The problem is that the recommender system for planning a trip to Thailand still not effective enough. Users require a lot of effort when planning a trip. Therefore, the objective of this study is to develop the prototype of a tourism recommender system that automatically understands the user's preferences of their favorite tourist attractions without asking them any question. It applied machine learning to extract the user's preferences from the user's Instagram photos. Those preferences then use to compute the similarity with the attributes from 23 example tourist attractions in Ubon Ratchathani Province. A user study was conducted with 42 participates to preliminary study the precision and the adoption of the prototype. The results suggested that the prototype has been judged as satisfactory by participants for both precision and adoption. Moreover, the findings of this study will serve as insights for the direction of our planned future research such as applying the recommender system to other provinces of Thailand.",2020,"[{'authorId': '3249220', 'name': 'Charnsak Srisawatsakul'}, {'authorId': '3419653', 'name': 'W. Boontarig'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/InCIT50588.2020.9310777?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/InCIT50588.2020.9310777, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the past decade, recommender systems have become an essential part of online services such as netflix, youtube, online shopping, etc. the tourism agencies such as tripadvisor or expedia also apply the recommender system to their services. for thailand, the tourism industry is one of the most important revenues of the country. the problem is that the recommender system for planning a trip to thailand still not effective enough. users require a lot of effort when planning a trip. therefore, the objective of this study is to develop the prototype of a tourism recommender system that automatically understands the user's preferences of their favorite tourist attractions without asking them any question. it applied machine learning to extract the user's preferences from the user's instagram photos. those preferences then use to compute the similarity with the attributes from 23 example tourist attractions in ubon ratchathani province. a user study was conducted with 42 participates to preliminary study the precision and the adoption of the prototype. the results suggested that the prototype has been judged as satisfactory by participants for both precision and adoption. moreover, the findings of this study will serve as insights for the direction of our planned future research such as applying the recommender system to other provinces of thailand.",
ca320a1c793e276966eaf05817a0a49b08bd6b79,An Autonomous Courses Recommender System For Undergraduate Using Machine Learning Techniques,"A University admission process is a complex process that needs a tremendous amount of time and labor to allocate course(s) to the prospective applicants. The study aimed at tackling the wrong placement of applicants into courses and to also address the wastage of admission vacancies by recommending the appropriate course(s). About 8,700 data for three academic sessions were collected from two different universities for training and testing the system. The features used are the results of Senior Secondary School subjects and the average score of UTME and Post-UTME. The proposed system employed five (5) classification models, which include Linear Regression, Naive Bayes, Support Vector Machine, K-Nearest Neighbor and Decision Tree Algorithm. The Linear Regression Model has the Root Mean Square Error (RMSE) as 2. 614 $e^{-14}$ The other four (4) classification models are also found to be efficient with an efficiency of at least 90% sequel to the dimensionality reduction in the dataset. The result shows that both Naive Bayes Classifier and Support Vector Machine have achieved the highest recommendation accuracy of approximately 99.94%, which outperformed Decision Tree and K-Nearest Neighbor algorithms with an accuracy of 98.10% and 99.87% respectively. The system can be adjusted with the change of admission criteria in Nigerian Universities. In consideration of the high degree of prediction accuracy, flexibility is an advantage, as the system can predict suitable courses that match the students’ grades. Therefore, the system is adaptive and good in making the prediction and can be used as a framework for further research on the admission recommender system.",2020,"[{'authorId': '1660936152', 'name': ""Murtala Isma'il""}, {'authorId': '2274502096', 'name': 'Usman Haruna'}, {'authorId': '48082306', 'name': 'G. Aliyu'}, {'authorId': '1429833598', 'name': 'Idris Abdulmumin'}, {'authorId': '2041920770', 'name': 'Shehu Adamu'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICMCECS47690.2020.240882?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICMCECS47690.2020.240882, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a university admission process is a complex process that needs a tremendous amount of time and labor to allocate course(s) to the prospective applicants. the study aimed at tackling the wrong placement of applicants into courses and to also address the wastage of admission vacancies by recommending the appropriate course(s). about 8,700 data for three academic sessions were collected from two different universities for training and testing the system. the features used are the results of senior secondary school subjects and the average score of utme and post-utme. the proposed system employed five (5) classification models, which include linear regression, naive bayes, support vector machine, k-nearest neighbor and decision tree algorithm. the linear regression model has the root mean square error (rmse) as 2. 614 $e^{-14}$ the other four (4) classification models are also found to be efficient with an efficiency of at least 90% sequel to the dimensionality reduction in the dataset. the result shows that both naive bayes classifier and support vector machine have achieved the highest recommendation accuracy of approximately 99.94%, which outperformed decision tree and k-nearest neighbor algorithms with an accuracy of 98.10% and 99.87% respectively. the system can be adjusted with the change of admission criteria in nigerian universities. in consideration of the high degree of prediction accuracy, flexibility is an advantage, as the system can predict suitable courses that match the students’ grades. therefore, the system is adaptive and good in making the prediction and can be used as a framework for further research on the admission recommender system.",
ab5faef896b5b1dcb9adf2549fe13ee29b23c7de,Knowledge Based Recommender System for Academia Using Machine Learning: A Case Study on Higher Education Landscape of Pakistan,"Allocation of courses and research students based on faculty’s subject specialization and area of interest has always remained a challenging task for university administration due to the presence of academics’ cross-domain interests, stale faculty resumes at university portals and changing the skill set demands from the industry. Collaborative filtering and content-based recommender systems have already been in use by the industry for recommending things, such as movies, news, restaurants, and shopping items to the users, and however, no one has utilized these off-the-shelf models for enhancing the student experience and improving the quality of higher education in academia. This paper presents a case study showcasing the use of probabilistic topic models for generating recommendations to users in academia through appropriate course allocation and supervisor assignment. The proposed system coined as ScholarLite harnesses the power of machine learning to extract research themes from faculty members’ past publications, mines research interests from their resumes, and combines it with their educational background to generate recommendations for course teaching, research supervision, and industry–academia collaboration. We have shown the recommendation results on real-world data gathered from the higher education commission of the country and demonstrated that the proposed techniques are scalable across various programs offered by the universities and could be deployed in a small budget by universities for automating course and supervisor allocation procedures. The experiments confirm our performance expectation by showing good relevance and objectivity in results, thus making this decision management system more appealing for large-scale deployment and use by academia.",2019,"[{'authorId': '1994559948', 'name': 'Huma Samin'}, {'authorId': '1801630', 'name': 'T. Azim'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08693719.pdf', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2019.2912012?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2019.2912012, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","allocation of courses and research students based on faculty’s subject specialization and area of interest has always remained a challenging task for university administration due to the presence of academics’ cross-domain interests, stale faculty resumes at university portals and changing the skill set demands from the industry. collaborative filtering and content-based recommender systems have already been in use by the industry for recommending things, such as movies, news, restaurants, and shopping items to the users, and however, no one has utilized these off-the-shelf models for enhancing the student experience and improving the quality of higher education in academia. this paper presents a case study showcasing the use of probabilistic topic models for generating recommendations to users in academia through appropriate course allocation and supervisor assignment. the proposed system coined as scholarlite harnesses the power of machine learning to extract research themes from faculty members’ past publications, mines research interests from their resumes, and combines it with their educational background to generate recommendations for course teaching, research supervision, and industry–academia collaboration. we have shown the recommendation results on real-world data gathered from the higher education commission of the country and demonstrated that the proposed techniques are scalable across various programs offered by the universities and could be deployed in a small budget by universities for automating course and supervisor allocation procedures. the experiments confirm our performance expectation by showing good relevance and objectivity in results, thus making this decision management system more appealing for large-scale deployment and use by academia.",https://ieeexplore.ieee.org/ielx7/6287639/8600701/08693719.pdf
7feba17a67e636e5d9d217e3931924416f676c6c,A lightweight deep learning model based recommender system by sentiment analysis,"Recommender systems based on sentiment analysis become challenging due to the presence of enormous data available over the internet. With the lack of proper data cleaning and analysis methods, existing machine learning (ML) techniques fail to generate accurate recommendations. To overcome this issue, this paper proposes a Light Deep Learning (LightDL)-based recommender system that uses Twitter-based reviews. First, the data is collected from Twitter and cleaned by subsequent data cleaning processes. Then, this pre-processed data is fed into the LightDL model, which learns the important features like hashtags, unigrams, multigrams, etc. from each piece of data. Here, we have learned about four groups of features, including semantic features, syntactic features, symbolic features, and tweet-based features. Finally, the data is classified into positive, negative, and neutral categories according to the learned features. On the basis of classified sentiment, the review is generated to the users. Finally, the model is evaluated in terms of accuracy, precision, recall, f-measure, and error rate through extensive experiments in Matlab. The proposed LightDL model outperforms in all performance measures; specifically, it achieves 95% accuracy for the Twitter dataset.",2023,"[{'authorId': '2213963007', 'name': 'Phaneendra Chiranjeevi'}, {'authorId': '2154964574', 'name': 'A. Rajaram'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3233/jifs-223871?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3233/jifs-223871, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems based on sentiment analysis become challenging due to the presence of enormous data available over the internet. with the lack of proper data cleaning and analysis methods, existing machine learning (ml) techniques fail to generate accurate recommendations. to overcome this issue, this paper proposes a light deep learning (lightdl)-based recommender system that uses twitter-based reviews. first, the data is collected from twitter and cleaned by subsequent data cleaning processes. then, this pre-processed data is fed into the lightdl model, which learns the important features like hashtags, unigrams, multigrams, etc. from each piece of data. here, we have learned about four groups of features, including semantic features, syntactic features, symbolic features, and tweet-based features. finally, the data is classified into positive, negative, and neutral categories according to the learned features. on the basis of classified sentiment, the review is generated to the users. finally, the model is evaluated in terms of accuracy, precision, recall, f-measure, and error rate through extensive experiments in matlab. the proposed lightdl model outperforms in all performance measures; specifically, it achieves 95% accuracy for the twitter dataset.",
6ae845f996b8f2d0615f24757015980200fd7793,Breaking Filter Bubble: A Reinforcement Learning Framework of Controllable Recommender System,"In the information-overloaded era of the Web, recommender systems that provide personalized content filtering are now the mainstream portal for users to access Web information. Recommender systems deploy machine learning models to learn users’ preferences from collected historical data, leading to more centralized recommendation results due to the feedback loop. As a result, it will harm the ranking of content outside the narrowed scope and limit the options seen by users. In this work, we first conduct data analysis from a graph view to observe that the users’ feedback is restricted to limited items, verifying the phenomenon of centralized recommendation. We further develop a general simulation framework to derive the procedure of the recommender system, including data collection, model learning, and item exposure, which forms a loop. To address the filter bubble issue under the feedback loop, we then propose a general and easy-to-use reinforcement learning-based method, which can adaptively select few but effective connections between nodes from different communities as the exposure list. We conduct extensive experiments in the simulation framework based on large-scale real-world datasets. The results demonstrate that our proposed reinforcement learning-based control method can serve as an effective solution to alleviate the filter bubble and the separated communities induced by it. We believe the proposed framework of controllable recommendation in this work can inspire not only the researchers of recommender systems, but also a broader community concerned with artificial intelligence algorithms’ impact on humanity, especially for those vulnerable populations on the Web.",2023,"[{'authorId': '2157623608', 'name': 'Zhenyan Li'}, {'authorId': '2153514690', 'name': 'Yancheng Dong'}, {'authorId': '49281242', 'name': 'Chen Gao'}, {'authorId': '2338013426', 'name': 'Yizhou Zhao'}, {'authorId': '2108821147', 'name': 'Dong Li'}, {'authorId': '2069718816', 'name': 'Jianye Hao'}, {'authorId': '2215580245', 'name': 'Kai Zhang'}, {'authorId': '2154403926', 'name': 'Yong Li'}, {'authorId': '2108388268', 'name': 'Zhi Wang'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3543507.3583856', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3543507.3583856?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3543507.3583856, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the information-overloaded era of the web, recommender systems that provide personalized content filtering are now the mainstream portal for users to access web information. recommender systems deploy machine learning models to learn users’ preferences from collected historical data, leading to more centralized recommendation results due to the feedback loop. as a result, it will harm the ranking of content outside the narrowed scope and limit the options seen by users. in this work, we first conduct data analysis from a graph view to observe that the users’ feedback is restricted to limited items, verifying the phenomenon of centralized recommendation. we further develop a general simulation framework to derive the procedure of the recommender system, including data collection, model learning, and item exposure, which forms a loop. to address the filter bubble issue under the feedback loop, we then propose a general and easy-to-use reinforcement learning-based method, which can adaptively select few but effective connections between nodes from different communities as the exposure list. we conduct extensive experiments in the simulation framework based on large-scale real-world datasets. the results demonstrate that our proposed reinforcement learning-based control method can serve as an effective solution to alleviate the filter bubble and the separated communities induced by it. we believe the proposed framework of controllable recommendation in this work can inspire not only the researchers of recommender systems, but also a broader community concerned with artificial intelligence algorithms’ impact on humanity, especially for those vulnerable populations on the web.",https://dl.acm.org/doi/pdf/10.1145/3543507.3583856
0bb18b392d78280fca8a527ee3fe322885a6c341,Building an effective recommender system using machine learning based framework,"Machine learning forms the base of many information retrieval applications those effect our day to day lives directly or indirectly. One of the Commonly used application of machine learning algorithms is Recommender Systems. Recommender system are information flitering system which takes users rating for items into account and predict user preferences. Many online ecommerce and other categorical websites are able to generate recommendations either on the basis of implicit feedback or explicit feedback. In implicit feedback, preferences are actually based on analysis of browsing patterns of the user, for example, purchase history, web logs etc. Explicit feedback is generated from the ratings provided by the user. In this paper we have shown adaption of collaborative filtering in Apache Mahout platforms via Eclipse on a sample data set.",2017,"[{'authorId': '9093205', 'name': 'Ruchika'}, {'authorId': '2117775672', 'name': 'A. Singh'}, {'authorId': '2013564241', 'name': 'Mayank Sharma'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICTUS.2017.8286008?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICTUS.2017.8286008, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","machine learning forms the base of many information retrieval applications those effect our day to day lives directly or indirectly. one of the commonly used application of machine learning algorithms is recommender systems. recommender system are information flitering system which takes users rating for items into account and predict user preferences. many online ecommerce and other categorical websites are able to generate recommendations either on the basis of implicit feedback or explicit feedback. in implicit feedback, preferences are actually based on analysis of browsing patterns of the user, for example, purchase history, web logs etc. explicit feedback is generated from the ratings provided by the user. in this paper we have shown adaption of collaborative filtering in apache mahout platforms via eclipse on a sample data set.",
5ca40430df0f0925499fe457bef98855f624bb4d,Autoencoders and their applications in machine learning: a survey,"Autoencoders have become a hot researched topic in unsupervised learning due to their ability to learn data features and act as a dimensionality reduction method. With rapid evolution of autoencoder methods, there has yet to be a complete study that provides a full autoencoders roadmap for both stimulating technical improvements and orienting research newbies to autoencoders. In this paper, we present a comprehensive survey of autoencoders, starting with an explanation of the principle of conventional autoencoder and their primary development process. We then provide a taxonomy of autoencoders based on their structures and principles and thoroughly analyze and discuss the related models. Furthermore, we review the applications of autoencoders in various fields, including machine vision, natural language processing, complex network, recommender system, speech process, anomaly detection, and others. Lastly, we summarize the limitations of current autoencoder algorithms and discuss the future directions of the field.",2024,"[{'authorId': '2254140462', 'name': 'Kamal Berahmand'}, {'authorId': '2282810608', 'name': 'Fatemeh Daneshfar'}, {'authorId': '2282807272', 'name': 'Elaheh Sadat Salehi'}, {'authorId': '2256305163', 'name': 'Yuefeng Li'}, {'authorId': '2261670871', 'name': 'Yue Xu'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s10462-023-10662-6.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10462-023-10662-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10462-023-10662-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","autoencoders have become a hot researched topic in unsupervised learning due to their ability to learn data features and act as a dimensionality reduction method. with rapid evolution of autoencoder methods, there has yet to be a complete study that provides a full autoencoders roadmap for both stimulating technical improvements and orienting research newbies to autoencoders. in this paper, we present a comprehensive survey of autoencoders, starting with an explanation of the principle of conventional autoencoder and their primary development process. we then provide a taxonomy of autoencoders based on their structures and principles and thoroughly analyze and discuss the related models. furthermore, we review the applications of autoencoders in various fields, including machine vision, natural language processing, complex network, recommender system, speech process, anomaly detection, and others. lastly, we summarize the limitations of current autoencoder algorithms and discuss the future directions of the field.",https://link.springer.com/content/pdf/10.1007/s10462-023-10662-6.pdf
da6bfb6b296b017ce550b9c77dd02e996b5b2727,E-Learning Course Recommender System Using Collaborative Filtering Models,"e-Learning is a sought-after option for learners during pandemic situations. In e-Learning platforms, there are many courses available, and the user needs to select the best option for them. Thus, recommender systems play an important role to provide better automation services to users in making course choices. It makes recommendations for users in selecting the desired option based on their preferences. This system can use machine intelligence (MI)-based techniques to carry out the recommendation mechanism. Based on the preferences and history, this system is able to know what the users like most. In this work, a recommender system is proposed using the collaborative filtering mechanism for e-Learning course recommendation. This work is focused on MI-based models such as K-nearest neighbor (KNN), Singular Value Decomposition (SVD) and neural network–based collaborative filtering (NCF) models. Here, one lakh of Coursera’s course review dataset is taken from Kaggle for analysis. The proposed work can help learners to select the e-Learning courses as per their preferences. This work is implemented using Python language. The performance of these models is evaluated using performance metrics such as hit rate (HR), average reciprocal hit ranking (ARHR) and mean absolute error (MAE). From the results, it is observed that KNN is able to perform better in terms of higher HR and ARHR and lower MAE values as compared to other models.",2022,"[{'authorId': '67052795', 'name': 'K. K. Jena'}, {'authorId': '3047382', 'name': 'Sourav Kumar Bhoi'}, {'authorId': '2198973011', 'name': 'Tushar Kanta Malik'}, {'authorId': '5203143', 'name': 'K. Sahoo'}, {'authorId': '3218095', 'name': 'Noor Zaman Jhanjhi'}, {'authorId': '2697329', 'name': 'Sajal Bhatia'}, {'authorId': '3419502', 'name': 'Fathi H. Amsaad'}]","{'url': 'https://www.mdpi.com/2079-9292/12/1/157/pdf?version=1672311230', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/electronics12010157?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/electronics12010157, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","e-learning is a sought-after option for learners during pandemic situations. in e-learning platforms, there are many courses available, and the user needs to select the best option for them. thus, recommender systems play an important role to provide better automation services to users in making course choices. it makes recommendations for users in selecting the desired option based on their preferences. this system can use machine intelligence (mi)-based techniques to carry out the recommendation mechanism. based on the preferences and history, this system is able to know what the users like most. in this work, a recommender system is proposed using the collaborative filtering mechanism for e-learning course recommendation. this work is focused on mi-based models such as k-nearest neighbor (knn), singular value decomposition (svd) and neural network–based collaborative filtering (ncf) models. here, one lakh of coursera’s course review dataset is taken from kaggle for analysis. the proposed work can help learners to select the e-learning courses as per their preferences. this work is implemented using python language. the performance of these models is evaluated using performance metrics such as hit rate (hr), average reciprocal hit ranking (arhr) and mean absolute error (mae). from the results, it is observed that knn is able to perform better in terms of higher hr and arhr and lower mae values as compared to other models.",https://www.mdpi.com/2079-9292/12/1/157/pdf?version=1672311230
11d097d324ce206fd800af2c6e90c959269bcf89,A personalized recommender system using Machine Learning based Sentiment Analysis over social data,"Social Media platforms are already an indispensable part of our daily lives. With its constant growth, it has contributed to superfluous, heterogeneous data which can be overwhelming due to its volume and velocity, thus limiting the availability of relevant and required information when a particular query is to be served. Hence, a need for personalized, fine-grained user preference-oriented framework for resolving this problem and also, to enhance user experience is increasingly felt. In this paper, we propose a such a social framework, which extracts user's reviews, comments of restaurants and points of interest such as events and locations, to personalize and rank suggestions based on user preferences. Machine Learning and Sentiment Analysis based techniques are used for further optimizing search query results. This provides the user with quicker and more relevant data, thus avoiding irrelevant data and providing much needed personalization.",2016,"[{'authorId': '144155516', 'name': 'M. Ashok'}, {'authorId': '35163816', 'name': 'S. Rajanna'}, {'authorId': '9281131', 'name': 'P. Joshi'}, {'authorId': '9234505', 'name': 'S. Kamath S'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/SCEECS.2016.7509354?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SCEECS.2016.7509354, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","social media platforms are already an indispensable part of our daily lives. with its constant growth, it has contributed to superfluous, heterogeneous data which can be overwhelming due to its volume and velocity, thus limiting the availability of relevant and required information when a particular query is to be served. hence, a need for personalized, fine-grained user preference-oriented framework for resolving this problem and also, to enhance user experience is increasingly felt. in this paper, we propose a such a social framework, which extracts user's reviews, comments of restaurants and points of interest such as events and locations, to personalize and rank suggestions based on user preferences. machine learning and sentiment analysis based techniques are used for further optimizing search query results. this provides the user with quicker and more relevant data, thus avoiding irrelevant data and providing much needed personalization.",
af5912e12f935ef0fa06ecfe69e2ade149bf1af4,Compute Job Memory Recommender System Using Machine Learning,"This paper presents a machine learning approach to predict the amount of compute memory needed by jobs which are submitted to Load Sharing Facility (LSF® ) with a high level of accuracy. LSF® is the compute resource manager and job scheduler for Qualcomm chip design process. It schedules the jobs based on available resources: CPU, memory, storage, and software licenses. Memory is one of the key resources and its proper utilization leads to a substantial improvement in saving machine resources which in turn results in a significant reduction in overall job pending time. In addition, efficient memory utilization helps to reduce the operations cost by decreasing the number of servers needed for the end-to-end design process. In this paper, we explored a suite of statistical and machine learning techniques to develop a Compute Memory Recommender System for the Qualcomm chip design process with over 90% accuracy in predicting the amount of memory a job needs. Moreover, it demonstrates the potential to significantly reduce job pending time.",2016,"[{'authorId': '2184274', 'name': 'Taraneh Taghavi'}, {'authorId': '2105042957', 'name': 'Maria Lupetini'}, {'authorId': '2879545', 'name': 'Y. Kretchmer'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/2939672.2939717?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2939672.2939717, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper presents a machine learning approach to predict the amount of compute memory needed by jobs which are submitted to load sharing facility (lsf® ) with a high level of accuracy. lsf® is the compute resource manager and job scheduler for qualcomm chip design process. it schedules the jobs based on available resources: cpu, memory, storage, and software licenses. memory is one of the key resources and its proper utilization leads to a substantial improvement in saving machine resources which in turn results in a significant reduction in overall job pending time. in addition, efficient memory utilization helps to reduce the operations cost by decreasing the number of servers needed for the end-to-end design process. in this paper, we explored a suite of statistical and machine learning techniques to develop a compute memory recommender system for the qualcomm chip design process with over 90% accuracy in predicting the amount of memory a job needs. moreover, it demonstrates the potential to significantly reduce job pending time.",
14716ea95ccf374e282fb084988f459ee1c3d664,Automated Machine Learning for Deep Recommender Systems: A Survey,"Deep recommender systems (DRS) are critical for current commercial online service providers, which address the issue of information overload by recommending items that are tailored to the user’s interests and preferences. They have unprecedented feature representations effectiveness and the capacity of modeling the non-linear relationships be-tween users and items. Despite their advancements, DRS models, like other deep learning models, employ sophisticated neural network architectures and other vital components that are typically designed and tuned by human experts. This article will give a comprehensive summary of automated machine learning (AutoML) for developing DRS models. We ﬁrst provide an overview of AutoML for DRS models and the related techniques. Then we discuss the state-of-the-art AutoML approaches that automate the feature selection, feature embeddings, feature interactions, and system design in DRS. Finally, we discuss appealing research directions and summarize the survey.",2022,"[{'authorId': '92633145', 'name': 'Bo Chen'}, {'authorId': '2733057', 'name': 'Xiangyu Zhao'}, {'authorId': '2162455919', 'name': 'Yejing Wang'}, {'authorId': '41031455', 'name': 'Wenqi Fan'}, {'authorId': '3339005', 'name': 'Huifeng Guo'}, {'authorId': '2824766', 'name': 'Ruiming Tang'}]","{'url': 'http://arxiv.org/pdf/2204.01390', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.48550/arXiv.2204.01390?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.48550/arXiv.2204.01390, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep recommender systems (drs) are critical for current commercial online service providers, which address the issue of information overload by recommending items that are tailored to the user’s interests and preferences. they have unprecedented feature representations effectiveness and the capacity of modeling the non-linear relationships be-tween users and items. despite their advancements, drs models, like other deep learning models, employ sophisticated neural network architectures and other vital components that are typically designed and tuned by human experts. this article will give a comprehensive summary of automated machine learning (automl) for developing drs models. we ﬁrst provide an overview of automl for drs models and the related techniques. then we discuss the state-of-the-art automl approaches that automate the feature selection, feature embeddings, feature interactions, and system design in drs. finally, we discuss appealing research directions and summarize the survey.",http://arxiv.org/pdf/2204.01390
d22630e331a7af64b6956cd04377c9eda56d6696,"Handling Sparse Rating Matrix for E-commerce Recommender System Using Hybrid Deep Learning Based on LSTM, SDAE and Latent Factor",": E-commerce is the most essential application for conducting business transactions. Delivering product information to customers require an essential machine called recommender system. Recommender systems have been adopted in many large e-commerce companies such as Amazon, e-Bay, Alibaba, YouTube, iTunes, and so on. Ratings have become an essential factor to calculate product information. They are users’ expressions about their satisfaction regarding a product or service. Unfortunately, the number of ratings is extremely sparse. Generating rating prediction is a major issue in the recommender system research field. The most popular model using latent factor or matrix factorization to generate rating prediction faced the problem in accuracy performance. This research aimed to develop a novel model to generate rating prediction using two deep learning variants based on Stack Denoising Auto Encoder (SDAE), Long Short Term Memory (LSTM), and combining with a latent factor model based on Probabilistic Matrix Factorization (PMF). This study considered integrated information resources, including user information and document product information. Following the experiment report involved in Movielens and Amazon Information Video dataset, our model outperformed previous works using PMF, Collaborative Deep Learning (CDL), Probabilistic Hybrid Deep Learning (PHD) and LSTM-PMF model, with more than 5% in average using Root Mean Square Error (RMSE) evaluation metrices.",2022,"[{'authorId': '2157729433', 'name': 'Eli Pujastuti'}, {'authorId': '2078994820', 'name': 'A. Laksito'}, {'authorId': '48796389', 'name': 'Richki Hardi'}, {'authorId': '70086794', 'name': 'R. Perwira'}, {'authorId': '69569087', 'name': 'A. Arfriandi'}]","{'url': 'https://doi.org/10.22266/ijies2022.0430.35', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.22266/ijies2022.0430.35?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.22266/ijies2022.0430.35, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",": e-commerce is the most essential application for conducting business transactions. delivering product information to customers require an essential machine called recommender system. recommender systems have been adopted in many large e-commerce companies such as amazon, e-bay, alibaba, youtube, itunes, and so on. ratings have become an essential factor to calculate product information. they are users’ expressions about their satisfaction regarding a product or service. unfortunately, the number of ratings is extremely sparse. generating rating prediction is a major issue in the recommender system research field. the most popular model using latent factor or matrix factorization to generate rating prediction faced the problem in accuracy performance. this research aimed to develop a novel model to generate rating prediction using two deep learning variants based on stack denoising auto encoder (sdae), long short term memory (lstm), and combining with a latent factor model based on probabilistic matrix factorization (pmf). this study considered integrated information resources, including user information and document product information. following the experiment report involved in movielens and amazon information video dataset, our model outperformed previous works using pmf, collaborative deep learning (cdl), probabilistic hybrid deep learning (phd) and lstm-pmf model, with more than 5% in average using root mean square error (rmse) evaluation metrices.",https://doi.org/10.22266/ijies2022.0430.35
1966509b718b0397281dc0cf569d187cb7d63ff5,Do-It-Yourself Recommender System: Reusing and Recycling With Blockchain and Deep Learning,"Due to aggressive urbanization (with population size), waste increases exponentially, resulting in environmental damage. Even though it looks challenging, such an issue can be controlled if we can reuse them. To handle this, in our work, we design a machine learning and blockchain-oriented system that identifies the waste objects/products and recommends to the user multiple ‘Do-It-Yourself’ (DIY) ideas to reuse or recycle. Blockchain records every transaction in the shared ledger to enable transaction verifiability and supports better decision-making. In this study, a Deep Neural Network (DNN) trained on about 11700 images is developed using ResNet50 architecture for object recognition (training accuracy of 94%). We deploy several smart contracts in the Hyperledger Fabric (HF) blockchain platform to validate recommended DIY ideas by blockchain network members. HF is a decentralized ledger technology platform that executes the deployed smart contracts in a secured Docker container to initialize and manage the ledger state. The complete model is delivered on a web platform using Flask, where our recommendation system works on a web scraping script written using Python. Fetching DIY ideas using web-scraping takes nearly 1 second on a desktop machine with an Intel Core-i7 processor with 8 cores, 16 GB RAM, installed with Ubuntu 18.04 64-bit operating system, and Python 3.6 package. Further, we evaluate blockchain-based smart contracts’ latencies and throughput performances using the hyperledger caliper benchmark. To the best of our knowledge, this is the first work that integrates blockchain technology and deep learning for the DIY recommender system.",2022,"[{'authorId': '2182397179', 'name': 'Sachi Pandey'}, {'authorId': '51511276', 'name': 'Vikas Chouhan'}, {'authorId': '51115481', 'name': 'Devanshi Verma'}, {'authorId': '2182492602', 'name': 'Shubham Rajrah'}, {'authorId': '51477868', 'name': 'Fayadh S. Alenezi'}, {'authorId': '3415124', 'name': 'Rajkumar Saini'}, {'authorId': '144253310', 'name': 'K. Santosh'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/6514899/09864188.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2022.3199661?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2022.3199661, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","due to aggressive urbanization (with population size), waste increases exponentially, resulting in environmental damage. even though it looks challenging, such an issue can be controlled if we can reuse them. to handle this, in our work, we design a machine learning and blockchain-oriented system that identifies the waste objects/products and recommends to the user multiple ‘do-it-yourself’ (diy) ideas to reuse or recycle. blockchain records every transaction in the shared ledger to enable transaction verifiability and supports better decision-making. in this study, a deep neural network (dnn) trained on about 11700 images is developed using resnet50 architecture for object recognition (training accuracy of 94%). we deploy several smart contracts in the hyperledger fabric (hf) blockchain platform to validate recommended diy ideas by blockchain network members. hf is a decentralized ledger technology platform that executes the deployed smart contracts in a secured docker container to initialize and manage the ledger state. the complete model is delivered on a web platform using flask, where our recommendation system works on a web scraping script written using python. fetching diy ideas using web-scraping takes nearly 1 second on a desktop machine with an intel core-i7 processor with 8 cores, 16 gb ram, installed with ubuntu 18.04 64-bit operating system, and python 3.6 package. further, we evaluate blockchain-based smart contracts’ latencies and throughput performances using the hyperledger caliper benchmark. to the best of our knowledge, this is the first work that integrates blockchain technology and deep learning for the diy recommender system.",https://ieeexplore.ieee.org/ielx7/6287639/6514899/09864188.pdf
5cab0ef0b6d9f453b415ccde66fd0379798ae617,A Machine-Learning-Based Action Recommender for Network Operation Centers,"Failure management and cost-aware traffic engineering are two important tasks done in Network Operation Centers (NOC). These are performed by expert technicians who must carefully analyze the network state and the flow of incoming alarms to decide how, where and when to take actions on the network. While based on implicit guiding principles, these network actions are very hard to automate with explicit rules due to the high complexity of the system; hence NOC action is essentially a manual process today. To automate part of that process, in this paper we introduce an Action Recommendation Engine (ARE) that can learn implicit NOC action rules with supervised machine learning from historical data. As a result, ARE can recommend suitable action(s) to remedy network faults and engineer the traffic to minimize costs, all while maximizing the users’ Quality of Experience. To quantify the effectiveness of different NOC action scenarios, we introduce the QoE-OPEX metric which balances between users’ quality of Experience and ISP’s operational costs. After proper model training on 56,000 data points with 66 features, we demonstrate that ARE can effectively reproduce implicit action-taking logic of NOC technicians, thus moving us one step closer to reliable autonomous networks and fully-automated NOCs.",2021,"[{'authorId': '26905745', 'name': 'S. Mohammed'}, {'authorId': '30440143', 'name': 'Ayşe Rumeysa Mohammed'}, {'authorId': '2064784322', 'name': 'David Côté'}, {'authorId': '1748276', 'name': 'S. Shirmohammadi'}]","{'url': 'https://doi.org/10.1109/tnsm.2021.3095463', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/tnsm.2021.3095463?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/tnsm.2021.3095463, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","failure management and cost-aware traffic engineering are two important tasks done in network operation centers (noc). these are performed by expert technicians who must carefully analyze the network state and the flow of incoming alarms to decide how, where and when to take actions on the network. while based on implicit guiding principles, these network actions are very hard to automate with explicit rules due to the high complexity of the system; hence noc action is essentially a manual process today. to automate part of that process, in this paper we introduce an action recommendation engine (are) that can learn implicit noc action rules with supervised machine learning from historical data. as a result, are can recommend suitable action(s) to remedy network faults and engineer the traffic to minimize costs, all while maximizing the users’ quality of experience. to quantify the effectiveness of different noc action scenarios, we introduce the qoe-opex metric which balances between users’ quality of experience and isp’s operational costs. after proper model training on 56,000 data points with 66 features, we demonstrate that are can effectively reproduce implicit action-taking logic of noc technicians, thus moving us one step closer to reliable autonomous networks and fully-automated nocs.",https://doi.org/10.1109/tnsm.2021.3095463
82921c5f3622cb54aba641e7e12f5bb0befe8764,Blockchain-Secured Recommender System for Special Need Patients Using Deep Learning,"Recommender systems offer several advantages to hospital data management units and patients with special needs. These systems are more dependent on the extreme subtle hospital-patient data. Thus, disregarding the confidentiality of patients with special needs is not an option. In recent times, several proposed techniques failed to cryptographically guarantee the data privacy of the patients with special needs in the diet recommender systems (RSs) deployment. In order to tackle this pitfall, this paper incorporates a blockchain privacy system (BPS) into deep learning for a diet recommendation system for patients with special needs. Our proposed technique allows patients to get notifications about recommended treatments and medications based on their personalized data without revealing their confidential information. Additionally, the paper implemented machine and deep learning algorithms such as RNN, Logistic Regression, MLP, etc., on an Internet of Medical Things (IoMT) dataset acquired via the internet and hospitals that comprises the data of 50 patients with 13 features of various diseases and 1,000 products. The product section has a set of eight features. The IoMT data features were analyzed with BPS and further encoded prior to the application of deep and machine learning-based frameworks. The performance of the different machine and deep learning methods were carried out and the results verify that the long short-term memory (LSTM) technique is more effective than other schemes regarding prediction accuracy, precision, F1-measures, and recall in a secured blockchain privacy system. Results showed that 97.74% accuracy utilizing the LSTM deep learning model was attained. The precision of 98%, recall, and F1-measure of 99% each for the allowed class was also attained. For the disallowed class, the scores were 89, 73, and 80% for precision, recall, and F1-measure, respectively. The performance of our proposed BPS is subdivided into two categories: the secured communication channel of the recommendation system and an enhanced deep learning approach using health base medical dataset that spontaneously identifies what food a patient with special needs should have based on their disease and certain features including gender, weight, age, etc. The proposed system is outstanding as none of the earlier revised works of literature described a recommender system of this kind.",2021,"[{'authorId': '9630150', 'name': 'Eric Appiah Mantey'}, {'authorId': '1889592', 'name': 'Conghua Zhou'}, {'authorId': '51313099', 'name': 'J. H. Anajemba'}, {'authorId': '2127409150', 'name': 'I. M. Okpalaoguchi'}, {'authorId': '2115004854', 'name': 'Onyeachonam Dominic-Mario Chiadika'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fpubh.2021.737269/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8488210, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems offer several advantages to hospital data management units and patients with special needs. these systems are more dependent on the extreme subtle hospital-patient data. thus, disregarding the confidentiality of patients with special needs is not an option. in recent times, several proposed techniques failed to cryptographically guarantee the data privacy of the patients with special needs in the diet recommender systems (rss) deployment. in order to tackle this pitfall, this paper incorporates a blockchain privacy system (bps) into deep learning for a diet recommendation system for patients with special needs. our proposed technique allows patients to get notifications about recommended treatments and medications based on their personalized data without revealing their confidential information. additionally, the paper implemented machine and deep learning algorithms such as rnn, logistic regression, mlp, etc., on an internet of medical things (iomt) dataset acquired via the internet and hospitals that comprises the data of 50 patients with 13 features of various diseases and 1,000 products. the product section has a set of eight features. the iomt data features were analyzed with bps and further encoded prior to the application of deep and machine learning-based frameworks. the performance of the different machine and deep learning methods were carried out and the results verify that the long short-term memory (lstm) technique is more effective than other schemes regarding prediction accuracy, precision, f1-measures, and recall in a secured blockchain privacy system. results showed that 97.74% accuracy utilizing the lstm deep learning model was attained. the precision of 98%, recall, and f1-measure of 99% each for the allowed class was also attained. for the disallowed class, the scores were 89, 73, and 80% for precision, recall, and f1-measure, respectively. the performance of our proposed bps is subdivided into two categories: the secured communication channel of the recommendation system and an enhanced deep learning approach using health base medical dataset that spontaneously identifies what food a patient with special needs should have based on their disease and certain features including gender, weight, age, etc. the proposed system is outstanding as none of the earlier revised works of literature described a recommender system of this kind.",https://www.frontiersin.org/articles/10.3389/fpubh.2021.737269/pdf
0f8d57634127c708c46688501cf2d0cf01386bde,Machine Learning Techniques for Recommender Systems – A Comparative Case Analysis,"Recommender System (RS) is one of the most popular applications of Artificial Intelligence which attracted researchers all around the world. Many machine learning algorithms are used to develop RSs. Choosing the best machine learning algorithm to provide users with a product or service is the most challenging task in the area of RSs. Now we are witnessing a paradigm shift in the purchase habits of people from in-shop to online resulting in the availability of online information exponentially growing every day. The ever-increasing online information and the number of online users create new avenues in RS. In an online shopping scenario, these systems must be able to recommend relevant items to the users. The RSs have to deal with the huge amount of information by filtering the relevant information based on the analysis made on the inputs made by the users during their online sessions. These systems can recommend appropriate items to users based on their interest and previous preference which can lead to increased sales. The three major techniques used to build a RS are content-based, collaborative based and hybrid-based. This paper presents the various applications of RSs and makes a detailed comparative study of different machine learning approaches used. The methodologies used for identifying research articles for analysis, the merits and demerits of different techniques in RSs and domain-specific applications of these techniques are well explained here with scientific review analysis.",2021,"[{'authorId': '80149125', 'name': 'B. Thomas'}, {'authorId': '2089749567', 'name': 'Amruth K John'}]","{'url': 'https://doi.org/10.1088/1757-899x/1085/1/012011', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1088/1757-899X/1085/1/012011?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/1757-899X/1085/1/012011, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender system (rs) is one of the most popular applications of artificial intelligence which attracted researchers all around the world. many machine learning algorithms are used to develop rss. choosing the best machine learning algorithm to provide users with a product or service is the most challenging task in the area of rss. now we are witnessing a paradigm shift in the purchase habits of people from in-shop to online resulting in the availability of online information exponentially growing every day. the ever-increasing online information and the number of online users create new avenues in rs. in an online shopping scenario, these systems must be able to recommend relevant items to the users. the rss have to deal with the huge amount of information by filtering the relevant information based on the analysis made on the inputs made by the users during their online sessions. these systems can recommend appropriate items to users based on their interest and previous preference which can lead to increased sales. the three major techniques used to build a rs are content-based, collaborative based and hybrid-based. this paper presents the various applications of rss and makes a detailed comparative study of different machine learning approaches used. the methodologies used for identifying research articles for analysis, the merits and demerits of different techniques in rss and domain-specific applications of these techniques are well explained here with scientific review analysis.",https://doi.org/10.1088/1757-899x/1085/1/012011
186f0d6e18289ffccdcc868d1c0a2d7065101063,Interpretable Recommender System With Heterogeneous Information: A Geometric Deep Learning Perspective,"Recommender systems (RS) are ubiquitous in digital space. This paper develops a deep learning-based approach to address three practical challenges in RS: complex structures of high-dimensional data, noise in relational information, and the black-box nature of machine learning algorithms. Our method—Multi-GraphGraph Attention Network (MG-GAT)—learns latent user and business representations by aggregating a diverse set of information from neighbors of each user (business) on a neighbor importance graph. MG-GAT out-performs state-of-the-art deep learning models in the recommendation task using two large-scale datasets collected from Yelp and four other standard datasets in RS. The improved performance highlights MG-GAT’s advantage in incorporating multi-modal features in a principled manner. The features importance, neighbor importance graph, and latent representations reveal business insights on predictive features and explainable characteristics of business and users. Moreover, the learned neighbor importance graph can be used in a variety of management applications, such as targeting customers, promoting new businesses, and designing information acquisition strategies. Our paper presents a quintessential big data application of deep learning models in management while providing interpretability essential for real-world decision-making.",2020,"[{'authorId': '1828604', 'name': 'Yan Leng'}, {'authorId': '2057488210', 'name': 'Rodrigo Ruiz'}, {'authorId': '145392527', 'name': 'Xiaowen Dong'}, {'authorId': '1682773', 'name': 'A. Pentland'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3696092?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3696092, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems (rs) are ubiquitous in digital space. this paper develops a deep learning-based approach to address three practical challenges in rs: complex structures of high-dimensional data, noise in relational information, and the black-box nature of machine learning algorithms. our method—multi-graphgraph attention network (mg-gat)—learns latent user and business representations by aggregating a diverse set of information from neighbors of each user (business) on a neighbor importance graph. mg-gat out-performs state-of-the-art deep learning models in the recommendation task using two large-scale datasets collected from yelp and four other standard datasets in rs. the improved performance highlights mg-gat’s advantage in incorporating multi-modal features in a principled manner. the features importance, neighbor importance graph, and latent representations reveal business insights on predictive features and explainable characteristics of business and users. moreover, the learned neighbor importance graph can be used in a variety of management applications, such as targeting customers, promoting new businesses, and designing information acquisition strategies. our paper presents a quintessential big data application of deep learning models in management while providing interpretability essential for real-world decision-making.",
4a215520c5c57ba29e8a55a71e1691c0521a5ab5,Designing and deploying insurance recommender systems using machine learning,"Recommender systems have become extremely important to various types of industries where customer interaction and feedback is paramount to the success of the business. For companies that face changes that arise with ever‐growing markets, providing product recommendations to new and existing customers is a challenge. Our goal is to give our customers personalized recommendations based on what other similar people with similar portfolios have, in order to make sure they are adequately covered for their needs. Our system uses customer characteristics in addition to customer portfolio data. Since the number of possible recommendable products is relatively small, compared to other recommender domains, and missing data is relatively frequent, we chose to use Bayesian Networks for modeling our systems. We also present a deep‐learning‐based approach to provide recommendations to prospects (potential customers) where only external marketing data is available at the time of prediction.",2020,"[{'authorId': '40233730', 'name': 'M. Qazi'}, {'authorId': '1729267871', 'name': 'Kaya Tollas'}, {'authorId': '66479836', 'name': 'Teja Kanchinadam'}, {'authorId': '2009082', 'name': 'Joseph Bockhorst'}, {'authorId': '2064481572', 'name': 'G. Fung'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/widm.1363?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/widm.1363, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems have become extremely important to various types of industries where customer interaction and feedback is paramount to the success of the business. for companies that face changes that arise with ever‐growing markets, providing product recommendations to new and existing customers is a challenge. our goal is to give our customers personalized recommendations based on what other similar people with similar portfolios have, in order to make sure they are adequately covered for their needs. our system uses customer characteristics in addition to customer portfolio data. since the number of possible recommendable products is relatively small, compared to other recommender domains, and missing data is relatively frequent, we chose to use bayesian networks for modeling our systems. we also present a deep‐learning‐based approach to provide recommendations to prospects (potential customers) where only external marketing data is available at the time of prediction.",
2cd9d31c78185d3c52db64c760476d07bb8bc435,Drug Recommendation System based on Sentiment Analysis of Drug Reviews using Machine Learning,"Since coronavirus has shown up, inaccessibility of legitimate clinical resources is at its peak, like the shortage of specialists and healthcare workers, lack of proper equipment and medicines etc. The entire medical fraternity is in distress, which results in numerous individual's demise. Due to unavailability, individuals started taking medication independently without appropriate consultation, making the health condition worse than usual. As of late, machine learning has been valuable in numerous applications, and there is an increase in innovative work for automation. This paper intends to present a drug recommender system that can drastically reduce specialists heap. In this research, we build a medicine recommendation system that uses patient reviews to predict the sentiment using various vectorization processes like Bow, TF-IDF, Word2Vec, and Manual Feature Analysis, which can help recommend the top drug for a given disease by different classification algorithms. The predicted sentiments were evaluated by precision, recall, f1score, accuracy, and AUC score. The results show that classifier LinearSVC using TF-IDF vectorization outperforms all other models with 93% accuracy.",2021,"[{'authorId': '108213111', 'name': 'Satvik Garg'}]","{'url': 'https://arxiv.org/pdf/2104.01113', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2104.01113, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","since coronavirus has shown up, inaccessibility of legitimate clinical resources is at its peak, like the shortage of specialists and healthcare workers, lack of proper equipment and medicines etc. the entire medical fraternity is in distress, which results in numerous individual's demise. due to unavailability, individuals started taking medication independently without appropriate consultation, making the health condition worse than usual. as of late, machine learning has been valuable in numerous applications, and there is an increase in innovative work for automation. this paper intends to present a drug recommender system that can drastically reduce specialists heap. in this research, we build a medicine recommendation system that uses patient reviews to predict the sentiment using various vectorization processes like bow, tf-idf, word2vec, and manual feature analysis, which can help recommend the top drug for a given disease by different classification algorithms. the predicted sentiments were evaluated by precision, recall, f1score, accuracy, and auc score. the results show that classifier linearsvc using tf-idf vectorization outperforms all other models with 93% accuracy.",https://arxiv.org/pdf/2104.01113
f7ed7580fdddf0eaacb6610d84de1451ab7a552e,Explicit or implicit feedback? engagement or satisfaction?: a field experiment on machine-learning-based recommender systems,"Recommender systems algorithms are generally evaluated primarily on machine learning criteria such as recommendation accuracy or top-n precision. In this work, we evaluate six recommendation algorithms from a user-centric perspective, collecting both objective user activity data and subjective user perceptions. In a field experiment involving 1508 users who participated for at least a month, we compare six algorithms built using machine learning techniques, ranging from supervised matrix factorization, contextual bandit learning to Q learning. We found that the objective design in machine-learning-based recommender systems significantly affects user experience. Specifically, a recommender optimizing for implicit action prediction error engages users more than optimizing for explicit rating prediction error when modeled with the classical matrix factorization algorithms, which empirically explains the historical transition of recommender system research from modeling explicit feedback data to implicit feedback data. However, the action-based recommender is not as precise as the rating-based recommender in that it increases not only positive engagement but also negative engagement, e.g., negative action rate and user browsing effort which are negatively correlated with user satisfaction. We show that blending both explicit and implicit feedback from users through an online learning algorithm can gain the benefits of engagement and mitigate one of the possible costs (i.e., the increased browsing effort).",2018,"[{'authorId': '2110999732', 'name': 'Qian Zhao'}, {'authorId': '145192090', 'name': 'F. M. Harper'}, {'authorId': '1744007', 'name': 'G. Adomavicius'}, {'authorId': '2478310', 'name': 'J. Konstan'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3167132.3167275?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3167132.3167275, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems algorithms are generally evaluated primarily on machine learning criteria such as recommendation accuracy or top-n precision. in this work, we evaluate six recommendation algorithms from a user-centric perspective, collecting both objective user activity data and subjective user perceptions. in a field experiment involving 1508 users who participated for at least a month, we compare six algorithms built using machine learning techniques, ranging from supervised matrix factorization, contextual bandit learning to q learning. we found that the objective design in machine-learning-based recommender systems significantly affects user experience. specifically, a recommender optimizing for implicit action prediction error engages users more than optimizing for explicit rating prediction error when modeled with the classical matrix factorization algorithms, which empirically explains the historical transition of recommender system research from modeling explicit feedback data to implicit feedback data. however, the action-based recommender is not as precise as the rating-based recommender in that it increases not only positive engagement but also negative engagement, e.g., negative action rate and user browsing effort which are negatively correlated with user satisfaction. we show that blending both explicit and implicit feedback from users through an online learning algorithm can gain the benefits of engagement and mitigate one of the possible costs (i.e., the increased browsing effort).",
b25083b5de852c9444646438137aae03c39ee4f9,A Recommender System for the Web: Using User Profiles and Machine Learning Methods,"Web development without an integrated structure makes lots of difficulties for users. Web personalization systems are presented to make the website compatible with interest of users in both aspects of contents and services. In this paper extracting user navigation patterns is used to capture similar behaviors of users in order to increase the quality of recommendations. Based on patterns extracted from the same user navigation, recommendations are provided to the user to make it easier to navigate. Recently, web browsing techniques have been widely used for personalization. In this study, a method is proposed to create a user profile with the web usage mining by clustering and neural networks in order to predict the user's future requests and then generate a list of the pages of user's favorites. Simulation results shows that proposed method will increase the accuracy of recommender systems.",2014,"[{'authorId': '2112906241', 'name': 'Saman Rajabi'}, {'authorId': '3275209', 'name': 'A. Harounabadi'}, {'authorId': '2127070', 'name': 'Vahe Aghazarian'}]","{'url': 'https://doi.org/10.5120/16840-6694', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5120/16840-6694?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5120/16840-6694, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","web development without an integrated structure makes lots of difficulties for users. web personalization systems are presented to make the website compatible with interest of users in both aspects of contents and services. in this paper extracting user navigation patterns is used to capture similar behaviors of users in order to increase the quality of recommendations. based on patterns extracted from the same user navigation, recommendations are provided to the user to make it easier to navigate. recently, web browsing techniques have been widely used for personalization. in this study, a method is proposed to create a user profile with the web usage mining by clustering and neural networks in order to predict the user's future requests and then generate a list of the pages of user's favorites. simulation results shows that proposed method will increase the accuracy of recommender systems.",https://doi.org/10.5120/16840-6694
f59093c03a4c78b84a023b22b346ffdb48f16836,Vertical Federated Graph Neural Network for Recommender System,"Conventional recommender systems are required to train the recommendation model using a centralized database. However, due to data privacy concerns, this is often impractical when multi-parties are involved in recommender system training. Federated learning appears as an excellent solution to the data isolation and privacy problem. Recently, Graph neural network (GNN) is becoming a promising approach for federated recommender systems. However, a key challenge is to conduct embedding propagation while preserving the privacy of the graph structure. Few studies have been conducted on the federated GNN-based recommender system. Our study proposes the first vertical federated GNN-based recommender system, called VerFedGNN. We design a framework to transmit: (i) the summation of neighbor embeddings using random projection, and (ii) gradients of public parameter perturbed by ternary quantization mechanism. Empirical studies show that VerFedGNN has competitive prediction accuracy with existing privacy preserving GNN frameworks while enhanced privacy protection for users' interaction information.",2023,"[{'authorId': '2187874977', 'name': 'Peihua Mai'}, {'authorId': '2057013573', 'name': 'Yan Pang'}]","{'url': 'http://arxiv.org/pdf/2303.05786', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2303.05786, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","conventional recommender systems are required to train the recommendation model using a centralized database. however, due to data privacy concerns, this is often impractical when multi-parties are involved in recommender system training. federated learning appears as an excellent solution to the data isolation and privacy problem. recently, graph neural network (gnn) is becoming a promising approach for federated recommender systems. however, a key challenge is to conduct embedding propagation while preserving the privacy of the graph structure. few studies have been conducted on the federated gnn-based recommender system. our study proposes the first vertical federated gnn-based recommender system, called verfedgnn. we design a framework to transmit: (i) the summation of neighbor embeddings using random projection, and (ii) gradients of public parameter perturbed by ternary quantization mechanism. empirical studies show that verfedgnn has competitive prediction accuracy with existing privacy preserving gnn frameworks while enhanced privacy protection for users' interaction information.",http://arxiv.org/pdf/2303.05786
5670ce06f2437c966b526e1dcccb8483c74621e8,Realizing an Efficient IoMT-Assisted Patient Diet Recommendation System Through Machine Learning Model,"Recent studies have shown that robust diets recommended to patients by Dietician or an Artificial Intelligent automated medical diet based cloud system can increase longevity, protect against further disease, and improve the overall quality of life. However, medical personnel are yet to fully understand patient-dietician’s rationale of recommender system. This paper proposes a deep learning solution for health base medical dataset that automatically detects which food should be given to which patient base on the disease and other features like age, gender, weight, calories, protein, fat, sodium, fiber, cholesterol. This research framework is focused on implementing both machine and deep learning algorithms like, logistic regression, naive bayes, Recurrent Neural Network (RNN), Multilayer Perceptron (MLP), Gated Recurrent Units (GRU), and Long Short-Term Memory (LSTM). The medical dataset collected through the internet and hospitals consists of 30 patient’s data with 13 features of different diseases and 1000 products. Product section has 8 features set. The features of these IoMT data were analyzed and further encoded before applying deep and machine and learning-based protocols. The performance of various machine learning and deep learning techniques was carried and the result proves that LSTM technique performs better than other scheme with respect to forecasting accuracy, recall, precision, and <inline-formula> <tex-math notation=""LaTeX"">$F1$ </tex-math></inline-formula>-measures. We achieved 97.74% accuracy using LSTM deep learning model. Similarly 98% precision, 99% recall and <inline-formula> <tex-math notation=""LaTeX"">$99\%~F1$ </tex-math></inline-formula>-measure for allowed class is achieved, and for not-allowed class precision is 89%, recall score is 73% and <inline-formula> <tex-math notation=""LaTeX"">$F1$ </tex-math></inline-formula> Measure score is 80%.",2020,"[{'authorId': '41018486', 'name': 'C. Iwendi'}, {'authorId': '2144296163', 'name': 'Suleman Khan'}, {'authorId': '51313099', 'name': 'J. H. Anajemba'}, {'authorId': '47311590', 'name': 'A. Bashir'}, {'authorId': '143789028', 'name': 'F. Noor'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/08964364.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2020.2968537?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2020.2968537, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent studies have shown that robust diets recommended to patients by dietician or an artificial intelligent automated medical diet based cloud system can increase longevity, protect against further disease, and improve the overall quality of life. however, medical personnel are yet to fully understand patient-dietician’s rationale of recommender system. this paper proposes a deep learning solution for health base medical dataset that automatically detects which food should be given to which patient base on the disease and other features like age, gender, weight, calories, protein, fat, sodium, fiber, cholesterol. this research framework is focused on implementing both machine and deep learning algorithms like, logistic regression, naive bayes, recurrent neural network (rnn), multilayer perceptron (mlp), gated recurrent units (gru), and long short-term memory (lstm). the medical dataset collected through the internet and hospitals consists of 30 patient’s data with 13 features of different diseases and 1000 products. product section has 8 features set. the features of these iomt data were analyzed and further encoded before applying deep and machine and learning-based protocols. the performance of various machine learning and deep learning techniques was carried and the result proves that lstm technique performs better than other scheme with respect to forecasting accuracy, recall, precision, and $f1$ -measures. we achieved 97.74% accuracy using lstm deep learning model. similarly 98% precision, 99% recall and $99\%~f1$ -measure for allowed class is achieved, and for not-allowed class precision is 89%, recall score is 73% and $f1$ measure score is 80%.",https://ieeexplore.ieee.org/ielx7/6287639/8948470/08964364.pdf
9dc912557bd2dae91bcbedf8bbe8f338456ffa29,Design and analysis of an efficient machine learning based hybrid recommendation system with enhanced density-based spatial clustering for digital e-learning applications,"A decision-making system is one of the most important tools in data mining. The data mining field has become a forum where it is necessary to utilize users' interactions, decision-making processes and overall experience. Nowadays, e-learning is indeed a progressive method to provide online education in long-lasting terms, contrasting to the customary head-to-head process of educating with culture. Through e-learning, an ever-increasing number of learners have profited from different programs. Notwithstanding, the highly assorted variety of the students on the internet presents new difficulties to the conservative one-estimate fit-all learning systems, in which a solitary arrangement of learning assets is specified to the learners. The problems and limitations in well-known recommender systems are much variations in the expected absolute error, consuming more query processing time, and providing less accuracy in the final recommendation. The main objectives of this research are the design and analysis of a new transductive support vector machine-based hybrid personalized hybrid recommender for the machine learning public data sets. The learning experience has been achieved through the habits of the learners. This research designs some of the new strategies that are experimented with to improve the performance of a hybrid recommender. The modified one-source denoising approach is designed to preprocess the learner dataset. The modified anarchic society optimization strategy is designed to improve the performance measurements. The enhanced and generalized sequential pattern strategy is proposed to mine the sequential pattern of learners. The enhanced transductive support vector machine is developed to evaluate the extracted habits and interests. These new strategies analyze the confidential rate of learners and provide the best recommendation to the learners. The proposed generalized model is simulated on public datasets for machine learning such as movies, music, books, food, merchandise, healthcare, dating, scholarly paper, and open university learning recommendation. The experimental analysis concludes that the enhanced clustering strategy discovers clusters that are based on random size. The proposed recommendation strategies achieve better significant performance over the methods in terms of expected absolute error, accuracy, ranking score, recall, and precision measurements. The accuracy of the proposed datasets lies between 82 and 98%. The MAE metric lies between 5 and 19.2% for the simulated public datasets. The simulation results prove the proposed generalized recommender has a great strength to improve the quality and performance.",2021,"[{'authorId': '98411009', 'name': 'S. Bhaskaran'}, {'authorId': '2258140279', 'name': 'Raja Marappan'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s40747-021-00509-4.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s40747-021-00509-4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s40747-021-00509-4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a decision-making system is one of the most important tools in data mining. the data mining field has become a forum where it is necessary to utilize users' interactions, decision-making processes and overall experience. nowadays, e-learning is indeed a progressive method to provide online education in long-lasting terms, contrasting to the customary head-to-head process of educating with culture. through e-learning, an ever-increasing number of learners have profited from different programs. notwithstanding, the highly assorted variety of the students on the internet presents new difficulties to the conservative one-estimate fit-all learning systems, in which a solitary arrangement of learning assets is specified to the learners. the problems and limitations in well-known recommender systems are much variations in the expected absolute error, consuming more query processing time, and providing less accuracy in the final recommendation. the main objectives of this research are the design and analysis of a new transductive support vector machine-based hybrid personalized hybrid recommender for the machine learning public data sets. the learning experience has been achieved through the habits of the learners. this research designs some of the new strategies that are experimented with to improve the performance of a hybrid recommender. the modified one-source denoising approach is designed to preprocess the learner dataset. the modified anarchic society optimization strategy is designed to improve the performance measurements. the enhanced and generalized sequential pattern strategy is proposed to mine the sequential pattern of learners. the enhanced transductive support vector machine is developed to evaluate the extracted habits and interests. these new strategies analyze the confidential rate of learners and provide the best recommendation to the learners. the proposed generalized model is simulated on public datasets for machine learning such as movies, music, books, food, merchandise, healthcare, dating, scholarly paper, and open university learning recommendation. the experimental analysis concludes that the enhanced clustering strategy discovers clusters that are based on random size. the proposed recommendation strategies achieve better significant performance over the methods in terms of expected absolute error, accuracy, ranking score, recall, and precision measurements. the accuracy of the proposed datasets lies between 82 and 98%. the mae metric lies between 5 and 19.2% for the simulated public datasets. the simulation results prove the proposed generalized recommender has a great strength to improve the quality and performance.",https://link.springer.com/content/pdf/10.1007/s40747-021-00509-4.pdf
4558d4eb033dffcf7a260ea63f5ef6809603dffd,FedDyn: A dynamic and efficient federated distillation approach on Recommender System,"Federated Learning (FL) is a popular distributed machine learning paradigm that enables devices to work together to train a centralized model without transmitting raw data. However, when the model becomes complex, mobile devices’ communication overhead can be unacceptably large in traditional FL methods. To address this problem, Federated Distillation (FD) is proposed as a federated version of knowledge distillation. Most of the recent FD methods calculate the model output (logits) of each client as the local knowledge on a public proxy dataset and do distillation with the average of the clients’ logits on the server side. Nevertheless, these FD methods are not robust and perform poorly in the non-IID (data is nonindependent and non-identically distributed) scenario such as Federated Recommendation (FR). In order to eliminate the non-IID problem and apply FD in FR, we proposed a novel method named FedDyn to construct a proxy dataset and extract local knowledge dynamically in this paper. In this method, we replaced the average strategy with focus distillation to strengthen reliable knowledge, which solved the non-IID problem that the local model has biased knowledge. The average strategy is a dilution and perturbation of knowledge since it treats reliable and unreliable knowledge equally important. In addition, to prevent inference of private user information from local knowledge, we used a method like local differential privacy techniques to protect this knowledge on the client side. The experimental results showed that our method has a faster convergence speed and lower communication overhead than the baselines on three datasets, including MovieLens-10OK, MovieLens-IM and Pinterest.",2023,"[{'authorId': '2213994098', 'name': 'Cheng Jin'}, {'authorId': '2213341961', 'name': 'Xuandong Chen'}, {'authorId': '2213606894', 'name': 'Yi Gu'}, {'authorId': '2108646557', 'name': 'Qu Li'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICPADS56603.2022.00107?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICPADS56603.2022.00107, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","federated learning (fl) is a popular distributed machine learning paradigm that enables devices to work together to train a centralized model without transmitting raw data. however, when the model becomes complex, mobile devices’ communication overhead can be unacceptably large in traditional fl methods. to address this problem, federated distillation (fd) is proposed as a federated version of knowledge distillation. most of the recent fd methods calculate the model output (logits) of each client as the local knowledge on a public proxy dataset and do distillation with the average of the clients’ logits on the server side. nevertheless, these fd methods are not robust and perform poorly in the non-iid (data is nonindependent and non-identically distributed) scenario such as federated recommendation (fr). in order to eliminate the non-iid problem and apply fd in fr, we proposed a novel method named feddyn to construct a proxy dataset and extract local knowledge dynamically in this paper. in this method, we replaced the average strategy with focus distillation to strengthen reliable knowledge, which solved the non-iid problem that the local model has biased knowledge. the average strategy is a dilution and perturbation of knowledge since it treats reliable and unreliable knowledge equally important. in addition, to prevent inference of private user information from local knowledge, we used a method like local differential privacy techniques to protect this knowledge on the client side. the experimental results showed that our method has a faster convergence speed and lower communication overhead than the baselines on three datasets, including movielens-10ok, movielens-im and pinterest.",
fb8d71f2b5596d58549166e9c22d8692fc765742,MTRecS-DLT: Multi-Modal Transport Recommender System using Deep Learning and Tree Models,"Multi-modal transport recommender systems aim to provide different users with different route choices for more than one mode of transportation. Most existing systems focus on unimodal transportation providing shortest distance or travel time. Knowing that the use of machine learning and deep learning techniques are achieving success in many fields, it has also been applied to improve the transport networks by helping individuals to meet their needs and observe their various preferences. In this paper, we develop a model called MTRecS-DLT (Multi-Modal Transport Recommender System using Deep Learning and Tree Models) for recommending the most appropriate transport mode for different users. We have used the weighted average ensembling method of Convolutional Neural Network (CNN) and Gradient-Boosted Decision Trees (GBDT) that shows promising results. We have extracted context and user features from the training data. Then, CNN has been applied to extract latent features. The proposed model utilizes a weighted average ensembling to combine CNN and GBDT.",2019,"[{'authorId': '1470750141', 'name': 'Ayat Abedalla'}, {'authorId': '145398706', 'name': 'A. Fadel'}, {'authorId': '118482523', 'name': 'Ibraheem Tuffaha'}, {'authorId': '1410926560', 'name': 'Hani Al-Omari'}, {'authorId': '15535231', 'name': 'Mohammad Omari'}, {'authorId': '19265487', 'name': 'Malak Abdullah'}, {'authorId': '1398466553', 'name': 'M. Al-Ayyoub'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/SNAMS.2019.8931864?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SNAMS.2019.8931864, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","multi-modal transport recommender systems aim to provide different users with different route choices for more than one mode of transportation. most existing systems focus on unimodal transportation providing shortest distance or travel time. knowing that the use of machine learning and deep learning techniques are achieving success in many fields, it has also been applied to improve the transport networks by helping individuals to meet their needs and observe their various preferences. in this paper, we develop a model called mtrecs-dlt (multi-modal transport recommender system using deep learning and tree models) for recommending the most appropriate transport mode for different users. we have used the weighted average ensembling method of convolutional neural network (cnn) and gradient-boosted decision trees (gbdt) that shows promising results. we have extracted context and user features from the training data. then, cnn has been applied to extract latent features. the proposed model utilizes a weighted average ensembling to combine cnn and gbdt.",
857e5b9c49c98f624d682fbc90ce23b534652199,Learning Path Recommender System based on Recurrent Neural Network,"Programming education has recently received increased attention due to growing demands for programming and information technology skills. However, a lack of teaching materials and human resources presents a major challenge to meeting the growing demand for programming education. One way to compensate for a shortage of trained teachers is to use machine learning techniques to assist learners. Therefore, we propose a learning path recommendation system based on a learner’s ability charts by means of a recurrent neural network. In brief, a learning path is constructed from a learner’s submission history with a trial-and-error process, and the learner’s ability chart is used as a barometer of their current knowledge. In this paper, an approach for constructing a learning path recommendation system by using ability charts and its implementation based on a sequential prediction model by a recurrent neural network, are presented. Experimental evaluation with data from an e-learning system is also provided.",2018,"[{'authorId': '2111117751', 'name': 'Tomohiro Saito'}, {'authorId': '2338416509', 'name': 'Yutaka Watanobe'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICAWST.2018.8517231?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICAWST.2018.8517231, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","programming education has recently received increased attention due to growing demands for programming and information technology skills. however, a lack of teaching materials and human resources presents a major challenge to meeting the growing demand for programming education. one way to compensate for a shortage of trained teachers is to use machine learning techniques to assist learners. therefore, we propose a learning path recommendation system based on a learner’s ability charts by means of a recurrent neural network. in brief, a learning path is constructed from a learner’s submission history with a trial-and-error process, and the learner’s ability chart is used as a barometer of their current knowledge. in this paper, an approach for constructing a learning path recommendation system by using ability charts and its implementation based on a sequential prediction model by a recurrent neural network, are presented. experimental evaluation with data from an e-learning system is also provided.",
0e97e1772578ef856e0b91350c7fe8f1f39bb0a6,Intelligent Digital Learning: Agent-Based Recommender System,"In the context of intelligent digital learning, we propose an agent-based recommender system that aims to help learners overcome their gaps by suggesting relevant learning resources. The main idea is to provide them with appropriate support in order to make their learning experience more effective. To this end we design an agent-based cooperative system where autonomous agents are able to update recommendation data and to improve the recommender outcome on behalf of their past experiences in the learning platform.",2017,"[{'authorId': '1397816062', 'name': 'I. Brigui-Chtioui'}, {'authorId': '1685736', 'name': 'Philippe Caillou'}, {'authorId': '46826110', 'name': 'E. Negre'}]","{'url': 'https://hal.inria.fr/hal-01680527/file/icmlc17.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3055635.3056592?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3055635.3056592, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the context of intelligent digital learning, we propose an agent-based recommender system that aims to help learners overcome their gaps by suggesting relevant learning resources. the main idea is to provide them with appropriate support in order to make their learning experience more effective. to this end we design an agent-based cooperative system where autonomous agents are able to update recommendation data and to improve the recommender outcome on behalf of their past experiences in the learning platform.",https://hal.inria.fr/hal-01680527/file/icmlc17.pdf
9779f919685adee936835eff46914d3d69d9ccb9,Bias and Debias in Recommender System: A Survey and Future Directions,"While recent years have witnessed a rapid growth of research papers on recommender system (RS), most of the papers focus on inventing machine learning models to better fit user behavior data. However, user behavior data is observational rather than experimental. This makes various biases widely exist in the data, including but not limited to selection bias, position bias, exposure bias, and popularity bias. Blindly fitting the data without considering the inherent biases will result in many serious issues, e.g., the discrepancy between offline evaluation and online metrics, hurting user satisfaction and trust on the recommendation service, and so on. To transform the large volume of research models into practical improvements, it is highly urgent to explore the impacts of the biases and perform debiasing when necessary. When reviewing the papers that consider biases in RS, we find that, to our surprise, the studies are rather fragmented and lack a systematic organization. The terminology “bias” is widely used in the literature, but its definition is usually vague and even inconsistent across papers. This motivates us to provide a systematic survey of existing work on RS biases. In this paper, we first summarize seven types of biases in recommendation, along with their definitions and characteristics. We then provide a taxonomy to position and organize the existing work on recommendation debiasing. Finally, we identify some open challenges and envision some future directions, with the hope of inspiring more research work on this important yet less investigated topic. The summary of debiasing methods reviewed in this survey can be found at https://github.com/jiawei-chen/RecDebiasing.",2020,"[{'authorId': '1452347263', 'name': 'Jiawei Chen'}, {'authorId': '1753659544', 'name': 'Hande Dong'}, {'authorId': '2144796537', 'name': 'Xiang Wang'}, {'authorId': '2163400298', 'name': 'Fuli Feng'}, {'authorId': '2146059323', 'name': 'Meng Wang'}, {'authorId': '7792071', 'name': 'Xiangnan He'}]","{'url': 'https://arxiv.org/pdf/2010.03240', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2010.03240, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","while recent years have witnessed a rapid growth of research papers on recommender system (rs), most of the papers focus on inventing machine learning models to better fit user behavior data. however, user behavior data is observational rather than experimental. this makes various biases widely exist in the data, including but not limited to selection bias, position bias, exposure bias, and popularity bias. blindly fitting the data without considering the inherent biases will result in many serious issues, e.g., the discrepancy between offline evaluation and online metrics, hurting user satisfaction and trust on the recommendation service, and so on. to transform the large volume of research models into practical improvements, it is highly urgent to explore the impacts of the biases and perform debiasing when necessary. when reviewing the papers that consider biases in rs, we find that, to our surprise, the studies are rather fragmented and lack a systematic organization. the terminology “bias” is widely used in the literature, but its definition is usually vague and even inconsistent across papers. this motivates us to provide a systematic survey of existing work on rs biases. in this paper, we first summarize seven types of biases in recommendation, along with their definitions and characteristics. we then provide a taxonomy to position and organize the existing work on recommendation debiasing. finally, we identify some open challenges and envision some future directions, with the hope of inspiring more research work on this important yet less investigated topic. the summary of debiasing methods reviewed in this survey can be found at https://github.com/jiawei-chen/recdebiasing.",https://arxiv.org/pdf/2010.03240
4e5e2a14f4d1d8b96a95b2eda0a9810233888b94,Machine Learning based Efficient Recommendation System for Book Selection using User based Collaborative Filtering Algorithm,"Recommender system is a new generation of internet tool that helps users to access the web and receive information about their preferences. Using an online recommender is comparatively an easy and faster procedure to purchase items and this is done quickly. Recommendation systems plays an indispensable role in ecommerce websites to help users in identifying the right goods. One of the best methods to increase profits and attract customers is a recommendation process. The existing methodologies allow the systems to collect the irrelevant data and lead to a downfall in attracting the users and completing their work in a quick and reliable way. This paper provides an overview of the Recommendation Systems that is currently employed in the operations of the online book shopping domain. This paper proposes a simple understandable system for book recommendations that help readers to suggest the right book, which is to be studied next. In recent years, information analysis challenge has been focused on for the administration recommendation system. For clients, network assets are completely linked and quickly developed. The proposed method works on training, feedback, management, reporting, configuration, and using it to offer useful information to the user in order to aid in decision-making and data item recommendations. We have used a User Based Collaborative Filtering (UBCF) approach and measured the performance of similarity measures in recommending books to a user. The proposed system’s overall architecture is introduced and its implementation is represented with a model design.",2020,"[{'authorId': '115163398', 'name': 'M. Kommineni'}, {'authorId': '2285183599', 'name': 'Mohana Vyshnavi'}, {'authorId': '2106275734', 'name': 'K. Swetha'}, {'authorId': '84308101', 'name': 'P. Alekhya'}, {'authorId': '2099926191', 'name': 'V. Aparna'}, {'authorId': '2288243031', 'name': 'V. Mounika'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICISC47916.2020.9171222?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICISC47916.2020.9171222, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender system is a new generation of internet tool that helps users to access the web and receive information about their preferences. using an online recommender is comparatively an easy and faster procedure to purchase items and this is done quickly. recommendation systems plays an indispensable role in ecommerce websites to help users in identifying the right goods. one of the best methods to increase profits and attract customers is a recommendation process. the existing methodologies allow the systems to collect the irrelevant data and lead to a downfall in attracting the users and completing their work in a quick and reliable way. this paper provides an overview of the recommendation systems that is currently employed in the operations of the online book shopping domain. this paper proposes a simple understandable system for book recommendations that help readers to suggest the right book, which is to be studied next. in recent years, information analysis challenge has been focused on for the administration recommendation system. for clients, network assets are completely linked and quickly developed. the proposed method works on training, feedback, management, reporting, configuration, and using it to offer useful information to the user in order to aid in decision-making and data item recommendations. we have used a user based collaborative filtering (ubcf) approach and measured the performance of similarity measures in recommending books to a user. the proposed system’s overall architecture is introduced and its implementation is represented with a model design.",
d11b060c7d968f2b42aa466688d4dddb9118bb6c,E-commerce platform based on Machine Learning Recommendation System,"Information overload is one of the potential setbacks to many e-commerce platform users. It is very important to filter the media and the choices that are overwhelming for internet users while making buying decisions using online stores. To solve this problem, recommendation systems are used widely. A recommender system helps users find a product of their own choice by filtering and prioritizing and effectively generating the relevant information to its users. The purpose of a recommender system is to save time and hassle of searching through the World Wide Web, instead it generates specific and relevant content that promotes online transaction and bring satisfaction to the users of e-commerce platforms. The proposed system is an e-commerce platform based on an apparel recommendation system that recommends products on the foundation of the user's preferences.",2021,"[{'authorId': '2143806974', 'name': 'Muhammad Tahir'}, {'authorId': '2052319', 'name': 'Rabia Noor Enam'}, {'authorId': '2157249427', 'name': 'Syed Muhammad Nabeel Mustafa'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/IMTIC53841.2021.9719822?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IMTIC53841.2021.9719822, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","information overload is one of the potential setbacks to many e-commerce platform users. it is very important to filter the media and the choices that are overwhelming for internet users while making buying decisions using online stores. to solve this problem, recommendation systems are used widely. a recommender system helps users find a product of their own choice by filtering and prioritizing and effectively generating the relevant information to its users. the purpose of a recommender system is to save time and hassle of searching through the world wide web, instead it generates specific and relevant content that promotes online transaction and bring satisfaction to the users of e-commerce platforms. the proposed system is an e-commerce platform based on an apparel recommendation system that recommends products on the foundation of the user's preferences.",
ef3ab9530bd2998a1c3ee699a7323dc489626951,Restaurant Recommendation System using Machine Learning,"Nowadays a big challenge when going out to a new restaurant or cafe, people usually use websites or applications to look up nearby places and then choose one based on an average rating. But most of the time the average rating isn't enough to predict the quality or hygiene of the restaurant. Different people have different perspectives and priorities when evaluating a restaurant. Many online businesses now have implemented personalized recommendation systems which basically try to identify user preferences and then provide relevant products to enhance the users experience . In turn, users will be able to enjoy exploring what they might like with convenience and ease because of the recommendation results. Finding an ideal restaurant can be a struggle because the mainstream recommender apps have not yet adopted the personalized recommender approach. So we took up this challenge and we aim to build the prototype of a personalized recommender system that incorporates metadata which is basically the information provided by interactions of customers and restaurants online(reviews), which gives a pretty good idea of customers satisfaction and taste as well as features of the restaurant. This type of approach enhances user experience of finding a restaurant that suits their taste better. This paper has used a package called lightfm(the library of python for implementing popular recommendation algorithms) and the dataset from yelp. There are different methods of filtering the data, here we have used Hybrid filtering which is a combination of Content-based filtering (CBF) and Collaborative Filtering (CF). Since the results from Hybrid filtering are far more closer to accuracy than CBF or CF respectively. Then hybrid filtering gives results in the form of personalized recommendations for users after training and testing of the data",2021,"[{'authorId': '2237657309', 'name': 'Ketan Mahajan'}, {'authorId': '2237657084', 'name': 'Varsha Joshi'}, {'authorId': '2237656742', 'name': 'Mohini Khedkar'}, {'authorId': '2237658648', 'name': 'Jacky Galani'}, {'authorId': '2237658766', 'name': 'Mayuri Kulkarni'}]","{'url': 'https://doi.org/10.30534/ijatcse/2021/261032021', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.30534/ijatcse/2021/261032021?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.30534/ijatcse/2021/261032021, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","nowadays a big challenge when going out to a new restaurant or cafe, people usually use websites or applications to look up nearby places and then choose one based on an average rating. but most of the time the average rating isn't enough to predict the quality or hygiene of the restaurant. different people have different perspectives and priorities when evaluating a restaurant. many online businesses now have implemented personalized recommendation systems which basically try to identify user preferences and then provide relevant products to enhance the users experience . in turn, users will be able to enjoy exploring what they might like with convenience and ease because of the recommendation results. finding an ideal restaurant can be a struggle because the mainstream recommender apps have not yet adopted the personalized recommender approach. so we took up this challenge and we aim to build the prototype of a personalized recommender system that incorporates metadata which is basically the information provided by interactions of customers and restaurants online(reviews), which gives a pretty good idea of customers satisfaction and taste as well as features of the restaurant. this type of approach enhances user experience of finding a restaurant that suits their taste better. this paper has used a package called lightfm(the library of python for implementing popular recommendation algorithms) and the dataset from yelp. there are different methods of filtering the data, here we have used hybrid filtering which is a combination of content-based filtering (cbf) and collaborative filtering (cf). since the results from hybrid filtering are far more closer to accuracy than cbf or cf respectively. then hybrid filtering gives results in the form of personalized recommendations for users after training and testing of the data",https://doi.org/10.30534/ijatcse/2021/261032021
8124282bbbe3063dbc59a8057e795c961d9532b2,IoT and distributed machine learning powered optimal state recommender solution,"Recommender systems add significant benefits to E-commerce in terms of sale conversion, revenues, customer experience, loyalty and lifetime value. But the recommendations from these systems do not change on inputs beyond user and item profile and transaction data. There have been some attempts in the past to optimize on more varied data in recommenders, example of which is the location based recommenders. But location is just one dimension of the state that a user could have shared with GPS/GLONASS/BaiDeu sensor available in most Smartphones. With an upcoming era of Smart-wears and pervasive IoTs, there are a lot many other dimensions of a user state which can be utilized to optimize upon the concept of Optimal State Recommender Solutions. This paper suggests upgrading from conventional recommendations that are based on user/ item preferences alone with systems that provide the best recommendation at the most optimal state when the user is most receptive to accept the recommendation, the “optimal state recommendation solution” and proposes solutions and architectures to overcome the challenges of dealing with real time, distributed machine learning on IoT scale data in implementing this solution. The paper leverages some of the advance distributed machine learning algorithms like variants of Distributed Kalman Filters, Distributed Alternating Least Square Recommenders, Distributed Mini-Batch Stochastic Gradient Descent(SGD) based Classifiers, and highly scalable distributed computation and machine learning platforms like Apache Spark, (Apache) Spark MLlib, Spark Streaming, Python/PySpark, R/SparkR, Apache Kafka in an high performance, distributed, fault tolerant architecture. The solution also aspires to be compliant with upcoming IoT standards and architectures like IEEE P2413 to provide a standard solution for such problems beyond the current scope of this paper.",2016,"[{'authorId': '152420788', 'name': 'Mohit Sewak'}, {'authorId': '51888075', 'name': 'Sachchidanand Singh'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/IOTA.2016.7562703?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IOTA.2016.7562703, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems add significant benefits to e-commerce in terms of sale conversion, revenues, customer experience, loyalty and lifetime value. but the recommendations from these systems do not change on inputs beyond user and item profile and transaction data. there have been some attempts in the past to optimize on more varied data in recommenders, example of which is the location based recommenders. but location is just one dimension of the state that a user could have shared with gps/glonass/baideu sensor available in most smartphones. with an upcoming era of smart-wears and pervasive iots, there are a lot many other dimensions of a user state which can be utilized to optimize upon the concept of optimal state recommender solutions. this paper suggests upgrading from conventional recommendations that are based on user/ item preferences alone with systems that provide the best recommendation at the most optimal state when the user is most receptive to accept the recommendation, the “optimal state recommendation solution” and proposes solutions and architectures to overcome the challenges of dealing with real time, distributed machine learning on iot scale data in implementing this solution. the paper leverages some of the advance distributed machine learning algorithms like variants of distributed kalman filters, distributed alternating least square recommenders, distributed mini-batch stochastic gradient descent(sgd) based classifiers, and highly scalable distributed computation and machine learning platforms like apache spark, (apache) spark mllib, spark streaming, python/pyspark, r/sparkr, apache kafka in an high performance, distributed, fault tolerant architecture. the solution also aspires to be compliant with upcoming iot standards and architectures like ieee p2413 to provide a standard solution for such problems beyond the current scope of this paper.",
8cae308facbcf19305697164b1b03aff37d507dc,"Job Recommendation System, Machine Learning, Regression, Classification, Natural Language Processing","In today’s highly competitive job market, it is becoming increasingly important for companies to hire employees who are best fit for a job and to ensure they retain these employees in the long run. Studies have shown that employees who find their job meaningful and satisfying are generally more productive and less likely to leave the job. Human Resource professionals therefore need to ensure that proper screening of candidates is conducted during the recruitment process and that they hire the best fit candidate for a job. Given the usually high number of applicants for a particular job, the recruitment process is time consuming and it is not always possible to conduct proper screening and interviews for each applicant. This paper presents the development of JobFit, a job recommendation system which makes use of a recommender system, machine learning techniques and past data to predict the best fit candidate for a job. The proposed job recommendation system takes as input the requirement of a job and the profile of the applicants and outputs a JobFit score indicating how fit each applicant is for the particular job. The system ultimately provides the HR professionals with a sorted list of all candidates with those who are more fit and apt for the job recommended first. This shall help to ensure the HR focus on the screening and interviews of only a small pool of candidates, the best ones recommended by the system, while at the same time be confident that the better candidates are not being missed.",2020,"[{'authorId': '2086795763', 'name': 'K. Appadoo'}, {'authorId': '2086795756', 'name': 'Muhammad Bilaal Soonnoo'}, {'authorId': '1410073523', 'name': 'Zahra Mungloo-Dilmohamud'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/CSDE50874.2020.9411584?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CSDE50874.2020.9411584, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in today’s highly competitive job market, it is becoming increasingly important for companies to hire employees who are best fit for a job and to ensure they retain these employees in the long run. studies have shown that employees who find their job meaningful and satisfying are generally more productive and less likely to leave the job. human resource professionals therefore need to ensure that proper screening of candidates is conducted during the recruitment process and that they hire the best fit candidate for a job. given the usually high number of applicants for a particular job, the recruitment process is time consuming and it is not always possible to conduct proper screening and interviews for each applicant. this paper presents the development of jobfit, a job recommendation system which makes use of a recommender system, machine learning techniques and past data to predict the best fit candidate for a job. the proposed job recommendation system takes as input the requirement of a job and the profile of the applicants and outputs a jobfit score indicating how fit each applicant is for the particular job. the system ultimately provides the hr professionals with a sorted list of all candidates with those who are more fit and apt for the job recommended first. this shall help to ensure the hr focus on the screening and interviews of only a small pool of candidates, the best ones recommended by the system, while at the same time be confident that the better candidates are not being missed.",
ffb83fa1978d48a5d39a679869a427c0773fc8f2,A collaborative filtering recommender system with randomized learning rate and regularized parameter,Recommender systems with the approach of collaborative filtering by using the algorithms of machine learning gives better optimized results. But selecting the appropriate learning rate and regularized parameter is not an easy task. RMSE changes from one set of these values to others. The best set of these parameters has to be selected so that the RMSE must be optimized. In this paper we proposed a method to resolve this problem. Our proposed system selects appropriate learning rate and regularized parameter for given data.,2016,"[{'authorId': '2227455961', 'name': 'V. R. Murali'}, {'authorId': '2227575544', 'name': 'Krishna Rao'}, {'authorId': '2005041236', 'name': 'Hsiang-Yu Fu'}, {'authorId': '2111752193', 'name': 'Yu'}, {'authorId': '1793529', 'name': 'Cho-Jui Hsieh'}, {'authorId': '3422911', 'name': 'Si Si'}, {'authorId': '2227407680', 'name': 'Dhillon I'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCTAC.2016.7567331?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCTAC.2016.7567331, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",recommender systems with the approach of collaborative filtering by using the algorithms of machine learning gives better optimized results. but selecting the appropriate learning rate and regularized parameter is not an easy task. rmse changes from one set of these values to others. the best set of these parameters has to be selected so that the rmse must be optimized. in this paper we proposed a method to resolve this problem. our proposed system selects appropriate learning rate and regularized parameter for given data.,
7b98e102c73737fd6021346ef1c052408d741022,Hybrid Movie Recommendation System Using Machine Learning,"Every year new movies are released with a varied story-line or a genre which could be of potential interest to viewers. Various online movie or video streaming platforms can keep the customers engaged by recommending movies of the viewer’s preference. A key research challenge for Recommender engines is make more targeted recommendations. This paper presents Filtering approaches including Content-based, which recommends items (movies) to the user (viewer) based on their previous history/ preferences and Collaborative-based which uses opinions and actions of other similar users (viewers) to recommend items (movies). In Collaborative filtering, User-based, Item based, SVD, and SVD++ algorithms have been implemented and the performance evaluated. Finally, a hybrid recommendation engine that stacks both the Content-based and SVD filtering models is shown to have optimal performance and improved movie recommendations to retain active viewer engagement with the service.",2021,"[{'authorId': '35700231', 'name': 'Sakina Salmani'}, {'authorId': '20693498', 'name': 'Sarvesh Kulkarni'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCICT50803.2021.9510058?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCICT50803.2021.9510058, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","every year new movies are released with a varied story-line or a genre which could be of potential interest to viewers. various online movie or video streaming platforms can keep the customers engaged by recommending movies of the viewer’s preference. a key research challenge for recommender engines is make more targeted recommendations. this paper presents filtering approaches including content-based, which recommends items (movies) to the user (viewer) based on their previous history/ preferences and collaborative-based which uses opinions and actions of other similar users (viewers) to recommend items (movies). in collaborative filtering, user-based, item based, svd, and svd++ algorithms have been implemented and the performance evaluated. finally, a hybrid recommendation engine that stacks both the content-based and svd filtering models is shown to have optimal performance and improved movie recommendations to retain active viewer engagement with the service.",
163c6e0d24778162136dd33c670c816d29ebc028,Offline Recommender System Evaluation: Challenges and New Directions,"Offline evaluation is an essential complement to online experiments in the selection, improvement, tuning, and deployment of recommender systems. Offline methodologies for recommender system evaluation evolved from experimental practice in Machine Learning (ML) and Information Retrieval (IR). However, evaluating recommendations involves particularities that pose challenges to the assumptions upon which the ML and IR methodologies were developed. We recap and reflect on the development and current status of recommender system evaluation, providing an updated perspective. With a focus on offline evaluation, we review the adaptation of IR principles, procedures and metrics, and the implications of those techniques when applied to recommender systems. At the same time, we identify the singularities of recommendation that require different responses, or involve specific new needs. In addition, we provide an overview of important choices in the configuration of experiments that require particular care and understanding; discuss broader perspectives of evaluation such as recommendation value beyond accuracy; and survey open challenges such as experimental biases, and the cyclic dimension of recommendation.",2022,"[{'authorId': '2912921', 'name': 'P. Castells'}, {'authorId': '144448479', 'name': 'Alistair Moffat'}]","{'url': 'https://repositorio.uam.es/bitstream/10486/711245/1/offline_castells_AI_Magazine_2022.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/aaai.12051?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/aaai.12051, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","offline evaluation is an essential complement to online experiments in the selection, improvement, tuning, and deployment of recommender systems. offline methodologies for recommender system evaluation evolved from experimental practice in machine learning (ml) and information retrieval (ir). however, evaluating recommendations involves particularities that pose challenges to the assumptions upon which the ml and ir methodologies were developed. we recap and reflect on the development and current status of recommender system evaluation, providing an updated perspective. with a focus on offline evaluation, we review the adaptation of ir principles, procedures and metrics, and the implications of those techniques when applied to recommender systems. at the same time, we identify the singularities of recommendation that require different responses, or involve specific new needs. in addition, we provide an overview of important choices in the configuration of experiments that require particular care and understanding; discuss broader perspectives of evaluation such as recommendation value beyond accuracy; and survey open challenges such as experimental biases, and the cyclic dimension of recommendation.",https://repositorio.uam.es/bitstream/10486/711245/1/offline_castells_AI_Magazine_2022.pdf
46654081b36e2fbbb48ba6c074d8d23ee92307f9,University Recommender System based on Student Profile using Feature Weighted Algorithm and KNN,"This article removes the recommender structure for undergrad and graduate understudies which can help with picking the best schools matching their profile. The proposed model has used different extracting techniques for scrapping the data based on student profiles who have secured the seat successfully earlier. Then, machine learning technology is used to calculate the weighted scores based upon the training and testing data. This research study has introduced the KNN and Feature weighted algorithms to display the top N comparable clients for the test clients and recommend the Top M colleges to clients from the N comparative clients. As there is a colossal course of action of data and User profile, this research work is highly intended to use Knowledge-based techniques for two unmistakable models. Case-based information recommendation is used to calculate Graduate recommendations and constant-based recommendation is used for Undergraduate proposals.",2022,"[{'authorId': '2080054338', 'name': 'N. P'}, {'authorId': '50841200', 'name': 'K. Saiteja'}, {'authorId': '2163624941', 'name': 'K. K. Ram'}, {'authorId': '101370110', 'name': 'K. Kanta'}, {'authorId': '101235114', 'name': 'S. K. Aditya'}, {'authorId': '134487214', 'name': 'M. V'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICSCDS53736.2022.9760852?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICSCDS53736.2022.9760852, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this article removes the recommender structure for undergrad and graduate understudies which can help with picking the best schools matching their profile. the proposed model has used different extracting techniques for scrapping the data based on student profiles who have secured the seat successfully earlier. then, machine learning technology is used to calculate the weighted scores based upon the training and testing data. this research study has introduced the knn and feature weighted algorithms to display the top n comparable clients for the test clients and recommend the top m colleges to clients from the n comparative clients. as there is a colossal course of action of data and user profile, this research work is highly intended to use knowledge-based techniques for two unmistakable models. case-based information recommendation is used to calculate graduate recommendations and constant-based recommendation is used for undergraduate proposals.",
80932b4cd48f8d8d143d3ad14cfe14b244676ed3,Diagnosis of Chronic Diseases Based on Patients’ Health Records in IoT Healthcare Using the Recommender System,"Due to the growth of IoT applications, especially health care, the information of patients’ health records using data collection from IoT-connected devices has been considered. Biological data of patients in the health record helps to monitor the patient’s status and identify various diseases. Chronic diseases are a type of silent disease that, if not diagnosed in time, can cause irreparable damage to patients. The use of patients’ medical record data for early diagnosis of chronic diseases has recently attracted the attention of many researchers. On the other hand, the application of machine learning methods in the form of recommender systems has taken an important step in improving medical services and health care. In this paper, a medical recommender system was presented to identify and treat chronic diseases using an IoT device. In the present method, the electronic patient health record dataset that is loaded in the PhysioNet data repository has been used. In the present dataset, patients’ health records have been recorded according to the identified diseases and the physician’s diagnosis. In the proposed method, the 
 
 K
 
 -nearest neighbor classification method is used to identify the type of disease, and the collaborative filtering method is used to find the appropriate treatment for patients. The results of the implementation of the proposed method show that this approach, based on the use of symptom similarity among patients, has good accuracy in diagnosing and predicting chronic diseases and has provided higher results than previous methods.",2022,"[{'authorId': '71108866', 'name': 'Y. A. Nanehkaran'}, {'authorId': '71020465', 'name': 'Zhu Licai'}, {'authorId': '152425934', 'name': 'Junde Chen'}, {'authorId': '9360978', 'name': 'Qiu Zhongpan'}, {'authorId': '2166000843', 'name': 'Yuan Xiaofeng'}, {'authorId': '101286632', 'name': 'Y. D. Navaei'}, {'authorId': '2087611662', 'name': 'Sajad Einy'}]","{'url': 'https://downloads.hindawi.com/journals/wcmc/2022/5663001.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1155/2022/5663001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1155/2022/5663001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","due to the growth of iot applications, especially health care, the information of patients’ health records using data collection from iot-connected devices has been considered. biological data of patients in the health record helps to monitor the patient’s status and identify various diseases. chronic diseases are a type of silent disease that, if not diagnosed in time, can cause irreparable damage to patients. the use of patients’ medical record data for early diagnosis of chronic diseases has recently attracted the attention of many researchers. on the other hand, the application of machine learning methods in the form of recommender systems has taken an important step in improving medical services and health care. in this paper, a medical recommender system was presented to identify and treat chronic diseases using an iot device. in the present method, the electronic patient health record dataset that is loaded in the physionet data repository has been used. in the present dataset, patients’ health records have been recorded according to the identified diseases and the physician’s diagnosis. in the proposed method, the k -nearest neighbor classification method is used to identify the type of disease, and the collaborative filtering method is used to find the appropriate treatment for patients. the results of the implementation of the proposed method show that this approach, based on the use of symptom similarity among patients, has good accuracy in diagnosing and predicting chronic diseases and has provided higher results than previous methods.",https://downloads.hindawi.com/journals/wcmc/2022/5663001.pdf
15bc5ab9de23416c375eb7b16aa9a1a3e383490a,e-Commerce Personalized Recommendation Based on Machine Learning Technology,"As e-commerce offers more and more choices for users, its structure becomes more and more complicated. Inevitably, it brings about the problem of information overload. The solution to this problem is an e-commerce personalized recommendation system using machine learning technology. People often seem confused when facing extensive information and cannot grasp the key points. This paper studies the personalized recommendation technology of e-commerce: deeply analyzes the related technologies and algorithms of the e-commerce recommendation system and proposes the latest architecture of the e-commerce recommendation system according to the current development status of the e-commerce recommendation system. The system recommends accuracy and real-time requirements and divides the system into two parts: offline mining and online recommendation and analyzes and implements the functions and technologies of each part. User-based recommender systems, collaborative filtering recommender systems, and content-based recommender systems are analyzed, respectively. The personalized recommendation cannot only quickly help customers find the required commodity information in a wide range of complex information but also can compare more commodity information to help customers to judge. However, the existing recommendation system has some problems such as the lack of recommendation personality, the reduced relevance of recommendation, and the poor timeliness of recommendation. Finally, a recommendation system that combines three recommendation algorithms is designed, and experiments are carried out. The newly designed recommendation system is compared with three different recommendation systems, and a summary and outlook are made. Based on the introduction of the relevant theories, characteristics, and mainstream technologies of personalized recommendation based on machine learning, this document presents a constructive example of a model based on the factors that influence personalized e-commerce information recommendations in the retail sector. Through questionnaire surveys, we analyze and design the influencing factors for consumers to purchase personalized products after the survey and build a project using state-of-the-art field learning techniques. Through the model to test the eight hypotheses proposed in this paper, the results show that customer income level, customer online shopping experience, commodity prices, product quality, recommendation relevance, credit evaluation, and service quality will have a significant positive impact on shopping willingness and ultimately affect the customer’s shopping behavior. e-commerce platform can use this influencing factor to establish personalized information recommendation service mode.",2022,"[{'authorId': '2109356508', 'name': 'Liping Liu'}]","{'url': 'https://downloads.hindawi.com/journals/misy/2022/1761579.pdf', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1155/2022/1761579?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1155/2022/1761579, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","as e-commerce offers more and more choices for users, its structure becomes more and more complicated. inevitably, it brings about the problem of information overload. the solution to this problem is an e-commerce personalized recommendation system using machine learning technology. people often seem confused when facing extensive information and cannot grasp the key points. this paper studies the personalized recommendation technology of e-commerce: deeply analyzes the related technologies and algorithms of the e-commerce recommendation system and proposes the latest architecture of the e-commerce recommendation system according to the current development status of the e-commerce recommendation system. the system recommends accuracy and real-time requirements and divides the system into two parts: offline mining and online recommendation and analyzes and implements the functions and technologies of each part. user-based recommender systems, collaborative filtering recommender systems, and content-based recommender systems are analyzed, respectively. the personalized recommendation cannot only quickly help customers find the required commodity information in a wide range of complex information but also can compare more commodity information to help customers to judge. however, the existing recommendation system has some problems such as the lack of recommendation personality, the reduced relevance of recommendation, and the poor timeliness of recommendation. finally, a recommendation system that combines three recommendation algorithms is designed, and experiments are carried out. the newly designed recommendation system is compared with three different recommendation systems, and a summary and outlook are made. based on the introduction of the relevant theories, characteristics, and mainstream technologies of personalized recommendation based on machine learning, this document presents a constructive example of a model based on the factors that influence personalized e-commerce information recommendations in the retail sector. through questionnaire surveys, we analyze and design the influencing factors for consumers to purchase personalized products after the survey and build a project using state-of-the-art field learning techniques. through the model to test the eight hypotheses proposed in this paper, the results show that customer income level, customer online shopping experience, commodity prices, product quality, recommendation relevance, credit evaluation, and service quality will have a significant positive impact on shopping willingness and ultimately affect the customer’s shopping behavior. e-commerce platform can use this influencing factor to establish personalized information recommendation service mode.",https://downloads.hindawi.com/journals/misy/2022/1761579.pdf
3f0386fe909703fb5adfe31f31e1b0a421037631,A DASH Diet Recommendation System for Hypertensive Patients Using Machine Learning,"Hypertension is becoming a serious health issue in the world. People tend to have a busy lifestyle and to adopt unhealthy diets. Due to poor eating habits, the rate of Non Communicable Diseases (NCDs) such as hypertension together with the rate of death caused by such diseases are rising. In order to promote healthy eating habits in Mauritius, the paper proposes a DASH diet recommender system that recommends healthy Mauritian diet plans to hypertensive patients. The system consists of a recommendation engine that uses techniques such as content-based filtering along with machine learning algorithms to recommend personalized diet plans to hypertensive patients based on factors such as age, user preferences about food, allergies, smoking level, alcohol level, blood pressure level and dietary intake. The system makes use of a mobile application which is handy and quick to use. Based on a survey carried out, the application has helped users to control and reduce their BP level.",2019,"[{'authorId': '1396393460', 'name': 'Romeshwar Sookrah'}, {'authorId': '1396393448', 'name': 'Jaysree Devee Dhowtal'}, {'authorId': '1396393443', 'name': 'Soulakshmee Devi Nagowah'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICoICT.2019.8835323?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICoICT.2019.8835323, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","hypertension is becoming a serious health issue in the world. people tend to have a busy lifestyle and to adopt unhealthy diets. due to poor eating habits, the rate of non communicable diseases (ncds) such as hypertension together with the rate of death caused by such diseases are rising. in order to promote healthy eating habits in mauritius, the paper proposes a dash diet recommender system that recommends healthy mauritian diet plans to hypertensive patients. the system consists of a recommendation engine that uses techniques such as content-based filtering along with machine learning algorithms to recommend personalized diet plans to hypertensive patients based on factors such as age, user preferences about food, allergies, smoking level, alcohol level, blood pressure level and dietary intake. the system makes use of a mobile application which is handy and quick to use. based on a survey carried out, the application has helped users to control and reduce their bp level.",
5796dc2ff2211dfe67ca39efd0325b1582c1ca05,Finding with NEMO: a recommender system to forecast the next modeling operations,"Nowadays, while modeling environments provide users with facilities to specify different kinds of artifacts, e.g., metamodels, models, and transformations, the possibility of learning from previous modeling experiences and being assisted during modeling tasks remains largely unexplored. In this paper, we propose NEMO, a recommender system based on an Encoder-Decoder neural network to assist modelers in performing model editing operations. NEMO learns from past modeling activities and performs predictions employing a deep learning technique. Such an algorithm has been successfully applied in machine translation to convert a text from a language to another foreign language and vice versa. An empirical evaluation on a dataset of BPMN change-based persistent model demonstrates that the technique permits learning from existing operations and effectively predicting the next editing operations with considerably high prediction accuracy. In particular, NEMO gets 0.977 as precision/recall and 0.992 as success rate score by the best performance.",2022,"[{'authorId': '37121973', 'name': 'Juri Di Rocco'}, {'authorId': '1644891552', 'name': 'Claudio Di Sipio'}, {'authorId': '2143967289', 'name': 'Phuong T. Nguyen'}, {'authorId': '2133181', 'name': 'D. D. Ruscio'}, {'authorId': '1929185', 'name': 'A. Pierantonio'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3550355.3552459', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3550355.3552459?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3550355.3552459, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","nowadays, while modeling environments provide users with facilities to specify different kinds of artifacts, e.g., metamodels, models, and transformations, the possibility of learning from previous modeling experiences and being assisted during modeling tasks remains largely unexplored. in this paper, we propose nemo, a recommender system based on an encoder-decoder neural network to assist modelers in performing model editing operations. nemo learns from past modeling activities and performs predictions employing a deep learning technique. such an algorithm has been successfully applied in machine translation to convert a text from a language to another foreign language and vice versa. an empirical evaluation on a dataset of bpmn change-based persistent model demonstrates that the technique permits learning from existing operations and effectively predicting the next editing operations with considerably high prediction accuracy. in particular, nemo gets 0.977 as precision/recall and 0.992 as success rate score by the best performance.",https://dl.acm.org/doi/pdf/10.1145/3550355.3552459
55a39038fd132f35696c18eba49af2c330a1f0da,Movie Recommender System Using Content-based and Collaborative Filtering,"One of the most effective and widely used applications of machine learning technologies in business is recommender systems. Machine learning algorithms from the field of artificial intelligence have recently been used in these systems. Many varieties of movies have become increasingly diverse as technology and entertainment development have advanced, leaving users perplexed as to how to choose amongst them. The main aim of a movie recommendation system is to deal with a recommender approach using data clustering and computational intelligence. This recommender system’s goal is to acquire insights based on the user ‘s choices and to achieve customer satisfaction by presenting effective findings and optimizing the time a user spends on the website or platform.",2022,"[{'authorId': '2184494758', 'name': 'Jurreyyah Firdaws Mohammad'}, {'authorId': '49375463', 'name': 'S. Urolagin'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/GlobConET53749.2022.9872515?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/GlobConET53749.2022.9872515, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","one of the most effective and widely used applications of machine learning technologies in business is recommender systems. machine learning algorithms from the field of artificial intelligence have recently been used in these systems. many varieties of movies have become increasingly diverse as technology and entertainment development have advanced, leaving users perplexed as to how to choose amongst them. the main aim of a movie recommendation system is to deal with a recommender approach using data clustering and computational intelligence. this recommender system’s goal is to acquire insights based on the user ‘s choices and to achieve customer satisfaction by presenting effective findings and optimizing the time a user spends on the website or platform.",
681e2e1799a88e60516d17b334b3b218d1abb96b,Recommender system for discovery of inorganic compounds,"A recommender system based on experimental databases is useful for the efficient discovery of inorganic compounds. Here, we review studies on the discovery of as-yet-unknown compounds using recommender systems. The first method used compositional descriptors made up of elemental features. Chemical compositions registered in the inorganic crystal structure database (ICSD) were supplied to machine learning for binary classification. The other method did not use any descriptors, but a tensor decomposition technique was adopted. The predictive performance for currently unknown chemically relevant compositions (CRCs) was determined by examining their presence in other databases. According to the recommendation, synthesis experiments of two pseudo-ternary compounds with currently unknown structures were successful. Finally, a synthesis-condition recommender system was constructed by machine learning of a parallel experimental data-set collected in-house using a polymerized complex method. Recommendation scores for unexperimented conditions were then evaluated. Synthesis experiments under the targeted conditions found two yet-unknown pseudo-binary oxides.",2022,"[{'authorId': '48865897', 'name': 'Hiroyuki Hayashi'}, {'authorId': '1947843', 'name': 'Atsuto Seko'}, {'authorId': '2137173128', 'name': 'Isao Tanaka'}]","{'url': 'https://www.nature.com/articles/s41524-022-00899-0.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41524-022-00899-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41524-022-00899-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a recommender system based on experimental databases is useful for the efficient discovery of inorganic compounds. here, we review studies on the discovery of as-yet-unknown compounds using recommender systems. the first method used compositional descriptors made up of elemental features. chemical compositions registered in the inorganic crystal structure database (icsd) were supplied to machine learning for binary classification. the other method did not use any descriptors, but a tensor decomposition technique was adopted. the predictive performance for currently unknown chemically relevant compositions (crcs) was determined by examining their presence in other databases. according to the recommendation, synthesis experiments of two pseudo-ternary compounds with currently unknown structures were successful. finally, a synthesis-condition recommender system was constructed by machine learning of a parallel experimental data-set collected in-house using a polymerized complex method. recommendation scores for unexperimented conditions were then evaluated. synthesis experiments under the targeted conditions found two yet-unknown pseudo-binary oxides.",https://www.nature.com/articles/s41524-022-00899-0.pdf
80a3e1d693adec7c7d094abed0e7f818f8cb5dd9,A Machine-Learning Item Recommendation System for Video Games,"Video-game players generate huge amounts of data, as everything they do within a game is recorded. In particular, among all the stored actions and behaviors, there is information on the in-game purchases of virtual products. Such information is of critical importance in modern free-to-play titles, where gamers can select or buy a profusion of items during the game in order to progress and fully enjoy their experience. To try to maximize these kind of purchases, one can use a recommendation system so as to present players with items that might be interesting for them. Such systems can better achieve their goal by employing machine learning algorithms that are able to predict the rating of an item or product by a particular user. In this paper we evaluate and compare two of these algorithms, an ensemble-based model (extremely randomized trees) and a deep neural network, both of which are promising candidates for operational video-game recommender engines. Item recommenders can help developers improve the game. But, more importantly, it should be possible to integrate them into the game, so that users automatically get personalized recommendations while playing. The presented models are not only able to meet this challenge, providing accurate predictions of the items that a particular player will find attractive, but also sufficiently fast and robust to be used in operational settings.",2018,"[{'authorId': '46373253', 'name': 'Paul Bertens'}, {'authorId': '153675975', 'name': 'Anna Guitart'}, {'authorId': '2158501099', 'name': 'Pei Pei Chen'}, {'authorId': '35897158', 'name': 'Á. Periáñez'}]","{'url': 'https://arxiv.org/pdf/1806.04900', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1806.04900, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","video-game players generate huge amounts of data, as everything they do within a game is recorded. in particular, among all the stored actions and behaviors, there is information on the in-game purchases of virtual products. such information is of critical importance in modern free-to-play titles, where gamers can select or buy a profusion of items during the game in order to progress and fully enjoy their experience. to try to maximize these kind of purchases, one can use a recommendation system so as to present players with items that might be interesting for them. such systems can better achieve their goal by employing machine learning algorithms that are able to predict the rating of an item or product by a particular user. in this paper we evaluate and compare two of these algorithms, an ensemble-based model (extremely randomized trees) and a deep neural network, both of which are promising candidates for operational video-game recommender engines. item recommenders can help developers improve the game. but, more importantly, it should be possible to integrate them into the game, so that users automatically get personalized recommendations while playing. the presented models are not only able to meet this challenge, providing accurate predictions of the items that a particular player will find attractive, but also sufficiently fast and robust to be used in operational settings.",https://arxiv.org/pdf/1806.04900
7614a5ec57ff5002ccfdef42ebbd075a962a0218,The Design of Hybrid Crop Recommendation System using Machine Learning Algorithms,"Crop Recommendation System for agriculture is based on various input parameters. This paper proposes a hybrid model for recommending crops to south Indian states by considering various attributes. The recommender model is built as a hybrid model using the classifier algorithm such as Naive Bayes, J48 and association rules. Based on the appropriate parameters, the system will recommend the crop. Technologybased crop recommendation system for agriculture helps the farmers to increase the crop yield by recommending a suitable crop for their land with the help of geographic and the climatic parameters. The proposed hybrid recommender model is found to be effective in recommending a suitable crop",2019,[],"{'url': 'https://doi.org/10.35940/ijitee.b7219.129219', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.35940/ijitee.b7219.129219?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.35940/ijitee.b7219.129219, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","crop recommendation system for agriculture is based on various input parameters. this paper proposes a hybrid model for recommending crops to south indian states by considering various attributes. the recommender model is built as a hybrid model using the classifier algorithm such as naive bayes, j48 and association rules. based on the appropriate parameters, the system will recommend the crop. technologybased crop recommendation system for agriculture helps the farmers to increase the crop yield by recommending a suitable crop for their land with the help of geographic and the climatic parameters. the proposed hybrid recommender model is found to be effective in recommending a suitable crop",https://doi.org/10.35940/ijitee.b7219.129219
096ec0e2dc58fec028697e44b1119e1c22548f69,Recommendation System for Smart LMS Using Machine Learning: A Literature Review,"This paper presents the result of Systematic Literature Review (SLR) on Recommender System (RS) topic as a preliminary toward a further study on designing a smart Learning Management System (LMS) for online learning which adopts Natural Language Processing techniques. As a foundation to a broader study on smart LMS, this study focused on analyzing prominent study reports on recommender systems in general and online learning in particular. The SLR method analyzed papers published in the range of 2013-2018. Out of the 109 papers this study analyzed indepth 42 papers. The study findings confirmed that most of RS studies still focused on e-commerce, movies, tourists, and more whose most popular RS methods were collaborative filtering and content base. Some studies in RS for online education were mostly focused on scheduling, recommendations for courses, books, prospective students and others. The results of this study found that there are still much opportunities to develop methods and approaches for RS in online learning. This study findings gives foundation of our future research to develop a model of conscious contextual recommendation system using Machine Learning based on smart LMS for online learning.",2018,"[{'authorId': '11145294', 'name': 'Dina Fitria Murad'}, {'authorId': '9400166', 'name': 'Yaya Heryadi'}, {'authorId': '30995397', 'name': 'B. Wijanarko'}, {'authorId': '143724017', 'name': 'S. M. Isa'}, {'authorId': '1882065', 'name': 'W. Budiharto'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCED.2018.00031?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCED.2018.00031, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper presents the result of systematic literature review (slr) on recommender system (rs) topic as a preliminary toward a further study on designing a smart learning management system (lms) for online learning which adopts natural language processing techniques. as a foundation to a broader study on smart lms, this study focused on analyzing prominent study reports on recommender systems in general and online learning in particular. the slr method analyzed papers published in the range of 2013-2018. out of the 109 papers this study analyzed indepth 42 papers. the study findings confirmed that most of rs studies still focused on e-commerce, movies, tourists, and more whose most popular rs methods were collaborative filtering and content base. some studies in rs for online education were mostly focused on scheduling, recommendations for courses, books, prospective students and others. the results of this study found that there are still much opportunities to develop methods and approaches for rs in online learning. this study findings gives foundation of our future research to develop a model of conscious contextual recommendation system using machine learning based on smart lms for online learning.",
f5b10e92511ca81913b7e3ed130f89e926840867,Movie Recommender System,"The amount of content available on platforms like youtube, Netflix, Hulu, Disney is increasing each day. With the increasing number of available content, viewers started spending a lot of time searching for content of their likings. A good recommendation engine can save a lot of time for all the viewers while finding the content of their taste. A great recommender system avoids viewers wasting time watching trailers or movies for a few minutes and then switching to a different one as they did not like it. Without a recommendation system, a user might leave the platform if they cannot find a product or content of their taste. . Recommendation engines or recommender systems filter a large list of products, movies, or things to present only products or things that customers might be interested in. Recommender systems are machine learning systems that help us discover new products, media content, and services depending on their earlier activities.",2021,"[{'authorId': '2340455038', 'name': 'A. N. Varma'}]","{'url': 'https://doi.org/10.22214/ijraset.2021.32936', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.22214/IJRASET.2021.32936?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.22214/IJRASET.2021.32936, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the amount of content available on platforms like youtube, netflix, hulu, disney is increasing each day. with the increasing number of available content, viewers started spending a lot of time searching for content of their likings. a good recommendation engine can save a lot of time for all the viewers while finding the content of their taste. a great recommender system avoids viewers wasting time watching trailers or movies for a few minutes and then switching to a different one as they did not like it. without a recommendation system, a user might leave the platform if they cannot find a product or content of their taste. . recommendation engines or recommender systems filter a large list of products, movies, or things to present only products or things that customers might be interested in. recommender systems are machine learning systems that help us discover new products, media content, and services depending on their earlier activities.",https://doi.org/10.22214/ijraset.2021.32936
0d32013656d9a926a5f6b6c7fded287cc1a57309,A Recommender System for Healthy Food Choices: Building a Hybrid Model for Recipe Recommendations using Big Data Sets,"Advances in Big Data analytics and machine learning have offered intangible benefits across many areas of one’s health. One such area is a move towards healthier lifestyle choices such as one’s diet. Recommender systems apply techniques that can filter information and narrow that information down based on user preferences or user needs and help users choose what information is relevant. Commonly adopted across e-commerce sites, social networking and entertainment industries, recommender systems can also support nutrition-based health management, offering individuals more food options, not only based on one’s preferred tastes but also on one’s dietary needs and restrictions. This research presents the design, implementation and evaluation of three recommender systems using content-based, collaborative filtering and hybrid recommendation models within the nutrition domain.",2021,"[{'authorId': '5185992', 'name': 'Pallavi Chavan'}, {'authorId': '144112422', 'name': 'Brian Thoms'}, {'authorId': '48886787', 'name': 'J. Isaacs'}]","{'url': 'http://scholarspace.manoa.hawaii.edu/bitstream/10125/71074/1/0372.pdf', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.24251/HICSS.2021.458?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.24251/HICSS.2021.458, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","advances in big data analytics and machine learning have offered intangible benefits across many areas of one’s health. one such area is a move towards healthier lifestyle choices such as one’s diet. recommender systems apply techniques that can filter information and narrow that information down based on user preferences or user needs and help users choose what information is relevant. commonly adopted across e-commerce sites, social networking and entertainment industries, recommender systems can also support nutrition-based health management, offering individuals more food options, not only based on one’s preferred tastes but also on one’s dietary needs and restrictions. this research presents the design, implementation and evaluation of three recommender systems using content-based, collaborative filtering and hybrid recommendation models within the nutrition domain.",http://scholarspace.manoa.hawaii.edu/bitstream/10125/71074/1/0372.pdf
cecde56f93738e1d2d1dcb32464881920fcb54ed,Analysis of Intelligent movie recommender system from facial expression,"The advent of machine learning provides a new angle to solver different real-time challenges in business and research applications. In general, machine learning is nothing but the greater conversion of traditional mathematics application. Machine learning models play a significant role in facial recognition applications. Facial recognition is used in many real-time applications like security systems, automated attendance, offices etc. One of the important applications of machine learning models is movie recommendation using facial detection. This has been carried out by capturing the emotion to save time of the user rather than searching individual movies. Some relevant research works are carried out based on the attentional convolutional neural (recognizes each facial micro expression) and recommender system has been implemented to provide either the movies or song based on the output received from previous input i.e. CNN. Another work implemented for facial recognition using decision trees, boosting algorithms has been proven to be very inefficient compared to CNN. So, CNN seems more appropriate to obtain the best possible accuracy. Also, the combination of both the types of recommendation system i.e. content based and collaborative filtering offers more power for recommender system.",2021,"[{'authorId': '2089576272', 'name': 'Shavak Chauhan'}, {'authorId': '2089476814', 'name': 'Rajdeep Mangrola'}, {'authorId': '2300310851', 'name': 'D. Viji'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCMC51019.2021.9418421?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCMC51019.2021.9418421, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the advent of machine learning provides a new angle to solver different real-time challenges in business and research applications. in general, machine learning is nothing but the greater conversion of traditional mathematics application. machine learning models play a significant role in facial recognition applications. facial recognition is used in many real-time applications like security systems, automated attendance, offices etc. one of the important applications of machine learning models is movie recommendation using facial detection. this has been carried out by capturing the emotion to save time of the user rather than searching individual movies. some relevant research works are carried out based on the attentional convolutional neural (recognizes each facial micro expression) and recommender system has been implemented to provide either the movies or song based on the output received from previous input i.e. cnn. another work implemented for facial recognition using decision trees, boosting algorithms has been proven to be very inefficient compared to cnn. so, cnn seems more appropriate to obtain the best possible accuracy. also, the combination of both the types of recommendation system i.e. content based and collaborative filtering offers more power for recommender system.",
bff82fd086cc4c04164e84064e97d978fef23c35,A Recommender System for Crowdsourcing Food Rescue Platforms,"The challenges of food waste and insecurity arise in wealthy and developing nations alike, impacting millions of livelihoods. The ongoing pandemic only exacerbates the problem. A major force to combat food waste and insecurity, food rescue (FR) organizations match food donations to the non-profits that serve low-resource communities. Since they rely on external volunteers to pick up and deliver the food, some FRs use web-based mobile applications to reach the right set of volunteers. In this paper, we propose the first machine learning based model to improve volunteer engagement in the food waste and security domain. We (1) develop a recommender system to send push notifications to the most likely volunteers for each given rescue, (2) leverage a mathematical programming based approach to diversify our recommendations, and (3) propose an online algorithm to dynamically select the volunteers to notify without the knowledge of future rescues. Our recommendation system improves the hit ratio from 44% achieved by the previous method to 73%. A pilot study of our method is scheduled to take place in the near future.",2021,"[{'authorId': '2110397609', 'name': 'Z. Shi'}, {'authorId': '10736111', 'name': 'Leah Lizarondo'}, {'authorId': '2067779833', 'name': 'Fei Fang'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3442381.3449787', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3442381.3449787?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3442381.3449787, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the challenges of food waste and insecurity arise in wealthy and developing nations alike, impacting millions of livelihoods. the ongoing pandemic only exacerbates the problem. a major force to combat food waste and insecurity, food rescue (fr) organizations match food donations to the non-profits that serve low-resource communities. since they rely on external volunteers to pick up and deliver the food, some frs use web-based mobile applications to reach the right set of volunteers. in this paper, we propose the first machine learning based model to improve volunteer engagement in the food waste and security domain. we (1) develop a recommender system to send push notifications to the most likely volunteers for each given rescue, (2) leverage a mathematical programming based approach to diversify our recommendations, and (3) propose an online algorithm to dynamically select the volunteers to notify without the knowledge of future rescues. our recommendation system improves the hit ratio from 44% achieved by the previous method to 73%. a pilot study of our method is scheduled to take place in the near future.",https://dl.acm.org/doi/pdf/10.1145/3442381.3449787
40667a731593a44d4e2f9391f1d14f368321b751,Building Semantic Based Recommender System Using Knowledge Graph Embedding,"Recommendation systems are information filtering mechanisms used in E-commerce, media and entertainment industry. It essentially facilitate the customers for a better user experience by processing the content user-specific. This is known as personalization. However, though leveraged by machine learning algorithms existing recommendation systems, still suffers from the problem of cold-start and sparcity. These problems could be resolved by using knowledge graphs since it gives a semantic explanation of recommendations. Also, graph learning method overcomes the problems of manual feature extraction and is effective for feature learning in predicting tasks. In this research, we develop a semantic based recommender through link prediction in a knowledge graph. We apply graph embedding techniques for extracting the semantics of explicable recommendations. The proposed method is validated by building a knowledge graph using the MovieLens dataset. We observed that factorization based scoring functions such as HolE and DistMult provides better semantic recommendations.",2021,"[{'authorId': '2154100097', 'name': 'Miriyala Kartheek'}, {'authorId': '2314288', 'name': 'G. Sajeev'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICIIP53038.2021.9702632?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICIIP53038.2021.9702632, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommendation systems are information filtering mechanisms used in e-commerce, media and entertainment industry. it essentially facilitate the customers for a better user experience by processing the content user-specific. this is known as personalization. however, though leveraged by machine learning algorithms existing recommendation systems, still suffers from the problem of cold-start and sparcity. these problems could be resolved by using knowledge graphs since it gives a semantic explanation of recommendations. also, graph learning method overcomes the problems of manual feature extraction and is effective for feature learning in predicting tasks. in this research, we develop a semantic based recommender through link prediction in a knowledge graph. we apply graph embedding techniques for extracting the semantics of explicable recommendations. the proposed method is validated by building a knowledge graph using the movielens dataset. we observed that factorization based scoring functions such as hole and distmult provides better semantic recommendations.",
29370a6d990ae1782974593b61804a32f13b440c,A Federated Recommender System for Online Services,"Due to privacy and security constraints, directly sharing user data between parties is undesired. Such decentralized data silo issues commonly exist in recommender systems. In general, recommender systems are data-driven. The more data it uses, the better performance it obtains. The data silo issues is a severe limitation of the recommender’s performance. Federated learning is an emerging technology, which bridges the data silos and builds machine learning models without compromising user privacy and data security. We design a recommender system based on federated learning. It is known as the federated recommender system. The system implements plenty of popular algorithms to support various online recommendation services. The algorithm implementation is open-sourced. We also deploy the system on a real-world content recommendation application, achieving significant performance improvement. In this demonstration, we present the architecture of the federated recommender system and give an online demo to show its detailed working procedures and results in content recommendations.",2020,"[{'authorId': '2057798743', 'name': 'Ben Tan'}, {'authorId': None, 'name': 'Bo Liu'}, {'authorId': '3113725', 'name': 'V. Zheng'}, {'authorId': '153096457', 'name': 'Qiang Yang'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3383313.3411528?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3383313.3411528, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","due to privacy and security constraints, directly sharing user data between parties is undesired. such decentralized data silo issues commonly exist in recommender systems. in general, recommender systems are data-driven. the more data it uses, the better performance it obtains. the data silo issues is a severe limitation of the recommender’s performance. federated learning is an emerging technology, which bridges the data silos and builds machine learning models without compromising user privacy and data security. we design a recommender system based on federated learning. it is known as the federated recommender system. the system implements plenty of popular algorithms to support various online recommendation services. the algorithm implementation is open-sourced. we also deploy the system on a real-world content recommendation application, achieving significant performance improvement. in this demonstration, we present the architecture of the federated recommender system and give an online demo to show its detailed working procedures and results in content recommendations.",
16d6a11881fa16655fc23338b5cecdd58937e104,ExMrec2vec: Explainable Movie Recommender System based on Word2vec,"According to the user profile, a recommender system intends to offer items to the user that may interest him. The recommendations have been applied successfully in various fields. Recommended items include movies, books, travel and tourism services, friends, research articles, research queries, and much more. Hence the presence of recommender systems in many areas, in particular, movies recommendations. Most current Machine Learning recommender systems serve as black boxes that do not provide the user with any insight into or justification for the system's logic. What puts users at risk of losing their confidence. Recommender systems suffer from an overload of information, which poses numerous problems, including high cost, slow data processing, and low time complexity. That is why researchers in have been using graph embeddings algorithms in the recommendation field to reduce the quantity of data, as these algorithms have been successful in the last few years. This work aims to improve the quality of recommendation and the simplicity of recommendation explanation based on the word2vec graph embeddings model. Keywords—Recommender system; explainable artificial intelligence machine learning; Word2vec",2021,"[{'authorId': '69524492', 'name': 'A. Samih'}, {'authorId': '2218372', 'name': 'A. Ghadi'}, {'authorId': '2934311', 'name': 'A. Fennan'}]","{'url': 'http://thesai.org/Downloads/Volume12No8/Paper_76-ExMrec2vec_Explainable_Movie_Recommender_System.pdf', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.14569/ijacsa.2021.0120876?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.14569/ijacsa.2021.0120876, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","according to the user profile, a recommender system intends to offer items to the user that may interest him. the recommendations have been applied successfully in various fields. recommended items include movies, books, travel and tourism services, friends, research articles, research queries, and much more. hence the presence of recommender systems in many areas, in particular, movies recommendations. most current machine learning recommender systems serve as black boxes that do not provide the user with any insight into or justification for the system's logic. what puts users at risk of losing their confidence. recommender systems suffer from an overload of information, which poses numerous problems, including high cost, slow data processing, and low time complexity. that is why researchers in have been using graph embeddings algorithms in the recommendation field to reduce the quantity of data, as these algorithms have been successful in the last few years. this work aims to improve the quality of recommendation and the simplicity of recommendation explanation based on the word2vec graph embeddings model. keywords—recommender system; explainable artificial intelligence machine learning; word2vec",http://thesai.org/Downloads/Volume12No8/Paper_76-ExMrec2vec_Explainable_Movie_Recommender_System.pdf
9c6081579f34f13e3ae9315ef15b6b4a36aa83b7,Content-Based Recommendation Using Machine Learning,"Currently, the user profile based online recommender system has become a hit both in research and engineering domain. Accurately capturing users' profile is the key of recommendation. Recently, lots of researches on user profile extraction have been launched, including content-based recommendation. To better capture users' profiles, a three-step profiling method is adopted in this work. (1) Purchase item prediction is made based on Logistic Regression. (2) Purchase category prediction is made based on support vector machine (SVM), and (3) User's rating prediction is made based on convolutional neural network (CNN) and Long Short-Term Memory (LSTM). This work outperformed the baseline model on the user dataset collected from Amazon. So, in conclusion, the work has the ability of giving reasonable recommendation for users who would like to purchase online. In the future, the video signal processing techniques will also be taken under consideration to capture users' face expression for better recommendation.",2021,"[{'authorId': '2141779200', 'name': 'Yifan Tai'}, {'authorId': '2145129639', 'name': 'Zhenyu Sun'}, {'authorId': '2113321902', 'name': 'Zixuan Yao'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/mlsp52302.2021.9596525?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/mlsp52302.2021.9596525, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","currently, the user profile based online recommender system has become a hit both in research and engineering domain. accurately capturing users' profile is the key of recommendation. recently, lots of researches on user profile extraction have been launched, including content-based recommendation. to better capture users' profiles, a three-step profiling method is adopted in this work. (1) purchase item prediction is made based on logistic regression. (2) purchase category prediction is made based on support vector machine (svm), and (3) user's rating prediction is made based on convolutional neural network (cnn) and long short-term memory (lstm). this work outperformed the baseline model on the user dataset collected from amazon. so, in conclusion, the work has the ability of giving reasonable recommendation for users who would like to purchase online. in the future, the video signal processing techniques will also be taken under consideration to capture users' face expression for better recommendation.",
6124d55268b7c88500970bc91b06be15f235989e,A Data-Driven Personalized Lighting Recommender System,"Recommender systems attempt to identify and recommend the most preferable item (product-service) to individual users. These systems predict user interest in items based on related items, users, and the interactions between items and users. We aim to build an auto-routine and color scheme recommender system for home-based smart lighting that leverages a wealth of historical data and machine learning methods. We utilize an unsupervised method to recommend a routine for smart lighting. Moreover, by analyzing users’ daily logs, geographical location, temporal and usage information, we understand user preferences and predict their preferred light colors. To do so, users are clustered based on their geographical information and usage distribution. We then build and train a predictive model within each cluster and aggregate the results. Results indicate that models based on similar users increases the prediction accuracy, with and without prior knowledge about user preferences.",2021,"[{'authorId': '101991066', 'name': 'Atousa Zarindast'}, {'authorId': '2087821213', 'name': 'Jonathan Wood'}]","{'url': 'https://doi.org/10.3389/fdata.2021.706117', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8552333, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems attempt to identify and recommend the most preferable item (product-service) to individual users. these systems predict user interest in items based on related items, users, and the interactions between items and users. we aim to build an auto-routine and color scheme recommender system for home-based smart lighting that leverages a wealth of historical data and machine learning methods. we utilize an unsupervised method to recommend a routine for smart lighting. moreover, by analyzing users’ daily logs, geographical location, temporal and usage information, we understand user preferences and predict their preferred light colors. to do so, users are clustered based on their geographical information and usage distribution. we then build and train a predictive model within each cluster and aggregate the results. results indicate that models based on similar users increases the prediction accuracy, with and without prior knowledge about user preferences.",https://doi.org/10.3389/fdata.2021.706117
0a83b4cead7c4e99049b32cfaaee30269d5455da,An E-Learning Recommender That Helps Learners Find the Right Materials,"
 
 Learning materials are increasingly available on the Web making them an excellent source of information for building e-Learning recommendation systems. However, learners often have difficulty finding the right materials to support their learning goals because they lack sufficient domain knowledge to craft effective queries that convey what they wish to learn. The unfamiliar vocabulary often used by domain experts creates a semantic gap between learners and experts, and also makes it difficult to map a learner's query to relevant learning materials. We build an e-Learning recommender system that uses background knowledge extracted from a collection of teaching materials and encyclopedia sources to support the refinement of learners' queries. Our approach allows us to bridge the gap between learners and teaching experts. We evaluate our method using a collection of realistic learner queries and a dataset of Machine Learning and Data Mining documents. Evaluation results show our method to outperform benchmark approaches and demonstrates its effectiveness in assisting learners to find the right materials.
 
",2018,"[{'authorId': '2158707', 'name': 'Blessing Mbipom'}, {'authorId': '144004005', 'name': 'Stewart Massie'}, {'authorId': '2257301493', 'name': 'Susan Craw'}]","{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/11389/11248', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1609/aaai.v32i1.11389?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/aaai.v32i1.11389, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","learning materials are increasingly available on the web making them an excellent source of information for building e-learning recommendation systems. however, learners often have difficulty finding the right materials to support their learning goals because they lack sufficient domain knowledge to craft effective queries that convey what they wish to learn. the unfamiliar vocabulary often used by domain experts creates a semantic gap between learners and experts, and also makes it difficult to map a learner's query to relevant learning materials. we build an e-learning recommender system that uses background knowledge extracted from a collection of teaching materials and encyclopedia sources to support the refinement of learners' queries. our approach allows us to bridge the gap between learners and teaching experts. we evaluate our method using a collection of realistic learner queries and a dataset of machine learning and data mining documents. evaluation results show our method to outperform benchmark approaches and demonstrates its effectiveness in assisting learners to find the right materials.",https://ojs.aaai.org/index.php/AAAI/article/download/11389/11248
331d55e3d600970b017709db9ccb46a43aa3b377,Movie Recommender System Using K-Means Clustering AND K-Nearest Neighbor,"In the field of Artificial Intelligence Machine learning provides the automatic systems which learn and improve itself from experience without being explicitly programmed. In this research work a movie recommender system is built using the K-Means Clustering and K-Nearest Neighbor algorithms. The movielens dataset is taken from kaggle. The system is implemented in python programming language. The proposed work deals with the introduction of various concepts related to machine learning and recommendation system. In this work, various tools and techniques have been used to build recommender systems. Various algorithms such as K-Means Clustering, KNN, Collaborative Filtering, Content-Based Filtering have been described in detail. Further, after studying different types of machine learning algorithms, there is a clear picture of where to apply which algorithm in different areas of industries such as recommender systems, e-commerce, etc. Then there is an illustration of how implementations and working of the proposed system are used for the implementation of the movie recommender system. Various building blocks of the proposed system such as Architecture, Process Flow, Pseudo Code, Implementation and Working of the System is described in detail. Finally, in this work for different cluster values, different values of Root Mean Squared Error are obtained. In this proposed work as the no of clusters decreases, the value of RMSE also decreases. The best value of RMSE obtained is 1.081648. The results given by the proposed system are better than the existing technique on the basis of RMSE value.",2019,"[{'authorId': '151369116', 'name': 'Rishabh Ahuja'}, {'authorId': '97420399', 'name': 'A. Solanki'}, {'authorId': '3286242', 'name': 'A. Nayyar'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/CONFLUENCE.2019.8776969?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CONFLUENCE.2019.8776969, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the field of artificial intelligence machine learning provides the automatic systems which learn and improve itself from experience without being explicitly programmed. in this research work a movie recommender system is built using the k-means clustering and k-nearest neighbor algorithms. the movielens dataset is taken from kaggle. the system is implemented in python programming language. the proposed work deals with the introduction of various concepts related to machine learning and recommendation system. in this work, various tools and techniques have been used to build recommender systems. various algorithms such as k-means clustering, knn, collaborative filtering, content-based filtering have been described in detail. further, after studying different types of machine learning algorithms, there is a clear picture of where to apply which algorithm in different areas of industries such as recommender systems, e-commerce, etc. then there is an illustration of how implementations and working of the proposed system are used for the implementation of the movie recommender system. various building blocks of the proposed system such as architecture, process flow, pseudo code, implementation and working of the system is described in detail. finally, in this work for different cluster values, different values of root mean squared error are obtained. in this proposed work as the no of clusters decreases, the value of rmse also decreases. the best value of rmse obtained is 1.081648. the results given by the proposed system are better than the existing technique on the basis of rmse value.",
f6d5d48db35748e703a620075e9b060aeddad13f,AutoRec: An Automated Recommender System,"Realistic recommender systems are often required to adapt to ever-changing data and tasks or to explore different models systematically. To address the need, we present AutoRec 1 2, an open-source automated machine learning (AutoML) platform extended from the TensorFlow [3] ecosystem and, to our knowledge, the first framework to leverage AutoML for model search and hyperparameter tuning in deep recommendation models. AutoRec also supports a highly flexible pipeline that accommodates both sparse and dense inputs, rating prediction and click-through rate (CTR) prediction tasks, and an array of recommendation models. Lastly, AutoRec provides a simple, user-friendly API. Experiments conducted on the benchmark datasets reveal AutoRec is reliable and can identify models which resemble the best model without prior knowledge.",2020,"[{'authorId': '2155391478', 'name': 'Ting-Hsiang Wang'}, {'authorId': '25274194', 'name': 'Qingquan Song'}, {'authorId': '50017230', 'name': 'Xiaotian Han'}, {'authorId': '47781070', 'name': 'Zirui Liu'}, {'authorId': '49475312', 'name': 'Haifeng Jin'}, {'authorId': '48539382', 'name': 'Xia Hu'}]","{'url': 'https://arxiv.org/pdf/2007.07224', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2007.07224, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","realistic recommender systems are often required to adapt to ever-changing data and tasks or to explore different models systematically. to address the need, we present autorec 1 2, an open-source automated machine learning (automl) platform extended from the tensorflow [3] ecosystem and, to our knowledge, the first framework to leverage automl for model search and hyperparameter tuning in deep recommendation models. autorec also supports a highly flexible pipeline that accommodates both sparse and dense inputs, rating prediction and click-through rate (ctr) prediction tasks, and an array of recommendation models. lastly, autorec provides a simple, user-friendly api. experiments conducted on the benchmark datasets reveal autorec is reliable and can identify models which resemble the best model without prior knowledge.",https://arxiv.org/pdf/2007.07224
089506f213372bbdee9dbeba1fa030a4c202e6b8,Drugs Rating Generation and Recommendation from Sentiment Analysis of Drug Reviews using Machine Learning,"A recommendation system can assist the user to compose an understanding of requirements and propose informed decisions from a lot of complicated knowledge. Recommendation from an analysis of sentiments seems to be a great challenge as user-generated content is represented using human language in several complicated ways. Many studies have focused on common fields such as reviews of electrical items, films, and restaurants, but not enough on health and medical issues. Sentiment analysis of healthcare in general and that of the drug experiences of individuals, in particular, may shed considerable light on how to focus on improving public health and reach the correct decision. In this paper, we design and implement a drug recommender system framework that applies sentiment analysis technologies on drug reviews. The objective of this research is to build a decision-making support platform to help patients to achieve more significant choices in drug selection. Firstly, we propose a sentimental measurement approach to drug reviews and generate ratings on drugs. Secondly, we take how much the drug reviews are useful to users, patient's conditions, and dictionary sentiment polarity of drug reviews into consideration. Then, we fuse those factors into the recommendation system to list appropriate medications. Experiments have been carried out using Decision Tree, K-Nearest Neighbors, and Linear Support Vector Classifier algorithm in rating generation and Hybrid model in recommendation based on the given open dataset. The analysis is carried out to tune the parameters for each algorithm in order to achieve greater performance. Finally, Linear Support Vector Classifier is selected for rating generation to obtain a good trade-off among model accuracy, model efficiency, and model scalability.",2020,"[{'authorId': '144070982', 'name': 'Md.Deloar Hossain'}, {'authorId': '47004428', 'name': 'M. S. Azam'}, {'authorId': '52154404', 'name': 'Md Jahan Ali'}, {'authorId': '3037431', 'name': 'Hakilo Sabit'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ETCCE51779.2020.9350868?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ETCCE51779.2020.9350868, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a recommendation system can assist the user to compose an understanding of requirements and propose informed decisions from a lot of complicated knowledge. recommendation from an analysis of sentiments seems to be a great challenge as user-generated content is represented using human language in several complicated ways. many studies have focused on common fields such as reviews of electrical items, films, and restaurants, but not enough on health and medical issues. sentiment analysis of healthcare in general and that of the drug experiences of individuals, in particular, may shed considerable light on how to focus on improving public health and reach the correct decision. in this paper, we design and implement a drug recommender system framework that applies sentiment analysis technologies on drug reviews. the objective of this research is to build a decision-making support platform to help patients to achieve more significant choices in drug selection. firstly, we propose a sentimental measurement approach to drug reviews and generate ratings on drugs. secondly, we take how much the drug reviews are useful to users, patient's conditions, and dictionary sentiment polarity of drug reviews into consideration. then, we fuse those factors into the recommendation system to list appropriate medications. experiments have been carried out using decision tree, k-nearest neighbors, and linear support vector classifier algorithm in rating generation and hybrid model in recommendation based on the given open dataset. the analysis is carried out to tune the parameters for each algorithm in order to achieve greater performance. finally, linear support vector classifier is selected for rating generation to obtain a good trade-off among model accuracy, model efficiency, and model scalability.",
58055e0236db5d8980ce8bb9f35a5cf24c025d23,A New Profile Learning Model for Recommendation System based on Machine Learning Technique,"Recommender systems (RSs) have been used to successfully address the information overload problem by providing personalized and targeted recommendations to the end users. RSs are software tools and techniques providing suggestions for items to be of use to a user, hence, they typically apply techniques and methodologies from Data Mining. The main contribution of this paper is to introduce a new user profile learning model to promote the recommendation accuracy of vertical recommendation systems. The proposed profile learning model employs the vertical classifier that has been used in multi classification module of the Intelligent. Adaptive Vertical Recommendation (IAVR) system to discover the user’s area of interest, and then build the user’s profile accordingly. Experimental results have proven the effectiveness of the proposed profile learning model, which accordingly will promote the recommendation accuracy",2016,"[{'authorId': '152819220', 'name': 'Shereen H. Ali'}, {'authorId': '41187812', 'name': 'Ali I. El Desouky'}, {'authorId': '2433144', 'name': 'A. Saleh'}]","{'url': 'https://doi.org/10.4172/2165-7866.1000170', 'status': 'CLOSED', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4172/2165-7866.1000170?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4172/2165-7866.1000170, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems (rss) have been used to successfully address the information overload problem by providing personalized and targeted recommendations to the end users. rss are software tools and techniques providing suggestions for items to be of use to a user, hence, they typically apply techniques and methodologies from data mining. the main contribution of this paper is to introduce a new user profile learning model to promote the recommendation accuracy of vertical recommendation systems. the proposed profile learning model employs the vertical classifier that has been used in multi classification module of the intelligent. adaptive vertical recommendation (iavr) system to discover the user’s area of interest, and then build the user’s profile accordingly. experimental results have proven the effectiveness of the proposed profile learning model, which accordingly will promote the recommendation accuracy",https://doi.org/10.4172/2165-7866.1000170
c99c90d24f1f782e16e2c01a7ae81bc4e5703c9a,OrderRex clinical user testing: a randomized trial of recommender system decision support on simulated cases,"Abstract Objective To assess usability and usefulness of a machine learning-based order recommender system applied to simulated clinical cases. Materials and Methods 43 physicians entered orders for 5 simulated clinical cases using a clinical order entry interface with or without access to a previously developed automated order recommender system. Cases were randomly allocated to the recommender system in a 3:2 ratio. A panel of clinicians scored whether the orders placed were clinically appropriate. Our primary outcome included the difference in clinical appropriateness scores. Secondary outcomes included total number of orders, case time, and survey responses. Results Clinical appropriateness scores per order were comparable for cases randomized to the order recommender system (mean difference -0.11 order per score, 95% CI: [-0.41, 0.20]). Physicians using the recommender placed more orders (median 16 vs 15 orders, incidence rate ratio 1.09, 95%CI: [1.01-1.17]). Case times were comparable with the recommender system. Order suggestions generated from the recommender system were more likely to match physician needs than standard manual search options. Physicians used recommender suggestions in 98% of available cases. Approximately 95% of participants agreed the system would be useful for their workflows. Discussion User testing with a simulated electronic medical record interface can assess the value of machine learning and clinical decision support tools for clinician usability and acceptance before live deployments. Conclusions Clinicians can use and accept machine learned clinical order recommendations integrated into an electronic order entry interface in a simulated setting. The clinical appropriateness of orders entered was comparable even when supported by automated recommendations.",2020,"[{'authorId': '2119320393', 'name': 'Andre Kumar'}, {'authorId': '35310392', 'name': 'Rachael C. Aikens'}, {'authorId': '37686747', 'name': 'J. Hom'}, {'authorId': '3037048', 'name': 'L. Shieh'}, {'authorId': '1733089099', 'name': 'Jonathan Chiang'}, {'authorId': '2054077003', 'name': 'David Morales'}, {'authorId': '2059419651', 'name': 'Divya Saini'}, {'authorId': '1680938', 'name': 'M. Musen'}, {'authorId': '47788618', 'name': 'M. Baiocchi'}, {'authorId': '144446128', 'name': 'R. Altman'}, {'authorId': '2216258', 'name': 'M. Goldstein'}, {'authorId': '2527115', 'name': 'S. Asch'}, {'authorId': '1421788668', 'name': 'Jonathan H. Chen'}]","{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7727352', 'status': 'GREEN', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7727352, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract objective to assess usability and usefulness of a machine learning-based order recommender system applied to simulated clinical cases. materials and methods 43 physicians entered orders for 5 simulated clinical cases using a clinical order entry interface with or without access to a previously developed automated order recommender system. cases were randomly allocated to the recommender system in a 3:2 ratio. a panel of clinicians scored whether the orders placed were clinically appropriate. our primary outcome included the difference in clinical appropriateness scores. secondary outcomes included total number of orders, case time, and survey responses. results clinical appropriateness scores per order were comparable for cases randomized to the order recommender system (mean difference -0.11 order per score, 95% ci: [-0.41, 0.20]). physicians using the recommender placed more orders (median 16 vs 15 orders, incidence rate ratio 1.09, 95%ci: [1.01-1.17]). case times were comparable with the recommender system. order suggestions generated from the recommender system were more likely to match physician needs than standard manual search options. physicians used recommender suggestions in 98% of available cases. approximately 95% of participants agreed the system would be useful for their workflows. discussion user testing with a simulated electronic medical record interface can assess the value of machine learning and clinical decision support tools for clinician usability and acceptance before live deployments. conclusions clinicians can use and accept machine learned clinical order recommendations integrated into an electronic order entry interface in a simulated setting. the clinical appropriateness of orders entered was comparable even when supported by automated recommendations.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7727352
c99ed8619e6fe8e6eae4a8b5ca61135b90396a98,How good your recommender system is? A survey on evaluations in recommendation,"Recommender Systems have become a very useful tool for a large variety of domains. Researchers have been attempting to improve their algorithms in order to issue better predictions to the users. However, one of the current challenges in the area refers to how to properly evaluate the predictions generated by a recommender system. In the extent of offline evaluations, some traditional concepts of evaluation have been explored, such as accuracy, Root Mean Square Error and P@N for top-k recommendations. In recent years, more research have proposed some new concepts such as novelty, diversity and serendipity. These concepts have been addressed with the goal to satisfy the users’ requirements. Numerous definitions and metrics have been proposed in previous work. On the absence of a specific summarization on evaluations of recommendation combining traditional metrics and recent progresses, this paper surveys and organizes the main research that present definitions about concepts and propose metrics or strategies to evaluate recommendations. In addition, this survey also settles the relationship between the concepts, categorizes them according to their objectives and suggests potential future topics on user satisfaction.",2017,"[{'authorId': '143709691', 'name': 'Thiago Silveira'}, {'authorId': '38898636', 'name': 'Min Zhang'}, {'authorId': '2117690202', 'name': 'Xiao Lin'}, {'authorId': '1783406', 'name': 'Yiqun Liu'}, {'authorId': '8093158', 'name': 'Shaoping Ma'}]","{'url': 'https://link.springer.com/content/pdf/10.1007%2Fs13042-017-0762-9.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13042-017-0762-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13042-017-0762-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems have become a very useful tool for a large variety of domains. researchers have been attempting to improve their algorithms in order to issue better predictions to the users. however, one of the current challenges in the area refers to how to properly evaluate the predictions generated by a recommender system. in the extent of offline evaluations, some traditional concepts of evaluation have been explored, such as accuracy, root mean square error and p@n for top-k recommendations. in recent years, more research have proposed some new concepts such as novelty, diversity and serendipity. these concepts have been addressed with the goal to satisfy the users’ requirements. numerous definitions and metrics have been proposed in previous work. on the absence of a specific summarization on evaluations of recommendation combining traditional metrics and recent progresses, this paper surveys and organizes the main research that present definitions about concepts and propose metrics or strategies to evaluate recommendations. in addition, this survey also settles the relationship between the concepts, categorizes them according to their objectives and suggests potential future topics on user satisfaction.",https://link.springer.com/content/pdf/10.1007%2Fs13042-017-0762-9.pdf
20e28774ba3f6b5bda85f72a79e1a0b35b9255ac,Recommendation Systems with Machine Learning,"Recommender systems are a subclass of information filtering systems. These systems are specialized software components, which usually make part of a larger software system, but can also be standalone tools. A recommender system’s main goal is to provide the user software suggestions for items that can be useful. The suggestions are related to different decision-making mechanisms, different techniques, such as, what product to buy, what movie to watch, or what vacation to reserve. In the context of recommender systems, the general term “item” refers to what the system is actually recommending to its users. The paper presents the development and the comparison of multiple recommendation systems, capable of making item suggestions, based on user, item and user-item interaction data, using different machine learning algorithms. Also, the paper deals with finding different ways of using machine learning models to create recommendation systems, training, evaluating and comparing the different methods in order to provide a general but accurate solution for ranking prediction.",2020,"[{'authorId': '9443907', 'name': 'Alexandra Fanca'}, {'authorId': '29379814', 'name': 'A. Puscasiu'}, {'authorId': '123464438', 'name': 'D. Goța'}, {'authorId': '1711476', 'name': 'H. Valean'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCC49264.2020.9257290?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCC49264.2020.9257290, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems are a subclass of information filtering systems. these systems are specialized software components, which usually make part of a larger software system, but can also be standalone tools. a recommender system’s main goal is to provide the user software suggestions for items that can be useful. the suggestions are related to different decision-making mechanisms, different techniques, such as, what product to buy, what movie to watch, or what vacation to reserve. in the context of recommender systems, the general term “item” refers to what the system is actually recommending to its users. the paper presents the development and the comparison of multiple recommendation systems, capable of making item suggestions, based on user, item and user-item interaction data, using different machine learning algorithms. also, the paper deals with finding different ways of using machine learning models to create recommendation systems, training, evaluating and comparing the different methods in order to provide a general but accurate solution for ranking prediction.",
189e6d515c9673446e1053d0d4464981fd29a2db,An Edge Intelligence Empowered Recommender System Enabling Cultural Heritage Applications,"Recommender systems are increasingly playing an important role in our life, enabling users to find “what they need” within large data collections and supporting a variety of applications, from e-commerce to e-tourism. In this paper, we present a Big Data architecture supporting typical cultural heritage applications. On the top of querying, browsing, and analyzing cultural contents coming from distributed and heterogeneous repositories, we propose a novel user-centered recommendation strategy for cultural items suggestion. Despite centralizing the processing operations within the cloud, the vision of edge intelligence has been exploited by having a mobile app (Smart Search Museum) to perform semantic searches and machine-learning-based inference so as to be capable of suggesting museums, together with other items of interest, to users when they are visiting a city, exploiting jointly recommendation techniques and edge artificial intelligence facilities. Experimental results on accuracy and user satisfaction show the goodness of the proposed application.",2019,"[{'authorId': '50821858', 'name': 'Xin Su'}, {'authorId': '2682488', 'name': 'Giancarlo Sperlí'}, {'authorId': '1707400', 'name': 'V. Moscato'}, {'authorId': '1695194', 'name': 'A. Picariello'}, {'authorId': '39850767', 'name': 'C. Esposito'}, {'authorId': '145685544', 'name': 'Chang Choi'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TII.2019.2908056?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TII.2019.2908056, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems are increasingly playing an important role in our life, enabling users to find “what they need” within large data collections and supporting a variety of applications, from e-commerce to e-tourism. in this paper, we present a big data architecture supporting typical cultural heritage applications. on the top of querying, browsing, and analyzing cultural contents coming from distributed and heterogeneous repositories, we propose a novel user-centered recommendation strategy for cultural items suggestion. despite centralizing the processing operations within the cloud, the vision of edge intelligence has been exploited by having a mobile app (smart search museum) to perform semantic searches and machine-learning-based inference so as to be capable of suggesting museums, together with other items of interest, to users when they are visiting a city, exploiting jointly recommendation techniques and edge artificial intelligence facilities. experimental results on accuracy and user satisfaction show the goodness of the proposed application.",
0f260bea653d05676e403d6bd456f0863c4e6f7d,Campus Shuttle Bus Route Optimization Using Machine Learning Predictive Analysis: A Case Study,"Public transportation is a vital service provided to enable a community to carry out daily activities. One of the mass transportations used in an area is a bus. Moreover, the smart transportation concept is an integrated application of technology and strategy in the transportation system. Using smart idea is the key to the application of the Internet of Things. The ways to improve the management transportation system become a bottleneck for the traditional data analytics solution, one of the answers used in machine learning. This paper uses the Artificial Neural Network (ANN) and Support Vector Machine (SVM) algorithm for the best prediction of travel time with a lower error rate on a case study of a university shuttle bus. Apart from predicting the travel time, this study also considers the fuel cost and gas emission from transportation. The analysis of the experiment shows that the ANN outperformed the SVM. Furthermore, a recommender system is used to recommend suitable routes for the chosen scenario. The experiments extend the discussion with a range of future directions on the stipulated field of study.",2020,"[{'authorId': '49239481', 'name': 'R. M. Noor'}, {'authorId': '97585144', 'name': 'Nadia Bella Gustiani Rasyidi'}, {'authorId': '1389963465', 'name': 'Tarak Nandy'}, {'authorId': '9116000', 'name': 'Raenu Kolandaisamy'}]","{'url': 'https://www.mdpi.com/2071-1050/13/1/225/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su13010225?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su13010225, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","public transportation is a vital service provided to enable a community to carry out daily activities. one of the mass transportations used in an area is a bus. moreover, the smart transportation concept is an integrated application of technology and strategy in the transportation system. using smart idea is the key to the application of the internet of things. the ways to improve the management transportation system become a bottleneck for the traditional data analytics solution, one of the answers used in machine learning. this paper uses the artificial neural network (ann) and support vector machine (svm) algorithm for the best prediction of travel time with a lower error rate on a case study of a university shuttle bus. apart from predicting the travel time, this study also considers the fuel cost and gas emission from transportation. the analysis of the experiment shows that the ann outperformed the svm. furthermore, a recommender system is used to recommend suitable routes for the chosen scenario. the experiments extend the discussion with a range of future directions on the stipulated field of study.",https://www.mdpi.com/2071-1050/13/1/225/pdf
66d81cc846429510d786ae178b372dbce3e79f04,Online Recommender system for Accessible Tourism Destinations,"Traveling for leisure has become an important part of our society. It has proven time and again its benefits for wellbeing and personal growth. There are many types of tourism and one of them is Accessible Tourism (AT), an ongoing endeavor to ensure that everyone, regardless of condition, has the right to benefit from tourism experiences. Recommender systems (RSs) represent a mature technique for generating clear and personalized suggestions. While being widely researched and used by the tourism academic community and the tourism industry in general, Recommender Systems (RSs) can still do much more for Accessible Tourism (AT). This thesis aims to build a recommender system dedicated to recommending accessible tourism destinations and easy the process of e2e trip planning for people with disabilities. With a modular design, use of ontologies, machine learning techniques and a “start small, define expansion, expand” approach, this recommender system, once built, aims to be validated by real users.",2020,"[{'authorId': '1405840883', 'name': 'Luchiana Cezara Brodeala'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3383313.3411450?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3383313.3411450, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","traveling for leisure has become an important part of our society. it has proven time and again its benefits for wellbeing and personal growth. there are many types of tourism and one of them is accessible tourism (at), an ongoing endeavor to ensure that everyone, regardless of condition, has the right to benefit from tourism experiences. recommender systems (rss) represent a mature technique for generating clear and personalized suggestions. while being widely researched and used by the tourism academic community and the tourism industry in general, recommender systems (rss) can still do much more for accessible tourism (at). this thesis aims to build a recommender system dedicated to recommending accessible tourism destinations and easy the process of e2e trip planning for people with disabilities. with a modular design, use of ontologies, machine learning techniques and a “start small, define expansion, expand” approach, this recommender system, once built, aims to be validated by real users.",
3f64cc788fb3526f90f5c1196ab9a10563bfc48c,A Simple and Efficient Federated Recommender System,"Federated Learning (FL) is recently explored as a machine learning paradigm to communally gain generalizable knowledge from the data available in a collection of edge devices without the requirement to transfer the data. FL gives rise to the opportunity to train models on edge devices while preserving user's privacy as the data never leaves user's premises. In this paper, we introduce a simple yet efficient extension of FL for recommender systems to improve on personalization and discuss closely-related meta-learning algorithms. Compared to state-of-the-art federated recommenders, our proposed algorithm is simpler and more robust in real-life scenarios. Through experiments on benchmark data, we evaluate our algorithm in root mean squared error (RMSE) of user's rating prediction.",2019,"[{'authorId': '2805195', 'name': 'A. Jalalirad'}, {'authorId': '35330865', 'name': 'Marco Scavuzzo'}, {'authorId': '66930184', 'name': 'Catalin Capota'}, {'authorId': '153287200', 'name': 'Michael R. Sprague'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3365109.3368788?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3365109.3368788, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","federated learning (fl) is recently explored as a machine learning paradigm to communally gain generalizable knowledge from the data available in a collection of edge devices without the requirement to transfer the data. fl gives rise to the opportunity to train models on edge devices while preserving user's privacy as the data never leaves user's premises. in this paper, we introduce a simple yet efficient extension of fl for recommender systems to improve on personalization and discuss closely-related meta-learning algorithms. compared to state-of-the-art federated recommenders, our proposed algorithm is simpler and more robust in real-life scenarios. through experiments on benchmark data, we evaluate our algorithm in root mean squared error (rmse) of user's rating prediction.",
1d1c08dad674fddf1f3d2fcfca5535569760be83,A Recommender System for Inverse Design of Polycarbonates and Polyesters,"The convergence of artificial intelligence and machine learning with material science holds significant promise to rapidly accelerate development timelines of new high-performance polymeric materials. Within this context, we report an inverse design strategy for polycarbonate and polyester discovery based on a recommendation system that proposes polymerization experiments that are likely to produce materials with targeted properties. Following recommendations of the system driven by the historical ring-opening polymerization results, we carried out experiments targeting specific ranges of monomer conversion and dispersity of the polymers obtained from cyclic lactones and carbonates. The results of the experiments were in close agreement with the recommendation targets with few false negatives or positives obtained for each class.",2020,"[{'authorId': '10237561', 'name': 'Nathaniel H. Park'}, {'authorId': '35312152', 'name': 'D. Zubarev'}, {'authorId': '145295498', 'name': 'J. Hedrick'}, {'authorId': '1573796099', 'name': 'Vivien Kiyek'}, {'authorId': '2080838889', 'name': 'Christiaan Corbet'}, {'authorId': '2042047349', 'name': 'S. Lottier'}]","{'url': 'https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/60c74ea9702a9b3ee618ba32/original/a-recommender-system-for-inverse-design-of-polycarbonates-and-polyesters.pdf', 'status': 'BRONZE', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.26434/chemrxiv.12679031.v1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.26434/chemrxiv.12679031.v1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the convergence of artificial intelligence and machine learning with material science holds significant promise to rapidly accelerate development timelines of new high-performance polymeric materials. within this context, we report an inverse design strategy for polycarbonate and polyester discovery based on a recommendation system that proposes polymerization experiments that are likely to produce materials with targeted properties. following recommendations of the system driven by the historical ring-opening polymerization results, we carried out experiments targeting specific ranges of monomer conversion and dispersity of the polymers obtained from cyclic lactones and carbonates. the results of the experiments were in close agreement with the recommendation targets with few false negatives or positives obtained for each class.",https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/60c74ea9702a9b3ee618ba32/original/a-recommender-system-for-inverse-design-of-polycarbonates-and-polyesters.pdf
ec8cd75eb1e8e4f86ef4383c9f81166619e6e5ab,ISSUES IN VARIOUS RECOMMENDER SYSTEM IN E-COMMERCE – A SURVEY,"The replacement of traditional shopping fashion by the various modes of online shopping in real-time. Because of traditional shopping, most of them are getting into real feel about the product whichever they buy. The product features will be manually realized by the consumers whereas in online shopping all the consumers believe the descriptive summary of the products and the various factors based on the sold historical data. Now a days modern shopping method is moving gradually towards hitting more number of customers. Here recommendation system playing a vital role in suggesting the product by considering the earlier records and increasing the demand. Many of the consumers are attracted by factors like deals on an item, rating, review, and cost of the product. Through these factors, most of the consumers are attracted to taking online shopping instead of traditional shopping methods. For suggesting the products to consumers, many kinds of recommendation algorithms are applied using machine learning and deep learning technology to train the system automatically by observing the customer behavior patterns. But the believing factors of the product will be forged some time; in such cases, consumers are not satisfied with their expectations. The overall survey of this paper will address the research gap and opportunities with the recommendation system.",2020,"[{'authorId': '28653202', 'name': 'R. Venkatesan'}, {'authorId': '145589522', 'name': 'A. Sabari'}]","{'url': 'https://doi.org/10.31838/jcr.07.07.109', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.31838/jcr.07.07.109?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.31838/jcr.07.07.109, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the replacement of traditional shopping fashion by the various modes of online shopping in real-time. because of traditional shopping, most of them are getting into real feel about the product whichever they buy. the product features will be manually realized by the consumers whereas in online shopping all the consumers believe the descriptive summary of the products and the various factors based on the sold historical data. now a days modern shopping method is moving gradually towards hitting more number of customers. here recommendation system playing a vital role in suggesting the product by considering the earlier records and increasing the demand. many of the consumers are attracted by factors like deals on an item, rating, review, and cost of the product. through these factors, most of the consumers are attracted to taking online shopping instead of traditional shopping methods. for suggesting the products to consumers, many kinds of recommendation algorithms are applied using machine learning and deep learning technology to train the system automatically by observing the customer behavior patterns. but the believing factors of the product will be forged some time; in such cases, consumers are not satisfied with their expectations. the overall survey of this paper will address the research gap and opportunities with the recommendation system.",https://doi.org/10.31838/jcr.07.07.109
7a3f109b0432ded92541f805faa246b8649580a1,Ontology-based Recommender System in Higher Education,"Academic advising is limited in its ability to assist students in identifying academic pathways. Selecting a major and a university is a challenging process rife with anxiety. Students at high school are not sure how to match their interests with their working future or major. Therefore, high school students need guidance and support. Moreover, students need to filter, prioritize and efficiently get appropriate information from the web in order to solve the problem of information overload. This paper represents an approach for developing ontology-based recommender system improved with machine learning techniques to orient students in higher education. The proposed recommender system is an assessment tool for students' vocational strengths and weaknesses, interests and capabilities. The main objective of our ontology-based recommender system is to identify the student requirements, interests, preferences and capabilities to recommend the appropriate major and university for each one.",2018,"[{'authorId': '2081278888', 'name': 'Charbel Obeid'}, {'authorId': '1887620', 'name': 'Inaya Lahoud'}, {'authorId': '3214961', 'name': 'Hicham El Khoury'}, {'authorId': '2881039', 'name': 'Pierre-Antoine Champin'}]","{'url': 'http://dl.acm.org/ft_gateway.cfm?id=3191533&type=pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3184558.3191533?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3184558.3191533, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","academic advising is limited in its ability to assist students in identifying academic pathways. selecting a major and a university is a challenging process rife with anxiety. students at high school are not sure how to match their interests with their working future or major. therefore, high school students need guidance and support. moreover, students need to filter, prioritize and efficiently get appropriate information from the web in order to solve the problem of information overload. this paper represents an approach for developing ontology-based recommender system improved with machine learning techniques to orient students in higher education. the proposed recommender system is an assessment tool for students' vocational strengths and weaknesses, interests and capabilities. the main objective of our ontology-based recommender system is to identify the student requirements, interests, preferences and capabilities to recommend the appropriate major and university for each one.",http://dl.acm.org/ft_gateway.cfm?id=3191533&type=pdf
7629dbe1f150fa6b1fe7897f69fd24003d715745,A proposed framework in an intelligent recommender system for the college student,"This article aims to proposed framework an Intelligent Recommender System (IRS) for students in higher education institutions. This conceptual framework includes problems in predicting student performance, the possibility of graduating on time, and recommends choosing subjects according to performance, and career interests, which are useful for assisting pedagogical interventions in future student development. The success in the development and implementation of the proposed IRS framework is inseparable from using data mining and machine learning techniques in predicting and providing recommendations. Data analysis consisted of clustering techniques, association rules, and classification using Support Vector Machine (SVM), Naïve Bayes, and k-Nearest Neighbour (k-NN). These techniques are used to solve problems related to students and to provide appropriate recommendations. The result is an IRS conceptual framework for the college student that can be used as smart agents to provide student guidance and suggestions to support the process of education in higher education.",2019,"[{'authorId': '2081977024', 'name': 'D. Kurniadi'}, {'authorId': '18142707', 'name': 'E. Abdurachman'}, {'authorId': '2105727363', 'name': 'H L H S Warnars'}, {'authorId': '2139144550', 'name': 'W. Suparta'}]","{'url': 'https://doi.org/10.1088/1742-6596/1402/6/066100', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1088/1742-6596/1402/6/066100?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/1742-6596/1402/6/066100, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this article aims to proposed framework an intelligent recommender system (irs) for students in higher education institutions. this conceptual framework includes problems in predicting student performance, the possibility of graduating on time, and recommends choosing subjects according to performance, and career interests, which are useful for assisting pedagogical interventions in future student development. the success in the development and implementation of the proposed irs framework is inseparable from using data mining and machine learning techniques in predicting and providing recommendations. data analysis consisted of clustering techniques, association rules, and classification using support vector machine (svm), naïve bayes, and k-nearest neighbour (k-nn). these techniques are used to solve problems related to students and to provide appropriate recommendations. the result is an irs conceptual framework for the college student that can be used as smart agents to provide student guidance and suggestions to support the process of education in higher education.",https://doi.org/10.1088/1742-6596/1402/6/066100
4a7758da6c2b191326862885cb24d8a3e1abf6ce,Preliminary Investigation for Tamil cine music deployment for mood music recommender system,"Music, as all other art forms, has been used primarily as a vehicle for conveying ideas, experiences and emotions in a stylistic manner. It thus makes sense to attempt to categorize a library of music into either its style or the emotions expressed in the tracks. In this work, preliminary results of the signal processing module and machine learning module with four songs in detail and with a database of 100 songs is carried out. The signal processing algorithms employed are Mel Frequency Cepstral Coefficients and beat Histogram. Human emotions were classified based on Thayers model into Happy, Sad, Angry and Relaxed. The Machine Learning classification algorithms employed are Decision Tree Classifier and Random Forest Classifier. A low accuracy suggests improvement in the features and better machine learning algorithm before porting to Android for development as a Mobile App.",2020,"[{'authorId': '122217882', 'name': 'S. P.'}, {'authorId': '1484420995', 'name': 'J. R'}, {'authorId': '1652002258', 'name': 'Jeyanth C.'}, {'authorId': '1652573744', 'name': 'Yogeshwar Ba'}, {'authorId': '1654094250', 'name': 'Adith Sarvesh'}, {'authorId': '1654094244', 'name': 'Mohamed Shurfudeen'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICACCS48705.2020.9074249?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICACCS48705.2020.9074249, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","music, as all other art forms, has been used primarily as a vehicle for conveying ideas, experiences and emotions in a stylistic manner. it thus makes sense to attempt to categorize a library of music into either its style or the emotions expressed in the tracks. in this work, preliminary results of the signal processing module and machine learning module with four songs in detail and with a database of 100 songs is carried out. the signal processing algorithms employed are mel frequency cepstral coefficients and beat histogram. human emotions were classified based on thayers model into happy, sad, angry and relaxed. the machine learning classification algorithms employed are decision tree classifier and random forest classifier. a low accuracy suggests improvement in the features and better machine learning algorithm before porting to android for development as a mobile app.",
504e970f40bebdb80ea481138d134d00dd871e00,Collaborative Filtering-Based Electricity Plan Recommender System,"Owning to electricity market deregulation, residential customers now enjoy the freedom to choose their preferred electricity retailers. This paper investigates the application of recommender system, a fast-developing technique in machine learning, into the task of recommending electricity plans for the individual residential customer. Based on a collaborative filtering strategy, an electricity plan recommender system (EPRS) is developed. By providing easily obtainable data of some household appliances, residential customers of the EPRS are recommended with predicted ratings of different plans, which can provide effective guidance to customers in the selection of suitable plans and proper tariffs. Different numerical tests are carried out to evaluate the performance of the EPRS. The EPRS outperforms other strategies in the accuracy of recommendation result and is verified to be a promising solution to electricity plan recommendation task.",2019,"[{'authorId': None, 'name': 'Yuan Zhang'}, {'authorId': '145734483', 'name': 'K. Meng'}, {'authorId': '40632536', 'name': 'Weicong Kong'}, {'authorId': '144402926', 'name': 'Z. Dong'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TII.2018.2856842?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TII.2018.2856842, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","owning to electricity market deregulation, residential customers now enjoy the freedom to choose their preferred electricity retailers. this paper investigates the application of recommender system, a fast-developing technique in machine learning, into the task of recommending electricity plans for the individual residential customer. based on a collaborative filtering strategy, an electricity plan recommender system (eprs) is developed. by providing easily obtainable data of some household appliances, residential customers of the eprs are recommended with predicted ratings of different plans, which can provide effective guidance to customers in the selection of suitable plans and proper tariffs. different numerical tests are carried out to evaluate the performance of the eprs. the eprs outperforms other strategies in the accuracy of recommendation result and is verified to be a promising solution to electricity plan recommendation task.",
7a1836fc4d634111fd56aa8585b99fa57b2d9403,Semantically enhanced machine learning approach to recommend e-learning content,"E-learning platforms contain a large number of heterogeneous resources of knowledge. In current e-learning systems, learners spend a lot of time and effort trying to find relevant learning resources. It is necessary to consider the learner's true needs according to different factors, such as learning style, experience, and preferences. Learning needs to be relevant to the context of the required concept. This work presents analytical review of the current status of e-learning system design. A new approach based on machine learning (ML) combined with ontology techniques has been suggested to develop an efficient e-learning recommender system. The proposed model uses Bayesian inference algorithm to predict learning materials, which are collected and indexed within the system. Ontology has been used to expand the initial terms extracted. Semantic relation between the learning material and the term was generated and fed to the model. Experimental results using this model show promising performance.",2020,"[{'authorId': '72560794', 'name': 'H. Ezaldeen'}, {'authorId': '120547986', 'name': 'Rachita Misra'}, {'authorId': '2023361368', 'name': 'R. Alatrash'}, {'authorId': '31712192', 'name': 'R. Priyadarshini'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1504/ijeb.2020.10033040?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1504/ijeb.2020.10033040, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","e-learning platforms contain a large number of heterogeneous resources of knowledge. in current e-learning systems, learners spend a lot of time and effort trying to find relevant learning resources. it is necessary to consider the learner's true needs according to different factors, such as learning style, experience, and preferences. learning needs to be relevant to the context of the required concept. this work presents analytical review of the current status of e-learning system design. a new approach based on machine learning (ml) combined with ontology techniques has been suggested to develop an efficient e-learning recommender system. the proposed model uses bayesian inference algorithm to predict learning materials, which are collected and indexed within the system. ontology has been used to expand the initial terms extracted. semantic relation between the learning material and the term was generated and fed to the model. experimental results using this model show promising performance.",
56bfc9baf7f6b87b9759df166cd40f3826e5c3a6,Towards Automated Auditing with Machine Learning,"We present the Automated List Inspection (ALI) tool that utilizes methods from machine learning, natural language processing, combined with domain expert knowledge to automate financial statement auditing. ALI is a content based context-aware recommender system, that matches relevant text passages from the notes to the financial statement to specific law regulations. In this paper, we present the architecture of the recommender tool which includes text mining, language modeling, unsupervised and supervised methods that range from binary classification models to deep recurrent neural networks. Next to our main findings, we present quantitative and qualitative comparisons of the algorithms as well as concepts for how to further extend the functionality of the tool.",2019,"[{'authorId': '2018549', 'name': 'R. Sifa'}, {'authorId': '2173126', 'name': 'Anna Ladi'}, {'authorId': '153758438', 'name': 'Maren Pielka'}, {'authorId': '21780262', 'name': 'Rajkumar Ramamurthy'}, {'authorId': '1406353697', 'name': 'L. Hillebrand'}, {'authorId': '36891596', 'name': 'Birgit Kirsch'}, {'authorId': '1396757068', 'name': 'D. Biesner'}, {'authorId': '153636939', 'name': 'Robin Stenzel'}, {'authorId': '1381415318', 'name': 'Thiago Bell'}, {'authorId': '1396407321', 'name': 'Max Lübbering'}, {'authorId': '2500295', 'name': 'Ulrich Nütten'}, {'authorId': '1692283', 'name': 'C. Bauckhage'}, {'authorId': '92737832', 'name': 'Ulrich Warning'}, {'authorId': '2074900286', 'name': 'Benedikt Fürst'}, {'authorId': '1396757045', 'name': 'T. Khameneh'}, {'authorId': '2076974707', 'name': 'Daniel Thom'}, {'authorId': '2329388552', 'name': 'Ilgar Huseynov'}, {'authorId': '9559341', 'name': 'Roland Kahlert'}, {'authorId': '1396757035', 'name': 'Jennifer Schlums'}, {'authorId': '2055601135', 'name': 'Hisham Ismail'}, {'authorId': '1391590643', 'name': 'Bernd Kliem'}, {'authorId': '2090348766', 'name': 'Rüdiger Loitz'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3342558.3345421?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3342558.3345421, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we present the automated list inspection (ali) tool that utilizes methods from machine learning, natural language processing, combined with domain expert knowledge to automate financial statement auditing. ali is a content based context-aware recommender system, that matches relevant text passages from the notes to the financial statement to specific law regulations. in this paper, we present the architecture of the recommender tool which includes text mining, language modeling, unsupervised and supervised methods that range from binary classification models to deep recurrent neural networks. next to our main findings, we present quantitative and qualitative comparisons of the algorithms as well as concepts for how to further extend the functionality of the tool.",
6cd571bb472cda196f34773e8a3d382066470ba6,An adaptive doctor-recommender system,"ABSTRACT Recommender systems use machine-learning techniques to make predictions about resources. The medical field is one where much research is currently being conducted on recommender system utility. In the last few years, the amount of information available online that relates to healthcare has increased tremendously. Patients nowadays are more aware and look for answers to healthcare problems online. This has resulted in a dire need of an effective reliable online system to recommend the physician that is best suited to a particular patient in a limited time. In this article, a hybrid doctor-recommender system is proposed, by combining different recommendation approaches: content base, collaborative and demographic filtering to effectively tackle the issue of doctor recommendation. The proposed system addresses the issue of personalization through analysing patient's interest towards selecting a doctor. It uses a novel adoptive algorithm to construct a doctor's ranking function. Moreover, this ranking function is used to translate patients’ criteria for selecting a doctor into a numerical base rating, which will eventually be used in the recommendation of doctors. The system has been evaluated thoroughly, and result show that recommendations are reasonable and can fulfil patient's demand for reliable doctor's selection effectively.",2019,"[{'authorId': '145582420', 'name': 'Muhammad Waqar'}, {'authorId': '66373548', 'name': 'N. Majeed'}, {'authorId': '51260966', 'name': 'H. Dawood'}, {'authorId': '40247823', 'name': 'Ali Daud'}, {'authorId': '3035633', 'name': 'Naif R. Aljohani'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/0144929X.2019.1625441?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/0144929X.2019.1625441, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract recommender systems use machine-learning techniques to make predictions about resources. the medical field is one where much research is currently being conducted on recommender system utility. in the last few years, the amount of information available online that relates to healthcare has increased tremendously. patients nowadays are more aware and look for answers to healthcare problems online. this has resulted in a dire need of an effective reliable online system to recommend the physician that is best suited to a particular patient in a limited time. in this article, a hybrid doctor-recommender system is proposed, by combining different recommendation approaches: content base, collaborative and demographic filtering to effectively tackle the issue of doctor recommendation. the proposed system addresses the issue of personalization through analysing patient's interest towards selecting a doctor. it uses a novel adoptive algorithm to construct a doctor's ranking function. moreover, this ranking function is used to translate patients’ criteria for selecting a doctor into a numerical base rating, which will eventually be used in the recommendation of doctors. the system has been evaluated thoroughly, and result show that recommendations are reasonable and can fulfil patient's demand for reliable doctor's selection effectively.",
18a8d90920cda6d7da416a299e4369a01c10990f,Analyzing Learners' Relationship to Improve the Quality of Recommender System for Group Learning Support,"Recommender systems are now a popular research area and have become powerful tools to present personalized offers to users in many domains (e.g. e-commerce, e-learning). In this paper, we introduced an approach of personalization which extracts learners’ relationship based on learning processes and learning activities (e.g. note taking) to provide more authenticity, personalized recommendations for group learning support. Base on learners’ learning activities some interaction factors are extracted by using natural language process technologies and data mining automatically. Then, extracted interaction factors are utilized to generate some relationship indicators for inferring the learners’ directive relationship. These indicators are as symbols in order to describe a situation and relative degree which knowledge and understanding are socially distributed among group learners. Thirdly, we use a machine learning approach for acquiring a learner relationship identify module according to the relationship indicators. The experimental result shows that the proposed approach can give a more satisfying and qualified recommendation.",2011,"[{'authorId': '49113938', 'name': 'Xin Wan'}, {'authorId': '2417420', 'name': 'Qimanguli Jamaliding'}, {'authorId': '6232654', 'name': 'Toshio Okamoto'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4304/jcp.6.2.254-262?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4304/jcp.6.2.254-262, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recommender systems are now a popular research area and have become powerful tools to present personalized offers to users in many domains (e.g. e-commerce, e-learning). in this paper, we introduced an approach of personalization which extracts learners’ relationship based on learning processes and learning activities (e.g. note taking) to provide more authenticity, personalized recommendations for group learning support. base on learners’ learning activities some interaction factors are extracted by using natural language process technologies and data mining automatically. then, extracted interaction factors are utilized to generate some relationship indicators for inferring the learners’ directive relationship. these indicators are as symbols in order to describe a situation and relative degree which knowledge and understanding are socially distributed among group learners. thirdly, we use a machine learning approach for acquiring a learner relationship identify module according to the relationship indicators. the experimental result shows that the proposed approach can give a more satisfying and qualified recommendation.",
2a1ec9961acbb14cb769d9ef6bf30124195ccfcb,A Smart Recommender Based on Hybrid Learning Methods for Personal Well-Being Services,"The main focus of the paper is to propose a smart recommender system based on the methods of hybrid learning for personal well-being services, called a smart recommender system of hybrid learning (SRHL). The essential health factor is considered to be personal lifestyle, with the help of a critical examination of various disciplines. Integrating the recommender system effectively contributes to the prevention of disease, and it also leads to a reduction in treatment cost, which contributes to an improvement in the quality of life. At the same time, there exist various challenges within the recommender system, mainly cold start and scalability. To effectively address the inefficiencies, we propose combined hybrid methods in regard to machine learning. The primary aim of this learning method is to integrate the most effective and efficient learning algorithms to examine how combined hybrid filtering can help to improve the cold star problem efficiently in the provision of personalized well-being in regard to health food service. These methods include: (1) switching among content-based and collaborative filtering; (2) identifying the user context with the integration of dynamic filtering; and (3) learning the profiles with the help of processing and screening of reflecting feedback loops. The experimental results were evaluated by using three absolute error measures, providing comparable results with other studies relative to machine learning domains. The effects of using the hybrid learning method are gathered with the help of the experimental results. Our experiments also show that the hybrid method improves accuracy by 14.61% of the average error predicted in the recommender systems in comparison to the collaborative methods, which mainly focus on the computation of similar entities.",2019,"[{'authorId': '65724144', 'name': 'Rayan M. Nouh'}, {'authorId': '2203041832', 'name': 'Hyun-Ho Lee'}, {'authorId': '48115222', 'name': 'Won-Jin Lee'}, {'authorId': '2144678745', 'name': 'Jae-Dong Lee'}]","{'url': 'https://www.mdpi.com/1424-8220/19/2/431/pdf?version=1548076076', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6359500, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the main focus of the paper is to propose a smart recommender system based on the methods of hybrid learning for personal well-being services, called a smart recommender system of hybrid learning (srhl). the essential health factor is considered to be personal lifestyle, with the help of a critical examination of various disciplines. integrating the recommender system effectively contributes to the prevention of disease, and it also leads to a reduction in treatment cost, which contributes to an improvement in the quality of life. at the same time, there exist various challenges within the recommender system, mainly cold start and scalability. to effectively address the inefficiencies, we propose combined hybrid methods in regard to machine learning. the primary aim of this learning method is to integrate the most effective and efficient learning algorithms to examine how combined hybrid filtering can help to improve the cold star problem efficiently in the provision of personalized well-being in regard to health food service. these methods include: (1) switching among content-based and collaborative filtering; (2) identifying the user context with the integration of dynamic filtering; and (3) learning the profiles with the help of processing and screening of reflecting feedback loops. the experimental results were evaluated by using three absolute error measures, providing comparable results with other studies relative to machine learning domains. the effects of using the hybrid learning method are gathered with the help of the experimental results. our experiments also show that the hybrid method improves accuracy by 14.61% of the average error predicted in the recommender systems in comparison to the collaborative methods, which mainly focus on the computation of similar entities.",https://www.mdpi.com/1424-8220/19/2/431/pdf?version=1548076076
0e51ef82e5433266b0f498cdbbe4f3161cc3c8f9,PrivateJobMatch: a privacy-oriented deferred multi-match recommender system for stable employment,"Coordination failure reduces match quality among employers and candidates in the job market, resulting in a large number of unfilled positions and/or unstable, short-term employment. Centralized job search engines provide a platform that connects directly employers with job-seekers. However, they require users to disclose a significant amount of personal data, i.e., build a user profile, in order to provide meaningful recommendations. In this paper, we present PrivateJobMatch - a privacy-oriented deferred multi-match recommender system - which generates stable pairings while requiring users to provide only a partial ranking of their preferences. PrivateJobMatch explores a series of adaptations of the game-theoretic Gale-Shapley deferred acceptance algorithm which combine the flexibility of decentralized markets with the intelligence of centralized matching. We identify the shortcomings of the original algorithm when applied to a job market and propose novel solutions that rely on machine learning techniques. Experimental results on real and synthetic data confirm the benefits of the proposed algorithms across several quality measures. Over the past year, we have implemented a PrivateJobMatch prototype and deployed it in an active job market economy. Using the gathered real-user preference data, we find that the match recommendations are superior to a typical decentralized job market---while requiring only a partial ranking of the user preferences.",2019,"[{'authorId': '49553301', 'name': 'Amarjit Saini'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3298689.3346983', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1905.04564, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","coordination failure reduces match quality among employers and candidates in the job market, resulting in a large number of unfilled positions and/or unstable, short-term employment. centralized job search engines provide a platform that connects directly employers with job-seekers. however, they require users to disclose a significant amount of personal data, i.e., build a user profile, in order to provide meaningful recommendations. in this paper, we present privatejobmatch - a privacy-oriented deferred multi-match recommender system - which generates stable pairings while requiring users to provide only a partial ranking of their preferences. privatejobmatch explores a series of adaptations of the game-theoretic gale-shapley deferred acceptance algorithm which combine the flexibility of decentralized markets with the intelligence of centralized matching. we identify the shortcomings of the original algorithm when applied to a job market and propose novel solutions that rely on machine learning techniques. experimental results on real and synthetic data confirm the benefits of the proposed algorithms across several quality measures. over the past year, we have implemented a privatejobmatch prototype and deployed it in an active job market economy. using the gathered real-user preference data, we find that the match recommendations are superior to a typical decentralized job market---while requiring only a partial ranking of the user preferences.",https://dl.acm.org/doi/pdf/10.1145/3298689.3346983
e9154864092a091b7363462733bd933174626fdf,An Enhanced Group Recommender System by Exploiting Preference Relation,"With ties among people have been much more closer, making recommendations for groups of users became a more general demand, which facilitates the prevalence of group recommender system (GRS). Existing solutions for GRS are mostly established based on preference feedbacks of absolute form such as ratings, yet neglecting that preference assessment criteria are usually heterogeneous among different members. In this paper, we propose GRS-PR, an enhanced group recommender system by exploiting preference relation. First, a preference relation-based multi-variate extreme learning machine model is formulated to predict unknown preference relations in candidate items. Second, on the basis of predicted results, borda voting rule is employed to generate recommendation results from candidate items. In addition, efficiency, parameter sensitivity, and sparsity tolerance of the GRS-PR are evaluated through a set of experiments.",2019,"[{'authorId': '49694829', 'name': 'Zhiwei Guo'}, {'authorId': '2069640318', 'name': 'Wenru Zeng'}, {'authorId': '2149696290', 'name': 'Heng Wang'}, {'authorId': '97908423', 'name': 'Yu Shen'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08635454.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2019.2897760?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2019.2897760, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with ties among people have been much more closer, making recommendations for groups of users became a more general demand, which facilitates the prevalence of group recommender system (grs). existing solutions for grs are mostly established based on preference feedbacks of absolute form such as ratings, yet neglecting that preference assessment criteria are usually heterogeneous among different members. in this paper, we propose grs-pr, an enhanced group recommender system by exploiting preference relation. first, a preference relation-based multi-variate extreme learning machine model is formulated to predict unknown preference relations in candidate items. second, on the basis of predicted results, borda voting rule is employed to generate recommendation results from candidate items. in addition, efficiency, parameter sensitivity, and sparsity tolerance of the grs-pr are evaluated through a set of experiments.",https://ieeexplore.ieee.org/ielx7/6287639/8600701/08635454.pdf
0c558a426dd1b0ed5ee843291323956de2833208,Recommender System of Successful Processing Conditions for New Compounds Based on a Parallel Experimental Data Set,"We propose a machine-learning method to recommend successful processing conditions for new compounds on the basis of parallel experiments. Initially, an experimental database was constructed for 67...",2019,"[{'authorId': '48865897', 'name': 'Hiroyuki Hayashi'}, {'authorId': '3366424', 'name': 'K. Hayashi'}, {'authorId': '2050791858', 'name': 'Keita Kouzai'}, {'authorId': '1947843', 'name': 'Atsuto Seko'}, {'authorId': '46487378', 'name': 'I. Tanaka'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1021/acs.chemmater.9b01799?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/acs.chemmater.9b01799, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",recommender system of successful processing conditions for new compounds based on a parallel experimental data set,
fb1e7c75979d748568a6795ea6e2710d458eee58,Deep Learning for Search and Recommender Systems in Practice,"In this talk, we will go over the components of personalized search and recommender systems and demonstrate the applications of various deep learning techniques along the way. Search and recommender systems are probably the most prevalent ML powered application across the industry. They share most of the components composition and provide a user a ranked list of items, while there is subtle difference that a search system typically acts passively with a clear user intention in terms of queries and a recommender system acts more proactively. Deep learning has been wildly successful in solving complex tasks such as image recognition, speech recognition, natural language processing and understanding, machine translation, etc. In the area of personalized recommender systems, deep learning has been showing tremendous impact in recent years. Search and recommender systems can be staged roughly in three phases: 1. User and query understanding, where a query or a user profile are processed so that the systems can use the processed information to 2. retrieve all the related items (high recall) and 3. rank the items by the order of the most relevance to the user's intent (high precision). Each phase has its unique challenges but deep learning has been ubiquitously pushing beyond the limit. After walking through the talk, we hope the audience would gain some first-hand experience building a personalized search/recommender system using deep learning techniques.",2020,"[{'authorId': '1887610660', 'name': 'Zhoutong Fu'}, {'authorId': '1722362', 'name': 'Huiji Gao'}, {'authorId': '48544634', 'name': 'Weiwei Guo'}, {'authorId': '8117157', 'name': 'S. Jha'}, {'authorId': '2117241913', 'name': 'Jun Jia'}, {'authorId': '2109116511', 'name': 'Xiaowei Liu'}, {'authorId': '143947042', 'name': 'Bo Long'}, {'authorId': '2113235078', 'name': 'Jun Shi'}, {'authorId': '16230274', 'name': 'Sida Wang'}, {'authorId': '1893250486', 'name': 'Mingzhou Zhou'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3394486.3406709?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3394486.3406709, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this talk, we will go over the components of personalized search and recommender systems and demonstrate the applications of various deep learning techniques along the way. search and recommender systems are probably the most prevalent ml powered application across the industry. they share most of the components composition and provide a user a ranked list of items, while there is subtle difference that a search system typically acts passively with a clear user intention in terms of queries and a recommender system acts more proactively. deep learning has been wildly successful in solving complex tasks such as image recognition, speech recognition, natural language processing and understanding, machine translation, etc. in the area of personalized recommender systems, deep learning has been showing tremendous impact in recent years. search and recommender systems can be staged roughly in three phases: 1. user and query understanding, where a query or a user profile are processed so that the systems can use the processed information to 2. retrieve all the related items (high recall) and 3. rank the items by the order of the most relevance to the user's intent (high precision). each phase has its unique challenges but deep learning has been ubiquitously pushing beyond the limit. after walking through the talk, we hope the audience would gain some first-hand experience building a personalized search/recommender system using deep learning techniques.",
0943b84d8adaa9a92bd87fbb8b22a9a7bf497ba9,A Personalized Hybrid Tourism Recommender System,"This paper focuses on building personalized recommender system in the tourism field. The application recommends to a tourist the best attractions in a particular place according to his preferences, his profile and his appreciation to previous visited places. This paper proposes a hybrid recommender system that combines the three most known recommender methods which are: the collaborative filtering (CF), the content-based filtering (CB) and the demographic filtering (DF). In order to implement these recommender methods, we have applied different machine learning algorithms which are the K-nearest neighbors (K-NN) for both CB and CF and the decision tree for the DF. The hybridization is a good choice to make the best of their advantages and to overcome the cold start problem. To enhance the recommendation accuracy, we use two hybridization techniques: switching and weighted. For the weighted approach, a novel linear programming model is applied to obtain the optimal weights' values. An extensive experimental study is conducted based on different evaluation metrics using extracted data from TripAdvisor. Our results show that the hybrid method is more accurate than the other recommender approaches used separately.",2017,"[{'authorId': '39013735', 'name': 'Mohamed Elyes Ben Haj Kbaier'}, {'authorId': '1796813', 'name': 'Hela Masri'}, {'authorId': '1759250', 'name': 'S. Krichen'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/AICCSA.2017.12?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/AICCSA.2017.12, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper focuses on building personalized recommender system in the tourism field. the application recommends to a tourist the best attractions in a particular place according to his preferences, his profile and his appreciation to previous visited places. this paper proposes a hybrid recommender system that combines the three most known recommender methods which are: the collaborative filtering (cf), the content-based filtering (cb) and the demographic filtering (df). in order to implement these recommender methods, we have applied different machine learning algorithms which are the k-nearest neighbors (k-nn) for both cb and cf and the decision tree for the df. the hybridization is a good choice to make the best of their advantages and to overcome the cold start problem. to enhance the recommendation accuracy, we use two hybridization techniques: switching and weighted. for the weighted approach, a novel linear programming model is applied to obtain the optimal weights' values. an extensive experimental study is conducted based on different evaluation metrics using extracted data from tripadvisor. our results show that the hybrid method is more accurate than the other recommender approaches used separately.",
ff0c83cebaa271b889544f2e198c6f720cb0162a,Intelligent Mobile-Based Recommender System Framework for Smart Freight Transport,"This paper1 presents a smart freight transporting system that uses machine learning in order to optimize resources and a mobile apps to display results to potential users. In the proposed framework, we developed a clustering based recommender system for customers, strategic objectives are statements that indicate what is critical to the final decision, and the proposed smart system has as an objective to reduce CO2 emissions, fuel consumption, and congestion by reducing the waiting time of the customers. The framework has the potential to identify more efficient and affordable solutions for traffic management and customer satisfactions.",2019,"[{'authorId': '1418984453', 'name': 'Mohamed Yacine Gheraibia'}, {'authorId': '1403322736', 'name': 'Charles Gouin-Vallerand'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3342428.3342697?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3342428.3342697, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper1 presents a smart freight transporting system that uses machine learning in order to optimize resources and a mobile apps to display results to potential users. in the proposed framework, we developed a clustering based recommender system for customers, strategic objectives are statements that indicate what is critical to the final decision, and the proposed smart system has as an objective to reduce co2 emissions, fuel consumption, and congestion by reducing the waiting time of the customers. the framework has the potential to identify more efficient and affordable solutions for traffic management and customer satisfactions.",
533115e143e9a02cf6cf2f31bf221fd6ab7baad9,Regularized Singular Value Decomposition and Application to Recommender System,"Singular value decomposition (SVD) is the mathematical basis of principal component analysis (PCA). Together, SVD and PCA are one of the most widely used mathematical formalism/decomposition in machine learning, data mining, pattern recognition, artificial intelligence, computer vision, signal processing, etc. In recent applications, regularization becomes an increasing trend. In this paper, we present a regularized SVD (RSVD), present an efficient computational algorithm, and provide several theoretical analysis. We show that although RSVD is non-convex, it has a closed-form global optimal solution. Finally, we apply RSVD to the application of recommender system and experimental result show that RSVD outperforms SVD significantly.",2018,"[{'authorId': '49654376', 'name': 'Shuai Zheng'}, {'authorId': '1737469', 'name': 'C. Ding'}, {'authorId': '144962210', 'name': 'F. Nie'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1804.05090, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","singular value decomposition (svd) is the mathematical basis of principal component analysis (pca). together, svd and pca are one of the most widely used mathematical formalism/decomposition in machine learning, data mining, pattern recognition, artificial intelligence, computer vision, signal processing, etc. in recent applications, regularization becomes an increasing trend. in this paper, we present a regularized svd (rsvd), present an efficient computational algorithm, and provide several theoretical analysis. we show that although rsvd is non-convex, it has a closed-form global optimal solution. finally, we apply rsvd to the application of recommender system and experimental result show that rsvd outperforms svd significantly.",
2f8bb2ac9899fbf33dffebed48d768b74a27e241,Recommender system for big data in education,"With the advent of web based e-learning systems, a huge amount of educational data is getting generated. These massive data gave rise to Big data in educational sectors. Currently, big data analytics techniques are being used to analyze these educational data and generate different predictions and recommendations for students, teachers and schools. Recommendation systems are already very helpful in e-commerce, service industry and social networking sites. Recently recommendation systems are proved to be efficient for education sector as well. In this work we are using recommendation system for Big data in education. This work uses collaborative filtering based recommendation techniques to recommend elective courses to students, depending upon their grade points obtained in other subjects. We are using item based recommendation of Mahout machine learning library on top of Hadoop to generate set of recommendations. Similarity Log-likelihood is used to discover patterns among grades and subjects. Root Mean Square Error between actual grade and recommended grade is used to test the recommendation system. The output of this study can be used by schools, colleges or universities to suggest alternative elective courses to students.",2017,"[{'authorId': '2059698096', 'name': 'S. Dwivedi'}, {'authorId': '2288967045', 'name': 'Dr Kumari Roshni'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ELELTECH.2017.8074993?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ELELTECH.2017.8074993, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with the advent of web based e-learning systems, a huge amount of educational data is getting generated. these massive data gave rise to big data in educational sectors. currently, big data analytics techniques are being used to analyze these educational data and generate different predictions and recommendations for students, teachers and schools. recommendation systems are already very helpful in e-commerce, service industry and social networking sites. recently recommendation systems are proved to be efficient for education sector as well. in this work we are using recommendation system for big data in education. this work uses collaborative filtering based recommendation techniques to recommend elective courses to students, depending upon their grade points obtained in other subjects. we are using item based recommendation of mahout machine learning library on top of hadoop to generate set of recommendations. similarity log-likelihood is used to discover patterns among grades and subjects. root mean square error between actual grade and recommended grade is used to test the recommendation system. the output of this study can be used by schools, colleges or universities to suggest alternative elective courses to students.",
6a9766ecff07c797d6af400173cefe7f2c1a6eef,Compositional descriptor-based recommender system for the materials discovery.,"Structures and properties of many inorganic compounds have been collected historically. However, it only covers a very small portion of possible inorganic crystals, which implies the presence of numerous currently unknown compounds. A powerful machine-learning strategy is mandatory to discover new inorganic compounds from all chemical combinations. Herein we propose a descriptor-based recommender-system approach to estimate the relevance of chemical compositions where crystals can be formed [i.e., chemically relevant compositions (CRCs)]. In addition to data-driven compositional similarity used in the literature, the use of compositional descriptors as a prior knowledge is helpful for the discovery of new compounds. We validate our recommender systems in two ways. First, one database is used to construct a model, while another is used for the validation. Second, we estimate the phase stability for compounds at expected CRCs using density functional theory calculations.",2017,"[{'authorId': '1947843', 'name': 'Atsuto Seko'}, {'authorId': '48865897', 'name': 'Hiroyuki Hayashi'}, {'authorId': '46487378', 'name': 'I. Tanaka'}]","{'url': 'https://arxiv.org/pdf/1711.06387', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1711.06387, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","structures and properties of many inorganic compounds have been collected historically. however, it only covers a very small portion of possible inorganic crystals, which implies the presence of numerous currently unknown compounds. a powerful machine-learning strategy is mandatory to discover new inorganic compounds from all chemical combinations. herein we propose a descriptor-based recommender-system approach to estimate the relevance of chemical compositions where crystals can be formed [i.e., chemically relevant compositions (crcs)]. in addition to data-driven compositional similarity used in the literature, the use of compositional descriptors as a prior knowledge is helpful for the discovery of new compounds. we validate our recommender systems in two ways. first, one database is used to construct a model, while another is used for the validation. second, we estimate the phase stability for compounds at expected crcs using density functional theory calculations.",https://arxiv.org/pdf/1711.06387
4ad6d8af42236c6521e1cda91209909f25a4f19b,Spectrum Occupancy Prediction for Land Mobile Radio Bands Using a Recommender System,"Spectrum occupancy prediction is a key enabler of agile and proactive decision-making for dynamic spectrum management. In this paper, state-of-the- art statistical models and machine learning prediction methods are evaluated on real-world occupancy time series measured in the Land Mobile Radio bands. While there is no universally best method for forecasting spectrum usage data, significant accuracy improvements are shown to be achievable by selecting a suitable prediction method for different frequencies. Motivated by this observation, we treat the problem of automating the selection of a suitable prediction method from a candidate pool as a machine learning task. An approach is proposed that recommends the best performing method for new data instances by learning from prior predictions on spectrum data with similar characteristics. The merit of this approach is shown in terms of improving the prediction accuracy compared to baseline selections without the recommender.",2018,"[{'authorId': '3122454', 'name': 'K. Baddour'}, {'authorId': '144418414', 'name': 'A. Ghasemi'}, {'authorId': '3343365', 'name': 'H. Rutagemwa'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/VTCFall.2018.8690654?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/VTCFall.2018.8690654, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","spectrum occupancy prediction is a key enabler of agile and proactive decision-making for dynamic spectrum management. in this paper, state-of-the- art statistical models and machine learning prediction methods are evaluated on real-world occupancy time series measured in the land mobile radio bands. while there is no universally best method for forecasting spectrum usage data, significant accuracy improvements are shown to be achievable by selecting a suitable prediction method for different frequencies. motivated by this observation, we treat the problem of automating the selection of a suitable prediction method from a candidate pool as a machine learning task. an approach is proposed that recommends the best performing method for new data instances by learning from prior predictions on spectrum data with similar characteristics. the merit of this approach is shown in terms of improving the prediction accuracy compared to baseline selections without the recommender.",
d8514c3b645790b20a8664d818a39febe46ab1f6,A hybrid web recommender system based on Q-learning,"Different efforts have been made to address the problem of information overload on the Internet. Recommender systems aim at directing users through this information space, toward the resources that best meet their needs and interests. Web Content Recommendation has been an active application area for Information Filtering, Web Mining and Machine Learning research. Recent studies show that combining the conceptual and usage information can improve the quality of web recommendations. In this paper we exploit this idea to enhance a reinforcement learning framework, primarily devised for web recommendations based on web usage data. A hybrid web recommendation method is proposed by making use of the conceptual relationships among web resources to derive a novel model of the problem, enriched with semantic knowledge about the usage behavior. With our hybrid model for the web page recommendation problem we show the apt and flexibility of the reinforcement learning framework in the web recommendation domain, and demonstrate how it can be extended in order to incorporate various sources of information. We evaluate our method under different settings and show how this method can improve the overall quality of web recommendations.",2008,"[{'authorId': '3061599', 'name': 'N. Taghipour'}, {'authorId': '1695547', 'name': 'A. Kardan'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/1363686.1363954?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/1363686.1363954, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","different efforts have been made to address the problem of information overload on the internet. recommender systems aim at directing users through this information space, toward the resources that best meet their needs and interests. web content recommendation has been an active application area for information filtering, web mining and machine learning research. recent studies show that combining the conceptual and usage information can improve the quality of web recommendations. in this paper we exploit this idea to enhance a reinforcement learning framework, primarily devised for web recommendations based on web usage data. a hybrid web recommendation method is proposed by making use of the conceptual relationships among web resources to derive a novel model of the problem, enriched with semantic knowledge about the usage behavior. with our hybrid model for the web page recommendation problem we show the apt and flexibility of the reinforcement learning framework in the web recommendation domain, and demonstrate how it can be extended in order to incorporate various sources of information. we evaluate our method under different settings and show how this method can improve the overall quality of web recommendations.",
3061cf7f1bafa31f867942e69b9c394121b92d87,Research of natural language processing based on dynamic search corpus in cultural translation and emotional analysis,"In order to enable students to directly face empirical data, summarize translation rules and learn translation skills, this paper studies the basis, motivation and methods of applying research dynamics in translation and teaching. Presenting data in class is the main method of dynamically searching corpora, which enables learners to face enough bilingual data that are easy to choose, and makes translation skills and teaching of translation of selected language items relatively focused. In recent years, the emotional analysis text has attracted academic scientists, and the professionals involved in the research, the use of research methods, and the cultural background related to language have become more and more extensive. In this paper, natural language processing is used to analyze emotions contained in translated texts. Natural language processing not only helps to manage the huge ability of data to efficiently translate text, but also helps to extract the hidden emotions in text translation. It only takes half the effort to achieve the multiplier effect. The multi label classification in natural language processing can reflect the information contained in emotion. The translated text is more detailed, which is helpful for further research.",2023,"[{'authorId': '1845704297', 'name': 'Junyao Wang'}]","{'url': 'https://www.researchsquare.com/article/rs-2576109/latest.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s00500-023-08138-4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s00500-023-08138-4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in order to enable students to directly face empirical data, summarize translation rules and learn translation skills, this paper studies the basis, motivation and methods of applying research dynamics in translation and teaching. presenting data in class is the main method of dynamically searching corpora, which enables learners to face enough bilingual data that are easy to choose, and makes translation skills and teaching of translation of selected language items relatively focused. in recent years, the emotional analysis text has attracted academic scientists, and the professionals involved in the research, the use of research methods, and the cultural background related to language have become more and more extensive. in this paper, natural language processing is used to analyze emotions contained in translated texts. natural language processing not only helps to manage the huge ability of data to efficiently translate text, but also helps to extract the hidden emotions in text translation. it only takes half the effort to achieve the multiplier effect. the multi label classification in natural language processing can reflect the information contained in emotion. the translated text is more detailed, which is helpful for further research.",https://www.researchsquare.com/article/rs-2576109/latest.pdf
151c1ca4e0e60d9686161f5087b0f78f4b9707f1,Applications of Natural Language Processing and Large Language Models for Social Determinants of Health: Protocol for a Systematic Review,"Background In recent years, the intersection of natural language processing (NLP) and public health has opened innovative pathways for investigating social determinants of health (SDOH) in textual datasets. Despite the promise of NLP in the SDOH domain, the literature is dispersed across various disciplines, and there is a need to consolidate existing knowledge, identify knowledge gaps in the literature, and inform future research directions in this emerging field. Objective This research protocol describes a systematic review to identify and highlight NLP techniques, including large language models, used for SDOH-related studies. Methods A search strategy will be executed across PubMed, Web of Science, IEEE Xplore, Scopus, PsycINFO, HealthSource: Academic Nursing, and ACL Anthology to find studies published in English between 2014 and 2024. Three reviewers (SR, ZZ, and YC) will independently screen the studies to avoid voting bias, and two (AS and YX) additional reviewers will resolve any conflicts during the screening process. We will further screen studies that cited the included studies (forward search). Following the title abstract and full-text screening, the characteristics and main findings of the included studies and resources will be tabulated, visualized, and summarized. Results The search strategy was formulated and run across the 7 databases in August 2024. We expect the results to be submitted for peer review publication in early 2025. As of December 2024, the title and abstract screening was underway. Conclusions This systematic review aims to provide a comprehensive study of existing research on the application of NLP for various SDOH tasks across multiple textual datasets. By rigorously evaluating the methodologies, tools, and outcomes of eligible studies, the review will identify gaps in current knowledge and suggest directions for future research in the form of specific research questions. The findings will be instrumental in developing more effective NLP models for SDOH, ultimately contributing to improved health outcomes and a better understanding of social determinants in diverse populations. International Registered Report Identifier (IRRID) DERR1-10.2196/66094",2024,"[{'authorId': '2283288168', 'name': 'Swati Rajwal'}, {'authorId': '2116460586', 'name': 'Ziyuan Zhang'}, {'authorId': '2681738', 'name': 'Yankai Chen'}, {'authorId': '2266836475', 'name': 'H. Rogers'}, {'authorId': '2291753811', 'name': 'Abeed Sarker'}, {'authorId': '2256294113', 'name': 'Yunyu Xiao'}]","{'url': '', 'status': None, 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11795155, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background in recent years, the intersection of natural language processing (nlp) and public health has opened innovative pathways for investigating social determinants of health (sdoh) in textual datasets. despite the promise of nlp in the sdoh domain, the literature is dispersed across various disciplines, and there is a need to consolidate existing knowledge, identify knowledge gaps in the literature, and inform future research directions in this emerging field. objective this research protocol describes a systematic review to identify and highlight nlp techniques, including large language models, used for sdoh-related studies. methods a search strategy will be executed across pubmed, web of science, ieee xplore, scopus, psycinfo, healthsource: academic nursing, and acl anthology to find studies published in english between 2014 and 2024. three reviewers (sr, zz, and yc) will independently screen the studies to avoid voting bias, and two (as and yx) additional reviewers will resolve any conflicts during the screening process. we will further screen studies that cited the included studies (forward search). following the title abstract and full-text screening, the characteristics and main findings of the included studies and resources will be tabulated, visualized, and summarized. results the search strategy was formulated and run across the 7 databases in august 2024. we expect the results to be submitted for peer review publication in early 2025. as of december 2024, the title and abstract screening was underway. conclusions this systematic review aims to provide a comprehensive study of existing research on the application of nlp for various sdoh tasks across multiple textual datasets. by rigorously evaluating the methodologies, tools, and outcomes of eligible studies, the review will identify gaps in current knowledge and suggest directions for future research in the form of specific research questions. the findings will be instrumental in developing more effective nlp models for sdoh, ultimately contributing to improved health outcomes and a better understanding of social determinants in diverse populations. international registered report identifier (irrid) derr1-10.2196/66094",
493633eaac5a7ea2b68fd54dbf7ad1fbe08ea9cd,Using an Artificial Intelligence Tool Incorporating Natural Language Processing to Identify Low-Prevalence Cases of ANCA-Associated Vasculitis in Electronic Health Records,". Background: Anti-neutrophil cytoplasmatic antibody (ANCA)-associated vasculitis (AAV) is a rare, life-threatening, systemic auto-immune disease. Due to the low prevalence and heterogenous registration, there is an urgent need to improve identification of AAV patients within the electronic health record (EHR)-system of health organizations to facilitate clinical research. Methods: Our aim was to identify, with a high sensitivity, low-prevalence AAV patients within large EHR-systems (>2.000.000 records) using an artificial intelligence (AI)-search tool. We combined a search on structured and unstructured data with natural language processing (NLP)-based exclusion. We developed the method in an academic center with an established AAV training set (n=203) and validated the method in a non-academic center with a validation set (n=84). We anonymously reviewed all identified patient records for AAV diagnosis. Results: The final search strategy combined four queries on disease description, laboratory measurements, medication and specialisms. In the training center, this search identified 608 patients, of which 346 were AAV patients upon manual review. 197/203 patients of the training set were retrieved, indicating a sensitivity of 97%. Employing NLP-based exclusion resulted in 444 patients with 339 AAV patients, resulting in an increase of positive predictive value (PPV) from 57% to 78% and a sensitivity of 96%. In the validation center the search strategy identified 333 patients, of which 194 were AAV patients, including 82/84 (98%) patients of the validation set. After NLP-based exclusion 223 patients remained, including 196 AAV patients, improving PPV from 58 to 86% with a sensitivity of 98%. Our identification method outperformed ICD-10 coding predominantly in identifying myeloperoxidase (MPO)-positive AAV patients and patients with few specialisms involved. Conclusions: We demonstrated excellent performance of an AI-based identification method, incorporating NLP, to identify AAV patients in EHRs and we validated the applicability and transportability. This method can accelerate research efforts, while avoiding the limitations of ICD-10-based registration.",2023,"[{'authorId': '2282283991', 'name': 'J. R. V. Leeuwen'}, {'authorId': '6276523', 'name': 'E. L. Penne'}, {'authorId': '2291742856', 'name': 'Ton J. Rabelink'}, {'authorId': '2302250488', 'name': 'Rachel Knevel'}, {'authorId': '2301844474', 'name': 'Yoe Kie Onno Teng'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1681/ASN.20233411S1102b?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1681/ASN.20233411S1102b, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",". background: anti-neutrophil cytoplasmatic antibody (anca)-associated vasculitis (aav) is a rare, life-threatening, systemic auto-immune disease. due to the low prevalence and heterogenous registration, there is an urgent need to improve identification of aav patients within the electronic health record (ehr)-system of health organizations to facilitate clinical research. methods: our aim was to identify, with a high sensitivity, low-prevalence aav patients within large ehr-systems (>2.000.000 records) using an artificial intelligence (ai)-search tool. we combined a search on structured and unstructured data with natural language processing (nlp)-based exclusion. we developed the method in an academic center with an established aav training set (n=203) and validated the method in a non-academic center with a validation set (n=84). we anonymously reviewed all identified patient records for aav diagnosis. results: the final search strategy combined four queries on disease description, laboratory measurements, medication and specialisms. in the training center, this search identified 608 patients, of which 346 were aav patients upon manual review. 197/203 patients of the training set were retrieved, indicating a sensitivity of 97%. employing nlp-based exclusion resulted in 444 patients with 339 aav patients, resulting in an increase of positive predictive value (ppv) from 57% to 78% and a sensitivity of 96%. in the validation center the search strategy identified 333 patients, of which 194 were aav patients, including 82/84 (98%) patients of the validation set. after nlp-based exclusion 223 patients remained, including 196 aav patients, improving ppv from 58 to 86% with a sensitivity of 98%. our identification method outperformed icd-10 coding predominantly in identifying myeloperoxidase (mpo)-positive aav patients and patients with few specialisms involved. conclusions: we demonstrated excellent performance of an ai-based identification method, incorporating nlp, to identify aav patients in ehrs and we validated the applicability and transportability. this method can accelerate research efforts, while avoiding the limitations of icd-10-based registration.",
d67d3e20bf9fbcba639231bc9a7d10f4d5cd6f7e,Using Natural Language Processing to Enhance the Efficiency of Digital Services: A Systematic Literature Review,"The study focuses on the use of Natural Language Processing (NLP) to enhance the efficiency of digital services. The primary goal is to evaluate and analyze research published over a five-year span regarding NLP and its impact on digital services. This includes the predominant publishing mediums, high-impact journals, recurring keywords, and the geographical contribution in this domain. The research was conducted following the guidelines set by Kitchenham and Charters. The search was centered on well-established academic databases, using advanced search queries with pertinent keywords. Selected articles were assessed based on specific criteria, and key information from each article was extracted using the Mendeley Desktop tool. Research outcomes highlighted an upward trend in publishing NLP studies in high-impact journals, with a notable contribution from the United States, China, India, and the United Kingdom. The recurring keywords underscored the link between NLP, Machine Learning, and Deep Learning. Additionally, the rising significance of NLP in improving digital services was observed, indicating a bright future for its role in digital transformation.",2023,"[{'authorId': '2290957067', 'name': 'Thalía Díaz Tunjar'}]","{'url': 'https://revistasinvestigacion.unmsm.edu.pe/index.php/sistem/article/download/27142/20646', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.15381/risi.v16i2.27142?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.15381/risi.v16i2.27142, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the study focuses on the use of natural language processing (nlp) to enhance the efficiency of digital services. the primary goal is to evaluate and analyze research published over a five-year span regarding nlp and its impact on digital services. this includes the predominant publishing mediums, high-impact journals, recurring keywords, and the geographical contribution in this domain. the research was conducted following the guidelines set by kitchenham and charters. the search was centered on well-established academic databases, using advanced search queries with pertinent keywords. selected articles were assessed based on specific criteria, and key information from each article was extracted using the mendeley desktop tool. research outcomes highlighted an upward trend in publishing nlp studies in high-impact journals, with a notable contribution from the united states, china, india, and the united kingdom. the recurring keywords underscored the link between nlp, machine learning, and deep learning. additionally, the rising significance of nlp in improving digital services was observed, indicating a bright future for its role in digital transformation.",https://revistasinvestigacion.unmsm.edu.pe/index.php/sistem/article/download/27142/20646
301c6b4117580efba62549c87687ac4bcbe701f2,Natural Language Processing Methods and Bipolar Disorder: Scoping Review,"Background Health researchers are increasingly using natural language processing (NLP) to study various mental health conditions using both social media and electronic health records (EHRs). There is currently no published synthesis that relates specifically to the use of NLP methods for bipolar disorder, and this scoping review was conducted to synthesize valuable insights that have been presented in the literature. Objective This scoping review explored how NLP methods have been used in research to better understand bipolar disorder and identify opportunities for further use of these methods. Methods A systematic, computerized search of index and free-text terms related to bipolar disorder and NLP was conducted using 5 databases and 1 anthology: MEDLINE, PsycINFO, Academic Search Ultimate, Scopus, Web of Science Core Collection, and the ACL Anthology. Results Of 507 identified studies, a total of 35 (6.9%) studies met the inclusion criteria. A narrative synthesis was used to describe the data, and the studies were grouped into four objectives: prediction and classification (n=25), characterization of the language of bipolar disorder (n=13), use of EHRs to measure health outcomes (n=3), and use of EHRs for phenotyping (n=2). Ethical considerations were reported in 60% (21/35) of the studies. Conclusions The current literature demonstrates how language analysis can be used to assist in and improve the provision of care for people living with bipolar disorder. Individuals with bipolar disorder and the medical community could benefit from research that uses NLP to investigate risk-taking, web-based services, social and occupational functioning, and the representation of gender in bipolar disorder populations on the web. Future research that implements NLP methods to study bipolar disorder should be governed by ethical principles, and any decisions regarding the collection and sharing of data sets should ultimately be made on a case-by-case basis, considering the risk to the data participants and whether their privacy can be ensured.",2022,"[{'authorId': '2163193669', 'name': 'Daisy Harvey'}, {'authorId': '6492935', 'name': 'F. Lobban'}, {'authorId': '1929390', 'name': 'Paul Rayson'}, {'authorId': '146219419', 'name': 'Aaron Warner'}, {'authorId': '34576083', 'name': 'Steven H. Jones'}]","{'url': 'https://mental.jmir.org/2022/4/e35928/PDF', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9077496, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background health researchers are increasingly using natural language processing (nlp) to study various mental health conditions using both social media and electronic health records (ehrs). there is currently no published synthesis that relates specifically to the use of nlp methods for bipolar disorder, and this scoping review was conducted to synthesize valuable insights that have been presented in the literature. objective this scoping review explored how nlp methods have been used in research to better understand bipolar disorder and identify opportunities for further use of these methods. methods a systematic, computerized search of index and free-text terms related to bipolar disorder and nlp was conducted using 5 databases and 1 anthology: medline, psycinfo, academic search ultimate, scopus, web of science core collection, and the acl anthology. results of 507 identified studies, a total of 35 (6.9%) studies met the inclusion criteria. a narrative synthesis was used to describe the data, and the studies were grouped into four objectives: prediction and classification (n=25), characterization of the language of bipolar disorder (n=13), use of ehrs to measure health outcomes (n=3), and use of ehrs for phenotyping (n=2). ethical considerations were reported in 60% (21/35) of the studies. conclusions the current literature demonstrates how language analysis can be used to assist in and improve the provision of care for people living with bipolar disorder. individuals with bipolar disorder and the medical community could benefit from research that uses nlp to investigate risk-taking, web-based services, social and occupational functioning, and the representation of gender in bipolar disorder populations on the web. future research that implements nlp methods to study bipolar disorder should be governed by ethical principles, and any decisions regarding the collection and sharing of data sets should ultimately be made on a case-by-case basis, considering the risk to the data participants and whether their privacy can be ensured.",https://mental.jmir.org/2022/4/e35928/PDF
88acbd6530b3a21a2f1da4b093db1eabeb0ede91,Natural Language Processing to Identify Digital Learning Tools in Postgraduate Family Medicine: Protocol for a Scoping Review,"Background The COVID-19 pandemic has highlighted the growing need for digital learning tools in postgraduate family medicine training. Family medicine departments must understand and recognize the use and effectiveness of digital tools in order to integrate them into curricula and develop effective learning tools that fill gaps and meet the learning needs of trainees. Objective This scoping review will aim to explore and organize the breadth of knowledge regarding digital learning tools in family medicine training. Methods This scoping review follows the 6 stages of the methodological framework outlined first by Arksey and O’Malley, then refined by Levac et al, including a search of published academic literature in 6 databases (MEDLINE, ERIC, Education Source, Embase, Scopus, and Web of Science) and gray literature. Following title and abstract and full text screening, characteristics and main findings of the included studies and resources will be tabulated and summarized. Thematic analysis and natural language processing (NLP) will be conducted in parallel using a 9-step approach to identify common themes and synthesize the literature. Additionally, NLP will be employed for bibliometric and scientometric analysis of the identified literature. Results The search strategy has been developed and launched. As of October 2021, we have completed stages 1, 2, and 3 of the scoping review. We identified 132 studies for inclusion through the academic literature search and 127 relevant studies in the gray literature search. Further refinement of the eligibility criteria and data extraction has been ongoing since September 2021. Conclusions In this scoping review, we will identify and consolidate information and evidence related to the use and effectiveness of existing digital learning tools in postgraduate family medicine training. Our findings will improve the understanding of the current landscape of digital learning tools, which will be of great value to educators and trainees interested in using existing tools, innovators looking to design digital learning tools that meet current needs, and researchers involved in the study of digital tools. Trial Registration OSF Registries osf.io/wju4k; https://osf.io/wju4k International Registered Report Identifier (IRRID) DERR1-10.2196/34575",2022,"[{'authorId': '2164037540', 'name': 'Hui Yan'}, {'authorId': '3399428', 'name': 'Arya Rahgozar'}, {'authorId': '2029730606', 'name': 'Claire Sethuram'}, {'authorId': '51185137', 'name': 'S. Karunananthan'}, {'authorId': '144195412', 'name': 'D. Archibald'}, {'authorId': '38240464', 'name': 'Lindsay Bradley'}, {'authorId': '1789626409', 'name': 'Ramtin Hakimjavadi'}, {'authorId': '1432862358', 'name': 'Mary Helmer-Smith'}, {'authorId': '1422056561', 'name': 'K. Jolin-Dahel'}, {'authorId': '113959990', 'name': 'T. McCutcheon'}, {'authorId': '2139435111', 'name': 'Jeffrey Puncher'}, {'authorId': '13112681', 'name': 'Parisa Rezaiefar'}, {'authorId': '1995342622', 'name': 'Lina Shoppoff'}, {'authorId': '143710688', 'name': 'C. Liddy'}]","{'url': 'https://www.researchprotocols.org/2022/5/e34575/PDF', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9112078, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background the covid-19 pandemic has highlighted the growing need for digital learning tools in postgraduate family medicine training. family medicine departments must understand and recognize the use and effectiveness of digital tools in order to integrate them into curricula and develop effective learning tools that fill gaps and meet the learning needs of trainees. objective this scoping review will aim to explore and organize the breadth of knowledge regarding digital learning tools in family medicine training. methods this scoping review follows the 6 stages of the methodological framework outlined first by arksey and o’malley, then refined by levac et al, including a search of published academic literature in 6 databases (medline, eric, education source, embase, scopus, and web of science) and gray literature. following title and abstract and full text screening, characteristics and main findings of the included studies and resources will be tabulated and summarized. thematic analysis and natural language processing (nlp) will be conducted in parallel using a 9-step approach to identify common themes and synthesize the literature. additionally, nlp will be employed for bibliometric and scientometric analysis of the identified literature. results the search strategy has been developed and launched. as of october 2021, we have completed stages 1, 2, and 3 of the scoping review. we identified 132 studies for inclusion through the academic literature search and 127 relevant studies in the gray literature search. further refinement of the eligibility criteria and data extraction has been ongoing since september 2021. conclusions in this scoping review, we will identify and consolidate information and evidence related to the use and effectiveness of existing digital learning tools in postgraduate family medicine training. our findings will improve the understanding of the current landscape of digital learning tools, which will be of great value to educators and trainees interested in using existing tools, innovators looking to design digital learning tools that meet current needs, and researchers involved in the study of digital tools. trial registration osf registries osf.io/wju4k; https://osf.io/wju4k international registered report identifier (irrid) derr1-10.2196/34575",https://www.researchprotocols.org/2022/5/e34575/PDF
28686431d07a248bc63fcc57694a6408f2e88a56,Digital learning tools for postgraduate family medicine training: Protocol for a scoping review using natural language processing (Preprint),"
 BACKGROUND
 Introduction
The COVID-19 pandemic has highlighted the growing need for digital learning tools in postgraduate family medicine training. Family medicine departments must understand and recognize the use and effectiveness of digital tools in order to integrate them into curricula and develop effective learning tools that fill gaps and meet the learning needs of trainees.
 
 
 OBJECTIVE
 This scoping review will aim to explore and organize the breadth of knowledge regarding digital learning tools in family medicine training.
 
 
 METHODS
 This scoping review will follow the methodological framework outlined by Arksey and O’Malley, including a search of published academic literature in six databases (MEDLINE, ERIC, Education Source, Embase, Scopus, and Web of Science) and grey literature. Following title/abstract, and full text screening, characteristics and main findings of the included studies and resources will be tabulated and summarized. Thematic analysis and natural language processing will be conducted to identify common themes and synthesize the literature. Additionally, natural language processing (NLP) will be employed for bibliometric and scientometric analysis of the identified literature.
 
 
 RESULTS
 The search strategy has been developed and launched. Data extraction is currently underway.
 
 
 CONCLUSIONS
 In this scoping review, we will identify and consolidate information and evidence related to the use and effectiveness of existing digital learning tools in postgraduate family medicine training. Our findings will improve the understanding of the current landscape of digital learning tools, which will be of great value to educators and trainees interested in using existing tools, to innovators looking to design digital learning tools that meet current needs, and to researchers involved in the study of digital tools.
",2021,"[{'authorId': '2108942500', 'name': 'Huijun Yan'}, {'authorId': '3399428', 'name': 'Arya Rahgozar'}, {'authorId': '2029730606', 'name': 'Claire Sethuram'}, {'authorId': '2139424121', 'name': 'Sathya Karunananathan'}, {'authorId': '144195412', 'name': 'D. Archibald'}, {'authorId': '38240464', 'name': 'Lindsay Bradley'}, {'authorId': '1789626409', 'name': 'Ramtin Hakimjavadi'}, {'authorId': '1432862358', 'name': 'Mary Helmer-Smith'}, {'authorId': '1422056561', 'name': 'K. Jolin-Dahel'}, {'authorId': '113959990', 'name': 'T. McCutcheon'}, {'authorId': '2139435111', 'name': 'Jeffrey Puncher'}, {'authorId': '13112681', 'name': 'Parisa Rezaiefar'}, {'authorId': '1995342622', 'name': 'Lina Shoppoff'}, {'authorId': '143710688', 'name': 'C. Liddy'}]","{'url': 'https://www.researchprotocols.org/2022/5/e34575/PDF', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2196/preprints.34575?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2196/preprints.34575, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background introduction the covid-19 pandemic has highlighted the growing need for digital learning tools in postgraduate family medicine training. family medicine departments must understand and recognize the use and effectiveness of digital tools in order to integrate them into curricula and develop effective learning tools that fill gaps and meet the learning needs of trainees. objective this scoping review will aim to explore and organize the breadth of knowledge regarding digital learning tools in family medicine training. methods this scoping review will follow the methodological framework outlined by arksey and o’malley, including a search of published academic literature in six databases (medline, eric, education source, embase, scopus, and web of science) and grey literature. following title/abstract, and full text screening, characteristics and main findings of the included studies and resources will be tabulated and summarized. thematic analysis and natural language processing will be conducted to identify common themes and synthesize the literature. additionally, natural language processing (nlp) will be employed for bibliometric and scientometric analysis of the identified literature. results the search strategy has been developed and launched. data extraction is currently underway. conclusions in this scoping review, we will identify and consolidate information and evidence related to the use and effectiveness of existing digital learning tools in postgraduate family medicine training. our findings will improve the understanding of the current landscape of digital learning tools, which will be of great value to educators and trainees interested in using existing tools, to innovators looking to design digital learning tools that meet current needs, and to researchers involved in the study of digital tools.",https://www.researchprotocols.org/2022/5/e34575/PDF
63fbfdb5b0a4bbf76ca0c4403bcc623803674600,GenCLiP 3: mining human genes' functions and regulatory networks from PubMed based on co-occurrences and natural language processing,"SUMMARY
We present a web server, GenCLiP 3, which is an updated version of GenCLiP 2.0 to enhance analysis of human gene functions and regulatory networks, with the following improvements: i) accurate recognition of molecular interactions with polarity and directionality from the entire PubMed database; ii) support for Boolean search to customize multiple-term search and to quickly retrieve function related genes; iii) strengthened association between gene and keyword by a new scoring method; and iv) daily updates following literature release at PubMed FTP.


AVAILABILITY
The server is freely available for academic use at: http://ci.smu.edu.cn/genclip3/.


SUPPLEMENTARY INFORMATION
Supplementary data are available at Bioinformatics online.",2019,"[{'authorId': '2110182515', 'name': 'Jia-Hong Wang'}, {'authorId': '2147621', 'name': 'Ling-Feng Zhao'}, {'authorId': '2109012678', 'name': 'Hua-Feng Wang'}, {'authorId': '2114782661', 'name': 'Yu Wen'}, {'authorId': '2052123563', 'name': 'Kui-Kui Jiang'}, {'authorId': '2067699252', 'name': 'Xiang-Ming Mao'}, {'authorId': '2112254032', 'name': 'Zi-Ying Zhou'}, {'authorId': '1793666', 'name': 'K. Yao'}, {'authorId': '2067901680', 'name': 'Qing-Shan Geng'}, {'authorId': '2068108071', 'name': 'Dan Guo'}, {'authorId': '2189914546', 'name': 'Zhong-Xi Huang'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/bioinformatics/btz807?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/bioinformatics/btz807, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","summary we present a web server, genclip 3, which is an updated version of genclip 2.0 to enhance analysis of human gene functions and regulatory networks, with the following improvements: i) accurate recognition of molecular interactions with polarity and directionality from the entire pubmed database; ii) support for boolean search to customize multiple-term search and to quickly retrieve function related genes; iii) strengthened association between gene and keyword by a new scoring method; and iv) daily updates following literature release at pubmed ftp. availability the server is freely available for academic use at: http://ci.smu.edu.cn/genclip3/. supplementary information supplementary data are available at bioinformatics online.",
114c1ce4096ea5b8218cd3959da4edaa5ae2fa16,842-P: Analysis of Primary Care Provider (PCP) EHR Notes for Discussions of Prediabetes Using Natural Language Processing (NLP) Methods,"Background: Prior studies using structured EHR data suggest that patients with prediabetes are not receiving evidence-based care, but prediabetes may be discussed in unstructured data. We developed and validated an NLP tool to identify discussions about prediabetes in EHR notes. Methods: We included adult patients without diabetes with an in-person office visit at any general medicine clinic at a single academic center and at least one HbA1c 5.7-6.4% between 7/1/2016 and 12/31/2018. In phase 1, we devised an initial keyword search strategy based on clinical experience. We extracted notes with at least one of the keywords and manually annotated them to determine whether they represented clinical discussions of prediabetes. We used the annotated notes to train and evaluate multiple machine learning and deep learning classifiers to replicate human annotation. In phase 2, we applied a similar annotation process and machine learning method on notes from a different group of clinic practices. We analyzed notes from phase 2 to describe the content of prediabetes discussions: labs ordered or reviewed (HbA1c or fasting glucose); lifestyle counseling; diabetes prevention program (DPP) discussion/referral; nutrition referral/discussion; and metformin discussion or ordering/continuation. Results: We identified 269 patients with prediabetes discussions in phase 2. Most commonly, PCPs provided lifestyle counseling (80%), reviewed current labs (63%) and ordered follow-up labs (60%). PCPs rarely discussed/referred to a nutritionist (4%). We did not find any discussions/referrals to a DPP. Metformin was discussed, ordered or continued in Conclusions: We developed and validated a NLP tool that identifies clinical discussions about prediabetes in the EHR. PCPs most commonly provided lifestyle counseling in the office and infrequently placed referrals to nutrition or DPPs, which have strong evidence for preventing progression to diabetes. Disclosure E. Tseng: None. J.L. Schwartz: None. M. Rouhizadeh: None. N.M. Maruthur: Other Relationship; Self; Johns Hopkins HealthCare Solutions. Funding National Institute of Diabetes and Digestive and Kidney Diseases (1K23DK118205-01A1)",2020,"[{'authorId': '4586519', 'name': 'Eva Tseng'}, {'authorId': '2047102831', 'name': 'J. L. Schwartz'}, {'authorId': '3188285', 'name': 'Masoud Rouhizadeh'}, {'authorId': '5619004', 'name': 'N. Maruthur'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2337/db20-842-p?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2337/db20-842-p, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background: prior studies using structured ehr data suggest that patients with prediabetes are not receiving evidence-based care, but prediabetes may be discussed in unstructured data. we developed and validated an nlp tool to identify discussions about prediabetes in ehr notes. methods: we included adult patients without diabetes with an in-person office visit at any general medicine clinic at a single academic center and at least one hba1c 5.7-6.4% between 7/1/2016 and 12/31/2018. in phase 1, we devised an initial keyword search strategy based on clinical experience. we extracted notes with at least one of the keywords and manually annotated them to determine whether they represented clinical discussions of prediabetes. we used the annotated notes to train and evaluate multiple machine learning and deep learning classifiers to replicate human annotation. in phase 2, we applied a similar annotation process and machine learning method on notes from a different group of clinic practices. we analyzed notes from phase 2 to describe the content of prediabetes discussions: labs ordered or reviewed (hba1c or fasting glucose); lifestyle counseling; diabetes prevention program (dpp) discussion/referral; nutrition referral/discussion; and metformin discussion or ordering/continuation. results: we identified 269 patients with prediabetes discussions in phase 2. most commonly, pcps provided lifestyle counseling (80%), reviewed current labs (63%) and ordered follow-up labs (60%). pcps rarely discussed/referred to a nutritionist (4%). we did not find any discussions/referrals to a dpp. metformin was discussed, ordered or continued in conclusions: we developed and validated a nlp tool that identifies clinical discussions about prediabetes in the ehr. pcps most commonly provided lifestyle counseling in the office and infrequently placed referrals to nutrition or dpps, which have strong evidence for preventing progression to diabetes. disclosure e. tseng: none. j.l. schwartz: none. m. rouhizadeh: none. n.m. maruthur: other relationship; self; johns hopkins healthcare solutions. funding national institute of diabetes and digestive and kidney diseases (1k23dk118205-01a1)",
7a478258ad219ba07f7de83f175b0ac68fdcbe3b,Building a Natural Language Processing Tool to Identify Patients With High Clinical Suspicion for Kawasaki Disease from Emergency Department Notes.,"OBJECTIVE
Delayed diagnosis of Kawasaki disease (KD) may lead to serious cardiac complications. We sought to create and test the performance of a natural language processing (NLP) tool, the KD-NLP, in the identification of emergency department (ED) patients for whom the diagnosis of KD should be considered.


METHODS
We developed an NLP tool that recognizes the KD diagnostic criteria based on standard clinical terms and medical word usage using 22 pediatric ED notes augmented by Unified Medical Language System vocabulary. With high suspicion for KD defined as fever and three or more KD clinical signs, KD-NLP was applied to 253 ED notes from children ultimately diagnosed with either KD or another febrile illness. We evaluated KD-NLP performance against ED notes manually reviewed by clinicians and compared the results to a simple keyword search.


RESULTS
KD-NLP identified high-suspicion patients with a sensitivity of 93.6% and specificity of 77.5% compared to notes manually reviewed by clinicians. The tool outperformed a simple keyword search (sensitivity = 41.0%; specificity = 76.3%).


CONCLUSIONS
KD-NLP showed comparable performance to clinician manual chart review for identification of pediatric ED patients with a high suspicion for KD. This tool could be incorporated into the ED electronic health record system to alert providers to consider the diagnosis of KD. KD-NLP could serve as a model for decision support for other conditions in the ED.",2016,"[{'authorId': '145744305', 'name': 'S. Doan'}, {'authorId': '10998257', 'name': 'C. Maehara'}, {'authorId': '11008582', 'name': 'Juan D. Chaparro'}, {'authorId': '101396942', 'name': 'Sisi Lu'}, {'authorId': '47246490', 'name': 'Ruiling Liu'}, {'authorId': '2053875373', 'name': 'Amanda Graham'}, {'authorId': '49431632', 'name': 'Erika K Berry'}, {'authorId': '34607455', 'name': 'Chun-Nan Hsu'}, {'authorId': '5045924', 'name': 'J. Kanegaye'}, {'authorId': '37865894', 'name': 'D. D. Lloyd'}, {'authorId': '1397958221', 'name': 'L. Ohno-Machado'}, {'authorId': '6298375', 'name': 'J. Burns'}, {'authorId': '6000647', 'name': 'A. Tremoulet'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/acem.12925', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/acem.12925?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/acem.12925, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objective delayed diagnosis of kawasaki disease (kd) may lead to serious cardiac complications. we sought to create and test the performance of a natural language processing (nlp) tool, the kd-nlp, in the identification of emergency department (ed) patients for whom the diagnosis of kd should be considered. methods we developed an nlp tool that recognizes the kd diagnostic criteria based on standard clinical terms and medical word usage using 22 pediatric ed notes augmented by unified medical language system vocabulary. with high suspicion for kd defined as fever and three or more kd clinical signs, kd-nlp was applied to 253 ed notes from children ultimately diagnosed with either kd or another febrile illness. we evaluated kd-nlp performance against ed notes manually reviewed by clinicians and compared the results to a simple keyword search. results kd-nlp identified high-suspicion patients with a sensitivity of 93.6% and specificity of 77.5% compared to notes manually reviewed by clinicians. the tool outperformed a simple keyword search (sensitivity = 41.0%; specificity = 76.3%). conclusions kd-nlp showed comparable performance to clinician manual chart review for identification of pediatric ed patients with a high suspicion for kd. this tool could be incorporated into the ed electronic health record system to alert providers to consider the diagnosis of kd. kd-nlp could serve as a model for decision support for other conditions in the ed.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/acem.12925
0eb1f3a1653db79f19324da10a6fed809e70aa31,Effect of faculty on research cooperation and publication: Employing natural language processing,"DOI: 10.14254/2071789X.2018/11-4/11 ABSTRACT. This study continues a series of studies on the effectiveness of scientific conferences. This topic has not been sufficiently investigated although it receives large funds, assuming that these conferences have added value for staff members' academic-professional development. Predicated on questionnaires filled by 96 academic staff members from 17 different departments, we found that when choosing conferences to attend, the type of faculty affect the search for cooperation. Moreover, staff members from the Faculty of Natural Sciences attribute more significance to conferences that result in publications than staff members from the Faculty of Health. The Faculty of Engineering creates negative mediation in the correlation between gender and cooperation. Namely, the Faculty of Engineering does not urge cooperation and even has a negative effect, but its effect is evident mainly among men. This finding complements prior research findings showing that women are more inclined to cooperation (Eckhaus & Davidovitch, 2018a). The current findings show that the inclination to cooperation is not related only to gender issues rather the faculty has an effect as well. The current findings might have a contribution to the significance of the faculty as an influential factor of conferences on cooperation – and in fact on the professional development of staff members.",2018,"[{'authorId': '14102072', 'name': 'N. Davidovitch'}, {'authorId': '71927876', 'name': 'Eyal Eckhaus'}]","{'url': 'https://www.economics-sociology.eu/files/11_317_Davidovitch.pdf', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.14254/2071-789X.2018/11-4/11?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.14254/2071-789X.2018/11-4/11, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","doi: 10.14254/2071789x.2018/11-4/11 abstract. this study continues a series of studies on the effectiveness of scientific conferences. this topic has not been sufficiently investigated although it receives large funds, assuming that these conferences have added value for staff members' academic-professional development. predicated on questionnaires filled by 96 academic staff members from 17 different departments, we found that when choosing conferences to attend, the type of faculty affect the search for cooperation. moreover, staff members from the faculty of natural sciences attribute more significance to conferences that result in publications than staff members from the faculty of health. the faculty of engineering creates negative mediation in the correlation between gender and cooperation. namely, the faculty of engineering does not urge cooperation and even has a negative effect, but its effect is evident mainly among men. this finding complements prior research findings showing that women are more inclined to cooperation (eckhaus & davidovitch, 2018a). the current findings show that the inclination to cooperation is not related only to gender issues rather the faculty has an effect as well. the current findings might have a contribution to the significance of the faculty as an influential factor of conferences on cooperation – and in fact on the professional development of staff members.",https://www.economics-sociology.eu/files/11_317_Davidovitch.pdf
7119249d02998a3f164c94ce825195ef56c4b828,Talk to Papers: Bringing Neural Question Answering to Academic Search,"We introduce Talk to Papers, which exploits the recent open-domain question answering (QA) techniques to improve the current experience of academic search. It’s designed to enable researchers to use natural language queries to find precise answers and extract insights from a massive amount of academic papers. We present a large improvement over classic search engine baseline on several standard QA datasets and provide the community a collaborative data collection tool to curate the first natural language processing research QA dataset via a community effort.",2020,"[{'authorId': '8200875', 'name': 'Tiancheng Zhao'}, {'authorId': '2014351', 'name': 'Kyusong Lee'}]","{'url': 'https://www.aclweb.org/anthology/2020.acl-demos.5.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2004.02002, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we introduce talk to papers, which exploits the recent open-domain question answering (qa) techniques to improve the current experience of academic search. it’s designed to enable researchers to use natural language queries to find precise answers and extract insights from a massive amount of academic papers. we present a large improvement over classic search engine baseline on several standard qa datasets and provide the community a collaborative data collection tool to curate the first natural language processing research qa dataset via a community effort.",https://www.aclweb.org/anthology/2020.acl-demos.5.pdf
984ec2da7e1544c9e4153503be0774ee66950d48,Taxonomy-guided Semantic Indexing for Academic Paper Search,"Academic paper search is an essential task for efficient literature discovery and scientific advancement. While dense retrieval has advanced various ad-hoc searches, it often struggles to match the underlying academic concepts between queries and documents, which is critical for paper search. To enable effective academic concept matching for paper search, we propose Taxonomy-guided Semantic Indexing (TaxoIndex) framework. TaxoIndex extracts key concepts from papers and organizes them as a semantic index guided by an academic taxonomy, and then leverages this index as foundational knowledge to identify academic concepts and link queries and documents. As a plug-and-play framework, TaxoIndex can be flexibly employed to enhance existing dense retrievers. Extensive experiments show that TaxoIndex brings significant improvements, even with highly limited training data, and greatly enhances interpretability.",2024,"[{'authorId': '71965979', 'name': 'SeongKu Kang'}, {'authorId': '48379289', 'name': 'Yunyi Zhang'}, {'authorId': '2149498192', 'name': 'Pengcheng Jiang'}, {'authorId': '3067773', 'name': 'Dongha Lee'}, {'authorId': '2284641156', 'name': 'Jiawei Han'}, {'authorId': '2286165699', 'name': 'Hwanjo Yu'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.19218, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","academic paper search is an essential task for efficient literature discovery and scientific advancement. while dense retrieval has advanced various ad-hoc searches, it often struggles to match the underlying academic concepts between queries and documents, which is critical for paper search. to enable effective academic concept matching for paper search, we propose taxonomy-guided semantic indexing (taxoindex) framework. taxoindex extracts key concepts from papers and organizes them as a semantic index guided by an academic taxonomy, and then leverages this index as foundational knowledge to identify academic concepts and link queries and documents. as a plug-and-play framework, taxoindex can be flexibly employed to enhance existing dense retrievers. extensive experiments show that taxoindex brings significant improvements, even with highly limited training data, and greatly enhances interpretability.",
abb8ce181054bef0bf6f2fe68b9f37b4ef11cce0,NLP-Powered Repository and Search Engine for Academic Papers: A Case Study on Cyber Risk Literature with CyLit,"As the body of academic literature continues to grow, researchers face increasing difficulties in effectively searching for relevant resources. Existing databases and search engines often fall short of providing a comprehensive and contextually relevant collection of academic literature. To address this issue, we propose a novel framework that leverages Natural Language Processing (NLP) techniques. This framework automates the retrieval, summarization, and clustering of academic literature within a specific research domain. To demonstrate the effectiveness of our approach, we introduce CyLit, an NLP-powered repository specifically designed for the cyber risk literature. CyLit empowers researchers by providing access to context-specific resources and enabling the tracking of trends in the dynamic and rapidly evolving field of cyber risk. Through the automatic processing of large volumes of data, our NLP-powered solution significantly enhances the efficiency and specificity of academic literature searches. We compare the literature categorization results of CyLit to those presented in survey papers or generated by ChatGPT, highlighting the distinctive insights this tool provides into cyber risk research literature. Using NLP techniques, we aim to revolutionize the way researchers discover, analyze, and utilize academic resources, ultimately fostering advancements in various domains of knowledge.",2024,"[{'authorId': '2320464002', 'name': 'Linfeng Zhang'}, {'authorId': '2164536663', 'name': 'Changyue Hu'}, {'authorId': '152517200', 'name': 'Zhiyu Quan'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2409.06226, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","as the body of academic literature continues to grow, researchers face increasing difficulties in effectively searching for relevant resources. existing databases and search engines often fall short of providing a comprehensive and contextually relevant collection of academic literature. to address this issue, we propose a novel framework that leverages natural language processing (nlp) techniques. this framework automates the retrieval, summarization, and clustering of academic literature within a specific research domain. to demonstrate the effectiveness of our approach, we introduce cylit, an nlp-powered repository specifically designed for the cyber risk literature. cylit empowers researchers by providing access to context-specific resources and enabling the tracking of trends in the dynamic and rapidly evolving field of cyber risk. through the automatic processing of large volumes of data, our nlp-powered solution significantly enhances the efficiency and specificity of academic literature searches. we compare the literature categorization results of cylit to those presented in survey papers or generated by chatgpt, highlighting the distinctive insights this tool provides into cyber risk research literature. using nlp techniques, we aim to revolutionize the way researchers discover, analyze, and utilize academic resources, ultimately fostering advancements in various domains of knowledge.",
e349aa6cd6400fa5bed3416d951cc9ffb5ec07ea,An Academic Information Collection System based on Large Language Model,"To effectively assess a scholar's capabilities, it is essential to begin by gathering their basic information, forming the foundational step for subsequent analysis. This entails sourcing pertinent details such as the scholar's affiliation, title, research focus, and published papers from online sources. We curated a comprehensive dataset comprising the homepages of numerous scholars and develop a system to collect information. Our methodology involved harnessing search engines and webpage classifiers to locate scholars' homepages across the internet. Once identified, these pages underwent meticulous parsing to extract academic information. Recent advancements in Large Language Models (LLMs) have demonstrated remarkable proficiency across various domains, particularly in fundamental Natural Language Processing (NLP) tasks. By leveraging LLM capabilities, we conducted text extraction from webpage content, resulting in the successful compilation of academic data.",2024,"[{'authorId': '2127615454', 'name': 'Qiwei Lang'}, {'authorId': '2322675553', 'name': 'Shiqi Lyu'}, {'authorId': '2322797431', 'name': 'Haoyi Wang'}, {'authorId': '2311394371', 'name': 'Rui Zhang'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICECAI62591.2024.10675124?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICECAI62591.2024.10675124, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","to effectively assess a scholar's capabilities, it is essential to begin by gathering their basic information, forming the foundational step for subsequent analysis. this entails sourcing pertinent details such as the scholar's affiliation, title, research focus, and published papers from online sources. we curated a comprehensive dataset comprising the homepages of numerous scholars and develop a system to collect information. our methodology involved harnessing search engines and webpage classifiers to locate scholars' homepages across the internet. once identified, these pages underwent meticulous parsing to extract academic information. recent advancements in large language models (llms) have demonstrated remarkable proficiency across various domains, particularly in fundamental natural language processing (nlp) tasks. by leveraging llm capabilities, we conducted text extraction from webpage content, resulting in the successful compilation of academic data.",
26e9df537a9808f8478cda7497f35bbf84819c93,Machine Reading at Scale: A Search Engine for Scientific and Academic Research,"The Internet, much like our universe, is ever-expanding. Information, in the most varied formats, is continuously added to the point of information overload. Consequently, the ability to navigate this ocean of data is crucial in our day-to-day lives, with familiar tools such as search engines carving a path through this unknown. In the research world, articles on a myriad of topics with distinct complexity levels are published daily, requiring specialized tools to facilitate the access and assessment of the information within. Recent endeavors in artificial intelligence, and in natural language processing in particular, can be seen as potential solutions for breaking information overload and provide enhanced search mechanisms by means of advanced algorithms. As the advent of transformer-based language models contributed to a more comprehensive analysis of both text-encoded intents and true document semantic meaning, there is simultaneously a need for additional computational resources. Information retrieval methods can act as low-complexity, yet reliable, filters to feed heavier algorithms, thus reducing computational requirements substantially. In this work, a new search engine is proposed, addressing machine reading at scale in the context of scientific and academic research. It combines state-of-the-art algorithms for information retrieval and reading comprehension tasks to extract meaningful answers from a corpus of scientific documents. The solution is then tested on two current and relevant topics, cybersecurity and energy, proving that the system is able to perform under distinct knowledge domains while achieving competent performance.",2022,"[{'authorId': '2117260291', 'name': 'Norberto Sousa'}, {'authorId': '2058498789', 'name': 'Nuno Oliveira'}, {'authorId': '1683082', 'name': 'Isabel Praça'}]","{'url': 'https://www.mdpi.com/2079-8954/10/2/43/pdf?version=1649908028', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/systems10020043?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/systems10020043, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the internet, much like our universe, is ever-expanding. information, in the most varied formats, is continuously added to the point of information overload. consequently, the ability to navigate this ocean of data is crucial in our day-to-day lives, with familiar tools such as search engines carving a path through this unknown. in the research world, articles on a myriad of topics with distinct complexity levels are published daily, requiring specialized tools to facilitate the access and assessment of the information within. recent endeavors in artificial intelligence, and in natural language processing in particular, can be seen as potential solutions for breaking information overload and provide enhanced search mechanisms by means of advanced algorithms. as the advent of transformer-based language models contributed to a more comprehensive analysis of both text-encoded intents and true document semantic meaning, there is simultaneously a need for additional computational resources. information retrieval methods can act as low-complexity, yet reliable, filters to feed heavier algorithms, thus reducing computational requirements substantially. in this work, a new search engine is proposed, addressing machine reading at scale in the context of scientific and academic research. it combines state-of-the-art algorithms for information retrieval and reading comprehension tasks to extract meaningful answers from a corpus of scientific documents. the solution is then tested on two current and relevant topics, cybersecurity and energy, proving that the system is able to perform under distinct knowledge domains while achieving competent performance.",https://www.mdpi.com/2079-8954/10/2/43/pdf?version=1649908028
a3c0719d847a8cab836500a0ee3b9f4717ed136d,From human writing to artificial intelligence generated text: examining the prospects and potential threats of ChatGPT in academic writing.,"Natural language processing (NLP) has been studied in computing for decades. Recent technological advancements have led to the development of sophisticated artificial intelligence (AI) models, such as Chat Generative Pre-trained Transformer (ChatGPT). These models can perform a range of language tasks and generate human-like responses, which offers exciting prospects for academic efficiency. This manuscript aims at (i) exploring the potential benefits and threats of ChatGPT and other NLP technologies in academic writing and research publications; (ii) highlights the ethical considerations involved in using these tools, and (iii) consider the impact they may have on the authenticity and credibility of academic work. This study involved a literature review of relevant scholarly articles published in peer-reviewed journals indexed in Scopus as quartile 1. The search used keywords such as ""ChatGPT,"" ""AI-generated text,"" ""academic writing,"" and ""natural language processing."" The analysis was carried out using a quasi-qualitative approach, which involved reading and critically evaluating the sources and identifying relevant data to support the research questions. The study found that ChatGPT and other NLP technologies have the potential to enhance academic writing and research efficiency. However, their use also raises concerns about the impact on the authenticity and credibility of academic work. The study highlights the need for comprehensive discussions on the potential use, threats, and limitations of these tools, emphasizing the importance of ethical and academic principles, with human intelligence and critical thinking at the forefront of the research process. This study highlights the need for comprehensive debates and ethical considerations involved in their use. The study also recommends that academics exercise caution when using these tools and ensure transparency in their use, emphasizing the importance of human intelligence and critical thinking in academic work.",2023,"[{'authorId': '151397304', 'name': 'Ismail Dergaa'}, {'authorId': '5446245', 'name': 'K. Chamari'}, {'authorId': '5979825', 'name': 'P. Żmijewski'}, {'authorId': '3806970', 'name': 'H. Ben Saad'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5114/biolsport.2023.125623?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5114/biolsport.2023.125623, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","natural language processing (nlp) has been studied in computing for decades. recent technological advancements have led to the development of sophisticated artificial intelligence (ai) models, such as chat generative pre-trained transformer (chatgpt). these models can perform a range of language tasks and generate human-like responses, which offers exciting prospects for academic efficiency. this manuscript aims at (i) exploring the potential benefits and threats of chatgpt and other nlp technologies in academic writing and research publications; (ii) highlights the ethical considerations involved in using these tools, and (iii) consider the impact they may have on the authenticity and credibility of academic work. this study involved a literature review of relevant scholarly articles published in peer-reviewed journals indexed in scopus as quartile 1. the search used keywords such as ""chatgpt,"" ""ai-generated text,"" ""academic writing,"" and ""natural language processing."" the analysis was carried out using a quasi-qualitative approach, which involved reading and critically evaluating the sources and identifying relevant data to support the research questions. the study found that chatgpt and other nlp technologies have the potential to enhance academic writing and research efficiency. however, their use also raises concerns about the impact on the authenticity and credibility of academic work. the study highlights the need for comprehensive discussions on the potential use, threats, and limitations of these tools, emphasizing the importance of ethical and academic principles, with human intelligence and critical thinking at the forefront of the research process. this study highlights the need for comprehensive debates and ethical considerations involved in their use. the study also recommends that academics exercise caution when using these tools and ensure transparency in their use, emphasizing the importance of human intelligence and critical thinking in academic work.",
ea9a516d5cb0b298f0df50e82b3e0400b72fcdff,Microsoft Academic Graph: When experts are not enough,"Abstract An ongoing project explores the extent to which artificial intelligence (AI), specifically in the areas of natural language processing and semantic reasoning, can be exploited to facilitate the studies of science by deploying software agents equipped with natural language understanding capabilities to read scholarly publications on the web. The knowledge extracted by these AI agents is organized into a heterogeneous graph, called Microsoft Academic Graph (MAG), where the nodes and the edges represent the entities engaging in scholarly communications and the relationships among them, respectively. The frequently updated data set and a few software tools central to the underlying AI components are distributed under an open data license for research and commercial applications. This paper describes the design, schema, and technical and business motivations behind MAG and elaborates how MAG can be used in analytics, search, and recommendation scenarios. How AI plays an important role in avoiding various biases and human induced errors in other data sets and how the technologies can be further improved in the future are also discussed.",2020,"[{'authorId': '1748169', 'name': 'Kuansan Wang'}, {'authorId': '3303634', 'name': 'Zhihong Shen'}, {'authorId': '92605280', 'name': 'Chiyuan Huang'}, {'authorId': '153248481', 'name': 'Chieh-Han Wu'}, {'authorId': '2047998', 'name': 'Yuxiao Dong'}, {'authorId': '2035106', 'name': 'Anshul Kanakia'}]","{'url': 'https://www.mitpressjournals.org/doi/pdf/10.1162/qss_a_00021', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1162/qss_a_00021?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1162/qss_a_00021, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract an ongoing project explores the extent to which artificial intelligence (ai), specifically in the areas of natural language processing and semantic reasoning, can be exploited to facilitate the studies of science by deploying software agents equipped with natural language understanding capabilities to read scholarly publications on the web. the knowledge extracted by these ai agents is organized into a heterogeneous graph, called microsoft academic graph (mag), where the nodes and the edges represent the entities engaging in scholarly communications and the relationships among them, respectively. the frequently updated data set and a few software tools central to the underlying ai components are distributed under an open data license for research and commercial applications. this paper describes the design, schema, and technical and business motivations behind mag and elaborates how mag can be used in analytics, search, and recommendation scenarios. how ai plays an important role in avoiding various biases and human induced errors in other data sets and how the technologies can be further improved in the future are also discussed.",https://www.mitpressjournals.org/doi/pdf/10.1162/qss_a_00021
80e4375f3dc4bcb6901c234f0e58940c13fbcb8a,Enhancing linguistic research through AI-powered reference management: A proposal for a voice-controlled academic assistant,"In today’s digital age, the amount of available research literature is growing exponentially, making it more challenging for researchers to efficiently manage and cite relevant sources. This issue is particularly pronounced in fields like linguistics, where scholars must contend with interdisciplinary sources spanning linguistics, psychology, and computer science. This paper proposes the development of an AI-powered, voice-controlled academic assistant aimed at enhancing the research experience for linguists by streamlining the literature review and citation process. The assistant would use natural language processing (NLP) and machine learning to allow researchers to search for, retrieve, and cite references using voice commands, thereby eliminating many of the tedious aspects of academic research. This proposal outlines the current state of voice-controlled technology, discusses how these technologies can be implemented in academic workflows, and presents a roadmap for the development of a linguist-friendly reference management system. By addressing key technical, ethical, and practical concerns, this paper offers a compelling vision for the future of linguistic research, powered by AI.",2024,"[{'authorId': '70395692', 'name': 'Abdullah Al Fraidan'}]","{'url': 'https://doi.org/10.55214/25768484.v9i1.2240', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.55214/25768484.v9i1.2240?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55214/25768484.v9i1.2240, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in today’s digital age, the amount of available research literature is growing exponentially, making it more challenging for researchers to efficiently manage and cite relevant sources. this issue is particularly pronounced in fields like linguistics, where scholars must contend with interdisciplinary sources spanning linguistics, psychology, and computer science. this paper proposes the development of an ai-powered, voice-controlled academic assistant aimed at enhancing the research experience for linguists by streamlining the literature review and citation process. the assistant would use natural language processing (nlp) and machine learning to allow researchers to search for, retrieve, and cite references using voice commands, thereby eliminating many of the tedious aspects of academic research. this proposal outlines the current state of voice-controlled technology, discusses how these technologies can be implemented in academic workflows, and presents a roadmap for the development of a linguist-friendly reference management system. by addressing key technical, ethical, and practical concerns, this paper offers a compelling vision for the future of linguistic research, powered by ai.",https://doi.org/10.55214/25768484.v9i1.2240
b2cfc2f37c495e1c806ac31a0edde64f3827c35f,Academic assistance chatbot-a comprehensive NLP and deep learning-based approaches,"The rapid growth of digital technologies and natural language processing (NLP) have revolutionized the field of education, creating new demand for automated academic assistance systems. In this paper, we present an NLP-based academic assistance chatbot designed to provide comprehensive support to students and researchers using deep learning techniques.  The chatbot incorporates a range of intelligent features to assist with university recommendations, article writing, automatic question answering (QA), and job search. By leveraging sentiment analysis and sarcasm detection models. The proposed chatbot could offer accurate and insightful university recommendations. Additionally, the chatbot incorporates spell and grammar checking, summarization, paraphrasing, and topic modeling capabilities to aid users in enhancing their writing skills. The QA module enables users to obtain quick and precise answers to factoid-based questions. Moreover, the chatbot helps with internships and job search. According to literature, this work presents the first assistance chatbot that encapsulates all features that may be needed by a university student to facilitate and improve his/her learning process. The results demonstrated clearly in the body of the paper showed the success achieved by the academic assistant proposed and built in this work in all its features or modules to offer help to university students and graduates.",2024,"[{'authorId': '2279490457', 'name': 'Nermin K. Negied'}, {'authorId': '2280569039', 'name': 'Sara H. Anwar'}, {'authorId': '2280570053', 'name': 'Karim M. Abouaish'}, {'authorId': '2280564153', 'name': 'Emil M. Matta'}, {'authorId': '2280568339', 'name': 'Ahmed A. Ahmed'}, {'authorId': '2280569037', 'name': 'Amr K. Farouq'}]","{'url': 'https://ijeecs.iaescore.com/index.php/IJEECS/article/download/35305/17968', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.11591/ijeecs.v33.i2.pp1042-1056?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.11591/ijeecs.v33.i2.pp1042-1056, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the rapid growth of digital technologies and natural language processing (nlp) have revolutionized the field of education, creating new demand for automated academic assistance systems. in this paper, we present an nlp-based academic assistance chatbot designed to provide comprehensive support to students and researchers using deep learning techniques. the chatbot incorporates a range of intelligent features to assist with university recommendations, article writing, automatic question answering (qa), and job search. by leveraging sentiment analysis and sarcasm detection models. the proposed chatbot could offer accurate and insightful university recommendations. additionally, the chatbot incorporates spell and grammar checking, summarization, paraphrasing, and topic modeling capabilities to aid users in enhancing their writing skills. the qa module enables users to obtain quick and precise answers to factoid-based questions. moreover, the chatbot helps with internships and job search. according to literature, this work presents the first assistance chatbot that encapsulates all features that may be needed by a university student to facilitate and improve his/her learning process. the results demonstrated clearly in the body of the paper showed the success achieved by the academic assistant proposed and built in this work in all its features or modules to offer help to university students and graduates.",https://ijeecs.iaescore.com/index.php/IJEECS/article/download/35305/17968
eb00f7cc9678b2306ddbc208f997098ef89caf65,Harnessing Artificial Intelligence for Enhanced Efficiency in Academic Writing and Research,"In the recent past, there has been a surge in the use of artificial intelligence (AI) in the development of smart technologies for the purpose of improving efficiency in writing academic papers and conducting researches. However, the potential of using AI in the improvement of scholarly processes has not been optimally realized due to low awareness and visibility of the tool among the users. In this respect, this paper aims to describe the following tools of AI which can be applied in the research process including literature search and manuscript preparation. To assess the AI technology, the current literature in form of case studies was reviewed and this included the automated literature search engines, citation management software, natural language processing tools and data analysis tools. It also reveals that AI approaches can also help in decreasing the amount of time spent in article and data search, citation, citation management, and even in the generation of quality publications. This essay also examines the ethical issues of using artificial intelligence in research and any bias that may be present. In conclusion, it is necessary to underline that AI can be useful in improving the results of learning processes. But it is crucial that the researchers are trained well and are put in a position to doubt the outcome produced by the AI. Thus, the purpose of the paper is to discuss how AI is being used in academia at the moment and what could be done to expand its use in the future.",2024,"[{'authorId': '2311564936', 'name': 'Alaa Alaa'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.54216/fpa.160209?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.54216/fpa.160209, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the recent past, there has been a surge in the use of artificial intelligence (ai) in the development of smart technologies for the purpose of improving efficiency in writing academic papers and conducting researches. however, the potential of using ai in the improvement of scholarly processes has not been optimally realized due to low awareness and visibility of the tool among the users. in this respect, this paper aims to describe the following tools of ai which can be applied in the research process including literature search and manuscript preparation. to assess the ai technology, the current literature in form of case studies was reviewed and this included the automated literature search engines, citation management software, natural language processing tools and data analysis tools. it also reveals that ai approaches can also help in decreasing the amount of time spent in article and data search, citation, citation management, and even in the generation of quality publications. this essay also examines the ethical issues of using artificial intelligence in research and any bias that may be present. in conclusion, it is necessary to underline that ai can be useful in improving the results of learning processes. but it is crucial that the researchers are trained well and are put in a position to doubt the outcome produced by the ai. thus, the purpose of the paper is to discuss how ai is being used in academia at the moment and what could be done to expand its use in the future.",
afa8b205ec0d0f65e4e9779f947cd1ee5704afc2,Contextual Revelation of Intentions in Machine Learning Articles on arXiv: A New Dimension in Academic Content Analysis,"Our study focuses on developing an innovative system for classifying intentions in machine learning articles on arXiv. This research aims to bring a new dimension to the analysis of academic content by identifying and classifying the underlying intentions of authors, a dimension not covered by traditional search systems. Our method, which enriches content with contextual classifications, transcends simple domain categorization by incorporating specific intention identifications such as proposing new methods, analyzing existing data, or presenting experimental results. To achieve this, we have implemented natural language processing models based on transformers, which have proven to be extremely effective for this task, offering high accuracy in intention classification. The methods used and the results obtained demonstrate the effectiveness of these advanced models in enriching academic articles, thus contributing to the creation of a valuable and contextual tool for the scientific community, particularly in the field of machine learning.",2024,"[{'authorId': '2309835625', 'name': 'Nabila Khouya'}, {'authorId': '35699266', 'name': 'A. Retbi'}, {'authorId': '2264616785', 'name': 'S. Bennani'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ISIVC61350.2024.10577900?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ISIVC61350.2024.10577900, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","our study focuses on developing an innovative system for classifying intentions in machine learning articles on arxiv. this research aims to bring a new dimension to the analysis of academic content by identifying and classifying the underlying intentions of authors, a dimension not covered by traditional search systems. our method, which enriches content with contextual classifications, transcends simple domain categorization by incorporating specific intention identifications such as proposing new methods, analyzing existing data, or presenting experimental results. to achieve this, we have implemented natural language processing models based on transformers, which have proven to be extremely effective for this task, offering high accuracy in intention classification. the methods used and the results obtained demonstrate the effectiveness of these advanced models in enriching academic articles, thus contributing to the creation of a valuable and contextual tool for the scientific community, particularly in the field of machine learning.",
9899bb66cb4ebf24e1c16a6ad76486350f737c2c,Exploring named‐entity recognition techniques for academic books,"Recent advances in the natural language processing (NLP) field have achieved impressive results in various tasks. However, NLP techniques are underrepresented in the analysis of Humanities and Social Science texts and in languages other than English. In particular, academic books are a highly valuable source of information that has not been exploited by these techniques at all. The recognition of named entities (person names, organizations or locations) and their semantic annotation over books could enrich the visibility and discoverability of the information by users. This is an opportunity for academia and the academic publishing industry in which semantic search is a central task and now books can be queried by named entities of interest that are in their content. This work proposes a methodology to apply named‐entity recognition to publish the results into an ontological semantic‐web format. The work has been performed over a corpus of academic books provided by UNE (Unión de Editoriales Universitarias Españolas, Union of Spanish University Presses). Results show an enrichment of the information extracted over the books and of the possibilities of querying them at the individual level but also within the whole set of books, increasing the possibilities for books to be discovered or retrieved beyond metadata.",2024,"[{'authorId': '2311122309', 'name': 'Pablo Calleja-Ibáñez'}, {'authorId': '2082842389', 'name': 'E. Giménez-Toledo'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/leap.1610', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/leap.1610?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/leap.1610, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent advances in the natural language processing (nlp) field have achieved impressive results in various tasks. however, nlp techniques are underrepresented in the analysis of humanities and social science texts and in languages other than english. in particular, academic books are a highly valuable source of information that has not been exploited by these techniques at all. the recognition of named entities (person names, organizations or locations) and their semantic annotation over books could enrich the visibility and discoverability of the information by users. this is an opportunity for academia and the academic publishing industry in which semantic search is a central task and now books can be queried by named entities of interest that are in their content. this work proposes a methodology to apply named‐entity recognition to publish the results into an ontological semantic‐web format. the work has been performed over a corpus of academic books provided by une (unión de editoriales universitarias españolas, union of spanish university presses). results show an enrichment of the information extracted over the books and of the possibilities of querying them at the individual level but also within the whole set of books, increasing the possibilities for books to be discovered or retrieved beyond metadata.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/leap.1610
12d3dc17c53df2e92c4073c6b97863efc48e1bc7,Improving Bibliographic Data Retrieval through Large Language Models,": The advent of large language models (LLMs) has revolutionized various domains of natural language processing, including bibliographic data retrieval. This paper explores the potential of LLMs to enhance the accuracy and efficiency of retrieving bibliographic data from vast digital repositories. By leveraging the deep learning capabilities of LLMs, we propose a novel approach that surpasses traditional keyword-based search methods. Our methodology involves fine-tuning pre-trained LLMs on a comprehensive dataset of bibliographic records, enabling the model to understand and interpret complex queries more effectively. Experimental results demonstrate that our approach significantly improves precision and recall metrics, thereby reducing the retrieval of irrelevant data and enhancing the overall user experience. Furthermore, we discuss the implications of these findings for academic research, library sciences, and digital archiving, highlighting the transformative potential of LLMs in organizing and accessing scholarly information. This study provides a foundation for future research into the integration of LLMs with bibliographic databases, aiming to develop smarter, more intuitive information retrieval systems.",2024,"[{'authorId': '2309497794', 'name': 'Jingjing Qiao'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.25236/fsst.2024.060608?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.25236/fsst.2024.060608, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",": the advent of large language models (llms) has revolutionized various domains of natural language processing, including bibliographic data retrieval. this paper explores the potential of llms to enhance the accuracy and efficiency of retrieving bibliographic data from vast digital repositories. by leveraging the deep learning capabilities of llms, we propose a novel approach that surpasses traditional keyword-based search methods. our methodology involves fine-tuning pre-trained llms on a comprehensive dataset of bibliographic records, enabling the model to understand and interpret complex queries more effectively. experimental results demonstrate that our approach significantly improves precision and recall metrics, thereby reducing the retrieval of irrelevant data and enhancing the overall user experience. furthermore, we discuss the implications of these findings for academic research, library sciences, and digital archiving, highlighting the transformative potential of llms in organizing and accessing scholarly information. this study provides a foundation for future research into the integration of llms with bibliographic databases, aiming to develop smarter, more intuitive information retrieval systems.",
a93e4403e6d897e0569214d1acd18685629212b0,Decoding the Encoded – Linguistic Secrets of Language Models: A Systematic Literature Review,"Language models’ growing role in natural language processing neces- sitates a deeper understanding of their linguistic knowledge. Linguistic probing tasks have become crucial for model explainability, designed to evaluate models’ understanding of vari-ous linguistic phenomena. Objective: This systematic review critically assesses the linguistic knowledge of language models via linguistic probing, providing a comprehensive overview ofthe understood linguistic phenomena and identifying future research areas. Method: We performed an extensive search of relevant academic databases and analyzed 57 articles pub- lished between October 2018 and October 2022. Results: While language models exhibit extensive linguistic knowledge, limitations persist in their comprehension of specific phe- nomena. The review also points to a need for consensus on evaluating language models’ linguistic knowledge and the linguistic terminology used. Conclusion: Our review offers an extensive look into linguistic knowledge of language models through linguistic probing tasks. This study underscores the importance of understanding these models’ linguistic capabilities for effective use in NLP applications and for fostering more explainable AI systems.",2023,"[{'authorId': '2148605181', 'name': 'H. Avetisyan'}, {'authorId': '2244217549', 'name': 'D. Broneske'}]","{'url': 'https://doi.org/10.5121/csit.2023.131606', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5121/csit.2023.131606?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5121/csit.2023.131606, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","language models’ growing role in natural language processing neces- sitates a deeper understanding of their linguistic knowledge. linguistic probing tasks have become crucial for model explainability, designed to evaluate models’ understanding of vari-ous linguistic phenomena. objective: this systematic review critically assesses the linguistic knowledge of language models via linguistic probing, providing a comprehensive overview ofthe understood linguistic phenomena and identifying future research areas. method: we performed an extensive search of relevant academic databases and analyzed 57 articles pub- lished between october 2018 and october 2022. results: while language models exhibit extensive linguistic knowledge, limitations persist in their comprehension of specific phe- nomena. the review also points to a need for consensus on evaluating language models’ linguistic knowledge and the linguistic terminology used. conclusion: our review offers an extensive look into linguistic knowledge of language models through linguistic probing tasks. this study underscores the importance of understanding these models’ linguistic capabilities for effective use in nlp applications and for fostering more explainable ai systems.",https://doi.org/10.5121/csit.2023.131606
ac6c23a5ee616266d902cd7b67e8e70a09edc276,A Comprehensive Evaluation of Biomedical Entity-centric Search,"Biomedical information retrieval has often been studied as a task of detecting whether a system correctly detects entity spans and links these entities to concepts from a given terminology. Most academic research has focused on evaluation of named entity recognition (NER) and entity linking (EL) models which are key components to recognizing diseases and genes in PubMed abstracts. In this work, we perform a fine-grained evaluation intended to understand the efficiency of state-of-the-art BERT-based information extraction (IE) architecture as a biomedical search engine. We present a novel manually annotated dataset of abstracts for disease and gene search. The dataset contains 23K query-abstract pairs, where 152 queries are selected from logs of our target discovery platform and PubMed abstracts annotated with relevance judgments. Specifically, the query list also includes a subset of concepts with at least one ambiguous concept name. As a base-line, we use off-she-shelf Elasticsearch with BM25. Our experiments on NER, EL, and retrieval in a zero-shot setup show the neural IE architecture shows superior performance for both disease and gene concept queries.",2022,"[{'authorId': '2617496', 'name': 'E. Tutubalina'}, {'authorId': '22673596', 'name': 'Z. Miftahutdinov'}, {'authorId': '2212875286', 'name': 'Vladimir Muravlev'}, {'authorId': '2119566307', 'name': 'Anastasia Shneyderman'}]","{'url': 'https://aclanthology.org/2022.emnlp-industry.61.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.18653/v1/2022.emnlp-industry.61?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.18653/v1/2022.emnlp-industry.61, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","biomedical information retrieval has often been studied as a task of detecting whether a system correctly detects entity spans and links these entities to concepts from a given terminology. most academic research has focused on evaluation of named entity recognition (ner) and entity linking (el) models which are key components to recognizing diseases and genes in pubmed abstracts. in this work, we perform a fine-grained evaluation intended to understand the efficiency of state-of-the-art bert-based information extraction (ie) architecture as a biomedical search engine. we present a novel manually annotated dataset of abstracts for disease and gene search. the dataset contains 23k query-abstract pairs, where 152 queries are selected from logs of our target discovery platform and pubmed abstracts annotated with relevance judgments. specifically, the query list also includes a subset of concepts with at least one ambiguous concept name. as a base-line, we use off-she-shelf elasticsearch with bm25. our experiments on ner, el, and retrieval in a zero-shot setup show the neural ie architecture shows superior performance for both disease and gene concept queries.",https://aclanthology.org/2022.emnlp-industry.61.pdf
d79043d23b9579be583e26327e24d0c4d96de74f,A Post-Search System for Grouping Relevant Academic Articles into Research Topics,"In this paper, we develop a smart topics finding system to organize the research topics into a hierarchical tree. First of all, we use some natural language processing techniques to convert the collected snippets into a series of meaningful candidate terms. Second, we use a suffix tree clustering with threshold and two-steps hash to generate the topic label. Third, we use a divisive hierarchical clustering method to arrange the topic label into a hierarchical tree. In this paper, we use precision and normalized Google distance to measure the quality of topic results. According to the results of experiments, we conclude that using our system can give significant performance gains than current academic systems.",2017,"[{'authorId': '38269076', 'name': 'Lin-Chih Chen'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.6138/JIT.2017.18.6.20151010?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.6138/JIT.2017.18.6.20151010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this paper, we develop a smart topics finding system to organize the research topics into a hierarchical tree. first of all, we use some natural language processing techniques to convert the collected snippets into a series of meaningful candidate terms. second, we use a suffix tree clustering with threshold and two-steps hash to generate the topic label. third, we use a divisive hierarchical clustering method to arrange the topic label into a hierarchical tree. in this paper, we use precision and normalized google distance to measure the quality of topic results. according to the results of experiments, we conclude that using our system can give significant performance gains than current academic systems.",
f7b15064013409a8899c8323eebeb0b926faaafe,Search and Recommendation Procedure with the Help of Artificial Intelligence,"This comprehensive research paper examines the integration of Artificial Intelligence (AI) in search and recommendation systems, focusing on developments. The study delves into various AI techniques, including machine learning algorithms, natural language processing, and deep learning, and their applications in enhancing search procedures and recommendation systems. Through an extensive literature review, analysis of case studies, and examination of current challenges, this paper provides in-depth insights into the state-of-the-art AI-driven search and recommendation procedures. The research also discusses ethical considerations, future trends, and potential innovations in this rapidly evolving field, offering a holistic view of the subject matter for both industry professionals and academic researchers.",2019,"[{'authorId': '2321316534', 'name': 'Aravind Reddy Nayani'}, {'authorId': '2321310777', 'name': 'Alok Gupta'}, {'authorId': '2321310894', 'name': 'Prassanna Selvaraj'}, {'authorId': '2321309059', 'name': 'Ravi Kumar Singh'}, {'authorId': '2321310870', 'name': 'Harsh Vaidya'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.36676/jrps.v10.i4.1503?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.36676/jrps.v10.i4.1503, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this comprehensive research paper examines the integration of artificial intelligence (ai) in search and recommendation systems, focusing on developments. the study delves into various ai techniques, including machine learning algorithms, natural language processing, and deep learning, and their applications in enhancing search procedures and recommendation systems. through an extensive literature review, analysis of case studies, and examination of current challenges, this paper provides in-depth insights into the state-of-the-art ai-driven search and recommendation procedures. the research also discusses ethical considerations, future trends, and potential innovations in this rapidly evolving field, offering a holistic view of the subject matter for both industry professionals and academic researchers.",
4a455bf57096e67b9f9ace23132e2b89bb22cf94,Electronic Medical Record Search Engine (EMERSE): An Information Retrieval Tool for Supporting Cancer Research,"PURPOSE The Electronic Medical Record Search Engine (EMERSE) is a software tool built to aid research spanning cohort discovery, population health, and data abstraction for clinical trials. EMERSE is now live at three academic medical centers, with additional sites currently working on implementation. In this report, we describe how EMERSE has been used to support cancer research based on a variety of metrics. METHODS We identified peer-reviewed publications that used EMERSE through online searches as well as through direct e-mails to users based on audit logs. These logs were also used to summarize use at each of the three sites. Search terms for two of the sites were characterized using the natural language processing tool MetaMap to determine to which semantic types the terms could be mapped. RESULTS We identified a total of 326 peer-reviewed publications that used EMERSE through August 2019, although this is likely an underestimation of the true total based on the use log analysis. Oncology-related research comprised nearly one third (n = 105; 32.2%) of all research output. The use logs showed that EMERSE had been used by multiple people at each site (nearly 3,500 across all three) who had collectively logged into the system > 100,000 times. Many user-entered search queries could not be mapped to a semantic type, but the most common semantic type for terms that did match was “disease or syndrome,” followed by “pharmacologic substance.” CONCLUSION EMERSE has been shown to be a valuable tool for supporting cancer research. It has been successfully deployed at other sites, despite some implementation challenges unique to each deployment environment.",2020,"[{'authorId': '2706974', 'name': 'D. Hanauer'}, {'authorId': '1390166347', 'name': 'J. Barnholtz-Sloan'}, {'authorId': '153198500', 'name': 'Mark F. Beno'}, {'authorId': '115263828', 'name': 'G. Del Fiol'}, {'authorId': '3742715', 'name': 'E. Durbin'}, {'authorId': '2278684814', 'name': 'Oksana Gologorskaya'}, {'authorId': '2075342760', 'name': 'Daniel Harris'}, {'authorId': '2485302', 'name': 'Brett M. Harnett'}, {'authorId': '1692553', 'name': 'Kensaku Kawamoto'}, {'authorId': '2055445751', 'name': 'Benjamin May'}, {'authorId': '2064661280', 'name': 'Eric Meeks'}, {'authorId': '32733281', 'name': 'E. Pfaff'}, {'authorId': '1700987503', 'name': 'Janie Weiss'}, {'authorId': '119315113', 'name': 'K. Zheng'}]","{'url': 'https://doi.org/10.1200/cci.19.00134', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7265780, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose the electronic medical record search engine (emerse) is a software tool built to aid research spanning cohort discovery, population health, and data abstraction for clinical trials. emerse is now live at three academic medical centers, with additional sites currently working on implementation. in this report, we describe how emerse has been used to support cancer research based on a variety of metrics. methods we identified peer-reviewed publications that used emerse through online searches as well as through direct e-mails to users based on audit logs. these logs were also used to summarize use at each of the three sites. search terms for two of the sites were characterized using the natural language processing tool metamap to determine to which semantic types the terms could be mapped. results we identified a total of 326 peer-reviewed publications that used emerse through august 2019, although this is likely an underestimation of the true total based on the use log analysis. oncology-related research comprised nearly one third (n = 105; 32.2%) of all research output. the use logs showed that emerse had been used by multiple people at each site (nearly 3,500 across all three) who had collectively logged into the system > 100,000 times. many user-entered search queries could not be mapped to a semantic type, but the most common semantic type for terms that did match was “disease or syndrome,” followed by “pharmacologic substance.” conclusion emerse has been shown to be a valuable tool for supporting cancer research. it has been successfully deployed at other sites, despite some implementation challenges unique to each deployment environment.",https://doi.org/10.1200/cci.19.00134
4f77035a577d46ecc884150bdc3c3ffb0e04bb28,Utilization of Automated Keyword Search to Identify E-Scooter Injuries in the Emergency Department,"Background and objective Accurate identification and categorization of injuries from medical records can be challenging, yet it is important for injury epidemiology and prevention efforts. Coding systems such as the International Classification of Diseases (ICD) have well-known limitations. Utilizing computer-based techniques such as natural language processing (NLP) can help augment the identification and categorization of diseases in electronic health records. We used a Python program to search the text to identify cases of scooter injuries that presented to our emergency department (ED). Materials and methods This retrospective chart review was conducted between March 2017 and June 2019 in a single, urban academic ED with approximately 80,000 annual visits. The physician documentation was stored as combined PDF files by date. A Python program was developed to search the text from 186,987 encounters to find the string “scoot” and to extract the 100 characters before and after the phrase to facilitate a manual review of this subset of charts. Results A total of 890 charts were identified using the Python program, of which 235 (26.4%) were confirmed as e-scooter cases. Patients had an average age of 36 years and 53% were male. In 81.7% of cases, the patients reported a fall from the scooter and only 1.7% reported wearing a helmet during the event. The most commonly injured body areas were the upper extremity (57.9%), head (42.1%), and lower extremity (36.2%). The most frequently consulted specialists were orthopedic and trauma surgeons with 28% of cases requiring a consult. In our population, 9.4% of patients required admission to the hospital. Conclusions The number of results and data returned by the Python program was easy to manage and made it easier to identify charts for abstraction. The charts obtained allowed us to understand the nature and demographics of e-scooter injuries in our ED. E-scooters continue to be a popular mode of transportation, and understanding injury patterns related to them may inform and guide opportunities for policy and prevention.",2021,"[{'authorId': '6258924', 'name': 'A. Pourmand'}, {'authorId': '3239604', 'name': 'K. Boniface'}, {'authorId': '47847304', 'name': 'K. Douglass'}, {'authorId': '1635771877', 'name': 'C. Hood'}, {'authorId': '4314195', 'name': 'S. Frasure'}, {'authorId': '51032488', 'name': 'J. Barnett'}, {'authorId': '39257582', 'name': 'K. Bhatt'}, {'authorId': '3974734', 'name': 'N. Sikka'}]","{'url': 'https://www.cureus.com/articles/75967-utilization-of-automated-keyword-search-to-identify-e-scooter-injuries-in-the-emergency-department.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8667961, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background and objective accurate identification and categorization of injuries from medical records can be challenging, yet it is important for injury epidemiology and prevention efforts. coding systems such as the international classification of diseases (icd) have well-known limitations. utilizing computer-based techniques such as natural language processing (nlp) can help augment the identification and categorization of diseases in electronic health records. we used a python program to search the text to identify cases of scooter injuries that presented to our emergency department (ed). materials and methods this retrospective chart review was conducted between march 2017 and june 2019 in a single, urban academic ed with approximately 80,000 annual visits. the physician documentation was stored as combined pdf files by date. a python program was developed to search the text from 186,987 encounters to find the string “scoot” and to extract the 100 characters before and after the phrase to facilitate a manual review of this subset of charts. results a total of 890 charts were identified using the python program, of which 235 (26.4%) were confirmed as e-scooter cases. patients had an average age of 36 years and 53% were male. in 81.7% of cases, the patients reported a fall from the scooter and only 1.7% reported wearing a helmet during the event. the most commonly injured body areas were the upper extremity (57.9%), head (42.1%), and lower extremity (36.2%). the most frequently consulted specialists were orthopedic and trauma surgeons with 28% of cases requiring a consult. in our population, 9.4% of patients required admission to the hospital. conclusions the number of results and data returned by the python program was easy to manage and made it easier to identify charts for abstraction. the charts obtained allowed us to understand the nature and demographics of e-scooter injuries in our ed. e-scooters continue to be a popular mode of transportation, and understanding injury patterns related to them may inform and guide opportunities for policy and prevention.",https://www.cureus.com/articles/75967-utilization-of-automated-keyword-search-to-identify-e-scooter-injuries-in-the-emergency-department.pdf
566d205b2cfde4775f43cee703b05ecd77d571f3,A relevant document search system model using word2vec approaches,"USU Repository is an institutional digital information system provided by Universitas Sumatera Utara (USU) that preserves and distributes academic papers, such as thesis and dissertation, from all departments in USU. A search box is provided to help search relevant topics from this repository. However, sometimes the search results returned were irrelevant and did not satisfy the user’s expectations. One of the causes for this situation is that the search engine could not perform optimally, particularly if the query were long and complicated. One approach that can be used to solve the problem is using semantic search. Semantic search is an information retrieval process from a sentence that involves understanding the results returned by natural language processing. In light of this approach, this paper aimed to propose a semantic search to seek the relevance between the user’s input query and academic papers returned as search results. This study implemented word2vec method in converting sentences into vectors. This study indicated average precision scores for small datasets as 46% and 73% for larger datasets.",2021,"[{'authorId': '2007039753', 'name': 'S. A. Savittri'}, {'authorId': '2349188073', 'name': 'A. Amalia'}, {'authorId': '2074972634', 'name': 'M. A. Budiman'}]","{'url': 'https://doi.org/10.1088/1742-6596/1898/1/012008', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1088/1742-6596/1898/1/012008?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/1742-6596/1898/1/012008, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","usu repository is an institutional digital information system provided by universitas sumatera utara (usu) that preserves and distributes academic papers, such as thesis and dissertation, from all departments in usu. a search box is provided to help search relevant topics from this repository. however, sometimes the search results returned were irrelevant and did not satisfy the user’s expectations. one of the causes for this situation is that the search engine could not perform optimally, particularly if the query were long and complicated. one approach that can be used to solve the problem is using semantic search. semantic search is an information retrieval process from a sentence that involves understanding the results returned by natural language processing. in light of this approach, this paper aimed to propose a semantic search to seek the relevance between the user’s input query and academic papers returned as search results. this study implemented word2vec method in converting sentences into vectors. this study indicated average precision scores for small datasets as 46% and 73% for larger datasets.",https://doi.org/10.1088/1742-6596/1898/1/012008
2ced926ba4625fc08ac6685de16df2f142b3126f,Automatic assessment of text-based responses in post-secondary education: A systematic review,"Text-based open-ended questions in academic formative and summative assessments help students become deep learners and prepare them to understand concepts for a subsequent conceptual assessment. However, grading text-based questions, especially in large courses, is tedious and time-consuming for instructors. Text processing models continue progressing with the rapid development of Artificial Intelligence (AI) tools and Natural Language Processing (NLP) algorithms. Especially after breakthroughs in Large Language Models (LLM), there is immense potential to automate rapid assessment and feedback of text-based responses in education. This systematic review adopts a scientific and reproducible literature search strategy based on the PRISMA process using explicit inclusion and exclusion criteria to study text-based automatic assessment systems in post-secondary education, screening 838 papers and synthesizing 93 studies. To understand how text-based automatic assessment systems have been developed and applied in education in recent years, three research questions are considered. All included studies are summarized and categorized according to a proposed comprehensive framework, including the input and output of the system, research motivation, and research outcomes, aiming to answer the research questions accordingly. Additionally, the typical studies of automated assessment systems, research methods, and application domains in these studies are investigated and summarized. This systematic review provides an overview of recent educational applications of text-based assessment systems for understanding the latest AI/NLP developments assisting in text-based assessments in higher education. Findings will particularly benefit researchers and educators incorporating LLMs such as ChatGPT into their educational activities.",2023,"[{'authorId': '1516857733', 'name': 'Rujun Gao'}, {'authorId': '71420013', 'name': 'H. Merzdorf'}, {'authorId': '40648965', 'name': 'S. Anwar'}, {'authorId': '46819858', 'name': 'M. C. Hipwell'}, {'authorId': '2133932165', 'name': 'Arun Srinivasa'}]","{'url': 'https://arxiv.org/pdf/2308.16151', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2308.16151, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","text-based open-ended questions in academic formative and summative assessments help students become deep learners and prepare them to understand concepts for a subsequent conceptual assessment. however, grading text-based questions, especially in large courses, is tedious and time-consuming for instructors. text processing models continue progressing with the rapid development of artificial intelligence (ai) tools and natural language processing (nlp) algorithms. especially after breakthroughs in large language models (llm), there is immense potential to automate rapid assessment and feedback of text-based responses in education. this systematic review adopts a scientific and reproducible literature search strategy based on the prisma process using explicit inclusion and exclusion criteria to study text-based automatic assessment systems in post-secondary education, screening 838 papers and synthesizing 93 studies. to understand how text-based automatic assessment systems have been developed and applied in education in recent years, three research questions are considered. all included studies are summarized and categorized according to a proposed comprehensive framework, including the input and output of the system, research motivation, and research outcomes, aiming to answer the research questions accordingly. additionally, the typical studies of automated assessment systems, research methods, and application domains in these studies are investigated and summarized. this systematic review provides an overview of recent educational applications of text-based assessment systems for understanding the latest ai/nlp developments assisting in text-based assessments in higher education. findings will particularly benefit researchers and educators incorporating llms such as chatgpt into their educational activities.",https://arxiv.org/pdf/2308.16151
a2392cf46fe388c78dd9d5e7b5598db9e2d72510,ConvERSe'20: The WSDM 2020 Workshop on Conversational Systems for E-Commerce Recommendations and Search,"Conversational systems have improved dramatically recently, and are receiving increasing attention in academic literature. These systems are also becoming adapted in E-Commerce due to increased integration of E-Commerce search and recommendation source with virtual assistants such as Alexa, Siri, and Google assistant. However, significant research challenges remain spanning areas of dialogue systems, spoken natural language processing, human-computer interaction, and search and recommender systems, which all are exacerbated with demanding requirements of E-Commerce. The purpose of this workshop is to bring together researchers and practitioners in the areas of conversational systems, human-computer interaction, information retrieval, and recommender systems. Bringing diverse research areas together into a single workshop would accelerate progress on adapting conversation systems to the E-Commerce domain, to set a research agenda, to examine how to build and share data sets, and to establish common evaluation metrics and benchmarks to drive research progress.",2020,"[{'authorId': '1685296', 'name': 'Eugene Agichtein'}, {'authorId': '1395813836', 'name': 'Dilek Z. Hakkani-Tür'}, {'authorId': '3378098', 'name': 'Surya Kallumadi'}, {'authorId': '2854981', 'name': 'S. Malmasi'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3336191.3371882?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3336191.3371882, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","conversational systems have improved dramatically recently, and are receiving increasing attention in academic literature. these systems are also becoming adapted in e-commerce due to increased integration of e-commerce search and recommendation source with virtual assistants such as alexa, siri, and google assistant. however, significant research challenges remain spanning areas of dialogue systems, spoken natural language processing, human-computer interaction, and search and recommender systems, which all are exacerbated with demanding requirements of e-commerce. the purpose of this workshop is to bring together researchers and practitioners in the areas of conversational systems, human-computer interaction, information retrieval, and recommender systems. bringing diverse research areas together into a single workshop would accelerate progress on adapting conversation systems to the e-commerce domain, to set a research agenda, to examine how to build and share data sets, and to establish common evaluation metrics and benchmarks to drive research progress.",
a8d4075ae4390db7c1bf04d30c72a65726608e5e,A systematic literature review of hate speech identification on Arabic Twitter data: research challenges and future directions,"The automatic speech identification in Arabic tweets has generated substantial attention among academics in the fields of text mining and natural language processing (NLP). The quantity of studies done on this subject has experienced significant growth. This study aims to provide an overview of this field by conducting a systematic review of literature that focuses on automatic hate speech identification, particularly in the Arabic language. The goal is to examine the research trends in Arabic hate speech identification and offer guidance to researchers by highlighting the most significant studies published between 2018 and 2023. This systematic study addresses five specific research questions concerning the types of the Arabic language used, hate speech categories, classification techniques, feature engineering techniques, performance metrics, validation methods, existing challenges faced by researchers, and potential future research directions. Through a comprehensive search across nine academic databases, 24 studies that met the predefined inclusion criteria and quality assessment were identified. The review findings revealed the existence of many Arabic linguistic varieties used in hate speech on Twitter, with modern standard Arabic (MSA) being the most prominent. In identification techniques, machine learning categories are the most used technique for Arabic hate speech identification. The result also shows different feature engineering techniques used and indicates that N-gram and CBOW are the most used techniques. F1-score, precision, recall, and accuracy were also identified as the most used performance metric. The review also shows that the most used validation method is the train/test split method. Therefore, the findings of this study can serve as valuable guidance for researchers in enhancing the efficacy of their models in future investigations. Besides, algorithm development, policy rule regulation, community management, and legal and ethical consideration are other real-world applications that can be reaped from this research.",2024,"[{'authorId': '2247948147', 'name': 'Ali Alhazmi'}, {'authorId': '2292336733', 'name': 'Rohana Mahmud'}, {'authorId': '36826893', 'name': 'N. Idris'}, {'authorId': '51951454', 'name': 'M. E. M. Abo'}, {'authorId': '2295045432', 'name': 'Christopher Ifeanyi Eke'}]","{'url': 'https://doi.org/10.7717/peerj-cs.1966', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11041964, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the automatic speech identification in arabic tweets has generated substantial attention among academics in the fields of text mining and natural language processing (nlp). the quantity of studies done on this subject has experienced significant growth. this study aims to provide an overview of this field by conducting a systematic review of literature that focuses on automatic hate speech identification, particularly in the arabic language. the goal is to examine the research trends in arabic hate speech identification and offer guidance to researchers by highlighting the most significant studies published between 2018 and 2023. this systematic study addresses five specific research questions concerning the types of the arabic language used, hate speech categories, classification techniques, feature engineering techniques, performance metrics, validation methods, existing challenges faced by researchers, and potential future research directions. through a comprehensive search across nine academic databases, 24 studies that met the predefined inclusion criteria and quality assessment were identified. the review findings revealed the existence of many arabic linguistic varieties used in hate speech on twitter, with modern standard arabic (msa) being the most prominent. in identification techniques, machine learning categories are the most used technique for arabic hate speech identification. the result also shows different feature engineering techniques used and indicates that n-gram and cbow are the most used techniques. f1-score, precision, recall, and accuracy were also identified as the most used performance metric. the review also shows that the most used validation method is the train/test split method. therefore, the findings of this study can serve as valuable guidance for researchers in enhancing the efficacy of their models in future investigations. besides, algorithm development, policy rule regulation, community management, and legal and ethical consideration are other real-world applications that can be reaped from this research.",https://doi.org/10.7717/peerj-cs.1966
611c5c2a6bb389e4d16eb01774d5d962e74ce07d,Delving into the Utilisation of ChatGPT in Scientific Publications in Astronomy,"Rapid progress in the capabilities of machine learning approaches in natural language processing has culminated in the rise of large language models over the last two years. Recent works have shown unprecedented adoption of these for academic writing, especially in some fields, but their pervasiveness in astronomy has not been studied sufficiently. To remedy this, we extract words that ChatGPT uses more often than humans when generating academic text and search a total of 1 million articles for them. This way, we assess the frequency of word occurrence in published works in astronomy tracked by the NASA Astrophysics Data System since 2000. We then perform a statistical analysis of the occurrences. We identify a list of words favoured by ChatGPT and find a statistically significant increase for these words against a control group in 2024, which matches the trend in other disciplines. These results suggest a widespread adoption of these models in the writing of astronomy papers. We encourage organisations, publishers, and researchers to work together to identify ethical and pragmatic guidelines to maximise the benefits of these systems while maintaining scientific rigour.",2024,"[{'authorId': '2304327443', 'name': 'Simone Astarita'}, {'authorId': '2308097144', 'name': 'Sandor Kruk'}, {'authorId': '2303708937', 'name': 'Jan Reerink'}, {'authorId': '2308097044', 'name': ""Pablo G'omez""}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2406.17324, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","rapid progress in the capabilities of machine learning approaches in natural language processing has culminated in the rise of large language models over the last two years. recent works have shown unprecedented adoption of these for academic writing, especially in some fields, but their pervasiveness in astronomy has not been studied sufficiently. to remedy this, we extract words that chatgpt uses more often than humans when generating academic text and search a total of 1 million articles for them. this way, we assess the frequency of word occurrence in published works in astronomy tracked by the nasa astrophysics data system since 2000. we then perform a statistical analysis of the occurrences. we identify a list of words favoured by chatgpt and find a statistically significant increase for these words against a control group in 2024, which matches the trend in other disciplines. these results suggest a widespread adoption of these models in the writing of astronomy papers. we encourage organisations, publishers, and researchers to work together to identify ethical and pragmatic guidelines to maximise the benefits of these systems while maintaining scientific rigour.",
5c74b818e952e791434cfdca1fb64d81ad20edba,Comparative Study of AI Code Generation Tools: Quality Assessment and Performance Analysis,"Artificial intelligence (AI) code generation tools are crucial in software development, processing natural language to improve programming efficiency. Their increasing integration in various industries highlights their potential to transform the way programmers approach and execute software projects. The present research was conducted with the purpose of determining the accuracy and quality of code generated by artificial intelligence (AI) tools. The study began with a systematic mapping of the literature to identify applicable AI tools. Databases such as ACM, Engineering Source, Academic Search Ultimate, IEEE Xplore and Scopus were consulted, from which 621 papers were initially extracted. After applying inclusion criteria, such as English-language papers in computing areas published between 2020 and 2024, 113 resources were selected. A further screening process reduced this number to 44 papers, which identified 11 AI tools for code generation. The method used was a comparative study in which ten programming exercises of varying levels of difficulty were designed and the results obtained from 4 of them are presented. The identified tools generated code for these exercises in different programming languages. The quality of the generated code was evaluated using the SonarQube static analyzer, considering aspects such as safety, reliability and maintainability. The results showed significant variations in code quality among the AI tools. Bing as a code generation tool showed slightly superior performance compared to others, although none stood out as a noticeably superior AI. In conclusion, the research evidenced that, although AI tools for code generation are promising, they still require a pilot to reach their full potential, giving evidence that there is still a long way to go.",2024,"[{'authorId': '2318130319', 'name': 'Michael Alexander Florez Muñoz'}, {'authorId': '2318130363', 'name': 'Juan Camilo Jaramillo De La Torre'}, {'authorId': '2318133504', 'name': 'Stefany Pareja López'}, {'authorId': '2317935973', 'name': 'Stiven Herrera'}, {'authorId': '2318133601', 'name': 'Christian Andrés Candela Uribe'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.62486/latia2024104?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.62486/latia2024104, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","artificial intelligence (ai) code generation tools are crucial in software development, processing natural language to improve programming efficiency. their increasing integration in various industries highlights their potential to transform the way programmers approach and execute software projects. the present research was conducted with the purpose of determining the accuracy and quality of code generated by artificial intelligence (ai) tools. the study began with a systematic mapping of the literature to identify applicable ai tools. databases such as acm, engineering source, academic search ultimate, ieee xplore and scopus were consulted, from which 621 papers were initially extracted. after applying inclusion criteria, such as english-language papers in computing areas published between 2020 and 2024, 113 resources were selected. a further screening process reduced this number to 44 papers, which identified 11 ai tools for code generation. the method used was a comparative study in which ten programming exercises of varying levels of difficulty were designed and the results obtained from 4 of them are presented. the identified tools generated code for these exercises in different programming languages. the quality of the generated code was evaluated using the sonarqube static analyzer, considering aspects such as safety, reliability and maintainability. the results showed significant variations in code quality among the ai tools. bing as a code generation tool showed slightly superior performance compared to others, although none stood out as a noticeably superior ai. in conclusion, the research evidenced that, although ai tools for code generation are promising, they still require a pilot to reach their full potential, giving evidence that there is still a long way to go.",
2dc26ffdf9ab5bfcab52125d41118e5994004586,Automation of Text Summarization Using Hugging Face NLP,"Within the expansive domain of “Natural Language Processing” (NLP), the task of “text summarization” emerges as a foundational element, playing a pivotal role in distilling relevant information from extensive textual corpora. In the digital age, the importance of efficient summarization becomes increasingly critical, given the overwhelming volume of textual information. This comprehensive study delves into the intricacies of both extractive and abstractive summarization techniques, placing a specific focus on transformer-based models like BERT and GPT. These models, celebrated for their remarkable capabilities in context comprehension and coherent summarization, are rigorously evaluated alongside established methods like TF-IDF, TextRank, Sumy, Fine Tuning Transformers, Model-T5, LSTM, greedy, and beam search. The practical implications of text summarization extend across diverse fields, encompassing news stories, academic papers, and social media content, underscoring its broad utility in various domains. This study not only incorporates cutting-edge models but also explores a gamut of evaluation methods to discern the quality of summarization. By intertwining theory and application, this research positions itself at the forefront of evolving summarization approaches, shedding light on the transformative impact on information consumption patterns. The dynamic landscape of summarization methods underscores the need for continuous research and innovation, as technological advancements continue to reshape how individuals access and comprehend information.",2024,"[{'authorId': None, 'name': 'Asmitha M'}, {'authorId': '2268071961', 'name': 'Aashritha Danda'}, {'authorId': '2268071811', 'name': 'Hemanth Bysani'}, {'authorId': '2268107320', 'name': 'R. Singh'}, {'authorId': '10788504', 'name': 'Sneha Kanchan'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/INCET61516.2024.10593316?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/INCET61516.2024.10593316, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","within the expansive domain of “natural language processing” (nlp), the task of “text summarization” emerges as a foundational element, playing a pivotal role in distilling relevant information from extensive textual corpora. in the digital age, the importance of efficient summarization becomes increasingly critical, given the overwhelming volume of textual information. this comprehensive study delves into the intricacies of both extractive and abstractive summarization techniques, placing a specific focus on transformer-based models like bert and gpt. these models, celebrated for their remarkable capabilities in context comprehension and coherent summarization, are rigorously evaluated alongside established methods like tf-idf, textrank, sumy, fine tuning transformers, model-t5, lstm, greedy, and beam search. the practical implications of text summarization extend across diverse fields, encompassing news stories, academic papers, and social media content, underscoring its broad utility in various domains. this study not only incorporates cutting-edge models but also explores a gamut of evaluation methods to discern the quality of summarization. by intertwining theory and application, this research positions itself at the forefront of evolving summarization approaches, shedding light on the transformative impact on information consumption patterns. the dynamic landscape of summarization methods underscores the need for continuous research and innovation, as technological advancements continue to reshape how individuals access and comprehend information.",
897df806e6795c775d37085fc745ff7b1ab39be3,GradExplore: A Holistic Approach to Assisting Higher Studies in Overseas Universities,"In an era marked by a surge in Indian students pursuing higher education abroad, “GradExplore” emerges as a transformative platform, addressing the intricate challenges faced by these aspiring scholars. The platform helps people looking for international education in three steps, considering their specific needs. The first phase, University Recommendation, employs a sophisticated blend of the K-Nearest Neighbors (KNN) algorithm and content-based filtering. This dual methodology ensures that recommendations are not only personalized but also align precisely with students' academic and personal preferences. Moving on to the second phase, Admission Prediction, GradExplore delves into the intricacies of ensemble learning techniques. By leveraging AdaBoost alongside gradient boosting, linear regression, logistic regression, and decision trees, the platform elevates predictive accuracy. In the third phase, Accommodation Assistance, GradExplore leverages the power of Natural Language Processing (NLP) to streamline the housing search process. GradExplore aims to enhance the international student experience, fostering enriching academic journeys and global perspectives.",2024,"[{'authorId': '2212914670', 'name': 'S. A'}, {'authorId': '2277665524', 'name': 'Aakash S'}, {'authorId': '2277663041', 'name': 'Mb. Hariharan'}, {'authorId': '2277643357', 'name': 'Abijith P'}, {'authorId': '2277655989', 'name': 'S. S'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCDS60734.2024.10560459?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCDS60734.2024.10560459, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in an era marked by a surge in indian students pursuing higher education abroad, “gradexplore” emerges as a transformative platform, addressing the intricate challenges faced by these aspiring scholars. the platform helps people looking for international education in three steps, considering their specific needs. the first phase, university recommendation, employs a sophisticated blend of the k-nearest neighbors (knn) algorithm and content-based filtering. this dual methodology ensures that recommendations are not only personalized but also align precisely with students' academic and personal preferences. moving on to the second phase, admission prediction, gradexplore delves into the intricacies of ensemble learning techniques. by leveraging adaboost alongside gradient boosting, linear regression, logistic regression, and decision trees, the platform elevates predictive accuracy. in the third phase, accommodation assistance, gradexplore leverages the power of natural language processing (nlp) to streamline the housing search process. gradexplore aims to enhance the international student experience, fostering enriching academic journeys and global perspectives.",
d1d27aa4eecedb4f830238fe827b05e3c5356a6b,Deep Learning for Intelligent Human–Computer Interaction,"In recent years, gesture recognition and speech recognition, as important input methods in Human–Computer Interaction (HCI), have been widely used in the field of virtual reality. In particular, with the rapid development of deep learning, artificial intelligence, and other computer technologies, gesture recognition and speech recognition have achieved breakthrough research progress. The search platform used in this work is mainly the Google Academic and literature database Web of Science. According to the keywords related to HCI and deep learning, such as “intelligent HCI”, “speech recognition”, “gesture recognition”, and “natural language processing”, nearly 1000 studies were selected. Then, nearly 500 studies of research methods were selected and 100 studies were finally selected as the research content of this work after five years (2019–2022) of year screening. First, the current situation of the HCI intelligent system is analyzed, the realization of gesture interaction and voice interaction in HCI is summarized, and the advantages brought by deep learning are selected for research. Then, the core concepts of gesture interaction are introduced and the progress of gesture recognition and speech recognition interaction is analyzed. Furthermore, the representative applications of gesture recognition and speech recognition interaction are described. Finally, the current HCI in the direction of natural language processing is investigated. The results show that the combination of intelligent HCI and deep learning is deeply applied in gesture recognition, speech recognition, emotion recognition, and intelligent robot direction. A wide variety of recognition methods were proposed in related research fields and verified by experiments. Compared with interactive methods without deep learning, high recognition accuracy was achieved. In Human–Machine Interfaces (HMIs) with voice support, context plays an important role in improving user interfaces. Whether it is voice search, mobile communication, or children’s speech recognition, HCI combined with deep learning can maintain better robustness. The combination of convolutional neural networks and long short-term memory networks can greatly improve the accuracy and precision of action recognition. Therefore, in the future, the application field of HCI will involve more industries and greater prospects are expected.",2022,"[{'authorId': '2112382820', 'name': 'Zhihan Lv'}, {'authorId': '2247819406', 'name': 'F. Poiesi'}, {'authorId': '2053112198', 'name': 'Qi Dong'}, {'authorId': '144484046', 'name': 'Jaime Lloret'}, {'authorId': '72482218', 'name': 'H. Song'}]","{'url': 'https://www.mdpi.com/2076-3417/12/22/11457/pdf?version=1668165580', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app122211457?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app122211457, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent years, gesture recognition and speech recognition, as important input methods in human–computer interaction (hci), have been widely used in the field of virtual reality. in particular, with the rapid development of deep learning, artificial intelligence, and other computer technologies, gesture recognition and speech recognition have achieved breakthrough research progress. the search platform used in this work is mainly the google academic and literature database web of science. according to the keywords related to hci and deep learning, such as “intelligent hci”, “speech recognition”, “gesture recognition”, and “natural language processing”, nearly 1000 studies were selected. then, nearly 500 studies of research methods were selected and 100 studies were finally selected as the research content of this work after five years (2019–2022) of year screening. first, the current situation of the hci intelligent system is analyzed, the realization of gesture interaction and voice interaction in hci is summarized, and the advantages brought by deep learning are selected for research. then, the core concepts of gesture interaction are introduced and the progress of gesture recognition and speech recognition interaction is analyzed. furthermore, the representative applications of gesture recognition and speech recognition interaction are described. finally, the current hci in the direction of natural language processing is investigated. the results show that the combination of intelligent hci and deep learning is deeply applied in gesture recognition, speech recognition, emotion recognition, and intelligent robot direction. a wide variety of recognition methods were proposed in related research fields and verified by experiments. compared with interactive methods without deep learning, high recognition accuracy was achieved. in human–machine interfaces (hmis) with voice support, context plays an important role in improving user interfaces. whether it is voice search, mobile communication, or children’s speech recognition, hci combined with deep learning can maintain better robustness. the combination of convolutional neural networks and long short-term memory networks can greatly improve the accuracy and precision of action recognition. therefore, in the future, the application field of hci will involve more industries and greater prospects are expected.",https://www.mdpi.com/2076-3417/12/22/11457/pdf?version=1668165580
cef12d3f1ee80fd59dfaf1509a56c14b5ec9a82a,A Technical Review of Sequence-to-Sequence Models,"Seq2Seq models and their variants have become a mainstay of modern natural language processing and sequence modelling tasks. Just Information about Seq2Seq models. In this paper, we provide a comprehensive overview of the evolution of Seq2Seq architecture from early-stage RNN based approaches to recent Transformer based methods. The paper extensively covers additional important methods such as attention mechanisms, bidirectional encoders, pointer-generator networks, as well as optimization methods such as beam search, scheduled sampling and reinforcement learning. It also discusses the challenges of data preprocessing, loss functions, and evaluation metrics, as well as applications in machine translation, summarization, speech recognition, and conversational AI. This paper provides a comprehensive report on the design and future directions of Seq2Seq models emphasizing on theoretical foundations as well as real world applications.",2025,"[{'authorId': '2355542950', 'name': 'Tao Bo'}, {'authorId': '2355568582', 'name': 'Weiyi Li'}, {'authorId': '2355925203', 'name': 'Yue Liu'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.70393/616a6e73.323834?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.70393/616a6e73.323834, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","seq2seq models and their variants have become a mainstay of modern natural language processing and sequence modelling tasks. just information about seq2seq models. in this paper, we provide a comprehensive overview of the evolution of seq2seq architecture from early-stage rnn based approaches to recent transformer based methods. the paper extensively covers additional important methods such as attention mechanisms, bidirectional encoders, pointer-generator networks, as well as optimization methods such as beam search, scheduled sampling and reinforcement learning. it also discusses the challenges of data preprocessing, loss functions, and evaluation metrics, as well as applications in machine translation, summarization, speech recognition, and conversational ai. this paper provides a comprehensive report on the design and future directions of seq2seq models emphasizing on theoretical foundations as well as real world applications.",
8082c02609db848d21b776280c6dab4e43a41fa5,The Use of ChatGPT in Education: A New Path to Personalized Instruction,"ChatGPT an artificial intelligence (AI) program based on natural language processing and deep learning algorithm training, has the capacity to learn human languages and understand their semantics through colossal amounts of text data and to conduct natural language-based communication with humans (Jiao, 2023). It has garnered tremendous attention of the internet users since its release in 2022. It has also instigated a lot of discussions on its application in education among educational researchers and teachers. According to Aljanabi (2023), ChatGPT’s potent information search and organization capabilities enable the student to seek out a more complete answer for the question and to obtain learning resources needed using natural language. Chu (2023) argued that ChatGPT could act as an AI teaching assistant to aid teachers in developing course plans and generating questions of varying difficulty levels as well as an intelligent academic supporter to help students with their academic papers and assessments. Research also shows that ChatGPT has significant value in the area of personalized learning.",2024,"[{'authorId': '2333169834', 'name': 'Yuhua Luo'}]","{'url': 'https://doi.org/10.15354/sief.24.co360', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.15354/sief.24.co360?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.15354/sief.24.co360, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","chatgpt an artificial intelligence (ai) program based on natural language processing and deep learning algorithm training, has the capacity to learn human languages and understand their semantics through colossal amounts of text data and to conduct natural language-based communication with humans (jiao, 2023). it has garnered tremendous attention of the internet users since its release in 2022. it has also instigated a lot of discussions on its application in education among educational researchers and teachers. according to aljanabi (2023), chatgpt’s potent information search and organization capabilities enable the student to seek out a more complete answer for the question and to obtain learning resources needed using natural language. chu (2023) argued that chatgpt could act as an ai teaching assistant to aid teachers in developing course plans and generating questions of varying difficulty levels as well as an intelligent academic supporter to help students with their academic papers and assessments. research also shows that chatgpt has significant value in the area of personalized learning.",https://doi.org/10.15354/sief.24.co360
8c4048bb839bfe04aa593df232579ba6b59c7a61,Generación de Vínculos Relacionados a Textos Transcritos para Videos de YouTube,"The way people learn has undergone a significant transformation thanks to the advancement of technology. Various digital tools complement daily and academic activities, facilitating access to updated and diverse information. The Internet, in particular, has positioned itself as the primary source of information, offering a large amount of textual and audiovisual content, with short content in the form of videos being the most popular. However, the learning process inevitably involves acquiring new concepts and terms. When encountering unfamiliar vocabulary in videos, people often search for additional information to understand the content better. Therefore, this research seeks to develop a tool capable of analyzing video transcripts using Natural Language Processing techniques to identify key terms and relate them to other relevant information sources, thus facilitating learning. When evaluating the relevance of terms to the textual content of videos on various topics using an Artificial Intelligence model, a relevance greater than 75% was evidenced for all terms. This confirms the efficacy of this approach for analyzing and understanding the textual content of transcribed videos.",2024,"[{'authorId': '2326359438', 'name': 'Pablo Martínez León'}, {'authorId': '2066608314', 'name': 'Marcos Orellana'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.37815/rte.v36ne1.1206?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.37815/rte.v36ne1.1206, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the way people learn has undergone a significant transformation thanks to the advancement of technology. various digital tools complement daily and academic activities, facilitating access to updated and diverse information. the internet, in particular, has positioned itself as the primary source of information, offering a large amount of textual and audiovisual content, with short content in the form of videos being the most popular. however, the learning process inevitably involves acquiring new concepts and terms. when encountering unfamiliar vocabulary in videos, people often search for additional information to understand the content better. therefore, this research seeks to develop a tool capable of analyzing video transcripts using natural language processing techniques to identify key terms and relate them to other relevant information sources, thus facilitating learning. when evaluating the relevance of terms to the textual content of videos on various topics using an artificial intelligence model, a relevance greater than 75% was evidenced for all terms. this confirms the efficacy of this approach for analyzing and understanding the textual content of transcribed videos.",
a08ec2c8218ff7bc3953544ca648ad7c0033be62,Sentiment Analysis: A comparative Analysis of Machine learning models,"Sentiment analysis (SA) is the process of Finding or adding a meaning to a text using natural language processing, a deep examination of data that is maintained online at various platforms such as movie reviews, product reviews at different online shopping apps, twitter (now X), etc., to recognize and classify the opinions and ideas that are expressed in a certain passage of text. The process's aim is to search for the author's perspective on a certain topic, film, item, etc. The outcome can be neutral, bad, or good. There have been studies that demonstrated various methods in the SA methodology for gathering and analysing feelings related to the selected subjects’ polarity—positive, negative, or neutral. Social media SA is a reliable source of data and information. SA becomes significant in a variety of business, social, and academic fields. The evaluation and sentiment analysis process, however, is looked upon with difficulties. Finding the proper side of polarity and accurately interpreting sentiments that are hindered by these difficulties. Sentiment analysis is a part of natural language processing and used text mining to find and evaluate the bias from the text.",2024,"[{'authorId': '2339480699', 'name': 'Aryan Panwar'}, {'authorId': '2355641663', 'name': 'Ishitva Singh'}, {'authorId': '2355638935', 'name': 'Abhishek Kumar'}, {'authorId': '2355636056', 'name': 'Jaspreet Kaur'}, {'authorId': '7293588', 'name': 'S. Yadav'}, {'authorId': '2341736091', 'name': 'Aditya Verma'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/IHCSP63227.2024.10959760?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IHCSP63227.2024.10959760, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","sentiment analysis (sa) is the process of finding or adding a meaning to a text using natural language processing, a deep examination of data that is maintained online at various platforms such as movie reviews, product reviews at different online shopping apps, twitter (now x), etc., to recognize and classify the opinions and ideas that are expressed in a certain passage of text. the process's aim is to search for the author's perspective on a certain topic, film, item, etc. the outcome can be neutral, bad, or good. there have been studies that demonstrated various methods in the sa methodology for gathering and analysing feelings related to the selected subjects’ polarity—positive, negative, or neutral. social media sa is a reliable source of data and information. sa becomes significant in a variety of business, social, and academic fields. the evaluation and sentiment analysis process, however, is looked upon with difficulties. finding the proper side of polarity and accurately interpreting sentiments that are hindered by these difficulties. sentiment analysis is a part of natural language processing and used text mining to find and evaluate the bias from the text.",
d0fcada546b8d6cc0fb4587a8ed837e27b78620d,The ProjectValt: A Repository for the Student’s Projects Reports,"Academic institutions amass a wealth of knowledge through student projects, yet this valuable resource often remains
untapped. ProjectValt addresses this by creating a centralized platform that empowers users to efficiently discover, understand,
and leverage past student work.
At the core of ProjectValt lies an intelligent summarization tool. Utilizing advanced natural language processing, this tool
automatically generates concise summaries of project reports, enabling users to quickly grasp key findings and insights.
Furthermore, ProjectValt incorporates sophisticated search capabilities, including keyword matching and semantic similarity
analysis. This allows users to effectively search for projects based on specific criteria, fostering a culture of knowledge sharing
and reuse within the academic community.
By providing a user-friendly interface and powerful tools, ProjectValt unlocks the potential of past student projects. This
platform not only preserves valuable research but also inspires future innovation by enabling students, faculty, and researchers
to build upon the work of their predecessors",2024,"[{'authorId': '2336968357', 'name': 'Abhishek Pandey'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.22214/ijraset.2024.65935?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.22214/ijraset.2024.65935, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","academic institutions amass a wealth of knowledge through student projects, yet this valuable resource often remains untapped. projectvalt addresses this by creating a centralized platform that empowers users to efficiently discover, understand, and leverage past student work. at the core of projectvalt lies an intelligent summarization tool. utilizing advanced natural language processing, this tool automatically generates concise summaries of project reports, enabling users to quickly grasp key findings and insights. furthermore, projectvalt incorporates sophisticated search capabilities, including keyword matching and semantic similarity analysis. this allows users to effectively search for projects based on specific criteria, fostering a culture of knowledge sharing and reuse within the academic community. by providing a user-friendly interface and powerful tools, projectvalt unlocks the potential of past student projects. this platform not only preserves valuable research but also inspires future innovation by enabling students, faculty, and researchers to build upon the work of their predecessors",
9d98a4f99c07591c97e32c3980af57b245ebbaac,Bayes Theorem in Machine Learning: A Literature Review,"In the era of big data and articial intelligence, machine learning has become a crucial tool for extracting insights and making predictions across various domains. Bayes theorem, a fundamental principle in probability theory, has emerged as a cornerstone in many machine learning algorithms. This literature review explores the main applications of Bayes theorem in machine learning, focusing on its role in classication, Natural Language Processing (NLP), and other emerging elds. The study aims to provide an overview of how Bayesian principles enhance learning algorithms, improve decision-making processes, and address complex problems in articial intelligence. Through a systematic review of academic papers from Google Scholar, this research synthesizes current knowledge on Bayesian methods in machine learning. The methodology involves dening the research scope, conducting a literature search using specic keywords, screening relevant studies, and analyzing the collected data. By examining diverse applications ranging from disease prediction to sentiment analysis, this review highlights the versatility and signicance of Bayes theorem in advancing machine learning techniques and their real-world implementations.",2025,"[{'authorId': '2340428411', 'name': 'Bowen Qu'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.54254/2753-8818/2025.20329?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.54254/2753-8818/2025.20329, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the era of big data and articial intelligence, machine learning has become a crucial tool for extracting insights and making predictions across various domains. bayes theorem, a fundamental principle in probability theory, has emerged as a cornerstone in many machine learning algorithms. this literature review explores the main applications of bayes theorem in machine learning, focusing on its role in classication, natural language processing (nlp), and other emerging elds. the study aims to provide an overview of how bayesian principles enhance learning algorithms, improve decision-making processes, and address complex problems in articial intelligence. through a systematic review of academic papers from google scholar, this research synthesizes current knowledge on bayesian methods in machine learning. the methodology involves dening the research scope, conducting a literature search using specic keywords, screening relevant studies, and analyzing the collected data. by examining diverse applications ranging from disease prediction to sentiment analysis, this review highlights the versatility and signicance of bayes theorem in advancing machine learning techniques and their real-world implementations.",
85faa1bafeb0bb51792eeb593117c11ee857ab2b,Beyond ChatGPT: How DeepSeek R1 may transform academia and libraries?,"Purpose
This paper aims to examine the evolution of DeepSeek R1 as an advanced alternative to ChatGPT in academic and library contexts. It highlights DeepSeek R1’s potential to enhance research methodologies, optimize search and metadata processing and refine content development. Additionally, it explores the ethical implications of integrating next-generation AI models in academia, focusing on bias, privacy and academic integrity.

Design/methodology/approach
The study employs a comparative analysis of DeepSeek R1 and ChatGPT, evaluating their capabilities in academic applications through structured interviews and technical assessments. Key areas analyzed include natural language processing, reasoning capabilities and code generation. The research also incorporates an ethical framework to assess the implications of AI-driven academic support tools.

Findings
DeepSeek R1 outperforms ChatGPT in several academic domains, particularly in reasoning, computational efficiency and metadata organization. Its open-source architecture allows for greater customization, making it more adaptable for academic institutions. However, the study also identifies limitations, such as content filtering restrictions and ethical concerns related to AI dependence and data privacy. The findings suggest that DeepSeek R1 can serve as a powerful complement to existing AI tools in academia.

Research limitations/implications
Given the rapid development of AI models, this study’s findings may require future validation as newer versions of DeepSeek R1 and ChatGPT emerge. Further research is recommended to explore long-term AI adoption in academic settings and assess evolving ethical concerns.

Practical implications
This research provides valuable insights for academic institutions and libraries on integrating AI-driven tools. It offers practical recommendations for leveraging DeepSeek R1 to enhance academic workflows, while ensuring ethical AI use through transparency, bias mitigation and privacy safeguards.

Originality/value
This paper contributes to the discourse on AI in academia by providing an in-depth comparative analysis of DeepSeek R1 and ChatGPT. It offers a structured evaluation of AI’s evolving role in academic research and library services, emphasizing ethical considerations and best practices for AI adoption in educational institutions.
",2025,"[{'authorId': '2284874922', 'name': 'Ravi Varma Kumar Bevara'}, {'authorId': '2212887866', 'name': 'Nishith Reddy Mannuru'}, {'authorId': '2306162340', 'name': 'Brady Lund'}, {'authorId': '2297887259', 'name': 'Sai Pranathi Karedla'}, {'authorId': '2277742033', 'name': 'Aashrith Mannuru'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/lhtn-01-2025-0024?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/lhtn-01-2025-0024, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose this paper aims to examine the evolution of deepseek r1 as an advanced alternative to chatgpt in academic and library contexts. it highlights deepseek r1’s potential to enhance research methodologies, optimize search and metadata processing and refine content development. additionally, it explores the ethical implications of integrating next-generation ai models in academia, focusing on bias, privacy and academic integrity. design/methodology/approach the study employs a comparative analysis of deepseek r1 and chatgpt, evaluating their capabilities in academic applications through structured interviews and technical assessments. key areas analyzed include natural language processing, reasoning capabilities and code generation. the research also incorporates an ethical framework to assess the implications of ai-driven academic support tools. findings deepseek r1 outperforms chatgpt in several academic domains, particularly in reasoning, computational efficiency and metadata organization. its open-source architecture allows for greater customization, making it more adaptable for academic institutions. however, the study also identifies limitations, such as content filtering restrictions and ethical concerns related to ai dependence and data privacy. the findings suggest that deepseek r1 can serve as a powerful complement to existing ai tools in academia. research limitations/implications given the rapid development of ai models, this study’s findings may require future validation as newer versions of deepseek r1 and chatgpt emerge. further research is recommended to explore long-term ai adoption in academic settings and assess evolving ethical concerns. practical implications this research provides valuable insights for academic institutions and libraries on integrating ai-driven tools. it offers practical recommendations for leveraging deepseek r1 to enhance academic workflows, while ensuring ethical ai use through transparency, bias mitigation and privacy safeguards. originality/value this paper contributes to the discourse on ai in academia by providing an in-depth comparative analysis of deepseek r1 and chatgpt. it offers a structured evaluation of ai’s evolving role in academic research and library services, emphasizing ethical considerations and best practices for ai adoption in educational institutions.",
c94fb1509c8ee8abe01a1fd5066177fb6fba1997,"Perancangan Sistem ADAN (Abstracting, Documenting, and Archiving Network)","Abstracting, Documenting, and Archiving Network (ADAN) system was developed to address the challenges of scientific information management in the digital era by integrating abstraction, documentation, and archiving functions in one integrated platform. This study aims to design an efficient and responsive system to academic needs by utilizing artificial intelligence (AI), natural language processing (NLP), and machine learning (ML) technologies. In-depth literature study and needs analysis through interviews, Focus Group Discussions (FGD), and surveys of 250 academic respondents identified priorities such as fast access, data preservation, and content recommendations. ADAN is designed with a modular 5-tier architecture, supporting interoperability with standards such as Dublin Core and OAI-PMH. Test results show that automatic metadata extraction achieves 93% accuracy, 89% content classification, and 0.8 seconds search response time for 10,000 documents. The system also offers an intuitive user interface with a System Usability Scale (SUS) score of 82.5, confirming its potential as an innovative solution in scientific information management.",2025,"[{'authorId': '2354142767', 'name': 'Muhammad Wali'}, {'authorId': '73802101', 'name': 'Taufiq Iqbal'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.58477/cj.v3i1.202?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.58477/cj.v3i1.202, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstracting, documenting, and archiving network (adan) system was developed to address the challenges of scientific information management in the digital era by integrating abstraction, documentation, and archiving functions in one integrated platform. this study aims to design an efficient and responsive system to academic needs by utilizing artificial intelligence (ai), natural language processing (nlp), and machine learning (ml) technologies. in-depth literature study and needs analysis through interviews, focus group discussions (fgd), and surveys of 250 academic respondents identified priorities such as fast access, data preservation, and content recommendations. adan is designed with a modular 5-tier architecture, supporting interoperability with standards such as dublin core and oai-pmh. test results show that automatic metadata extraction achieves 93% accuracy, 89% content classification, and 0.8 seconds search response time for 10,000 documents. the system also offers an intuitive user interface with a system usability scale (sus) score of 82.5, confirming its potential as an innovative solution in scientific information management.",
8e7ce2956fbd22e16e04c3d4d8d0c0f5907be70a,Keyword-Based Exploration of Library Resources,"
The project ""Keyword-Based Exploration of Library Resources"" addresses the challenges associated with

accessing and discovering academic resources efficiently. Traditional systems often suffer from limitations such as inadequate multilingual support, poor metadata utilization, and restricted filtering capabilities, which hinder users from locating relevant research materials effectively. This project proposes an innovative solution

leveraging Artificial Intelligence (AI) and Natural Language Processing (NLP) techniques to enhance search capabilities and inclusivity.

The system incorporates:

•  Multilingual Search: Enabling users to perform queries in various languages using translation APIs.

•  Advanced Filtering Options: Allowing searches to be refined by author, publication year, journal, and more.

•  AI-Powered Metadata Extraction: Utilizing Optical Character Recognition (OCR) and NLP to extract and catalogue metadata like keywords, authors, and publication years.

The proposed system is built on a Python backend using Flask for API integration and MyAWS CLOUD for secure data storage. By integrating robust search mechanisms and user-friendly design, the project contributes to Sustainable Development Goal 4 (Quality Education), fostering global accessibility to knowledge and academic research. The outcomes of this project are anticipated to significantly improve resource discoverability,

inclusivity, and precision, addressing the needs of diverse academic communities.

INDEX TERMS
Keyword Search, Library Resource Management, Information Retrieval, Digital Libraries, Metadata Extraction, Search Optimization, Natural Language Processing (NLP), Database Searching, Search Algorithms, Document Retrieval Systems, Academic Research Tools.",2025,"[{'authorId': '2342915270', 'name': 'Vaibhav Gupta'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.55041/ijsrem40835?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55041/ijsrem40835, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the project ""keyword-based exploration of library resources"" addresses the challenges associated with accessing and discovering academic resources efficiently. traditional systems often suffer from limitations such as inadequate multilingual support, poor metadata utilization, and restricted filtering capabilities, which hinder users from locating relevant research materials effectively. this project proposes an innovative solution leveraging artificial intelligence (ai) and natural language processing (nlp) techniques to enhance search capabilities and inclusivity. the system incorporates: • multilingual search: enabling users to perform queries in various languages using translation apis. • advanced filtering options: allowing searches to be refined by author, publication year, journal, and more. • ai-powered metadata extraction: utilizing optical character recognition (ocr) and nlp to extract and catalogue metadata like keywords, authors, and publication years. the proposed system is built on a python backend using flask for api integration and myaws cloud for secure data storage. by integrating robust search mechanisms and user-friendly design, the project contributes to sustainable development goal 4 (quality education), fostering global accessibility to knowledge and academic research. the outcomes of this project are anticipated to significantly improve resource discoverability, inclusivity, and precision, addressing the needs of diverse academic communities. index terms keyword search, library resource management, information retrieval, digital libraries, metadata extraction, search optimization, natural language processing (nlp), database searching, search algorithms, document retrieval systems, academic research tools.",
97d2c993e85dcbadfd24ba483c0e8ab7b42f521c,Authorship Weightage Algorithm for Academic publications: A new calculation and ACES webserver for determining expertise.,"Finding experts in any field can be difficult, especially when relying on academic publications given the use of jargons despite publication lists being publicly available. Within the use of publications, discernment of expertise by authorship positions is often absent in the many pub-lication-based expert search platforms available which could function as another discernment filter of expertise. Given that it is common in many academic fields for the research group lead or lab heads to take the position of the last author, the existing authorship scoring systems that assign a decreasing weightage from the first author would not reflect the last author correctly. To address these mentioned problems, we incorporated natural language processing (Common Crawl using fastText) to identify related keywords for a search compatible to using jargons as well as an au-thorship positional scoring with the option to provide greater weightage to the last author. The resulting output is a ranked scoring system of researchers upon every search which we imple-mented as a webserver for internal agency use called ‘APD lab Capability & Expertise Search (ACES)’ webserver which can be accessed from webserver.apdskeg.com/aces.",2021,"[{'authorId': '2004573534', 'name': 'Weiling Wu'}, {'authorId': '2117468570', 'name': 'Owen Tan'}, {'authorId': '66504888', 'name': 'Kwok-Fong Chan'}, {'authorId': '1573608926', 'name': 'N. Ong'}, {'authorId': '2049202946', 'name': 'David Gunasegaran'}, {'authorId': '3098206', 'name': 'S. Gan'}]","{'url': 'https://engrxiv.org/preprint/download/1704/3475', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.31224/osf.io/4vz8n?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.31224/osf.io/4vz8n, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","finding experts in any field can be difficult, especially when relying on academic publications given the use of jargons despite publication lists being publicly available. within the use of publications, discernment of expertise by authorship positions is often absent in the many pub-lication-based expert search platforms available which could function as another discernment filter of expertise. given that it is common in many academic fields for the research group lead or lab heads to take the position of the last author, the existing authorship scoring systems that assign a decreasing weightage from the first author would not reflect the last author correctly. to address these mentioned problems, we incorporated natural language processing (common crawl using fasttext) to identify related keywords for a search compatible to using jargons as well as an au-thorship positional scoring with the option to provide greater weightage to the last author. the resulting output is a ranked scoring system of researchers upon every search which we imple-mented as a webserver for internal agency use called ‘apd lab capability & expertise search (aces)’ webserver which can be accessed from webserver.apdskeg.com/aces.",https://engrxiv.org/preprint/download/1704/3475
9d664b1dbaeb8c0e3850e8cac783e462e486c920,Authorship Weightage Algorithm for Academic Publications: A New Calculation and ACES Webserver for Determining Expertise,"Despite the public availability, finding experts in any field when relying on academic publications can be challenging, especially with the use of jargons. Even after overcoming these issues, the discernment of expertise by authorship positions is often also absent in the many publication-based search platforms. Given that it is common in many academic fields for the research group lead or lab head to take the position of the last author, some of the existing authorship scoring systems that assign a decreasing weightage from the first author would not reflect the last author correctly. To address these problems, we incorporated natural language processing (Common Crawl using fastText) to retrieve related keywords when using jargons as well as a modified authorship positional scoring that allows the assignment of greater weightage to the last author. The resulting output is a ranked scoring system of researchers upon every search that we implemented as a webserver for internal use called the APD lab Capability & Expertise Search (ACES).",2021,"[{'authorId': '2004573534', 'name': 'Weiling Wu'}, {'authorId': '2117468570', 'name': 'Owen Tan'}, {'authorId': '66504888', 'name': 'Kwok-Fong Chan'}, {'authorId': '1573608926', 'name': 'N. Ong'}, {'authorId': '2049202946', 'name': 'David Gunasegaran'}, {'authorId': '3098206', 'name': 'S. Gan'}]","{'url': 'https://www.mdpi.com/2409-9279/4/2/41/pdf?version=1623219854', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8293319, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","despite the public availability, finding experts in any field when relying on academic publications can be challenging, especially with the use of jargons. even after overcoming these issues, the discernment of expertise by authorship positions is often also absent in the many publication-based search platforms. given that it is common in many academic fields for the research group lead or lab head to take the position of the last author, some of the existing authorship scoring systems that assign a decreasing weightage from the first author would not reflect the last author correctly. to address these problems, we incorporated natural language processing (common crawl using fasttext) to retrieve related keywords when using jargons as well as a modified authorship positional scoring that allows the assignment of greater weightage to the last author. the resulting output is a ranked scoring system of researchers upon every search that we implemented as a webserver for internal use called the apd lab capability & expertise search (aces).",https://www.mdpi.com/2409-9279/4/2/41/pdf?version=1623219854
842104ef0575823498f26cdd57b4b4dba655df9e,"ZeroPrompt: Scaling Prompt-Based Pretraining to 1, 000 Tasks Improves Zero-Shot Generalization","We propose a multitask pretraining approach ZeroPrompt for zero-shot generalization, focusing on task scaling and zero-shot prompting. While previous models are trained on only a few dozen tasks, we scale to 1,000 tasks for the first time using real-world data. This leads to a crucial discovery that task scaling can be an efficient alternative to model scaling; i.e., the model size has little impact on performance with an extremely large number of tasks. Our results show that task scaling can substantially improve training efficiency by 30 times in FLOPs. Moreover, we present a prompting method that incorporates a genetic algorithm to automatically search for the best prompt for unseen tasks, along with a few other improvements. Empirically, ZeroPrompt substantially improves both the efficiency and the performance of zero-shot learning across a variety of academic and production datasets.",2022,"[{'authorId': '2156103139', 'name': 'Hanwei Xu'}, {'authorId': '144400514', 'name': 'Yujun Chen'}, {'authorId': '15394369', 'name': 'Yulun Du'}, {'authorId': '145175617', 'name': 'Nan Shao'}, {'authorId': None, 'name': 'Yanggang Wang'}, {'authorId': '2155674310', 'name': 'Haiyu Li'}, {'authorId': '2109512754', 'name': 'Zhilin Yang'}]","{'url': 'https://aclanthology.org/2022.findings-emnlp.312.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2201.06910, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we propose a multitask pretraining approach zeroprompt for zero-shot generalization, focusing on task scaling and zero-shot prompting. while previous models are trained on only a few dozen tasks, we scale to 1,000 tasks for the first time using real-world data. this leads to a crucial discovery that task scaling can be an efficient alternative to model scaling; i.e., the model size has little impact on performance with an extremely large number of tasks. our results show that task scaling can substantially improve training efficiency by 30 times in flops. moreover, we present a prompting method that incorporates a genetic algorithm to automatically search for the best prompt for unseen tasks, along with a few other improvements. empirically, zeroprompt substantially improves both the efficiency and the performance of zero-shot learning across a variety of academic and production datasets.",https://aclanthology.org/2022.findings-emnlp.312.pdf
90614889fe7dcd3c56849e94a7dbf455d11c1834,An Explanatory Query-Based Framework for Exploring Academic Expertise,"The success of research institutions heavily relies upon identifying the right researchers""for the job"": researchers may need to identify appropriate collaborators, often from across disciplines; students may need to identify suitable supervisors for projects of their interest; administrators may need to match funding opportunities with relevant researchers, and so on. Usually, finding potential collaborators in institutions is a time-consuming manual search task prone to bias. In this paper, we propose a novel query-based framework for searching, scoring, and exploring research expertise automatically, based upon processing abstracts of academic publications. Given user queries in natural language, our framework finds researchers with relevant expertise, making use of domain-specific knowledge bases and word embeddings. It also generates explanations for its recommendations. We evaluate our framework with an institutional repository of papers from a leading university, using, as baselines, artificial neural networks and transformer-based models for a multilabel classification task to identify authors of publication abstracts. We also assess the cross-domain effectiveness of our framework with a (separate) research funding repository for the same institution. We show that our simple method is effective in identifying matches, while satisfying desirable properties and being efficient.",2021,"[{'authorId': '3458679', 'name': 'O. Cocarascu'}, {'authorId': '2064036342', 'name': 'A. McLean'}, {'authorId': '2093578348', 'name': 'Paul French'}, {'authorId': '49973505', 'name': 'Francesca Toni'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2105.13728, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the success of research institutions heavily relies upon identifying the right researchers""for the job"": researchers may need to identify appropriate collaborators, often from across disciplines; students may need to identify suitable supervisors for projects of their interest; administrators may need to match funding opportunities with relevant researchers, and so on. usually, finding potential collaborators in institutions is a time-consuming manual search task prone to bias. in this paper, we propose a novel query-based framework for searching, scoring, and exploring research expertise automatically, based upon processing abstracts of academic publications. given user queries in natural language, our framework finds researchers with relevant expertise, making use of domain-specific knowledge bases and word embeddings. it also generates explanations for its recommendations. we evaluate our framework with an institutional repository of papers from a leading university, using, as baselines, artificial neural networks and transformer-based models for a multilabel classification task to identify authors of publication abstracts. we also assess the cross-domain effectiveness of our framework with a (separate) research funding repository for the same institution. we show that our simple method is effective in identifying matches, while satisfying desirable properties and being efficient.",
9d4237e2f0646ae6a3e4209fdbb2f8b6e0ec0639,Artificial Intelligence for the Otolaryngologist: A State of the Art Review,"Objective To provide a state of the art review of artificial intelligence (AI), including its subfields of machine learning and natural language processing, as it applies to otolaryngology and to discuss current applications, future impact, and limitations of these technologies. Data Sources PubMed and Medline search engines. Review Methods A structured search of the current literature was performed (up to and including September 2018). Search terms related to topics of AI in otolaryngology were identified and queried to identify relevant articles. Conclusions AI is at the forefront of conversation in academic research and popular culture. In recent years, it has been touted for its potential to revolutionize health care delivery. Yet, to date, it has made few contributions to actual medical practice or patient care. Future adoption of AI technologies in otolaryngology practice may be hindered by misconceptions of what AI is and a fear that machine errors may compromise patient care. However, with potential clinical and economic benefits, it is vital for otolaryngologists to understand the principles and scope of AI. Implications for Practice In the coming years, AI is likely to have a major impact on biomedical research and the practice of medicine. Otolaryngologists are key stakeholders in the development and clinical integration of meaningful AI technologies that will improve patient care. High-quality data collection is essential for the development of AI technologies, and otolaryngologists should seek opportunities to collaborate with data scientists to guide them toward the most impactful clinical questions.",2019,"[{'authorId': '46962930', 'name': 'A. Bur'}, {'authorId': '6442409', 'name': 'M. Shew'}, {'authorId': '47154567', 'name': 'J. New'}]","{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/0194599819827507', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/0194599819827507?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/0194599819827507, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objective to provide a state of the art review of artificial intelligence (ai), including its subfields of machine learning and natural language processing, as it applies to otolaryngology and to discuss current applications, future impact, and limitations of these technologies. data sources pubmed and medline search engines. review methods a structured search of the current literature was performed (up to and including september 2018). search terms related to topics of ai in otolaryngology were identified and queried to identify relevant articles. conclusions ai is at the forefront of conversation in academic research and popular culture. in recent years, it has been touted for its potential to revolutionize health care delivery. yet, to date, it has made few contributions to actual medical practice or patient care. future adoption of ai technologies in otolaryngology practice may be hindered by misconceptions of what ai is and a fear that machine errors may compromise patient care. however, with potential clinical and economic benefits, it is vital for otolaryngologists to understand the principles and scope of ai. implications for practice in the coming years, ai is likely to have a major impact on biomedical research and the practice of medicine. otolaryngologists are key stakeholders in the development and clinical integration of meaningful ai technologies that will improve patient care. high-quality data collection is essential for the development of ai technologies, and otolaryngologists should seek opportunities to collaborate with data scientists to guide them toward the most impactful clinical questions.",https://journals.sagepub.com/doi/pdf/10.1177/0194599819827507
22aa29fa637ef0df2aa19282b31ea15c2b92b563,Retrieval of whole human genome clinical variant information through search motors,"The interpretation of variation in the human genome constitutes one of the most pressing challenges in biomedicine. There are many academic and proprietary resources that provide annotation, interpretation, scoring and knowledge of genetic variants under multiple access modalities. For these resources, information is available through portals, wikis, APIs, curated content and databases, and pipelines. Here we explore the use of search motors to provide facilitated access to the main sources of information that are used by clinical geneticists and researchers. We also support the browsing experience with natural language processing and automated summaries of available information. The resulting tool, ai-OMNI.com, is intrinsically flexible, expandable and intuitive, thus providing a different experience for querying the human genome for the consequences of variation.",2019,"[{'authorId': '2114014280', 'name': 'Li Yin'}, {'authorId': '134152380', 'name': 'J. di Iulio'}, {'authorId': '48253417', 'name': 'S. Lelong'}, {'authorId': '39929911', 'name': 'Chunlei Wu'}, {'authorId': '2969256', 'name': 'A. Telenti'}]","{'url': 'https://www.biorxiv.org/content/biorxiv/early/2019/04/05/600098.full.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1101/600098?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1101/600098, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the interpretation of variation in the human genome constitutes one of the most pressing challenges in biomedicine. there are many academic and proprietary resources that provide annotation, interpretation, scoring and knowledge of genetic variants under multiple access modalities. for these resources, information is available through portals, wikis, apis, curated content and databases, and pipelines. here we explore the use of search motors to provide facilitated access to the main sources of information that are used by clinical geneticists and researchers. we also support the browsing experience with natural language processing and automated summaries of available information. the resulting tool, ai-omni.com, is intrinsically flexible, expandable and intuitive, thus providing a different experience for querying the human genome for the consequences of variation.",https://www.biorxiv.org/content/biorxiv/early/2019/04/05/600098.full.pdf
ec6fa268bb5078fdec6420153a1c5d850eddd58c,Machine Learning Methods for Systematic Reviews:,"Objective At the forefront of machine learning research since its inception has been natural language processing, also known as text mining, referring to a wide range of statistical processes for analyzing textual data and retrieving information. In medical fields, text mining has made valuable contributions in unexpected ways, not least by synthesizing data from disparate biomedical studies. This rapid scoping review examines how machine learning methods for text mining can be implemented at the intersection of these disparate fields to improve the workflow and process of conducting systematic reviews in medical research and related academic disciplines. Methods The primary research question that this investigation asked, “what impact does the use of machine learning have on the methods used by systematic review teams to carry out the systematic review process, such as the precision of search strategies, unbiased article selection or data abstraction and/or analysis for systematic reviews and other comprehensive review types of similar methodology?” A literature search was conducted by a medical librarian utilizing multiple databases, a grey literature search and handsearching of the literature. The search was completed on December 4, 2020. Handsearching was done on an ongoing basis with an end date of April 14, 2023. Results The search yielded 23,190 studies after duplicates were removed. As a result, 117 studies (1.70%) met eligibility criteria for inclusion in this rapid scoping review. Conclusions There are several techniques and/or types of machine learning methods in development or that have already been fully developed to assist with the systematic review stages. Combined with human intelligence, these machine learning methods and tools provide promise for making the systematic review process more efficient, saving valuable time for systematic review authors, and increasing the speed in which evidence can be created and placed in the hands of decision makers and the public.",2023,"[{'authorId': '2277585483', 'name': 'Stephanie C. Roth'}, {'authorId': '1403978284', 'name': 'Alex Wermer-Colan'}]","{'url': '', 'status': None, 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10759980, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objective at the forefront of machine learning research since its inception has been natural language processing, also known as text mining, referring to a wide range of statistical processes for analyzing textual data and retrieving information. in medical fields, text mining has made valuable contributions in unexpected ways, not least by synthesizing data from disparate biomedical studies. this rapid scoping review examines how machine learning methods for text mining can be implemented at the intersection of these disparate fields to improve the workflow and process of conducting systematic reviews in medical research and related academic disciplines. methods the primary research question that this investigation asked, “what impact does the use of machine learning have on the methods used by systematic review teams to carry out the systematic review process, such as the precision of search strategies, unbiased article selection or data abstraction and/or analysis for systematic reviews and other comprehensive review types of similar methodology?” a literature search was conducted by a medical librarian utilizing multiple databases, a grey literature search and handsearching of the literature. the search was completed on december 4, 2020. handsearching was done on an ongoing basis with an end date of april 14, 2023. results the search yielded 23,190 studies after duplicates were removed. as a result, 117 studies (1.70%) met eligibility criteria for inclusion in this rapid scoping review. conclusions there are several techniques and/or types of machine learning methods in development or that have already been fully developed to assist with the systematic review stages. combined with human intelligence, these machine learning methods and tools provide promise for making the systematic review process more efficient, saving valuable time for systematic review authors, and increasing the speed in which evidence can be created and placed in the hands of decision makers and the public.",
6d9452a76ad406781430f9f11c594274b21ca48b,Yara Parser: A Fast and Accurate Dependency Parser,"Dependency parsers are among the most crucial tools in natural language processing as they have many important applications in downstream tasks such as information retrieval, machine translation and knowledge acquisition. We introduce the Yara Parser, a fast and accurate open-source dependency parser based on the arc-eager algorithm and beam search. It achieves an unlabeled accuracy of 93.32 on the standard WSJ test set which ranks it among the top dependency parsers. At its fastest, Yara can parse about 4000 sentences per second when in greedy mode (1 beam). When optimizing for accuracy (using 64 beams and Brown cluster features), Yara can parse 45 sentences per second. The parser can be trained on any syntactic dependency treebank and dierent options are provided in order to make it more flexible and tunable for specific tasks. It is released with the Apache version 2.0 license and can be used for both commercial and academic purposes. The parser can be found at https: //github.com/yahoo/YaraParser.",2015,"[{'authorId': '2653340', 'name': 'Mohammad Sadegh Rasooli'}, {'authorId': '1739099', 'name': 'Joel R. Tetreault'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1503.06733, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","dependency parsers are among the most crucial tools in natural language processing as they have many important applications in downstream tasks such as information retrieval, machine translation and knowledge acquisition. we introduce the yara parser, a fast and accurate open-source dependency parser based on the arc-eager algorithm and beam search. it achieves an unlabeled accuracy of 93.32 on the standard wsj test set which ranks it among the top dependency parsers. at its fastest, yara can parse about 4000 sentences per second when in greedy mode (1 beam). when optimizing for accuracy (using 64 beams and brown cluster features), yara can parse 45 sentences per second. the parser can be trained on any syntactic dependency treebank and dierent options are provided in order to make it more flexible and tunable for specific tasks. it is released with the apache version 2.0 license and can be used for both commercial and academic purposes. the parser can be found at https: //github.com/yahoo/yaraparser.",
b2152cc13444c692948e15277da2fd2b559d8bee,POS1179 USING ARTIFICIAL INTELLIGENCE TO IDENTIFY ANTI-NEUTROPHIL CYTOPLASMATIC ANTIBODY (ANCA)-ASSOCIATED VASCULITIS PATIENTS IN ELECTRONIC HEALTH RECORDS,"Anti-neutrophil cytoplasmatic antibody (ANCA) associated vasculitis (AAV) is a rare, life-threatening, systemic auto-immune disease.[1]Due to the low prevalence, multiple treating disciplines and poor registration, including ICD-10 classification, identifying AAV patients for (pre-)clinical studies, research and health care evaluation is challenging.[2, 3]Therefore, there is an urgent need to improve identifying these patients in health care organisations. Employing artificial intelligence (AI) – supported search engines are increasingly suggested to achieve this.Reliably identify AAV patients in electronic health records (EHR) using an AI-based tool that incorporates text mining and Natural Language Processing (NLP).The identification method consists of a search strategy combined with NLP-based exclusion. A search strategy to optimally identify AAV patients within a single center EHR system of an academic hospital was developed using an established AAV cohort (n=203) as a gold-standard reference set. Patient records, identified by the search strategy outside of the reference set, underwent manual review to confirm newly-identified AAV patients. Then, improvement in performance by adding NLP to the text-mining search strategy was investigated. Validation was performed on an independent EHR system of a non-academic hospital with an established AAV cohort available for reference (n=84).The search strategy combined five queries based on disease description, laboratory measurements, medication and relevant specialisms. In the determination EHR, the search strategy identified 608 patients, including 197/203 (97.0%) AAV patients of the reference set and 149 newly-identified AAV cases confirmed by manual review. Employing NLP in the identification method improved the positive predictive value (PPV) from 57% (346/608 patients) to 78% (339/444 patients). These results were validated in an independent EHR system where the search strategy identified 333 patient, including 82/84 (97.6%) AAV patients of the reference set and 112 newly-identified AAV cases upon manual review. NLP improved PPV from 59% (194/333 patients) to 86% (192/223 patients). Negative predictive values and specificities were above 98% in all analyses.We present an AI based identification method to identify low-prevalent AAV patients in EHR systems. We demonstrated improved performance when adding NLP to the text-mining search strategy. Successful validation in an independent health organisation supports the applicability and transportability of this method which can be an important accelerator for research efforts and health care evaluation in AAV patients.[1]Kitching AR, Anders HJ, Basu N, Brouwer E, Gordon J, Jayne DR, et al. ANCA-associated vasculitis. Nat Rev Dis Primers. 2020;6(1):71.[2]Quan H, Li B, Saunders LD, Parsons GA, Nilsson CI, Alibhai A, et al. Assessing validity of ICD-9-CM and ICD-10 administrative data in recording clinical conditions in a unique dually coded database. Health Serv Res. 2008;43(4):1424-41.[3]Spierings J BT, Dirikgil E, Moens HB. Overdaad aan ICD-coderingen hindert onderzoek. Medisch Contact. 2020;22:18-20.NIL.Jolijn van Leeuwen: None declared, Erik Penne: None declared, Y.K. Onno Teng Consultant of: YKOT received an unrestricted research grant and consultancy fees from Vifor Pharma., Grant/research support from: The work of YKOT was supported by the Dutch Kidney Foundation (17OKG04) and by the Arthritis Research and Collaboration Hub Foundation. Arthritis Research and Collaboration Hub is funded by Dutch Arthritis Foundation (ReumaNederland).",2023,"[{'authorId': '2144752233', 'name': 'J. V. van Leeuwen'}, {'authorId': '77660397', 'name': 'E. Penne'}, {'authorId': '47516217', 'name': 'Y. Teng'}]","{'url': 'https://ard.bmj.com/content/annrheumdis/82/Suppl_1/922.2.full.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1136/annrheumdis-2023-eular.2632?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1136/annrheumdis-2023-eular.2632, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","anti-neutrophil cytoplasmatic antibody (anca) associated vasculitis (aav) is a rare, life-threatening, systemic auto-immune disease.[1]due to the low prevalence, multiple treating disciplines and poor registration, including icd-10 classification, identifying aav patients for (pre-)clinical studies, research and health care evaluation is challenging.[2, 3]therefore, there is an urgent need to improve identifying these patients in health care organisations. employing artificial intelligence (ai) – supported search engines are increasingly suggested to achieve this.reliably identify aav patients in electronic health records (ehr) using an ai-based tool that incorporates text mining and natural language processing (nlp).the identification method consists of a search strategy combined with nlp-based exclusion. a search strategy to optimally identify aav patients within a single center ehr system of an academic hospital was developed using an established aav cohort (n=203) as a gold-standard reference set. patient records, identified by the search strategy outside of the reference set, underwent manual review to confirm newly-identified aav patients. then, improvement in performance by adding nlp to the text-mining search strategy was investigated. validation was performed on an independent ehr system of a non-academic hospital with an established aav cohort available for reference (n=84).the search strategy combined five queries based on disease description, laboratory measurements, medication and relevant specialisms. in the determination ehr, the search strategy identified 608 patients, including 197/203 (97.0%) aav patients of the reference set and 149 newly-identified aav cases confirmed by manual review. employing nlp in the identification method improved the positive predictive value (ppv) from 57% (346/608 patients) to 78% (339/444 patients). these results were validated in an independent ehr system where the search strategy identified 333 patient, including 82/84 (97.6%) aav patients of the reference set and 112 newly-identified aav cases upon manual review. nlp improved ppv from 59% (194/333 patients) to 86% (192/223 patients). negative predictive values and specificities were above 98% in all analyses.we present an ai based identification method to identify low-prevalent aav patients in ehr systems. we demonstrated improved performance when adding nlp to the text-mining search strategy. successful validation in an independent health organisation supports the applicability and transportability of this method which can be an important accelerator for research efforts and health care evaluation in aav patients.[1]kitching ar, anders hj, basu n, brouwer e, gordon j, jayne dr, et al. anca-associated vasculitis. nat rev dis primers. 2020;6(1):71.[2]quan h, li b, saunders ld, parsons ga, nilsson ci, alibhai a, et al. assessing validity of icd-9-cm and icd-10 administrative data in recording clinical conditions in a unique dually coded database. health serv res. 2008;43(4):1424-41.[3]spierings j bt, dirikgil e, moens hb. overdaad aan icd-coderingen hindert onderzoek. medisch contact. 2020;22:18-20.nil.jolijn van leeuwen: none declared, erik penne: none declared, y.k. onno teng consultant of: ykot received an unrestricted research grant and consultancy fees from vifor pharma., grant/research support from: the work of ykot was supported by the dutch kidney foundation (17okg04) and by the arthritis research and collaboration hub foundation. arthritis research and collaboration hub is funded by dutch arthritis foundation (reumanederland).",https://ard.bmj.com/content/annrheumdis/82/Suppl_1/922.2.full.pdf
11a37999f061b2f95d763a491fd685c25dd3793d,Keyword Extraction from Scientific Publications Using Local Features and Embedding Model,"In the field of natural language processing (NLP), keywords are crucial for enhancing information retrieval (IR) and content summarization, as well as for optimizing search engines and organizing documents. As the volume of generated information increases, identifying keywords manually from large documents becomes more challenging and no longer feasible. Therefore, automatic keyword extraction is necessary as a cost-effective method to handle large documents and to provide scalable solutions for various applications in NLP and information management. In the academic domain, automatic keyword extraction simplifies the process of finding and categorizing scientific publications, enabling paper repositories to optimize their IR and document organizing systems. However, many methods of keyword extraction use either global semantic features based on pre-trained embedding models or local statistical features separately, which yields low results. Since a good keyword must be identified by both external knowledge and local statistical features, this paper proposes a method to improve the performance of keyword extraction from scientific publications by combining local statistical features with embedding models. The proposed method outperforms the baseline methods with an F-score of 0.70 on the SemEval2017 dataset using the SciBERT model and SVM classifier. This research confirms that both local statistical information and contextualized semantic information are important to identify keywords.",2023,"[{'authorId': '2280944811', 'name': 'Girvan S.K. Kurniawan'}, {'authorId': '8769141', 'name': 'K. Lhaksmana'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICSPIS59665.2023.10402723?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICSPIS59665.2023.10402723, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the field of natural language processing (nlp), keywords are crucial for enhancing information retrieval (ir) and content summarization, as well as for optimizing search engines and organizing documents. as the volume of generated information increases, identifying keywords manually from large documents becomes more challenging and no longer feasible. therefore, automatic keyword extraction is necessary as a cost-effective method to handle large documents and to provide scalable solutions for various applications in nlp and information management. in the academic domain, automatic keyword extraction simplifies the process of finding and categorizing scientific publications, enabling paper repositories to optimize their ir and document organizing systems. however, many methods of keyword extraction use either global semantic features based on pre-trained embedding models or local statistical features separately, which yields low results. since a good keyword must be identified by both external knowledge and local statistical features, this paper proposes a method to improve the performance of keyword extraction from scientific publications by combining local statistical features with embedding models. the proposed method outperforms the baseline methods with an f-score of 0.70 on the semeval2017 dataset using the scibert model and svm classifier. this research confirms that both local statistical information and contextualized semantic information are important to identify keywords.",
a2fe888b5bbff361429d9f28ca6818915becf0b1,AI Literature Review Suite,"The process of conducting literature reviews is often time-consuming and labor-intensive. To streamline this process, I present an AI Literature Review Suite that integrates several functionalities to provide a comprehensive literature review. This tool leverages the power of open access science, large language models (LLMs) and natural language processing to enable the searching, downloading, and organizing of PDF files, as well as extracting content from articles. Semantic search queries are used for data retrieval, while text embeddings and summarization using LLMs present succinct literature reviews. Interaction with PDFs is enhanced through a user-friendly graphical user interface (GUI). The suite also features integrated programs for bibliographic organization, interaction and query, and literature review summaries. This tool presents a robust solution to automate and optimize the process of literature review in academic and industrial research.",2023,"[{'authorId': '2627789', 'name': 'David A. Tovar'}]","{'url': 'https://arxiv.org/pdf/2308.02443', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2308.02443, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the process of conducting literature reviews is often time-consuming and labor-intensive. to streamline this process, i present an ai literature review suite that integrates several functionalities to provide a comprehensive literature review. this tool leverages the power of open access science, large language models (llms) and natural language processing to enable the searching, downloading, and organizing of pdf files, as well as extracting content from articles. semantic search queries are used for data retrieval, while text embeddings and summarization using llms present succinct literature reviews. interaction with pdfs is enhanced through a user-friendly graphical user interface (gui). the suite also features integrated programs for bibliographic organization, interaction and query, and literature review summaries. this tool presents a robust solution to automate and optimize the process of literature review in academic and industrial research.",https://arxiv.org/pdf/2308.02443
371c7be6ae7a779ed48eb2f209bd7ecac33d281c,Researcher Profile: An Automated Solution for Searching and Gathering People’s Profiles,"This project presents an innovative solution to facilitate the search and analysis of professional profiles in academic platforms by automating manual processes and using advanced technologies such as Natural Language Processing (NLP) and third-party application programming interface (API). We designed an architecture based on a React/NextJS front-end and back-end with REST APIs to enable robust and scalable performance for the proposed system. Our proposed architecture and implementation plan provided a solid foundation for the development of the solution. Our initial prototype and advanced functionalities, such as sentiment analysis, keyword extraction, and personalized profile recommendations, are expected to improve the user experience and provide added value to the academic and professional community.",2023,"[{'authorId': '144510866', 'name': 'Juan Carlos Martinez-Santos'}, {'authorId': '2284872076', 'name': 'Jenifer Vásquez'}, {'authorId': '2262229458', 'name': 'Edwin Puertas'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/C358072.2023.10436220?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/C358072.2023.10436220, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this project presents an innovative solution to facilitate the search and analysis of professional profiles in academic platforms by automating manual processes and using advanced technologies such as natural language processing (nlp) and third-party application programming interface (api). we designed an architecture based on a react/nextjs front-end and back-end with rest apis to enable robust and scalable performance for the proposed system. our proposed architecture and implementation plan provided a solid foundation for the development of the solution. our initial prototype and advanced functionalities, such as sentiment analysis, keyword extraction, and personalized profile recommendations, are expected to improve the user experience and provide added value to the academic and professional community.",
6c6125b98f5b83f97a4bc1bae6e2df493aadf9ae,Impact of Nationwide Utilization of a Machine Learning Model to Identify Home Therapy Candidates,". Background: Anti-neutrophil cytoplasmatic antibody (ANCA)-associated vasculitis (AAV) is a rare, life-threatening, systemic auto-immune disease. Due to the low prevalence and heterogenous registration, there is an urgent need to improve identification of AAV patients within the electronic health record (EHR)-system of health organizations to facilitate clinical research. Methods: Our aim was to identify, with a high sensitivity, low-prevalence AAV patients within large EHR-systems (>2.000.000 records) using an artificial intelligence (AI)-search tool. We combined a search on structured and unstructured data with natural language processing (NLP)-based exclusion. We developed the method in an academic center with an established AAV training set (n=203) and validated the method in a non-academic center with a validation set (n=84). We anonymously reviewed all identified patient records for AAV diagnosis. Results: The final search strategy combined four queries on disease description, laboratory measurements, medication and specialisms. In the training center, this search identified 608 patients, of which 346 were AAV patients upon manual review. 197/203 patients of the training set were retrieved, indicating a sensitivity of 97%. Employing NLP-based exclusion resulted in 444 patients with 339 AAV patients, resulting in an increase of positive predictive value (PPV) from 57% to 78% and a sensitivity of 96%. In the validation center the search strategy identified 333 patients, of which 194 were AAV patients, including 82/84 (98%) patients of the validation set. After NLP-based exclusion 223 patients remained, including 196 AAV patients, improving PPV from 58 to 86% with a sensitivity of 98%. Our identification method outperformed ICD-10 coding predominantly in identifying myeloperoxidase (MPO)-positive AAV patients and patients with few specialisms involved. Conclusions: We demonstrated excellent performance of an AI-based identification method, incorporating NLP, to identify AAV patients in EHRs and we validated the applicability and transportability. This method can accelerate research efforts, while avoiding the limitations of ICD-10-based registration.",2023,"[{'authorId': '152619420', 'name': 'C. Monaghan'}, {'authorId': '2302205852', 'name': 'Maria Hanson'}, {'authorId': '2295586896', 'name': 'Hao Han'}, {'authorId': '2151683063', 'name': 'Joanna Willetts'}, {'authorId': '3478721', 'name': 'L. Usvyat'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1681/ASN.20233411S1102c?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1681/ASN.20233411S1102c, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",". background: anti-neutrophil cytoplasmatic antibody (anca)-associated vasculitis (aav) is a rare, life-threatening, systemic auto-immune disease. due to the low prevalence and heterogenous registration, there is an urgent need to improve identification of aav patients within the electronic health record (ehr)-system of health organizations to facilitate clinical research. methods: our aim was to identify, with a high sensitivity, low-prevalence aav patients within large ehr-systems (>2.000.000 records) using an artificial intelligence (ai)-search tool. we combined a search on structured and unstructured data with natural language processing (nlp)-based exclusion. we developed the method in an academic center with an established aav training set (n=203) and validated the method in a non-academic center with a validation set (n=84). we anonymously reviewed all identified patient records for aav diagnosis. results: the final search strategy combined four queries on disease description, laboratory measurements, medication and specialisms. in the training center, this search identified 608 patients, of which 346 were aav patients upon manual review. 197/203 patients of the training set were retrieved, indicating a sensitivity of 97%. employing nlp-based exclusion resulted in 444 patients with 339 aav patients, resulting in an increase of positive predictive value (ppv) from 57% to 78% and a sensitivity of 96%. in the validation center the search strategy identified 333 patients, of which 194 were aav patients, including 82/84 (98%) patients of the validation set. after nlp-based exclusion 223 patients remained, including 196 aav patients, improving ppv from 58 to 86% with a sensitivity of 98%. our identification method outperformed icd-10 coding predominantly in identifying myeloperoxidase (mpo)-positive aav patients and patients with few specialisms involved. conclusions: we demonstrated excellent performance of an ai-based identification method, incorporating nlp, to identify aav patients in ehrs and we validated the applicability and transportability. this method can accelerate research efforts, while avoiding the limitations of icd-10-based registration.",
7d19b336e67d0bf87af4a81cb79f2743c0192a91,"Cross-Modal Question Generation: NLP-based Approaches for Text, Image, PDF, and Video Inputs","Natural Language Processing (NLP) has advanced recently, and this has fundamentally changed how humans interact with and understand written material. Among the many uses of natural language processing (NLP), automated question generation (QG) has attracted significant interest in data retrieval and academic research. This study explores novel approaches and tactics for bringing NLP methods to the field of QG. This study provides a thorough synopsis of the many stages of the QG process, including the preparation of preliminary data, the creation of questionnaires, and the interviewing procedure. This study examines each of these phases in detail and discusses about the issues that have surfaced recently along with their associated fixes. It also highlights the critical role that neural networks—in particular, transformer-based models—play in improving QG system performance. Furthermore, this study covers a wide range of applications for automated QG, from search engine building and chatbot interaction to the creation of content for research and education. give case studies and practical applications where the effectiveness of automated QG has been shown. The study also looks at accepted assessment measures and benchmarks for determining the quality of questionnaires that are created. To make it possible to compare QG systems meaningfully, this study emphasizes the value of human participation in research and the usefulness of standardized datasets.",2023,"[{'authorId': '2262309002', 'name': 'Snehal R. Rathi'}, {'authorId': '2297397687', 'name': 'Prasad Chate'}, {'authorId': '2297392637', 'name': 'Gaurav Desai'}, {'authorId': '2297393269', 'name': 'Om Gangji'}, {'authorId': '2297393816', 'name': 'Vishwajeet Kale'}, {'authorId': '2297392651', 'name': 'Aditya Kalbhor'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICIMIA60377.2023.10426142?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICIMIA60377.2023.10426142, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","natural language processing (nlp) has advanced recently, and this has fundamentally changed how humans interact with and understand written material. among the many uses of natural language processing (nlp), automated question generation (qg) has attracted significant interest in data retrieval and academic research. this study explores novel approaches and tactics for bringing nlp methods to the field of qg. this study provides a thorough synopsis of the many stages of the qg process, including the preparation of preliminary data, the creation of questionnaires, and the interviewing procedure. this study examines each of these phases in detail and discusses about the issues that have surfaced recently along with their associated fixes. it also highlights the critical role that neural networks—in particular, transformer-based models—play in improving qg system performance. furthermore, this study covers a wide range of applications for automated qg, from search engine building and chatbot interaction to the creation of content for research and education. give case studies and practical applications where the effectiveness of automated qg has been shown. the study also looks at accepted assessment measures and benchmarks for determining the quality of questionnaires that are created. to make it possible to compare qg systems meaningfully, this study emphasizes the value of human participation in research and the usefulness of standardized datasets.",
99a1eacc40f918f60c1827cecfee554d2663b2d4,Polygenic Prediction of Estimated Glomerular Filtration Rate in Individuals of African Descent and from the Americas,". Background: Anti-neutrophil cytoplasmatic antibody (ANCA)-associated vasculitis (AAV) is a rare, life-threatening, systemic auto-immune disease. Due to the low prevalence and heterogenous registration, there is an urgent need to improve identification of AAV patients within the electronic health record (EHR)-system of health organizations to facilitate clinical research. Methods: Our aim was to identify, with a high sensitivity, low-prevalence AAV patients within large EHR-systems (>2.000.000 records) using an artificial intelligence (AI)-search tool. We combined a search on structured and unstructured data with natural language processing (NLP)-based exclusion. We developed the method in an academic center with an established AAV training set (n=203) and validated the method in a non-academic center with a validation set (n=84). We anonymously reviewed all identified patient records for AAV diagnosis. Results: The final search strategy combined four queries on disease description, laboratory measurements, medication and specialisms. In the training center, this search identified 608 patients, of which 346 were AAV patients upon manual review. 197/203 patients of the training set were retrieved, indicating a sensitivity of 97%. Employing NLP-based exclusion resulted in 444 patients with 339 AAV patients, resulting in an increase of positive predictive value (PPV) from 57% to 78% and a sensitivity of 96%. In the validation center the search strategy identified 333 patients, of which 194 were AAV patients, including 82/84 (98%) patients of the validation set. After NLP-based exclusion 223 patients remained, including 196 AAV patients, improving PPV from 58 to 86% with a sensitivity of 98%. Our identification method outperformed ICD-10 coding predominantly in identifying myeloperoxidase (MPO)-positive AAV patients and patients with few specialisms involved. Conclusions: We demonstrated excellent performance of an AI-based identification method, incorporating NLP, to identify AAV patients in EHRs and we validated the applicability and transportability. This method can accelerate research efforts, while avoiding the limitations of ICD-10-based registration.",2023,"[{'authorId': '2290268521', 'name': 'Holly J Kramer'}, {'authorId': '2302263566', 'name': 'Amy Bentley'}, {'authorId': '2276128541', 'name': 'Odessica N. Hughes'}, {'authorId': '2344815727', 'name': 'Girish N. Nadkarni'}, {'authorId': '2053859', 'name': 'J. Mychaleckyj'}, {'authorId': '2302209350', 'name': 'Andrew Morris'}, {'authorId': '2301896910', 'name': 'Nora Franceschini'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1681/ASN.20233411S1102e?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1681/ASN.20233411S1102e, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",". background: anti-neutrophil cytoplasmatic antibody (anca)-associated vasculitis (aav) is a rare, life-threatening, systemic auto-immune disease. due to the low prevalence and heterogenous registration, there is an urgent need to improve identification of aav patients within the electronic health record (ehr)-system of health organizations to facilitate clinical research. methods: our aim was to identify, with a high sensitivity, low-prevalence aav patients within large ehr-systems (>2.000.000 records) using an artificial intelligence (ai)-search tool. we combined a search on structured and unstructured data with natural language processing (nlp)-based exclusion. we developed the method in an academic center with an established aav training set (n=203) and validated the method in a non-academic center with a validation set (n=84). we anonymously reviewed all identified patient records for aav diagnosis. results: the final search strategy combined four queries on disease description, laboratory measurements, medication and specialisms. in the training center, this search identified 608 patients, of which 346 were aav patients upon manual review. 197/203 patients of the training set were retrieved, indicating a sensitivity of 97%. employing nlp-based exclusion resulted in 444 patients with 339 aav patients, resulting in an increase of positive predictive value (ppv) from 57% to 78% and a sensitivity of 96%. in the validation center the search strategy identified 333 patients, of which 194 were aav patients, including 82/84 (98%) patients of the validation set. after nlp-based exclusion 223 patients remained, including 196 aav patients, improving ppv from 58 to 86% with a sensitivity of 98%. our identification method outperformed icd-10 coding predominantly in identifying myeloperoxidase (mpo)-positive aav patients and patients with few specialisms involved. conclusions: we demonstrated excellent performance of an ai-based identification method, incorporating nlp, to identify aav patients in ehrs and we validated the applicability and transportability. this method can accelerate research efforts, while avoiding the limitations of icd-10-based registration.",
92883c9459b2f9a3c543fb375a28f71a41b67be5,Ontology based information retrieval system for Academic Library,"Information retrieval system is taking an important role in current search engine which performs searching operation based on keywords which results in enormous amount of data available to the user, from which user cannot figure out the essential and most important information. This limitation may be overcome by a new web architecture known as semantic web which overcome the limitation of keyword based search technique called conceptual or semantic search technique. Natural language processing technique is mostly implemented in QA system for asking user's question and several steps are also followed for conversion of questions to query form for getting an exact answer. In conceptual search, search engine interprets the meaning of user's query and the relation among the concepts that documents contains with respect to a particular domain that produces specific answers instead of giving list of answers. In this paper, we proposed ontology based semantic information retrieval system and Jena semantic web framework in which, user enters an input query which is parsed by Standford Parser then triplet extraction algorithm is used. To all input query, SPARQL query is formed and then it is fired on the knowledge base (Ontology) that finds appropriate RDF triples in knowledge base and retrieve the relevant information using Jena framework.",2015,"[{'authorId': '9254599', 'name': 'Amol N. Jamgade'}, {'authorId': '144236982', 'name': 'S. Karale'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICIIECS.2015.7193106?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICIIECS.2015.7193106, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","information retrieval system is taking an important role in current search engine which performs searching operation based on keywords which results in enormous amount of data available to the user, from which user cannot figure out the essential and most important information. this limitation may be overcome by a new web architecture known as semantic web which overcome the limitation of keyword based search technique called conceptual or semantic search technique. natural language processing technique is mostly implemented in qa system for asking user's question and several steps are also followed for conversion of questions to query form for getting an exact answer. in conceptual search, search engine interprets the meaning of user's query and the relation among the concepts that documents contains with respect to a particular domain that produces specific answers instead of giving list of answers. in this paper, we proposed ontology based semantic information retrieval system and jena semantic web framework in which, user enters an input query which is parsed by standford parser then triplet extraction algorithm is used. to all input query, sparql query is formed and then it is fired on the knowledge base (ontology) that finds appropriate rdf triples in knowledge base and retrieve the relevant information using jena framework.",
638cedba3635bdd7d18f97246c40ad3a2201d354,A Systematic Literature Review of Automated ICD Coding and Classification Systems using Discharge Summaries,"Codification of free-text clinical narratives have long been recognised to be beneficial for secondary uses such as funding, insurance claim processing and research. The current scenario of assigning codes is a manual process which is very expensive, time-consuming and error prone. In recent years, many researchers have studied the use of Natural Language Processing (NLP), related Machine Learning (ML) and Deep Learning (DL) methods and techniques to resolve the problem of manual coding of clinical narratives and to assist human coders to assign clinical codes more accurately and efficiently. This systematic literature review provides a comprehensive overview of automated clinical coding systems that utilises appropriate NLP, ML and DL methods and techniques to assign ICD codes to discharge summaries. We have followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses(PRISMA) guidelines and conducted a comprehensive search of publications from January, 2010 to December 2020 in four academic databases- PubMed, ScienceDirect, Association for Computing Machinery(ACM) Digital Library, and the Association for Computational Linguistics(ACL) Anthology. We reviewed 7,556 publications; 38 met the inclusion criteria. This review identified: datasets having discharge summaries; NLP techniques along with some other data extraction processes, different feature extraction and embedding techniques. To measure the performance of classification methods, different evaluation metrics are used. Lastly, future research directions are provided to scholars who are interested in automated ICD code assignment. Efforts are still required to improve ICD code prediction accuracy, availability of large-scale de-identified clinical corpora with the latest version of the classification system. This can be a platform to guide and share knowledge with the less experienced coders and researchers.",2021,"[{'authorId': '9410576', 'name': 'R. Kaur'}, {'authorId': '2615312', 'name': 'J. A. Ginige'}, {'authorId': '2067321083', 'name': 'O. Obst'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2107.10652, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","codification of free-text clinical narratives have long been recognised to be beneficial for secondary uses such as funding, insurance claim processing and research. the current scenario of assigning codes is a manual process which is very expensive, time-consuming and error prone. in recent years, many researchers have studied the use of natural language processing (nlp), related machine learning (ml) and deep learning (dl) methods and techniques to resolve the problem of manual coding of clinical narratives and to assist human coders to assign clinical codes more accurately and efficiently. this systematic literature review provides a comprehensive overview of automated clinical coding systems that utilises appropriate nlp, ml and dl methods and techniques to assign icd codes to discharge summaries. we have followed the preferred reporting items for systematic reviews and meta-analyses(prisma) guidelines and conducted a comprehensive search of publications from january, 2010 to december 2020 in four academic databases- pubmed, sciencedirect, association for computing machinery(acm) digital library, and the association for computational linguistics(acl) anthology. we reviewed 7,556 publications; 38 met the inclusion criteria. this review identified: datasets having discharge summaries; nlp techniques along with some other data extraction processes, different feature extraction and embedding techniques. to measure the performance of classification methods, different evaluation metrics are used. lastly, future research directions are provided to scholars who are interested in automated icd code assignment. efforts are still required to improve icd code prediction accuracy, availability of large-scale de-identified clinical corpora with the latest version of the classification system. this can be a platform to guide and share knowledge with the less experienced coders and researchers.",
8823dceb318c002a54800056a979fc2ab3517458,Crowdsourcing forensics: Creating a curated catalog of digital forensic artifacts,"The increasing volume, variety, velocity, distribution, structural intricacy, and complexity of use of digital evidence can make it difficult for practitioners to find and understand the most forensically useful information (Casey E. Digital evidence and computer crime: Forensic science, computers, and the Internet. Academic Press; 2011. p. 31; Pollitt M. The hermeneutics of the hard drive: Using narratology, natural language processing, and knowledge management to improve the effectiveness of the digital forensic process [PhD dissertation]. University of Central Florida; 2011). Digital forensic practitioners currently search for information and solutions in an ad hoc manner, leading to results that are unstructured, unverified, and sometimes incomplete. As a result, certain digital evidence is being missed or misinterpreted. To mitigate risks of knowledge gaps, there is a pressing need for a systematic mechanism that practitioners can use to codify and combine their collective knowledge. This work presents the design and development of a solution that catalogs crowdsourced knowledge of digital forensic artifacts in a well‐structured, easily searchable form to support efficient and automated extraction of pertinent information, improving availability and reliability of interpretation of artifacts (general acceptance). Technical implementation and artifact curation are discussed with illustrative examples and recommendations for future work.",2022,"[{'authorId': '143778267', 'name': 'E. Casey'}, {'authorId': '2151126375', 'name': 'Lam Nguyen'}, {'authorId': '2175632079', 'name': 'Jeffrey Mates'}, {'authorId': '2175630155', 'name': 'Scott Lalliss'}]","{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9543441', 'status': 'GREEN', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9543441, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the increasing volume, variety, velocity, distribution, structural intricacy, and complexity of use of digital evidence can make it difficult for practitioners to find and understand the most forensically useful information (casey e. digital evidence and computer crime: forensic science, computers, and the internet. academic press; 2011. p. 31; pollitt m. the hermeneutics of the hard drive: using narratology, natural language processing, and knowledge management to improve the effectiveness of the digital forensic process [phd dissertation]. university of central florida; 2011). digital forensic practitioners currently search for information and solutions in an ad hoc manner, leading to results that are unstructured, unverified, and sometimes incomplete. as a result, certain digital evidence is being missed or misinterpreted. to mitigate risks of knowledge gaps, there is a pressing need for a systematic mechanism that practitioners can use to codify and combine their collective knowledge. this work presents the design and development of a solution that catalogs crowdsourced knowledge of digital forensic artifacts in a well‐structured, easily searchable form to support efficient and automated extraction of pertinent information, improving availability and reliability of interpretation of artifacts (general acceptance). technical implementation and artifact curation are discussed with illustrative examples and recommendations for future work.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9543441
4ba2e7c6249222b125348c4fbbeea0a57dd501cd,Patient treatment and outcome after breast cancer orbital and periorbital metastases: a comprehensive case series including analysis of lobular versus ductal tumor histology,"Background Breast cancer is the most common malignancy to spread to the orbit and periorbit, and the invasive lobular carcinoma (ILC) histologic subtype of breast cancer has been reported to form these ophthalmic metastases (OM) more frequently than invasive ductal carcinomas (IDC). We herein report our single academic institution experience with breast cancer OM with respect to anatomical presentation, histology (lobular vs. ductal), treatment, and survival. Methods We employed the natural language processing platform, TIES (Text Information Extraction System), to search 2.3 million de-identified patient pathology and radiology records at our institution in order to identify patients with OM secondary to breast cancer. We then compared the resultant cohort, the “OM cohort,” to two other representative metastatic breast cancer patient (MBC) databases from our institution. Histological analysis of selected patients was performed. Results Our TIES search and manual refinement ultimately identified 28 patients who were diagnosed with breast cancer between 1995 and 2016 that subsequently developed OM. Median age at diagnosis was 54 (range 28–77) years of age. ER, PR, and HER2 status from the 28 patients with OM did not differ from other patients with MBC from our institution. The relative proportion of patients with ILC was significantly higher in the OM cohort (32.1%) than in other MBC patients in our institution (11.3%, p  = 0.007). Median time to first OM in the OM cohort was 46.7 months, and OM were the second most frequent first metastases after bony metastases. After diagnosis of the first distant metastasis of any kind, median survival of patients with ILC (21.4 months) was significantly shorter than that of patients with IDC (55.3 months, p  = 0.03). Nine patients developed bilateral OM. We observed a significant co-occurrence of OM and central nervous system metastases ( p  = 0.0053). The histological analysis revealed an interesting case in which the primary tumor was of a mixed ILC/IDC subtype, while only ILC was present in the OM. Conclusions OM from breast cancer are illustrative of the difference in metastatic behavior of ILC versus IDC and should be considered when treating patients with ILC, especially in those with complaints of visual acuity changes.",2020,"[{'authorId': '1573328595', 'name': 'Martin Blohmer'}, {'authorId': '2144059181', 'name': 'Li Zhu'}, {'authorId': '33877936', 'name': 'J. Atkinson'}, {'authorId': '5419826', 'name': 'S. Beriwal'}, {'authorId': '1420609124', 'name': 'J. Rodríguez-López'}, {'authorId': '3587465', 'name': 'M. Rosenzweig'}, {'authorId': '48138547', 'name': 'A. Brufsky'}, {'authorId': '1799353', 'name': 'G. Tseng'}, {'authorId': '143771262', 'name': 'P. C. Lucas'}, {'authorId': '145263625', 'name': 'Adrian V. Lee'}, {'authorId': '2486035', 'name': 'S. Oesterreich'}, {'authorId': '3839221', 'name': 'R. Jankowitz'}]","{'url': 'https://breast-cancer-research.biomedcentral.com/track/pdf/10.1186/s13058-020-01309-3', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7318761, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background breast cancer is the most common malignancy to spread to the orbit and periorbit, and the invasive lobular carcinoma (ilc) histologic subtype of breast cancer has been reported to form these ophthalmic metastases (om) more frequently than invasive ductal carcinomas (idc). we herein report our single academic institution experience with breast cancer om with respect to anatomical presentation, histology (lobular vs. ductal), treatment, and survival. methods we employed the natural language processing platform, ties (text information extraction system), to search 2.3 million de-identified patient pathology and radiology records at our institution in order to identify patients with om secondary to breast cancer. we then compared the resultant cohort, the “om cohort,” to two other representative metastatic breast cancer patient (mbc) databases from our institution. histological analysis of selected patients was performed. results our ties search and manual refinement ultimately identified 28 patients who were diagnosed with breast cancer between 1995 and 2016 that subsequently developed om. median age at diagnosis was 54 (range 28–77) years of age. er, pr, and her2 status from the 28 patients with om did not differ from other patients with mbc from our institution. the relative proportion of patients with ilc was significantly higher in the om cohort (32.1%) than in other mbc patients in our institution (11.3%, p = 0.007). median time to first om in the om cohort was 46.7 months, and om were the second most frequent first metastases after bony metastases. after diagnosis of the first distant metastasis of any kind, median survival of patients with ilc (21.4 months) was significantly shorter than that of patients with idc (55.3 months, p = 0.03). nine patients developed bilateral om. we observed a significant co-occurrence of om and central nervous system metastases ( p = 0.0053). the histological analysis revealed an interesting case in which the primary tumor was of a mixed ilc/idc subtype, while only ilc was present in the om. conclusions om from breast cancer are illustrative of the difference in metastatic behavior of ilc versus idc and should be considered when treating patients with ilc, especially in those with complaints of visual acuity changes.",https://breast-cancer-research.biomedcentral.com/track/pdf/10.1186/s13058-020-01309-3
5148766ee1d0eb4b565a883bcdce5efecd66cda6,DEADLINER: building a new niche search engine,"We present DEADLINER, a search engine that catalogs conference and workshop announcements, and ultimately will monitor and extract a wide range of academic convocation material from the web. The system currently extracts speakers, locations, dates, paper submission (and other) deadlines, topics, program committees, abstracts, and aAEliations. A user or user agent can perform detailed searches on these elds. DEADLINER was constructed using a methodology for rapid implementation of specialized search engines. This methodology avoids complex hand-tuned text extraction solutions, or natural language processing, by Bayesian integration of simple extractors that exploit loose formatting and keyw ord con ventions. The Bayesian framework further produces a search engine where each user can control the false alarm rate on a eld in an intuitive yet rigorous fashion.",2000,"[{'authorId': '144540443', 'name': 'A. Kruger'}, {'authorId': '145157784', 'name': 'C. Lee Giles'}, {'authorId': '2083483274', 'name': 'Frans Coetzee'}, {'authorId': '3165312', 'name': 'E. Glover'}, {'authorId': '1687227', 'name': 'G. Flake'}, {'authorId': '145840115', 'name': 'S. Lawrence'}, {'authorId': '1740471', 'name': 'C. Omlin'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/354756.354829', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/354756.354829?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/354756.354829, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we present deadliner, a search engine that catalogs conference and workshop announcements, and ultimately will monitor and extract a wide range of academic convocation material from the web. the system currently extracts speakers, locations, dates, paper submission (and other) deadlines, topics, program committees, abstracts, and aaeliations. a user or user agent can perform detailed searches on these elds. deadliner was constructed using a methodology for rapid implementation of specialized search engines. this methodology avoids complex hand-tuned text extraction solutions, or natural language processing, by bayesian integration of simple extractors that exploit loose formatting and keyw ord con ventions. the bayesian framework further produces a search engine where each user can control the false alarm rate on a eld in an intuitive yet rigorous fashion.",https://dl.acm.org/doi/pdf/10.1145/354756.354829
1e7a31d8829bcea3e3b57c4c871e755325a81f28,Machine Learning Approach for Hemodialysis Prescription: Model Development and Validation Study,". Background: Anti-neutrophil cytoplasmatic antibody (ANCA)-associated vasculitis (AAV) is a rare, life-threatening, systemic auto-immune disease. Due to the low prevalence and heterogenous registration, there is an urgent need to improve identification of AAV patients within the electronic health record (EHR)-system of health organizations to facilitate clinical research. Methods: Our aim was to identify, with a high sensitivity, low-prevalence AAV patients within large EHR-systems (>2.000.000 records) using an artificial intelligence (AI)-search tool. We combined a search on structured and unstructured data with natural language processing (NLP)-based exclusion. We developed the method in an academic center with an established AAV training set (n=203) and validated the method in a non-academic center with a validation set (n=84). We anonymously reviewed all identified patient records for AAV diagnosis. Results: The final search strategy combined four queries on disease description, laboratory measurements, medication and specialisms. In the training center, this search identified 608 patients, of which 346 were AAV patients upon manual review. 197/203 patients of the training set were retrieved, indicating a sensitivity of 97%. Employing NLP-based exclusion resulted in 444 patients with 339 AAV patients, resulting in an increase of positive predictive value (PPV) from 57% to 78% and a sensitivity of 96%. In the validation center the search strategy identified 333 patients, of which 194 were AAV patients, including 82/84 (98%) patients of the validation set. After NLP-based exclusion 223 patients remained, including 196 AAV patients, improving PPV from 58 to 86% with a sensitivity of 98%. Our identification method outperformed ICD-10 coding predominantly in identifying myeloperoxidase (MPO)-positive AAV patients and patients with few specialisms involved. Conclusions: We demonstrated excellent performance of an AI-based identification method, incorporating NLP, to identify AAV patients in EHRs and we validated the applicability and transportability. This method can accelerate research efforts, while avoiding the limitations of ICD-10-based registration.",2022,"[{'authorId': '2051576563', 'name': 'T. Ghonimi'}, {'authorId': '2301820983', 'name': 'Abdullah I Hamad'}, {'authorId': '2300449970', 'name': 'M. T. Abdellatif'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1681/ASN.20233411S1102a?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1681/ASN.20233411S1102a, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",". background: anti-neutrophil cytoplasmatic antibody (anca)-associated vasculitis (aav) is a rare, life-threatening, systemic auto-immune disease. due to the low prevalence and heterogenous registration, there is an urgent need to improve identification of aav patients within the electronic health record (ehr)-system of health organizations to facilitate clinical research. methods: our aim was to identify, with a high sensitivity, low-prevalence aav patients within large ehr-systems (>2.000.000 records) using an artificial intelligence (ai)-search tool. we combined a search on structured and unstructured data with natural language processing (nlp)-based exclusion. we developed the method in an academic center with an established aav training set (n=203) and validated the method in a non-academic center with a validation set (n=84). we anonymously reviewed all identified patient records for aav diagnosis. results: the final search strategy combined four queries on disease description, laboratory measurements, medication and specialisms. in the training center, this search identified 608 patients, of which 346 were aav patients upon manual review. 197/203 patients of the training set were retrieved, indicating a sensitivity of 97%. employing nlp-based exclusion resulted in 444 patients with 339 aav patients, resulting in an increase of positive predictive value (ppv) from 57% to 78% and a sensitivity of 96%. in the validation center the search strategy identified 333 patients, of which 194 were aav patients, including 82/84 (98%) patients of the validation set. after nlp-based exclusion 223 patients remained, including 196 aav patients, improving ppv from 58 to 86% with a sensitivity of 98%. our identification method outperformed icd-10 coding predominantly in identifying myeloperoxidase (mpo)-positive aav patients and patients with few specialisms involved. conclusions: we demonstrated excellent performance of an ai-based identification method, incorporating nlp, to identify aav patients in ehrs and we validated the applicability and transportability. this method can accelerate research efforts, while avoiding the limitations of icd-10-based registration.",
e20ead0dc8c162d26342c7ef8090c75d30982911,The NLP Powered BI Toolkit: The Case of MESOC,"In this paper, we present a business intelligence (BI) toolkit based on natural language processing (NLP) methods for the arts and culture domain, collected in the Measuring the Social Dimension of Culture (MESOC) project. The main NLP methods in the underlying pipeline are keyword extraction, multi-label classification of texts, and detection of potential social impacts of cultural policies and practices, all trained on texts from open-access academic publications. The MESOC Toolkit is a georeferenced visualization tool for analyzing impact on social value creation in the areas of health and well-being, urban regeneration, and social cohesion, and enables semantic search for content in the MESOC domain. Therefore, the presented research can serve as a prototype for measuring societal value by identifying recurrent pathways of transformational processes in society that reach beyond the selected field of art and culture.",2022,"[{'authorId': '2140666461', 'name': 'Petar Kristijan Bogovic'}, {'authorId': '1478398400', 'name': 'Dino Aljevic'}, {'authorId': '39845471', 'name': 'Bozidar Kovacic'}, {'authorId': '1403643862', 'name': 'Sanda Martinčić-Ipšić'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.23919/mipro55190.2022.9803434?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.23919/mipro55190.2022.9803434, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this paper, we present a business intelligence (bi) toolkit based on natural language processing (nlp) methods for the arts and culture domain, collected in the measuring the social dimension of culture (mesoc) project. the main nlp methods in the underlying pipeline are keyword extraction, multi-label classification of texts, and detection of potential social impacts of cultural policies and practices, all trained on texts from open-access academic publications. the mesoc toolkit is a georeferenced visualization tool for analyzing impact on social value creation in the areas of health and well-being, urban regeneration, and social cohesion, and enables semantic search for content in the mesoc domain. therefore, the presented research can serve as a prototype for measuring societal value by identifying recurrent pathways of transformational processes in society that reach beyond the selected field of art and culture.",
e05992453805af5108d38ae987055b3452ec2b2f,"TutorialBank: A Manually-Collected Corpus for Prerequisite Chains, Survey Extraction and Resource Recommendation","The field of Natural Language Processing (NLP) is growing rapidly, with new research published daily along with an abundance of tutorials, codebases and other online resources. In order to learn this dynamic field or stay up-to-date on the latest research, students as well as educators and researchers must constantly sift through multiple sources to find valuable, relevant information. To address this situation, we introduce TutorialBank, a new, publicly available dataset which aims to facilitate NLP education and research. We have manually collected and categorized over 5,600 resources on NLP as well as the related fields of Artificial Intelligence (AI), Machine Learning (ML) and Information Retrieval (IR). Our dataset is notably the largest manually-picked corpus of resources intended for NLP education which does not include only academic papers. Additionally, we have created both a search engine and a command-line tool for the resources and have annotated the corpus to include lists of research topics, relevant resources for each topic, prerequisite relations among topics, relevant sub-parts of individual resources, among other annotations. We are releasing the dataset and present several avenues for further research.",2018,"[{'authorId': '46255971', 'name': 'Alexander R. Fabbri'}, {'authorId': '46331602', 'name': 'Irene Li'}, {'authorId': '46249770', 'name': 'Prawat Trairatvorakul'}, {'authorId': '2118917583', 'name': 'Yijiao He'}, {'authorId': '2074500906', 'name': 'Wei Tai Ting'}, {'authorId': '144413646', 'name': 'R. Tung'}, {'authorId': '46198034', 'name': 'Caitlin Westerfield'}, {'authorId': '9215251', 'name': 'Dragomir R. Radev'}]","{'url': 'https://www.aclweb.org/anthology/P18-1057.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1805.04617, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the field of natural language processing (nlp) is growing rapidly, with new research published daily along with an abundance of tutorials, codebases and other online resources. in order to learn this dynamic field or stay up-to-date on the latest research, students as well as educators and researchers must constantly sift through multiple sources to find valuable, relevant information. to address this situation, we introduce tutorialbank, a new, publicly available dataset which aims to facilitate nlp education and research. we have manually collected and categorized over 5,600 resources on nlp as well as the related fields of artificial intelligence (ai), machine learning (ml) and information retrieval (ir). our dataset is notably the largest manually-picked corpus of resources intended for nlp education which does not include only academic papers. additionally, we have created both a search engine and a command-line tool for the resources and have annotated the corpus to include lists of research topics, relevant resources for each topic, prerequisite relations among topics, relevant sub-parts of individual resources, among other annotations. we are releasing the dataset and present several avenues for further research.",https://www.aclweb.org/anthology/P18-1057.pdf
9962cdbe40bf25952524337bd45396c2efd07b4d,Applying text mining methods to suicide research.,"OBJECTIVE
To introduce the research methods of computerized text mining and its possible applications in suicide research and to demonstrate the procedures of applying a specific text mining area, document classification, to a suicide-related study.


METHOD
A systematic search of academic papers that applied text mining methods to suicide research was conducted. Relevant papers were reviewed focusing on their research objectives and sources of data. Furthermore, a case of using natural language processing and document classification methods to analyze a large amount of suicide news was elaborated to showcase the methods.


RESULTS
Eighty-six papers using text mining methods for suicide research have been published since 2001. The most common research objective (72.1%) was to classify which documents exhibit suicide risk or were written by suicidal people. The most frequently used data source was online social media posts (45.3%), followed by e-healthcare records (25.6%). For the news classification case, the top three classifiers trained for classification tasks achieved 84% or higher accuracy.


CONCLUSIONS
Computerized text mining methods can help to scale up content analysis capacity and efficiency and uncover new insights and perspectives for suicide research.",2021,"[{'authorId': '37670084', 'name': 'Q. Cheng'}, {'authorId': '123534778', 'name': 'Carrie Lui'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/sltb.12680?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/sltb.12680, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objective to introduce the research methods of computerized text mining and its possible applications in suicide research and to demonstrate the procedures of applying a specific text mining area, document classification, to a suicide-related study. method a systematic search of academic papers that applied text mining methods to suicide research was conducted. relevant papers were reviewed focusing on their research objectives and sources of data. furthermore, a case of using natural language processing and document classification methods to analyze a large amount of suicide news was elaborated to showcase the methods. results eighty-six papers using text mining methods for suicide research have been published since 2001. the most common research objective (72.1%) was to classify which documents exhibit suicide risk or were written by suicidal people. the most frequently used data source was online social media posts (45.3%), followed by e-healthcare records (25.6%). for the news classification case, the top three classifiers trained for classification tasks achieved 84% or higher accuracy. conclusions computerized text mining methods can help to scale up content analysis capacity and efficiency and uncover new insights and perspectives for suicide research.",
7dcd275571674072e5b11163fa33315b1251fd25,Bibliometric-Enhanced Information Retrieval 10th Anniversary Workshop Edition,"The Bibliometric-enhanced Information Retrieval workshop series (BIR) was launched at ECIR in 2014 [19] and it was held at ECIR each year since then. This year we organize the 10th iteration of BIR. The workshop series at ECIR and JCDL/SIGIR tackles issues related to academic search, at the crossroads between Information Retrieval, Natural Language Processing and Bibliometrics. In this overview paper, we summarize the past workshops, present the workshop topics for 2020 and reflect on some future steps for this workshop series.",2020,"[{'authorId': '1805055', 'name': 'G. Cabanac'}, {'authorId': '1694490', 'name': 'Ingo Frommholz'}, {'authorId': '151474454', 'name': 'Philipp Mayr'}]","{'url': 'https://link.springer.com/content/pdf/10.1007%2F978-3-030-45442-5_85.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2001.10336, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the bibliometric-enhanced information retrieval workshop series (bir) was launched at ecir in 2014 [19] and it was held at ecir each year since then. this year we organize the 10th iteration of bir. the workshop series at ecir and jcdl/sigir tackles issues related to academic search, at the crossroads between information retrieval, natural language processing and bibliometrics. in this overview paper, we summarize the past workshops, present the workshop topics for 2020 and reflect on some future steps for this workshop series.",https://link.springer.com/content/pdf/10.1007%2F978-3-030-45442-5_85.pdf
8b22cfbf580c42d73420449fc49c597cb105ed94,Two Disciplines in Search of Love,"Though computational linguistics (CL) dates back to the first efforts in machine translation in the mid 1950s, it is only in the last decade or so that it has had a substantial impact on literary studies through the statistical techniques of corpus linguistics and data mining (know as natural language processing, NLP). In this essay I briefly review the history of computational linguistics from its early days involving symbolic computing to current developments in NLP and set that in relationship to academic literary study. In particular, I discuss the deeply problematic struggle that literary study has had with the question of evaluation: What makes good literature? I argue that literary studies should own up to this tension and recognize a distinction between ethical criticism, which is explicitly concerned with values, and naturalist criticism, which sidesteps questions of value in favor of understanding how literature works in the mind and in culture. I then argue that the primary relationship between CL and NLP and literary studies should be through naturalist criticism. I conclude by discussing the relative roles of CL and NLP in a large-scale and long-term investigation of romantic love.",2013,"[{'authorId': '3195738', 'name': 'W. Benzon'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/SSRN.2335932?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/SSRN.2335932, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","though computational linguistics (cl) dates back to the first efforts in machine translation in the mid 1950s, it is only in the last decade or so that it has had a substantial impact on literary studies through the statistical techniques of corpus linguistics and data mining (know as natural language processing, nlp). in this essay i briefly review the history of computational linguistics from its early days involving symbolic computing to current developments in nlp and set that in relationship to academic literary study. in particular, i discuss the deeply problematic struggle that literary study has had with the question of evaluation: what makes good literature? i argue that literary studies should own up to this tension and recognize a distinction between ethical criticism, which is explicitly concerned with values, and naturalist criticism, which sidesteps questions of value in favor of understanding how literature works in the mind and in culture. i then argue that the primary relationship between cl and nlp and literary studies should be through naturalist criticism. i conclude by discussing the relative roles of cl and nlp in a large-scale and long-term investigation of romantic love.",
5d9f27451d101c05d4b6411b7420a9c736755f7d,Text-mining analysis of mHealth research.,"In recent years, because of the advancements in communication and networking technologies, mobile technologies have been developing at an unprecedented rate. mHealth, the use of mobile technologies in medicine, and the related research has also surged parallel to these technological advancements. Although there have been several attempts to review mHealth research through manual processes such as systematic reviews, the sheer magnitude of the number of studies published in recent years makes this task very challenging. The most recent developments in machine learning and text mining offer some potential solutions to address this challenge by allowing analyses of large volumes of texts through semi-automated processes. The objective of this study is to analyze the evolution of mHealth research by utilizing text-mining and natural language processing (NLP) analyses. The study sample included abstracts of 5,644 mHealth research articles, which were gathered from five academic search engines by using search terms such as mobile health, and mHealth. The analysis used the Text Explorer module of JMP Pro 13 and an iterative semi-automated process involving tokenizing, phrasing, and terming. After developing the document term matrix (DTM) analyses such as single value decomposition (SVD), topic, and hierarchical document clustering were performed, along with the topic-informed document clustering approach. The results were presented in the form of word-clouds and trend analyses. There were several major findings regarding research clusters and trends. First, our results confirmed time-dependent nature of terminology use in mHealth research. For example, in earlier versus recent years the use of terminology changed from ""mobile phone"" to ""smartphone"" and from ""applications"" to ""apps"". Second, ten clusters for mHealth research were identified including (I) Clinical Research on Lifestyle Management, (II) Community Health, (III) Literature Review, (IV) Medical Interventions, (V) Research Design, (VI) Infrastructure, (VII) Applications, (VIII) Research and Innovation in Health Technologies, (IX) Sensor-based Devices and Measurement Algorithms, (X) Survey-based Research. Third, the trend analyses indicated the infrastructure cluster as the highest percentage researched area until 2014. The Research and Innovation in Health Technologies cluster experienced the largest increase in numbers of publications in recent years, especially after 2014. This study is unique because it is the only known study utilizing text-mining analyses to reveal the streams and trends for mHealth research. The fast growth in mobile technologies is expected to lead to higher numbers of studies focusing on mHealth and its implications for various healthcare outcomes. Findings of this study can be utilized by researchers in identifying areas for future studies.",2017,"[{'authorId': '2348649', 'name': 'Bunyamin Ozaydin'}, {'authorId': '29995876', 'name': 'F. Zengul'}, {'authorId': '35670741', 'name': 'N. Oner'}, {'authorId': '1798498', 'name': 'D. Delen'}]","{'url': 'https://europepmc.org/articles/pmc5803006?pdf=render', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.21037/mhealth.2017.12.02?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.21037/mhealth.2017.12.02, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent years, because of the advancements in communication and networking technologies, mobile technologies have been developing at an unprecedented rate. mhealth, the use of mobile technologies in medicine, and the related research has also surged parallel to these technological advancements. although there have been several attempts to review mhealth research through manual processes such as systematic reviews, the sheer magnitude of the number of studies published in recent years makes this task very challenging. the most recent developments in machine learning and text mining offer some potential solutions to address this challenge by allowing analyses of large volumes of texts through semi-automated processes. the objective of this study is to analyze the evolution of mhealth research by utilizing text-mining and natural language processing (nlp) analyses. the study sample included abstracts of 5,644 mhealth research articles, which were gathered from five academic search engines by using search terms such as mobile health, and mhealth. the analysis used the text explorer module of jmp pro 13 and an iterative semi-automated process involving tokenizing, phrasing, and terming. after developing the document term matrix (dtm) analyses such as single value decomposition (svd), topic, and hierarchical document clustering were performed, along with the topic-informed document clustering approach. the results were presented in the form of word-clouds and trend analyses. there were several major findings regarding research clusters and trends. first, our results confirmed time-dependent nature of terminology use in mhealth research. for example, in earlier versus recent years the use of terminology changed from ""mobile phone"" to ""smartphone"" and from ""applications"" to ""apps"". second, ten clusters for mhealth research were identified including (i) clinical research on lifestyle management, (ii) community health, (iii) literature review, (iv) medical interventions, (v) research design, (vi) infrastructure, (vii) applications, (viii) research and innovation in health technologies, (ix) sensor-based devices and measurement algorithms, (x) survey-based research. third, the trend analyses indicated the infrastructure cluster as the highest percentage researched area until 2014. the research and innovation in health technologies cluster experienced the largest increase in numbers of publications in recent years, especially after 2014. this study is unique because it is the only known study utilizing text-mining analyses to reveal the streams and trends for mhealth research. the fast growth in mobile technologies is expected to lead to higher numbers of studies focusing on mhealth and its implications for various healthcare outcomes. findings of this study can be utilized by researchers in identifying areas for future studies.",https://europepmc.org/articles/pmc5803006?pdf=render
46d7598a2adf5857ba3c586645b0d6e14beb8adc,T-Know: a Knowledge Graph-based Question Answering and Infor-mation Retrieval System for Traditional Chinese Medicine,"T-Know is a knowledge service system based on the constructed knowledge graph of Traditional Chinese Medicine (TCM). Using authorized and anonymized clinical records, medicine clinical guidelines, teaching materials, classic medical books, academic publications, etc., as data resources, the system extracts triples from free texts to build a TCM knowledge graph by our developed natural language processing methods. On the basis of the knowledge graph, a deep learning algorithm is implemented for single-round question understanding and multiple-round dialogue. In addition, the TCM knowledge graph also is used to support human-computer interactive knowledge retrieval by normalizing search keywords to medical terminology.",2018,"[{'authorId': '2117941612', 'name': 'Ziqing Liu'}, {'authorId': '51194554', 'name': 'Enwei Peng'}, {'authorId': '7189761', 'name': 'Shixing Yan'}, {'authorId': '2139738355', 'name': 'Guozheng Li'}, {'authorId': '144824187', 'name': 'Tianyong Hao'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://aclanthology.org/C18-2004, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","t-know is a knowledge service system based on the constructed knowledge graph of traditional chinese medicine (tcm). using authorized and anonymized clinical records, medicine clinical guidelines, teaching materials, classic medical books, academic publications, etc., as data resources, the system extracts triples from free texts to build a tcm knowledge graph by our developed natural language processing methods. on the basis of the knowledge graph, a deep learning algorithm is implemented for single-round question understanding and multiple-round dialogue. in addition, the tcm knowledge graph also is used to support human-computer interactive knowledge retrieval by normalizing search keywords to medical terminology.",
ffb2058863a90dd25af3f383f1928b444a9ef5c1,Report on the 10th anniversary workshop on bibliometric-enhanced information retrieval (BIR 2020),"The Bibliometric-enhanced Information Retrieval workshop series (BIR) was launched at ECIR in 2014 [Mayr et al., 2014] and it was held at ECIR each year since then. This year we organized the 10th iteration of BIR as an all-virtual workshop with a peak of 97 participants. The workshop series at ECIR and JCDL/SIGIR tackles issues related to academic search, at the crossroads between Information Retrieval, Natural Language Processing and Bibliometrics. In this report, we summarize the past workshops, present the workshop topics for 2020 [Cabanac et al., 2020] and reflect on some future steps for this workshop series.",2020,"[{'authorId': '1805055', 'name': 'G. Cabanac'}, {'authorId': '1694490', 'name': 'Ingo Frommholz'}, {'authorId': '151474454', 'name': 'Philipp Mayr'}]","{'url': 'https://hal.archives-ouvertes.fr/hal-03184987/file/CabanacEtAl2020.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3451964.3451974?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3451964.3451974, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the bibliometric-enhanced information retrieval workshop series (bir) was launched at ecir in 2014 [mayr et al., 2014] and it was held at ecir each year since then. this year we organized the 10th iteration of bir as an all-virtual workshop with a peak of 97 participants. the workshop series at ecir and jcdl/sigir tackles issues related to academic search, at the crossroads between information retrieval, natural language processing and bibliometrics. in this report, we summarize the past workshops, present the workshop topics for 2020 [cabanac et al., 2020] and reflect on some future steps for this workshop series.",https://hal.archives-ouvertes.fr/hal-03184987/file/CabanacEtAl2020.pdf
d2905d6d5264bf09dfae24c7ae37e0730f343e72,Augmenting Wikipedia with Named Entity Tags,"Wikipedia is the largest organized knowledge repository on the Web, increasingly employed by natural language processing and search tools. In this paper, we investigate the task of labeling Wikipedia pages with standard named entity tags, which can be used further by a range of information extraction and language processing tools. To train the classifiers, we manually annotated a small set of Wikipedia pages and then extrapolated the annotations using the Wikipedia category information to a much larger training set. We employed several distinct features for each page: bag-of-words, page structure, abstract, titles, and entity mentions. We report high accuracies for several of the classifiers built. As a result of this work, a Web service that classifies any Wikipedia page has been made available to the academic community.",2008,"[{'authorId': '2278277', 'name': 'Wisam Dakka'}, {'authorId': '73040249', 'name': 'Silviu Cucerzan'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://aclanthology.org/I08-1071, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","wikipedia is the largest organized knowledge repository on the web, increasingly employed by natural language processing and search tools. in this paper, we investigate the task of labeling wikipedia pages with standard named entity tags, which can be used further by a range of information extraction and language processing tools. to train the classifiers, we manually annotated a small set of wikipedia pages and then extrapolated the annotations using the wikipedia category information to a much larger training set. we employed several distinct features for each page: bag-of-words, page structure, abstract, titles, and entity mentions. we report high accuracies for several of the classifiers built. as a result of this work, a web service that classifies any wikipedia page has been made available to the academic community.",
2d3bc40ba1c0f8d9e4dbb26d903190a8d254e40f,Quantum Machine Learning,". Machine Learning (ML) is becoming a more and more popular ﬁeld of knowledge, being a term known not only in the academic ﬁeld due to its successful applications to many real-world problems. The advent of Deep Learning and Big Data in the last decade has contributed to make it even more popular. Many companies, both large ones and SMEs, have created speciﬁc departments for ML and data analysis, being in fact their main activity in many cases. This current exploitation of ML should not mislead us; while it is a mature ﬁeld of knowledge, there is still room for many novel contributions, namely, a better understanding of the underlying Mathe-matics, proposal and tuning of algorithms suitable for new problems (e.g., Natural Language Processing), automation and optimization of the search of parameters, etc. Within this framework of new contributions to ML, Quantum Machine Learning (QML) has emerged strongly lately, speeding up ML calculations and providing alternative representations to existing approaches. This special session includes six high-quality papers dealing with some of the most relevant aspects of QML, including analysis of learning in quantum computing and quantum annealers, quantum versions of classical ML models –like neural networks or learning vector quantization–, and quantum learning approaches for measurement and control.",2020,"[{'authorId': '2226778622', 'name': 'J. Martín-Guerrero'}, {'authorId': '4291120', 'name': 'L. Lamata'}]","{'url': 'https://arxiv.org/pdf/1611.09347', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1142/9781786348210_0010?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1142/9781786348210_0010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",". machine learning (ml) is becoming a more and more popular ﬁeld of knowledge, being a term known not only in the academic ﬁeld due to its successful applications to many real-world problems. the advent of deep learning and big data in the last decade has contributed to make it even more popular. many companies, both large ones and smes, have created speciﬁc departments for ml and data analysis, being in fact their main activity in many cases. this current exploitation of ml should not mislead us; while it is a mature ﬁeld of knowledge, there is still room for many novel contributions, namely, a better understanding of the underlying mathe-matics, proposal and tuning of algorithms suitable for new problems (e.g., natural language processing), automation and optimization of the search of parameters, etc. within this framework of new contributions to ml, quantum machine learning (qml) has emerged strongly lately, speeding up ml calculations and providing alternative representations to existing approaches. this special session includes six high-quality papers dealing with some of the most relevant aspects of qml, including analysis of learning in quantum computing and quantum annealers, quantum versions of classical ml models –like neural networks or learning vector quantization–, and quantum learning approaches for measurement and control.",https://arxiv.org/pdf/1611.09347
5c2ba6ff5bb03e71f0e74e03655ffb7d322d4ddb,Patient treatment and outcome after breast cancer orbital and periorbital metastases: a comprehensive case series including analysis of lobular versus ductal tumor histology,"Breast cancer is the most common malignancy to spread to the orbit and periorbit, and the invasive lobular carcinoma (ILC) histologic subtype of breast cancer has been reported to form these ophthalmic metastases (OM) more frequently than invasive ductal carcinomas (IDC). We herein report our single academic institution experience with breast cancer OM with respect to anatomical presentation, histology (lobular vs. ductal), treatment, and survival. We employed the natural language processing platform, TIES (Text Information Extraction System), to search 2.3 million de-identified patient pathology and radiology records at our institution in order to identify patients with OM secondary to breast cancer. We then compared the resultant cohort, the “OM cohort,” to two other representative metastatic breast cancer patient (MBC) databases from our institution. Histological analysis of selected patients was performed. Our TIES search and manual refinement ultimately identified 28 patients who were diagnosed with breast cancer between 1995 and 2016 that subsequently developed OM. Median age at diagnosis was 54 (range 28–77) years of age. ER, PR, and HER2 status from the 28 patients with OM did not differ from other patients with MBC from our institution. The relative proportion of patients with ILC was significantly higher in the OM cohort (32.1%) than in other MBC patients in our institution (11.3%, p = 0.007). Median time to first OM in the OM cohort was 46.7 months, and OM were the second most frequent first metastases after bony metastases. After diagnosis of the first distant metastasis of any kind, median survival of patients with ILC (21.4 months) was significantly shorter than that of patients with IDC (55.3 months, p = 0.03). Nine patients developed bilateral OM. We observed a significant co-occurrence of OM and central nervous system metastases (p = 0.0053). The histological analysis revealed an interesting case in which the primary tumor was of a mixed ILC/IDC subtype, while only ILC was present in the OM. OM from breast cancer are illustrative of the difference in metastatic behavior of ILC versus IDC and should be considered when treating patients with ILC, especially in those with complaints of visual acuity changes.",2020,"[{'authorId': '1573328595', 'name': 'Martin Blohmer'}, {'authorId': '2144059181', 'name': 'Li Zhu'}, {'authorId': '33877936', 'name': 'J. Atkinson'}, {'authorId': '5419826', 'name': 'S. Beriwal'}, {'authorId': '1420609124', 'name': 'J. Rodríguez-López'}, {'authorId': '2113936633', 'name': 'M. Rosenzweig'}, {'authorId': '48138547', 'name': 'A. Brufsky'}, {'authorId': '2059775234', 'name': 'G. Tseng'}, {'authorId': '143771262', 'name': 'P. C. Lucas'}, {'authorId': '145263625', 'name': 'Adrian V. Lee'}, {'authorId': '2486035', 'name': 'S. Oesterreich'}, {'authorId': '3839221', 'name': 'R. Jankowitz'}]","{'url': 'https://breast-cancer-research.biomedcentral.com/track/pdf/10.1186/s13058-020-01309-3', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1186/s13058-020-01309-3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/s13058-020-01309-3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","breast cancer is the most common malignancy to spread to the orbit and periorbit, and the invasive lobular carcinoma (ilc) histologic subtype of breast cancer has been reported to form these ophthalmic metastases (om) more frequently than invasive ductal carcinomas (idc). we herein report our single academic institution experience with breast cancer om with respect to anatomical presentation, histology (lobular vs. ductal), treatment, and survival. we employed the natural language processing platform, ties (text information extraction system), to search 2.3 million de-identified patient pathology and radiology records at our institution in order to identify patients with om secondary to breast cancer. we then compared the resultant cohort, the “om cohort,” to two other representative metastatic breast cancer patient (mbc) databases from our institution. histological analysis of selected patients was performed. our ties search and manual refinement ultimately identified 28 patients who were diagnosed with breast cancer between 1995 and 2016 that subsequently developed om. median age at diagnosis was 54 (range 28–77) years of age. er, pr, and her2 status from the 28 patients with om did not differ from other patients with mbc from our institution. the relative proportion of patients with ilc was significantly higher in the om cohort (32.1%) than in other mbc patients in our institution (11.3%, p = 0.007). median time to first om in the om cohort was 46.7 months, and om were the second most frequent first metastases after bony metastases. after diagnosis of the first distant metastasis of any kind, median survival of patients with ilc (21.4 months) was significantly shorter than that of patients with idc (55.3 months, p = 0.03). nine patients developed bilateral om. we observed a significant co-occurrence of om and central nervous system metastases (p = 0.0053). the histological analysis revealed an interesting case in which the primary tumor was of a mixed ilc/idc subtype, while only ilc was present in the om. om from breast cancer are illustrative of the difference in metastatic behavior of ilc versus idc and should be considered when treating patients with ilc, especially in those with complaints of visual acuity changes.",https://breast-cancer-research.biomedcentral.com/track/pdf/10.1186/s13058-020-01309-3
f8ef8a36cf563395c07d3b75943e3efd7653cfdb,Utility of Blood Cultures and Empiric Antibiotics in Febrile Pediatric Hemophilia Patients With Central Venous Access Devices,"Background Children with hemophilia frequently require long-term central venous access devices (CVADs) for regular infusion of factor products. Hemophilia patients are not immunocompromised, but the presence and use of CVADs are associated with infections including bacteremia. Currently, the utility of blood cultures in evaluation of the febrile hemophilia patient with an indwelling CVAD is unknown, nor is optimal empiric antibiotic use. Methods We performed a retrospective cross-sectional study of febrile immunocompetent hemophilia patients with CVADs presenting to a large academic urban pediatric emergency department from 1995 to 2017. We used a natural language processing electronic search, followed by manual chart review to construct the cohort. We analyzed rate of pathogen recovery from cultures of blood in subgroups of hemophilia patients, the pathogen profile, and the reported pathogen susceptibilities to ceftriaxone. Results Natural language processing electronic search identified 181 visits for fever among hemophilia patients with indwelling CVADs of which 147 cases from 44 unique patients met study criteria. Cultures of blood were positive in 56 (38%) of 147 patients (95% confidence interval, 30%–47%). Seventeen different organisms were isolated (10 pathogens and 7 possible pathogens) with Staphylococcus aureus and coagulase-negative Staphylococcus species as the most common. Thirty-four percent of isolates were reported as susceptible to ceftriaxone. Positive blood cultures were more common in cases involving patients with inhibitors (n = 71) versus those without (n = 76), odds ratio, 7.4 (95% confidence interval, 3.5–15.9). This was observed irrespective of hemophilia type. Conclusions Febrile immunocompetent hemophilia patients with indwelling CVADs have high rates of bacteremia. Empiric antimicrobial therapy should be targeted to anticipated pathogens and take into consideration local susceptibility patterns for Staphylococcus aureus.",2020,"[{'authorId': '1402204584', 'name': 'H. Al‐Samkari'}, {'authorId': '145667247', 'name': 'A. Ozonoff'}, {'authorId': '8033928', 'name': 'Assaf Landschaft'}, {'authorId': '15274154', 'name': 'R. Kimia'}, {'authorId': '32523278', 'name': 'M. Harper'}, {'authorId': '40228262', 'name': 'S. Croteau'}, {'authorId': '5537892', 'name': 'A. Kimia'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1097/PEC.0000000000002106?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1097/PEC.0000000000002106, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background children with hemophilia frequently require long-term central venous access devices (cvads) for regular infusion of factor products. hemophilia patients are not immunocompromised, but the presence and use of cvads are associated with infections including bacteremia. currently, the utility of blood cultures in evaluation of the febrile hemophilia patient with an indwelling cvad is unknown, nor is optimal empiric antibiotic use. methods we performed a retrospective cross-sectional study of febrile immunocompetent hemophilia patients with cvads presenting to a large academic urban pediatric emergency department from 1995 to 2017. we used a natural language processing electronic search, followed by manual chart review to construct the cohort. we analyzed rate of pathogen recovery from cultures of blood in subgroups of hemophilia patients, the pathogen profile, and the reported pathogen susceptibilities to ceftriaxone. results natural language processing electronic search identified 181 visits for fever among hemophilia patients with indwelling cvads of which 147 cases from 44 unique patients met study criteria. cultures of blood were positive in 56 (38%) of 147 patients (95% confidence interval, 30%–47%). seventeen different organisms were isolated (10 pathogens and 7 possible pathogens) with staphylococcus aureus and coagulase-negative staphylococcus species as the most common. thirty-four percent of isolates were reported as susceptible to ceftriaxone. positive blood cultures were more common in cases involving patients with inhibitors (n = 71) versus those without (n = 76), odds ratio, 7.4 (95% confidence interval, 3.5–15.9). this was observed irrespective of hemophilia type. conclusions febrile immunocompetent hemophilia patients with indwelling cvads have high rates of bacteremia. empiric antimicrobial therapy should be targeted to anticipated pathogens and take into consideration local susceptibility patterns for staphylococcus aureus.",
fb5c327aa1a20ec6ff533d447cede487420207bc,An Ontology-Based Approach to Estimate the Frequency of Rare Diseases in Narrative-Text Radiology Reports,"This study sought to use ontology-based knowledge to identify patients with rare diseases and to estimate the frequency of those diseases in a large database of radiology reports. Natural language processing methods were applied to 12,377,743 narrarive-text radiology reports of 7,803,811 patients at an academic health system. Using knowledge from the Orphanet Rare Disease Ontology and Radiology Gamuts Ontology, 1,154 of 6,794 rare diseases (17.0%) were observed in a total of 237,840 patients (3.05%). Ninety of 2,129 diseases (4%) with known prevalence less than 1 per 1,000,000 were observed in the database, whereas 100 of 173 diseases (58%) with prevalence greater than 1 per 10,000 were observed; the difference was statistically significant (p < .00001). Automated ontology-based search of radiology reports can estimate the frequency of rare diseases, and those diseases with higher known prevalence were significantly more likely to appear in radiology reports.",2017,"[{'authorId': '145673195', 'name': 'C. E. Kahn'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3233/978-1-61499-830-3-896?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3233/978-1-61499-830-3-896, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study sought to use ontology-based knowledge to identify patients with rare diseases and to estimate the frequency of those diseases in a large database of radiology reports. natural language processing methods were applied to 12,377,743 narrarive-text radiology reports of 7,803,811 patients at an academic health system. using knowledge from the orphanet rare disease ontology and radiology gamuts ontology, 1,154 of 6,794 rare diseases (17.0%) were observed in a total of 237,840 patients (3.05%). ninety of 2,129 diseases (4%) with known prevalence less than 1 per 1,000,000 were observed in the database, whereas 100 of 173 diseases (58%) with prevalence greater than 1 per 10,000 were observed; the difference was statistically significant (p < .00001). automated ontology-based search of radiology reports can estimate the frequency of rare diseases, and those diseases with higher known prevalence were significantly more likely to appear in radiology reports.",
36744115dfb1503f80309a9aeda31b3b15ce456e,Rookie: A unique approach for exploring news archives,"News archives are an invaluable primary source for placing current events in historical context. But current search engine tools do a poor job at uncovering broad themes and narratives across documents. We present Rookie: a practical software system which uses natural language processing (NLP) to help readers, reporters and editors uncover broad stories in news archives. Unlike prior work, Rookie's design emerged from 18 months of iterative development in consultation with editors and computational journalists. This process lead to a dramatically different approach from previous academic systems with similar goals. Our efforts offer a generalizable case study for others building real-world journalism software using NLP.",2017,"[{'authorId': '3422919', 'name': 'Abram Handler'}, {'authorId': '153724741', 'name': ""Brendan T. O'Connor""}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1708.01944, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","news archives are an invaluable primary source for placing current events in historical context. but current search engine tools do a poor job at uncovering broad themes and narratives across documents. we present rookie: a practical software system which uses natural language processing (nlp) to help readers, reporters and editors uncover broad stories in news archives. unlike prior work, rookie's design emerged from 18 months of iterative development in consultation with editors and computational journalists. this process lead to a dramatically different approach from previous academic systems with similar goals. our efforts offer a generalizable case study for others building real-world journalism software using nlp.",
b6eec8dcd86427db2dd995bbb9165b645f1ab4c3,An Approach to the Exact Packed String Matching Problem,"Searching data is a natural behavior of humankind and is also a fundamental operation in both industrial and academic areas. There has been research into developing sophisticated methods and techniques for string searching. The common method is to make use of prefixes and suffixes to move through the text while searching a string query in a text. It suffers from high computational complexity since it has to repeatedly search each character in the string query sequentially. In this paper, we address the difficulty and propose a novel approach that enables a parallel search of the text without indexing the text or the query which is needed for sequential search. The proposed approach utilizes an XNOR operation in conjunction with the shift method to find the instance of a query. We validated it through experiments finding improvement against other methods.",2020,"[{'authorId': '48427141', 'name': 'Michael Olson'}, {'authorId': '2083440459', 'name': 'Daniel Davis'}, {'authorId': '2155778486', 'name': 'Jae Woong Lee'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3443279.3443296?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3443279.3443296, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","searching data is a natural behavior of humankind and is also a fundamental operation in both industrial and academic areas. there has been research into developing sophisticated methods and techniques for string searching. the common method is to make use of prefixes and suffixes to move through the text while searching a string query in a text. it suffers from high computational complexity since it has to repeatedly search each character in the string query sequentially. in this paper, we address the difficulty and propose a novel approach that enables a parallel search of the text without indexing the text or the query which is needed for sequential search. the proposed approach utilizes an xnor operation in conjunction with the shift method to find the instance of a query. we validated it through experiments finding improvement against other methods.",
111a2c6a717bc382513260720939fd4c7eeb65d5,A semi-supervised approach for author disambiguation in KDD CUP 2013,"Name disambiguation, which aims to identify multiple names which correspond to one person and same names which refer to different persons, is one of the most important basic problems in many areas such as natural language processing, information retrieval and digital libraries. Microsoft academic search data in KDD Cup 2013 Track 2 task brings one such challenge to the researchers in the knowledge discovery and data mining community. Besides the real-world and large-scale characteristic, the Track 2 task raises several challenges: (1) Consideration of both synonym and polysemy problems; (2) Existence of huge amount of noisy data with missing attributes; (3) Absence of labeled data that makes this challenge a cold start problem.
 In this paper, we describe our solution to Track 2 of KDD Cup 2013. The challenge of this track is author disambiguation, which aims at identifying whether authors are the same person by using academic publication data. We propose a multi-phase semi-supervised approach to deal with the challenge. First, we preprocess the dataset and generate features for models, then construct a coauthor-based network and employ community detection to accomplish first-phase disambiguation task, which handles the cold-start problem. Second, using results in first phase, we use support vector machine and various other models to utilize noisy data with missing attributes in the dataset. Further, we propose a self-taught procedure to solve ambiguity in coauthor information, boosting performance of results from other models. Finally, by blending results from different models, we finally achieves 6th place with 0.98717 mean F-score on public leaderboard and 7th place with 0.98651 mean F-score on private leaderboard.",2013,"[{'authorId': None, 'name': 'Jianyu Zhao'}, {'authorId': '2155300106', 'name': 'Peng Wang'}, {'authorId': '2112769298', 'name': 'Kai Huang'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/2517288.2517298?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2517288.2517298, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","name disambiguation, which aims to identify multiple names which correspond to one person and same names which refer to different persons, is one of the most important basic problems in many areas such as natural language processing, information retrieval and digital libraries. microsoft academic search data in kdd cup 2013 track 2 task brings one such challenge to the researchers in the knowledge discovery and data mining community. besides the real-world and large-scale characteristic, the track 2 task raises several challenges: (1) consideration of both synonym and polysemy problems; (2) existence of huge amount of noisy data with missing attributes; (3) absence of labeled data that makes this challenge a cold start problem. in this paper, we describe our solution to track 2 of kdd cup 2013. the challenge of this track is author disambiguation, which aims at identifying whether authors are the same person by using academic publication data. we propose a multi-phase semi-supervised approach to deal with the challenge. first, we preprocess the dataset and generate features for models, then construct a coauthor-based network and employ community detection to accomplish first-phase disambiguation task, which handles the cold-start problem. second, using results in first phase, we use support vector machine and various other models to utilize noisy data with missing attributes in the dataset. further, we propose a self-taught procedure to solve ambiguity in coauthor information, boosting performance of results from other models. finally, by blending results from different models, we finally achieves 6th place with 0.98717 mean f-score on public leaderboard and 7th place with 0.98651 mean f-score on private leaderboard.",
3a1247225c1561e67669317a817f1a70fd0b4087,Serving the readers of scholarly documents: A grand challenge for the introspective digital library,"The scholarly literature produced by human civilization will soon be considered small data, able to be portably conveyed by the network and carried on personal machines. This semi-structured text centric knowledge base is a focus of attention for scholars, as the wealth of facts, facets and connections in scholarly documents are large. Such machine analysis can derive insights that can inform policy makers, academic and industrial management, as well as scholars as authors themselves. There is another underserved community of scholarly document users that has been overlooked: the readers themselves. I call for the community to put more efforts towards supporting our own scholars (especially beginning scholars, new to the research process) with automation from information retrieval and natural language processing. Techniques that mine information from within the full text of a document could be used to introspect a digital library's materials, inferring better search metadata, improving scholarly document recommendation, and aiding the understanding of the text, figures, presentations and citations of our scholarly literature. Such an introspective digital library will enable scholars to assemble an understanding of other scholars' work more efficiently, and provide downstream machine reading applications with input for their analytics.",2015,"[{'authorId': '37596605', 'name': 'Min-Yen Kan'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/35021BIGCOMP.2015.7072807?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/35021BIGCOMP.2015.7072807, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the scholarly literature produced by human civilization will soon be considered small data, able to be portably conveyed by the network and carried on personal machines. this semi-structured text centric knowledge base is a focus of attention for scholars, as the wealth of facts, facets and connections in scholarly documents are large. such machine analysis can derive insights that can inform policy makers, academic and industrial management, as well as scholars as authors themselves. there is another underserved community of scholarly document users that has been overlooked: the readers themselves. i call for the community to put more efforts towards supporting our own scholars (especially beginning scholars, new to the research process) with automation from information retrieval and natural language processing. techniques that mine information from within the full text of a document could be used to introspect a digital library's materials, inferring better search metadata, improving scholarly document recommendation, and aiding the understanding of the text, figures, presentations and citations of our scholarly literature. such an introspective digital library will enable scholars to assemble an understanding of other scholars' work more efficiently, and provide downstream machine reading applications with input for their analytics.",
d81129e100d9a710424603ecb61a6f9f8c179e1f,A Comprehensive NLP System for Modern Standard Arabic and Modern Hebrew,"This paper presents a comprehensive NLP system by Melingo that has been recently developed for Arabic, based on Morfix™ - an operational formerly developed highly successful comprehensive Hebrew NLP system.The system discussed includes modules for morphological analysis, context sensitive lemmatization, vocalization, text-to-phoneme conversion, and syntactic-analysis-based prosody (intonation) model. It is employed in applications such as full text search, information retrieval, text categorization, textual data mining, online contextual dictionaries, filtering, and text-to-speech applications in the fields of telephony and accessibility and could serve as a handy accessory for non-fluent Arabic or Hebrew speakers.Modern Hebrew and Modern Standard Arabic share some unique Semitic linguistic characteristics. Yet up to now, the two languages have been handled separately in Natural Language Processing circles, both on the academic and on the applicative levels. This paper reviews the major similarities and the minor dissimilarities between Modern Hebrew and Modern Standard Arabic from the NLP standpoint, and emphasizes the benefit of developing and maintaining a unified system for both languages.",2002,"[{'authorId': '40692384', 'name': 'Dror Kamir'}, {'authorId': '102304898', 'name': 'N. Soreq'}, {'authorId': '40701361', 'name': 'Yoni Neeman'}]","{'url': 'https://dl.acm.org/doi/pdf/10.3115/1118637.1118646', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://aclanthology.org/W02-0509, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper presents a comprehensive nlp system by melingo that has been recently developed for arabic, based on morfix™ - an operational formerly developed highly successful comprehensive hebrew nlp system.the system discussed includes modules for morphological analysis, context sensitive lemmatization, vocalization, text-to-phoneme conversion, and syntactic-analysis-based prosody (intonation) model. it is employed in applications such as full text search, information retrieval, text categorization, textual data mining, online contextual dictionaries, filtering, and text-to-speech applications in the fields of telephony and accessibility and could serve as a handy accessory for non-fluent arabic or hebrew speakers.modern hebrew and modern standard arabic share some unique semitic linguistic characteristics. yet up to now, the two languages have been handled separately in natural language processing circles, both on the academic and on the applicative levels. this paper reviews the major similarities and the minor dissimilarities between modern hebrew and modern standard arabic from the nlp standpoint, and emphasizes the benefit of developing and maintaining a unified system for both languages.",https://dl.acm.org/doi/pdf/10.3115/1118637.1118646
d58f323dcbe079e8158baf1bf59f757aaadd733e,Improving research paper searching with social tagging — A preliminary investigation,"The WWW provides an efficient way to store and share information. Search engines and social bookmarking systems are important tools for web resource discovery. This study investigated three different indexing approaches applied to CiteULike — a social bookmarking system for tagging academic research papers. The indexing approaches here are known as: Tag only; Title with Abstract; and Tag, Title with Abstract. These three indexing approaches were evaluated using mean values of Normalized Discount Cumulative Gain (NDCG). The preliminary results illustrated that indexing using “Tag, Title, with Abstract” performed the best. The initial evaluation on our implementation implied that these designs might improve the accuracy and efficiency of web resource searching on social bookmarking system, not only in academics but also in other domains.",2009,"[{'authorId': '3033198', 'name': 'P. Jomsri'}, {'authorId': '1810884', 'name': 'S. Sanguansintukul'}, {'authorId': '2770516', 'name': 'W. Choochaiwattana'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/SNLP.2009.5340927?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SNLP.2009.5340927, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the www provides an efficient way to store and share information. search engines and social bookmarking systems are important tools for web resource discovery. this study investigated three different indexing approaches applied to citeulike — a social bookmarking system for tagging academic research papers. the indexing approaches here are known as: tag only; title with abstract; and tag, title with abstract. these three indexing approaches were evaluated using mean values of normalized discount cumulative gain (ndcg). the preliminary results illustrated that indexing using “tag, title, with abstract” performed the best. the initial evaluation on our implementation implied that these designs might improve the accuracy and efficiency of web resource searching on social bookmarking system, not only in academics but also in other domains.",
deb4d895c0977c4703734eeb900d1f055580ebd0,NTU corpus of Formosan languages: A state-of-the-art report,"The NTU Corpus of Formosan Languages (http://corpus.linguistics.ntu.edu .tw) started as one of the sub-projects of the Multimedia Laboratory established by the Center for Information and ElectronicsTechnologies.The corpus integrates the professional and academic works of various departments and colleges1 at National Taiwan University, with a view to establish a standard for the creation of linguistic corpora databases through the application of information technology on linguistics research. The development of natural language processing techniques and dynamic web technology has generated wide interest in the construction of an integrated platform which enables people to submit, browse and search among collected texts against established corpora. For seriously endangered languages, corpus documentation plays a crucial role in preserving the precious linguistic and cultural data. The NTU Corpus of Formosan Languages is constructed for the purpose of preserving Austronesian Languages spoken in Taiwan, many of which are on the verge of extinction. It is the result of our effort in providing a multilingual on-line corpus with multimedia capability to meet the needs of both linguists and those interested. It features: (i) discourse-oriented documentation that goes beyond sentential level, (ii) retrieval with cross-referencing capability, (iii) ethnolinguistic notes preserving precious cultural information, and (iv) multi-media data with interoperability with different systems for the greatest interest of the users. To record faithfully discourse data collected, we incorporate in our corpus interactional linguistic features such as pauses, hesitations, fillers, repetitions, false starts etc.Approaching language from a functional approach, we believe linguistic features as such are non-trivial in that they may reveal cognitively and psychologically important details of language in use. Investigating spoken data in natural context makes it possible for us to explore issues beyond the scope offered by the traditional syntactic studies. For example, linguistic",2008,"[{'authorId': '70971686', 'name': 'L. Su'}, {'authorId': '40071178', 'name': 'Li-May Sung'}, {'authorId': '2118018561', 'name': 'Shuping Huang'}, {'authorId': '1901699', 'name': 'Fuhui Hsieh'}, {'authorId': '2112753776', 'name': 'Zhemin Lin'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1515/CLLT.2008.012?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1515/CLLT.2008.012, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the ntu corpus of formosan languages (http://corpus.linguistics.ntu.edu .tw) started as one of the sub-projects of the multimedia laboratory established by the center for information and electronicstechnologies.the corpus integrates the professional and academic works of various departments and colleges1 at national taiwan university, with a view to establish a standard for the creation of linguistic corpora databases through the application of information technology on linguistics research. the development of natural language processing techniques and dynamic web technology has generated wide interest in the construction of an integrated platform which enables people to submit, browse and search among collected texts against established corpora. for seriously endangered languages, corpus documentation plays a crucial role in preserving the precious linguistic and cultural data. the ntu corpus of formosan languages is constructed for the purpose of preserving austronesian languages spoken in taiwan, many of which are on the verge of extinction. it is the result of our effort in providing a multilingual on-line corpus with multimedia capability to meet the needs of both linguists and those interested. it features: (i) discourse-oriented documentation that goes beyond sentential level, (ii) retrieval with cross-referencing capability, (iii) ethnolinguistic notes preserving precious cultural information, and (iv) multi-media data with interoperability with different systems for the greatest interest of the users. to record faithfully discourse data collected, we incorporate in our corpus interactional linguistic features such as pauses, hesitations, fillers, repetitions, false starts etc.approaching language from a functional approach, we believe linguistic features as such are non-trivial in that they may reveal cognitively and psychologically important details of language in use. investigating spoken data in natural context makes it possible for us to explore issues beyond the scope offered by the traditional syntactic studies. for example, linguistic",
8df523cc42d90ad916fcb9365a8f2e81346f33fc,Session 12: Information Retrieval,"Research in information retrieval is enjoying renewed interest by many different communities. Commercial retrieval systems, which in the past have concentrated on Boolean pat tern matching methodologies, are beginning to look into more sophist icated search methods, including complex stat istical and /o r natural language processing systems. This has spurred new interest in research in information retrieval in this community and also in the academic communities. Technology is being addit ionally pushed by the current emphasis on electronic communication, including digital libraries and the interlinking of oflices to allow ofrice automation. The availability of electronic text records in huge (and exponentially-growing) quantities, and the rapidly-expanding Internet access by potent ial users, is a third factor in promoting research. ARPA has contr ibuted to this increased interest by sponsoring a new test collection for information retrieval. The widespread availability of the T I P S T E R collection has allowed research on large-scale, real-world retrieval problems. This has not only opened up new areas of research tha t were not discovered using the smMler test collections, but has provided proof tha t the more complex retrieval systems do indeed scale up to handle realistic text collections. The first paper in this session, ""Overview of the Second Text Retrieval Conference (TREC-2) ' , by Donna Harman, i l lustrates the use of this collection in a massive crosssystem evaluation. The TREC-2 conference, held in August of 1993, compared results from 31 different retrieval systems working with the T I P S T E R collection. These systems used many different approaches to retrieval, including manually constructed patterns, automatical ly constructed stat is t ical queries that were input to stat ist ical retrieval systems, and natural language approaches to information retrieval. The paper discusses the T I P S T E R test collection, the evaluation methods used in TREC, and the results from the conference. The next two papers in the session represent systems that appeared in TREG-2. The first of these papers discusses a mostly stat is t ical system and the second of these papers discusses a system using natural language processing techniques. The paper ""Learning from Relevant Documents in Large Scale Routing Retrieval"", by K.L. Kwok and L. Grunfeld, discusses experiments performed using a routing or filtering paradigm. This type of information retrieval assumes that users have a s tanding request for information, such as in an electronic dissemination service or an intelligence operation. There exists training information in the form of previously-seen documents considered relevant, and this training information is used to produce bet ter queries. This paper discusses in detail the problems of learning from fulltext relevant documents, which range in length from a short paragraph to many hundreds of pages. This problem is compounded by the availabili ty of large numbers of such relevant documents. Many experiments were performed to discover the opt imal method of selecting which (and what parts) of documents to use for training, and the results are given in the paper. The next paper, ""Document Representat ion in Natural Language Text Retrieval"", by Tomek Strzalkowski, discusses experiments performed using mostly the adhoc retrieval paradigm. In this case the documents are known in advance, but the information is requested on an ""adhoc"" basis. There is no training data , and systems are often required to deal with short user requests that might not map well onto the terminology used in the documents. One way around this problem is to automatical ly transform the user query into a linguistic s tructure that is expanded to bet ter map into the document collection. This paper presents a series of experiments in automatical ly locating useful lingulstic fragments of documents to match against such a modified user query. One of the main issues dealt with here is the correct term weighting for these fragments. Information retrieval is not l imited to the matching of textual material; two of the papers in the session deal with speech retrieval systems. The first of these papers describes a modification of t radi t ional information retrieval methods to handle speech, whereas the second paper uses t radi t ional speech recognition technology with information retrieval as the application. The paper, ""Assessing the Retrieval Effectiveness of a Speech Retrieval System by Simulating Recognition Errors"", by Peter Schauble and Ulrike Glavltsch, deals with retrieval of speech (speech ""documents""). Their retrieval system uses phonetically motivated subword units as opposed to complete words for indexing of speech. The use of subwords as index terms means tha t the system can be used against either speech or text, and that techniques tradit ionally used in text retrieval can be modified for use with speech. The production of these subwords is dependent on current speech recognition technology, which is known to be error-prone. This paper presents some experiments using simulated speech recognition errors against well-known information retrieval test collections (textual) to see what effects these errors have on retrieval performance. The second of these papers, ""Speech-Based Retrieval using Semantic Co-Occurrence Fil tering"", by Julian Kupiec, Don Kimber, and Vijay Balasubramanian, uses a s tandard hidden Markov model as input to a text retrieval system. The issue in this paper is how to deal with the very large (generally unrestricted) vocabulary size that is normal for most text retrieval applications. Speech input using large vocabularies (and possibly many different speakers) is likely",1994,"[{'authorId': '144169170', 'name': 'D. Harman'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://aclanthology.org/H94-1069, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","research in information retrieval is enjoying renewed interest by many different communities. commercial retrieval systems, which in the past have concentrated on boolean pat tern matching methodologies, are beginning to look into more sophist icated search methods, including complex stat istical and /o r natural language processing systems. this has spurred new interest in research in information retrieval in this community and also in the academic communities. technology is being addit ionally pushed by the current emphasis on electronic communication, including digital libraries and the interlinking of oflices to allow ofrice automation. the availability of electronic text records in huge (and exponentially-growing) quantities, and the rapidly-expanding internet access by potent ial users, is a third factor in promoting research. arpa has contr ibuted to this increased interest by sponsoring a new test collection for information retrieval. the widespread availability of the t i p s t e r collection has allowed research on large-scale, real-world retrieval problems. this has not only opened up new areas of research tha t were not discovered using the smmler test collections, but has provided proof tha t the more complex retrieval systems do indeed scale up to handle realistic text collections. the first paper in this session, ""overview of the second text retrieval conference (trec-2) ' , by donna harman, i l lustrates the use of this collection in a massive crosssystem evaluation. the trec-2 conference, held in august of 1993, compared results from 31 different retrieval systems working with the t i p s t e r collection. these systems used many different approaches to retrieval, including manually constructed patterns, automatical ly constructed stat is t ical queries that were input to stat ist ical retrieval systems, and natural language approaches to information retrieval. the paper discusses the t i p s t e r test collection, the evaluation methods used in trec, and the results from the conference. the next two papers in the session represent systems that appeared in treg-2. the first of these papers discusses a mostly stat is t ical system and the second of these papers discusses a system using natural language processing techniques. the paper ""learning from relevant documents in large scale routing retrieval"", by k.l. kwok and l. grunfeld, discusses experiments performed using a routing or filtering paradigm. this type of information retrieval assumes that users have a s tanding request for information, such as in an electronic dissemination service or an intelligence operation. there exists training information in the form of previously-seen documents considered relevant, and this training information is used to produce bet ter queries. this paper discusses in detail the problems of learning from fulltext relevant documents, which range in length from a short paragraph to many hundreds of pages. this problem is compounded by the availabili ty of large numbers of such relevant documents. many experiments were performed to discover the opt imal method of selecting which (and what parts) of documents to use for training, and the results are given in the paper. the next paper, ""document representat ion in natural language text retrieval"", by tomek strzalkowski, discusses experiments performed using mostly the adhoc retrieval paradigm. in this case the documents are known in advance, but the information is requested on an ""adhoc"" basis. there is no training data , and systems are often required to deal with short user requests that might not map well onto the terminology used in the documents. one way around this problem is to automatical ly transform the user query into a linguistic s tructure that is expanded to bet ter map into the document collection. this paper presents a series of experiments in automatical ly locating useful lingulstic fragments of documents to match against such a modified user query. one of the main issues dealt with here is the correct term weighting for these fragments. information retrieval is not l imited to the matching of textual material; two of the papers in the session deal with speech retrieval systems. the first of these papers describes a modification of t radi t ional information retrieval methods to handle speech, whereas the second paper uses t radi t ional speech recognition technology with information retrieval as the application. the paper, ""assessing the retrieval effectiveness of a speech retrieval system by simulating recognition errors"", by peter schauble and ulrike glavltsch, deals with retrieval of speech (speech ""documents""). their retrieval system uses phonetically motivated subword units as opposed to complete words for indexing of speech. the use of subwords as index terms means tha t the system can be used against either speech or text, and that techniques tradit ionally used in text retrieval can be modified for use with speech. the production of these subwords is dependent on current speech recognition technology, which is known to be error-prone. this paper presents some experiments using simulated speech recognition errors against well-known information retrieval test collections (textual) to see what effects these errors have on retrieval performance. the second of these papers, ""speech-based retrieval using semantic co-occurrence fil tering"", by julian kupiec, don kimber, and vijay balasubramanian, uses a s tandard hidden markov model as input to a text retrieval system. the issue in this paper is how to deal with the very large (generally unrestricted) vocabulary size that is normal for most text retrieval applications. speech input using large vocabularies (and possibly many different speakers) is likely",
aaa971c619766f9445c223a22783dab303b7d526,A Comparative Analysis of Generative Artificial Intelligence Tools for Natural Language Processing,"Generative artificial intelligence tools have recently attracted a great deal of attention. This is because of their huge advantages, which include ease of usage, quick generation of answers to requests, and the human-like intelligence they possess. This paper presents a vivid comparative analysis of the top 9 generative artificial intelligence (AI) tools, namely ChatGPT, Perplexity AI, YouChat, ChatSonic, Google's Bard, Microsoft Bing Assistant, HuggingChat, Jasper AI, and Quora's Poe, paying attention to the Pros and Cons each of the AI tools presents. This comparative analysis shows that the generative AI tools have several Pros that outweigh the Cons. Further, we explore the transformative impact of generative AI in Natural Language Processing (NLP), focusing on its integration with search engines, privacy concerns, and ethical implications. A comparative analysis categorizes generative AI tools based on popularity and evaluates challenges in development, including data limitations and computational costs. The study highlights ethical considerations such as technology misuse and regulatory challenges. Additionally, we delved into AI Planning techniques in NLP, covering classical planning, probabilistic planning, hierarchical planning, temporal planning, knowledge-driven planning, and neural planning models. These planning approaches are vital in achieving specific goals in NLP tasks. In conclusion, we provide a concise overview of the current state of generative AI, including its challenges, ethical considerations, and potential applications, contributing to the academic discourse on human-computer interaction.  ",2024,"[{'authorId': '84013024', 'name': 'A. Iorliam'}, {'authorId': '2289408364', 'name': 'Joseph Abunimye Ingio'}]","{'url': 'https://publikasi.dinus.ac.id/index.php/jcta/article/download/9447/4379', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.62411/jcta.9447?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.62411/jcta.9447, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative artificial intelligence tools have recently attracted a great deal of attention. this is because of their huge advantages, which include ease of usage, quick generation of answers to requests, and the human-like intelligence they possess. this paper presents a vivid comparative analysis of the top 9 generative artificial intelligence (ai) tools, namely chatgpt, perplexity ai, youchat, chatsonic, google's bard, microsoft bing assistant, huggingchat, jasper ai, and quora's poe, paying attention to the pros and cons each of the ai tools presents. this comparative analysis shows that the generative ai tools have several pros that outweigh the cons. further, we explore the transformative impact of generative ai in natural language processing (nlp), focusing on its integration with search engines, privacy concerns, and ethical implications. a comparative analysis categorizes generative ai tools based on popularity and evaluates challenges in development, including data limitations and computational costs. the study highlights ethical considerations such as technology misuse and regulatory challenges. additionally, we delved into ai planning techniques in nlp, covering classical planning, probabilistic planning, hierarchical planning, temporal planning, knowledge-driven planning, and neural planning models. these planning approaches are vital in achieving specific goals in nlp tasks. in conclusion, we provide a concise overview of the current state of generative ai, including its challenges, ethical considerations, and potential applications, contributing to the academic discourse on human-computer interaction.",https://publikasi.dinus.ac.id/index.php/jcta/article/download/9447/4379
712aa254275c8d888f73f3fe65f83ef0bce76271,We are Who We Cite: Bridges of Influence Between Natural Language Processing and Other Academic Fields,"Natural Language Processing (NLP) is poised to substantially influence the world. However, significant progress comes hand-in-hand with substantial risks. Addressing them requires broad engagement with various fields of study. Yet, little empirical work examines the state of such engagement (past or current). In this paper, we quantify the degree of influence between 23 fields of study and NLP (on each other). We analyzed ~77k NLP papers, ~3.1m citations from NLP papers to other papers, and ~1.8m citations from other papers to NLP papers. We show that, unlike most fields, the cross-field engagement of NLP, measured by our proposed Citation Field Diversity Index (CFDI), has declined from 0.58 in 1980 to 0.31 in 2022 (an all-time low). In addition, we find that NLP has grown more insular -- citing increasingly more NLP papers and having fewer papers that act as bridges between fields. NLP citations are dominated by computer science; Less than 8% of NLP citations are to linguistics, and less than 3% are to math and psychology. These findings underscore NLP's urgent need to reflect on its engagement with various fields.",2023,"[{'authorId': '2056772135', 'name': 'Jan Philip Wahle'}, {'authorId': '2261364222', 'name': 'Terry Ruas'}, {'authorId': '2283931971', 'name': 'Mohamed Abdalla'}, {'authorId': '2261364118', 'name': 'Bela Gipp'}, {'authorId': '2261458500', 'name': 'Saif Mohammad'}]","{'url': 'https://aclanthology.org/2023.emnlp-main.797.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2310.14870, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","natural language processing (nlp) is poised to substantially influence the world. however, significant progress comes hand-in-hand with substantial risks. addressing them requires broad engagement with various fields of study. yet, little empirical work examines the state of such engagement (past or current). in this paper, we quantify the degree of influence between 23 fields of study and nlp (on each other). we analyzed ~77k nlp papers, ~3.1m citations from nlp papers to other papers, and ~1.8m citations from other papers to nlp papers. we show that, unlike most fields, the cross-field engagement of nlp, measured by our proposed citation field diversity index (cfdi), has declined from 0.58 in 1980 to 0.31 in 2022 (an all-time low). in addition, we find that nlp has grown more insular -- citing increasingly more nlp papers and having fewer papers that act as bridges between fields. nlp citations are dominated by computer science; less than 8% of nlp citations are to linguistics, and less than 3% are to math and psychology. these findings underscore nlp's urgent need to reflect on its engagement with various fields.",https://aclanthology.org/2023.emnlp-main.797.pdf
48167fbde4ef8d5caa69e1c0c9d6e2ac7fd48c3b,NAS-Bench-NLP: Neural Architecture Search Benchmark for Natural Language Processing,"Neural Architecture Search (NAS) is a promising and rapidly evolving research area. Training a large number of neural networks requires an exceptional amount of computational power, which makes NAS unreachable for those researchers who have limited or no access to high-performance clusters and supercomputers. A few benchmarks with precomputed neural architectures performances have been recently introduced to overcome this problem and ensure reproducible experiments. However, these benchmarks are only for the computer vision domain and, thus, are built from the image datasets and convolution-derived architectures. In this work, we step outside the computer vision domain by leveraging the language modeling task, which is the core of natural language processing (NLP). Our main contribution is as follows: we have provided search space of recurrent neural networks on the text datasets and trained 14k architectures within it; we have conducted both intrinsic and extrinsic evaluation of the trained models using datasets for semantic relatedness and language understanding evaluation; finally, we have tested several NAS algorithms to demonstrate how the precomputed results can be utilized. We consider that the benchmark will provide more reliable empirical findings in the community and stimulate progress in developing new NAS methods well suited for recurrent architectures.",2020,"[{'authorId': '143888131', 'name': 'Nikita Klyuchnikov'}, {'authorId': '144035647', 'name': 'I. Trofimov'}, {'authorId': '13033978', 'name': 'E. Artemova'}, {'authorId': '49614468', 'name': 'Mikhail Salnikov'}, {'authorId': '143954683', 'name': 'M. Fedorov'}, {'authorId': '51139941', 'name': 'Evgeny Burnaev'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/9668973/09762315.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2006.07116, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","neural architecture search (nas) is a promising and rapidly evolving research area. training a large number of neural networks requires an exceptional amount of computational power, which makes nas unreachable for those researchers who have limited or no access to high-performance clusters and supercomputers. a few benchmarks with precomputed neural architectures performances have been recently introduced to overcome this problem and ensure reproducible experiments. however, these benchmarks are only for the computer vision domain and, thus, are built from the image datasets and convolution-derived architectures. in this work, we step outside the computer vision domain by leveraging the language modeling task, which is the core of natural language processing (nlp). our main contribution is as follows: we have provided search space of recurrent neural networks on the text datasets and trained 14k architectures within it; we have conducted both intrinsic and extrinsic evaluation of the trained models using datasets for semantic relatedness and language understanding evaluation; finally, we have tested several nas algorithms to demonstrate how the precomputed results can be utilized. we consider that the benchmark will provide more reliable empirical findings in the community and stimulate progress in developing new nas methods well suited for recurrent architectures.",https://ieeexplore.ieee.org/ielx7/6287639/9668973/09762315.pdf
d0d8b42f3e8ed1dabde40020bb46eafcd5cbafad,A Study of Query Expansion Strategies Effectiveness based on Natural Language Processing,"The Information Retrieval (IR) process starts with the query entered by the user in the system. The IR system is mostly used in the search string in text utilities and web search engines. For IR algorithms to efficiently retrieve pertinent documents, the documents are usually converted into an appropriate representation. Query expansion and Natural Language Processing (NLP) are the most researched fields in Artificial Intelligence (AI). The query expansion process provides the additional information that is understood by the user in their query. This research study explores several NLP query expansion techniques that utilize word embedding methods for autonomous query expansion including deep learning, machine learning, and ontology approach. This research also discusses the importance of query expansion to improve search efficacy and provides a coherent view of NLP-based query expansion methods that leverage a range of data sources and methodologies.",2024,"[{'authorId': '2279920431', 'name': 'Hemendra Shanker Sharma'}, {'authorId': '2320726994', 'name': 'Ashish Sharma'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICIPCN63822.2024.00055?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICIPCN63822.2024.00055, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the information retrieval (ir) process starts with the query entered by the user in the system. the ir system is mostly used in the search string in text utilities and web search engines. for ir algorithms to efficiently retrieve pertinent documents, the documents are usually converted into an appropriate representation. query expansion and natural language processing (nlp) are the most researched fields in artificial intelligence (ai). the query expansion process provides the additional information that is understood by the user in their query. this research study explores several nlp query expansion techniques that utilize word embedding methods for autonomous query expansion including deep learning, machine learning, and ontology approach. this research also discusses the importance of query expansion to improve search efficacy and provides a coherent view of nlp-based query expansion methods that leverage a range of data sources and methodologies.",
63d7a7273078dd051b63d1aa1db2cb967b9b2efa,Using Natural Language Processing to Evaluate the Quality of Supervisor Narrative Comments in Competency-Based Medical Education,"Abstract Purpose Learner development and promotion rely heavily on narrative assessment comments, but narrative assessment quality is rarely evaluated in medical education. Educators have developed tools such as the Quality of Assessment for Learning (QuAL) tool to evaluate the quality of narrative assessment comments; however, scoring the comments generated in medical education assessment programs is time intensive. The authors developed a natural language processing (NLP) model for applying the QuAL score to narrative supervisor comments. Method Samples of 2,500 Entrustable Professional Activities assessments were randomly extracted and deidentified from the McMaster (1,250 comments) and Saskatchewan (1,250 comments) emergency medicine (EM) residency training programs during the 2019–2020 academic year. Comments were rated using the QuAL score by 25 EM faculty members and 25 EM residents. The results were used to develop and test an NLP model to predict the overall QuAL score and QuAL subscores. Results All 50 raters completed the rating exercise. Approximately 50% of the comments had perfect agreement on the QuAL score, with the remaining resolved by the study authors. Creating a meaningful suggestion for improvement was the key differentiator between high- and moderate-quality feedback. The overall QuAL model predicted the exact human-rated score or 1 point above or below it in 87% of instances. Overall model performance was excellent, especially regarding the subtasks on suggestions for improvement and the link between resident performance and improvement suggestions, which achieved 85% and 82% balanced accuracies, respectively. Conclusions This model could save considerable time for programs that want to rate the quality of supervisor comments, with the potential to automatically score a large volume of comments. This model could be used to provide faculty with real-time feedback or as a tool to quantify and track the quality of assessment comments at faculty, rotation, program, or institution levels.",2024,"[{'authorId': '3466526', 'name': 'Maxwell T. Spadafore'}, {'authorId': '1990649554', 'name': 'Y. Yılmaz'}, {'authorId': '2279792713', 'name': 'Veronica Rally'}, {'authorId': '2275224002', 'name': 'Teresa M. Chan'}, {'authorId': '2060635604', 'name': 'Mackenzie Russell'}, {'authorId': '2257647050', 'name': 'Brent Thoma'}, {'authorId': '2108519962', 'name': 'S. Singh'}, {'authorId': '2272033552', 'name': 'Sandra Monteiro'}, {'authorId': '9564437', 'name': 'A. Pardhan'}, {'authorId': '2279797190', 'name': 'Lynsey Martin'}, {'authorId': '3946095', 'name': 'S. Monrad'}, {'authorId': '2240657775', 'name': 'Rob Woods'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1097/ACM.0000000000005634?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1097/ACM.0000000000005634, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract purpose learner development and promotion rely heavily on narrative assessment comments, but narrative assessment quality is rarely evaluated in medical education. educators have developed tools such as the quality of assessment for learning (qual) tool to evaluate the quality of narrative assessment comments; however, scoring the comments generated in medical education assessment programs is time intensive. the authors developed a natural language processing (nlp) model for applying the qual score to narrative supervisor comments. method samples of 2,500 entrustable professional activities assessments were randomly extracted and deidentified from the mcmaster (1,250 comments) and saskatchewan (1,250 comments) emergency medicine (em) residency training programs during the 2019–2020 academic year. comments were rated using the qual score by 25 em faculty members and 25 em residents. the results were used to develop and test an nlp model to predict the overall qual score and qual subscores. results all 50 raters completed the rating exercise. approximately 50% of the comments had perfect agreement on the qual score, with the remaining resolved by the study authors. creating a meaningful suggestion for improvement was the key differentiator between high- and moderate-quality feedback. the overall qual model predicted the exact human-rated score or 1 point above or below it in 87% of instances. overall model performance was excellent, especially regarding the subtasks on suggestions for improvement and the link between resident performance and improvement suggestions, which achieved 85% and 82% balanced accuracies, respectively. conclusions this model could save considerable time for programs that want to rate the quality of supervisor comments, with the potential to automatically score a large volume of comments. this model could be used to provide faculty with real-time feedback or as a tool to quantify and track the quality of assessment comments at faculty, rotation, program, or institution levels.",
bbbf70edc1232ae341c9062c7cbb9626536972ec,A Complexity-Aware Web Searching Paradigm to Improve User Productivity using Natural Language Processing and the DistilBERT Transformer Model,"Search engines (Google search, Bing search, etc.) have had great success over the past decade, promoting productivity in almost every area. Based on user inputs, search engines are able to present users with lists of related contents (links) and previews. More recently, high-level human-like responses combining various searched contents are being made possible due to recent advancements in large language models (LLM). However, oftentimes, users still find it still hard to quickly navigate to the contents they really look for and demand a better searching framework. For example, some users might waste time skimming through lots of technical details when they just hope to have an overview. We examine this user demand and believe a complexity-aware pipeline could greatly help with this inconvenience. More specifically, we propose a searching paradigm that analyzes results from standard search engines by their complexities first, and then present users with complexity-labeled contents through a new user interface design. Through this new searching paradigm, we aim to present users with more customized search results sorted by their complexity labels with consideration to user intent, whether that would be a high-level overview or a detailed technical inspection. This is done through utilizing state-of-the-art transformer models fine-tuned on our custom-made dataset and modified for our intent.",2024,"[{'authorId': '2311999683', 'name': 'Ruiyi Zhang'}, {'authorId': '2305279710', 'name': 'Carlos Gonzalez'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5121/csit.2024.141004?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5121/csit.2024.141004, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","search engines (google search, bing search, etc.) have had great success over the past decade, promoting productivity in almost every area. based on user inputs, search engines are able to present users with lists of related contents (links) and previews. more recently, high-level human-like responses combining various searched contents are being made possible due to recent advancements in large language models (llm). however, oftentimes, users still find it still hard to quickly navigate to the contents they really look for and demand a better searching framework. for example, some users might waste time skimming through lots of technical details when they just hope to have an overview. we examine this user demand and believe a complexity-aware pipeline could greatly help with this inconvenience. more specifically, we propose a searching paradigm that analyzes results from standard search engines by their complexities first, and then present users with complexity-labeled contents through a new user interface design. through this new searching paradigm, we aim to present users with more customized search results sorted by their complexity labels with consideration to user intent, whether that would be a high-level overview or a detailed technical inspection. this is done through utilizing state-of-the-art transformer models fine-tuned on our custom-made dataset and modified for our intent.",
6f712dfd414b76518fbaeb401d849579b540404c,Using natural language processing in emergency medicine health service research: A systematic review and meta-analysis.,"OBJECTIVES
Natural language processing (NLP) represents one of the adjunct technologies within artificial intelligence and machine learning, creating structure out of unstructured data. This study aims to assess the performance of employing NLP to identify and categorize unstructured data within the emergency medicine (EM) setting.


METHODS
We systematically searched publications related to EM research and NLP across databases including MEDLINE, Embase, Scopus, CENTRAL, and ProQuest Dissertations & Theses Global. Independent reviewers screened, reviewed, and evaluated article quality and bias. NLP usage was categorized into syndromic surveillance, radiologic interpretation, and identification of specific diseases/events/syndromes, with respective sensitivity analysis reported. Performance metrics for NLP usage were calculated and the overall area under the summary of receiver operating characteristic curve (SROC) was determined.


RESULTS
A total of 27 studies underwent meta-analysis. Findings indicated an overall mean sensitivity (recall) of 82%-87%, specificity of 95%, with the area under the SROC at 0.96 (95% CI 0.94-0.98). Optimal performance using NLP was observed in radiologic interpretation, demonstrating an overall mean sensitivity of 93% and specificity of 96%.


CONCLUSIONS
Our analysis revealed a generally favorable performance accuracy in using NLP within EM research, particularly in the realm of radiologic interpretation. Consequently, we advocate for the adoption of NLP-based research to augment EM health care management.",2024,"[{'authorId': '2274194202', 'name': 'Hao Wang'}, {'authorId': '1409447224', 'name': 'Naomi Alanis'}, {'authorId': '2301563336', 'name': 'Laura Haygood'}, {'authorId': '2274083716', 'name': 'Thomas K. Swoboda'}, {'authorId': '2301558964', 'name': 'Nathan Hoot'}, {'authorId': '2301559914', 'name': 'Daniel Phillips'}, {'authorId': '73771091', 'name': 'Heidi C. Knowles'}, {'authorId': '2301563730', 'name': 'Sara Ann Stinson'}, {'authorId': '2301564430', 'name': 'Prachi Mehta'}, {'authorId': '3940620', 'name': 'U. Sambamoorthi'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/acem.14937', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/acem.14937?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/acem.14937, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objectives natural language processing (nlp) represents one of the adjunct technologies within artificial intelligence and machine learning, creating structure out of unstructured data. this study aims to assess the performance of employing nlp to identify and categorize unstructured data within the emergency medicine (em) setting. methods we systematically searched publications related to em research and nlp across databases including medline, embase, scopus, central, and proquest dissertations & theses global. independent reviewers screened, reviewed, and evaluated article quality and bias. nlp usage was categorized into syndromic surveillance, radiologic interpretation, and identification of specific diseases/events/syndromes, with respective sensitivity analysis reported. performance metrics for nlp usage were calculated and the overall area under the summary of receiver operating characteristic curve (sroc) was determined. results a total of 27 studies underwent meta-analysis. findings indicated an overall mean sensitivity (recall) of 82%-87%, specificity of 95%, with the area under the sroc at 0.96 (95% ci 0.94-0.98). optimal performance using nlp was observed in radiologic interpretation, demonstrating an overall mean sensitivity of 93% and specificity of 96%. conclusions our analysis revealed a generally favorable performance accuracy in using nlp within em research, particularly in the realm of radiologic interpretation. consequently, we advocate for the adoption of nlp-based research to augment em health care management.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/acem.14937
998f15ee791c749ddb9bf695a73589b79350a82b,A systematic review of natural language processing applications for hydrometeorological hazards assessment,"Natural language processing (NLP) is a promising tool for collecting data that are usually hard to obtain during extreme weather, like community response and infrastructure performance. Patterns and trends in abundant data sources such as weather reports, news articles, and social media may provide insights into potential impacts and early warnings of impending disasters. This paper reviews the peer-reviewed studies (journals and conference proceedings) that used NLP to assess extreme weather events, focusing on heavy rainfall events. The methodology searches four databases (ScienceDirect, Web of Science, Scopus, and IEEE Xplore) for articles published in English before June 2022. The preferred reporting items for systematic reviews and meta-analysis reviews and meta-analysis guidelines were followed to select and refine the search. The method led to the identification of thirty-five studies. In this study, hurricanes, typhoons, and flooding were considered. NLP models were implemented in information extraction, topic modeling, clustering, and classification. The findings show that NLP remains underutilized in studying extreme weather events. The review demonstrated that NLP could potentially improve the usefulness of social media platforms, newspapers, and other data sources that could improve weather event assessment. In addition, NLP could generate new information that should complement data from ground-based sensors, reducing monitoring costs. Key outcomes of NLP use include improved accuracy, increased public safety, improved data collection, and enhanced decision-making are identified in the study. On the other hand, researchers must overcome data inadequacy, inaccessibility, nonrepresentative and immature NLP approaches, and computing skill requirements to use NLP properly.",2023,"[{'authorId': '2173650255', 'name': 'Achraf Tounsi'}, {'authorId': '2472014', 'name': 'M. Temimi'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11069-023-05842-0.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9905760, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","natural language processing (nlp) is a promising tool for collecting data that are usually hard to obtain during extreme weather, like community response and infrastructure performance. patterns and trends in abundant data sources such as weather reports, news articles, and social media may provide insights into potential impacts and early warnings of impending disasters. this paper reviews the peer-reviewed studies (journals and conference proceedings) that used nlp to assess extreme weather events, focusing on heavy rainfall events. the methodology searches four databases (sciencedirect, web of science, scopus, and ieee xplore) for articles published in english before june 2022. the preferred reporting items for systematic reviews and meta-analysis reviews and meta-analysis guidelines were followed to select and refine the search. the method led to the identification of thirty-five studies. in this study, hurricanes, typhoons, and flooding were considered. nlp models were implemented in information extraction, topic modeling, clustering, and classification. the findings show that nlp remains underutilized in studying extreme weather events. the review demonstrated that nlp could potentially improve the usefulness of social media platforms, newspapers, and other data sources that could improve weather event assessment. in addition, nlp could generate new information that should complement data from ground-based sensors, reducing monitoring costs. key outcomes of nlp use include improved accuracy, increased public safety, improved data collection, and enhanced decision-making are identified in the study. on the other hand, researchers must overcome data inadequacy, inaccessibility, nonrepresentative and immature nlp approaches, and computing skill requirements to use nlp properly.",https://link.springer.com/content/pdf/10.1007/s11069-023-05842-0.pdf
d3a86208370e1945854b027fa1b8caadfb9b6a4b,Implementation of Circular Economy Business Models by Small and Medium-Sized Enterprises (SMEs): Barriers and Enablers,"Small and medium-sized enterprises (SMEs) are increasingly aware of the benefits of closing loops and improving resource efficiency, such as saving material costs, creating competitive advantages, and accessing new markets. At the same time, however, various barriers pose challenges to small businesses in their transition to a circular economy, namely a lack of financial resources and lack of technical skills. The aim of this paper is to increase knowledge and understanding about the barriers and enablers experienced by SMEs when implementing circular economy business models. Looking first at the barriers that prevent SMEs from realising the benefits of the circular economy, an investigation is carried out in the form of a literature review and an analysis of a sample of SME case studies that are featured on the GreenEcoNet EU-funded web platform. Several enabling factors that help SMEs adopt circular economy practices are then identified. The paper concludes that although various policy instruments are available to help SMEs incorporate circular economy principles into their business models, several barriers remain. The authors recommend that European and national policies strengthen their focus on greening consumer preferences, market value chains and company cultures, and support the recognition of SMEs’ green business models. This can be achieved through the creation of dedicated marketplaces and communities of practice, for example.",2016,"[{'authorId': '95013687', 'name': 'Vasileios Rizos'}, {'authorId': '1902853', 'name': 'A. Behrens'}, {'authorId': '27077073', 'name': 'W. Gaast'}, {'authorId': '73896510', 'name': 'E. Hofman'}, {'authorId': '34770378', 'name': 'A. Ioannou'}, {'authorId': '17748298', 'name': 'Terri Kafyeke'}, {'authorId': '2540844', 'name': 'A. Flamos'}, {'authorId': '2052680517', 'name': 'Roberto Rinaldi'}, {'authorId': '108472737', 'name': 'S. Papadelis'}, {'authorId': '2087568650', 'name': 'M. Hirschnitz-Garbers'}, {'authorId': '98762319', 'name': 'C. Topi'}]","{'url': 'https://www.mdpi.com/2071-1050/8/11/1212/pdf?version=1479899574', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/SU8111212?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/SU8111212, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","small and medium-sized enterprises (smes) are increasingly aware of the benefits of closing loops and improving resource efficiency, such as saving material costs, creating competitive advantages, and accessing new markets. at the same time, however, various barriers pose challenges to small businesses in their transition to a circular economy, namely a lack of financial resources and lack of technical skills. the aim of this paper is to increase knowledge and understanding about the barriers and enablers experienced by smes when implementing circular economy business models. looking first at the barriers that prevent smes from realising the benefits of the circular economy, an investigation is carried out in the form of a literature review and an analysis of a sample of sme case studies that are featured on the greeneconet eu-funded web platform. several enabling factors that help smes adopt circular economy practices are then identified. the paper concludes that although various policy instruments are available to help smes incorporate circular economy principles into their business models, several barriers remain. the authors recommend that european and national policies strengthen their focus on greening consumer preferences, market value chains and company cultures, and support the recognition of smes’ green business models. this can be achieved through the creation of dedicated marketplaces and communities of practice, for example.",https://www.mdpi.com/2071-1050/8/11/1212/pdf?version=1479899574
808fe0e4998ac04c7de2e856a53bb441a3240891,Use of life cycle assessment to evaluate circular economy business models in the case of Li-ion battery remanufacturing,"Purpose The purpose of this study is to advance and illustrate how life cycle assessment (LCA) can assess circular economy business models for lithium-ion batteries to verify potential environmental benefits compared to linear business models. Scenarios for battery repurpose are assessed to support future decision-makers regarding the choice of new versus second life batteries for stationary energy storage. A procedure to determine the substitution coefficient for repurpose and reuse of batteries is proposed. Methods Two different circular economy business models are assessed by applying primary data from two Norwegian companies for the development of a new life cycle inventory. With this new data, the authors compare second life battery (from first life in electric vehicle) scenarios and avoided production potential by performing a complete consequential LCA. Building on earlier work, a procedure to identify the substitution coefficient (i.e., potential for avoided production) for battery life cycle assessments is proposed. Interviews during factory visits were performed to identify a technical and a market factor affecting the substitution coefficient. Results and discussion This study illustrates how life cycle assessment methodology can detect and thus enhance the potential environmental benefits and trade-offs of circular economy business models. Results show that the CBMs which use second life batteries correspond to 16% (for global warming potential) of manufacturing a new battery. This means that a second life battery must avoid > 16% production of a new battery to become the preferred alternative. Hence, circular economy business models with second life batteries can generate net environmental benefits while the remaining battery capacity and market price are identified factors that can alter the potential environmental benefits. The findings suggest that assumptions concerning the avoided production emissions are crucial for understanding the overall impacts of battery value chains. Conclusions Circular economy business models which enable second life batteries show lower environmental impacts compared to a new battery when it can partly avoid production of a new battery. Based on the identified technical and market factor affecting this potential, a key message to industry and other organizations is that second life batteries should be chosen over new batteries. This depends on the remaining capacity being satisfactory for the new application, and the investment is not performed because of a low price compared to a new battery. Consequential LCA practitioners adopting a market approach while evaluating battery reuse and repurpose should model and account for the avoided production potential.",2023,"[{'authorId': '101178418', 'name': 'Benedikte Wrålsen'}, {'authorId': '1414147341', 'name': ""R. O'Born""}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11367-023-02154-0.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s11367-023-02154-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s11367-023-02154-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose the purpose of this study is to advance and illustrate how life cycle assessment (lca) can assess circular economy business models for lithium-ion batteries to verify potential environmental benefits compared to linear business models. scenarios for battery repurpose are assessed to support future decision-makers regarding the choice of new versus second life batteries for stationary energy storage. a procedure to determine the substitution coefficient for repurpose and reuse of batteries is proposed. methods two different circular economy business models are assessed by applying primary data from two norwegian companies for the development of a new life cycle inventory. with this new data, the authors compare second life battery (from first life in electric vehicle) scenarios and avoided production potential by performing a complete consequential lca. building on earlier work, a procedure to identify the substitution coefficient (i.e., potential for avoided production) for battery life cycle assessments is proposed. interviews during factory visits were performed to identify a technical and a market factor affecting the substitution coefficient. results and discussion this study illustrates how life cycle assessment methodology can detect and thus enhance the potential environmental benefits and trade-offs of circular economy business models. results show that the cbms which use second life batteries correspond to 16% (for global warming potential) of manufacturing a new battery. this means that a second life battery must avoid > 16% production of a new battery to become the preferred alternative. hence, circular economy business models with second life batteries can generate net environmental benefits while the remaining battery capacity and market price are identified factors that can alter the potential environmental benefits. the findings suggest that assumptions concerning the avoided production emissions are crucial for understanding the overall impacts of battery value chains. conclusions circular economy business models which enable second life batteries show lower environmental impacts compared to a new battery when it can partly avoid production of a new battery. based on the identified technical and market factor affecting this potential, a key message to industry and other organizations is that second life batteries should be chosen over new batteries. this depends on the remaining capacity being satisfactory for the new application, and the investment is not performed because of a low price compared to a new battery. consequential lca practitioners adopting a market approach while evaluating battery reuse and repurpose should model and account for the avoided production potential.",https://link.springer.com/content/pdf/10.1007/s11367-023-02154-0.pdf
d67ad7ddd478ae3d68f0dd4c9535a3b64a7f008f,Open strategy and dynamic capabilities: A framework for circular economy business models research,"The circular economy has attracted the interest of business leaders, policy makers and academics alike for its potential to contribute to a more resilient, prosperous and resource-efficient economy. The transition towards a circular economy requires new business models that challenge the linear logic of value creation that is still endemic across most industries. In turn, the transition from linear to circular business models involves the rethinking of strategic decision-making processes and the development of new organisational capabilities. This paper addresses these important strategic implications of the emergence and implementation of circular business models. Coupling business models with open strategy and dynamic capabilities, we develop a “ three-pronged ” strategy framework that advances the emerging field of circular business model research. Our contribution is crystallised into a series of propositions and future research questions for scholars working at the intersection of the circular economy and the strategy literature.",2023,"[{'authorId': '2156466846', 'name': 'Roberta De Angelis'}, {'authorId': '8897601', 'name': 'R. Morgan'}, {'authorId': '2171713572', 'name': 'Luigi M. De Luca'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/bse.3397', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/bse.3397?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/bse.3397, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the circular economy has attracted the interest of business leaders, policy makers and academics alike for its potential to contribute to a more resilient, prosperous and resource-efficient economy. the transition towards a circular economy requires new business models that challenge the linear logic of value creation that is still endemic across most industries. in turn, the transition from linear to circular business models involves the rethinking of strategic decision-making processes and the development of new organisational capabilities. this paper addresses these important strategic implications of the emergence and implementation of circular business models. coupling business models with open strategy and dynamic capabilities, we develop a “ three-pronged ” strategy framework that advances the emerging field of circular business model research. our contribution is crystallised into a series of propositions and future research questions for scholars working at the intersection of the circular economy and the strategy literature.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/bse.3397
297c3a164c45c08b6d4780ed5261aae46c520198,A State-of-the-Art Review of Sharing Economy Business Models and a Forecast of Future Research Directions for Sustainable Development: A Bibliometric Analysis Approach,"The area of sharing economy business models (SEBMs) is expanding worldwide. To date, a few qualitative literature reviews concentrating on specific business models have been undertaken, while several have focused on the general concept of the sharing economy. Meanwhile, there is a lack of quantitative reviews in this area. Therefore, a retrospective review of the evolution of the SEBM area and prospective forecasts based on quantified data are urgently needed. In order to fill the gaps and critically evaluate the extant literature on the SEBM area and its scientometrics-related topics, this paper combines the Scopus and Web of Science databases to establish a dataset for a thorough bibliometric analysis. With 951 studies from 552 sources identified, this research provides comprehensive and nuanced information covering the most influential authors and their contributions to the subject, impactful articles with their citation details, ranked sources with their h_, g_ and m-index as well as collaboration maps for authors, affiliations and countries. Graphical representation of knowledge mapping depicts the evolution of publications over time and the emerging trends of current interests and potential directions for future research for sustainable development. This study revealed that Sustainability is the most relevant and second most impactful journal in SEBM research. More importantly, this research deployed keyword dynamic and thematic evolution to detect the current and future trending topics, providing seven future research directions: (1) drivers-, location- and competition-related topics; (2) SEBMs in emerging economies; (3) country-, region- and culture-oriented SEBMs; (4) the link between e-commerce and social media frameworks and SEBMs; (5) sustainability and SEBMs; (6) new technologies and SEBMs and (7) COVID-19 effects on SEBMs. Overall, the results of this study theoretically enrich the sharing economy business model literature and have substantial implications for policymakers and practitioners.",2023,"[{'authorId': '1576539258', 'name': 'Carson Duan'}]","{'url': 'https://www.mdpi.com/2071-1050/15/5/4568/pdf?version=1677845664', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su15054568?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su15054568, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the area of sharing economy business models (sebms) is expanding worldwide. to date, a few qualitative literature reviews concentrating on specific business models have been undertaken, while several have focused on the general concept of the sharing economy. meanwhile, there is a lack of quantitative reviews in this area. therefore, a retrospective review of the evolution of the sebm area and prospective forecasts based on quantified data are urgently needed. in order to fill the gaps and critically evaluate the extant literature on the sebm area and its scientometrics-related topics, this paper combines the scopus and web of science databases to establish a dataset for a thorough bibliometric analysis. with 951 studies from 552 sources identified, this research provides comprehensive and nuanced information covering the most influential authors and their contributions to the subject, impactful articles with their citation details, ranked sources with their h_, g_ and m-index as well as collaboration maps for authors, affiliations and countries. graphical representation of knowledge mapping depicts the evolution of publications over time and the emerging trends of current interests and potential directions for future research for sustainable development. this study revealed that sustainability is the most relevant and second most impactful journal in sebm research. more importantly, this research deployed keyword dynamic and thematic evolution to detect the current and future trending topics, providing seven future research directions: (1) drivers-, location- and competition-related topics; (2) sebms in emerging economies; (3) country-, region- and culture-oriented sebms; (4) the link between e-commerce and social media frameworks and sebms; (5) sustainability and sebms; (6) new technologies and sebms and (7) covid-19 effects on sebms. overall, the results of this study theoretically enrich the sharing economy business model literature and have substantial implications for policymakers and practitioners.",https://www.mdpi.com/2071-1050/15/5/4568/pdf?version=1677845664
ca158c221165ea79502d04302fcbf12a16b2f1ec,Circular economy business models: The state of research and avenues ahead,"This study investigates how the circular economy and business models are related in the current business and management literature. Based on bibliometric analytical procedures, 253 articles were retrieved from the Scopus, Web of Science, and ScienceDirect scientific databases. The articles were analyzed according to network analysis principles, and key terms were mapped into a network. We used VOSviewer to build the network, explore the most‐researched terms and their relationships, and identify less‐explored terms and research gaps. We furthermore conducted a qualitative review of selected publications to provide an illustration of quantitative results and delve deeper into the research topics. The main findings revealed the networks of current topics as they appear in the publications such as business models, the circular economy, circular business models, value, supply chain, transition, resource, waste, and reuse, and their most prevalent relationships. The results also highlighted several emerging topics such as those connected with managerial, supply‐side, demand‐side, networking, performance, and contextual considerations of circular business models.",2020,"[{'authorId': '2697617', 'name': 'Marcos Ferasso'}, {'authorId': '39682799', 'name': 'Tatiana Beliaeva'}, {'authorId': '17743559', 'name': 'S. Kraus'}, {'authorId': '41134179', 'name': 'T. Clauss'}, {'authorId': '1397175888', 'name': 'D. Ribeiro-Soriano'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/bse.2554', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/bse.2554?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/bse.2554, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study investigates how the circular economy and business models are related in the current business and management literature. based on bibliometric analytical procedures, 253 articles were retrieved from the scopus, web of science, and sciencedirect scientific databases. the articles were analyzed according to network analysis principles, and key terms were mapped into a network. we used vosviewer to build the network, explore the most‐researched terms and their relationships, and identify less‐explored terms and research gaps. we furthermore conducted a qualitative review of selected publications to provide an illustration of quantitative results and delve deeper into the research topics. the main findings revealed the networks of current topics as they appear in the publications such as business models, the circular economy, circular business models, value, supply chain, transition, resource, waste, and reuse, and their most prevalent relationships. the results also highlighted several emerging topics such as those connected with managerial, supply‐side, demand‐side, networking, performance, and contextual considerations of circular business models.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/bse.2554
281ba24fa71bf4982e415b7146917a3f27ea3e19,Circular Economy Business Models in the SME Sector,"The article focuses on a bottom-up approach to implementing the concept of circular economy. All enterprises, not only the most aware ones, face the challenges of this economy. The modification of business models towards circular economy becomes a necessity. However, questions arise as to whether the use of circular economy business models is widely practiced and how enterprises are coping with the implementation of these models. This article presents the results of research aimed at assessing the organizational maturity of enterprises in terms of implementing the principles of circular economy. Based on the concept of organizational maturity levels of the CMMI model, the classification of circular business models according to R2Pi and the integrated business model (the so-called business model canvas), the maturity index of the circular economy business model is constructed. The results obtained do not allow one to formulate very optimistic conclusions. First of all, a competency gap in the field of circular business models is identified, which translates into a limited application of these models in practice. The most frequently implemented models are: circular raw materials, recovery of raw materials, modification and repair. Most enterprises tend to undertake activities that are characteristic of circular economy. Furthermore, the importance of these activities increases with the age of the enterprise.",2021,"[{'authorId': '2097212046', 'name': 'Katarzyna Brendzel-Skowera'}]","{'url': 'https://www.mdpi.com/2071-1050/13/13/7059/pdf?version=1624447149', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su13137059?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su13137059, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the article focuses on a bottom-up approach to implementing the concept of circular economy. all enterprises, not only the most aware ones, face the challenges of this economy. the modification of business models towards circular economy becomes a necessity. however, questions arise as to whether the use of circular economy business models is widely practiced and how enterprises are coping with the implementation of these models. this article presents the results of research aimed at assessing the organizational maturity of enterprises in terms of implementing the principles of circular economy. based on the concept of organizational maturity levels of the cmmi model, the classification of circular business models according to r2pi and the integrated business model (the so-called business model canvas), the maturity index of the circular economy business model is constructed. the results obtained do not allow one to formulate very optimistic conclusions. first of all, a competency gap in the field of circular business models is identified, which translates into a limited application of these models in practice. the most frequently implemented models are: circular raw materials, recovery of raw materials, modification and repair. most enterprises tend to undertake activities that are characteristic of circular economy. furthermore, the importance of these activities increases with the age of the enterprise.",https://www.mdpi.com/2071-1050/13/13/7059/pdf?version=1624447149
895ff72c3315d942e075b1bd4e067923adbacd56,Managerial practices for designing circular economy business models,"
Purpose
The purpose of this paper is to investigate the managerial practices that companies can implement in order to design a circular economy business model and how companies can create and capture value from a circular economy business model.


Design/methodology/approach
The paper adopts a single case study methodology with semi-structured interviews and company, supplier, and manufacturing site visits, conducted in a small-to-medium-size Italian company operating in the office supply industry.


Findings
The theoretical setting maps a set of managerial practices for a circular economy business model and sets the research gaps and questions in a research framework designed along three main dimensions: value network, customer value proposition and interface, and managerial commitment. Then, through an empirical analysis, the findings reveal that the proposed dimensions are interdependent and reinforce each other. Moreover, the managerial commitment as moderating factor between the value network and the customer value proposition and interface dimensions is identified as essential for reaching the intended goals of circular economy business models.


Research limitations/implications
This study maximizes the depth of the phenomenon under investigation by leveraging a single case study methodology, which ideally helps in a theory-testing approach as in the present case. Future research opportunities could be found in qualitative and quantitative studies to increase the generalizability of the findings of this paper.


Practical implications
The paper presents a set of relevant managerial practices for circular economy business models that can be used by managers who have the will to embrace in practice circular economy principles to support the design, change, or upgrade of the business model of companies within which they operate.


Originality/value
An interdisciplinary approach that integrates the research streams of circular economy, social psychology, organizational behavior, and business model design has been pursued to test the theoretical setting and the research framework for circular economy business models in a real-world context.
",2019,"[{'authorId': '82441205', 'name': 'Enes Ünal'}, {'authorId': '83946847', 'name': 'Andrea Urbinati'}, {'authorId': '31861970', 'name': 'D. Chiaroni'}]","{'url': 'https://re.public.polimi.it/bitstream/11311/1124826/1/Managerial%20practices%20for%20designing%20circular%20economy%20business%20models.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/JMTM-02-2018-0061?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/JMTM-02-2018-0061, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose the purpose of this paper is to investigate the managerial practices that companies can implement in order to design a circular economy business model and how companies can create and capture value from a circular economy business model. design/methodology/approach the paper adopts a single case study methodology with semi-structured interviews and company, supplier, and manufacturing site visits, conducted in a small-to-medium-size italian company operating in the office supply industry. findings the theoretical setting maps a set of managerial practices for a circular economy business model and sets the research gaps and questions in a research framework designed along three main dimensions: value network, customer value proposition and interface, and managerial commitment. then, through an empirical analysis, the findings reveal that the proposed dimensions are interdependent and reinforce each other. moreover, the managerial commitment as moderating factor between the value network and the customer value proposition and interface dimensions is identified as essential for reaching the intended goals of circular economy business models. research limitations/implications this study maximizes the depth of the phenomenon under investigation by leveraging a single case study methodology, which ideally helps in a theory-testing approach as in the present case. future research opportunities could be found in qualitative and quantitative studies to increase the generalizability of the findings of this paper. practical implications the paper presents a set of relevant managerial practices for circular economy business models that can be used by managers who have the will to embrace in practice circular economy principles to support the design, change, or upgrade of the business model of companies within which they operate. originality/value an interdisciplinary approach that integrates the research streams of circular economy, social psychology, organizational behavior, and business model design has been pursued to test the theoretical setting and the research framework for circular economy business models in a real-world context.",https://re.public.polimi.it/bitstream/11311/1124826/1/Managerial%20practices%20for%20designing%20circular%20economy%20business%20models.pdf
181216ad08cf6b2069c8137818f9e82fb0c1ddc2,Value configurations in sharing economy business models,"The sharing economy gains momentum and develops a major economic impact on traditional markets and firms. However, only rudimentary theoretical and empirical insights exist on how sharing networks, i.e., focal firms, shared goods providers and customers, create and capture value in their sharing-based business models. We conduct a qualitative study to find key differences in sharing-based business models that are decisive for their value configurations. Our results show that (1) customization versus standardization of shared goods and (2) the centralization versus particularization of property rights over the shared goods are two important dimensions to distinguish value configurations. A second, quantitative study confirms the visibility and relevance of these dimensions to customers. We discuss strategic options for focal firms to design value configurations regarding the two dimensions to optimize value creation and value capture in sharing networks. Firms can use this two-dimensional search grid to explore untapped opportunities in the sharing economy.",2021,"[{'authorId': '9616265', 'name': 'Andreas J. Reuschl'}, {'authorId': '103017633', 'name': 'V. Tiberius'}, {'authorId': '98733218', 'name': 'Matthias Filser'}, {'authorId': '2204387', 'name': 'Yixin Qiu'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11846-020-00433-w.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7817141, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the sharing economy gains momentum and develops a major economic impact on traditional markets and firms. however, only rudimentary theoretical and empirical insights exist on how sharing networks, i.e., focal firms, shared goods providers and customers, create and capture value in their sharing-based business models. we conduct a qualitative study to find key differences in sharing-based business models that are decisive for their value configurations. our results show that (1) customization versus standardization of shared goods and (2) the centralization versus particularization of property rights over the shared goods are two important dimensions to distinguish value configurations. a second, quantitative study confirms the visibility and relevance of these dimensions to customers. we discuss strategic options for focal firms to design value configurations regarding the two dimensions to optimize value creation and value capture in sharing networks. firms can use this two-dimensional search grid to explore untapped opportunities in the sharing economy.",https://link.springer.com/content/pdf/10.1007/s11846-020-00433-w.pdf
45af4010faf29f1970223bb0e1c6b94d102b654e,Circular Economy Business Models: The Complementarities with Sharing Economy and Eco-Innovations Investments,"The transition from the linear economy to the circular economy exhibits some criticalities that can be solved through the identification of factors pushing and pulling the transition itself. By adopting a public good perspective in analysing the main features of the circular business models, this study underlines how the sharing economy business models are well integrated and complementary to some features of the circular economy, representing a strong pulling factor. Other loops of the circular economy need an explicit push factor, individuated in a strong impulse to eco-efficiency, to be reached through consistent incentives to invest in R&D for eco-innovations. Seven case studies are investigated in their aims, feasibility and implementation to support the interpretative framework.",2021,"[{'authorId': '98557940', 'name': 'L. Aldieri'}, {'authorId': '101414855', 'name': 'Mohsen Brahmi'}, {'authorId': '51336631', 'name': 'B. Bruno'}, {'authorId': '113256216', 'name': 'C. P. Vinci'}]","{'url': 'https://www.mdpi.com/2071-1050/13/22/12438/pdf?version=1636615889', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su132212438?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su132212438, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the transition from the linear economy to the circular economy exhibits some criticalities that can be solved through the identification of factors pushing and pulling the transition itself. by adopting a public good perspective in analysing the main features of the circular business models, this study underlines how the sharing economy business models are well integrated and complementary to some features of the circular economy, representing a strong pulling factor. other loops of the circular economy need an explicit push factor, individuated in a strong impulse to eco-efficiency, to be reached through consistent incentives to invest in r&d for eco-innovations. seven case studies are investigated in their aims, feasibility and implementation to support the interpretative framework.",https://www.mdpi.com/2071-1050/13/22/12438/pdf?version=1636615889
6b037b47b0032b1ece50f7a7911e906de00ee211,Circular Economy Business Models: a Repertoire of Theoretical Relationships and a Research Agenda,"The shift towards a more resource efficient circular economy has become a necessity in the wake of current ecological, economic and social sustainability challenges. Mirroring circular-related developments in policy and business quarters, the circular economy literature is growing as a distinct field of academic enquiry. Yet, the conceptual and theoretical foundations of circular economy thinking need consolidation. Drawing from strategic management, sustainability transitions and systems theories, this article establishes some theoretical anchoring for circular economy business models. It finds that circular business models contribute to an understanding of both competitive advantage and the systemic nature of business. It also develops a future agenda for management research at the interface between the circular economy and business models.",2021,"[{'authorId': '145882288', 'name': 'R. De Angelis'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s43615-021-00133-x.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8611398, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the shift towards a more resource efficient circular economy has become a necessity in the wake of current ecological, economic and social sustainability challenges. mirroring circular-related developments in policy and business quarters, the circular economy literature is growing as a distinct field of academic enquiry. yet, the conceptual and theoretical foundations of circular economy thinking need consolidation. drawing from strategic management, sustainability transitions and systems theories, this article establishes some theoretical anchoring for circular economy business models. it finds that circular business models contribute to an understanding of both competitive advantage and the systemic nature of business. it also develops a future agenda for management research at the interface between the circular economy and business models.",https://link.springer.com/content/pdf/10.1007/s43615-021-00133-x.pdf
108121594ec75d20ee702894017286b007df916c,"Circular economy business models in developing economies: Lessons from India on reduce, recycle, and reuse paradigms","According to the UN Sustainable Development Goals in 2016, the demand for resources will require natural resources equivalent to two and three planets by 2030 and 2050, respectively. The linear economic model driven by a “take-make-dispose” philosophy is unable to manage the demand and supply balance in consumption of natural resources. This imbalance is affecting the sustainability of the countries and enterprises as well as affecting the global supply chain leading to socioeconomic and environmental risks and volatility. Realizing the future resource scarcity challenge, the current linear economy model is giving way to the circular economy model. The circular economy model focuses on careful alignment and management of resource flows across the value chain by integrating reverse logistics, design innovation, collaborative ecosystem, and business model innovation. This article examines how circular model is pushing the companies in developing economies like India to design and implement business models that are based on reduce, reuse, and recycle paradigms. © 2016 Wiley Periodicals, Inc.",2018,"[{'authorId': '48765598', 'name': 'Sandeep Goyal'}, {'authorId': '152193594', 'name': 'M. Esposito'}, {'authorId': '46493895', 'name': 'Amit Kapoor'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/TIE.21883?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/TIE.21883, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","according to the un sustainable development goals in 2016, the demand for resources will require natural resources equivalent to two and three planets by 2030 and 2050, respectively. the linear economic model driven by a “take-make-dispose” philosophy is unable to manage the demand and supply balance in consumption of natural resources. this imbalance is affecting the sustainability of the countries and enterprises as well as affecting the global supply chain leading to socioeconomic and environmental risks and volatility. realizing the future resource scarcity challenge, the current linear economy model is giving way to the circular economy model. the circular economy model focuses on careful alignment and management of resource flows across the value chain by integrating reverse logistics, design innovation, collaborative ecosystem, and business model innovation. this article examines how circular model is pushing the companies in developing economies like india to design and implement business models that are based on reduce, reuse, and recycle paradigms. © 2016 wiley periodicals, inc.",
320232668eb887fc1102f5b470b64123726fe2c5,"Circular Economy Business Models in the Micro, Small, and Medium Enterprises: A Review","MSME business should be built based on circular economy (CE)-based business models. The purpose of this article is to presenta review of several articles that have been published in Scopusdiscussing the CE-based business model and MSMEs to findresearch gaps and future research agendas. It used some tools of thetheoretical assay, such as bibliometric analysis, systematic literaturereview, theory, context, and characteristic methodology (TCCM).The paper outlines all findings of analyzed literature about CE’sbusiness model applied by MSME in the Scopus document untilJune 2021. The findings of this study provided more high-qualityevidence about research and practical gaps regarding the CE-basedbusiness model and MSME, which needs more research focuseson market desirability in the future and more understanding ofinternal processes in MSME’s case studies. The implication of thisarticle is to provide a future research agenda based on a collectionof research gaps as a basis for empirical research.JEL Classification: L26, M10, Q56",2022,"[{'authorId': '31102606', 'name': 'Astadi Pangarso'}, {'authorId': '2089292245', 'name': 'Kristina Sisilia'}, {'authorId': '9424066', 'name': 'Yahya Peranginangin'}]","{'url': 'https://journal.uinjkt.ac.id/index.php/etikonomi/article/download/24052/pdf', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.15408/etk.v21i2.24052?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.15408/etk.v21i2.24052, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","msme business should be built based on circular economy (ce)-based business models. the purpose of this article is to presenta review of several articles that have been published in scopusdiscussing the ce-based business model and msmes to findresearch gaps and future research agendas. it used some tools of thetheoretical assay, such as bibliometric analysis, systematic literaturereview, theory, context, and characteristic methodology (tccm).the paper outlines all findings of analyzed literature about ce’sbusiness model applied by msme in the scopus document untiljune 2021. the findings of this study provided more high-qualityevidence about research and practical gaps regarding the ce-basedbusiness model and msme, which needs more research focuseson market desirability in the future and more understanding ofinternal processes in msme’s case studies. the implication of thisarticle is to provide a future research agenda based on a collectionof research gaps as a basis for empirical research.jel classification: l26, m10, q56",https://journal.uinjkt.ac.id/index.php/etikonomi/article/download/24052/pdf
3668e2d4c2cdeee4424b8959233d3d37175c1a18,Circular Economy Business Models for the Tanzanian Coffee Sector: A Teaching Case Study,"One of the major issues the agri-food supply chains is the considerable production of by-products, which are mostly discarded as wastes and dangerously landfilled. This problem is particularly acute in the coffee supply chain: coffee cultivation generates by-products and in quantities which are potentially dangerous for the environment. A circular economy business model aimed at the recovery of these by-products may represent an interesting solution in terms of environmental, social, and economic sustainability. The goal of this paper was to provide teachers and educators with case material on circular business models that can be used for problem-based learning and case-based learning activities. The proposed case was built to address a real-world problematic situation related to the coffee supply chain. From a theoretical point of view, this study contributes to the literature on circular economy business models by providing a case study developed in the context of a developing country. Furthermore, the research entails practical implications since it shows managers and startuppers how to map a circular business model in all its components under the guidance of a conceptual framework.",2021,"[{'authorId': '87799270', 'name': 'F. Lagrasta'}, {'authorId': '1797751', 'name': 'P. Pontrandolfo'}, {'authorId': '2944176', 'name': 'B. Scozzi'}]","{'url': 'https://www.mdpi.com/2071-1050/13/24/13931/pdf?version=1639727712', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su132413931?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su132413931, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","one of the major issues the agri-food supply chains is the considerable production of by-products, which are mostly discarded as wastes and dangerously landfilled. this problem is particularly acute in the coffee supply chain: coffee cultivation generates by-products and in quantities which are potentially dangerous for the environment. a circular economy business model aimed at the recovery of these by-products may represent an interesting solution in terms of environmental, social, and economic sustainability. the goal of this paper was to provide teachers and educators with case material on circular business models that can be used for problem-based learning and case-based learning activities. the proposed case was built to address a real-world problematic situation related to the coffee supply chain. from a theoretical point of view, this study contributes to the literature on circular economy business models by providing a case study developed in the context of a developing country. furthermore, the research entails practical implications since it shows managers and startuppers how to map a circular business model in all its components under the guidance of a conceptual framework.",https://www.mdpi.com/2071-1050/13/24/13931/pdf?version=1639727712
9050fd373e428ec55578844f1316ffe4abfe1f09,Circular Economy Business Models—Supply Chain Perspectives,"Modern manufacturing generates waste and causes shortages in natural resources due to a “take-make-waste” production system. The circular economy (CE) has been a policy initiative for supply chain looping strategies to reuse, refurbish, recycle, minimize, eliminate, share, and optimize material and energy use while maintaining firm profitability. Circular economy business models (CEBM) are recommended for achieving competitiveness for firms and their supply chains while reducing manufacturing waste and natural resource shortages present in the “take-make-waste” production system of traditional manufacturing. Despite the benefits of implementing CEBMs, there is a struggle to visualize the implications of CEBMs in organizational supply chains and beyond. This article presents the benefits of supply chain collaboration and infrastructure components based on practices of CEBM from several case study examples. Organizational, managerial, and technology development implications based on economic, environmental, and social dimensions are discussed from an administrative perspective. The paper ends with actionable steps for further advancement of CEBM in practice, along with areas for future research.",2020,"[{'authorId': '47520016', 'name': 'Santosh Nandi'}, {'authorId': '1752845819', 'name': 'Aref A. Hervani'}, {'authorId': '1690853', 'name': 'M. Helms'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/EMR.2020.2991388?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/EMR.2020.2991388, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","modern manufacturing generates waste and causes shortages in natural resources due to a “take-make-waste” production system. the circular economy (ce) has been a policy initiative for supply chain looping strategies to reuse, refurbish, recycle, minimize, eliminate, share, and optimize material and energy use while maintaining firm profitability. circular economy business models (cebm) are recommended for achieving competitiveness for firms and their supply chains while reducing manufacturing waste and natural resource shortages present in the “take-make-waste” production system of traditional manufacturing. despite the benefits of implementing cebms, there is a struggle to visualize the implications of cebms in organizational supply chains and beyond. this article presents the benefits of supply chain collaboration and infrastructure components based on practices of cebm from several case study examples. organizational, managerial, and technology development implications based on economic, environmental, and social dimensions are discussed from an administrative perspective. the paper ends with actionable steps for further advancement of cebm in practice, along with areas for future research.",
cc1e7174fa95814f831864d3fc4ca43c7a1f6f80,Circular Economy Business Models with a Focus on Servitization,"During the fourth industrial revolution, based on information and communication technology (ICT), service-led growth has been an increasingly important development area. This paper focuses on service-led growth as an innovative business model in the circular economy and offers the ‘product as service model’. A business model needs to be flexibly adjustable for changes in the market in response to changes in technology, the economy, and the environment. For firms facing increasing scarcity of resources, the right business model for using resources is becoming crucial for their growth. In a circular economy, a new method of business modelling is essential. This paper introduces the ‘product as a service model’ using a conceptualized and case study methodology. We illustrate this innovative circular business model through product servitization at the Hyundai Automotive Enterprise in Korea. This business model can be effective because of emerging new ‘smart connected products’ such as the ‘internet of things’ and ‘fifth generation’ network technologies. Cost, convenience, and the circular economy for firms, consumers, and the environment are critical factors in this new business model.",2020,"[{'authorId': '48691370', 'name': 'Jung-hee Han'}, {'authorId': '2940959', 'name': 'A. Heshmati'}, {'authorId': '71524422', 'name': 'M. Rashidghalam'}]","{'url': 'https://www.mdpi.com/2071-1050/12/21/8799/pdf?version=1603435405', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su12218799?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su12218799, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","during the fourth industrial revolution, based on information and communication technology (ict), service-led growth has been an increasingly important development area. this paper focuses on service-led growth as an innovative business model in the circular economy and offers the ‘product as service model’. a business model needs to be flexibly adjustable for changes in the market in response to changes in technology, the economy, and the environment. for firms facing increasing scarcity of resources, the right business model for using resources is becoming crucial for their growth. in a circular economy, a new method of business modelling is essential. this paper introduces the ‘product as a service model’ using a conceptualized and case study methodology. we illustrate this innovative circular business model through product servitization at the hyundai automotive enterprise in korea. this business model can be effective because of emerging new ‘smart connected products’ such as the ‘internet of things’ and ‘fifth generation’ network technologies. cost, convenience, and the circular economy for firms, consumers, and the environment are critical factors in this new business model.",https://www.mdpi.com/2071-1050/12/21/8799/pdf?version=1603435405
1e2de70360105eafdf4c0d6533063ca2761b641a,Improving Circular Economy Business Models: Opportunities for Business and Innovation : A new framework for businesses to create a truly circular economy,"The circular economy (CE) is aimed at closing material loops by reducing and recovering resources in production and consumption processes. Many studies have discussed how CE helps companies create business opportunities while bringing environmental benefits. The business case for CE involves complicated issues such as industrial symbiosis, governmental interventions and the transformation of company culture. It is important to consider the whole context of CE when changing policies or business elements to optimise resource efficiency and avoid unsustainable consumption. By reviewing industry research reports and academic studies, this article summarises important circular business models and strategies and indicates current major barriers to CE. In addition, we explore multiple business cases and point out three important considerations that, if not used correctly, can lead to improper policies and environmental degradation when designing circular business models. These are (a) the use of biodegradable materials, (b) modular design for product life extension and (c) upcycling for new production processes. We then present a framework for companies to clarify vital considerations for resolving these issues based on systems thinking. The implications for business managers and policy makers are also discussed. This article serves to provide a better understanding of CE and explores how companies innovate in line with CE trends. Introduction",2020,"[{'authorId': '31203002', 'name': 'Chong‐Wen Chen'}]","{'url': 'https://doi.org/10.1595/205651320x15710564137538', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1595/205651320x15710564137538?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1595/205651320x15710564137538, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the circular economy (ce) is aimed at closing material loops by reducing and recovering resources in production and consumption processes. many studies have discussed how ce helps companies create business opportunities while bringing environmental benefits. the business case for ce involves complicated issues such as industrial symbiosis, governmental interventions and the transformation of company culture. it is important to consider the whole context of ce when changing policies or business elements to optimise resource efficiency and avoid unsustainable consumption. by reviewing industry research reports and academic studies, this article summarises important circular business models and strategies and indicates current major barriers to ce. in addition, we explore multiple business cases and point out three important considerations that, if not used correctly, can lead to improper policies and environmental degradation when designing circular business models. these are (a) the use of biodegradable materials, (b) modular design for product life extension and (c) upcycling for new production processes. we then present a framework for companies to clarify vital considerations for resolving these issues based on systems thinking. the implications for business managers and policy makers are also discussed. this article serves to provide a better understanding of ce and explores how companies innovate in line with ce trends. introduction",https://doi.org/10.1595/205651320x15710564137538
bc8df00e8b93b7fca0899b210d33824cfa90e57b,Circular Economy Business Models: A Critical Examination,"Abstract: In recent decades, increasing numbers of scholars and practitioners have rejected the conventional, “linear” view of economic activity (centered on “take, make, and dispose”) in favor of a “circular economy” perspective, which emphasizes the need for humans to live in harmony with Earth’s ecological system. As a consequence, various contemporary business models claim to draw inspiration from this new perspective. However, our critical examination reveals that many of these models say little about—and, on their own, may contribute little to achieving—ecological sustainability. We conclude by stressing the need for public policies that enable society to pursue what institutionalists call “higher efficiency.”",2020,"[{'authorId': '3199774', 'name': 'C. Whalen'}, {'authorId': '2275988172', 'name': 'Katherine A. Whalen'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/00213624.2020.1778404?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/00213624.2020.1778404, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract: in recent decades, increasing numbers of scholars and practitioners have rejected the conventional, “linear” view of economic activity (centered on “take, make, and dispose”) in favor of a “circular economy” perspective, which emphasizes the need for humans to live in harmony with earth’s ecological system. as a consequence, various contemporary business models claim to draw inspiration from this new perspective. however, our critical examination reveals that many of these models say little about—and, on their own, may contribute little to achieving—ecological sustainability. we conclude by stressing the need for public policies that enable society to pursue what institutionalists call “higher efficiency.”",
45c0d160d11b80bd62c725ab77311ded6df3577d,A Compass for Navigating Sharing Economy Business Models,"The sharing economy has emerged in recent years as a disruptive approach to traditional business models. Drawing on a multi-year research program and a design-based methodology, this article introduces a framework and generative tool called the Sharing Business Model Compass. As an actionable framework, the Compass helps elucidate the multiple, innovative forms sharing economy businesses are adopting. As a generative tool, it enables entrepreneurs, investors, incubators, and incumbents interested in entering the sharing economy to create, present, and evolve a compelling sharing business model as well as evaluate its extent of robustness.",2018,"[{'authorId': '143714977', 'name': 'P. Muñoz'}, {'authorId': '113030793', 'name': 'Boyd Cohen'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/0008125618795490?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/0008125618795490, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the sharing economy has emerged in recent years as a disruptive approach to traditional business models. drawing on a multi-year research program and a design-based methodology, this article introduces a framework and generative tool called the sharing business model compass. as an actionable framework, the compass helps elucidate the multiple, innovative forms sharing economy businesses are adopting. as a generative tool, it enables entrepreneurs, investors, incubators, and incumbents interested in entering the sharing economy to create, present, and evolve a compelling sharing business model as well as evaluate its extent of robustness.",
ce30a236906707303e1b432b35069dff77962e16,"Trust in Sharing Economy Business Models from the Perspective of Customers in Szczecin, Poland","The concept of a sharing economy, as part of a wider collaborative economy concept, is among the most important economic and technological trends that will influence socioeconomic development in the future. Interest in using the opportunities offered by sharing platforms is increasing; hence, the subject is a current and important issue. Confidence in technology, service providers and application providers is a key issue when making decisions about using such solutions. The aim of the paper is to examine the level of trust in sharing economy business models considering two groups of factors, trust in people and in technology, among several demographic groups. The paper has an empirical character and the results are provided on the basis of a survey conducted in Szczecin, Poland, with 403 respondents who are current and potential users of sharing platforms. The obtained results show that platform management requires more attention focused on building mutual trust networks among participants rather than strengthening the confidence in using the technology.",2019,"[{'authorId': '2062674249', 'name': 'N. Wagner'}, {'authorId': '1413105829', 'name': 'Roma Strulak-Wójcikiewicz'}, {'authorId': '2064859266', 'name': 'A. Landowska'}]","{'url': 'https://www.mdpi.com/2071-1050/11/23/6838/pdf?version=1575270331', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su11236838?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su11236838, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the concept of a sharing economy, as part of a wider collaborative economy concept, is among the most important economic and technological trends that will influence socioeconomic development in the future. interest in using the opportunities offered by sharing platforms is increasing; hence, the subject is a current and important issue. confidence in technology, service providers and application providers is a key issue when making decisions about using such solutions. the aim of the paper is to examine the level of trust in sharing economy business models considering two groups of factors, trust in people and in technology, among several demographic groups. the paper has an empirical character and the results are provided on the basis of a survey conducted in szczecin, poland, with 403 respondents who are current and potential users of sharing platforms. the obtained results show that platform management requires more attention focused on building mutual trust networks among participants rather than strengthening the confidence in using the technology.",https://www.mdpi.com/2071-1050/11/23/6838/pdf?version=1575270331
c49c4eb8f5b46833d2b20eff8fc1e5fb6984005a,Entrepreneurship in the sharing economy: A review of business models and social impacts,"The emergence of the sharing economy has fundamentally transformed conventional company structures, presenting novel prospects for entrepreneurs and questioning existing conventions across diverse industries. This study offers an extensive examination of entrepreneurship within the sharing economy, delving into various company models and scrutinising its societal ramifications. The sharing economy, which involves peer-to-peer transactions mediated by internet platforms, has seen the rise of new entrepreneurial businesses. This paper explores the diverse and complex nature of sharing economy business models, encompassing various platforms such as ride-sharing, accommodation-sharing, asset-sharing, and skill-sharing. A thorough examination of each model to explore the fundamental concepts, operational processes, and crucial aspects that contribute to entrepreneurial success in this rapidly changing environment is being explored. This study examines the impact of different business models on consumer behaviour, market dynamics, and social developments. The assessment examines the good and negative outcomes, taking into account factors such as improved efficiency in resource utilization, economic empowerment of individuals, and potential difficulties linked to regulatory issues, labor rights, and market competitiveness. This paper focuses on the essential role of technology and digital platforms in promoting entrepreneurship within the sharing economy. Through an analysis of the impact of digitalization on market accessibility, trust mechanisms, and scalability, the role of technology as a driver for entrepreneurial innovation and expansion is emphasized. Additionally, it analyses the impact of regulatory frameworks on entrepreneurial activity, investigating the difficult balance between stimulating innovation and maintaining consumer protection, fair competition, and social equality. In conclusion, this research gives useful insights into the entrepreneurial environment of the sharing economy, presenting a comprehensive knowledge of diverse business models and their societal implications. By putting light on both opportunities and problems, thereby contributing to the current conversation on the role of entrepreneurship in determining the future of the sharing economy and its consequences for society at large.",2024,"[{'authorId': '2282040415', 'name': 'Glory Ugochi Ebirim'}, {'authorId': '2282590243', 'name': 'Ifeyinwa Francisca Unigwe'}, {'authorId': '2281663172', 'name': 'Ndubuisi Leonard Ndubuisi'}, {'authorId': '2282729728', 'name': 'Chidera Victoria Ibeh'}, {'authorId': '2281663259', 'name': 'Onyeka Franca Asuzu'}, {'authorId': '2281663384', 'name': 'Odunayo Adewunmi Adelekan'}]","{'url': 'https://ijsra.net/sites/default/files/IJSRA-2024-0136.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.30574/ijsra.2024.11.1.0136?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.30574/ijsra.2024.11.1.0136, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the emergence of the sharing economy has fundamentally transformed conventional company structures, presenting novel prospects for entrepreneurs and questioning existing conventions across diverse industries. this study offers an extensive examination of entrepreneurship within the sharing economy, delving into various company models and scrutinising its societal ramifications. the sharing economy, which involves peer-to-peer transactions mediated by internet platforms, has seen the rise of new entrepreneurial businesses. this paper explores the diverse and complex nature of sharing economy business models, encompassing various platforms such as ride-sharing, accommodation-sharing, asset-sharing, and skill-sharing. a thorough examination of each model to explore the fundamental concepts, operational processes, and crucial aspects that contribute to entrepreneurial success in this rapidly changing environment is being explored. this study examines the impact of different business models on consumer behaviour, market dynamics, and social developments. the assessment examines the good and negative outcomes, taking into account factors such as improved efficiency in resource utilization, economic empowerment of individuals, and potential difficulties linked to regulatory issues, labor rights, and market competitiveness. this paper focuses on the essential role of technology and digital platforms in promoting entrepreneurship within the sharing economy. through an analysis of the impact of digitalization on market accessibility, trust mechanisms, and scalability, the role of technology as a driver for entrepreneurial innovation and expansion is emphasized. additionally, it analyses the impact of regulatory frameworks on entrepreneurial activity, investigating the difficult balance between stimulating innovation and maintaining consumer protection, fair competition, and social equality. in conclusion, this research gives useful insights into the entrepreneurial environment of the sharing economy, presenting a comprehensive knowledge of diverse business models and their societal implications. by putting light on both opportunities and problems, thereby contributing to the current conversation on the role of entrepreneurship in determining the future of the sharing economy and its consequences for society at large.",https://ijsra.net/sites/default/files/IJSRA-2024-0136.pdf
83ead2c0ae04adf010d02092be67826de7ca5281,Circular economy integration in traditional business models: Strategies and outcomes,"This study embarks on a critical examination of the integration of circular economy (CE) strategies into traditional business models, a pivotal transition in the quest for sustainable development. The purpose of the study is to elucidate the barriers hindering the effective adoption of CE principles and to propose actionable recommendations for overcoming these obstacles. Employing a comprehensive methodological framework, the study synthesizes findings from a broad array of literature, augmented by empirical data, to provide a nuanced understanding of the challenges and opportunities inherent in CE implementation. Key findings reveal that insufficient resources, resistance to change, and the complexity of integrating CE into existing business structures are major impediments. These barriers are dissected to uncover underlying causes, such as inadequate funding, stakeholder inertia, and logistical challenges in material recovery and recycling. The study concludes that addressing these issues requires a multifaceted approach, including the development of unified conceptual frameworks, increased financial and technical support, and enhanced stakeholder engagement. Furthermore, it emphasizes the role of consumer behavior in the success of CE initiatives, advocating for more research into consumer attitudes and the promotion of sustainable consumption practices. The recommendations presented aim to guide businesses and policymakers in fostering an environment conducive to CE, thereby accelerating the transition towards a sustainable and resilient economic model. 
Keywords:  Circular Economy, Business Models, Sustainable Development, Resource Efficiency, Consumer Behavior, Implementation Barriers.",2024,"[{'authorId': '2308150171', 'name': 'Amardas Tuboalabo'}, {'authorId': '2308148970', 'name': 'Ushena Buinwi'}, {'authorId': '2308147709', 'name': 'Chinenye Gbemisola Okatta'}, {'authorId': '2308148785', 'name': 'Ebunoluwa Johnson'}, {'authorId': '2308148450', 'name': 'Jumai Adama Buinwi'}]","{'url': 'https://fepbl.com/index.php/farj/article/download/1245/1472', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.51594/farj.v6i6.1245?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.51594/farj.v6i6.1245, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study embarks on a critical examination of the integration of circular economy (ce) strategies into traditional business models, a pivotal transition in the quest for sustainable development. the purpose of the study is to elucidate the barriers hindering the effective adoption of ce principles and to propose actionable recommendations for overcoming these obstacles. employing a comprehensive methodological framework, the study synthesizes findings from a broad array of literature, augmented by empirical data, to provide a nuanced understanding of the challenges and opportunities inherent in ce implementation. key findings reveal that insufficient resources, resistance to change, and the complexity of integrating ce into existing business structures are major impediments. these barriers are dissected to uncover underlying causes, such as inadequate funding, stakeholder inertia, and logistical challenges in material recovery and recycling. the study concludes that addressing these issues requires a multifaceted approach, including the development of unified conceptual frameworks, increased financial and technical support, and enhanced stakeholder engagement. furthermore, it emphasizes the role of consumer behavior in the success of ce initiatives, advocating for more research into consumer attitudes and the promotion of sustainable consumption practices. the recommendations presented aim to guide businesses and policymakers in fostering an environment conducive to ce, thereby accelerating the transition towards a sustainable and resilient economic model. keywords: circular economy, business models, sustainable development, resource efficiency, consumer behavior, implementation barriers.",https://fepbl.com/index.php/farj/article/download/1245/1472
7ce802d34843af3880be3f64e9a47c492730bdc5,"Digital Economy, Business Models, and Cloud Computing","From the invention of writing to the steam engine and to computers, human history has been one of technological inventions and change. In our relatively recent past we have witnessed several technological revolutions which rapidly replaced one set of technologies by another, and in the process created what Schumpeter called the creative destruction. Today, we are witnessing a technological revolution that is changing the way we live, work, and communicate. We call this the digital revolution which brings with it new technologies, methods, and business models. This chapter discusses the digital revolution and the platform business model. This business model is used by many “sharing economy” businesses such as Airbnb and Uber. The success of this business model is dependent on the rapid expansion of its user-base. This business model requires infrastructure and applications that can cope with this rapid expansion. Cloud computing has been providing these services.",2019,"[{'authorId': '1404635305', 'name': 'Abbas Strømmen-Bakhtiar'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4018/978-1-5225-3182-1.CH002?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4018/978-1-5225-3182-1.CH002, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","from the invention of writing to the steam engine and to computers, human history has been one of technological inventions and change. in our relatively recent past we have witnessed several technological revolutions which rapidly replaced one set of technologies by another, and in the process created what schumpeter called the creative destruction. today, we are witnessing a technological revolution that is changing the way we live, work, and communicate. we call this the digital revolution which brings with it new technologies, methods, and business models. this chapter discusses the digital revolution and the platform business model. this business model is used by many “sharing economy” businesses such as airbnb and uber. the success of this business model is dependent on the rapid expansion of its user-base. this business model requires infrastructure and applications that can cope with this rapid expansion. cloud computing has been providing these services.",
3804bc7f9d41921b4406d9b035db76b32f8d0354,Framing the Managerial Practices for Circular Economy Business Models: A Case Study Analysis,"Circular economy has become a hot topic for scholars and practitioners as it represents a new industrial paradigm for waste generation, resource scarcity and sustainable economic growth that aims to overcome open systems paradigms, based on the traditional make, take, and disposal process. Whereas this issue has posed a lot of attention to the policies of circular economy as guidelines for policymakers, we still lack of consolidated managerial directions that support companies to implement this paradigm. In other words, although several scientific contributions started to shift the attention from macro (policies) to micro (company) levels of analysis, the issue of which managerial practices companies have to adopt for circular economy implementation still deserves particular attention. Although this literature gap continues persisting, several scholars have opened up the research stream of circular economy business models, which tries to analyze the business model design choices in the light of circular economy principles. Accordingly, we revise the main scientific contributions that analyze the managerial practices for circular economy business models. In doing so, we propose in a comprehensive theoretical framework a map of the managerial practices for circular economy business models that can be adopted at two different business model dimensions, i.e., the value network and the customer value proposition and interface. Therefore, we will test the suitability of our framework on a small medium Italian company operating in office supply industry for 23 years, by looking into the managerial practices that this company has implemented.",2018,"[{'authorId': '83946847', 'name': 'Andrea Urbinati'}, {'authorId': '82441205', 'name': 'Enes Ünal'}, {'authorId': '31861970', 'name': 'D. Chiaroni'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/EEEIC.2018.8493650?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/EEEIC.2018.8493650, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","circular economy has become a hot topic for scholars and practitioners as it represents a new industrial paradigm for waste generation, resource scarcity and sustainable economic growth that aims to overcome open systems paradigms, based on the traditional make, take, and disposal process. whereas this issue has posed a lot of attention to the policies of circular economy as guidelines for policymakers, we still lack of consolidated managerial directions that support companies to implement this paradigm. in other words, although several scientific contributions started to shift the attention from macro (policies) to micro (company) levels of analysis, the issue of which managerial practices companies have to adopt for circular economy implementation still deserves particular attention. although this literature gap continues persisting, several scholars have opened up the research stream of circular economy business models, which tries to analyze the business model design choices in the light of circular economy principles. accordingly, we revise the main scientific contributions that analyze the managerial practices for circular economy business models. in doing so, we propose in a comprehensive theoretical framework a map of the managerial practices for circular economy business models that can be adopted at two different business model dimensions, i.e., the value network and the customer value proposition and interface. therefore, we will test the suitability of our framework on a small medium italian company operating in office supply industry for 23 years, by looking into the managerial practices that this company has implemented.",
ae0c1a6b19f9963d5d57d8cede6ba3e2952b6bb1,The Issues of Social Responsibility in Collaborative Economy Business Models,"Purpose: The main aim of the paper is to analyse common aspects of the concepts of corporate social responsibility and collaborative economy through identifying the issues of social responsibility included in the collaborative economy business models. Design/methodology/approach: Firstly, the questionnaire survey was used to gather the opinions of the participants of the confer-ence assembling the representatives of sharing and collaborative businesses in Poland. Secondly, there were conducted two individ-ual in-depth interviews with CEOs of businesses active in the col-laborative economy sector. The aim of this phase was to illustrate the theoretical framework with practical business experiences. Findings: There are strong relations among collaborative econ-omy and corporate social responsibility. The research results suggest that business models in collaborative economy approach are designed to multiple value creation for a broader group of stakeholders rather than only for clients and an organisation. Con-ducted research revealed that the issue of responsibility even if not clearly communicated is a very important element of business models’ DNA especially in its social dimension. Research and practical limitations/implications: The research results can be useful for practitioners establishing new ventures and seeking for business models including collaborative and responsible business principles. Due to the limited number of com-panies it is not possible to extend the findings and conclusions to the whole population. Originality/value: The paper presents the business point of view on the issue of collaborative business models and their relations with social responsibility. The issue of responsibility was presented as a key element of multiple value creation. The chosen research method allowed to present the voice of business representatives. It can be treated as an initial step of further research. Paper type: research paper.",2018,"[{'authorId': '152234485', 'name': 'Agata Rudnicka'}]","{'url': 'https://doi.org/10.12775/jcrl.2017.021', 'status': 'GOLD', 'license': 'CCBYND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.12775/JCRL.2017.021?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.12775/JCRL.2017.021, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose: the main aim of the paper is to analyse common aspects of the concepts of corporate social responsibility and collaborative economy through identifying the issues of social responsibility included in the collaborative economy business models. design/methodology/approach: firstly, the questionnaire survey was used to gather the opinions of the participants of the confer-ence assembling the representatives of sharing and collaborative businesses in poland. secondly, there were conducted two individ-ual in-depth interviews with ceos of businesses active in the col-laborative economy sector. the aim of this phase was to illustrate the theoretical framework with practical business experiences. findings: there are strong relations among collaborative econ-omy and corporate social responsibility. the research results suggest that business models in collaborative economy approach are designed to multiple value creation for a broader group of stakeholders rather than only for clients and an organisation. con-ducted research revealed that the issue of responsibility even if not clearly communicated is a very important element of business models’ dna especially in its social dimension. research and practical limitations/implications: the research results can be useful for practitioners establishing new ventures and seeking for business models including collaborative and responsible business principles. due to the limited number of com-panies it is not possible to extend the findings and conclusions to the whole population. originality/value: the paper presents the business point of view on the issue of collaborative business models and their relations with social responsibility. the issue of responsibility was presented as a key element of multiple value creation. the chosen research method allowed to present the voice of business representatives. it can be treated as an initial step of further research. paper type: research paper.",https://doi.org/10.12775/jcrl.2017.021
aab0a9b3b89fa5abdaf00a4e7ed1ffae8d24ab0a,Blockchain in Collaborative Economy business models,"In the last decade, we have witnessed the emergence of a new socioeconomic paradigm related to Internet-based virtual communities that promote practices of sharing the use or consumption of products and services: the collaborative economy. Despite growing research on the most diverse areas of the collaborative economy, research on the integration of blockchain systems into collaborative economy organizations is still rather limited. By the present investigation, purely explanatory and based on a comparative and interpretive case study, we intend to verify the susceptibility of the blockchain systems to foster the emergence of new business models. Due to the small number of organizations in the collaborative economy currently operating with blockchain-based business models, it will be important in future investigations to identify and study the influence of these systems on the business models of other organizations, in particular whether their adoption represents a source of competitive advantage.",2019,"[{'authorId': '1413812835', 'name': 'Fernando Belezas'}, {'authorId': '1403090147', 'name': 'M. Au-Yong-Oliveira'}, {'authorId': '144072673', 'name': 'F. Branco'}, {'authorId': '123956631', 'name': 'R. Gonçalves'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.23919/CISTI.2019.8760602?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.23919/CISTI.2019.8760602, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the last decade, we have witnessed the emergence of a new socioeconomic paradigm related to internet-based virtual communities that promote practices of sharing the use or consumption of products and services: the collaborative economy. despite growing research on the most diverse areas of the collaborative economy, research on the integration of blockchain systems into collaborative economy organizations is still rather limited. by the present investigation, purely explanatory and based on a comparative and interpretive case study, we intend to verify the susceptibility of the blockchain systems to foster the emergence of new business models. due to the small number of organizations in the collaborative economy currently operating with blockchain-based business models, it will be important in future investigations to identify and study the influence of these systems on the business models of other organizations, in particular whether their adoption represents a source of competitive advantage.",
f757437bd150f022bbc2b746cc4e4ef25d918df5,Sustainability in the Circular Economy: Insights and Dynamics of Designing Circular Business Models,"The integration of sustainability in the circular economy is an emerging paradigm that can offer a long term vision to achieve environmental and social sustainability targets in line with the United Nation’s Sustainable Development Goals. Developing scalable and sustainable impacts in circular economy business models (CEBMs) has many challenges. While many advanced technology manufacturing firms start as small enterprises, remarkably little is known about how material reuse firms in sociotechnical systems transition towards circular business models. Research into CEBMs integrating sustainability and environmental conservation is still in its early stages. There has been increased interest in sustainability and circular economy research, but current research is fragmented. The innovation surrounding CEBMs eludes some firms with relatively limited evidence of the transitional perspective necessary to integrate aspects of sustainability. This lack of evidence is especially applicable to the context of circular economy practices in small and medium enterprises in the United States regarding capabilities, operations obstacles, and elements of success in designing circular business models. Based on a qualitative, interview-based inductive study of a material reuse firm, our research develops a conceptual model of the critical success factors and obstacles that are part of implementing circular economy practices. Firms must first manage strategic enablers and monitor tactical enablers to achieve sustainability goals. In this study, we identify the underlying enablers of how these capabilities affect the transition to a CEBM that integrates sustainability. The framework emerging from our findings highlights the interplay of CEBM, innovation success factors, and obstacles at a micro-level. The investigation of a material reuse firm serves as the foundation for developing a framework for how managers can alter a company and revise the business model to transition towards a more innovative circular economy.",2022,"[{'authorId': '13259093', 'name': 'Usama Awan'}, {'authorId': '2931155', 'name': 'Robert Sroufe'}]","{'url': 'https://www.mdpi.com/2076-3417/12/3/1521/pdf?version=1644386831', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app12031521?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app12031521, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the integration of sustainability in the circular economy is an emerging paradigm that can offer a long term vision to achieve environmental and social sustainability targets in line with the united nation’s sustainable development goals. developing scalable and sustainable impacts in circular economy business models (cebms) has many challenges. while many advanced technology manufacturing firms start as small enterprises, remarkably little is known about how material reuse firms in sociotechnical systems transition towards circular business models. research into cebms integrating sustainability and environmental conservation is still in its early stages. there has been increased interest in sustainability and circular economy research, but current research is fragmented. the innovation surrounding cebms eludes some firms with relatively limited evidence of the transitional perspective necessary to integrate aspects of sustainability. this lack of evidence is especially applicable to the context of circular economy practices in small and medium enterprises in the united states regarding capabilities, operations obstacles, and elements of success in designing circular business models. based on a qualitative, interview-based inductive study of a material reuse firm, our research develops a conceptual model of the critical success factors and obstacles that are part of implementing circular economy practices. firms must first manage strategic enablers and monitor tactical enablers to achieve sustainability goals. in this study, we identify the underlying enablers of how these capabilities affect the transition to a cebm that integrates sustainability. the framework emerging from our findings highlights the interplay of cebm, innovation success factors, and obstacles at a micro-level. the investigation of a material reuse firm serves as the foundation for developing a framework for how managers can alter a company and revise the business model to transition towards a more innovative circular economy.",https://www.mdpi.com/2076-3417/12/3/1521/pdf?version=1644386831
437e569724b454aab00a819653a68125cb5f30ea,Designing the Business Models for Circular Economy—Towards the Conceptual Framework,"Switching from the current linear model of economy to a circular one has recently attracted increased attention from major global companies e.g., Google, Unilever, Renault, and policymakers attending the World Economic Forum. The reasons for this are the huge financial, social and environmental benefits. However, the global shift from one model of economy to another also concerns smaller companies on a micro-level. Thus, comprehensive knowledge on designing circular business models is needed to stimulate and foster implementation of the circular economy. Existing business models for the circular economy have limited transferability and there is no comprehensive framework supporting every kind of company in designing a circular business model. This study employs a literature review to identify and classify the circular economy characteristics according to a business model structure. The investigation in the eight sub-domains of research on circular business models was used to redefine the components of the business model canvas in the context of the circular economy. Two new components—the take-back system and adoption factors—have been identified, thereby leading to the conceptualization of an extended framework for the circular business model canvas. Additionally, the triple fit challenge has been recognized as an enabler of the transition towards a circular business model. Some directions for further research have been outlined, as well.",2016,"[{'authorId': '91090474', 'name': 'M. Lewandowski'}]","{'url': 'https://www.mdpi.com/2071-1050/8/1/43/pdf?version=1453104779', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/SU8010043?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/SU8010043, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","switching from the current linear model of economy to a circular one has recently attracted increased attention from major global companies e.g., google, unilever, renault, and policymakers attending the world economic forum. the reasons for this are the huge financial, social and environmental benefits. however, the global shift from one model of economy to another also concerns smaller companies on a micro-level. thus, comprehensive knowledge on designing circular business models is needed to stimulate and foster implementation of the circular economy. existing business models for the circular economy have limited transferability and there is no comprehensive framework supporting every kind of company in designing a circular business model. this study employs a literature review to identify and classify the circular economy characteristics according to a business model structure. the investigation in the eight sub-domains of research on circular business models was used to redefine the components of the business model canvas in the context of the circular economy. two new components—the take-back system and adoption factors—have been identified, thereby leading to the conceptualization of an extended framework for the circular business model canvas. additionally, the triple fit challenge has been recognized as an enabler of the transition towards a circular business model. some directions for further research have been outlined, as well.",https://www.mdpi.com/2071-1050/8/1/43/pdf?version=1453104779
f72e8f893a7d6fb00900ae6e1f30fd55fb6ff95e,How start-ups in emerging economies embrace circular business models and contribute towards a circular economy,"
Purpose
The purpose of this paper is to investigate the practices that start-ups in emerging economies can implement to design circular economy business models and how they can create and capture value from a circular economy business model.


Design/methodology/approach
The paper adopts a qualitative case method approach with semi-structured interviews with start-up founder promoters, its employees, its beneficiaries and its customers, conducted in two local Indian start-ups engaged in the manufacture of products and providing services that promote adoption of circular economy principles.


Findings
Analysis of the two business models reveals common patterns in building value proposition. The findings suggest that start-up ventures adopt an iterative approach to produce reusable and interlinked products and co-create with customers, vendors and local communities. They adopt mechanisms that can create, deliver and capture value while maintaining economic viability, and thus contribute towards micro- and macro-level benefits.


Research limitations/implications
This study maximizes the depth of the phenomenon under investigation by leveraging case study methodology. Future research opportunities could be found in quantitative studies to increase the generalizability of the findings of this paper.


Practical implications
The paper presents a theoretical model linking the circular business model design and deployment mechanisms that can be used by start-up entrepreneurs desirous of embracing circular economy principles and thus contribute towards environmental, economic and developmental goals in emerging economies.


Social implications
To accelerate the transition of adoption of circularity principles in emerging markets, start-up ventures could adopt circular business models that contribute towards achieving positive behavioural change. This can be achieved by integrating with different stakeholders in the value network such that they play a vital role in the process of value creation and delivery and benefit from the value captured.


Originality/value
An interdisciplinary approach that integrates the research streams of circular economy, and business model design has been pursued to identify the design and deployment mechanisms adopted in the circular business models of start-ups in real-world emerging economies’ context.
",2022,"[{'authorId': '11317173', 'name': 'S. Mehrotra'}, {'authorId': '1517956140', 'name': 'Santosh Rupa Jaladi'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/jeee-10-2021-0410?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/jeee-10-2021-0410, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose the purpose of this paper is to investigate the practices that start-ups in emerging economies can implement to design circular economy business models and how they can create and capture value from a circular economy business model. design/methodology/approach the paper adopts a qualitative case method approach with semi-structured interviews with start-up founder promoters, its employees, its beneficiaries and its customers, conducted in two local indian start-ups engaged in the manufacture of products and providing services that promote adoption of circular economy principles. findings analysis of the two business models reveals common patterns in building value proposition. the findings suggest that start-up ventures adopt an iterative approach to produce reusable and interlinked products and co-create with customers, vendors and local communities. they adopt mechanisms that can create, deliver and capture value while maintaining economic viability, and thus contribute towards micro- and macro-level benefits. research limitations/implications this study maximizes the depth of the phenomenon under investigation by leveraging case study methodology. future research opportunities could be found in quantitative studies to increase the generalizability of the findings of this paper. practical implications the paper presents a theoretical model linking the circular business model design and deployment mechanisms that can be used by start-up entrepreneurs desirous of embracing circular economy principles and thus contribute towards environmental, economic and developmental goals in emerging economies. social implications to accelerate the transition of adoption of circularity principles in emerging markets, start-up ventures could adopt circular business models that contribute towards achieving positive behavioural change. this can be achieved by integrating with different stakeholders in the value network such that they play a vital role in the process of value creation and delivery and benefit from the value captured. originality/value an interdisciplinary approach that integrates the research streams of circular economy, and business model design has been pursued to identify the design and deployment mechanisms adopted in the circular business models of start-ups in real-world emerging economies’ context.",
aac11d049e9de821705dba8af9f00cde5ab5a3e0,Designing business models in circular economy: A systematic literature review and research agenda,"The concept of circular economy is increasingly receiving attention in different domains, including strategic management, operations management, and technology management. It requires companies to design their business model (i.e., the value network, the relationships with the supply chain partners, and the value propositions towards customers) around a new concept of sustainable development that reduces consumption of natural resources and preserves the environment. However, extant research falls short in terms of explaining how companies design their business model according to the circular economy principles. Starting from this premise, the present paper provides a systematic review of the literature on the design of business models in the context of circular economy, aiming to offer an overview of the state of research and outline a promising research agenda.",2020,"[{'authorId': '2005325', 'name': 'Piera Centobelli'}, {'authorId': '10665249', 'name': 'Roberto Cerchione'}, {'authorId': '31861970', 'name': 'D. Chiaroni'}, {'authorId': '31868646', 'name': 'Pasquale Del Vecchio'}, {'authorId': '83946847', 'name': 'Andrea Urbinati'}]","{'url': 'https://hdl.handle.net/11311/1154730', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/bse.2466?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/bse.2466, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the concept of circular economy is increasingly receiving attention in different domains, including strategic management, operations management, and technology management. it requires companies to design their business model (i.e., the value network, the relationships with the supply chain partners, and the value propositions towards customers) around a new concept of sustainable development that reduces consumption of natural resources and preserves the environment. however, extant research falls short in terms of explaining how companies design their business model according to the circular economy principles. starting from this premise, the present paper provides a systematic review of the literature on the design of business models in the context of circular economy, aiming to offer an overview of the state of research and outline a promising research agenda.",https://hdl.handle.net/11311/1154730
186addf3ff472e703875b6cd04a9dc80770f721e,How to innovate business models for a circular bio‐economy?,"Shifting from a linear to a circular bio-economy requires new business models. The objective was getting insights into the uncharted research field of business model innovation for a circular and sustainable bio-economy within the agrifood sector. Eight European cases valorising agricultural waste and by-products by closing loops or cascading were studied regarding their innovation drivers and elements, via interviews, on-site visits and secondary data. In this domain, the findings highlight that business model innovations are depending on the (i) macro-environmental institutional-legal conditions and market trends, (ii) driven by internal economic, environmental and/or social objectives, but especially strongly linked to (iii) other actors often from different sectors seeking synergies and (iv) value co-creation via combined organisational and technological innovations. Business models for a circular bio-economy thus depend on various action levels and need radical combined organisational and technological innovations for a most efficient usage of agricultural waste and by-products. This also means new business configurations instead of linear innovation strategies currently still being dominant due to economic viability.",2021,"[{'authorId': '72288468', 'name': 'M. Donner'}, {'authorId': '145796682', 'name': 'H. D. Vries'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/bse.2725', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/BSE.2725?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/BSE.2725, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","shifting from a linear to a circular bio-economy requires new business models. the objective was getting insights into the uncharted research field of business model innovation for a circular and sustainable bio-economy within the agrifood sector. eight european cases valorising agricultural waste and by-products by closing loops or cascading were studied regarding their innovation drivers and elements, via interviews, on-site visits and secondary data. in this domain, the findings highlight that business model innovations are depending on the (i) macro-environmental institutional-legal conditions and market trends, (ii) driven by internal economic, environmental and/or social objectives, but especially strongly linked to (iii) other actors often from different sectors seeking synergies and (iv) value co-creation via combined organisational and technological innovations. business models for a circular bio-economy thus depend on various action levels and need radical combined organisational and technological innovations for a most efficient usage of agricultural waste and by-products. this also means new business configurations instead of linear innovation strategies currently still being dominant due to economic viability.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/bse.2725
247acf790d1cf72fba6a6b9d4e97cc5bff03b7a7,Exploring How Usage-Focused Business Models Enable Circular Economy through Digital Technologies,"Recent studies advocate that digital technologies are key enabling factors for the introduction of servitized business models. At the same time, these technologies support the implementation of the circular economy (CE) paradigm into businesses. Despite this general agreement, the literature still overlooks how digital technologies enable such a CE transition. To fill the gap, this paper develops a conceptual framework, based on the literature and a case study of a company implementing a usage-focused servitized business model in the household appliance industry. This study focuses on the Internet of Things (IoT), Big Data, and analytics, and identifies eight specific functionalities enabled by such technologies (improving product design, attracting target customers, monitoring and tracking product activity, providing technical support, providing preventive and predictive maintenance, optimizing the product usage, upgrading the product, enhancing renovation and end-of-life activities). By investigating how these functionalities affect three CE value drivers (increasing resource efficiency, extending lifespan, and closing the loop), the conceptual framework developed in this paper advances knowledge about the role of digital technologies as an enabler of the CE within usage-focused business models. Finally, this study shows how digital technologies help overcome the drawback of usage-focused business models for the adoption of CE pointed out by previous literature.",2018,"[{'authorId': '101312446', 'name': 'Gianmarco Bressanelli'}, {'authorId': '2214026', 'name': 'F. Adrodegari'}, {'authorId': '145134548', 'name': 'M. Perona'}, {'authorId': '2017441', 'name': 'N. Saccani'}]","{'url': 'https://www.mdpi.com/2071-1050/10/3/639/pdf?version=1519819004', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/SU10030639?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/SU10030639, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent studies advocate that digital technologies are key enabling factors for the introduction of servitized business models. at the same time, these technologies support the implementation of the circular economy (ce) paradigm into businesses. despite this general agreement, the literature still overlooks how digital technologies enable such a ce transition. to fill the gap, this paper develops a conceptual framework, based on the literature and a case study of a company implementing a usage-focused servitized business model in the household appliance industry. this study focuses on the internet of things (iot), big data, and analytics, and identifies eight specific functionalities enabled by such technologies (improving product design, attracting target customers, monitoring and tracking product activity, providing technical support, providing preventive and predictive maintenance, optimizing the product usage, upgrading the product, enhancing renovation and end-of-life activities). by investigating how these functionalities affect three ce value drivers (increasing resource efficiency, extending lifespan, and closing the loop), the conceptual framework developed in this paper advances knowledge about the role of digital technologies as an enabler of the ce within usage-focused business models. finally, this study shows how digital technologies help overcome the drawback of usage-focused business models for the adoption of ce pointed out by previous literature.",https://www.mdpi.com/2071-1050/10/3/639/pdf?version=1519819004
c2cebf26ab1302220ecf1d80f9a402debee63cb6,How do incumbent firms innovate their business models for the circular economy? Identifying micro‐foundations of dynamic capabilities,"The circular economy is promoted as a contributor to sustainable development;however, the process of circular business model innovation remains under-explored to date, hindering its implementation. Dynamic capabilities research provides a theoretical perspective to explore how incumbent firms can innovate in rapidly changing environments. An abductive qualitative research is done through an exploratory multiple case study on 10 incumbents that implemented a circular business model innovation. We identify 26 practices, aggregated in 12 micro-foundations of the dynamic capabilities of sensing, seizing, and reconfiguring. By integrating the few empirical studies characterizing dynamic capabilities for sustainability-oriented business model innovation, we offer a comprehensive framework of 33 practices. This study proposes that the most relevant practices for circular business model innovation processes are adopting a lifecycle perspective, employing sustainability-oriented instruments, ideating sustainable value propositions, developing a sustainability strategy and culture, and engaging and coordinating stakeholders in the business ecosystem. We also suggest seven particularly relevant practices for long-term business model transformations (e.g., top management commitment), four for innovations focused on short and medium loops of the circular economy (e.g., early customer engagement), and four for long loops (e.g., business ecosystem coordination). This study corroborates and expands recent research on dynamic capabilities for sustainability-oriented innovation and provides practitioners with a set of 33 skills, processes, procedures, and activities to be prioritized to successfully innovate their business models for the circular economy.",2021,"[{'authorId': '2096261505', 'name': 'Tomas Santa‐Maria'}, {'authorId': '87258760', 'name': 'W. Vermeulen'}, {'authorId': '15097000', 'name': 'R. Baumgartner'}]","{'url': 'https://unipub.uni-graz.at/obvugrfodok/content/titleinfo/6988834/full.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/bse.2956?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/bse.2956, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the circular economy is promoted as a contributor to sustainable development;however, the process of circular business model innovation remains under-explored to date, hindering its implementation. dynamic capabilities research provides a theoretical perspective to explore how incumbent firms can innovate in rapidly changing environments. an abductive qualitative research is done through an exploratory multiple case study on 10 incumbents that implemented a circular business model innovation. we identify 26 practices, aggregated in 12 micro-foundations of the dynamic capabilities of sensing, seizing, and reconfiguring. by integrating the few empirical studies characterizing dynamic capabilities for sustainability-oriented business model innovation, we offer a comprehensive framework of 33 practices. this study proposes that the most relevant practices for circular business model innovation processes are adopting a lifecycle perspective, employing sustainability-oriented instruments, ideating sustainable value propositions, developing a sustainability strategy and culture, and engaging and coordinating stakeholders in the business ecosystem. we also suggest seven particularly relevant practices for long-term business model transformations (e.g., top management commitment), four for innovations focused on short and medium loops of the circular economy (e.g., early customer engagement), and four for long loops (e.g., business ecosystem coordination). this study corroborates and expands recent research on dynamic capabilities for sustainability-oriented innovation and provides practitioners with a set of 33 skills, processes, procedures, and activities to be prioritized to successfully innovate their business models for the circular economy.",https://unipub.uni-graz.at/obvugrfodok/content/titleinfo/6988834/full.pdf
a144df50f06681094f558d6d6738d601bb3fe25a,Business models for the circular economy: Opportunities and challenges,"This is a call for papers for a special issue of the journal, Business Strategy and the Environment. The special issue aims to collect original and high-quality studies on how business models inform the perspective of the circular economy. Works were encouraged that analyze BMCs at the level of individual managers, single companies, value networks and industrial ecosystems. Particularly welcome were economic, management and sustainability theories and applications that specifically address the current challenges of designing, implementing and diffusing BMCs.",2019,"[{'authorId': '51221636', 'name': 'L. Fraccascia'}, {'authorId': '3348602', 'name': 'I. Giannoccaro'}, {'authorId': '50714295', 'name': 'A. Agarwal'}, {'authorId': '24168366', 'name': 'E. Hansen'}]","{'url': 'https://ris.utwente.nl/ws/files/97078894/Fraccascia_et_al_2019_Business_Strategy_and_the_Environment.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/BSE.2285?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/BSE.2285, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this is a call for papers for a special issue of the journal, business strategy and the environment. the special issue aims to collect original and high-quality studies on how business models inform the perspective of the circular economy. works were encouraged that analyze bmcs at the level of individual managers, single companies, value networks and industrial ecosystems. particularly welcome were economic, management and sustainability theories and applications that specifically address the current challenges of designing, implementing and diffusing bmcs.",https://ris.utwente.nl/ws/files/97078894/Fraccascia_et_al_2019_Business_Strategy_and_the_Environment.pdf
4f10ba8dd92e1532ec5b525a302e7ce933fcff52,Configuring New Business Models for Circular Economy through Product–Service Systems,"Product—service systems (PSSs) are often outlined as potential enablers of new business models for circular economy. However, not all business models based on product-service systems have superior circularity potential. This research demonstrates how the application of a previously developed business model configurator for circular economy can support the design and assessment of customer value, economic and resource decoupling potential for product-service system business models in practice. By applying action research in two Nordic manufacturing companies from the furniture sector, different business model concepts based on product-service systems were proposed and assessed. Results indicate positive uptake by companies regarding the usefulness of the obtained outcomes. This research identified two key findings about ‘product-service system business models for circular economy’: (i) their configuration should fulfil certain simultaneous conditions—i.e. superior customer value, economic growth, and resource decoupling potential—to contribute to circular economy; and (ii) they are often ‘niche solutions’, fulfilling specific needs and customer segments, and more likely to flourish with certain types/characteristic of products, segments or geographical locations. Lastly, a framework outlining the conditions and trade-offs for assessing the circularity potential of business models based on product-service systems is introduced as one of the key contributions.",2019,"[{'authorId': '2124212052', 'name': 'Marina P. P. Pieroni'}, {'authorId': '2130550325', 'name': 'Tim C. McAloone'}, {'authorId': '2130516890', 'name': 'Daniela C. A. Pigosso'}]","{'url': 'https://www.mdpi.com/2071-1050/11/13/3727/pdf?version=1562590436', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su11133727?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su11133727, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","product—service systems (psss) are often outlined as potential enablers of new business models for circular economy. however, not all business models based on product-service systems have superior circularity potential. this research demonstrates how the application of a previously developed business model configurator for circular economy can support the design and assessment of customer value, economic and resource decoupling potential for product-service system business models in practice. by applying action research in two nordic manufacturing companies from the furniture sector, different business model concepts based on product-service systems were proposed and assessed. results indicate positive uptake by companies regarding the usefulness of the obtained outcomes. this research identified two key findings about ‘product-service system business models for circular economy’: (i) their configuration should fulfil certain simultaneous conditions—i.e. superior customer value, economic growth, and resource decoupling potential—to contribute to circular economy; and (ii) they are often ‘niche solutions’, fulfilling specific needs and customer segments, and more likely to flourish with certain types/characteristic of products, segments or geographical locations. lastly, a framework outlining the conditions and trade-offs for assessing the circularity potential of business models based on product-service systems is introduced as one of the key contributions.",https://www.mdpi.com/2071-1050/11/13/3727/pdf?version=1562590436
9517edb861363e8e7f50d5efe7a7148fa9814e6a,Surviving in the digital era – business models of digital enterprises in a developing economy,"
Purpose
This study aims to explore the business models and strategies of digital enterprises in a developing economy context to understand the nature of their operations, as well as their survival tactics.


Design/methodology/approach
A review of literature on digital enterprise models led to the adaptation of a 16 business model archetype for analyzing digital enterprises in Ghana. Using a critical realism perspective, survey data from a sample of 91 digital enterprises were used for the study.


Findings
The findings suggest that among human, physical and intangible assets, financial assets were the least used assets in the operations of the digital enterprises. This stems from the fact that the online financial business sector is still in its nascent stages in most developing economies. The findings further suggest that all digital enterprises leverage on accessible and low-cost social networking services as part of their operations and use them as an avenue to engage with their target customers.


Research limitations/implications
The findings from this study provide guidelines to entrepreneurs who wish to venture into the digital ecosystem of Ghana, particularly with regard to the economic, financial and technological factors that enable digital enterprises to survive in the competitive digital economy.


Practical implications
The findings suggest that it is important for governments to realize that there is an increasing rise in digital enterprises in the developing economies and these enterprises are creating jobs and providing business solutions locally that would hitherto be sought from developed economies. There is therefore the need for the requisite legal infrastructure and financial support that will cushion these enterprises from the fierce competitions that stagnate their growth.


Originality/value
The study provides a mapping of the digital business models of Ghanaian digital enterprises. This knowledge is arguably the first of its kind in the context of a developing economy. Hence, it serves as a stepping-stone for future studies to explore other areas in the digital economy, especially from a developing economy perspective.
",2019,"[{'authorId': '31690783', 'name': 'Eric Ansong'}, {'authorId': '144447487', 'name': 'R. Boateng'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/DPRG-08-2018-0046?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/DPRG-08-2018-0046, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose this study aims to explore the business models and strategies of digital enterprises in a developing economy context to understand the nature of their operations, as well as their survival tactics. design/methodology/approach a review of literature on digital enterprise models led to the adaptation of a 16 business model archetype for analyzing digital enterprises in ghana. using a critical realism perspective, survey data from a sample of 91 digital enterprises were used for the study. findings the findings suggest that among human, physical and intangible assets, financial assets were the least used assets in the operations of the digital enterprises. this stems from the fact that the online financial business sector is still in its nascent stages in most developing economies. the findings further suggest that all digital enterprises leverage on accessible and low-cost social networking services as part of their operations and use them as an avenue to engage with their target customers. research limitations/implications the findings from this study provide guidelines to entrepreneurs who wish to venture into the digital ecosystem of ghana, particularly with regard to the economic, financial and technological factors that enable digital enterprises to survive in the competitive digital economy. practical implications the findings suggest that it is important for governments to realize that there is an increasing rise in digital enterprises in the developing economies and these enterprises are creating jobs and providing business solutions locally that would hitherto be sought from developed economies. there is therefore the need for the requisite legal infrastructure and financial support that will cushion these enterprises from the fierce competitions that stagnate their growth. originality/value the study provides a mapping of the digital business models of ghanaian digital enterprises. this knowledge is arguably the first of its kind in the context of a developing economy. hence, it serves as a stepping-stone for future studies to explore other areas in the digital economy, especially from a developing economy perspective.",
81990a78d04e7f691bfd2a018ffe5ef563036643,Circular Business Models for the Bio-Economy: A Review and New Directions for Future Research,"Circular and bio-economy represents a political and industrial initiative to ensure that our society can rely on renewable biological sources while achieving economic growth. However, there is a need to critical review how realistic and feasible such initiatives are towards fulfilling the promised benefits of this economy. The literature on bio-economy often discusses the importance of innovative business models and their role in a successful shift to a bio-economy. Still, much of the discussion that is related to circular business models is fragmented and immature. Therefore, the purpose of this study is to conduct a systematic literature review of circular business model activities and the barriers to a bio-economy. Further, this review provides future research directions for a shift to a bio-economy. This study is based on a systematic review of 42 scientific journal articles and book chapters on a forest-based bio-economy. The business model canvas is used to provide a structured aggregation of the existing circular business models activities being used by the forestry sector. In addition, we develop a framework that describes the barriers to bio-economy-based circular business models and suggest new directions for future research. The study highlights the need for alignment among the elements of a business model as a key condition for its successful implementation in a bio-economy.",2019,"[{'authorId': '119371810', 'name': 'W. Reim'}, {'authorId': '2925791', 'name': 'V. Parida'}, {'authorId': '2002141', 'name': 'D. Sjödin'}]","{'url': 'https://www.mdpi.com/2071-1050/11/9/2558/pdf?version=1556853063', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/SU11092558?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/SU11092558, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","circular and bio-economy represents a political and industrial initiative to ensure that our society can rely on renewable biological sources while achieving economic growth. however, there is a need to critical review how realistic and feasible such initiatives are towards fulfilling the promised benefits of this economy. the literature on bio-economy often discusses the importance of innovative business models and their role in a successful shift to a bio-economy. still, much of the discussion that is related to circular business models is fragmented and immature. therefore, the purpose of this study is to conduct a systematic literature review of circular business model activities and the barriers to a bio-economy. further, this review provides future research directions for a shift to a bio-economy. this study is based on a systematic review of 42 scientific journal articles and book chapters on a forest-based bio-economy. the business model canvas is used to provide a structured aggregation of the existing circular business models activities being used by the forestry sector. in addition, we develop a framework that describes the barriers to bio-economy-based circular business models and suggest new directions for future research. the study highlights the need for alignment among the elements of a business model as a key condition for its successful implementation in a bio-economy.",https://www.mdpi.com/2071-1050/11/9/2558/pdf?version=1556853063
1250f886ed5c96caa1a2248d9cc153b6a4b88b21,Theoretical and Practical Approaches of Circular Economy for Business Models and Technological Solutions,"Circular solutions are essential to tackle the imminent challenges of depleting resources and emerging environmental problems. The complex nature of material and energy systems and the changing economic and technological conditions depend on regional settings and accordingly result differently in developed and rapidly developing countries of the world. A wide variety of theoretical approaches can be used to facilitate a shift from the linear use of resources to circular systems, e.g., circular product planning, zero waste management, service-based repairing, refurbishing, and remanufacturing, to name just a few. The introduction and examination of circular solutions can be based on theoretical models in order to guarantee and ensure a successful application. The successful application of innovative technology approaches, business solutions, and organizational development can be facilitated through theoretical models and new scientific results that support innovation processes. The presented article focuses on sustainable and innovative methods that help and enable the proper use and recovery of resources.",2020,"[{'authorId': '69579172', 'name': 'C. Fogarassy'}, {'authorId': '36179421', 'name': 'D. Finger'}]","{'url': 'https://www.mdpi.com/2079-9276/9/6/76/pdf?version=1592795026', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/resources9060076?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/resources9060076, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","circular solutions are essential to tackle the imminent challenges of depleting resources and emerging environmental problems. the complex nature of material and energy systems and the changing economic and technological conditions depend on regional settings and accordingly result differently in developed and rapidly developing countries of the world. a wide variety of theoretical approaches can be used to facilitate a shift from the linear use of resources to circular systems, e.g., circular product planning, zero waste management, service-based repairing, refurbishing, and remanufacturing, to name just a few. the introduction and examination of circular solutions can be based on theoretical models in order to guarantee and ensure a successful application. the successful application of innovative technology approaches, business solutions, and organizational development can be facilitated through theoretical models and new scientific results that support innovation processes. the presented article focuses on sustainable and innovative methods that help and enable the proper use and recovery of resources.",https://www.mdpi.com/2079-9276/9/6/76/pdf?version=1592795026
0844c8a55f2580f18af46092561a3d35446d9d64,Transforming business models: towards a sufficiency-based circular economy,"Business model innovation for a circular economy has become core to contemporary sustainability research and practice, but does it go far enough? While circular economy initiatives have closed and narrowed resource loops to some extent, overall consumption continues to rise offsetting much of the benefits. A further paradigm shift is necessary, going beyond existing solutions, towards a broader societal-wide approach to deliver aÂ sufficiency-based circular economy.Â That is, a society where excessive levels of consumption (and production) are curtailed at their root cause to better satisfy the health and wellbeing needs of the individual consumer, broader society and global environment. We present sufficiency examples in the food and clothing sector and explore how such approaches can augment existing circular economy solutions. We present a framework to better understand how industry, society and policymakers might collaborate more effectively in designing and implementing long-term initiatives for moving towards a sufficiency-based circular economy.",2020,"[{'authorId': '2463177', 'name': 'N. Bocken'}, {'authorId': '3340648', 'name': 'S. Short'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4337/9781788972727.00028?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4337/9781788972727.00028, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","business model innovation for a circular economy has become core to contemporary sustainability research and practice, but does it go far enough? while circular economy initiatives have closed and narrowed resource loops to some extent, overall consumption continues to rise offsetting much of the benefits. a further paradigm shift is necessary, going beyond existing solutions, towards a broader societal-wide approach to deliver aâ sufficiency-based circular economy.â that is, a society where excessive levels of consumption (and production) are curtailed at their root cause to better satisfy the health and wellbeing needs of the individual consumer, broader society and global environment. we present sufficiency examples in the food and clothing sector and explore how such approaches can augment existing circular economy solutions. we present a framework to better understand how industry, society and policymakers might collaborate more effectively in designing and implementing long-term initiatives for moving towards a sufficiency-based circular economy.",
bcf75d37922b961ff90959a75416169fc13186ee,Digital Entrepreneurship: Innovative Business Models for the Sharing Economy,"What's mine is yours. An increasing number of people are participating in sharing and exchanging information, knowledge, data and goods. As research addressing the so-called ‘sharing economy’ is still in its infancy, this article aims to shed light on it. To do this, a qualitative research approach comprising guided interviews with 14 companies from Germany, Austria and Switzerland provides detailed insights into different aspects of the sharing economy phenomenon. Our results make a direct contribution to sharing economy research, especially regarding the new business models of start-ups. Here, we find a clear difference between the relevance of economic and social orientation. The latter appears to be in higher demand among customers than entrepreneurs. The increasingly digitalized environment has led to a changed living situation characterized by urbanity, openness to new solutions, changed working situations and new mindsets. All of these aspects drive the sharing economy. The results of this paper are summarized in a framework highlighting the requirements, drivers and goals of the sharing economy. Considering the limited research in this field, the developed framework is a strong basis for discussion, critique and/or support of future research.",2017,"[{'authorId': '2053647638', 'name': 'Chris Richter'}, {'authorId': '17743559', 'name': 'S. Kraus'}, {'authorId': '40653746', 'name': 'A. Brem'}, {'authorId': '1779069', 'name': 'S. Durst'}, {'authorId': '2080955539', 'name': 'Clemens Giselbrecht'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/caim.12227?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/caim.12227, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","what's mine is yours. an increasing number of people are participating in sharing and exchanging information, knowledge, data and goods. as research addressing the so-called ‘sharing economy’ is still in its infancy, this article aims to shed light on it. to do this, a qualitative research approach comprising guided interviews with 14 companies from germany, austria and switzerland provides detailed insights into different aspects of the sharing economy phenomenon. our results make a direct contribution to sharing economy research, especially regarding the new business models of start-ups. here, we find a clear difference between the relevance of economic and social orientation. the latter appears to be in higher demand among customers than entrepreneurs. the increasingly digitalized environment has led to a changed living situation characterized by urbanity, openness to new solutions, changed working situations and new mindsets. all of these aspects drive the sharing economy. the results of this paper are summarized in a framework highlighting the requirements, drivers and goals of the sharing economy. considering the limited research in this field, the developed framework is a strong basis for discussion, critique and/or support of future research.",
fbd53cc5a5d69e73bcf6b28f60493b8464841b8c,"“I like it, but I don't use it”: Impact of carsharing business models on usage intentions in the sharing economy","Carsharing is often promoted as a potentially environmental-friendly alternative to individual
car ownership. However, various carsharing programs have displayed limited success in the
past. An initial field study of a new carsharing service is such a story of failure: The
introduction of this new service at a medium-sized German university generated
unexpectedly low adoption rates so that the service was eventually scaled-down and then
suspended. Quantitative field study results as well as additional qualitative focus groups
reveal that missing compatibility is a key barrier to adoption. Drawing on extant conceptual
frameworks of user participation in sharing business models, a factorial survey identifies the
importance of different dimensions of carsharing business models for their acceptance. The
results reveal that a set of convenience and lifestyle dimensions influences usage intentions,
including mode of drive, pick-up and drop-off mode, service level, price model, availability,
and type of market mediation. In contrast, vehicle fleet does not appear to influence
carsharing models’ acceptance. These findings contribute to research on business model
configuration as well as the attitude-behavior gap in the sharing economy by determining
relevant dimensions of a carsharing business model which can bridge the gap between
basically positive attitudes and usage resistance. Thereby they also serve for concrete
managerial recommendations.",2019,"[{'authorId': '118001123', 'name': 'Rüdiger Hahn'}, {'authorId': '12318239', 'name': 'Felix Ostertag'}, {'authorId': '2060998808', 'name': 'Adrian Lehr'}, {'authorId': '2067736534', 'name': 'M. Büttgen'}, {'authorId': '145401648', 'name': 'S. Benoit'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/bse.2441', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/bse.2441?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/bse.2441, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","carsharing is often promoted as a potentially environmental-friendly alternative to individual car ownership. however, various carsharing programs have displayed limited success in the past. an initial field study of a new carsharing service is such a story of failure: the introduction of this new service at a medium-sized german university generated unexpectedly low adoption rates so that the service was eventually scaled-down and then suspended. quantitative field study results as well as additional qualitative focus groups reveal that missing compatibility is a key barrier to adoption. drawing on extant conceptual frameworks of user participation in sharing business models, a factorial survey identifies the importance of different dimensions of carsharing business models for their acceptance. the results reveal that a set of convenience and lifestyle dimensions influences usage intentions, including mode of drive, pick-up and drop-off mode, service level, price model, availability, and type of market mediation. in contrast, vehicle fleet does not appear to influence carsharing models’ acceptance. these findings contribute to research on business model configuration as well as the attitude-behavior gap in the sharing economy by determining relevant dimensions of a carsharing business model which can bridge the gap between basically positive attitudes and usage resistance. thereby they also serve for concrete managerial recommendations.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/bse.2441
3aa35171201a00cfae4ddd7de75547c0a67a476e,Overcoming the Main Barriers of Circular Economy Implementation through a New Visualization Tool for Circular Business Models,"There is a huge gap between the broad concept of circular economy (CE) and its practical implementation in the industrial sector due to several types of barriers, which shall be led back to the lack of consistent and precise information about resources, products, and processes. Without a proper information flow, it is impossible to quantify circular initiatives, both in comparison with the actual linear situation or with circular alternative opportunities. A proper quantification of circular initiatives allows the assessment of economic, environmental and social benefits and the preventative identification of potential barriers and relative solutions, monitoring the risk associated with circular investments and supporting the decision-making process. This paper describes a new tool to ensure the quantification of circular initiatives and the method to define it. It is a new Circular Business Model (CBM) visualization tool, which overcomes the main limitations of the existing models able to explain CE concepts but not to boost its practical implementation in industry. The new CBM visualization tool can be adopted in every industrial sector to highlight circular opportunities that are still hidden or unexploited or to select the best CE strategy. The proposed CBM visualization tool differs from the previous diagrams in two main characteristics: (i) the possibility to quantify resource flows and important indicators representing energy consumption, environmental and social impact, and (ii) the focus, which is not only on the product, but on the whole system, involving also the process, the company and the entire supply chain. The methodology to adopt and adapt the proposed model to different scales is described in detail. To provide a practical example, the model was qualitatively applied to a generic technical product to highlight its potential in the identification and quantification of circular activities.",2019,"[{'authorId': '51298568', 'name': 'A. Bianchini'}, {'authorId': '2060508290', 'name': 'J. Rossi'}, {'authorId': '1770126', 'name': 'M. Pellegrini'}]","{'url': 'https://www.mdpi.com/2071-1050/11/23/6614/pdf?version=1575373689', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su11236614?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su11236614, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","there is a huge gap between the broad concept of circular economy (ce) and its practical implementation in the industrial sector due to several types of barriers, which shall be led back to the lack of consistent and precise information about resources, products, and processes. without a proper information flow, it is impossible to quantify circular initiatives, both in comparison with the actual linear situation or with circular alternative opportunities. a proper quantification of circular initiatives allows the assessment of economic, environmental and social benefits and the preventative identification of potential barriers and relative solutions, monitoring the risk associated with circular investments and supporting the decision-making process. this paper describes a new tool to ensure the quantification of circular initiatives and the method to define it. it is a new circular business model (cbm) visualization tool, which overcomes the main limitations of the existing models able to explain ce concepts but not to boost its practical implementation in industry. the new cbm visualization tool can be adopted in every industrial sector to highlight circular opportunities that are still hidden or unexploited or to select the best ce strategy. the proposed cbm visualization tool differs from the previous diagrams in two main characteristics: (i) the possibility to quantify resource flows and important indicators representing energy consumption, environmental and social impact, and (ii) the focus, which is not only on the product, but on the whole system, involving also the process, the company and the entire supply chain. the methodology to adopt and adapt the proposed model to different scales is described in detail. to provide a practical example, the model was qualitatively applied to a generic technical product to highlight its potential in the identification and quantification of circular activities.",https://www.mdpi.com/2071-1050/11/23/6614/pdf?version=1575373689
9fc50d9f689b28fa73e1b4dac6df6c2cf23d0d84,Eco-innovation and Circular Business Models as drivers for a circular economy,"Eco-innovation is defined as any directed/oriented innovation aiming at reducing environmental impacts. Eco-innovation is not only a technology change; it also embraces organisational, social and system innovations. This systemic and complex thinking is necessary to understand the role of eco-innovation as an enabler of Circular Economy (CE). Circular Economy appears as a promising approach towards a sustainable transition from the linear socioeconomic paradigm. The objective of the Circular Economy is to maintain and to share value along the time. Eco-innovation for Circular Economy can be of technological and non-technological character. Indeed, it is acknowledged that CE needs to address important challenges regarding business models and socio-institutional frameworks, while technological change may not be necessarily radical. In order to pave the way to Circular Economy through eco-innovation, business models are considered a key driver. The business model is seen as a holistic approach towards the way of doing business. From the eco-innovation perspective, a business model needs to add ecological and social value to the value proposal and changing the producer and the consumer practices. In particular, eco-innovations with the potential to enable the transition to a resource-efficient circular economy model include efforts to change dominant business models (from new product and service design to reconfigured value chains, new/short supply chains), transform the way citizens interact with products and services (ownership, leasing, sharing, repairing, reducing, remanufacturing, etc.) and develop improved systems for delivering value (green mobility, smart energy systems, short supply chains,  etc.).",2018,"[{'authorId': '2451547', 'name': 'X. Vence'}, {'authorId': '145376087', 'name': 'Ángeles Pereira'}]","{'url': 'http://www.cya.unam.mx/index.php/cya/article/download/1806/1374', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.22201/FCA.24488410E.2019.1806?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.22201/FCA.24488410E.2019.1806, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","eco-innovation is defined as any directed/oriented innovation aiming at reducing environmental impacts. eco-innovation is not only a technology change; it also embraces organisational, social and system innovations. this systemic and complex thinking is necessary to understand the role of eco-innovation as an enabler of circular economy (ce). circular economy appears as a promising approach towards a sustainable transition from the linear socioeconomic paradigm. the objective of the circular economy is to maintain and to share value along the time. eco-innovation for circular economy can be of technological and non-technological character. indeed, it is acknowledged that ce needs to address important challenges regarding business models and socio-institutional frameworks, while technological change may not be necessarily radical. in order to pave the way to circular economy through eco-innovation, business models are considered a key driver. the business model is seen as a holistic approach towards the way of doing business. from the eco-innovation perspective, a business model needs to add ecological and social value to the value proposal and changing the producer and the consumer practices. in particular, eco-innovations with the potential to enable the transition to a resource-efficient circular economy model include efforts to change dominant business models (from new product and service design to reconfigured value chains, new/short supply chains), transform the way citizens interact with products and services (ownership, leasing, sharing, repairing, reducing, remanufacturing, etc.) and develop improved systems for delivering value (green mobility, smart energy systems, short supply chains, etc.).",http://www.cya.unam.mx/index.php/cya/article/download/1806/1374
74a9bdb6022a7c7d5106278c1a864996b134d029,Value Migration to the Sustainable Business Models of Digital Economy Companies on the Capital Market,"The topic of a sustainable business model is currently the subject of much scientific research that covers a wide range of topics, from terminological aspects to aspects related to the impact of sustainability factors on company development. So far, however, the topic of sustainability in business models operating in electronic markets has only been studied to some extent. This article covers broad research into the value migration to sustainable business models of companies operating in the digital economy on the capital market. The aim of the article is to present key results of research into value migration to sustainable business models of companies operating in the digital economy on the capital market. The relevant literature on the trends in the application of the sustainability concept in the digital economy, the attributes of business models, and the interpretation of value within the concept of business models is also reviewed. The results obtained are ambiguous.",2018,"[{'authorId': '1517521607', 'name': 'M. Jabłoński'}]","{'url': 'https://www.mdpi.com/2071-1050/10/9/3113/pdf?version=1535713305', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/SU10093113?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/SU10093113, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the topic of a sustainable business model is currently the subject of much scientific research that covers a wide range of topics, from terminological aspects to aspects related to the impact of sustainability factors on company development. so far, however, the topic of sustainability in business models operating in electronic markets has only been studied to some extent. this article covers broad research into the value migration to sustainable business models of companies operating in the digital economy on the capital market. the aim of the article is to present key results of research into value migration to sustainable business models of companies operating in the digital economy on the capital market. the relevant literature on the trends in the application of the sustainability concept in the digital economy, the attributes of business models, and the interpretation of value within the concept of business models is also reviewed. the results obtained are ambiguous.",https://www.mdpi.com/2071-1050/10/9/3113/pdf?version=1535713305
80e94edd200503b0a914ce36bd57d599f9a6331a,Sustainable Business Models Innovation and Design Thinking: A Bibliometric Analysis and Systematic Review of Literature,"The process of integrating sustainability into businesses and processes is still recent, both in startups, small and medium-sized companies and even multinationals. Sustainable business models became a phenomenon of global interest and Design Thinking has been increasingly used as a strategy to support this process. In this context, the aim of this article is to improve the understanding of how Design Thinking (DT) and its set of tools and methods contribute to the creation and innovation of sustainable business models (SBM). The analysis of frameworks indicates that the main methodologies linking Design Thinking and Sustainable Business Models are Workshops, Brainstorming, Co-creation and Prototyping. Also, approaches such as Circular Economy, Business Models and Product-Service System models are emerging as a means of enabling the collaborative consumption of products and services and with positive results for sustainable business. The analysis of the articles reveals that user-oriented innovation and analysis of stakeholder needs is present in practically all evaluated frames, but prototyping and experimentation represent a gap that should be better explored in the frameworks.",2023,"[{'authorId': '114358113', 'name': 'Julia Kurek'}, {'authorId': '13195043', 'name': 'L. Brandli'}, {'authorId': '147517239', 'name': 'Marcos Antonio Leite Frandoloso'}, {'authorId': '1932142858', 'name': 'Amanda Lange Salvia'}, {'authorId': '151056606', 'name': 'Janaína Mazutti'}]","{'url': 'https://www.mdpi.com/2071-1050/15/2/988/pdf?version=1672910692', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su15020988?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su15020988, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the process of integrating sustainability into businesses and processes is still recent, both in startups, small and medium-sized companies and even multinationals. sustainable business models became a phenomenon of global interest and design thinking has been increasingly used as a strategy to support this process. in this context, the aim of this article is to improve the understanding of how design thinking (dt) and its set of tools and methods contribute to the creation and innovation of sustainable business models (sbm). the analysis of frameworks indicates that the main methodologies linking design thinking and sustainable business models are workshops, brainstorming, co-creation and prototyping. also, approaches such as circular economy, business models and product-service system models are emerging as a means of enabling the collaborative consumption of products and services and with positive results for sustainable business. the analysis of the articles reveals that user-oriented innovation and analysis of stakeholder needs is present in practically all evaluated frames, but prototyping and experimentation represent a gap that should be better explored in the frameworks.",https://www.mdpi.com/2071-1050/15/2/988/pdf?version=1672910692
bae25e1c344feb16f413e757fc8680d2d1c4e8b4,Business Models of the Sharing Economy,"Sharing economy is a process of consumption and production in which the accent goes on shared access to resource, recirculation and reutilization of resources. As consumers embraced this concept, sharing economy has led to the development of innovative businesses that compete with traditional businesses. The aim of the paper is twofold. Firstly, it discusses the business models of the sharing economy. Based on a research on twelve representative companies of the sharing economy we analyse three representative business models: access-based, marketplace, on-demand service provider. Each business model is examined regarding three dimensions: value creation, value delivery and value capture. Secondly, the implications for the traditional companies are analysed are emphasized, with an accent on practical approaches and course of actions. Traditional companies need toincorporate innovation and technology in their business models in order to gain and maintain consumer engagement.",2018,"[{'authorId': '119144409', 'name': 'C. Barbu'}, {'authorId': '151181070', 'name': 'Rãducu ªtefan Bratu'}, {'authorId': '2083215343', 'name': 'Elena Mãdãlina Sîrbu'}]","{'url': 'https://doi.org/10.24818/rmci.2018.2.154', 'status': 'GOLD', 'license': 'CCBYSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.24818/RMCI.2018.2.154?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.24818/RMCI.2018.2.154, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","sharing economy is a process of consumption and production in which the accent goes on shared access to resource, recirculation and reutilization of resources. as consumers embraced this concept, sharing economy has led to the development of innovative businesses that compete with traditional businesses. the aim of the paper is twofold. firstly, it discusses the business models of the sharing economy. based on a research on twelve representative companies of the sharing economy we analyse three representative business models: access-based, marketplace, on-demand service provider. each business model is examined regarding three dimensions: value creation, value delivery and value capture. secondly, the implications for the traditional companies are analysed are emphasized, with an accent on practical approaches and course of actions. traditional companies need toincorporate innovation and technology in their business models in order to gain and maintain consumer engagement.",https://doi.org/10.24818/rmci.2018.2.154
227f127ef9cea2e3500c6d435efbe63767c58e9c,BIO-ECONOMY BASED BUSINESS MODELS FOR THE FOREST SECTOR – A SYSTEMATIC LITERATURE REVIEW,"The shift towards a bio-economy is one of the main focus areas of political initiatives aiming for a society relying on renewable biological sources while achieving economic growth. The forest sector is expected to contribute significantly to the development of the bio-economy which at the same time support rural development by creating new markets for advanced forest based products. However there is a need to focus more on the economic feasibility of such initiatives. Literature on bio-economy often implicitly addresses certain aspects connected to business models but is lacking a holistic perspective on the role of business models for the successful shift towards a bio-economy in the forest sector. Therefore, the purpose of this paper is to conduct a systematic literature review about bio-economy business models in the forest sector to advance the understanding about increased and sufficient value generation necessary to persuade a shift towards bio-economy. This paper is based on a systematic review of 42 scientific journal articles and book chapters on forest based bio-economy. The first result of the article is a structured aggregation of the existing bio-economy business models including the maturity and potential for large scale application. The main implication of the paper is an overall framework on how to facilitate the commercialization of bio-economy based business models through an improved understanding of all elements of the business model canvas to reach market acceptance of innovative business models. Recommendations for future research are presented in the end of the paper. Keywords: Bio-economy; Business models; Forest; Literature review Article DOI: http://doi.org/10.15544/RD.2017.109",2018,"[{'authorId': '119371810', 'name': 'W. Reim'}, {'authorId': '2002141', 'name': 'D. Sjödin'}, {'authorId': '2925791', 'name': 'V. Parida'}, {'authorId': '5125623', 'name': 'U. Rova'}, {'authorId': '73773866', 'name': 'P. Christakopoulos'}]","{'url': 'https://doi.org/10.15544/rd.2017.109', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.15544/RD.2017.109?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.15544/RD.2017.109, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the shift towards a bio-economy is one of the main focus areas of political initiatives aiming for a society relying on renewable biological sources while achieving economic growth. the forest sector is expected to contribute significantly to the development of the bio-economy which at the same time support rural development by creating new markets for advanced forest based products. however there is a need to focus more on the economic feasibility of such initiatives. literature on bio-economy often implicitly addresses certain aspects connected to business models but is lacking a holistic perspective on the role of business models for the successful shift towards a bio-economy in the forest sector. therefore, the purpose of this paper is to conduct a systematic literature review about bio-economy business models in the forest sector to advance the understanding about increased and sufficient value generation necessary to persuade a shift towards bio-economy. this paper is based on a systematic review of 42 scientific journal articles and book chapters on forest based bio-economy. the first result of the article is a structured aggregation of the existing bio-economy business models including the maturity and potential for large scale application. the main implication of the paper is an overall framework on how to facilitate the commercialization of bio-economy based business models through an improved understanding of all elements of the business model canvas to reach market acceptance of innovative business models. recommendations for future research are presented in the end of the paper. keywords: bio-economy; business models; forest; literature review article doi: http://doi.org/10.15544/rd.2017.109",https://doi.org/10.15544/rd.2017.109
0f4b70e73cf7a71752314dba747c0e66c48a51c8,"Editors’ Introduction: Business Models, Ecosystems, and Society in the Sharing Economy","This Special Issue of Academy of Management Discovery (AMD) examines how the Sharing economy can reshape the traditional management theories and practices. We define “sharing economy” as a socio-economic ecosystem that commonly uses information technology to connect different stakeholders – individuals, companies, governments, and other – to share or access different products and services and to enable collaborative consumption (Belk, 2014; Hamari, Sjoklint, and Ukkonen, 2016; Wosskow, 2014). We posit that the sharing economy represents a radical shift in how business is organized and leads us to question many of our management theories and practices of labor, employment, the firm, and the nature of economic enterprise (Davis, 2016b). In the sharing economy, the roles of suppliers and customers tend to often overlap and become imprecise as the different parties can act as both as suppliers and customers (Belk, 2014; Moore, 2013; Williamson and De Meyer, 2012).",2018,"[{'authorId': '66362415', 'name': 'T. Laamanen'}, {'authorId': '144545497', 'name': 'J. Pfeffer'}, {'authorId': '2795392', 'name': 'K. Rong'}, {'authorId': '2439024', 'name': 'A. Ven'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5465/AMD.2018.0110?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5465/AMD.2018.0110, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this special issue of academy of management discovery (amd) examines how the sharing economy can reshape the traditional management theories and practices. we define “sharing economy” as a socio-economic ecosystem that commonly uses information technology to connect different stakeholders – individuals, companies, governments, and other – to share or access different products and services and to enable collaborative consumption (belk, 2014; hamari, sjoklint, and ukkonen, 2016; wosskow, 2014). we posit that the sharing economy represents a radical shift in how business is organized and leads us to question many of our management theories and practices of labor, employment, the firm, and the nature of economic enterprise (davis, 2016b). in the sharing economy, the roles of suppliers and customers tend to often overlap and become imprecise as the different parties can act as both as suppliers and customers (belk, 2014; moore, 2013; williamson and de meyer, 2012).",
bb6e37085c8d01b9d5ec45176fe585eb2092c8fc,Microfoundations of dynamic capabilities: Insights from circular economy business cases,"Circular economy is a key strategy to achieve corporate sustainability. However, so far, most firms are unable to translate the concept of circular economy into their corporate strategies, business models, and operations. Some scholars have argued that firms need to develop new (and dynamic) capabilities for circular economy implementation. Yet there is a little discussion on how firms can develop such capabilities. Notably, there is a paucity of research on specific skills, processes, and organizational activities (microfoundations of dynamic capabilities) that may facilitate circular economy implementation. To address this knowledge gap, using a multiple‐case studies approach, we explore microfoundations of dynamic capabilities in successful circular economy business cases. Our findings indicate that dynamic capabilities positively contribute to circular economy implementation. Our case studies show that case firms identified circular economy opportunities by using four microfoundations of sensing capability. Further, case firms acted on the identified opportunities by using simultaneously three microfoundations of seizing capability and four microfoundations of reconfiguring capability. This paper contributes to the literature on the relations between dynamic capabilities and corporate sustainability by providing insights on how sensing, seizing, and reconfiguring dynamic capabilities act in successful operationalization of circular economy strategies.",2020,"[{'authorId': '2004273352', 'name': 'Owais Khan'}, {'authorId': '1960303', 'name': 'T. Daddi'}, {'authorId': '1971411', 'name': 'Fabio Iraldo'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/bse.2447?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/bse.2447, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","circular economy is a key strategy to achieve corporate sustainability. however, so far, most firms are unable to translate the concept of circular economy into their corporate strategies, business models, and operations. some scholars have argued that firms need to develop new (and dynamic) capabilities for circular economy implementation. yet there is a little discussion on how firms can develop such capabilities. notably, there is a paucity of research on specific skills, processes, and organizational activities (microfoundations of dynamic capabilities) that may facilitate circular economy implementation. to address this knowledge gap, using a multiple‐case studies approach, we explore microfoundations of dynamic capabilities in successful circular economy business cases. our findings indicate that dynamic capabilities positively contribute to circular economy implementation. our case studies show that case firms identified circular economy opportunities by using four microfoundations of sensing capability. further, case firms acted on the identified opportunities by using simultaneously three microfoundations of seizing capability and four microfoundations of reconfiguring capability. this paper contributes to the literature on the relations between dynamic capabilities and corporate sustainability by providing insights on how sensing, seizing, and reconfiguring dynamic capabilities act in successful operationalization of circular economy strategies.",
ac4f4f001e0b2b0d45645e8bc9905855cf251cda,Understanding Business Models in the Sharing Economy in China: A Case Study,"Along with a growing environmental consciousness and the advancement of information communication technology, car sharing and apartment sharing as the prominent examples of the sharing economy is becoming increasingly popular in China. This study aims to have a better understanding of business models in the sharing economy in China. Four research questions are presented. On the basis of a literature review on the business model and sharing economy, we proposed an analysis framework consisting of four major dimensions of business model concepts to study how the sharing economy works in China, including value network, value architecture, value proposition, and value finance. To address this, a case study with the Uber China is carried out. The key findings from the case study are presented in accordance with identified four dimensions of business model concepts.",2016,"[{'authorId': '145349501', 'name': 'Shang Gao'}, {'authorId': '2108070243', 'name': 'Xuemei Zhang'}]","{'url': 'https://hal.inria.fr/hal-01702170/file/396007_1_En_59_Chapter.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-319-45234-0_59?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-319-45234-0_59, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","along with a growing environmental consciousness and the advancement of information communication technology, car sharing and apartment sharing as the prominent examples of the sharing economy is becoming increasingly popular in china. this study aims to have a better understanding of business models in the sharing economy in china. four research questions are presented. on the basis of a literature review on the business model and sharing economy, we proposed an analysis framework consisting of four major dimensions of business model concepts to study how the sharing economy works in china, including value network, value architecture, value proposition, and value finance. to address this, a case study with the uber china is carried out. the key findings from the case study are presented in accordance with identified four dimensions of business model concepts.",https://hal.inria.fr/hal-01702170/file/396007_1_En_59_Chapter.pdf
9be0124c41496154d13ecd1ab84707b9939efa2e,The Circular Economy Business Model: Examining Consumers’ Acceptance of Recycled Goods,"The circular economy strategy supports the transformation of the linear consumption model into a closed-production model to achieve economic sustainability, with the consumers’ acceptance of circular products being one of the major challenges. Further, one important aspect of product circularity remains unexplored, such as the consumers’ purchase intention of recycled circular goods. In this context, the present study proposes and tests a conceptual model on consumers acceptance of recycled goods through PLS Structural Equation Modeling (PLS-SEM), based on the data obtained from 312 respondents. Results indicate that the positive image of circular products is the most important driver of consumers’ acceptance, followed by the product perceived safety. This study provides an empirical foundation for the important role of consumers in circular economy business models through the examination of consumers’ acceptance of recycled goods.",2020,"[{'authorId': '1399052826', 'name': 'Cristina Calvo-Porral'}, {'authorId': '1403059818', 'name': 'Jean-Pierre Lévy-Mangin'}]","{'url': 'https://www.mdpi.com/2076-3387/10/2/28/pdf?version=1589339409', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/admsci10020028?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/admsci10020028, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the circular economy strategy supports the transformation of the linear consumption model into a closed-production model to achieve economic sustainability, with the consumers’ acceptance of circular products being one of the major challenges. further, one important aspect of product circularity remains unexplored, such as the consumers’ purchase intention of recycled circular goods. in this context, the present study proposes and tests a conceptual model on consumers acceptance of recycled goods through pls structural equation modeling (pls-sem), based on the data obtained from 312 respondents. results indicate that the positive image of circular products is the most important driver of consumers’ acceptance, followed by the product perceived safety. this study provides an empirical foundation for the important role of consumers in circular economy business models through the examination of consumers’ acceptance of recycled goods.",https://www.mdpi.com/2076-3387/10/2/28/pdf?version=1589339409
ddb5a7cabd4769236904bd4a5e143d2199528d6c,Evaluating the Experience of LGBTQ+ People Using Large Language Model Based Chatbots for Mental Health Support,"LGBTQ+ individuals are increasingly turning to chatbots powered by large language models (LLMs) to meet their mental health needs. However, little research has explored whether these chatbots can adequately and safely provide tailored support for this demographic. We interviewed 18 LGBTQ+ and 13 non-LGBTQ+ participants about their experiences with LLM-based chatbots for mental health needs. LGBTQ+ participants relied on these chatbots for mental health support, likely due to an absence of support in real life. Notably, while LLMs offer prompt support, they frequently fall short in grasping the nuances of LGBTQ-specific challenges. Although fine-tuning LLMs to address LGBTQ+ needs can be a step in the right direction, it isn’t the panacea. The deeper issue is entrenched in societal discrimination. Consequently, we call on future researchers and designers to look beyond mere technical refinements and advocate for holistic strategies that confront and counteract the societal biases burdening the LGBTQ+ community.",2024,"[{'authorId': '2116609597', 'name': 'Zilin Ma'}, {'authorId': '2281471461', 'name': 'Yiyang Mei'}, {'authorId': '2284064791', 'name': 'Yinru Long'}, {'authorId': '2284168435', 'name': 'Zhaoyuan Su'}, {'authorId': '2268327054', 'name': 'Krzysztof Z. Gajos'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3613904.3642482', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2402.09260, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","lgbtq+ individuals are increasingly turning to chatbots powered by large language models (llms) to meet their mental health needs. however, little research has explored whether these chatbots can adequately and safely provide tailored support for this demographic. we interviewed 18 lgbtq+ and 13 non-lgbtq+ participants about their experiences with llm-based chatbots for mental health needs. lgbtq+ participants relied on these chatbots for mental health support, likely due to an absence of support in real life. notably, while llms offer prompt support, they frequently fall short in grasping the nuances of lgbtq-specific challenges. although fine-tuning llms to address lgbtq+ needs can be a step in the right direction, it isn’t the panacea. the deeper issue is entrenched in societal discrimination. consequently, we call on future researchers and designers to look beyond mere technical refinements and advocate for holistic strategies that confront and counteract the societal biases burdening the lgbtq+ community.",https://dl.acm.org/doi/pdf/10.1145/3613904.3642482
2a63f69217108247b3ac8322a7dca6bf10608318,Chatbot for Mental health support using NLP,"Mental health issues are a growing concern worldwide, and seeking support for these issues can be difficult due to various reasons. Chatbots have emerged as a promising solution to provide accessible and confidential support to individuals facing mental health issues. With recent advances in technology, digital interventions designed to supplement or replace in-person mental health services have proliferated, including the emergence of mental health chatbots that claim to provide assistance through automated natural language processing (NLP) therapeutic approaches. A chatbot can be described as a computer program capable of providing intelligent answers to user input by understanding natural language using one or more NLP techniques. In this study, we discuss the use of NLP in psychotherapy and compare the responses provided by chatbots to a set of predefined user inputs related to well-being and mental health queries and compare existing systems. A general analysis was performed. The general approach to building such chatbots includes basic NLP techniques such as word embedding, sentiment analysis, sequence-by-sequence models, and attention mechanisms. We also looked at Mental Ease, a mobile app that uses NLP technology not only to provide conversational assistance but also to tool up useful features for maintaining mental health. Incorporating mental health assessment tools into the chatbot interface, it can help patients cope with mild anxiety and depression alongside conventional therapy. It can also overcome some barriers to mental health, such as waiting lists and geographical barriers to face-to-face consultations.",2023,"[{'authorId': '2110402595', 'name': 'Vanshika Gupta'}, {'authorId': '2055614694', 'name': 'Varun Joshi'}, {'authorId': '2222535696', 'name': 'Akshat Jain'}, {'authorId': '2297530539', 'name': 'Inakshi Garg'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/INCET57972.2023.10170573?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/INCET57972.2023.10170573, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mental health issues are a growing concern worldwide, and seeking support for these issues can be difficult due to various reasons. chatbots have emerged as a promising solution to provide accessible and confidential support to individuals facing mental health issues. with recent advances in technology, digital interventions designed to supplement or replace in-person mental health services have proliferated, including the emergence of mental health chatbots that claim to provide assistance through automated natural language processing (nlp) therapeutic approaches. a chatbot can be described as a computer program capable of providing intelligent answers to user input by understanding natural language using one or more nlp techniques. in this study, we discuss the use of nlp in psychotherapy and compare the responses provided by chatbots to a set of predefined user inputs related to well-being and mental health queries and compare existing systems. a general analysis was performed. the general approach to building such chatbots includes basic nlp techniques such as word embedding, sentiment analysis, sequence-by-sequence models, and attention mechanisms. we also looked at mental ease, a mobile app that uses nlp technology not only to provide conversational assistance but also to tool up useful features for maintaining mental health. incorporating mental health assessment tools into the chatbot interface, it can help patients cope with mild anxiety and depression alongside conventional therapy. it can also overcome some barriers to mental health, such as waiting lists and geographical barriers to face-to-face consultations.",
7b7054033a0c0d0c708cfa29428ff50d34b7f5cb,Enhancing Emotion Detection in Chatbots for Improved Mental Health Support: Addressing Limitations in Mental Disorders and Emotion Detection,"The increase in the adoption of AI-driven chatbots in mental health support, accurately detecting and responding to users' emotions is crucial for effective communication. This paper proposes a novel framework that enhances emotion detection in chatbots by leveraging BERT (Bidirectional Encoder Representations from Transformers) and ensemble learning techniques. Our approach addresses the inherent limitations in existing emotion detection systems, particularly when dealing with complex emotional states and mental health disorders. Using an array of tests, we show that our suggested model works better than conventional approaches, providing enhanced precision, resilience, and the ability to more effectively assist mental health therapies. This research contributes to the ongoing development of AI in mental health, providing a more nuanced and effective approach to emotion detection.",2024,"[{'authorId': '2348933851', 'name': 'Nagendran Pillai Krabashini'}, {'authorId': '2337775711', 'name': 'Jiandong Guo'}, {'authorId': '2348950282', 'name': 'Junzuo Chen'}, {'authorId': '2349555300', 'name': 'Bolin Han'}, {'authorId': '2337790529', 'name': 'Zihan Dai'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/CISP-BMEI64163.2024.10906280?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CISP-BMEI64163.2024.10906280, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the increase in the adoption of ai-driven chatbots in mental health support, accurately detecting and responding to users' emotions is crucial for effective communication. this paper proposes a novel framework that enhances emotion detection in chatbots by leveraging bert (bidirectional encoder representations from transformers) and ensemble learning techniques. our approach addresses the inherent limitations in existing emotion detection systems, particularly when dealing with complex emotional states and mental health disorders. using an array of tests, we show that our suggested model works better than conventional approaches, providing enhanced precision, resilience, and the ability to more effectively assist mental health therapies. this research contributes to the ongoing development of ai in mental health, providing a more nuanced and effective approach to emotion detection.",
ba8845f54cef663bf9af339c5cc95262f1661bfb,Integrating Sentiment Analysis to Enhance Mental Health Support Chatbots,"Mental health conditions have adverse effects on an individual's quality of life. Between 2017 and 2019, there were 52.9 emergency department visits per 1,000 adults for mental health disorders. The rising popularity of artificial intelligence prompted its use in depression detection or mental condition diagnosis, establishing its prominent role in the mental health sector. In this research, we developed an AI chatbot with enhanced contextual intelligence using sentiment analysis to support individuals experiencing mental distress. For this research, we utilized a dataset of text data from 1.6 million posts on the social media platform X (formerly Twitter) due to its open-source availability and accessibility. The collected dataset was cleaned of repetitive characters, special characters, URLs, and numbers. NLP techniques, including tokenization, lemmatization, and stemming, were used for pre-processing. The application identifies sentiments, generates responses, and suggests basic support remedies. We used the Rasa framework to create a hybrid chatbot with customizable configurations. An LSTM model for sentiment analysis was integrated into the Rasa chatbot as a custom action component. A batch size of 32 and an optimal maximum sequence length were selected for balanced training efficiency and accuracy. The LSTM model achieved 76% accuracy in training and validation, enhancing the chatbot text comprehension. Future improvements will include adding personal features and expanding the user base.",2024,"[{'authorId': '2344879981', 'name': 'Senju Murase'}, {'authorId': '1712424220', 'name': 'Jarutas Andritsch'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/iccda64887.2024.10867341?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/iccda64887.2024.10867341, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mental health conditions have adverse effects on an individual's quality of life. between 2017 and 2019, there were 52.9 emergency department visits per 1,000 adults for mental health disorders. the rising popularity of artificial intelligence prompted its use in depression detection or mental condition diagnosis, establishing its prominent role in the mental health sector. in this research, we developed an ai chatbot with enhanced contextual intelligence using sentiment analysis to support individuals experiencing mental distress. for this research, we utilized a dataset of text data from 1.6 million posts on the social media platform x (formerly twitter) due to its open-source availability and accessibility. the collected dataset was cleaned of repetitive characters, special characters, urls, and numbers. nlp techniques, including tokenization, lemmatization, and stemming, were used for pre-processing. the application identifies sentiments, generates responses, and suggests basic support remedies. we used the rasa framework to create a hybrid chatbot with customizable configurations. an lstm model for sentiment analysis was integrated into the rasa chatbot as a custom action component. a batch size of 32 and an optimal maximum sequence length were selected for balanced training efficiency and accuracy. the lstm model achieved 76% accuracy in training and validation, enhancing the chatbot text comprehension. future improvements will include adding personal features and expanding the user base.",
13ab841e2e33d62293a323309f0285030f491a98,Expert and Interdisciplinary Analysis of AI-Driven Chatbots for Mental Health Support: Mixed Methods Study.,"BACKGROUND
Recent years have seen an immense surge in the creation and use of chatbots as social and mental health companions. Aiming to provide empathic responses in support of the delivery of personalized support, these tools are often presented as offering immense potential. However, it is also essential that we understand the risks of their deployment, including their potential adverse impacts on the mental health of users, including those most at risk.


OBJECTIVE
The study aims to assess the ethical and pragmatic clinical implications of using chatbots that claim to aid mental health. While several studies within human-computer interaction and related fields have examined users' perceptions of such systems, few studies have engaged mental health professionals in critical analysis of their conduct as mental health support tools. This paper comprises, in turn, an effort to assess the ethical and pragmatic clinical implications of using chatbots that claim to aid mental health.


METHODS
This study included 8 interdisciplinary mental health professional participants (from psychology and psychotherapy to social care and crisis volunteer workers) in a mixed methods and hands-on analysis of 2 popular mental health-related chatbots' data handling, interface design, and responses. This analysis was carried out through profession-specific tasks with each chatbot, eliciting participants' perceptions through both the Trust in Automation scale and semistructured interviews. Through thematic analysis and a 2-tailed, paired t test, these chatbots' implications for mental health support were thus evaluated.


RESULTS
Qualitative analysis revealed emphatic initial impressions among mental health professionals of chatbot responses likely to produce harm, exhibiting a generic mode of care, and risking user dependence and manipulation given the central role of trust in the therapeutic relationship. Trust scores from the Trust in Automation scale, while exhibiting no statistically significant differences between the chatbots (t6=-0.76; P=.48), indicated medium to low trust scores for each chatbot. The findings of this work highlight that the design and development of artificial intelligence (AI)-driven mental health-related solutions must be undertaken with utmost caution. The mental health professionals in this study collectively resist these chatbots and make clear that AI-driven chatbots used for mental health by at-risk users invite several potential and specific harms.


CONCLUSIONS
Through this work, we contributed insights into the mental health professional perspective on the design of chatbots used for mental health and underscore the necessity of ongoing critical assessment and iterative refinement to maximize the benefits and minimize the risks associated with integrating AI into mental health support.",2025,"[{'authorId': '2329103713', 'name': 'Kayley Moylan'}, {'authorId': '2357135405', 'name': 'Kevin Doherty'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2196/67114?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2196/67114, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background recent years have seen an immense surge in the creation and use of chatbots as social and mental health companions. aiming to provide empathic responses in support of the delivery of personalized support, these tools are often presented as offering immense potential. however, it is also essential that we understand the risks of their deployment, including their potential adverse impacts on the mental health of users, including those most at risk. objective the study aims to assess the ethical and pragmatic clinical implications of using chatbots that claim to aid mental health. while several studies within human-computer interaction and related fields have examined users' perceptions of such systems, few studies have engaged mental health professionals in critical analysis of their conduct as mental health support tools. this paper comprises, in turn, an effort to assess the ethical and pragmatic clinical implications of using chatbots that claim to aid mental health. methods this study included 8 interdisciplinary mental health professional participants (from psychology and psychotherapy to social care and crisis volunteer workers) in a mixed methods and hands-on analysis of 2 popular mental health-related chatbots' data handling, interface design, and responses. this analysis was carried out through profession-specific tasks with each chatbot, eliciting participants' perceptions through both the trust in automation scale and semistructured interviews. through thematic analysis and a 2-tailed, paired t test, these chatbots' implications for mental health support were thus evaluated. results qualitative analysis revealed emphatic initial impressions among mental health professionals of chatbot responses likely to produce harm, exhibiting a generic mode of care, and risking user dependence and manipulation given the central role of trust in the therapeutic relationship. trust scores from the trust in automation scale, while exhibiting no statistically significant differences between the chatbots (t6=-0.76; p=.48), indicated medium to low trust scores for each chatbot. the findings of this work highlight that the design and development of artificial intelligence (ai)-driven mental health-related solutions must be undertaken with utmost caution. the mental health professionals in this study collectively resist these chatbots and make clear that ai-driven chatbots used for mental health by at-risk users invite several potential and specific harms. conclusions through this work, we contributed insights into the mental health professional perspective on the design of chatbots used for mental health and underscore the necessity of ongoing critical assessment and iterative refinement to maximize the benefits and minimize the risks associated with integrating ai into mental health support.",
48b3d5c512a711e656ada574361684c18298756f,Can Your Phone Be Your Therapist? Young People’s Ethical Perspectives on the Use of Fully Automated Conversational Agents (Chatbots) in Mental Health Support,"Over the last decade, there has been an explosion of digital interventions that aim to either supplement or replace face-to-face mental health services. More recently, a number of automated conversational agents have also been made available, which respond to users in ways that mirror a real-life interaction. What are the social and ethical concerns that arise from these advances? In this article, we discuss, from a young person’s perspective, the strengths and limitations of using chatbots in mental health support. We also outline what we consider to be minimum ethical standards for these platforms, including issues surrounding privacy and confidentiality, efficacy, and safety, and review three existing platforms (Woebot, Joy, and Wysa) according to our proposed framework. It is our hope that this article will stimulate ethical debate among app developers, practitioners, young people, and other stakeholders, and inspire ethically responsible practice in digital mental health.",2019,"[{'authorId': '81842869', 'name': 'Kira Kretzschmar'}, {'authorId': '84580873', 'name': 'Holly Tyroll'}, {'authorId': '51287982', 'name': 'Gabriela Pavarini'}, {'authorId': '49134124', 'name': 'Arianna Manzini'}, {'authorId': '46472839', 'name': 'I. Singh'}]","{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/1178222619829083', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6402067, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","over the last decade, there has been an explosion of digital interventions that aim to either supplement or replace face-to-face mental health services. more recently, a number of automated conversational agents have also been made available, which respond to users in ways that mirror a real-life interaction. what are the social and ethical concerns that arise from these advances? in this article, we discuss, from a young person’s perspective, the strengths and limitations of using chatbots in mental health support. we also outline what we consider to be minimum ethical standards for these platforms, including issues surrounding privacy and confidentiality, efficacy, and safety, and review three existing platforms (woebot, joy, and wysa) according to our proposed framework. it is our hope that this article will stimulate ethical debate among app developers, practitioners, young people, and other stakeholders, and inspire ethically responsible practice in digital mental health.",https://journals.sagepub.com/doi/pdf/10.1177/1178222619829083
d030361469baabf5acbaee1623ea495e70591bae,ChatCounselor: A Large Language Models for Mental Health Support,"This paper presents ChatCounselor, a large language model (LLM) solution designed to provide mental health support. Unlike generic chatbots, ChatCounselor is distinguished by its foundation in real conversations between consulting clients and professional psychologists, enabling it to possess specialized knowledge and counseling skills in the field of psychology. The training dataset, Psych8k, was constructed from 260 in-depth interviews, each spanning an hour. To assess the quality of counseling responses, the counseling Bench was devised. Leveraging GPT-4 and meticulously crafted prompts based on seven metrics of psychological counseling assessment, the model underwent evaluation using a set of real-world counseling questions. Impressively, ChatCounselor surpasses existing open-source models in the counseling Bench and approaches the performance level of ChatGPT, showcasing the remarkable enhancement in model capability attained through high-quality domain-specific data.",2023,"[{'authorId': '2247666353', 'name': 'June M. Liu'}, {'authorId': '2248406777', 'name': 'Donghao Li'}, {'authorId': '2153244338', 'name': 'He Cao'}, {'authorId': '2247536954', 'name': 'Tianhe Ren'}, {'authorId': '2247514935', 'name': 'Zeyi Liao'}, {'authorId': '2247759048', 'name': 'Jiamin Wu'}]","{'url': 'https://arxiv.org/pdf/2309.15461', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2309.15461, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper presents chatcounselor, a large language model (llm) solution designed to provide mental health support. unlike generic chatbots, chatcounselor is distinguished by its foundation in real conversations between consulting clients and professional psychologists, enabling it to possess specialized knowledge and counseling skills in the field of psychology. the training dataset, psych8k, was constructed from 260 in-depth interviews, each spanning an hour. to assess the quality of counseling responses, the counseling bench was devised. leveraging gpt-4 and meticulously crafted prompts based on seven metrics of psychological counseling assessment, the model underwent evaluation using a set of real-world counseling questions. impressively, chatcounselor surpasses existing open-source models in the counseling bench and approaches the performance level of chatgpt, showcasing the remarkable enhancement in model capability attained through high-quality domain-specific data.",https://arxiv.org/pdf/2309.15461
5bbb4d4755738e7f4f25af1152f7ab2e165ba68b,Conversational AI for Mental Health Support,"Conversational AI can provide 24/7 access to mental health resources and services. Virtual assistants and chatbots can be used to detect early warning signs and symptoms of mental health problems. An AI-enabled app can provide advice on how to deal with stress and anxiety. Conversational AI has the potential to revolutionize mental health. In this article the authors have built a conversational AI using LSTM and using BERT on Mental Health Conversation data from Kaggle. However, current clinical practice should not be altered by using BERT or LSTM for brain injury in AI sessions. It should be used as an additional tool to encourage people and provide important and useful information. Overall, AI communication for mental health such as BERT or Through the provision of individualized, adaptable, and personalized services, LSTM could enhance people’s health.",2024,"[{'authorId': '2309519447', 'name': 'Swarali Kulkarni'}, {'authorId': '2123646332', 'name': 'Erum Parkar'}, {'authorId': '2309510306', 'name': 'Rutuja Lonkar'}, {'authorId': '70441825', 'name': 'Preksha Pareek'}, {'authorId': '90630252', 'name': 'S. Patil'}, {'authorId': '70191411', 'name': 'Sheetal Kusal'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/MITADTSoCiCon60330.2024.10575117?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/MITADTSoCiCon60330.2024.10575117, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","conversational ai can provide 24/7 access to mental health resources and services. virtual assistants and chatbots can be used to detect early warning signs and symptoms of mental health problems. an ai-enabled app can provide advice on how to deal with stress and anxiety. conversational ai has the potential to revolutionize mental health. in this article the authors have built a conversational ai using lstm and using bert on mental health conversation data from kaggle. however, current clinical practice should not be altered by using bert or lstm for brain injury in ai sessions. it should be used as an additional tool to encourage people and provide important and useful information. overall, ai communication for mental health such as bert or through the provision of individualized, adaptable, and personalized services, lstm could enhance people’s health.",
e28b41fe1439cf43e2ad5b9159a896fec3669ecc,A Qualitative Exploration of Acceptance of a Conversational Chatbot as a Tool for Mental Health Support among University Students in Sudan,"Background: Sudan’s political and economic challenges have increased mental health issues among university students, but access to mental healthcare is limited. Digital health interventions, such as chatbots, could provide a potential solution to inadequate care. This study aimed to evaluate the level of acceptance of a mental health chatbot prototype among university students in Khartoum, Sudan. Materials and Methods: This qualitative study investigated the perspectives of university students regarding a mental health chatbot prototype designed specifically for this research and deployed on Telegram. Twenty participants aged 18+, owning smartphones, and not receiving mental health treatment tested the prototype. Data was collected through individual, face-to-face, in-depth, semi-structured interviews. The data was analysed using both deductive and inductive content analysis methods. Results: Most of the participants acknowledged the importance of mental health but felt that it was an overlooked issue in Sudan. Participants considered the chatbot to be a unique and innovative concept, offering valuable features. They viewed the chatbot as a user-friendly and accessible tool, with advantages such as convenience, anonymity, and accessibility, and potential cost and time savings. However, most participants agreed that the chatbot has many limitations and should not be seen as a substitute for seeing a doctor or therapist. Conclusion: The mental health chatbot was viewed positively by participants in the study. Chatbots can be promising tools for providing accessible and confidential mental health support for university students in countries like Sudan. Long-term studies are required to assess chatbot’s mental health benefits and risks. Keywords: mental health, chatbots, university students, Sudan, young adults",2024,"[{'authorId': '122543020', 'name': 'Sir Mustafa'}, {'authorId': '2188886009', 'name': 'E. Mohammed'}, {'authorId': '2296733947', 'name': 'Ahmed Mustafa Salih'}, {'authorId': '2296731964', 'name': 'Kanagarajan Palani'}, {'authorId': '2296731002', 'name': 'Maha Mohamed Omer Albushra'}, {'authorId': '2188886311', 'name': 'S. Makkawi'}, {'authorId': '2296746015', 'name': 'Amgad Hassan Mustafa'}]","{'url': 'https://doi.org/10.55349/ijmsnr.2024411623', 'status': 'HYBRID', 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.55349/ijmsnr.2024411623?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55349/ijmsnr.2024411623, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background: sudan’s political and economic challenges have increased mental health issues among university students, but access to mental healthcare is limited. digital health interventions, such as chatbots, could provide a potential solution to inadequate care. this study aimed to evaluate the level of acceptance of a mental health chatbot prototype among university students in khartoum, sudan. materials and methods: this qualitative study investigated the perspectives of university students regarding a mental health chatbot prototype designed specifically for this research and deployed on telegram. twenty participants aged 18+, owning smartphones, and not receiving mental health treatment tested the prototype. data was collected through individual, face-to-face, in-depth, semi-structured interviews. the data was analysed using both deductive and inductive content analysis methods. results: most of the participants acknowledged the importance of mental health but felt that it was an overlooked issue in sudan. participants considered the chatbot to be a unique and innovative concept, offering valuable features. they viewed the chatbot as a user-friendly and accessible tool, with advantages such as convenience, anonymity, and accessibility, and potential cost and time savings. however, most participants agreed that the chatbot has many limitations and should not be seen as a substitute for seeing a doctor or therapist. conclusion: the mental health chatbot was viewed positively by participants in the study. chatbots can be promising tools for providing accessible and confidential mental health support for university students in countries like sudan. long-term studies are required to assess chatbot’s mental health benefits and risks. keywords: mental health, chatbots, university students, sudan, young adults",https://doi.org/10.55349/ijmsnr.2024411623
6b671b076f34949640eadfa407b79cc57a20445a,"AI Chatbots for Mental Health: A Scoping Review of Effectiveness, Feasibility, and Applications","Mental health disorders are a leading cause of disability worldwide, and there is a global shortage of mental health professionals. AI chatbots have emerged as a potential solution, offering accessible and scalable mental health interventions. This study aimed to conduct a scoping review to evaluate the effectiveness and feasibility of AI chatbots in treating mental health conditions. A literature search was conducted across multiple databases, including MEDLINE, Scopus, and PsycNet, as well as using AI-powered tools like Microsoft Copilot and Consensus. Relevant studies on AI chatbot interventions for mental health were selected based on predefined inclusion and exclusion criteria. Data extraction and quality assessment were performed independently by multiple reviewers. The search yielded 15 eligible studies covering various application areas, such as mental health support during COVID-19, interventions for specific conditions (e.g., depression, anxiety, substance use disorders), preventive care, health promotion, and usability assessments. AI chatbots demonstrated potential benefits in improving mental and emotional well-being, addressing specific mental health conditions, and facilitating behavior change. However, challenges related to usability, engagement, and integration with existing healthcare systems were identified. AI chatbots hold promise for mental health interventions, but widespread adoption hinges on improving usability, engagement, and integration with healthcare systems. Enhancing personalization and context-specific adaptation is key. Future research should focus on large-scale trials, optimal human–AI integration, and addressing ethical and social implications.",2024,"[{'authorId': '2146586547', 'name': 'Mirko Casu'}, {'authorId': '2145877835', 'name': 'Sergio Triscari'}, {'authorId': '1742452', 'name': 'S. Battiato'}, {'authorId': '40010524', 'name': 'Luca Guarnera'}, {'authorId': '2300630486', 'name': 'Pasquale Caponnetto'}]","{'url': 'https://www.mdpi.com/2076-3417/14/13/5889/pdf?version=1720515323', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app14135889?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app14135889, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mental health disorders are a leading cause of disability worldwide, and there is a global shortage of mental health professionals. ai chatbots have emerged as a potential solution, offering accessible and scalable mental health interventions. this study aimed to conduct a scoping review to evaluate the effectiveness and feasibility of ai chatbots in treating mental health conditions. a literature search was conducted across multiple databases, including medline, scopus, and psycnet, as well as using ai-powered tools like microsoft copilot and consensus. relevant studies on ai chatbot interventions for mental health were selected based on predefined inclusion and exclusion criteria. data extraction and quality assessment were performed independently by multiple reviewers. the search yielded 15 eligible studies covering various application areas, such as mental health support during covid-19, interventions for specific conditions (e.g., depression, anxiety, substance use disorders), preventive care, health promotion, and usability assessments. ai chatbots demonstrated potential benefits in improving mental and emotional well-being, addressing specific mental health conditions, and facilitating behavior change. however, challenges related to usability, engagement, and integration with existing healthcare systems were identified. ai chatbots hold promise for mental health interventions, but widespread adoption hinges on improving usability, engagement, and integration with healthcare systems. enhancing personalization and context-specific adaptation is key. future research should focus on large-scale trials, optimal human–ai integration, and addressing ethical and social implications.",https://www.mdpi.com/2076-3417/14/13/5889/pdf?version=1720515323
ea481e8da25150e1b8d1c52ee4c3c0616b1c3b3d,An AI Based Mental Health Support Chat-Bot for Cyber Bullied Victims,"In recent days, an unprecedented increase in cyberattacks has been seen globally. There are several cyberbullied victims who commit suicide every year as a consequence of their sensitive information being publicized. The victims who are being bullied or blackmailed need mental support and guidance on how to react. And some of the victims, due to defamation, may go as far as taking their lives. So, we've built two AI chatbots named Guidance Bot and Friendly Bot using Botpress and BrainShop API specifically for cyberbullying victims, as they may not directly plead for human help. Conversing with bots might seem more secure and reassuring than having a conversation with humans, as bots maintain secrecy. The bot comprehends the user's query and responds accordingly using natural language processing (NLP) and natural language understanding (NLU). We integrated our trained and developed chatbots into a website, which mainly includes three features, such as providing guidance on how to approach concerned authorities, providing information regarding cyberbullying, answering queries related to mental health, and finally assisting the victim's mental health. Moreover, we have implemented a WhatsApp redirection feature, enabling victims to effortlessly connect with mental health specialists by adding their contact numbers.",2023,"[{'authorId': '2273844084', 'name': 'Y. Naga'}, {'authorId': '2273817831', 'name': 'Himaja G. Anuradha'}, {'authorId': '2273825337', 'name': 'V. Lalitha'}, {'authorId': '2273824808', 'name': 'Nagaveni M. Sai Pravardhitha'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/CSITSS60515.2023.10334235?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CSITSS60515.2023.10334235, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent days, an unprecedented increase in cyberattacks has been seen globally. there are several cyberbullied victims who commit suicide every year as a consequence of their sensitive information being publicized. the victims who are being bullied or blackmailed need mental support and guidance on how to react. and some of the victims, due to defamation, may go as far as taking their lives. so, we've built two ai chatbots named guidance bot and friendly bot using botpress and brainshop api specifically for cyberbullying victims, as they may not directly plead for human help. conversing with bots might seem more secure and reassuring than having a conversation with humans, as bots maintain secrecy. the bot comprehends the user's query and responds accordingly using natural language processing (nlp) and natural language understanding (nlu). we integrated our trained and developed chatbots into a website, which mainly includes three features, such as providing guidance on how to approach concerned authorities, providing information regarding cyberbullying, answering queries related to mental health, and finally assisting the victim's mental health. moreover, we have implemented a whatsapp redirection feature, enabling victims to effortlessly connect with mental health specialists by adding their contact numbers.",
95cc29b434100f85360ba71db6d38dfd89865bd6,"Building Empathetic AI for Mental Health Support: A Human-Centered Approach Combining Prompt Engineering, Machine Learning, and Psychological Theories","In the recent era, mental health problems are increasing globally, leading to greater interest in using AI to develop therapy tools. These tools aim to reach and support more people in need. Even with new technology, current AI chatbots often don’t have the emotional understanding, professional knowledge, or flexibility needed to give good mental health support. This paper suggests a new approach that combines prompt design, machine learning, and psychology - especially Cognitive Behavioral Therapy (CBT) - to build AI systems that are more caring and helpful for mental health support. A close look at current research shows four main problems with AI systems: they use general prompts, often misunderstand emotions, forget past conversations quickly, and don’t have strong safety measures for handling crises. To address these issues, the proposed system includes components that generate supportive responses, understand user emotions, apply basic psychological reasoning, ensure user safety, and recall past conversations to provide better support. In conclusion, these features collectively enhance the AI’s ability to provide understanding and emotionally intelligent support, particularly in mental health settings. By integrating both technical and psychological insights, the system aims to offer a user-centered, reliable, and empathetic approach to mental health care.",2025,"[{'authorId': '2357764260', 'name': 'Dr. Sujata Patil'}, {'authorId': '21714873', 'name': 'Vidya Shinde'}, {'authorId': '2357757254', 'name': 'Dr. Sonali Nemade'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.59256/indjcst.20250401029?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.59256/indjcst.20250401029, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the recent era, mental health problems are increasing globally, leading to greater interest in using ai to develop therapy tools. these tools aim to reach and support more people in need. even with new technology, current ai chatbots often don’t have the emotional understanding, professional knowledge, or flexibility needed to give good mental health support. this paper suggests a new approach that combines prompt design, machine learning, and psychology - especially cognitive behavioral therapy (cbt) - to build ai systems that are more caring and helpful for mental health support. a close look at current research shows four main problems with ai systems: they use general prompts, often misunderstand emotions, forget past conversations quickly, and don’t have strong safety measures for handling crises. to address these issues, the proposed system includes components that generate supportive responses, understand user emotions, apply basic psychological reasoning, ensure user safety, and recall past conversations to provide better support. in conclusion, these features collectively enhance the ai’s ability to provide understanding and emotionally intelligent support, particularly in mental health settings. by integrating both technical and psychological insights, the system aims to offer a user-centered, reliable, and empathetic approach to mental health care.",
c840f690f0e1ab5ed6c23d79140d0709e13c4d09,“It happened to be the perfect thing”: experiences of generative AI chatbots for mental health,"The global mental health crisis underscores the need for accessible, effective interventions. Chatbots based on generative artificial intelligence (AI), like ChatGPT, are emerging as novel solutions, but research on real-life usage is limited. We interviewed nineteen individuals about their experiences using generative AI chatbots for mental health. Participants reported high engagement and positive impacts, including better relationships and healing from trauma and loss. We developed four themes: (1) a sense of ‘emotional sanctuary’, (2) ‘insightful guidance’, particularly about relationships, (3) the ‘joy of connection’, and (4) comparisons between the ‘AI therapist’ and human therapy. Some themes echoed prior research on rule-based chatbots, while others seemed novel to generative AI. Participants emphasised the need for better safety guardrails, human-like memory and the ability to lead the therapeutic process. Generative AI chatbots may offer mental health support that feels meaningful to users, but further research is needed on safety and effectiveness.",2024,"[{'authorId': '2327955073', 'name': 'Steven Siddals'}, {'authorId': '4058196', 'name': 'J. Torous'}, {'authorId': '2327956145', 'name': 'Astrid Coxon'}]","{'url': 'https://doi.org/10.1038/s44184-024-00097-4', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11514308, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the global mental health crisis underscores the need for accessible, effective interventions. chatbots based on generative artificial intelligence (ai), like chatgpt, are emerging as novel solutions, but research on real-life usage is limited. we interviewed nineteen individuals about their experiences using generative ai chatbots for mental health. participants reported high engagement and positive impacts, including better relationships and healing from trauma and loss. we developed four themes: (1) a sense of ‘emotional sanctuary’, (2) ‘insightful guidance’, particularly about relationships, (3) the ‘joy of connection’, and (4) comparisons between the ‘ai therapist’ and human therapy. some themes echoed prior research on rule-based chatbots, while others seemed novel to generative ai. participants emphasised the need for better safety guardrails, human-like memory and the ability to lead the therapeutic process. generative ai chatbots may offer mental health support that feels meaningful to users, but further research is needed on safety and effectiveness.",https://doi.org/10.1038/s44184-024-00097-4
0b04776792c83ec1bf4b83078c4b7618d85bc76e,Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools,"Objective: This study aims to develop and validate an evaluation framework to ensure the safety and reliability of mental health chatbots, which are increasingly popular due to their accessibility, human-like interactions, and context-aware support. Materials and Methods: We created an evaluation framework with 100 benchmark questions and ideal responses, and five guideline questions for chatbot responses. This framework, validated by mental health experts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation methods explored included large language model (LLM)-based scoring, an agentic approach using real-time data, and embedding models to compare chatbot responses against ground truth standards. Results: The results highlight the importance of guidelines and ground truth for improving LLM evaluation accuracy. The agentic method, dynamically accessing reliable information, demonstrated the best alignment with human assessments. Adherence to a standardized, expert-validated framework significantly enhanced chatbot response safety and reliability. Discussion: Our findings emphasize the need for comprehensive, expert-tailored safety evaluation metrics for mental health chatbots. While LLMs have significant potential, careful implementation is necessary to mitigate risks. The superior performance of the agentic approach underscores the importance of real-time data access in enhancing chatbot reliability. Conclusion: The study validated an evaluation framework for mental health chatbots, proving its effectiveness in improving safety and reliability. Future work should extend evaluations to accuracy, bias, empathy, and privacy to ensure holistic assessment and responsible integration into healthcare. Standardized evaluations will build trust among users and professionals, facilitating broader adoption and improved mental health support through technology.",2024,"[{'authorId': '2315914561', 'name': 'Jung In Park'}, {'authorId': '2182148069', 'name': 'Mahyar Abbasian'}, {'authorId': '2241201441', 'name': 'Iman Azimi'}, {'authorId': '2315810363', 'name': 'Dawn Bounds'}, {'authorId': '2315810053', 'name': 'Angela Jun'}, {'authorId': '2315889398', 'name': 'Jaesu Han'}, {'authorId': '2315811390', 'name': 'Robert McCarron'}, {'authorId': '2297708916', 'name': 'Jessica Borelli'}, {'authorId': '2348273518', 'name': 'Parmida Safavi'}, {'authorId': '2348305728', 'name': 'Sanaz Mirbaha'}, {'authorId': '2315875066', 'name': 'Jia Li'}, {'authorId': '2315811652', 'name': 'Mona Mahmoudi'}, {'authorId': '2315811354', 'name': 'Carmen Wiedenhoeft'}, {'authorId': '2311169857', 'name': 'Amir M. Rahmani'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.04650, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objective: this study aims to develop and validate an evaluation framework to ensure the safety and reliability of mental health chatbots, which are increasingly popular due to their accessibility, human-like interactions, and context-aware support. materials and methods: we created an evaluation framework with 100 benchmark questions and ideal responses, and five guideline questions for chatbot responses. this framework, validated by mental health experts, was tested on a gpt-3.5-turbo-based chatbot. automated evaluation methods explored included large language model (llm)-based scoring, an agentic approach using real-time data, and embedding models to compare chatbot responses against ground truth standards. results: the results highlight the importance of guidelines and ground truth for improving llm evaluation accuracy. the agentic method, dynamically accessing reliable information, demonstrated the best alignment with human assessments. adherence to a standardized, expert-validated framework significantly enhanced chatbot response safety and reliability. discussion: our findings emphasize the need for comprehensive, expert-tailored safety evaluation metrics for mental health chatbots. while llms have significant potential, careful implementation is necessary to mitigate risks. the superior performance of the agentic approach underscores the importance of real-time data access in enhancing chatbot reliability. conclusion: the study validated an evaluation framework for mental health chatbots, proving its effectiveness in improving safety and reliability. future work should extend evaluations to accuracy, bias, empathy, and privacy to ensure holistic assessment and responsible integration into healthcare. standardized evaluations will build trust among users and professionals, facilitating broader adoption and improved mental health support through technology.",
714c13e6f583219ac09f43092cb80704ded7ff75,Chatbots for Mental Health: Leveraging LSTM and Seq2Seq Architectures to Enhance User Well-being,"Addressing mental health concerns is a growing global challenge, and seeking support can often be hindered by various barriers. Chatbots present a promising solution to offer accessible and confidential assistance to individuals grappling with mental health issues. With recent technological advancements, digital interventions have become prevalent. The aim of this research is to raise awareness about mental health while simultaneously working towards removing the societal stigma surrounding it. Thus, in this paper, we have created an integrated chatbot that is specifically geared towards mentally ill individuals. The chatbot responds empathetically which is built using a Sequence-to-Sequence (Seq2Seq) encoder-decoder architecture. Through user interaction analysis and sentiment tracking, the research evaluates the chatbot's capacity to detect early signs of mental health issues and assesses its impact on user well-being. Furthermore, the study investigates how users see confidentiality, privacy, and the general user experience when dealing with a chatbot for mental health on a website. The results provide fascinating details about the potential of web-based chatbots for mental health as proactive and approachable resources to promote people's mental health and well being.",2024,"[{'authorId': '2316759647', 'name': 'Arman Ansari'}, {'authorId': '2316761441', 'name': 'Tejaswani Upadhyay'}, {'authorId': '2004908606', 'name': 'Himadri Vaidya'}, {'authorId': '2078898440', 'name': 'Akanksha Kapruwan'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICITEICS61368.2024.10624828?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICITEICS61368.2024.10624828, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","addressing mental health concerns is a growing global challenge, and seeking support can often be hindered by various barriers. chatbots present a promising solution to offer accessible and confidential assistance to individuals grappling with mental health issues. with recent technological advancements, digital interventions have become prevalent. the aim of this research is to raise awareness about mental health while simultaneously working towards removing the societal stigma surrounding it. thus, in this paper, we have created an integrated chatbot that is specifically geared towards mentally ill individuals. the chatbot responds empathetically which is built using a sequence-to-sequence (seq2seq) encoder-decoder architecture. through user interaction analysis and sentiment tracking, the research evaluates the chatbot's capacity to detect early signs of mental health issues and assesses its impact on user well-being. furthermore, the study investigates how users see confidentiality, privacy, and the general user experience when dealing with a chatbot for mental health on a website. the results provide fascinating details about the potential of web-based chatbots for mental health as proactive and approachable resources to promote people's mental health and well being.",
16c69d8bede26fd8bd898bc97d2e0795ebf11005,Loneliness and suicide mitigation for students using GPT3-enabled chatbots,"Mental health is a crisis for learners globally, and digital support is increasingly seen as a critical resource. Concurrently, Intelligent Social Agents receive exponentially more engagement than other conversational systems, but their use in digital therapy provision is nascent. A survey of 1006 student users of the Intelligent Social Agent, Replika, investigated participants’ loneliness, perceived social support, use patterns, and beliefs about Replika. We found participants were more lonely than typical student populations but still perceived high social support. Many used Replika in multiple, overlapping ways—as a friend, a therapist, and an intellectual mirror. Many also held overlapping and often conflicting beliefs about Replika—calling it a machine, an intelligence, and a human. Critically, 3% reported that Replika halted their suicidal ideation. A comparative analysis of this group with the wider participant population is provided.",2024,"[{'authorId': '1659011902', 'name': 'Bethanie Maples'}, {'authorId': '2280827198', 'name': 'Merve Cerit'}, {'authorId': '2280823745', 'name': 'Aditya Vishwanath'}, {'authorId': '2246886383', 'name': 'Roy Pea'}]","{'url': 'https://www.nature.com/articles/s44184-023-00047-6.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10955814, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mental health is a crisis for learners globally, and digital support is increasingly seen as a critical resource. concurrently, intelligent social agents receive exponentially more engagement than other conversational systems, but their use in digital therapy provision is nascent. a survey of 1006 student users of the intelligent social agent, replika, investigated participants’ loneliness, perceived social support, use patterns, and beliefs about replika. we found participants were more lonely than typical student populations but still perceived high social support. many used replika in multiple, overlapping ways—as a friend, a therapist, and an intellectual mirror. many also held overlapping and often conflicting beliefs about replika—calling it a machine, an intelligence, and a human. critically, 3% reported that replika halted their suicidal ideation. a comparative analysis of this group with the wider participant population is provided.",https://www.nature.com/articles/s44184-023-00047-6.pdf
3b3f73fdb5fd5cbac0ac62b7ddb2abee3bde83e2,AI for Mental Health: The Use of Chatbots and NLP to Support Therapy and Early Detection,"Abstract: The escalating mental health crisis worldwide has spurred the examination of alternative technologies to improve access to care, enable early identification of mental health conditions, and provide tailored support. This study investigates the use of Artificial Intelligence (AI), specifically chatbots and Natural Language Processing (NLP), for mental health care. AI-enabled chatbots are increasingly finding their way into therapeutic settings to provide immediate, scalable, and stigma-less support for individuals suffering from psychological distress. These virtual agents can mimic human-like conversations, deliver cognitive behavioural therapy (CBT) strategies, provide continuous mood monitoring, and facilitate evidence-informed interventions.

Using highly sophisticated NLP algorithms, AI systems can analyse users' use of language, sentiment, and vocal patterns to detect early signs of mental health-related disorders like depression, anxiety disorders, and posttraumatic stress disorder (PTSD). This paper provides an overview of existing AI-based mental health applications and investigates the effectiveness of AI-enabled chatbots through user engagement in comparison to traditional methods of therapy. Ultimately, this paper examines the ethical concerns around AI in mental health related to privacy of information, and the limitations of machines exhibiting empathy.

In addition, the study considers hybrid models made up of human therapists and AI technologies that can improve diagnostic accuracy and therapy benefits. The development of AI technologies in mental health care may dramatically improve barriers to treatment, particularly for those with limited access to mental health care, including those in underserved areas. Overall, the results indicate that artificial intelligence can be a valuable tool in traditional therapy, when developed responsibly and ethically, providing new opportunities for early intervention, ongoing support, and improved access to mental health services.

Keywords: mental health; mental health interventions; clinical psychology; artificialintelligence; AI chatbots; chatbot; AI;",2025,"[{'authorId': '2359749839', 'name': 'Neha Yadav'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.55041/isjem03402?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55041/isjem03402, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract: the escalating mental health crisis worldwide has spurred the examination of alternative technologies to improve access to care, enable early identification of mental health conditions, and provide tailored support. this study investigates the use of artificial intelligence (ai), specifically chatbots and natural language processing (nlp), for mental health care. ai-enabled chatbots are increasingly finding their way into therapeutic settings to provide immediate, scalable, and stigma-less support for individuals suffering from psychological distress. these virtual agents can mimic human-like conversations, deliver cognitive behavioural therapy (cbt) strategies, provide continuous mood monitoring, and facilitate evidence-informed interventions. using highly sophisticated nlp algorithms, ai systems can analyse users' use of language, sentiment, and vocal patterns to detect early signs of mental health-related disorders like depression, anxiety disorders, and posttraumatic stress disorder (ptsd). this paper provides an overview of existing ai-based mental health applications and investigates the effectiveness of ai-enabled chatbots through user engagement in comparison to traditional methods of therapy. ultimately, this paper examines the ethical concerns around ai in mental health related to privacy of information, and the limitations of machines exhibiting empathy. in addition, the study considers hybrid models made up of human therapists and ai technologies that can improve diagnostic accuracy and therapy benefits. the development of ai technologies in mental health care may dramatically improve barriers to treatment, particularly for those with limited access to mental health care, including those in underserved areas. overall, the results indicate that artificial intelligence can be a valuable tool in traditional therapy, when developed responsibly and ethically, providing new opportunities for early intervention, ongoing support, and improved access to mental health services. keywords: mental health; mental health interventions; clinical psychology; artificialintelligence; ai chatbots; chatbot; ai;",
d5c46a1bdc6a4b022c4908a78b523374a4b9da1a,Perinatal Mental Detection With Chatbots Using Machine Learning,"The use of human-robot interaction in mental health has received significant attention. As opposed to the traditional approach, using robots for mental health care reduces subjects' barriers in seeking help for their own mental conditions and obtains a more comprehensive data of patients that can aid users being aware of their state on a broader scale but also serves as support to clinicians towards diagnosing with better accuracy. This paper is about a chatbot to check the mental status of perinatal women. This paper applies supervised machine learning on a dataset comprised of 223 samples having 31 features to build predictive model for detecting Anxiety, Depression and Hypomania index in perinatal woman. Technical, psychological scales is accessed for the purpose of evaluation and to provide suggestions in terms of treatment which would help users recover from their mental illness. Perinatal mental health (PMH) problems are mood disorders that occur during pregnancy or up to 24-month postpartum period and can have far reaching effects on pregnant women, baby's wellbeing; the quality of family partnerships may be affected. Problems that a woman could face at any stage of her pregnancy Most used methods in the PMH diagnosis were self-reporting, behavioral scale testing and behavioral observation. To keep up with this, Chatbot is a good way. By collecting data on user health and communicating with humans, it can provide real-time perinatal mental health care.",2024,"[{'authorId': '2310827068', 'name': 'Prabhjot Kaur'}, {'authorId': '2275029894', 'name': 'Rinku Sharma'}, {'authorId': '2281432842', 'name': 'Mandeep Singh'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICTACS62700.2024.10840611?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICTACS62700.2024.10840611, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the use of human-robot interaction in mental health has received significant attention. as opposed to the traditional approach, using robots for mental health care reduces subjects' barriers in seeking help for their own mental conditions and obtains a more comprehensive data of patients that can aid users being aware of their state on a broader scale but also serves as support to clinicians towards diagnosing with better accuracy. this paper is about a chatbot to check the mental status of perinatal women. this paper applies supervised machine learning on a dataset comprised of 223 samples having 31 features to build predictive model for detecting anxiety, depression and hypomania index in perinatal woman. technical, psychological scales is accessed for the purpose of evaluation and to provide suggestions in terms of treatment which would help users recover from their mental illness. perinatal mental health (pmh) problems are mood disorders that occur during pregnancy or up to 24-month postpartum period and can have far reaching effects on pregnant women, baby's wellbeing; the quality of family partnerships may be affected. problems that a woman could face at any stage of her pregnancy most used methods in the pmh diagnosis were self-reporting, behavioral scale testing and behavioral observation. to keep up with this, chatbot is a good way. by collecting data on user health and communicating with humans, it can provide real-time perinatal mental health care.",
6b8e38a4e23c8e56d68761418819c86dab364562,Empathy Toward Artificial Intelligence Versus Human Experiences and the Role of Transparency in Mental Health and Social Support Chatbot Design: Comparative Study,"Background Empathy is a driving force in our connection to others, our mental well-being, and resilience to challenges. With the rise of generative artificial intelligence (AI) systems, mental health chatbots, and AI social support companions, it is important to understand how empathy unfolds toward stories from human versus AI narrators and how transparency plays a role in user emotions. Objective We aim to understand how empathy shifts across human-written versus AI-written stories, and how these findings inform ethical implications and human-centered design of using mental health chatbots as objects of empathy. Methods We conducted crowd-sourced studies with 985 participants who each wrote a personal story and then rated empathy toward 2 retrieved stories, where one was written by a language model, and another was written by a human. Our studies varied disclosing whether a story was written by a human or an AI system to see how transparent author information affects empathy toward the narrator. We conducted mixed methods analyses: through statistical tests, we compared user’s self-reported state empathy toward the stories across different conditions. In addition, we qualitatively coded open-ended feedback about reactions to the stories to understand how and why transparency affects empathy toward human versus AI storytellers. Results We found that participants significantly empathized with human-written over AI-written stories in almost all conditions, regardless of whether they are aware (t196=7.07, P<.001, Cohen d=0.60) or not aware (t298=3.46, P<.001, Cohen d=0.24) that an AI system wrote the story. We also found that participants reported greater willingness to empathize with AI-written stories when there was transparency about the story author (t494=–5.49, P<.001, Cohen d=0.36). Conclusions Our work sheds light on how empathy toward AI or human narrators is tied to the way the text is presented, thus informing ethical considerations of empathetic artificial social support or mental health chatbots.",2024,"[{'authorId': '2115509633', 'name': 'Jocelyn Jiayue Shen'}, {'authorId': '122443589', 'name': 'Daniella DiPaola'}, {'authorId': '51134075', 'name': 'Safinah Ali'}, {'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '2756001', 'name': 'Hae Won Park'}, {'authorId': '2266253563', 'name': 'C. Breazeal'}]","{'url': 'https://doi.org/10.2196/62679', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11464935, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background empathy is a driving force in our connection to others, our mental well-being, and resilience to challenges. with the rise of generative artificial intelligence (ai) systems, mental health chatbots, and ai social support companions, it is important to understand how empathy unfolds toward stories from human versus ai narrators and how transparency plays a role in user emotions. objective we aim to understand how empathy shifts across human-written versus ai-written stories, and how these findings inform ethical implications and human-centered design of using mental health chatbots as objects of empathy. methods we conducted crowd-sourced studies with 985 participants who each wrote a personal story and then rated empathy toward 2 retrieved stories, where one was written by a language model, and another was written by a human. our studies varied disclosing whether a story was written by a human or an ai system to see how transparent author information affects empathy toward the narrator. we conducted mixed methods analyses: through statistical tests, we compared user’s self-reported state empathy toward the stories across different conditions. in addition, we qualitatively coded open-ended feedback about reactions to the stories to understand how and why transparency affects empathy toward human versus ai storytellers. results we found that participants significantly empathized with human-written over ai-written stories in almost all conditions, regardless of whether they are aware (t196=7.07, p<.001, cohen d=0.60) or not aware (t298=3.46, p<.001, cohen d=0.24) that an ai system wrote the story. we also found that participants reported greater willingness to empathize with ai-written stories when there was transparency about the story author (t494=–5.49, p<.001, cohen d=0.36). conclusions our work sheds light on how empathy toward ai or human narrators is tied to the way the text is presented, thus informing ethical considerations of empathetic artificial social support or mental health chatbots.",https://doi.org/10.2196/62679
c49967c6640befc431431fce6f1ca4ba05bf7a3f,AI Hesitancy and Acceptability—Perceptions of AI Chatbots for Chronic Health Management and Long COVID Support: Survey Study,"Abstract Background Artificial intelligence (AI) chatbots have the potential to assist individuals with chronic health conditions by providing tailored information, monitoring symptoms, and offering mental health support. Despite their potential benefits, research on public attitudes toward health care chatbots is still limited. To effectively support individuals with long-term health conditions like long COVID (or post–COVID-19 condition), it is crucial to understand their perspectives and preferences regarding the use of AI chatbots. Objective This study has two main objectives: (1) provide insights into AI chatbot acceptance among people with chronic health conditions, particularly adults older than 55 years and (2) explore the perceptions of using AI chatbots for health self-management and long COVID support. Methods A web-based survey study was conducted between January and March 2023, specifically targeting individuals with diabetes and other chronic conditions. This particular population was chosen due to their potential awareness and ability to self-manage their condition. The survey aimed to capture data at multiple intervals, taking into consideration the public launch of ChatGPT, which could have potentially impacted public opinions during the project timeline. The survey received 1310 clicks and garnered 900 responses, resulting in a total of 888 usable data points. Results Although past experience with chatbots (P<.001, 95% CI .110-.302) and online information seeking (P<.001, 95% CI .039-.084) are strong indicators of respondents’ future adoption of health chatbots, they are in general skeptical or unsure about the use of AI chatbots for health care purposes. Less than one-third of the respondents (n=203, 30.1%) indicated that they were likely to use a health chatbot in the next 12 months if available. Most were uncertain about a chatbot’s capability to provide accurate medical advice. However, people seemed more receptive to using voice-based chatbots for mental well-being, health data collection, and analysis. Half of the respondents with long COVID showed interest in using emotionally intelligent chatbots. Conclusions AI hesitancy is not uniform across all health domains and user groups. Despite persistent AI hesitancy, there are promising opportunities for chatbots to offer support for chronic conditions in areas of lifestyle enhancement and mental well-being, potentially through voice-based user interfaces.",2023,"[{'authorId': '2302131185', 'name': 'Philip Fei Wu'}, {'authorId': '2237124087', 'name': 'Charlotte Summers'}, {'authorId': '68972492', 'name': 'Arjun Panesar'}, {'authorId': '2260725994', 'name': 'Amit Kaura'}, {'authorId': '2276654545', 'name': 'Li Zhang'}]","{'url': 'https://s3.ca-central-1.amazonaws.com/assets.jmir.org/assets/preprints/preprint-51086-accepted.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11287232, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract background artificial intelligence (ai) chatbots have the potential to assist individuals with chronic health conditions by providing tailored information, monitoring symptoms, and offering mental health support. despite their potential benefits, research on public attitudes toward health care chatbots is still limited. to effectively support individuals with long-term health conditions like long covid (or post–covid-19 condition), it is crucial to understand their perspectives and preferences regarding the use of ai chatbots. objective this study has two main objectives: (1) provide insights into ai chatbot acceptance among people with chronic health conditions, particularly adults older than 55 years and (2) explore the perceptions of using ai chatbots for health self-management and long covid support. methods a web-based survey study was conducted between january and march 2023, specifically targeting individuals with diabetes and other chronic conditions. this particular population was chosen due to their potential awareness and ability to self-manage their condition. the survey aimed to capture data at multiple intervals, taking into consideration the public launch of chatgpt, which could have potentially impacted public opinions during the project timeline. the survey received 1310 clicks and garnered 900 responses, resulting in a total of 888 usable data points. results although past experience with chatbots (p<.001, 95% ci .110-.302) and online information seeking (p<.001, 95% ci .039-.084) are strong indicators of respondents’ future adoption of health chatbots, they are in general skeptical or unsure about the use of ai chatbots for health care purposes. less than one-third of the respondents (n=203, 30.1%) indicated that they were likely to use a health chatbot in the next 12 months if available. most were uncertain about a chatbot’s capability to provide accurate medical advice. however, people seemed more receptive to using voice-based chatbots for mental well-being, health data collection, and analysis. half of the respondents with long covid showed interest in using emotionally intelligent chatbots. conclusions ai hesitancy is not uniform across all health domains and user groups. despite persistent ai hesitancy, there are promising opportunities for chatbots to offer support for chronic conditions in areas of lifestyle enhancement and mental well-being, potentially through voice-based user interfaces.",https://s3.ca-central-1.amazonaws.com/assets.jmir.org/assets/preprints/preprint-51086-accepted.pdf
a5e35909886f08faf55542ec4db6acfad9782eac,The Role of AI Chatbots in Mental Health Related Public Services in a (Post)Pandemic World: A Review and Future Research Agenda,"The purpose of this paper is to explore the advances in artificial intelligence (AI) chatbots as part of public services, mainly when applied to mental health in today’s post-pandemic world. The adoption of AI chatbots to keep up with basic customer support business activities is based on extensive knowledge, both from the hard (software development) and the soft side (increasing the added value to the service/product). However, using chatbots as extenders of public services to support mental health in pandemic times is an emerging research topic. Hence, the paper identifies niche and under-explored research gaps in state-of-the-art literature, thus contributing to the body of academic knowledge. The paper adopts a design science approach to formulate the problem statement, articulate the objectives of target solutions, and propose a design and development framework for future mental health chatbots by employing an extensive literature review. Findings from this paper emphasize considerations of ethical issues and governance, purposeful and goal-oriented design, and AI-based technology as critical enablers for designing new mental health chatbots. The paper contributes to the knowledge by providing clear and structured future research priorities and offers a framework for designing more effective and intelligent mental health chatbots that public organizations and managers may find useful.",2022,"[{'authorId': '2417852', 'name': 'Nadja Damij'}, {'authorId': '25131561', 'name': 'S. Bhattacharya'}]","{'url': 'http://nrl.northumbria.ac.uk/id/eprint/49808/1/TEMSCON%202022%20Final%20Manuscript-Damij%20%26%20Bhattacharya.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/temsconeurope54743.2022.9801962?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/temsconeurope54743.2022.9801962, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the purpose of this paper is to explore the advances in artificial intelligence (ai) chatbots as part of public services, mainly when applied to mental health in today’s post-pandemic world. the adoption of ai chatbots to keep up with basic customer support business activities is based on extensive knowledge, both from the hard (software development) and the soft side (increasing the added value to the service/product). however, using chatbots as extenders of public services to support mental health in pandemic times is an emerging research topic. hence, the paper identifies niche and under-explored research gaps in state-of-the-art literature, thus contributing to the body of academic knowledge. the paper adopts a design science approach to formulate the problem statement, articulate the objectives of target solutions, and propose a design and development framework for future mental health chatbots by employing an extensive literature review. findings from this paper emphasize considerations of ethical issues and governance, purposeful and goal-oriented design, and ai-based technology as critical enablers for designing new mental health chatbots. the paper contributes to the knowledge by providing clear and structured future research priorities and offers a framework for designing more effective and intelligent mental health chatbots that public organizations and managers may find useful.",http://nrl.northumbria.ac.uk/id/eprint/49808/1/TEMSCON%202022%20Final%20Manuscript-Damij%20%26%20Bhattacharya.pdf
03e0fffb458b512b51daa92f4a708e4d0c2a3479,Bridging Gender Disparities in Mental Health: A Bilingual Large Language Model for Multilingual Therapeutic Chatbots,"Significant gender disparities and a general lack of support systems compound the state of mental health in developing countries. Women, in particular, face unique challenges due to societal norms and expectations that often restrict their access to mental health services. Additionally, the cultural stigma associated with mental health issues affects both men and women but can be particularly debilitating for women who may be less likely to seek help or disclose their struggles. This study explores the application of Jais-13B, a pre-existing bilingual Large Language Model (LLM) proficient in English and Arabic, tailored to address mental health inquiries. We employed a rich dataset encompassing both languages, essential for fine-tuning and enhancing Jais-13B’s responsiveness and empathetic engagement in mental health contexts. The optimization focused on improving the model’s ability to deliver accurate and contextually aware responses, which is crucial for effective mental health support. Performance evaluation using the cross-entropy loss function demonstrated that Jais-13B achieved an accuracy of 70.58%, indicating its capability to produce relevant and precise answers to mental health questions. These results showcase Jais-13B’s potential to enhance digital mental health interventions significantly, providing accessible care solutions across diverse linguistic landscapes. This study reaffirms the effectiveness of bilingual LLMs in mental health applications and provides insights into their practical implementation, setting a foundational benchmark for future research in multilingual therapeutic chatbots.",2025,"[{'authorId': '2353269438', 'name': 'Ahmed Tamer Elboardy'}, {'authorId': '2353269736', 'name': 'Ziad Mohamed'}, {'authorId': '2281042054', 'name': 'Ghada Khoriba'}, {'authorId': '2279218380', 'name': 'Tamer Arafa'}, {'authorId': '2353268351', 'name': 'Essam A. Rashed'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/LT64002.2025.10941308?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/LT64002.2025.10941308, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","significant gender disparities and a general lack of support systems compound the state of mental health in developing countries. women, in particular, face unique challenges due to societal norms and expectations that often restrict their access to mental health services. additionally, the cultural stigma associated with mental health issues affects both men and women but can be particularly debilitating for women who may be less likely to seek help or disclose their struggles. this study explores the application of jais-13b, a pre-existing bilingual large language model (llm) proficient in english and arabic, tailored to address mental health inquiries. we employed a rich dataset encompassing both languages, essential for fine-tuning and enhancing jais-13b’s responsiveness and empathetic engagement in mental health contexts. the optimization focused on improving the model’s ability to deliver accurate and contextually aware responses, which is crucial for effective mental health support. performance evaluation using the cross-entropy loss function demonstrated that jais-13b achieved an accuracy of 70.58%, indicating its capability to produce relevant and precise answers to mental health questions. these results showcase jais-13b’s potential to enhance digital mental health interventions significantly, providing accessible care solutions across diverse linguistic landscapes. this study reaffirms the effectiveness of bilingual llms in mental health applications and provides insights into their practical implementation, setting a foundational benchmark for future research in multilingual therapeutic chatbots.",
958eb3d93a3ccf8fadb69a9e635706a269af52dd,Development and Evaluation of a Mental Health Chatbot Using ChatGPT 4.0: Mixed Methods User Experience Study With Korean Users,"Background Mental health chatbots have emerged as a promising tool for providing accessible and convenient support to individuals in need. Building on our previous research on digital interventions for loneliness and depression among Korean college students, this study addresses the limitations identified and explores more advanced artificial intelligence–driven solutions. Objective This study aimed to develop and evaluate the performance of HoMemeTown Dr. CareSam, an advanced cross-lingual chatbot using ChatGPT 4.0 (OpenAI) to provide seamless support in both English and Korean contexts. The chatbot was designed to address the need for more personalized and culturally sensitive mental health support identified in our previous work while providing an accessible and user-friendly interface for Korean young adults. Methods We conducted a mixed methods pilot study with 20 Korean young adults aged 18 to 27 (mean 23.3, SD 1.96) years. The HoMemeTown Dr CareSam chatbot was developed using the GPT application programming interface, incorporating features such as a gratitude journal and risk detection. User satisfaction and chatbot performance were evaluated using quantitative surveys and qualitative feedback, with triangulation used to ensure the validity and robustness of findings through cross-verification of data sources. Comparative analyses were conducted with other large language models chatbots and existing digital therapy tools (Woebot [Woebot Health Inc] and Happify [Twill Inc]). Results Users generally expressed positive views towards the chatbot, with positivity and support receiving the highest score on a 10-point scale (mean 9.0, SD 1.2), followed by empathy (mean 8.7, SD 1.6) and active listening (mean 8.0, SD 1.8). However, areas for improvement were noted in professionalism (mean 7.0, SD 2.0), complexity of content (mean 7.4, SD 2.0), and personalization (mean 7.4, SD 2.4). The chatbot demonstrated statistically significant performance differences compared with other large language models chatbots (F=3.27; P=.047), with more pronounced differences compared with Woebot and Happify (F=12.94; P<.001). Qualitative feedback highlighted the chatbot’s strengths in providing empathetic responses and a user-friendly interface, while areas for improvement included response speed and the naturalness of Korean language responses. Conclusions The HoMemeTown Dr CareSam chatbot shows potential as a cross-lingual mental health support tool, achieving high user satisfaction and demonstrating comparative advantages over existing digital interventions. However, the study’s limited sample size and short-term nature necessitate further research. Future studies should include larger-scale clinical trials, enhanced risk detection features, and integration with existing health care systems to fully realize its potential in supporting mental well-being across different linguistic and cultural contexts.",2024,"[{'authorId': '2312032441', 'name': 'Boyoung Kang'}, {'authorId': '2310515909', 'name': 'Munpyo Hong'}]","{'url': '', 'status': None, 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11748427, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background mental health chatbots have emerged as a promising tool for providing accessible and convenient support to individuals in need. building on our previous research on digital interventions for loneliness and depression among korean college students, this study addresses the limitations identified and explores more advanced artificial intelligence–driven solutions. objective this study aimed to develop and evaluate the performance of homemetown dr. caresam, an advanced cross-lingual chatbot using chatgpt 4.0 (openai) to provide seamless support in both english and korean contexts. the chatbot was designed to address the need for more personalized and culturally sensitive mental health support identified in our previous work while providing an accessible and user-friendly interface for korean young adults. methods we conducted a mixed methods pilot study with 20 korean young adults aged 18 to 27 (mean 23.3, sd 1.96) years. the homemetown dr caresam chatbot was developed using the gpt application programming interface, incorporating features such as a gratitude journal and risk detection. user satisfaction and chatbot performance were evaluated using quantitative surveys and qualitative feedback, with triangulation used to ensure the validity and robustness of findings through cross-verification of data sources. comparative analyses were conducted with other large language models chatbots and existing digital therapy tools (woebot [woebot health inc] and happify [twill inc]). results users generally expressed positive views towards the chatbot, with positivity and support receiving the highest score on a 10-point scale (mean 9.0, sd 1.2), followed by empathy (mean 8.7, sd 1.6) and active listening (mean 8.0, sd 1.8). however, areas for improvement were noted in professionalism (mean 7.0, sd 2.0), complexity of content (mean 7.4, sd 2.0), and personalization (mean 7.4, sd 2.4). the chatbot demonstrated statistically significant performance differences compared with other large language models chatbots (f=3.27; p=.047), with more pronounced differences compared with woebot and happify (f=12.94; p<.001). qualitative feedback highlighted the chatbot’s strengths in providing empathetic responses and a user-friendly interface, while areas for improvement included response speed and the naturalness of korean language responses. conclusions the homemetown dr caresam chatbot shows potential as a cross-lingual mental health support tool, achieving high user satisfaction and demonstrating comparative advantages over existing digital interventions. however, the study’s limited sample size and short-term nature necessitate further research. future studies should include larger-scale clinical trials, enhanced risk detection features, and integration with existing health care systems to fully realize its potential in supporting mental well-being across different linguistic and cultural contexts.",
30e2bdc4f414c3dfe3eedbf6c6ddd99f0b6c7643,Mental Health Therapist Chatbot Using NLP,"Artificial intelligence (AI) is being used in mental health care to create chatbots that act as therapists. The chatbots, using natural language processing (NLP), communicate with users to provide therapeutic support. This abstract discusses the development of chatbots serving as agents for individuals seeking mental health assistance. They offer convenient and confidential ways for people to talk about and ease issues such as anxiety, depression, and stress. The chatbot does not only inform users about mental health choices but also help decrease stigma and encourage a proactive approach to mental wellness. The innovative AI- driven therapist chatbot aims to tackle the intricate issues of depression, anxiety, and stress. By employing advanced Natural Language Processing (NLP) techniques, the proposed system aims to offer personalized and empathetic virtual support for individuals managing mental health challenges. It also utilizes sentiment analysis to interpret the emotional tone or sentiment conveyed in user inputs, usually in text form. Sentiment analysis, also referred to as opinion mining, determines whether a text expresses positive, negative, or neutral sentiment. The chatbots powered by AI and NLP play a crucial role in providing mental health support and breaking down barriers to seeking help. Their ability to analyze sentiments contributes to a better understanding of users' emotional needs and enables more effective communication in therapy sessions.",2024,"[{'authorId': '2299188015', 'name': 'Asha Vuyyuru'}, {'authorId': '2346528616', 'name': 'T. L. Praveena'}, {'authorId': '2346517981', 'name': 'Akanksha Sharma'}, {'authorId': '2346549692', 'name': 'Manaswini Yelagandula'}, {'authorId': '2346521063', 'name': 'Sanjana Nelli'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICAIQSA64000.2024.10882362?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICAIQSA64000.2024.10882362, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","artificial intelligence (ai) is being used in mental health care to create chatbots that act as therapists. the chatbots, using natural language processing (nlp), communicate with users to provide therapeutic support. this abstract discusses the development of chatbots serving as agents for individuals seeking mental health assistance. they offer convenient and confidential ways for people to talk about and ease issues such as anxiety, depression, and stress. the chatbot does not only inform users about mental health choices but also help decrease stigma and encourage a proactive approach to mental wellness. the innovative ai- driven therapist chatbot aims to tackle the intricate issues of depression, anxiety, and stress. by employing advanced natural language processing (nlp) techniques, the proposed system aims to offer personalized and empathetic virtual support for individuals managing mental health challenges. it also utilizes sentiment analysis to interpret the emotional tone or sentiment conveyed in user inputs, usually in text form. sentiment analysis, also referred to as opinion mining, determines whether a text expresses positive, negative, or neutral sentiment. the chatbots powered by ai and nlp play a crucial role in providing mental health support and breaking down barriers to seeking help. their ability to analyze sentiments contributes to a better understanding of users' emotional needs and enables more effective communication in therapy sessions.",
a343792f2633edf726ba6f8c51bfd0eebfedd8be,Effectiveness of a Mental Health Chatbot for People With Chronic Diseases: Randomized Controlled Trial,"Background People with chronic diseases tend to experience more mental health issues than their peers without these health conditions. Mental health chatbots offer a potential source of mental health support for people with chronic diseases. Objective The aim of this study was to determine whether a mental health chatbot can improve mental health in people with chronic diseases. We focused on 2 chronic diseases in particular: arthritis and diabetes. Methods Individuals with arthritis or diabetes were recruited using various web-based methods. Participants were randomly assigned to 1 of 2 groups. Those in the treatment group used a mental health chatbot app (Wysa [Wysa Inc]) over a period of 4 weeks. Those in the control group received no intervention. Participants completed measures of depression (Patient Health Questionnaire–9), anxiety (Generalized Anxiety Disorder Scale–7), and stress (Perceived Stress Scale–10) at baseline, with follow-up testing 2 and 4 weeks later. Participants in the treatment group completed feedback questions on their experiences with the app at the final assessment point. Results A total of 68 participants (n=47, 69% women; mean age 42.87, SD 11.27 years) were included in the analysis. Participants were divided evenly between the treatment and control groups. Those in the treatment group reported decreases in depression (P<.001) and anxiety (P<.001) severity over the study period. No such changes were found among participants in the control group. No changes in stress were reported by participants in either group. Participants with arthritis reported higher levels of depression (P=.004) and anxiety (P=.004) severity than participants with diabetes over the course of the study, as well as higher levels of stress (P=.01); otherwise, patterns of results were similar across these health conditions. In response to the feedback questions, participants in the treatment group said that they liked many of the functions and features of the app, the general design of the app, and the user experience. They also disliked some aspects of the app, with most of these reports focusing on the chatbot’s conversational abilities. Conclusions The results of this study suggest that mental health chatbots can be an effective source of mental health support for people with chronic diseases such as arthritis and diabetes. Although cost-effective and accessible, these programs have limitations and may not be well suited for all individuals. Trial Registration ClinicalTrials.gov NCT04620668; https://www.clinicaltrials.gov/study/NCT04620668",2024,"[{'authorId': '2079060538', 'name': 'A. MacNeill'}, {'authorId': '2299575195', 'name': 'Shelley Doucet'}, {'authorId': '2299664809', 'name': 'Alison Luke'}]","{'url': 'https://formative.jmir.org/2024/1/e50025/PDF', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11176869, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background people with chronic diseases tend to experience more mental health issues than their peers without these health conditions. mental health chatbots offer a potential source of mental health support for people with chronic diseases. objective the aim of this study was to determine whether a mental health chatbot can improve mental health in people with chronic diseases. we focused on 2 chronic diseases in particular: arthritis and diabetes. methods individuals with arthritis or diabetes were recruited using various web-based methods. participants were randomly assigned to 1 of 2 groups. those in the treatment group used a mental health chatbot app (wysa [wysa inc]) over a period of 4 weeks. those in the control group received no intervention. participants completed measures of depression (patient health questionnaire–9), anxiety (generalized anxiety disorder scale–7), and stress (perceived stress scale–10) at baseline, with follow-up testing 2 and 4 weeks later. participants in the treatment group completed feedback questions on their experiences with the app at the final assessment point. results a total of 68 participants (n=47, 69% women; mean age 42.87, sd 11.27 years) were included in the analysis. participants were divided evenly between the treatment and control groups. those in the treatment group reported decreases in depression (p<.001) and anxiety (p<.001) severity over the study period. no such changes were found among participants in the control group. no changes in stress were reported by participants in either group. participants with arthritis reported higher levels of depression (p=.004) and anxiety (p=.004) severity than participants with diabetes over the course of the study, as well as higher levels of stress (p=.01); otherwise, patterns of results were similar across these health conditions. in response to the feedback questions, participants in the treatment group said that they liked many of the functions and features of the app, the general design of the app, and the user experience. they also disliked some aspects of the app, with most of these reports focusing on the chatbot’s conversational abilities. conclusions the results of this study suggest that mental health chatbots can be an effective source of mental health support for people with chronic diseases such as arthritis and diabetes. although cost-effective and accessible, these programs have limitations and may not be well suited for all individuals. trial registration clinicaltrials.gov nct04620668; https://www.clinicaltrials.gov/study/nct04620668",https://formative.jmir.org/2024/1/e50025/PDF
a17ba9b439d9ad7f37cc141022671eefa40a1ec0,Towards Understanding Emotions for Engaged Mental Health Conversations,"Providing timely support and intervention is crucial in mental health settings. As the need to engage youth comfortable with texting increases, mental health providers are exploring and adopting text-based media such as chatbots, community-based forums, online therapies with licensed professionals, and helplines operated by trained responders. To support these text-based media for mental health–particularly for crisis care–we are developing a system to perform passive emotion-sensing using a combination of keystroke dynamics and sentiment analysis. Our early studies of this system posit that the analysis of short text messages and keyboard typing patterns can provide emotion information that may be used to support both clients and responders. We use our preliminary findings to discuss the way forward for applying AI to support mental health providers in providing better care.",2024,"[{'authorId': '2307010136', 'name': 'Kellie Yu Hui Sim'}, {'authorId': '2307010847', 'name': 'Kohleen Tijing Fortuno'}, {'authorId': '9511005', 'name': 'K. Choo'}]","{'url': 'https://arxiv.org/pdf/2406.11135', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2406.11135, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","providing timely support and intervention is crucial in mental health settings. as the need to engage youth comfortable with texting increases, mental health providers are exploring and adopting text-based media such as chatbots, community-based forums, online therapies with licensed professionals, and helplines operated by trained responders. to support these text-based media for mental health–particularly for crisis care–we are developing a system to perform passive emotion-sensing using a combination of keystroke dynamics and sentiment analysis. our early studies of this system posit that the analysis of short text messages and keyboard typing patterns can provide emotion information that may be used to support both clients and responders. we use our preliminary findings to discuss the way forward for applying ai to support mental health providers in providing better care.",https://arxiv.org/pdf/2406.11135
34f8edeb2c8245ac5172a92b12b541fe67015c9f,Private Yet Social: How LLM Chatbots Support and Challenge Eating Disorder Recovery,"Eating disorders (ED) are complex mental health conditions that require long-term management and support. Recent advancements in large language model (LLM)-based chatbots offer the potential to assist individuals in receiving immediate support. Yet, concerns remain about their reliability and safety in sensitive contexts such as ED. We explore the opportunities and potential harms of using LLM-based chatbots for ED recovery. We observe the interactions between 26 participants with ED and an LLM-based chatbot, WellnessBot, designed to support ED recovery, over 10 days. We discovered that our participants have felt empowered in recovery by discussing ED-related stories with the chatbot, which served as a personal yet social avenue. However, we also identified harmful chatbot responses, especially concerning individuals with ED, that went unnoticed partly due to participants' unquestioning trust in the chatbot's reliability. Based on these findings, we provide design implications for safe and effective LLM-based interventions in ED management.",2024,"[{'authorId': '2090976392', 'name': 'Ryuhaerang Choi'}, {'authorId': '2335667655', 'name': 'Taehan Kim'}, {'authorId': '2266362315', 'name': 'Subin Park'}, {'authorId': '2253975690', 'name': 'Jennifer G. Kim'}, {'authorId': '2266764017', 'name': 'Sung-Ju Lee'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.11656, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","eating disorders (ed) are complex mental health conditions that require long-term management and support. recent advancements in large language model (llm)-based chatbots offer the potential to assist individuals in receiving immediate support. yet, concerns remain about their reliability and safety in sensitive contexts such as ed. we explore the opportunities and potential harms of using llm-based chatbots for ed recovery. we observe the interactions between 26 participants with ed and an llm-based chatbot, wellnessbot, designed to support ed recovery, over 10 days. we discovered that our participants have felt empowered in recovery by discussing ed-related stories with the chatbot, which served as a personal yet social avenue. however, we also identified harmful chatbot responses, especially concerning individuals with ed, that went unnoticed partly due to participants' unquestioning trust in the chatbot's reliability. based on these findings, we provide design implications for safe and effective llm-based interventions in ed management.",
0b0bde375cda69bfdd0c13eab7ca577299d10fe3,Overview of chatbot usage on mental health: A scoping review,"Mental disorders have become the second most significant global health burden. One approach to reducing the medical and socio-economic impacts of mental illnesses/disorders is leveraging the power of digital health technology. Chatbots, in particular, hold great potential for providing social and psychological support, akin to human interactions. This research aims to map the use of mental health chatbot technology using the scoping review method based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extensions for Scoping Reviews. The results are categorized according to use, including acceptability, effectiveness, usability, adoption, and features. Study selection was assisted by Rayyan. Data extraction used a narrative approach. Chatbots were classified based on purpose, target population, targeted mental health disorders, and usage metrics. 21 out of 172 research articles met the inclusion criteria. Anxiety, depression, and stress were the most common target disorders for chatbot use, although a combination of focuses is quite ideal for mental health chatbots. Many chatbots have been used for various types of mental disorders. Their purposes range from prevention and training to therapy, with most being a combination. Further research is needed to understand the changes that occur following interventions using mental health chatbots.",2024,"[{'authorId': '2326547990', 'name': 'Ririn Indah Permatasari'}, {'authorId': '2326535256', 'name': 'Dian Parama Artha'}, {'authorId': '2326539213', 'name': 'Bayu Satria Wiratama'}, {'authorId': '2326540465', 'name': 'Hanifah Wulandari'}]","{'url': 'https://doi.org/10.1051/bioconf/202413205002', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1051/bioconf/202413205002?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1051/bioconf/202413205002, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mental disorders have become the second most significant global health burden. one approach to reducing the medical and socio-economic impacts of mental illnesses/disorders is leveraging the power of digital health technology. chatbots, in particular, hold great potential for providing social and psychological support, akin to human interactions. this research aims to map the use of mental health chatbot technology using the scoping review method based on the preferred reporting items for systematic reviews and meta-analyses extensions for scoping reviews. the results are categorized according to use, including acceptability, effectiveness, usability, adoption, and features. study selection was assisted by rayyan. data extraction used a narrative approach. chatbots were classified based on purpose, target population, targeted mental health disorders, and usage metrics. 21 out of 172 research articles met the inclusion criteria. anxiety, depression, and stress were the most common target disorders for chatbot use, although a combination of focuses is quite ideal for mental health chatbots. many chatbots have been used for various types of mental disorders. their purposes range from prevention and training to therapy, with most being a combination. further research is needed to understand the changes that occur following interventions using mental health chatbots.",https://doi.org/10.1051/bioconf/202413205002
d42177f5d46c2f350ace8ad5d908fc5c9a74dd92,Current Landscape and Future Directions for Mental Health Conversational Agents for Youth: Scoping Review,"Background Conversational agents (CAs; chatbots) are systems with the ability to interact with users using natural human dialogue. They are increasingly used to support interactive knowledge discovery of sensitive topics such as mental health topics. While much of the research on CAs for mental health has focused on adult populations, the insights from such research may not apply to CAs for youth. Objective This study aimed to comprehensively evaluate the state-of-the-art research on mental health CAs for youth. Methods Following PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, we identified 39 peer-reviewed studies specific to mental health CAs designed for youth across 4 databases, including ProQuest, Scopus, Web of Science, and PubMed. We conducted a scoping review of the literature to evaluate the characteristics of research on mental health CAs designed for youth, the design and computational considerations of mental health CAs for youth, and the evaluation outcomes reported in the research on mental health CAs for youth. Results We found that many mental health CAs (11/39, 28%) were designed as older peers to provide therapeutic or educational content to promote youth mental well-being. All CAs were designed based on expert knowledge, with a few that incorporated inputs from youth. The technical maturity of CAs was in its infancy, focusing on building prototypes with rule-based models to deliver prewritten content, with limited safety features to respond to imminent risk. Research findings suggest that while youth appreciate the 24/7 availability of friendly or empathetic conversation on sensitive topics with CAs, they found the content provided by CAs to be limited. Finally, we found that most (35/39, 90%) of the reviewed studies did not address the ethical aspects of mental health CAs, while youth were concerned about the privacy and confidentiality of their sensitive conversation data. Conclusions Our study highlights the need for researchers to continue to work together to align evidence-based research on mental health CAs for youth with lessons learned on how to best deliver these technologies to youth. Our review brings to light mental health CAs needing further development and evaluation. The new trend of large language model–based CAs can make such technologies more feasible. However, the privacy and safety of the systems should be prioritized. Although preliminary evidence shows positive trends in mental health CAs, long-term evaluative research with larger sample sizes and robust research designs is needed to validate their efficacy. More importantly, collaboration between youth and clinical experts is essential from the early design stages through to the final evaluation to develop safe, effective, and youth-centered mental health chatbots. Finally, best practices for risk mitigation and ethical development of CAs with and for youth are needed to promote their mental well-being.",2024,"[{'authorId': '2258316311', 'name': 'J. Park'}, {'authorId': '2258528786', 'name': 'Vivek Singh'}, {'authorId': '2281859332', 'name': 'Pamela J. Wisniewski'}]","{'url': '', 'status': None, 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11909484, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background conversational agents (cas; chatbots) are systems with the ability to interact with users using natural human dialogue. they are increasingly used to support interactive knowledge discovery of sensitive topics such as mental health topics. while much of the research on cas for mental health has focused on adult populations, the insights from such research may not apply to cas for youth. objective this study aimed to comprehensively evaluate the state-of-the-art research on mental health cas for youth. methods following prisma (preferred reporting items for systematic reviews and meta-analyses) guidelines, we identified 39 peer-reviewed studies specific to mental health cas designed for youth across 4 databases, including proquest, scopus, web of science, and pubmed. we conducted a scoping review of the literature to evaluate the characteristics of research on mental health cas designed for youth, the design and computational considerations of mental health cas for youth, and the evaluation outcomes reported in the research on mental health cas for youth. results we found that many mental health cas (11/39, 28%) were designed as older peers to provide therapeutic or educational content to promote youth mental well-being. all cas were designed based on expert knowledge, with a few that incorporated inputs from youth. the technical maturity of cas was in its infancy, focusing on building prototypes with rule-based models to deliver prewritten content, with limited safety features to respond to imminent risk. research findings suggest that while youth appreciate the 24/7 availability of friendly or empathetic conversation on sensitive topics with cas, they found the content provided by cas to be limited. finally, we found that most (35/39, 90%) of the reviewed studies did not address the ethical aspects of mental health cas, while youth were concerned about the privacy and confidentiality of their sensitive conversation data. conclusions our study highlights the need for researchers to continue to work together to align evidence-based research on mental health cas for youth with lessons learned on how to best deliver these technologies to youth. our review brings to light mental health cas needing further development and evaluation. the new trend of large language model–based cas can make such technologies more feasible. however, the privacy and safety of the systems should be prioritized. although preliminary evidence shows positive trends in mental health cas, long-term evaluative research with larger sample sizes and robust research designs is needed to validate their efficacy. more importantly, collaboration between youth and clinical experts is essential from the early design stages through to the final evaluation to develop safe, effective, and youth-centered mental health chatbots. finally, best practices for risk mitigation and ethical development of cas with and for youth are needed to promote their mental well-being.",
86112913c138554b7514e6ba65ba9dd5a0d56381,Implementing Cognitive Behavioral Therapy in Chatbots to Reduce Students’ Exam Stress using ChatGPT,"Undergraduate students frequently encounter academic stress, highlighting the need for accessible and effective coping mechanisms. This study develops an AI chatbot grounded in Cognitive Behavioral Therapy (CBT) principles to meet the mental health needs of these students. The primary goal is to devise and assess a chatbot that delivers personalized support for managing academic stress. The chatbot engages students in meaningful conversations, identifies cognitive distortions in their thought processes, and provides customized coping strategies. It leverages OpenAI’s GPT-3.5 turbo LLM for generating lifelike interactions and uses a vector database to store domain-specific knowledge. Responses are preprocessed with OpenAI embeddings for intent classification. Support Vector Machines (SVM), Multinomial Logistic Regression, and Random Forest models are used for classifying cognitive distortions, with SVM achieving the highest accuracy of $85.94 \%$. Intent classification is refined using cosine similarity, enhancing the chatbot’s conversational accuracy. Although SVM outperforms other models, ongoing challenges call for further research to refine the chatbot’s functionality and improve its impact on student well-being.",2024,"[{'authorId': '2341405258', 'name': 'M. M. A. H. Indumini'}, {'authorId': '2341392432', 'name': 'K. Kulathilake'}, {'authorId': '2341405272', 'name': 'D. K. Hettiarachchi'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/SLAAI-ICAI63667.2024.10844930?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SLAAI-ICAI63667.2024.10844930, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","undergraduate students frequently encounter academic stress, highlighting the need for accessible and effective coping mechanisms. this study develops an ai chatbot grounded in cognitive behavioral therapy (cbt) principles to meet the mental health needs of these students. the primary goal is to devise and assess a chatbot that delivers personalized support for managing academic stress. the chatbot engages students in meaningful conversations, identifies cognitive distortions in their thought processes, and provides customized coping strategies. it leverages openai’s gpt-3.5 turbo llm for generating lifelike interactions and uses a vector database to store domain-specific knowledge. responses are preprocessed with openai embeddings for intent classification. support vector machines (svm), multinomial logistic regression, and random forest models are used for classifying cognitive distortions, with svm achieving the highest accuracy of $85.94 \%$. intent classification is refined using cosine similarity, enhancing the chatbot’s conversational accuracy. although svm outperforms other models, ongoing challenges call for further research to refine the chatbot’s functionality and improve its impact on student well-being.",
cf3e8af119bae0d72a9d62fbc2a66d44bf854e94,An Integrative Survey on Mental Health Conversational Agents to Bridge Computer Science and Medical Perspectives,"Mental health conversational agents (a.k.a. chatbots) are widely studied for their potential to offer accessible support to those experiencing mental health challenges. Previous surveys on the topic primarily consider papers published in either computer science or medicine, leading to a divide in understanding and hindering the sharing of beneficial knowledge between both domains. To bridge this gap, we conduct a comprehensive literature review using the PRISMA framework, reviewing 534 papers published in both computer science and medicine. Our systematic review reveals 136 key papers on building mental health-related conversational agents with diverse characteristics of modeling and experimental design techniques. We find that computer science papers focus on LLM techniques and evaluating response quality using automated metrics with little attention to the application while medical papers use rule-based conversational agents and outcome metrics to measure the health outcomes of participants. Based on our findings on transparency, ethics, and cultural heterogeneity in this review, we provide a few recommendations to help bridge the disciplinary divide and enable the cross-disciplinary development of mental health conversational agents.",2023,"[{'authorId': '2261909926', 'name': 'Y. Cho'}, {'authorId': '2261734219', 'name': 'Sunny Rai'}, {'authorId': '1717822', 'name': 'Lyle Ungar'}, {'authorId': '2662374', 'name': 'João Sedoc'}, {'authorId': '2008166098', 'name': 'Sharath Chandra Guntuku'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2310.17017, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mental health conversational agents (a.k.a. chatbots) are widely studied for their potential to offer accessible support to those experiencing mental health challenges. previous surveys on the topic primarily consider papers published in either computer science or medicine, leading to a divide in understanding and hindering the sharing of beneficial knowledge between both domains. to bridge this gap, we conduct a comprehensive literature review using the prisma framework, reviewing 534 papers published in both computer science and medicine. our systematic review reveals 136 key papers on building mental health-related conversational agents with diverse characteristics of modeling and experimental design techniques. we find that computer science papers focus on llm techniques and evaluating response quality using automated metrics with little attention to the application while medical papers use rule-based conversational agents and outcome metrics to measure the health outcomes of participants. based on our findings on transparency, ethics, and cultural heterogeneity in this review, we provide a few recommendations to help bridge the disciplinary divide and enable the cross-disciplinary development of mental health conversational agents.",
0ad7a68961b264391ed40d91b9d42404733d7d34,How can technology support young people’s mental health and wellbeing? Use of technology in education to support neurotypical and neurodiverse students,"Purpose
The technology used in educational settings, including school, college, university and home, is becoming increasingly more influential on the wellbeing of young people. This essay will consider the impact of technology as a tool for improving wellbeing in the educational setting.

Design/methodology/approach
A 2019 survey found that managing students’ wellbeing was described as one of the top 3 challenges for 44% of teachers (Education Horizons 2021). Therefore, research should focus on how using technology can offer a more inclusive and positive learning environment.

Findings
This essay briefly discusses previous research which has been carried out into using technology as a well-being tool in schools and as a means of support for autistic students in particular.

Research limitations/implications
The essay will review the use of educational technology: chatbots, digital platforms and the hybrid inclusive classroom model to enhance wellbeing in institutions and how technology can combat the effects of autism on wellbeing.

Originality/value
It was found that technology can not only benefit the wellbeing of neurotypical students, through increasing classroom engagement, connections with teachers and allowing proactive intervention but also autistic students, through allowing a potentially more efficient route to diagnosis and reducing social isolation and communication barriers.
",2025,"[{'authorId': '2352312350', 'name': 'Rachel Louise Armstrong'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/mhdt-01-2025-0005?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/mhdt-01-2025-0005, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose the technology used in educational settings, including school, college, university and home, is becoming increasingly more influential on the wellbeing of young people. this essay will consider the impact of technology as a tool for improving wellbeing in the educational setting. design/methodology/approach a 2019 survey found that managing students’ wellbeing was described as one of the top 3 challenges for 44% of teachers (education horizons 2021). therefore, research should focus on how using technology can offer a more inclusive and positive learning environment. findings this essay briefly discusses previous research which has been carried out into using technology as a well-being tool in schools and as a means of support for autistic students in particular. research limitations/implications the essay will review the use of educational technology: chatbots, digital platforms and the hybrid inclusive classroom model to enhance wellbeing in institutions and how technology can combat the effects of autism on wellbeing. originality/value it was found that technology can not only benefit the wellbeing of neurotypical students, through increasing classroom engagement, connections with teachers and allowing proactive intervention but also autistic students, through allowing a potentially more efficient route to diagnosis and reducing social isolation and communication barriers.",
6133017a7893e06338ddcba6d5ed4cd10c6513a0,Usability Comparison Among Healthy Participants of an Anthropomorphic Digital Human and a Text-Based Chatbot as a Responder to Questions on Mental Health: Randomized Controlled Trial,"Background The use of chatbots in mental health support has increased exponentially in recent years, with studies showing that they may be effective in treating mental health problems. More recently, the use of visual avatars called digital humans has been introduced. Digital humans have the capability to use facial expressions as another dimension in human-computer interactions. It is important to study the difference in emotional response and usability preferences between text-based chatbots and digital humans for interacting with mental health services. Objective This study aims to explore to what extent a digital human interface and a text-only chatbot interface differed in usability when tested by healthy participants, using BETSY (Behavior, Emotion, Therapy System, and You) which uses 2 distinct interfaces: a digital human with anthropomorphic features and a text-only user interface. We also set out to explore how chatbot-generated conversations on mental health (specific to each interface) affected self-reported feelings and biometrics. Methods We explored to what extent a digital human with anthropomorphic features differed from a traditional text-only chatbot regarding perception of usability through the System Usability Scale, emotional reactions through electroencephalography, and feelings of closeness. Healthy participants (n=45) were randomized to 2 groups that used a digital human with anthropomorphic features (n=25) or a text-only chatbot with no such features (n=20). The groups were compared by linear regression analysis and t tests. Results No differences were observed between the text-only and digital human groups regarding demographic features. The mean System Usability Scale score was 75.34 (SD 10.01; range 57-90) for the text-only chatbot versus 64.80 (SD 14.14; range 40-90) for the digital human interface. Both groups scored their respective chatbot interfaces as average or above average in usability. Women were more likely to report feeling annoyed by BETSY. Conclusions The text-only chatbot was perceived as significantly more user-friendly than the digital human, although there were no significant differences in electroencephalography measurements. Male participants exhibited lower levels of annoyance with both interfaces, contrary to previously reported findings.",2023,"[{'authorId': '2123097642', 'name': 'Almira Osmanovic Thunström'}, {'authorId': '2072814', 'name': 'H. Carlsen'}, {'authorId': '4616232', 'name': 'L. Ali'}, {'authorId': '2284703836', 'name': 'Tomas Larson'}, {'authorId': '2284701780', 'name': 'Andreas Hellström'}, {'authorId': '2238792378', 'name': 'Steinn Steingrimsson'}]","{'url': 'https://doi.org/10.2196/54581', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11091805, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background the use of chatbots in mental health support has increased exponentially in recent years, with studies showing that they may be effective in treating mental health problems. more recently, the use of visual avatars called digital humans has been introduced. digital humans have the capability to use facial expressions as another dimension in human-computer interactions. it is important to study the difference in emotional response and usability preferences between text-based chatbots and digital humans for interacting with mental health services. objective this study aims to explore to what extent a digital human interface and a text-only chatbot interface differed in usability when tested by healthy participants, using betsy (behavior, emotion, therapy system, and you) which uses 2 distinct interfaces: a digital human with anthropomorphic features and a text-only user interface. we also set out to explore how chatbot-generated conversations on mental health (specific to each interface) affected self-reported feelings and biometrics. methods we explored to what extent a digital human with anthropomorphic features differed from a traditional text-only chatbot regarding perception of usability through the system usability scale, emotional reactions through electroencephalography, and feelings of closeness. healthy participants (n=45) were randomized to 2 groups that used a digital human with anthropomorphic features (n=25) or a text-only chatbot with no such features (n=20). the groups were compared by linear regression analysis and t tests. results no differences were observed between the text-only and digital human groups regarding demographic features. the mean system usability scale score was 75.34 (sd 10.01; range 57-90) for the text-only chatbot versus 64.80 (sd 14.14; range 40-90) for the digital human interface. both groups scored their respective chatbot interfaces as average or above average in usability. women were more likely to report feeling annoyed by betsy. conclusions the text-only chatbot was perceived as significantly more user-friendly than the digital human, although there were no significant differences in electroencephalography measurements. male participants exhibited lower levels of annoyance with both interfaces, contrary to previously reported findings.",https://doi.org/10.2196/54581
2cfb6a21c66142cd45cc5d5c8ce36d2b70514b26,Towards developing a pocket therapist: an intelligent adaptive psychological support chatbot against mental health disorders in a pandemic situation,"Nowadays with COVID-19 ongoing epidemic outbreak, containment for weeks was one of the most effective measures adopted to deal with the spread of the virus until a vaccine could be efficient. Over that period, increased anxiety, depression, suicide attempts and post-traumatic stress disorder are accumulated. Several studies referred to the need of using chatbots, which recognizes human emotions in such pandemic contexts. More recently, numerous research papers improved the ability of artificial intelligence methods to recognize human emotion. However, they are still limited. The aim of this paper is the development of a chatbot against the disturbing psychic consequences of the pandemic, taking human emotion recognition into account. The object is to help people; especially students; suffering from mental disorders, by progressively understanding the reasonsbehind them. This innovative chatbot was developed by using the natural language processing model of deep learning. An advanced model of deep learning has been elaborated the intention for people and that to help them to regulate their mood and to reduce distortion of negative thoughts, that why a collection of a new database was done. The sequence-to-sequence model encoder and decoder consist of Long short-term memory cells and it is defined with the bi-directional dynamic recurrent neural network packets.",2021,"[{'authorId': '46180721', 'name': 'Intissar Salhi'}, {'authorId': '2893287', 'name': 'K. E. Guemmat'}, {'authorId': '7623555', 'name': 'Mohammed Qbadou'}, {'authorId': '3442454', 'name': 'K. Mansouri'}]","{'url': 'https://ijeecs.iaescore.com/index.php/IJEECS/article/download/25060/15336', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.11591/ijeecs.v23.i2.pp1200-1211?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.11591/ijeecs.v23.i2.pp1200-1211, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","nowadays with covid-19 ongoing epidemic outbreak, containment for weeks was one of the most effective measures adopted to deal with the spread of the virus until a vaccine could be efficient. over that period, increased anxiety, depression, suicide attempts and post-traumatic stress disorder are accumulated. several studies referred to the need of using chatbots, which recognizes human emotions in such pandemic contexts. more recently, numerous research papers improved the ability of artificial intelligence methods to recognize human emotion. however, they are still limited. the aim of this paper is the development of a chatbot against the disturbing psychic consequences of the pandemic, taking human emotion recognition into account. the object is to help people; especially students; suffering from mental disorders, by progressively understanding the reasonsbehind them. this innovative chatbot was developed by using the natural language processing model of deep learning. an advanced model of deep learning has been elaborated the intention for people and that to help them to regulate their mood and to reduce distortion of negative thoughts, that why a collection of a new database was done. the sequence-to-sequence model encoder and decoder consist of long short-term memory cells and it is defined with the bi-directional dynamic recurrent neural network packets.",https://ijeecs.iaescore.com/index.php/IJEECS/article/download/25060/15336
adff031c7918ce7985b6ab18f00bcec57552ba1a,Mental Health Assist and Diagnosis Conversational Interface using Logistic Regression Model for Emotion and Sentiment Analysis,"The aim of this work was to create a fully functional AI-ML based conversational agent that behaves like a real time therapist which analyses the user’s emotion at every step and provides appropriate responses and feedback. AI chatbots, although fairly new to the domain of mental health, can help in destigmatizing seeking help, and are more easily accessible to everyone, at any time. Chatbots provide an effective way to communicate with a user and offer helpful emotional support in a more economical way. While making regular psychiatric visits often require a fixed duration/appointment which can be time consuming and is restricted to a fraction of the day, the proposed chatbot can keep track of your health on the go at any time. The application will have a self-healing kit suggesting various exercises, both mental and physical that the user may implement in his day-to-day life. The study below goes into further detail on the major insinuations for future chatbot agent design and assessment",2022,"[{'authorId': '2149664700', 'name': 'S. Moulya'}, {'authorId': '2149666443', 'name': 'T. R. Pragathi'}]","{'url': 'https://doi.org/10.1088/1742-6596/2161/1/012039', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1088/1742-6596/2161/1/012039?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/1742-6596/2161/1/012039, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the aim of this work was to create a fully functional ai-ml based conversational agent that behaves like a real time therapist which analyses the user’s emotion at every step and provides appropriate responses and feedback. ai chatbots, although fairly new to the domain of mental health, can help in destigmatizing seeking help, and are more easily accessible to everyone, at any time. chatbots provide an effective way to communicate with a user and offer helpful emotional support in a more economical way. while making regular psychiatric visits often require a fixed duration/appointment which can be time consuming and is restricted to a fraction of the day, the proposed chatbot can keep track of your health on the go at any time. the application will have a self-healing kit suggesting various exercises, both mental and physical that the user may implement in his day-to-day life. the study below goes into further detail on the major insinuations for future chatbot agent design and assessment",https://doi.org/10.1088/1742-6596/2161/1/012039
72639823ec5d0afd071b90d9045df4b5b28de38e,MindIntent: A Chatbot Using SVM for Identifying Mental Health Intervention Intentions,"Mental health issues are increasingly acknowledged as vital, yet traditional support systems have limitations in availability, cost, and accessibility. Chatbots provide a scalable solution for real-time support, but their usefulness is dependent on correctly understanding user input. This work uses a Support Vector Machine (SVM) to improve chatbot performance in mental health applications by effectively dealing with high-dimensional data and discriminating between emotional states and intents. We created a chatbot by gathering and annotating text data, preprocessing it, and extracting features with tools like TF-IDF and word embeddings. The SVM model was trained on this data and implemented into the chatbot, allowing for real-time classification of user inputs and contextually relevant responses. Our results show that the SVM-powered chatbot excels at accurately categorizing users.",2025,"[{'authorId': '2344100031', 'name': 'Varsha Jadhav'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.52783/jisem.v10i4s.564?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.52783/jisem.v10i4s.564, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mental health issues are increasingly acknowledged as vital, yet traditional support systems have limitations in availability, cost, and accessibility. chatbots provide a scalable solution for real-time support, but their usefulness is dependent on correctly understanding user input. this work uses a support vector machine (svm) to improve chatbot performance in mental health applications by effectively dealing with high-dimensional data and discriminating between emotional states and intents. we created a chatbot by gathering and annotating text data, preprocessing it, and extracting features with tools like tf-idf and word embeddings. the svm model was trained on this data and implemented into the chatbot, allowing for real-time classification of user inputs and contextually relevant responses. our results show that the svm-powered chatbot excels at accurately categorizing users.",
321e0898d492f6d03d60f4014065a8c810850cb9,FedMentalCare: Towards Privacy-Preserving Fine-Tuned LLMs to Analyze Mental Health Status Using Federated Learning Framework,"With the increasing prevalence of mental health conditions worldwide, AI-powered chatbots and conversational agents have emerged as accessible tools to support mental health. However, deploying Large Language Models (LLMs) in mental healthcare applications raises significant privacy concerns, especially regarding regulations like HIPAA and GDPR. In this work, we propose FedMentalCare, a privacy-preserving framework that leverages Federated Learning (FL) combined with Low-Rank Adaptation (LoRA) to fine-tune LLMs for mental health analysis. We investigate the performance impact of varying client data volumes and model architectures (e.g., MobileBERT and MiniLM) in FL environments. Our framework demonstrates a scalable, privacy-aware approach for deploying LLMs in real-world mental healthcare scenarios, addressing data security and computational efficiency challenges.",2025,"[{'authorId': '2349383855', 'name': 'S. M. Sarwar'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.05786, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with the increasing prevalence of mental health conditions worldwide, ai-powered chatbots and conversational agents have emerged as accessible tools to support mental health. however, deploying large language models (llms) in mental healthcare applications raises significant privacy concerns, especially regarding regulations like hipaa and gdpr. in this work, we propose fedmentalcare, a privacy-preserving framework that leverages federated learning (fl) combined with low-rank adaptation (lora) to fine-tune llms for mental health analysis. we investigate the performance impact of varying client data volumes and model architectures (e.g., mobilebert and minilm) in fl environments. our framework demonstrates a scalable, privacy-aware approach for deploying llms in real-world mental healthcare scenarios, addressing data security and computational efficiency challenges.",
c2a78bea743632a49980130ee0b8142c7b53296e,Bridging Technology and Therapy: Exploring AI in Mental Health Services through Counselors' and Students' Perspectives,"Aim of the Study: In the current era of advanced technology, AI is a widely used tool among the new generation. Its further advancements have introduced AI-powered counselors (robot-like chatbots) who provide mental health assistance and support for those needing mental health counseling. The current qualitative study explores the integration of AI in mental health counseling through the perspectives of counselors and students.
Methodology: Using the purposive sampling method, 20 mental health counselors and 20 students were selected to interview them about the effectiveness of AI in the mental health counselling field. Data was thematically analyzed with the help of Braun and Clarke’s (2006) six-step framework, and eight themes were developed, including: user experiences and satisfaction; perceived effectiveness; stigma and acceptance; confidentiality, trust, and privacy; personalization and customization; emotional concerns; cultural and religious sensitivity; and recommendations.
Findings: The findings reveal that AI provides accessible, flexible, and cost-effective mental health support, but it struggles with empathy, emotional connection, and handling high-risk cases. However, AI effectiveness varies in different cultural contexts and underserved areas; further, it's not as religiously sensitive.
Conclusion: AI-based mental health counseling services show promise of offering accessibility, convenience, and personalized interactions with some limitations, as AI cannot fully replicate the emotional depth and nuanced empathy of human mental health counselors. The study recommended that AI-based mental health counseling offers potential benefits to individuals, but it needs supervision of human professionals for effective integration in a hybrid model.",2025,"[{'authorId': '2260784759', 'name': 'Fouzia Rehman'}, {'authorId': '2248657178', 'name': 'Shahida Sajjad'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.71016/oms/hn8an983?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.71016/oms/hn8an983, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","aim of the study: in the current era of advanced technology, ai is a widely used tool among the new generation. its further advancements have introduced ai-powered counselors (robot-like chatbots) who provide mental health assistance and support for those needing mental health counseling. the current qualitative study explores the integration of ai in mental health counseling through the perspectives of counselors and students. methodology: using the purposive sampling method, 20 mental health counselors and 20 students were selected to interview them about the effectiveness of ai in the mental health counselling field. data was thematically analyzed with the help of braun and clarke’s (2006) six-step framework, and eight themes were developed, including: user experiences and satisfaction; perceived effectiveness; stigma and acceptance; confidentiality, trust, and privacy; personalization and customization; emotional concerns; cultural and religious sensitivity; and recommendations. findings: the findings reveal that ai provides accessible, flexible, and cost-effective mental health support, but it struggles with empathy, emotional connection, and handling high-risk cases. however, ai effectiveness varies in different cultural contexts and underserved areas; further, it's not as religiously sensitive. conclusion: ai-based mental health counseling services show promise of offering accessibility, convenience, and personalized interactions with some limitations, as ai cannot fully replicate the emotional depth and nuanced empathy of human mental health counselors. the study recommended that ai-based mental health counseling offers potential benefits to individuals, but it needs supervision of human professionals for effective integration in a hybrid model.",
9d18cad809b944292edb4a7540d50fa5f6e64744,Artificial Intelligence in Mental Health,"Chatbots are programmed conversational agents that emulate communication systematically using natural language processing. They can be programmed to assume a range of roles where regular human interaction occurs. Within mental health services, they are not as well represented as in other areas of healthcare, with research suggesting that uptake has been hindered by concerns over the accuracy of the information they provide, undeveloped technology, lack of adherence to an ethical framework, and the unconvincing portrayal of human authenticity. Technological improvements have addressed some of these concerns, and as the resultant solution choice increases, the potential for chatbots within mental health is receiving greater attention. In this chapter, two novel uses for chatbots are showcased. Foxbot, a recovery friend, accessible at the point of need to help mitigate some of the common risk factors to sustaining addiction recovery; and ERIC, a counselling client who allows trainee counsellors to practise their counselling skills without having to enlist an actual client.",2022,"[{'authorId': '119125556', 'name': 'L. Ogilvie'}, {'authorId': '12203367', 'name': 'J. Prescott'}, {'authorId': '49787486', 'name': 'T. Hanley'}, {'authorId': '32723726', 'name': 'J. Carson'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4018/978-1-7998-7991-6.ch013?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4018/978-1-7998-7991-6.ch013, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","chatbots are programmed conversational agents that emulate communication systematically using natural language processing. they can be programmed to assume a range of roles where regular human interaction occurs. within mental health services, they are not as well represented as in other areas of healthcare, with research suggesting that uptake has been hindered by concerns over the accuracy of the information they provide, undeveloped technology, lack of adherence to an ethical framework, and the unconvincing portrayal of human authenticity. technological improvements have addressed some of these concerns, and as the resultant solution choice increases, the potential for chatbots within mental health is receiving greater attention. in this chapter, two novel uses for chatbots are showcased. foxbot, a recovery friend, accessible at the point of need to help mitigate some of the common risk factors to sustaining addiction recovery; and eric, a counselling client who allows trainee counsellors to practise their counselling skills without having to enlist an actual client.",
cd037625ec4083a1ebc84f41fde17ea4dc91d4c7,"""It Listens Better Than My Therapist"": Exploring Social Media Discourse on LLMs as Mental Health Tool","The emergence of generative AI chatbots such as ChatGPT has prompted growing public and academic interest in their role as informal mental health support tools. While early rule-based systems have been around for several years, large language models (LLMs) offer new capabilities in conversational fluency, empathy simulation, and availability. This study explores how users engage with LLMs as mental health tools by analyzing over 10,000 TikTok comments from videos referencing LLMs as mental health tools. Using a self-developed tiered coding schema and supervised classification models, we identify user experiences, attitudes, and recurring themes. Results show that nearly 20% of comments reflect personal use, with these users expressing overwhelmingly positive attitudes. Commonly cited benefits include accessibility, emotional support, and perceived therapeutic value. However, concerns around privacy, generic responses, and the lack of professional oversight remain prominent. It is important to note that the user feedback does not indicate which therapeutic framework, if any, the LLM-generated output aligns with. While the findings underscore the growing relevance of AI in everyday practices, they also highlight the urgent need for clinical and ethical scrutiny in the use of AI for mental health support.",2025,"[{'authorId': '23107750', 'name': 'Anna Haensch'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2504.12337, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the emergence of generative ai chatbots such as chatgpt has prompted growing public and academic interest in their role as informal mental health support tools. while early rule-based systems have been around for several years, large language models (llms) offer new capabilities in conversational fluency, empathy simulation, and availability. this study explores how users engage with llms as mental health tools by analyzing over 10,000 tiktok comments from videos referencing llms as mental health tools. using a self-developed tiered coding schema and supervised classification models, we identify user experiences, attitudes, and recurring themes. results show that nearly 20% of comments reflect personal use, with these users expressing overwhelmingly positive attitudes. commonly cited benefits include accessibility, emotional support, and perceived therapeutic value. however, concerns around privacy, generic responses, and the lack of professional oversight remain prominent. it is important to note that the user feedback does not indicate which therapeutic framework, if any, the llm-generated output aligns with. while the findings underscore the growing relevance of ai in everyday practices, they also highlight the urgent need for clinical and ethical scrutiny in the use of ai for mental health support.",
3f2ab7cb380f31973c60b5313ec7c1b4ac22fad1,Personalized Mental Health Assistance: Integrating Emotion Prediction with GPT-Based Chatbot,"Mental health is a fundamental aspect of overall wellbeing, despite its importance, it remains one of the most neglected issues. By integrating Artificial Intelligence with Natural Language Processing into this domain helps to bridge the gaps and challenges. The proposed methodology provides easier access to mental health support by integrating emotion prediction, using the Bi-LSTM Model, with GPT-based chatbots. This system is designed to analyse user inputs, estimating the likelihood of various emotional states such as Anxiety, Depression, Stress, and Suicidal thoughts. These emotional probabilities are then used to inform and guide the responses generated by the GPT model, ensuring that the interactions are more relevant and supportive. Additionally, our approach focuses on providing personalized mental health care using sentiment analysis and prompt engineering. By understanding and interpreting users' emotional states, the chatbot can dynamically adjust its interactions to better meet the needs of everyone, thus improving the quality of mental health support.",2025,"[{'authorId': '2353269255', 'name': 'Muhammad Kifayathullah'}, {'authorId': '2277526242', 'name': 'Rajeev Sekar'}, {'authorId': '2277663505', 'name': 'Abinaya R'}, {'authorId': '2345377667', 'name': 'Vijayaprabakaran K'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/SCEECS64059.2025.10940203?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SCEECS64059.2025.10940203, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mental health is a fundamental aspect of overall wellbeing, despite its importance, it remains one of the most neglected issues. by integrating artificial intelligence with natural language processing into this domain helps to bridge the gaps and challenges. the proposed methodology provides easier access to mental health support by integrating emotion prediction, using the bi-lstm model, with gpt-based chatbots. this system is designed to analyse user inputs, estimating the likelihood of various emotional states such as anxiety, depression, stress, and suicidal thoughts. these emotional probabilities are then used to inform and guide the responses generated by the gpt model, ensuring that the interactions are more relevant and supportive. additionally, our approach focuses on providing personalized mental health care using sentiment analysis and prompt engineering. by understanding and interpreting users' emotional states, the chatbot can dynamically adjust its interactions to better meet the needs of everyone, thus improving the quality of mental health support.",
f3a3b4d007febb91754c5d391ecef133ddbed247,Development of a Comprehensive Evaluation Scale for LLM-Powered Counseling Chatbots (CES-LCC) Using the eDelphi Method,"Background/Objectives: With advancements in Large Language Models (LLMs), counseling chatbots are becoming essential tools for delivering scalable and accessible mental health support. Traditional evaluation scales, however, fail to adequately capture the sophisticated capabilities of these systems, such as personalized interactions, empathetic responses, and memory retention. This study aims to design a robust and comprehensive evaluation scale, the Comprehensive Evaluation Scale for LLM-Powered Counseling Chatbots (CES-LCC), using the eDelphi method to address this gap. Methods: A panel of 16 experts in psychology, artificial intelligence, human-computer interaction, and digital therapeutics participated in two iterative eDelphi rounds. The process focused on refining dimensions and items based on qualitative and quantitative feedback. Initial validation, conducted after assembling the final version of the scale, involved 49 participants using the CES-LCC to evaluate an LLM-powered chatbot delivering Self-Help Plus (SH+), an Acceptance and Commitment Therapy-based intervention for stress management. Results: The final version of the CES-LCC features 27 items grouped into nine dimensions: Understanding Requests, Providing Helpful Information, Clarity and Relevance of Responses, Language Quality, Trust, Emotional Support, Guidance and Direction, Memory, and Overall Satisfaction. Initial real-world validation revealed high internal consistency (Cronbach’s alpha = 0.94), although minor adjustments are required for specific dimensions, such as Clarity and Relevance of Responses. Conclusions: The CES-LCC fills a critical gap in the evaluation of LLM-powered counseling chatbots, offering a standardized tool for assessing their multifaceted capabilities. While preliminary results are promising, further research is needed to validate the scale across diverse populations and settings.",2025,"[{'authorId': '2129074011', 'name': 'Marco Bolpagni'}, {'authorId': '2256151847', 'name': 'Silvia Gabrielli'}]","{'url': 'https://doi.org/10.3390/informatics12010033', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/informatics12010033?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/informatics12010033, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background/objectives: with advancements in large language models (llms), counseling chatbots are becoming essential tools for delivering scalable and accessible mental health support. traditional evaluation scales, however, fail to adequately capture the sophisticated capabilities of these systems, such as personalized interactions, empathetic responses, and memory retention. this study aims to design a robust and comprehensive evaluation scale, the comprehensive evaluation scale for llm-powered counseling chatbots (ces-lcc), using the edelphi method to address this gap. methods: a panel of 16 experts in psychology, artificial intelligence, human-computer interaction, and digital therapeutics participated in two iterative edelphi rounds. the process focused on refining dimensions and items based on qualitative and quantitative feedback. initial validation, conducted after assembling the final version of the scale, involved 49 participants using the ces-lcc to evaluate an llm-powered chatbot delivering self-help plus (sh+), an acceptance and commitment therapy-based intervention for stress management. results: the final version of the ces-lcc features 27 items grouped into nine dimensions: understanding requests, providing helpful information, clarity and relevance of responses, language quality, trust, emotional support, guidance and direction, memory, and overall satisfaction. initial real-world validation revealed high internal consistency (cronbach’s alpha = 0.94), although minor adjustments are required for specific dimensions, such as clarity and relevance of responses. conclusions: the ces-lcc fills a critical gap in the evaluation of llm-powered counseling chatbots, offering a standardized tool for assessing their multifaceted capabilities. while preliminary results are promising, further research is needed to validate the scale across diverse populations and settings.",https://doi.org/10.3390/informatics12010033
203cc12258243c75117e24da8e2923f1db35ba17,A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education,"Cyberbullying harms teenagers’ mental health, and teaching them upstanding intervention is crucial. Wizard-of-Oz studies show chatbots can scale up personalized and interactive cyberbullying education, but implementing such chatbots is a challenging and delicate task. We created a no-code chatbot design tool for K-12 teachers. Using large language models and prompt chaining, our tool allows teachers to prototype bespoke dialogue flows and chatbot utterances. In offering this tool, we explore teachers’ distinctive needs when designing chatbots to assist their teaching, and how chatbot design tools might better support them. Our findings reveal that teachers welcome the tool enthusiastically. Moreover, they see themselves as playwrights guiding both the students’ and the chatbot’s behaviors, while allowing for some improvisation. Their goal is to enable students to rehearse both desirable and undesirable reactions to cyberbullying in a safe environment. We discuss the design opportunities LLM-Chains offer for empowering teachers and the research opportunities this work opens up.",2024,"[{'authorId': '51133383', 'name': 'Michael A. Hedderich'}, {'authorId': '2238003908', 'name': 'Natalie N. Bazarova'}, {'authorId': '2287772244', 'name': 'Wenting Zou'}, {'authorId': '2287837254', 'name': 'Ryun Shim'}, {'authorId': '2288044786', 'name': 'Xinda Ma'}, {'authorId': '2269123794', 'name': 'Qian Yang'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3613904.3642379', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2402.17456, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cyberbullying harms teenagers’ mental health, and teaching them upstanding intervention is crucial. wizard-of-oz studies show chatbots can scale up personalized and interactive cyberbullying education, but implementing such chatbots is a challenging and delicate task. we created a no-code chatbot design tool for k-12 teachers. using large language models and prompt chaining, our tool allows teachers to prototype bespoke dialogue flows and chatbot utterances. in offering this tool, we explore teachers’ distinctive needs when designing chatbots to assist their teaching, and how chatbot design tools might better support them. our findings reveal that teachers welcome the tool enthusiastically. moreover, they see themselves as playwrights guiding both the students’ and the chatbot’s behaviors, while allowing for some improvisation. their goal is to enable students to rehearse both desirable and undesirable reactions to cyberbullying in a safe environment. we discuss the design opportunities llm-chains offer for empowering teachers and the research opportunities this work opens up.",https://dl.acm.org/doi/pdf/10.1145/3613904.3642379
2aaf5dd29a4799a5c580f69298fac7887f387076,Psychological Assistant Bot Using Artificial Intelligence to Improve Individuals' Mental Health,"The ignorance of mental health has caused many lives. But there is no awareness among the peoplebecause most of the people of our country do not treat mental health issues as equally they treat the physicalissues and disagree to consult with any psychologist or spend money for psychological issues. The proposedidea is to create a psychological assistant bot using Artificial Intelligence based on supervised learning methodthat can diagnose the disease and provide basic instructions before consulting a doctor. To reduce thehealthcare costs and improve accessibility to psychological knowledge the Psychological Assistant Bot (PAB)is built. I have tried to build a prototype of a system that will take text input and give an output afterprocessing. Chabot is computer programs that mimic human conversation to interact with users through avariety of messaging channels. Chabot have also been employed for research and clinical support in everysector - domain. In the field of psychology, chatbots have been applied to informative research where surveyor interview data collection are substituted with chatbots that can interact with the subjects in web messagingapps in a psychological setting. This paper examines the design and development of a Chabot for a psychologyresearch study. The stakeholders, functionality, perspectives and technical challenges are presented anddiscussed. I apply a quality of experience framework to explore the factors that impact stakeholders andinfluence design priories.",2020,"[{'authorId': '2125624220', 'name': 'Shomoita Jahid Mitin'}]","{'url': 'https://osf.io/ewm82/download', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.31234/osf.io/ewm82?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.31234/osf.io/ewm82, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the ignorance of mental health has caused many lives. but there is no awareness among the peoplebecause most of the people of our country do not treat mental health issues as equally they treat the physicalissues and disagree to consult with any psychologist or spend money for psychological issues. the proposedidea is to create a psychological assistant bot using artificial intelligence based on supervised learning methodthat can diagnose the disease and provide basic instructions before consulting a doctor. to reduce thehealthcare costs and improve accessibility to psychological knowledge the psychological assistant bot (pab)is built. i have tried to build a prototype of a system that will take text input and give an output afterprocessing. chabot is computer programs that mimic human conversation to interact with users through avariety of messaging channels. chabot have also been employed for research and clinical support in everysector - domain. in the field of psychology, chatbots have been applied to informative research where surveyor interview data collection are substituted with chatbots that can interact with the subjects in web messagingapps in a psychological setting. this paper examines the design and development of a chabot for a psychologyresearch study. the stakeholders, functionality, perspectives and technical challenges are presented anddiscussed. i apply a quality of experience framework to explore the factors that impact stakeholders andinfluence design priories.",https://osf.io/ewm82/download
34add2d1b7ca7fb5f6212552f25e86899f5141bf,A Comprehensive Study on Mental Illness Through Speech and EEG Using Artificial Intelligence,"  
A typical mental ailment is depression that considerably harms an individual's everyday activities as well as their mental health. In light of the fact that mental health is one of the biggest problems facing society, researchers have been looking into several strategies for efficiently identifying depression. Mental illness can now be identified through speech analysis thanks to modern artificial intelligence. The speech aids in classifying a patient's mental health status, which could benefit their new study. For the purpose of identifying depression or any other emotion or mood in an individual, a number of past studies based on machine learning and artificial intelligence are being studied. The study also examines the effectiveness of facial expression, photos, emotional chatbots, and texts in identifying a person's emotions. Naive-Bayes, Support Vector Machines (SVM), Linear Support Vectors, Logistic Regression, etc. are ML approaches from text processing. Artificial Neural Network (ANN) is a sort of artificial intelligence method used to extract information from photos and classify them in order to recognise emotions from facial expressions.",2024,"[{'authorId': '2290330967', 'name': 'Sanjana Bhat'}, {'authorId': '2210899339', 'name': 'Reeja S R'}]","{'url': 'https://publications.eai.eu/index.php/phat/article/download/5328/2955', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4108/eetpht.10.5328?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4108/eetpht.10.5328, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a typical mental ailment is depression that considerably harms an individual's everyday activities as well as their mental health. in light of the fact that mental health is one of the biggest problems facing society, researchers have been looking into several strategies for efficiently identifying depression. mental illness can now be identified through speech analysis thanks to modern artificial intelligence. the speech aids in classifying a patient's mental health status, which could benefit their new study. for the purpose of identifying depression or any other emotion or mood in an individual, a number of past studies based on machine learning and artificial intelligence are being studied. the study also examines the effectiveness of facial expression, photos, emotional chatbots, and texts in identifying a person's emotions. naive-bayes, support vector machines (svm), linear support vectors, logistic regression, etc. are ml approaches from text processing. artificial neural network (ann) is a sort of artificial intelligence method used to extract information from photos and classify them in order to recognise emotions from facial expressions.",https://publications.eai.eu/index.php/phat/article/download/5328/2955
2bf3cb9a60a37612f96de3f276a9062c84856eee,"Chatbots in Cancer Applications, Advantages and Disadvantages: All that Glitters Is Not Gold","The emergence of digitalization and artificial intelligence has had a profound impact on society, especially in the field of medicine. Digital health is now a reality, with an increasing number of people using chatbots for prognostic or diagnostic purposes, therapeutic planning, and monitoring, as well as for nutritional and mental health support. Initially designed for various purposes, chatbots have demonstrated significant advantages in the medical field, as indicated by multiple sources. However, there are conflicting views in the current literature, with some sources highlighting their drawbacks and limitations, particularly in their use in oncology. This state-of-the-art review article seeks to present both the benefits and the drawbacks of chatbots in the context of medicine and cancer, while also addressing the challenges in their implementation, offering expert insights on the subject.",2024,"[{'authorId': '2260948164', 'name': 'G. Goumas'}, {'authorId': '2317553942', 'name': 'T. Dardavesis'}, {'authorId': '2317552668', 'name': 'K. Syrigos'}, {'authorId': '13482956', 'name': 'N. Syrigos'}, {'authorId': '2282436201', 'name': 'E. Simou'}]","{'url': 'https://doi.org/10.3390/jpm14080877', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11355580, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the emergence of digitalization and artificial intelligence has had a profound impact on society, especially in the field of medicine. digital health is now a reality, with an increasing number of people using chatbots for prognostic or diagnostic purposes, therapeutic planning, and monitoring, as well as for nutritional and mental health support. initially designed for various purposes, chatbots have demonstrated significant advantages in the medical field, as indicated by multiple sources. however, there are conflicting views in the current literature, with some sources highlighting their drawbacks and limitations, particularly in their use in oncology. this state-of-the-art review article seeks to present both the benefits and the drawbacks of chatbots in the context of medicine and cancer, while also addressing the challenges in their implementation, offering expert insights on the subject.",https://doi.org/10.3390/jpm14080877
e8c70d0f699cf5b45402a5d30412bc21221fa437,Development process of artificial intelligence based chatbot to support and promote mental wellbeing in sparsely populated areas of five European countries,"Introduction In many countries, people face problems regarding access to care, 24/7 support and evidence-based support. Digital interventions and services, such as chatbots, can be one option to tackle these challenges. There is a lack knowledge regarding how mental health chatbots are developed and how to ensure that there is collaboration between mental health and digital technology experts and users. Objectives This presentation describes the phases of the development for the ChatPal mental health and wellbeing chatbot. Methods Development process was conducted in five and with four different languages. First, using an electronic survey for mental health professionals (n =190) we screened how familiar they are with chatbots and how they evaluated their potential. Second, university students and staff, mental health professionals and service users (n=78) participated in workshops to design the chatbot content. Finally, the content and scripts of chatbot were written in multi-professional and multi-national collaboration. Results ChatPal is based on the PERMAH model of positive psychology and on the idea that we all have mental health which needs boosting and support from time to time. ChatPal includes relevant mental health information, exercises, mood diaries and simple monitoring and self-care tools. Based on preliminary evaluations, the ChatPal chatbot offers an option to offer support in areas where other mental health services are lacking or are insufficient. Conclusions ChatPal is already freely available in application stores and first scientific trials are have started. Preliminary results of 4-week and subsequent 12-week in-the-wild trials will be in place at the time of EPA 2022 conference. Disclosure No significant relationships.",2022,"[{'authorId': '2102413265', 'name': 'L. Kuosmanen'}, {'authorId': '2079705743', 'name': 'A. Vartiainen'}, {'authorId': '2085277907', 'name': 'H. Nieminen'}, {'authorId': '5848571', 'name': 'C. Kostenius'}, {'authorId': '115019872', 'name': 'R. Bond'}, {'authorId': '1789013', 'name': 'M. Mulvenna'}, {'authorId': '146417331', 'name': 'C. Potts'}, {'authorId': '3819131', 'name': 'E. Ennis'}, {'authorId': '145649656', 'name': 'M. Malcolm'}, {'authorId': '3049346', 'name': 'A. Vakaloudis'}, {'authorId': '2127603745', 'name': 'B. Cahill'}, {'authorId': '2285346015', 'name': 'I. Dhanapala'}]","{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/65FB21F704ECC9BF499D431D65059BCB/S0924933822004461a.pdf/div-class-title-development-process-of-artificial-intelligence-based-chatbot-to-support-and-promote-mental-wellbeing-in-sparsely-populated-areas-of-five-european-countries-div.pdf', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9562391, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","introduction in many countries, people face problems regarding access to care, 24/7 support and evidence-based support. digital interventions and services, such as chatbots, can be one option to tackle these challenges. there is a lack knowledge regarding how mental health chatbots are developed and how to ensure that there is collaboration between mental health and digital technology experts and users. objectives this presentation describes the phases of the development for the chatpal mental health and wellbeing chatbot. methods development process was conducted in five and with four different languages. first, using an electronic survey for mental health professionals (n =190) we screened how familiar they are with chatbots and how they evaluated their potential. second, university students and staff, mental health professionals and service users (n=78) participated in workshops to design the chatbot content. finally, the content and scripts of chatbot were written in multi-professional and multi-national collaboration. results chatpal is based on the permah model of positive psychology and on the idea that we all have mental health which needs boosting and support from time to time. chatpal includes relevant mental health information, exercises, mood diaries and simple monitoring and self-care tools. based on preliminary evaluations, the chatpal chatbot offers an option to offer support in areas where other mental health services are lacking or are insufficient. conclusions chatpal is already freely available in application stores and first scientific trials are have started. preliminary results of 4-week and subsequent 12-week in-the-wild trials will be in place at the time of epa 2022 conference. disclosure no significant relationships.",https://www.cambridge.org/core/services/aop-cambridge-core/content/view/65FB21F704ECC9BF499D431D65059BCB/S0924933822004461a.pdf/div-class-title-development-process-of-artificial-intelligence-based-chatbot-to-support-and-promote-mental-wellbeing-in-sparsely-populated-areas-of-five-european-countries-div.pdf
4a44c60466f697fb94c45434a3346f9593c52ac2,More Than Just a Pretty Face? Nudging and Bias in Chatbots,"T he sudden and shocking appearance of ChatGPT (OpenAI)—able to write scientific articles, pass medical licensing examinations, fetch CPT (Current Procedural Terminology) codes, and develop differential diagnoses (1, 2)—raises immediate questions about how health systems will use conversational artificial intelligence, or chatbots, in patient-facing contexts. ChatGPT may catalyze expansion of this technology’s uses in patient communication. Chatbots are already using other natural language processing methods to check COVID-19 symptoms, manage chronic diseases, support mental health treatment, and deliver genetic test results (3). Chatbots promise to support medical education, research, and practice but not without peril. They raise ethical issues around safety, privacy, data ownership, trust, and fairness (3). Sometimes overlooked is what a chatbot looks like—its avatar. Current chatbot avatars vary from faceless health system logos to cartoon characters or human-like caricatures. Chatbots could one day be digitized versions of a patient’s physician, with that physician’s likeness and voice. Far from an innocuous design decision, chatbot avatars raise novel ethical questions about nudging and bias.",2023,"[{'authorId': '2218877429', 'name': 'Marlee Akerson'}, {'authorId': '2218877427', 'name': 'Matt Andazola'}, {'authorId': '2084591123', 'name': 'Annie Moore'}, {'authorId': '48706760', 'name': 'M. Decamp'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.7326/M23-0877?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7326/M23-0877, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","t he sudden and shocking appearance of chatgpt (openai)—able to write scientific articles, pass medical licensing examinations, fetch cpt (current procedural terminology) codes, and develop differential diagnoses (1, 2)—raises immediate questions about how health systems will use conversational artificial intelligence, or chatbots, in patient-facing contexts. chatgpt may catalyze expansion of this technology’s uses in patient communication. chatbots are already using other natural language processing methods to check covid-19 symptoms, manage chronic diseases, support mental health treatment, and deliver genetic test results (3). chatbots promise to support medical education, research, and practice but not without peril. they raise ethical issues around safety, privacy, data ownership, trust, and fairness (3). sometimes overlooked is what a chatbot looks like—its avatar. current chatbot avatars vary from faceless health system logos to cartoon characters or human-like caricatures. chatbots could one day be digitized versions of a patient’s physician, with that physician’s likeness and voice. far from an innocuous design decision, chatbot avatars raise novel ethical questions about nudging and bias.",
a927eb9987b7059ee5f8bea835a2ce116e8528fd,Komorebi: Enhancing Mental Wellness with Sentiment Analysis and Cognitive Behavior Therapy,"In recent years, the rapid advancements in human and computer interaction have been reshaped by artificial intelligence (AI) and natural language processing (NLP). Chatbots have been among the most prominent use cases of NLP and have provided transformative technological applications which have been integral to our digital landscape. One of the most promising applications of chatbot utilization is in the medical industry, specifically mental health. NLP is at the heart of this AI capability and has revolutionized how chatbots interact with users, allowing the computer to generate, understand, and analyze human language interactions. This research presents the development and evaluation of a GPT-powered mental health chatbot for a mental wellness website with a foundation built on sentiment analysis techniques. The chatbot aims to provide personalized support and leverage evidence-based strategies for coping with and improving mental health issues prescribed using cognitive behavior therapy (CBT) interventions. Through the implementation of a combination of machine learning models and rule-based algorithms, the website features an activities module which categorizes user sentiments into positive, neutral, and negative emotions and prescribes a personalized CBT intervention to users. The system fosters an empathetic and supportive conversational environment between users and the virtual assistant to build rapport and trust. The effectiveness of this chatbot is measured through a mixed-methods approach that includes functional testing, user feedback, and ethical evaluation.",2024,"[{'authorId': '2337343508', 'name': 'Priyanka Lee'}, {'authorId': '35158410', 'name': 'Kanika Sood'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/iceccme62383.2024.10797013?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/iceccme62383.2024.10797013, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent years, the rapid advancements in human and computer interaction have been reshaped by artificial intelligence (ai) and natural language processing (nlp). chatbots have been among the most prominent use cases of nlp and have provided transformative technological applications which have been integral to our digital landscape. one of the most promising applications of chatbot utilization is in the medical industry, specifically mental health. nlp is at the heart of this ai capability and has revolutionized how chatbots interact with users, allowing the computer to generate, understand, and analyze human language interactions. this research presents the development and evaluation of a gpt-powered mental health chatbot for a mental wellness website with a foundation built on sentiment analysis techniques. the chatbot aims to provide personalized support and leverage evidence-based strategies for coping with and improving mental health issues prescribed using cognitive behavior therapy (cbt) interventions. through the implementation of a combination of machine learning models and rule-based algorithms, the website features an activities module which categorizes user sentiments into positive, neutral, and negative emotions and prescribes a personalized cbt intervention to users. the system fosters an empathetic and supportive conversational environment between users and the virtual assistant to build rapport and trust. the effectiveness of this chatbot is measured through a mixed-methods approach that includes functional testing, user feedback, and ethical evaluation.",
2bf9f66223af923723122dec9926c23010f79e90,HEALTH CARE MEDIBOT IN MEDICAL FIELD USING MACHINE LEARNING,"Health is considered an important part of human health, including physical, mental and social health, and plays an important role in our lives. Hospitals are the most common way for patients to receive physical examinations ,diagnosis , treatment recommendations. However, it Is very difficult to take every minor health problem to a doctor and get approval from the doctor. The idea is to use artificial intelligence to create a “medical chatbot” that can diagnose disease and provide useful information about the disease before going to the doctor. Chatbots are computers that use natural language to interact with users. The main goal of the project is to create a Medibot that can assist doctors and patients with tasks such as symptom assessment, diagnostic support, treatment recommendations and publication of medical information. Medibot will use machine learning algorithms that learn from big data of medical conversations to understand users' questions and ideas and respond accordingly. medical software or existing platforms and perform rigorous testing to ensure accuracy and reliability. A continuous evaluation and improvement process will be used to improve Medibot's performance over time. Through this project, the team is focusing on the development of AI driven solutions in healthcare while solving real-world problems faced by doctors and patients. Deploying Medibot has the potential to improve clinical processes, improve access to medical information, and ultimately improve patient care outcomes Key Words:: Medibot, Rasa framework, Health, Artificial intelligence, Natural language processing, Queries, Deployment of ML algorithms, intent, entity",2024,"[{'authorId': '2298920233', 'name': 'Thattikota Devi Prasanna'}]","{'url': 'https://ijsrem.com/download/health-care-medibot-in-medical-field-using-machine-learning/?wpdmdl=31646&refresh=665c0cb19905a1717308593', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.55041/ijsrem32307?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55041/ijsrem32307, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","health is considered an important part of human health, including physical, mental and social health, and plays an important role in our lives. hospitals are the most common way for patients to receive physical examinations ,diagnosis , treatment recommendations. however, it is very difficult to take every minor health problem to a doctor and get approval from the doctor. the idea is to use artificial intelligence to create a “medical chatbot” that can diagnose disease and provide useful information about the disease before going to the doctor. chatbots are computers that use natural language to interact with users. the main goal of the project is to create a medibot that can assist doctors and patients with tasks such as symptom assessment, diagnostic support, treatment recommendations and publication of medical information. medibot will use machine learning algorithms that learn from big data of medical conversations to understand users' questions and ideas and respond accordingly. medical software or existing platforms and perform rigorous testing to ensure accuracy and reliability. a continuous evaluation and improvement process will be used to improve medibot's performance over time. through this project, the team is focusing on the development of ai driven solutions in healthcare while solving real-world problems faced by doctors and patients. deploying medibot has the potential to improve clinical processes, improve access to medical information, and ultimately improve patient care outcomes key words:: medibot, rasa framework, health, artificial intelligence, natural language processing, queries, deployment of ml algorithms, intent, entity",https://ijsrem.com/download/health-care-medibot-in-medical-field-using-machine-learning/?wpdmdl=31646&refresh=665c0cb19905a1717308593
3b09a37c82d96afe0634c604664263bd50c141e0,"GUIDANCE FOR GENERATIVE AI IN EDUCATION AND RESEARCH"" FOR TEACHERS","From the book title is ""Guidance for Generative AI in Education and Research"" for teachers, or this book serves as part of the guidelines for using Generative AI (GenAI) in the fields of education and research. This book was written by W. Holmes and F. Miao in 2023. This book addresses the rapid emergence of publicly available Generative AI tools, with the release of new versions outpacing the establishment of national regulatory frameworks. The lack of national regulations on GenAI in most countries raises concerns about user data privacy and leaves educational institutions unprotected and largely unprepared to scrutinize these tools. UNESCO has issued the first global guidelines on GenAI in education, aiming to support countries in taking immediate action, formulating long-term policies, and developing human capacity to ensure that people can effectively use AI and enhance their work with Generative AI.",2024,"[{'authorId': '9301133', 'name': 'S. Boonlue'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.55003/jie.23202?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55003/jie.23202, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","from the book title is ""guidance for generative ai in education and research"" for teachers, or this book serves as part of the guidelines for using generative ai (genai) in the fields of education and research. this book was written by w. holmes and f. miao in 2023. this book addresses the rapid emergence of publicly available generative ai tools, with the release of new versions outpacing the establishment of national regulatory frameworks. the lack of national regulations on genai in most countries raises concerns about user data privacy and leaves educational institutions unprotected and largely unprepared to scrutinize these tools. unesco has issued the first global guidelines on genai in education, aiming to support countries in taking immediate action, formulating long-term policies, and developing human capacity to ensure that people can effectively use ai and enhance their work with generative ai.",
f75f924f53082736b5ecd85b7198f7d79e42e4ae,Unlocking the Power of ChatGPT: A Framework for Applying Generative AI in Education,"Purpose Artificial intelligence (AI) chatbots, such as ChatGPT and GPT-4, developed by OpenAI, have the potential to revolutionize education. This study explores the potential benefits and challenges of using ChatGPT in education (or “educative AI”). Design/Approach/Methods This paper proposes a theoretical framework called “IDEE” for educative AI such as using ChatGPT and other generative AI in education, which includes identifying the desired outcomes, determining the appropriate level of automation, ensuring ethical considerations, and evaluating effectiveness. Findings The benefits of using ChatGPT in education or more generally, educative AI, include a more personalized and efficient learning experience for students as well as easier and faster feedback for teachers. However, challenges such as the untested effectiveness of the technology, limitations in the quality of data, and ethical and safety concerns must also be considered. Originality/Value This study explored the opportunities and challenges of using ChatGPT in education within the proposed theoretical framework.",2023,"[{'authorId': '2215060241', 'name': 'Jiahong Su (苏嘉红)'}, {'authorId': '2161451413', 'name': 'Weipeng Yang (杨伟鹏)'}]","{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/20965311231168423', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/20965311231168423?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/20965311231168423, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose artificial intelligence (ai) chatbots, such as chatgpt and gpt-4, developed by openai, have the potential to revolutionize education. this study explores the potential benefits and challenges of using chatgpt in education (or “educative ai”). design/approach/methods this paper proposes a theoretical framework called “idee” for educative ai such as using chatgpt and other generative ai in education, which includes identifying the desired outcomes, determining the appropriate level of automation, ensuring ethical considerations, and evaluating effectiveness. findings the benefits of using chatgpt in education or more generally, educative ai, include a more personalized and efficient learning experience for students as well as easier and faster feedback for teachers. however, challenges such as the untested effectiveness of the technology, limitations in the quality of data, and ethical and safety concerns must also be considered. originality/value this study explored the opportunities and challenges of using chatgpt in education within the proposed theoretical framework.",https://journals.sagepub.com/doi/pdf/10.1177/20965311231168423
b11ce8ec43b1fffa5606a253e2b4fca3912bb880,"Generative AI in Education: A Study of Educators' Awareness, Sentiments, and Influencing Factors","This research full paper delves into university in-structors' experiences and attitudes toward AI language models, filling a gap in the literature by analyzing educators' perspectives on AI's role in the classroom and its potential impacts on teaching and learning. The rapid advancement of artificial intelligence (AI) and the expanding integration of large language models (LLMs) have ignited a debate about their application in education. The objective of this research is to investigate the level of awareness, overall sentiment towards adoption, and the factors influencing these attitudes for LLMs and generative AI-based tools in higher education. Data was collected through a survey using a Likert scale, which was complemented by follow-up interviews to gain a more nuanced understanding of the instructors' viewpoints. The collected data was processed using statistical and thematic analysis techniques. Our findings reveal that educators are increasingly aware of and generally positive towards these tools. We find no correlation between teaching style and attitude toward generative AI. Finally, while CS educators show far more confidence in their technical understanding of generative AI tools and more positivity towards them than educators in other fields, they show no more confidence in their ability to detect AI-generated work.",2024,"[{'authorId': '116552083', 'name': 'Aashish Ghimire'}, {'authorId': '2309177890', 'name': 'James Prather'}, {'authorId': '2293303152', 'name': 'John Edwards'}]","{'url': 'https://arxiv.org/pdf/2403.15586', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2403.15586, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this research full paper delves into university in-structors' experiences and attitudes toward ai language models, filling a gap in the literature by analyzing educators' perspectives on ai's role in the classroom and its potential impacts on teaching and learning. the rapid advancement of artificial intelligence (ai) and the expanding integration of large language models (llms) have ignited a debate about their application in education. the objective of this research is to investigate the level of awareness, overall sentiment towards adoption, and the factors influencing these attitudes for llms and generative ai-based tools in higher education. data was collected through a survey using a likert scale, which was complemented by follow-up interviews to gain a more nuanced understanding of the instructors' viewpoints. the collected data was processed using statistical and thematic analysis techniques. our findings reveal that educators are increasingly aware of and generally positive towards these tools. we find no correlation between teaching style and attitude toward generative ai. finally, while cs educators show far more confidence in their technical understanding of generative ai tools and more positivity towards them than educators in other fields, they show no more confidence in their ability to detect ai-generated work.",https://arxiv.org/pdf/2403.15586
de3c9e140af2be93b61d0203a1d182e343e52cb1,A bibliometric analysis of generative AI in education: current status and development,"ABSTRACT The rapid advancement of generative AI technology offers new opportunities for the innovation and transformation of education. However, this also brings forth risks and challenges, including the potential to exacerbate educational inequality and integrity. This study aims to address the extensive controversies surrounding the application of generative AI technology in education by providing an objective and comprehensive understanding of its current state, development in educational contexts. Using the CiteSpace and VOSviewer software, we conducted visual analyses of relevant literature from the Web of Science core collection pertaining to the application of generative AI in education.Subsequently, we identified productive journals, productive articles, collaboration patterns, article hotspots, and prevalent topics in this field.This study will facilitate the promotion of in-depth research and practical implementation of AI in education.",2024,"[{'authorId': '2276428746', 'name': 'Jun Liu'}, {'authorId': '2213516368', 'name': 'Cong Wang'}, {'authorId': '2276417210', 'name': 'Zile Liu'}, {'authorId': '2282244499', 'name': 'Minghui Gao'}, {'authorId': '2276448192', 'name': 'Yanhua Xu'}, {'authorId': '2282097484', 'name': 'Jiayu Chen'}, {'authorId': '2282098825', 'name': 'Yichun Cheng'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/02188791.2024.2305170?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/02188791.2024.2305170, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the rapid advancement of generative ai technology offers new opportunities for the innovation and transformation of education. however, this also brings forth risks and challenges, including the potential to exacerbate educational inequality and integrity. this study aims to address the extensive controversies surrounding the application of generative ai technology in education by providing an objective and comprehensive understanding of its current state, development in educational contexts. using the citespace and vosviewer software, we conducted visual analyses of relevant literature from the web of science core collection pertaining to the application of generative ai in education.subsequently, we identified productive journals, productive articles, collaboration patterns, article hotspots, and prevalent topics in this field.this study will facilitate the promotion of in-depth research and practical implementation of ai in education.",
38c5f3332f54d6876b74427482508bbf39b8fa33,Generative AI in education and research: A systematic mapping review,"Given the potential applications of generative AI (GenAI) in education and its rising interest in research, this systematic review mapped the thematic landscape of 407 publications indexed in the Web of Science, ScienceDirect and Scopus. Using EPPI Reviewer, publication type, educational level, disciplines, research areas and applications of GenAI were extracted. Eight discursive themes were identified, predominantly focused on ‘application, impact and potential’, ‘ethical implication and risks’, ‘perspectives and experiences’, ‘institutional and individual adoption’, and ‘performance and intelligence’. GenAI was conceptualised as a tool for ‘pedagogical enhancement’, ‘specialised training and practices’, ‘writing assistance and productivity’, ‘professional skills and development’, and as an ‘interdisciplinary learning tool’. Key gaps highlighted include a paucity of research and discussions on GenAI in K‐12 education; a limited exploration of GenAI's impact using experimental procedures; and a limited exploration of the potential and ethical concerns of GenAI from the lens of cultural dimensions. Promising opportunities for future research are highlighted.",2024,"[{'authorId': '2125901210', 'name': 'Abdullahi Yusuf'}, {'authorId': '79587760', 'name': 'Nasrin Pervin'}, {'authorId': '2094405146', 'name': 'Marcos Román‐González'}, {'authorId': '69545777', 'name': 'Norah Md Noor'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/rev3.3489?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/rev3.3489, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","given the potential applications of generative ai (genai) in education and its rising interest in research, this systematic review mapped the thematic landscape of 407 publications indexed in the web of science, sciencedirect and scopus. using eppi reviewer, publication type, educational level, disciplines, research areas and applications of genai were extracted. eight discursive themes were identified, predominantly focused on ‘application, impact and potential’, ‘ethical implication and risks’, ‘perspectives and experiences’, ‘institutional and individual adoption’, and ‘performance and intelligence’. genai was conceptualised as a tool for ‘pedagogical enhancement’, ‘specialised training and practices’, ‘writing assistance and productivity’, ‘professional skills and development’, and as an ‘interdisciplinary learning tool’. key gaps highlighted include a paucity of research and discussions on genai in k‐12 education; a limited exploration of genai's impact using experimental procedures; and a limited exploration of the potential and ethical concerns of genai from the lens of cultural dimensions. promising opportunities for future research are highlighted.",
04a97c2be21047b8e152e3b9066f17f3191e27b1,"Generative AI in Education: Pedagogical, Theoretical, and Methodological Perspectives","Recently, ChatGPT, a cutting-edge large language model, has emerged as a powerful Generative Artificial Intelligence (GenAI) tool with the capacity to influence education. ChatGPT provides ample opportunities for learners, researchers, educators, and practitioners to achieve the intended learning outcomes in various disciplines. This special issue examines the diverse applications and implications of GenAI tools including ChatGPT in education, highlighting their potential to enhance teaching and learning across various contexts. Key findings from seventeen studies collected in this special issue demonstrate that GenAI tools can significantly improve educational outcomes by providing personalized feedback, facilitating language learning, and supporting both qualitative and quantitative research methodologies. The findings emphasize GenAI’s capacity to increase learner engagement and motivation, yet also underscore the need for robust ethical guidelines and human oversight due to potential issues with privacy, bias, and accuracy. This special issue also highlights the challenges GenAI faces, such as limitations in contextual understanding and its impact on critical thinking skills. In addition, it provides a foundational framework for exploring effective and responsible GenAI integration, aiming to enrich educational experiences. We conclude that future research should focus on the longitudinal effects of GenAI tools on learning outcomes, developing ethical frameworks for their use, and ensuring their adaptability to diverse learner populations to promote inclusive educational practices.",2024,"[{'authorId': '1755438', 'name': 'O. Noroozi'}, {'authorId': '2304498020', 'name': 'Saba Soleimani'}, {'authorId': '71301279', 'name': 'Mohammadreza Farrokhnia'}, {'authorId': '118733794', 'name': 'S. K. Banihashem'}]","{'url': 'https://ijte.net/index.php/ijte/article/download/845/pdf', 'status': 'GOLD', 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.46328/ijte.845?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.46328/ijte.845, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recently, chatgpt, a cutting-edge large language model, has emerged as a powerful generative artificial intelligence (genai) tool with the capacity to influence education. chatgpt provides ample opportunities for learners, researchers, educators, and practitioners to achieve the intended learning outcomes in various disciplines. this special issue examines the diverse applications and implications of genai tools including chatgpt in education, highlighting their potential to enhance teaching and learning across various contexts. key findings from seventeen studies collected in this special issue demonstrate that genai tools can significantly improve educational outcomes by providing personalized feedback, facilitating language learning, and supporting both qualitative and quantitative research methodologies. the findings emphasize genai’s capacity to increase learner engagement and motivation, yet also underscore the need for robust ethical guidelines and human oversight due to potential issues with privacy, bias, and accuracy. this special issue also highlights the challenges genai faces, such as limitations in contextual understanding and its impact on critical thinking skills. in addition, it provides a foundational framework for exploring effective and responsible genai integration, aiming to enrich educational experiences. we conclude that future research should focus on the longitudinal effects of genai tools on learning outcomes, developing ethical frameworks for their use, and ensuring their adaptability to diverse learner populations to promote inclusive educational practices.",https://ijte.net/index.php/ijte/article/download/845/pdf
d4eb4adfa36b5dd0480793f1d0a89a43a8847661,The promise and challenges of generative AI in education,"Generative artificial intelligence (GenAI) tools, such as large language models (LLMs), generate natural language and other types of content to perform a wide range of tasks. This represents a significant technological advancement that poses opportunities and challenges to educational research and practice. This commentary brings together contributions from nine experts working in the intersection of learning and technology and presents critical reflections on the opportunities, challenges, and implications related to GenAI technologies in the context of education. In the commentary, it is acknowledged that GenAI’s capabilities can enhance some teaching and learning practices, such as learning design, regulation of learning, automated content, feedback, and assessment. Nevertheless, we also highlight its limitations, potential disruptions, ethical consequences, and potential misuses. The identified avenues for further research include the development of new insights into the roles human experts can play, strong and continuous evidence, human-centric design of technology, necessary policy, and support and competence mechanisms. Overall, we concur with the general skeptical optimism about the use of GenAI tools such as LLMs in education. Moreover, we highlight the danger of hastily adopting GenAI tools in education without deep consideration of the efficacy, ecosystem-level implications, ethics, and pedagogical soundness of such practices.",2024,"[{'authorId': '2290530633', 'name': 'Michail N. Giannakos'}, {'authorId': '2319298215', 'name': 'Roger Azevedo'}, {'authorId': '2069676493', 'name': 'Peter Brusilovsky'}, {'authorId': '3017153', 'name': 'M. Cukurova'}, {'authorId': '1757326', 'name': 'Y. Dimitriadis'}, {'authorId': '1403055884', 'name': 'D. Hernández‐Leo'}, {'authorId': '2248242831', 'name': 'Sanna Järvelä'}, {'authorId': '1765083', 'name': 'M. Mavrikis'}, {'authorId': '2316801051', 'name': 'Bart Rienties'}]","{'url': 'https://doi.org/10.1080/0144929x.2024.2394886', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/0144929x.2024.2394886?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/0144929x.2024.2394886, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative artificial intelligence (genai) tools, such as large language models (llms), generate natural language and other types of content to perform a wide range of tasks. this represents a significant technological advancement that poses opportunities and challenges to educational research and practice. this commentary brings together contributions from nine experts working in the intersection of learning and technology and presents critical reflections on the opportunities, challenges, and implications related to genai technologies in the context of education. in the commentary, it is acknowledged that genai’s capabilities can enhance some teaching and learning practices, such as learning design, regulation of learning, automated content, feedback, and assessment. nevertheless, we also highlight its limitations, potential disruptions, ethical consequences, and potential misuses. the identified avenues for further research include the development of new insights into the roles human experts can play, strong and continuous evidence, human-centric design of technology, necessary policy, and support and competence mechanisms. overall, we concur with the general skeptical optimism about the use of genai tools such as llms in education. moreover, we highlight the danger of hastily adopting genai tools in education without deep consideration of the efficacy, ecosystem-level implications, ethics, and pedagogical soundness of such practices.",https://doi.org/10.1080/0144929x.2024.2394886
09e94b984ae0593ef8b752344001a6416b4aee1f,"Critical analysis of the technological affordances, challenges and future directions of Generative AI in education: a systematic review","ABSTRACT Generative artificial intelligence has been regarded as a transformative tool. While responsible and ethical applications could bring opportunities to education, their misuse could pose demanding challenges. It is necessary to clarify the technological affordances and challenges in a normative way to lay the foundation for future development. This study addressed the dearth of literature by performing a systematic review, aiming to (i) explore the utility and availability from the technological affordances perspective; (ii) summarize the current challenges in risks prevention; and (iii) propose possible directions for future research and practice. A total of 27 academic articles published in core journals between 2020 and 2023 were analyzed, and the inductive grounded approach was used to categorize the coding schemes. The findings revealed four technological affordances: accessibility, personalization, automation, and interactivity; and five challenges: academic integrity risk, response errors and bias, over-dependence risk, the widening digital divide, and privacy and security. We propose future directions, encourage educational organizations to formulate guidelines for the ethical use of AI in education, call on educators to embrace future trends in AI education instead of shunning its use, and guide students to treat it as a thought aid and reference, rather than relying on it entirely.",2024,"[{'authorId': '2280864885', 'name': 'Nan Wang'}, {'authorId': '2280870632', 'name': 'Xiao Wang'}, {'authorId': '2237406159', 'name': 'Yu-Sheng Su'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/02188791.2024.2305156?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/02188791.2024.2305156, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract generative artificial intelligence has been regarded as a transformative tool. while responsible and ethical applications could bring opportunities to education, their misuse could pose demanding challenges. it is necessary to clarify the technological affordances and challenges in a normative way to lay the foundation for future development. this study addressed the dearth of literature by performing a systematic review, aiming to (i) explore the utility and availability from the technological affordances perspective; (ii) summarize the current challenges in risks prevention; and (iii) propose possible directions for future research and practice. a total of 27 academic articles published in core journals between 2020 and 2023 were analyzed, and the inductive grounded approach was used to categorize the coding schemes. the findings revealed four technological affordances: accessibility, personalization, automation, and interactivity; and five challenges: academic integrity risk, response errors and bias, over-dependence risk, the widening digital divide, and privacy and security. we propose future directions, encourage educational organizations to formulate guidelines for the ethical use of ai in education, call on educators to embrace future trends in ai education instead of shunning its use, and guide students to treat it as a thought aid and reference, rather than relying on it entirely.",
2b049b9daa1a0bac700e344ae0dab02831194cec,Generative AI in Education: Best Practices for Successful Implementation,"Generative artificial intelligence (AI) holds great promise in the field of education, with the potential to automate tasks such as lesson planning, feedback writing, and personalized learning. This study explores the implementation of generative AI in educational settings, examining the benefits and challenges associated with its use. Through a systematic literature review, this paper identifies effective strategies for integrating generative AI in classrooms, focusing on ethical considerations, privacy concerns, and pedagogical goals. The study also presents case studies highlighting successful implementations of generative AI, providing a framework for educators and policymakers to enhance teaching and learning experiences.",2024,"[{'authorId': '1665449647', 'name': 'Rommel Alali'}, {'authorId': '2238286876', 'name': 'Yousef Wardat'}, {'authorId': '2277923780', 'name': 'Khaled Al-Saud'}, {'authorId': '2304610837', 'name': 'Kamal Aldeen Alhayek'}]","{'url': 'https://ijor.co.uk/ijor/article/download/5033/2610', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.61707/pkwb8402?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.61707/pkwb8402, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative artificial intelligence (ai) holds great promise in the field of education, with the potential to automate tasks such as lesson planning, feedback writing, and personalized learning. this study explores the implementation of generative ai in educational settings, examining the benefits and challenges associated with its use. through a systematic literature review, this paper identifies effective strategies for integrating generative ai in classrooms, focusing on ethical considerations, privacy concerns, and pedagogical goals. the study also presents case studies highlighting successful implementations of generative ai, providing a framework for educators and policymakers to enhance teaching and learning experiences.",https://ijor.co.uk/ijor/article/download/5033/2610
c1cb6a46915155cfeecc098607730f0ffc914db3,Integrating Generative AI in Education: How ChatGPT Brings Challenges for Future Learning and Teaching,"ChatGPT, a chatbot based on the Open-AI’s generative pre-trained (GPT) language models, has been hailed as a “24/7 tutor” that has transformed the way people view education in just under six months since its debut. (Jason Pohl, 2023; Kara Manke, 2023) The impact of AI on future learning and teaching has sparked discussions that draw parallels to the debates held over 2,000 years ago by renowned Greek philosophers such as Socrates (469-399 B.C.), Plato (427-347 B.C.), and Aristotle (384-322 B.C.). These ancient thinkers delved into theories pertaining to the acquisition and dissemination of new knowledge. By drawing these historical comparisons, we gain valuable insights into the ongoing discourse surrounding the influence of AI in education. Does Socrates’ dialectic method, in which truth is discovered through discussions with peers, still have a role in the learning process? Could the peer involved in this case be considered a chatbot?",2023,"[{'authorId': '2145048028', 'name': 'Yi Wu'}]","{'url': 'https://www.pioneerpublisher.com/jare/article/download/324/286', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.56397/jare.2023.07.02?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.56397/jare.2023.07.02, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","chatgpt, a chatbot based on the open-ai’s generative pre-trained (gpt) language models, has been hailed as a “24/7 tutor” that has transformed the way people view education in just under six months since its debut. (jason pohl, 2023; kara manke, 2023) the impact of ai on future learning and teaching has sparked discussions that draw parallels to the debates held over 2,000 years ago by renowned greek philosophers such as socrates (469-399 b.c.), plato (427-347 b.c.), and aristotle (384-322 b.c.). these ancient thinkers delved into theories pertaining to the acquisition and dissemination of new knowledge. by drawing these historical comparisons, we gain valuable insights into the ongoing discourse surrounding the influence of ai in education. does socrates’ dialectic method, in which truth is discovered through discussions with peers, still have a role in the learning process? could the peer involved in this case be considered a chatbot?",https://www.pioneerpublisher.com/jare/article/download/324/286
ea077f87effc03e03704c35dc69e11bab48cdca3,Promoting Ethical Use of Generative AI in Education,"Generative artificial intelligence (AI) represents a crucial subset of AI models characterized by their ability to generate new content based on user input, showing vast potential to transform learning and teaching. However, educators have raised ethical concerns, particularly regarding the adverse effect on students' learning if students simply parrot generative AI-generated content without engaging in critical analysis or original thought. Moreover, there exists the potential of generative AI to perpetuate existing biases in training data. This editorial discusses three major concerns in generative AI use in education and proposes questions (on task-AI fit and people-AI fit) and approaches to address the ethical considerations by adopting five principles of AI ethics. The editorial also discusses developing a classroom AI use policy as one governance mechanism for promoting ethical use of AI. As generative AI technology continues to evolve, so must our educational practices. The editorial ends with a call for readers (educators) to collaboratively define the terms of engagement with generative AI in educational settings and to begin this discourse by sharing insights and experiences with promoting ethical use of generative AI.",2024,"[{'authorId': '2283516028', 'name': 'X. Deng'}, {'authorId': '2259963921', 'name': 'K. D. Joshi'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3685235.3685237?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3685235.3685237, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative artificial intelligence (ai) represents a crucial subset of ai models characterized by their ability to generate new content based on user input, showing vast potential to transform learning and teaching. however, educators have raised ethical concerns, particularly regarding the adverse effect on students' learning if students simply parrot generative ai-generated content without engaging in critical analysis or original thought. moreover, there exists the potential of generative ai to perpetuate existing biases in training data. this editorial discusses three major concerns in generative ai use in education and proposes questions (on task-ai fit and people-ai fit) and approaches to address the ethical considerations by adopting five principles of ai ethics. the editorial also discusses developing a classroom ai use policy as one governance mechanism for promoting ethical use of ai. as generative ai technology continues to evolve, so must our educational practices. the editorial ends with a call for readers (educators) to collaboratively define the terms of engagement with generative ai in educational settings and to begin this discourse by sharing insights and experiences with promoting ethical use of generative ai.",
1c8381cb91e59b5418b49401d7173b9e5b2b41c6,The role of generative AI in education: Perceptions of Saudi students,"Purpose: This study aims to provide an analysis of students’ perceptions of the role of generative artificial intelligence (GenAI) tools in education, through five axes: (1) level of knowledge and awareness, (2) level of acceptance and readiness, (3) the role of GenAI in education, (4 (level of awareness of potential concerns and challenges, and (5) The impact of GenAI tools on achieving the sustainable development goals in education.
Materials and methods: The study followed a descriptive quantitative methodology based on surveying through a questionnaire. The sample consisted of 1390 students from 15 Saudi universities.
Results: The students have positive perceptions towards the role of GenAI tools in education, as students have a high level of awareness and acceptance of adopting these tools. In addition, students are highly aware of the role of GenAI tools in improving their understanding of complex concepts, developing skills, improving their self-efficacy, learning outcomes, providing feedback, and making learning meaningful. The results also confirm their general awareness of the concerns and challenges. A relationship exists between students’ perceptions of GenAI and their scientific specializations, as students in computer sciences showed greater awareness regarding concerns and challenges, whereas students in agricultural sciences showed greater awareness of the impact of GenAI tools on achieving sustainable development goals.
Conclusions: The study offers valuable insights on GenAI adoption in higher education, also there is an urgent need to consider developing appropriate use policies, spreading awareness, and creating systems capable of detecting unethical cases.",2024,"[{'authorId': '2078184540', 'name': 'A. Aldossary'}, {'authorId': '2327426421', 'name': 'Alia Abdullah Aljindi'}, {'authorId': '71232025', 'name': 'J. Alamri'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.30935/cedtech/15496?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.30935/cedtech/15496, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose: this study aims to provide an analysis of students’ perceptions of the role of generative artificial intelligence (genai) tools in education, through five axes: (1) level of knowledge and awareness, (2) level of acceptance and readiness, (3) the role of genai in education, (4 (level of awareness of potential concerns and challenges, and (5) the impact of genai tools on achieving the sustainable development goals in education. materials and methods: the study followed a descriptive quantitative methodology based on surveying through a questionnaire. the sample consisted of 1390 students from 15 saudi universities. results: the students have positive perceptions towards the role of genai tools in education, as students have a high level of awareness and acceptance of adopting these tools. in addition, students are highly aware of the role of genai tools in improving their understanding of complex concepts, developing skills, improving their self-efficacy, learning outcomes, providing feedback, and making learning meaningful. the results also confirm their general awareness of the concerns and challenges. a relationship exists between students’ perceptions of genai and their scientific specializations, as students in computer sciences showed greater awareness regarding concerns and challenges, whereas students in agricultural sciences showed greater awareness of the impact of genai tools on achieving sustainable development goals. conclusions: the study offers valuable insights on genai adoption in higher education, also there is an urgent need to consider developing appropriate use policies, spreading awareness, and creating systems capable of detecting unethical cases.",
4ba69e4f0b7e9bbfeee091029f8eeccd2f984d09,Generative AI in education: To embrace it or not？,"Within the first few years of introducing new technology, there is often a lot of excitement and hype surrounding its potential. People tend to overestimate its immediate impact, believing that it will revolutionize various aspects of society and bring about rapid change. However, during this early stage, the technology may still be in its early development phase, and it may face a series of challenges and limitations that could prevent it from reaching its full potential. This pattern can be observed in various technologies throughout history, such as the internet, mobile phones, and others. It is essential to consider this hype cycle when evaluating the potential impact of emerging technologies such as generative AI and to maintain a balanced perspective on their development and adoption. Therefore, universities should actively encourage research on the impact of Generative AI on education, the workforce",2023,"[{'authorId': '2239882314', 'name': 'Samuel Ariyo Okaiyeto'}, {'authorId': '2240228773', 'name': 'Junwen Bai'}, {'authorId': '2240004738', 'name': 'Hongwei Xiao'}]","{'url': 'https://www.ijabe.org/index.php/ijabe/article/download/8486/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.25165/j.ijabe.20231603.8486?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.25165/j.ijabe.20231603.8486, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","within the first few years of introducing new technology, there is often a lot of excitement and hype surrounding its potential. people tend to overestimate its immediate impact, believing that it will revolutionize various aspects of society and bring about rapid change. however, during this early stage, the technology may still be in its early development phase, and it may face a series of challenges and limitations that could prevent it from reaching its full potential. this pattern can be observed in various technologies throughout history, such as the internet, mobile phones, and others. it is essential to consider this hype cycle when evaluating the potential impact of emerging technologies such as generative ai and to maintain a balanced perspective on their development and adoption. therefore, universities should actively encourage research on the impact of generative ai on education, the workforce",https://www.ijabe.org/index.php/ijabe/article/download/8486/pdf
32da19bec4898eaab80c6a4d82f51de8b99ab941,Generative AI in Education: Perspectives Through an Academic Lens,"In this paper, we investigated the role of generative AI in education in academic publications extracted from Web of Science (3506 records; 2019–2024). The proposed methodology included three main streams: (1) Monthly analysis trends; top-ranking research areas, keywords and universities; frequency of keywords over time; a keyword co-occurrence map; collaboration networks; and a Sankey diagram illustrating the relationship between AI-related terms, publication years and research areas; (2) Sentiment analysis using a custom list of words, VADER and TextBlob; (3) Topic modeling using Latent Dirichlet Allocation (LDA). Terms such as “artificial intelligence” and “generative artificial intelligence” were predominant, but they diverged and evolved over time. By 2024, AI applications had branched into specialized fields, including education and educational research, computer science, engineering, psychology, medical informatics, healthcare sciences, general medicine and surgery. The sentiment analysis reveals a growing optimism in academic publications regarding generative AI in education, with a steady increase in positive sentiment from 2023 to 2024, while maintaining a predominantly neutral tone. Five main topics were derived from AI applications in education, based on an analysis of the most relevant terms extracted by LDA: (1) Gen-AI’s impact in education and research; (2) ChatGPT as a tool for university students and teachers; (3) Large language models (LLMs) and prompting in computing education; (4) Applications of ChatGPT in patient education; (5) ChatGPT’s performance in medical examinations. The research identified several emerging topics: discipline-specific application of LLMs, multimodal gen-AI, personalized learning, AI as a peer or tutor and cross-cultural and multilingual tools aimed at developing culturally relevant educational content and supporting the teaching of lesser-known languages. Further, gamification with generative AI involves designing interactive storytelling and adaptive educational games to enhance engagement and hybrid human–AI classrooms explore co-teaching dynamics, teacher–student relationships and the impact on classroom authority.",2025,"[{'authorId': '1948633', 'name': 'Iulian Întorsureanu'}, {'authorId': '36065850', 'name': 'S. Oprea'}, {'authorId': '9725881', 'name': 'A. Bâra'}, {'authorId': '70063251', 'name': 'Dragoș Vespan'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/electronics14051053?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/electronics14051053, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this paper, we investigated the role of generative ai in education in academic publications extracted from web of science (3506 records; 2019–2024). the proposed methodology included three main streams: (1) monthly analysis trends; top-ranking research areas, keywords and universities; frequency of keywords over time; a keyword co-occurrence map; collaboration networks; and a sankey diagram illustrating the relationship between ai-related terms, publication years and research areas; (2) sentiment analysis using a custom list of words, vader and textblob; (3) topic modeling using latent dirichlet allocation (lda). terms such as “artificial intelligence” and “generative artificial intelligence” were predominant, but they diverged and evolved over time. by 2024, ai applications had branched into specialized fields, including education and educational research, computer science, engineering, psychology, medical informatics, healthcare sciences, general medicine and surgery. the sentiment analysis reveals a growing optimism in academic publications regarding generative ai in education, with a steady increase in positive sentiment from 2023 to 2024, while maintaining a predominantly neutral tone. five main topics were derived from ai applications in education, based on an analysis of the most relevant terms extracted by lda: (1) gen-ai’s impact in education and research; (2) chatgpt as a tool for university students and teachers; (3) large language models (llms) and prompting in computing education; (4) applications of chatgpt in patient education; (5) chatgpt’s performance in medical examinations. the research identified several emerging topics: discipline-specific application of llms, multimodal gen-ai, personalized learning, ai as a peer or tutor and cross-cultural and multilingual tools aimed at developing culturally relevant educational content and supporting the teaching of lesser-known languages. further, gamification with generative ai involves designing interactive storytelling and adaptive educational games to enhance engagement and hybrid human–ai classrooms explore co-teaching dynamics, teacher–student relationships and the impact on classroom authority.",
9398e2fcf32a243194f758897fbe1592b4d031a2,AI for learning unleashed: Pioneering generative AI in education at the University of Miami,"The University of Miami (UM) is at the forefront of integrating generative AI into education, spearheaded by Ann M. Olazábal, Interim Dean of the Miami Herbert Business School. This case study explores the dynamic landscape of AI adoption at UM, highlighting both the innovative potential and ethical challenges. The university has embraced AI tools like Adobe Firefly and Copilot, aiming to enhance learning experiences and internal processes. However, the misuse of AI for academic dishonesty poses significant dilemmas. The case contrasts two MBA students' approaches to AI: Alex, who uses AI to shortcut his studies, and Jordan, who leverages AI to deepen her understanding and enhance her learning. The narrative underscores the need for ethical AI use and the importance of fostering critical thinking and creativity. Ann’s strategic vision includes forming an AI task force to explore AI’s organizational impacts and potential use cases, such as a smart assistant for student curriculum planning and an AI-powered entrepreneurship lab. The case concludes with a discussion on balancing innovation with academic integrity and the challenges of centralized IT governance. The case serves as a foundation for classroom discussion including a comprehensive examination of the opportunities and risks associated with generative AI in higher education.",2024,"[{'authorId': '2313023139', 'name': 'Robert Wayne Gregory'}, {'authorId': '2312965260', 'name': 'Simran Narang'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/20438869241266258?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/20438869241266258, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the university of miami (um) is at the forefront of integrating generative ai into education, spearheaded by ann m. olazábal, interim dean of the miami herbert business school. this case study explores the dynamic landscape of ai adoption at um, highlighting both the innovative potential and ethical challenges. the university has embraced ai tools like adobe firefly and copilot, aiming to enhance learning experiences and internal processes. however, the misuse of ai for academic dishonesty poses significant dilemmas. the case contrasts two mba students' approaches to ai: alex, who uses ai to shortcut his studies, and jordan, who leverages ai to deepen her understanding and enhance her learning. the narrative underscores the need for ethical ai use and the importance of fostering critical thinking and creativity. ann’s strategic vision includes forming an ai task force to explore ai’s organizational impacts and potential use cases, such as a smart assistant for student curriculum planning and an ai-powered entrepreneurship lab. the case concludes with a discussion on balancing innovation with academic integrity and the challenges of centralized it governance. the case serves as a foundation for classroom discussion including a comprehensive examination of the opportunities and risks associated with generative ai in higher education.",
d4916a1aa2fcaea415d056d7181ea4abe03cad07,"Application Status, Problems and Future Prospects of Generative AI in Education","The emergence of Chat GPT signifies another revolutionary wave of information technology brought about by generative AI. This article introduces the development and technical support of generative AI, revealing that there are four main issues regarding its application in the education field: opacity and inexplicability, data privacy and security, individualization and fairness, and effectiveness and reliability. The article then looks forward to the future trends of generative AI in the education field from four aspects: personalized education, intelligent teaching, joint education, and virtual teaching, aiming to provide important reference value for research and practice in this field.",2023,"[{'authorId': '2110751949', 'name': 'Haotian Yu'}, {'authorId': '2249183925', 'name': 'Zhaoyang Liu'}, {'authorId': '152699208', 'name': 'Yunyun Guo'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/CSTE59648.2023.00065?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CSTE59648.2023.00065, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the emergence of chat gpt signifies another revolutionary wave of information technology brought about by generative ai. this article introduces the development and technical support of generative ai, revealing that there are four main issues regarding its application in the education field: opacity and inexplicability, data privacy and security, individualization and fairness, and effectiveness and reliability. the article then looks forward to the future trends of generative ai in the education field from four aspects: personalized education, intelligent teaching, joint education, and virtual teaching, aiming to provide important reference value for research and practice in this field.",
660e1b225f53776a2335f9250501e147a31d648a,Generative AI in Education,"Various fields including healthcare, education, research, and practice have witnessed the emergence of AI as a powerful tool. Generative AI (GAI) and chatbots play a significant role in this scenario. Their contributions have been summarized concisely and show how they have been used to develop invaluable community resources. Furthermore, the combination of text embedding and generative AI (GAI) has resulted in innovative convergence, thus presenting an upheaval in handling user inquiries in domains with unique requirements. The construction of a chatbot using AI and Generative Artificial Intelligence is the focus of this work. Meeting the demand for accessible and prompt educational assistance is the main objective of this article. In the 21st century, technological advances, particularly artificial intelligence, are transforming human-AI interaction and offering smart solutions across various platforms. This study aims to highlight the revolutionary impact of AI and chatbots on educational practices.",2023,"[{'authorId': '2457917', 'name': 'R. Kodali'}, {'authorId': '2297018767', 'name': 'Yatendra Prasad Upreti'}, {'authorId': '1963411', 'name': 'Lakshmi Boppana'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/HNICEM60674.2023.10589199?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/HNICEM60674.2023.10589199, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","various fields including healthcare, education, research, and practice have witnessed the emergence of ai as a powerful tool. generative ai (gai) and chatbots play a significant role in this scenario. their contributions have been summarized concisely and show how they have been used to develop invaluable community resources. furthermore, the combination of text embedding and generative ai (gai) has resulted in innovative convergence, thus presenting an upheaval in handling user inquiries in domains with unique requirements. the construction of a chatbot using ai and generative artificial intelligence is the focus of this work. meeting the demand for accessible and prompt educational assistance is the main objective of this article. in the 21st century, technological advances, particularly artificial intelligence, are transforming human-ai interaction and offering smart solutions across various platforms. this study aims to highlight the revolutionary impact of ai and chatbots on educational practices.",
8c875683f25bd134cd3baeb4cef9f8d2c684e204,Survey on Generative AI in Education,"This paper explores how large
language models are being used in educational
institutions, after which it goes on to examine their
applications, challenges, and ethical implications.
By synthesizing recent insights, the paper will
delve into LLM text clustering, customization of
higher education, and personalized learning. The
presence of generative AI tools, such as ChatGPT,
will transform the arena of research efficiency and
adaptive learning. However, issues related to
privacy, data security, and ethics such as
algorithmic bias are still present and have to be
sorted out. The paper presents suggestions for the
responsible integration of LLMs into learning
structures to nullify risk issues that may pose a
threat to augmenting positive learning outcomes.",2024,"[{'authorId': '2333953371', 'name': 'Mohammed Hisham'}, {'authorId': '2333940560', 'name': 'Nandana Vinod'}, {'authorId': '2333933030', 'name': 'Diana Liz Kuriakose'}, {'authorId': '2333953368', 'name': 'Maria Joshy Maria Joshy'}, {'authorId': '2333953373', 'name': 'Syama S Syama S'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.35629/5252-0611615620?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.35629/5252-0611615620, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper explores how large language models are being used in educational institutions, after which it goes on to examine their applications, challenges, and ethical implications. by synthesizing recent insights, the paper will delve into llm text clustering, customization of higher education, and personalized learning. the presence of generative ai tools, such as chatgpt, will transform the arena of research efficiency and adaptive learning. however, issues related to privacy, data security, and ethics such as algorithmic bias are still present and have to be sorted out. the paper presents suggestions for the responsible integration of llms into learning structures to nullify risk issues that may pose a threat to augmenting positive learning outcomes.",
d3b1fd3348f040814effaada60c1b6761ef0170f,Generative AI in Higher Education: A Global Perspective of Institutional Adoption Policies and Guidelines,"Integrating generative AI (GAI) into higher education is crucial for preparing a future generation of GAI-literate students. Yet a thorough understanding of the global institutional adoption policy remains absent, with most of the prior studies focused on the Global North and the promises and challenges of GAI, lacking a theoretical lens. This study utilizes the Diffusion of Innovations Theory to examine GAI adoption strategies in higher education across 40 universities from six global regions. It explores the characteristics of GAI innovation, including compatibility, trialability, and observability, and analyses the communication channels and roles and responsibilities outlined in university policies and guidelines. The findings reveal a proactive approach by universities towards GAI integration, emphasizing academic integrity, teaching and learning enhancement, and equity. Despite a cautious yet optimistic stance, a comprehensive policy framework is needed to evaluate the impacts of GAI integration and establish effective communication strategies that foster broader stakeholder engagement. The study highlights the importance of clear roles and responsibilities among faculty, students, and administrators for successful GAI integration, supporting a collaborative model for navigating the complexities of GAI in education. This study contributes insights for policymakers in crafting detailed strategies for its integration.",2024,"[{'authorId': '2211966973', 'name': 'Yueqiao Jin'}, {'authorId': '2110297110', 'name': 'Lixiang Yan'}, {'authorId': '2265579478', 'name': 'Vanessa Echeverría'}, {'authorId': '65953975', 'name': 'D. Gašević'}, {'authorId': '2285700108', 'name': 'Roberto Martínez Maldonado'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2405.11800, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","integrating generative ai (gai) into higher education is crucial for preparing a future generation of gai-literate students. yet a thorough understanding of the global institutional adoption policy remains absent, with most of the prior studies focused on the global north and the promises and challenges of gai, lacking a theoretical lens. this study utilizes the diffusion of innovations theory to examine gai adoption strategies in higher education across 40 universities from six global regions. it explores the characteristics of gai innovation, including compatibility, trialability, and observability, and analyses the communication channels and roles and responsibilities outlined in university policies and guidelines. the findings reveal a proactive approach by universities towards gai integration, emphasizing academic integrity, teaching and learning enhancement, and equity. despite a cautious yet optimistic stance, a comprehensive policy framework is needed to evaluate the impacts of gai integration and establish effective communication strategies that foster broader stakeholder engagement. the study highlights the importance of clear roles and responsibilities among faculty, students, and administrators for successful gai integration, supporting a collaborative model for navigating the complexities of gai in education. this study contributes insights for policymakers in crafting detailed strategies for its integration.",
16b0d4b611d1385b5b542903dce7bb926e7b5c4e,Bringing Generative AI to Adaptive Learning in Education,"The recent surge in generative AI technologies, such as large language models and diffusion models, has boosted the development of AI applications in various domains, including science, finance, and education. Concurrently, adaptive learning, a concept that has gained substantial interest in the educational sphere, has proven its efficacy in enhancing students' learning efficiency. In this position paper, we aim to shed light on the intersectional studies of these two methods, which combine generative AI with adaptive learning concepts. By presenting discussions about the benefits, challenges, and potentials in this field, we argue that this union will contribute significantly to the development of the next-stage learning format in education.",2024,"[{'authorId': '2261080028', 'name': 'Hang Li'}, {'authorId': '2286111714', 'name': 'Tianlong Xu'}, {'authorId': '2152737103', 'name': 'Chaoli Zhang'}, {'authorId': '2284986485', 'name': 'Eason Chen'}, {'authorId': '2284998924', 'name': 'Jing Liang'}, {'authorId': '2286407896', 'name': 'Xing Fan'}, {'authorId': '2287083640', 'name': 'Haoyang Li'}, {'authorId': '2256937217', 'name': 'Jiliang Tang'}, {'authorId': '2284983420', 'name': 'Qingsong Wen'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2402.14601, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the recent surge in generative ai technologies, such as large language models and diffusion models, has boosted the development of ai applications in various domains, including science, finance, and education. concurrently, adaptive learning, a concept that has gained substantial interest in the educational sphere, has proven its efficacy in enhancing students' learning efficiency. in this position paper, we aim to shed light on the intersectional studies of these two methods, which combine generative ai with adaptive learning concepts. by presenting discussions about the benefits, challenges, and potentials in this field, we argue that this union will contribute significantly to the development of the next-stage learning format in education.",
32d03cdea23f8445bc2b91888bcfa48a23bad1b6,From surface to deep learning approaches with Generative AI in higher education: an analytical framework of student agency,"ABSTRACT Recent emergence of generative artificial intelligence (GenAI) technology has stimulated interests as well as concerns in their potential in teaching and learning. Situated in the new and transforming context, this study provides an avenue for students to introspectively explore their use of GenAI in a postgraduate course. Seventy-four students from three Chinese universities participated in this study. By analyzing student interviews conducted pre- and post-course, alongside their chat logs with GenAI and reflective journal entries detailing their learning approaches, the research uncovers a spectrum of student perspectives on GenAI’s impact, ranging from beneficial optimism, to cautious skepticism and adaptable pragmatism. Notably, student agency is identified as a crucial element in relation to these themes. This was articulated in four types of learning activities: receptive, resistive, resourceful, and reflective. The research underscores the importance of supporting and empowering student agency in the learning approaches aided by GenAI in education, highlighting its role in optimizing its use and enhancing autonomous, lifelong learning skills amidst the evolving technologically advanced learning landscape.",2024,"[{'authorId': '2291739420', 'name': 'Yunying Yang'}, {'authorId': '2291972827', 'name': 'Jinwen Luo'}, {'authorId': '2291853349', 'name': 'Miaoyan Yang'}, {'authorId': '2291724002', 'name': 'Runde Yang'}, {'authorId': '2291850299', 'name': 'Jiayin Chen'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/03075079.2024.2327003?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/03075079.2024.2327003, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract recent emergence of generative artificial intelligence (genai) technology has stimulated interests as well as concerns in their potential in teaching and learning. situated in the new and transforming context, this study provides an avenue for students to introspectively explore their use of genai in a postgraduate course. seventy-four students from three chinese universities participated in this study. by analyzing student interviews conducted pre- and post-course, alongside their chat logs with genai and reflective journal entries detailing their learning approaches, the research uncovers a spectrum of student perspectives on genai’s impact, ranging from beneficial optimism, to cautious skepticism and adaptable pragmatism. notably, student agency is identified as a crucial element in relation to these themes. this was articulated in four types of learning activities: receptive, resistive, resourceful, and reflective. the research underscores the importance of supporting and empowering student agency in the learning approaches aided by genai in education, highlighting its role in optimizing its use and enhancing autonomous, lifelong learning skills amidst the evolving technologically advanced learning landscape.",
018f58247a20ec6b3256fd3119f57980a6f37748,Responsible Adoption of Generative AI in Higher Education: Developing a “Points to Consider” Approach Based on Faculty Perspectives,"This paper proposes an approach to the responsible adoption of generative AI in higher education, employing a “points to consider” approach that is sensitive to the goals, values, and structural features of higher education. Higher education's ethos of collaborative faculty governance, pedagogical and research goals, and embrace of academic freedom conflict, the paper argues, with centralized top-down approaches to governing AI that are common in the private sector. The paper is based on a semester-long effort at the University of Pittsburgh which gathered and organized perspectives on generative AI in higher education through a collaborative, iterative, interdisciplinary process that included recurring group discussions, three standalone focus groups, and an informal survey. The paper presents insights drawn from this effort—that give rise to the “points to consider” approach the paper develops. These insights include the benefits and risks of potential uses of generative AI In higher education, as well as barriers to its adoption, and culminate in the six normative points to consider when adopting and governing generative AI in institutions of higher education.",2024,"[{'authorId': '1441101651', 'name': 'Ravit Dotan'}, {'authorId': '2304655680', 'name': 'Lisa S. Parker'}, {'authorId': '98047144', 'name': 'John G. Radzilowicz'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3630106.3659023', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2406.01930, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper proposes an approach to the responsible adoption of generative ai in higher education, employing a “points to consider” approach that is sensitive to the goals, values, and structural features of higher education. higher education's ethos of collaborative faculty governance, pedagogical and research goals, and embrace of academic freedom conflict, the paper argues, with centralized top-down approaches to governing ai that are common in the private sector. the paper is based on a semester-long effort at the university of pittsburgh which gathered and organized perspectives on generative ai in higher education through a collaborative, iterative, interdisciplinary process that included recurring group discussions, three standalone focus groups, and an informal survey. the paper presents insights drawn from this effort—that give rise to the “points to consider” approach the paper develops. these insights include the benefits and risks of potential uses of generative ai in higher education, as well as barriers to its adoption, and culminate in the six normative points to consider when adopting and governing generative ai in institutions of higher education.",https://dl.acm.org/doi/pdf/10.1145/3630106.3659023
1b35339446c0f86d5e1e61b5051b65980a17bdba,Generative AI in Computing Education: Perspectives of Students and Instructors,"Generative models are now capable of producing natural language text that is, in some cases, comparable in quality to the text produced by people. In the computing education context, these models are being used to generate code, code explanations, and programming exercises. The rapid adoption of these models has prompted multiple position papers and workshops which discuss the implications of these models for computing education, both positive and negative. This paper presents results from a series of semi-structured interviews with 12 students and 6 instructors about their awareness, experiences, and preferences regarding the use of tools powered by generative AI in computing classrooms. The results suggest that Generative AI (GAI) tools will play an increasingly significant role in computing education. However, students and instructors also raised numerous concerns about how these models should be integrated to best support the needs and learning goals of students. We also identified interesting tensions and alignments that emerged between how instructors and students prefer to engage with these models. We discuss these results and provide recommendations related to curriculum development, assessment methods, and pedagogical practice. As GAI tools become increasingly prevalent, it's important to understand educational stakeholders' preferences and values to ensure that these tools can be used for good and that potential harms can be mitigated.",2023,"[{'authorId': '1471381491', 'name': 'Cynthia Zastudil'}, {'authorId': '3200986', 'name': 'M. Rogalska'}, {'authorId': '90928238', 'name': 'C. Kapp'}, {'authorId': '152224423', 'name': 'Jennifer L. Vaughn'}, {'authorId': '1564555946', 'name': 'S. Macneil'}]","{'url': 'https://arxiv.org/pdf/2308.04309', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2308.04309, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative models are now capable of producing natural language text that is, in some cases, comparable in quality to the text produced by people. in the computing education context, these models are being used to generate code, code explanations, and programming exercises. the rapid adoption of these models has prompted multiple position papers and workshops which discuss the implications of these models for computing education, both positive and negative. this paper presents results from a series of semi-structured interviews with 12 students and 6 instructors about their awareness, experiences, and preferences regarding the use of tools powered by generative ai in computing classrooms. the results suggest that generative ai (gai) tools will play an increasingly significant role in computing education. however, students and instructors also raised numerous concerns about how these models should be integrated to best support the needs and learning goals of students. we also identified interesting tensions and alignments that emerged between how instructors and students prefer to engage with these models. we discuss these results and provide recommendations related to curriculum development, assessment methods, and pedagogical practice. as gai tools become increasingly prevalent, it's important to understand educational stakeholders' preferences and values to ensure that these tools can be used for good and that potential harms can be mitigated.",https://arxiv.org/pdf/2308.04309
a91a121745574afffe46c2f517e4889f030bb623,Exploring the Potential of Generative AI in Shaping Engineering Education: Opportunities and Challenges,"Abstract—Engineering education equips students with the necessary knowledge and skills to thrive in rapidly evolving field of engineering and computer science. However, updating the curriculum to be current with the latest advancements can be challenging for educators. The curriculum and activities (both cocurricular and extra-curricular) activities must be designed such way as to educate a global engineer with multidimensional attributes. The faculty and administrators must be willing to adapt to the fast changes in technology and learning habits of our students. In this day and age of ChatGPT, Bard, Perplexity and other generative AI tools, educators have to adapt and focus on creative ways of engaging students towards lifelong learning with strong work ethics and professional skills. This paper explores the potential of generative artificial intelligence (AI) in revolutionizing engineering education by designing and offering up-to-date content. It examines specific examples in various engineering domains and discusses the benefits of generative AI in accreditation efforts and faculty time allocation. Keywords—engineering education; generative AI; prompt engineering.",2024,"[{'authorId': '2297566682', 'name': 'Kumar Yelamarthi'}, {'authorId': '2297566255', 'name': 'Raju Dandu'}, {'authorId': '2297833780', 'name': 'Mohan Rao'}, {'authorId': '2190220', 'name': 'V. P. Yanambaka'}, {'authorId': '2297559307', 'name': 'Satish Mahajan'}]","{'url': 'https://doi.org/10.16920/jeet/2024/v37is2/24072', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.16920/jeet/2024/v37is2/24072?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.16920/jeet/2024/v37is2/24072, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract—engineering education equips students with the necessary knowledge and skills to thrive in rapidly evolving field of engineering and computer science. however, updating the curriculum to be current with the latest advancements can be challenging for educators. the curriculum and activities (both cocurricular and extra-curricular) activities must be designed such way as to educate a global engineer with multidimensional attributes. the faculty and administrators must be willing to adapt to the fast changes in technology and learning habits of our students. in this day and age of chatgpt, bard, perplexity and other generative ai tools, educators have to adapt and focus on creative ways of engaging students towards lifelong learning with strong work ethics and professional skills. this paper explores the potential of generative artificial intelligence (ai) in revolutionizing engineering education by designing and offering up-to-date content. it examines specific examples in various engineering domains and discusses the benefits of generative ai in accreditation efforts and faculty time allocation. keywords—engineering education; generative ai; prompt engineering.",https://doi.org/10.16920/jeet/2024/v37is2/24072
cc25dcfc6c2ae9becfe1ac589815f03e8251d0fe,Pandora's Can of Worms: A Year of Generative AI in Higher Education,"abstract:In the year since ChatGPT was released by OpenAI, librarians, instructors, and higher education administrators have grappled with generative artificial intelligence (AI) and its implications for teaching, learning, research, and writing. Drawn from informal conversations, professional observations, discussion groups, and professional development events, this article reports on the experience of learning about generative AI at one university. This article considers ways that educators may use AI tools and reasons to resist adopting generative AI tools, situating uses on a spectrum of acceptability.",2024,"[{'authorId': '2279397713', 'name': 'Robin Elizabeth Miller'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1353/pla.2024.a916988?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1353/pla.2024.a916988, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract:in the year since chatgpt was released by openai, librarians, instructors, and higher education administrators have grappled with generative artificial intelligence (ai) and its implications for teaching, learning, research, and writing. drawn from informal conversations, professional observations, discussion groups, and professional development events, this article reports on the experience of learning about generative ai at one university. this article considers ways that educators may use ai tools and reasons to resist adopting generative ai tools, situating uses on a spectrum of acceptability.",
ffd0c9627aec97f391a64457fb4158e2e174a838,Generative AI in Higher Art Education,"This research delves into the perspectives of Chinese university art teachers on the integration of Artificial Intelligence in Generative Content. Collaboratively initiated by art teachers from Chinese universities through the AI Art Education Alliance in Wuhan, the study aims to comprehend their attitudes, concerns, and preparations regarding the infusion of generative AI tools into art and design curricula. The research employs a comprehensive approach, incorporating group interviews during the inaugural session of the AI Art Education Alliance. Additionally, questionnaire research is utilized as supplementary evidence. Participants include middle-level administrators and teachers from diverse colleges, offering a nuanced understanding of viewpoints across various educational institutions. Key findings reveal nuanced perspectives on AI in higher art education. Notably, there exists a spectrum of AI anxiety, with comprehensive universities showing readiness, while caution prevails in art colleges. The study underscores the potential benefits of AI in art education but highlights concerns about its impact on traditional pedagogy. The research emphasizes the urgency of addressing equity issues related to resource disparities, academic integrity, and cultural resistance within the education community. Recommendations include standardized AI tool usage, adaptations in professional structures, and fostering collaborative alliances to harness AI's potential effectively.",2024,"[{'authorId': '2305140319', 'name': 'Xi Chen'}, {'authorId': '2312108945', 'name': 'Yuebin Liao'}, {'authorId': '2298708986', 'name': 'Weihai Yu'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/CSTE62025.2024.00032?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CSTE62025.2024.00032, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this research delves into the perspectives of chinese university art teachers on the integration of artificial intelligence in generative content. collaboratively initiated by art teachers from chinese universities through the ai art education alliance in wuhan, the study aims to comprehend their attitudes, concerns, and preparations regarding the infusion of generative ai tools into art and design curricula. the research employs a comprehensive approach, incorporating group interviews during the inaugural session of the ai art education alliance. additionally, questionnaire research is utilized as supplementary evidence. participants include middle-level administrators and teachers from diverse colleges, offering a nuanced understanding of viewpoints across various educational institutions. key findings reveal nuanced perspectives on ai in higher art education. notably, there exists a spectrum of ai anxiety, with comprehensive universities showing readiness, while caution prevails in art colleges. the study underscores the potential benefits of ai in art education but highlights concerns about its impact on traditional pedagogy. the research emphasizes the urgency of addressing equity issues related to resource disparities, academic integrity, and cultural resistance within the education community. recommendations include standardized ai tool usage, adaptations in professional structures, and fostering collaborative alliances to harness ai's potential effectively.",
f2919187898f8bd33ffa4214a3902d26b84cfcb3,Discussing the Changing Landscape of Generative AI in Computing Education,"In a previous Birds of a Feather discussion, we delved into the nascent applications of generative AI, contemplating its potential and speculating on future trajectories. Since then, the landscape has continued to evolve revealing the capabilities and limitations of these models. Despite this progress, the computing education research community still faces uncertainty around pivotal aspects such as (1) academic integrity and assessments, (2) curricular adaptations, (3) pedagogical strategies, and (4) the competencies students require to instill responsible use of these tools. The goal of this Birds of a Feather discussion is to unravel these pressing and persistent issues with computing educators and researchers, fostering a collaborative exploration of strategies to navigate the educational implications of advancing generative AI technologies. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed leaders to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.",2024,"[{'authorId': '2249761745', 'name': 'Stephen Macneil'}, {'authorId': '34690956', 'name': 'Juho Leinonen'}, {'authorId': '2243041721', 'name': 'Paul Denny'}, {'authorId': '8449546', 'name': 'Natalie Kiesler'}, {'authorId': '3446322', 'name': 'Arto Hellas'}, {'authorId': '144793710', 'name': 'J. Prather'}, {'authorId': '2249760349', 'name': 'Brett A. Becker'}, {'authorId': '2291689941', 'name': 'Michel Wermelinger'}, {'authorId': '2346332015', 'name': 'Karen Reid'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3626253.3635369?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3626253.3635369, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in a previous birds of a feather discussion, we delved into the nascent applications of generative ai, contemplating its potential and speculating on future trajectories. since then, the landscape has continued to evolve revealing the capabilities and limitations of these models. despite this progress, the computing education research community still faces uncertainty around pivotal aspects such as (1) academic integrity and assessments, (2) curricular adaptations, (3) pedagogical strategies, and (4) the competencies students require to instill responsible use of these tools. the goal of this birds of a feather discussion is to unravel these pressing and persistent issues with computing educators and researchers, fostering a collaborative exploration of strategies to navigate the educational implications of advancing generative ai technologies. aligned with this goal of building an inclusive learning community, our bof is led by globally distributed leaders to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of llms in cs education.",
ff20587563f2ffac3985a18d7fd28b755873c8f2,Early Perceptions of Teaching and Learning Using Generative AI in Higher Education,"This project explored perceptions of ChatGPT in higher education among students and faculty to assess teaching and learning implications of this Generative Artificial Intelligence (Generative AI)–based novel tool. Two theoretical frameworks inspired the project, including Diffusion of Innovation theory (Rogers, 1962) and Technology Acceptance Model (Davis, 1989). An online survey was completed by 380 participants (N = 380). Participants indicated that they would not use ChatGPT to plagiarize but believed others would. When asked to rate the accuracy of ChatGPT's output, more than half took the incorrect output as correct/somewhat correct or could not tell whether it was correct or incorrect. Results varied based on participant demographics, including age, gender, and occupation. These findings support the need for data literacy. If Generative AI is to be used in higher education to aid in the learning process, it is imperative to continue teaching critical thinking.",2024,"[{'authorId': '2237707015', 'name': 'Amanda D. Damiano'}, {'authorId': '1846609', 'name': 'E. Lauría'}, {'authorId': '2287156498', 'name': 'Christian Sarmiento'}, {'authorId': '2287263645', 'name': 'Ningjing Zhao'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/00472395241233290?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/00472395241233290, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this project explored perceptions of chatgpt in higher education among students and faculty to assess teaching and learning implications of this generative artificial intelligence (generative ai)–based novel tool. two theoretical frameworks inspired the project, including diffusion of innovation theory (rogers, 1962) and technology acceptance model (davis, 1989). an online survey was completed by 380 participants (n = 380). participants indicated that they would not use chatgpt to plagiarize but believed others would. when asked to rate the accuracy of chatgpt's output, more than half took the incorrect output as correct/somewhat correct or could not tell whether it was correct or incorrect. results varied based on participant demographics, including age, gender, and occupation. these findings support the need for data literacy. if generative ai is to be used in higher education to aid in the learning process, it is imperative to continue teaching critical thinking.",
ced25dcf34f24b521cdb45a62292f92a54ca27ca,The Prospects of Generative AI in Higher Education,"Artificial intelligence (AI) has brought tremendous prospects and breakthroughs to a number of areas, including education. With an emphasis on the use of chatbots, analytics, generative AI, and personalized learning experiences, this research study offers a thorough analysis of the effects of AI on education. In order to shed light on the ethical implications, cultural considerations, language competence issues, and privacy concerns related to the use of AI in education, it explores the related limitations, obstacles, and concerns. Artificial Intelligence (AI) has the potential to completely transform higher education by promoting efficiency, creativity, customization, and engagement. Higher education could undergo a significant transition with the use of Generative Artificial Intelligence (GAI) tools as ChatGPT, Google BARD, and Bing Chat. But this integration also presents problems for avoiding plagiarism and upholding academic integrity. Within this In this work, we explore and evaluate useful strategies for effectively utilizing GAI's potential while also guaranteeing assignment integrity. We present the PAIGE (Promoting Assignment Integrity using Generative AI in Education) conceptual framework as a viable means of addressing these issues. This concept places a focus on the moral. The inclusion of GAI, encourages student engagement, and fosters chances for collaborative learning. Institutions of higher learning can efficiently use the promise of GAI while maintaining assignment integrity by utilizing the PAIGE framework. A responsible and prosperous future in education powered by generative AI is made possible by this strategy. The research report also explores the roles that parents, legislators, and educators play in minimizing the risks and optimizing the advantages of implementing AI in the classroom. Challenges with linguistic ability, privacy, and other factors related to using AI in education. Key Words: Generative AI, analytics, learning experiences, cognitive achievement, AI in the classroom, customized feedback",2024,"[{'authorId': '2300014517', 'name': 'Prof, Shweta A. Solanke'}]","{'url': 'https://ijsrem.com/download/the-prospects-of-generative-ai-in-higher-education/?wpdmdl=32626&refresh=665c3d7e340e51717321086', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.55041/ijsrem32533?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55041/ijsrem32533, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","artificial intelligence (ai) has brought tremendous prospects and breakthroughs to a number of areas, including education. with an emphasis on the use of chatbots, analytics, generative ai, and personalized learning experiences, this research study offers a thorough analysis of the effects of ai on education. in order to shed light on the ethical implications, cultural considerations, language competence issues, and privacy concerns related to the use of ai in education, it explores the related limitations, obstacles, and concerns. artificial intelligence (ai) has the potential to completely transform higher education by promoting efficiency, creativity, customization, and engagement. higher education could undergo a significant transition with the use of generative artificial intelligence (gai) tools as chatgpt, google bard, and bing chat. but this integration also presents problems for avoiding plagiarism and upholding academic integrity. within this in this work, we explore and evaluate useful strategies for effectively utilizing gai's potential while also guaranteeing assignment integrity. we present the paige (promoting assignment integrity using generative ai in education) conceptual framework as a viable means of addressing these issues. this concept places a focus on the moral. the inclusion of gai, encourages student engagement, and fosters chances for collaborative learning. institutions of higher learning can efficiently use the promise of gai while maintaining assignment integrity by utilizing the paige framework. a responsible and prosperous future in education powered by generative ai is made possible by this strategy. the research report also explores the roles that parents, legislators, and educators play in minimizing the risks and optimizing the advantages of implementing ai in the classroom. challenges with linguistic ability, privacy, and other factors related to using ai in education. key words: generative ai, analytics, learning experiences, cognitive achievement, ai in the classroom, customized feedback",https://ijsrem.com/download/the-prospects-of-generative-ai-in-higher-education/?wpdmdl=32626&refresh=665c3d7e340e51717321086
c99824765d2c2050893679b5fe255f785d480b23,Gender perceptions of generative AI in higher education,"PurposeThis study explored the themes and sentiments of online learners regarding the use of Generative Artificial Intelligence (AI) or “generative AI” technology in higher education.Design/methodology/approachEnglish-language tweets were subjected to topic modelling and sentiment analysis. Three prevalent themes were identified and discussed: curriculum development opportunities, lifelong learning prospects and challenges associated with generative AI use.FindingsThe results also indicated a range of topics and emotions towards generative AI in education, which were predominantly positive but also varied across male and female users.Originality/valueThe findings provide insights for educators, policymakers and researchers on the opportunities and challenges associated with the integration of generative AI in educational settings. This includes the importance of identifying AI-supported learning and teaching practices that align with gender-specific preferences to offer a more inclusive and tailored approach to learning.",2024,"[{'authorId': '1400904905', 'name': 'H. Al-Samarraie'}, {'authorId': '3425298', 'name': 'S. Sarsam'}, {'authorId': '2322238543', 'name': 'Ahmed Ibrahim Alzahrani'}, {'authorId': '2322119204', 'name': 'Arunangsu Chatterjee'}, {'authorId': '3464491', 'name': 'B. Swinnerton'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/jarhe-02-2024-0109?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/jarhe-02-2024-0109, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purposethis study explored the themes and sentiments of online learners regarding the use of generative artificial intelligence (ai) or “generative ai” technology in higher education.design/methodology/approachenglish-language tweets were subjected to topic modelling and sentiment analysis. three prevalent themes were identified and discussed: curriculum development opportunities, lifelong learning prospects and challenges associated with generative ai use.findingsthe results also indicated a range of topics and emotions towards generative ai in education, which were predominantly positive but also varied across male and female users.originality/valuethe findings provide insights for educators, policymakers and researchers on the opportunities and challenges associated with the integration of generative ai in educational settings. this includes the importance of identifying ai-supported learning and teaching practices that align with gender-specific preferences to offer a more inclusive and tailored approach to learning.",
3bba0c29d3cc6126803af23d50db4df2a7667f3d,"Exploring the Role of Generative AI in Second Language Education: Insights for Instruction, Learning, and Assessment","Artificial Intelligence (AI), broadly speaking, refers to the efforts to program computers in order to mimic human understandings and problem-solving abilities (Voss, 2024). Recent developments in Generative AI utilize large volumes of available training data that allow users to prompt AI-powered tools to automatically produce specific content (e.g., text or images) (Vajjala, 2024). As an innovative technology, Generative AI is reshaping many fields, including second language education (Ji et al., 2023; Zou et al., 2023). At the same time, it has sparked discussions about its seemingly obvious advantages and potential pitfalls (Voss et al., 2023). Many students, educators, and researchers have embraced Generative AI in their everyday practices. There are numerous Generative AI-powered language learning chatbots, tutors, programs, and tools freely available and widely used in language learning contexts around the world. ",2024,"[{'authorId': '1397313756', 'name': 'Mahshad Davoodifard'}, {'authorId': '2311774090', 'name': 'Daniel Eskin'}]","{'url': 'https://journals.library.columbia.edu/index.php/SALT/article/download/12863/6308', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.52214/salt.v24i1.12863?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.52214/salt.v24i1.12863, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","artificial intelligence (ai), broadly speaking, refers to the efforts to program computers in order to mimic human understandings and problem-solving abilities (voss, 2024). recent developments in generative ai utilize large volumes of available training data that allow users to prompt ai-powered tools to automatically produce specific content (e.g., text or images) (vajjala, 2024). as an innovative technology, generative ai is reshaping many fields, including second language education (ji et al., 2023; zou et al., 2023). at the same time, it has sparked discussions about its seemingly obvious advantages and potential pitfalls (voss et al., 2023). many students, educators, and researchers have embraced generative ai in their everyday practices. there are numerous generative ai-powered language learning chatbots, tutors, programs, and tools freely available and widely used in language learning contexts around the world.",https://journals.library.columbia.edu/index.php/SALT/article/download/12863/6308
8e0b932fbe5b4a9a9604c83dfadaf7eca0b3d249,Perspectives of Generative AI in Chemistry Education Within the TPACK Framework,"Artificial intelligence (AI) has made remarkable strides in recent years, finding applications in various fields, including chemistry research and industry. Its integration into chemistry education has gained attention more recently, particularly with the advent of generative AI (GAI) tools. However, there is a need to understand how teachers’ knowledge can impact their ability to integrate these tools into their practice. This position paper emphasizes two central points. First, teachers technological pedagogical content knowledge (TPACK) is essential for more accurate and responsible use of GAI. Second, prompt engineering—the practice of delivering instructions to GAI tools—requires knowledge that falls partially under the technological dimension of TPACK but also includes AI-related competencies that do not fit into any aspect of the framework, for example, the awareness of GAI-related issues such as bias, discrimination, and hallucinations. These points are demonstrated using ChatGPT on three examples drawn from chemistry education. This position paper extends the discussion about the types of knowledge teachers need to apply GAI effectively, highlights the need to further develop theoretical frameworks for teachers’ knowledge in the age of GAI, and, to address that, suggests ways to extend existing frameworks such as TPACK with AI-related dimensions.",2024,"[{'authorId': '1409259365', 'name': 'Yael Feldman-Maggor'}, {'authorId': '31996807', 'name': 'R. Blonder'}, {'authorId': '2795356', 'name': 'Giora Alexandron'}]","{'url': 'https://doi.org/10.1007/s10956-024-10147-3', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10956-024-10147-3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10956-024-10147-3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","artificial intelligence (ai) has made remarkable strides in recent years, finding applications in various fields, including chemistry research and industry. its integration into chemistry education has gained attention more recently, particularly with the advent of generative ai (gai) tools. however, there is a need to understand how teachers’ knowledge can impact their ability to integrate these tools into their practice. this position paper emphasizes two central points. first, teachers technological pedagogical content knowledge (tpack) is essential for more accurate and responsible use of gai. second, prompt engineering—the practice of delivering instructions to gai tools—requires knowledge that falls partially under the technological dimension of tpack but also includes ai-related competencies that do not fit into any aspect of the framework, for example, the awareness of gai-related issues such as bias, discrimination, and hallucinations. these points are demonstrated using chatgpt on three examples drawn from chemistry education. this position paper extends the discussion about the types of knowledge teachers need to apply gai effectively, highlights the need to further develop theoretical frameworks for teachers’ knowledge in the age of gai, and, to address that, suggests ways to extend existing frameworks such as tpack with ai-related dimensions.",https://doi.org/10.1007/s10956-024-10147-3
7a09a3aace49d33f1eeea68ea73facc8219593d0,Generative AI in Undergraduate Medical Education: A Rapid Review,"Generative artificial intelligence (AI) models such as OpenAI's ChatGPT and Google's Bard have forced educators to consider how these tools will be efficiently utilized to improve medical education. This article investigates current literature on how generative AI is and could be used and implemented in undergraduate medical education (UME). A rapid review of the literature was performed utilizing a librarian-generated search strategy to identify articles published before June 30, 2023, in 6 databases (Pubmed, EMBASE.com, Scopus, ERIC via EBSCO, Computer Science Database via EBSCO, and CINAHL via EBSCO). Inclusion criteria were (1) a focus on osteopathic and/or allopathic UME and (2) a defined use or implementation strategy for generative AI. Two reviewers screened all articles, and data extraction was performed by 1 reviewer and confirmed by the other reviewer. A total of 521 relevant articles were screened during this review. Forty-one articles underwent full-text review and data extraction. The majority of the articles were opinion pieces (9), case reports (8), letters to the editor (5), editorials (5), and commentaries (3) about the use of generative AI while 7 articles used qualitative and/or quantitative methods. The literature is best divided into 5 categories of uses for generative AI in UME: nonclinical learning assistant, content developer, virtual patient interaction, clinical decision-making tutor, and medical writing. The literature indicates generative AI tools’ greatest potential is for use as a virtual patient and clinical decision-making tutor. While the possibilities proliferate for generative AI in UME, there remains a dearth of quantitative evidence of its use for improving learner outcomes. The majority of the literature opines the potential for utilization, but only 7 studies formally evaluated the results of using generative AI. Future research should focus on the effectiveness of incorporating generative AI into preclinical and clinical curricula in UME.",2024,"[{'authorId': '2314630317', 'name': 'Joshua D Hale'}, {'authorId': '1840057877', 'name': 'S. Alexander'}, {'authorId': '2314586803', 'name': 'Sarah Towner Wright'}, {'authorId': '2306651430', 'name': 'Kurt Gilliland'}]","{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/23821205241266697', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/23821205241266697?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/23821205241266697, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative artificial intelligence (ai) models such as openai's chatgpt and google's bard have forced educators to consider how these tools will be efficiently utilized to improve medical education. this article investigates current literature on how generative ai is and could be used and implemented in undergraduate medical education (ume). a rapid review of the literature was performed utilizing a librarian-generated search strategy to identify articles published before june 30, 2023, in 6 databases (pubmed, embase.com, scopus, eric via ebsco, computer science database via ebsco, and cinahl via ebsco). inclusion criteria were (1) a focus on osteopathic and/or allopathic ume and (2) a defined use or implementation strategy for generative ai. two reviewers screened all articles, and data extraction was performed by 1 reviewer and confirmed by the other reviewer. a total of 521 relevant articles were screened during this review. forty-one articles underwent full-text review and data extraction. the majority of the articles were opinion pieces (9), case reports (8), letters to the editor (5), editorials (5), and commentaries (3) about the use of generative ai while 7 articles used qualitative and/or quantitative methods. the literature is best divided into 5 categories of uses for generative ai in ume: nonclinical learning assistant, content developer, virtual patient interaction, clinical decision-making tutor, and medical writing. the literature indicates generative ai tools’ greatest potential is for use as a virtual patient and clinical decision-making tutor. while the possibilities proliferate for generative ai in ume, there remains a dearth of quantitative evidence of its use for improving learner outcomes. the majority of the literature opines the potential for utilization, but only 7 studies formally evaluated the results of using generative ai. future research should focus on the effectiveness of incorporating generative ai into preclinical and clinical curricula in ume.",https://journals.sagepub.com/doi/pdf/10.1177/23821205241266697
72b3471f2e54dfafaf7585a2da6cfe261bd32412,Analysing the Impact of Generative AI in Arts Education: A Cross-Disciplinary Perspective of Educators and Students in Higher Education,"Generative AI refers specifically to a class of Artificial Intelligence models that use existing data to create new content that reflects the underlying patterns of real-world data. This contribution presents a study that aims to show what the current perception of arts educators and students of arts education is with regard to generative Artificial Intelligence. It is a qualitative research study using focus groups as a data collection technique in order to obtain an overview of the participating subjects. The research design consists of two phases: (1) generation of illustrations from prompts by students, professionals and a generative AI tool; and (2) focus groups with students (N = 5) and educators (N = 5) of artistic education. In general, the perception of educators and students coincides in the usefulness of generative AI as a tool to support the generation of illustrations. However, they agree that the human factor cannot be replaced by generative AI. The results obtained allow us to conclude that generative AI can be used as a motivating educational strategy for arts education.",2024,"[{'authorId': '2304639030', 'name': 'Sara Sáez-Velasco'}, {'authorId': '2304639032', 'name': 'Mario Alaguero-Rodríguez'}, {'authorId': '2101811559', 'name': 'Vanesa Delgado-Benito'}, {'authorId': '1429806857', 'name': 'S. Rodríguez-Cano'}]","{'url': 'https://www.mdpi.com/2227-9709/11/2/37/pdf?version=1717413188', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/informatics11020037?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/informatics11020037, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative ai refers specifically to a class of artificial intelligence models that use existing data to create new content that reflects the underlying patterns of real-world data. this contribution presents a study that aims to show what the current perception of arts educators and students of arts education is with regard to generative artificial intelligence. it is a qualitative research study using focus groups as a data collection technique in order to obtain an overview of the participating subjects. the research design consists of two phases: (1) generation of illustrations from prompts by students, professionals and a generative ai tool; and (2) focus groups with students (n = 5) and educators (n = 5) of artistic education. in general, the perception of educators and students coincides in the usefulness of generative ai as a tool to support the generation of illustrations. however, they agree that the human factor cannot be replaced by generative ai. the results obtained allow us to conclude that generative ai can be used as a motivating educational strategy for arts education.",https://www.mdpi.com/2227-9709/11/2/37/pdf?version=1717413188
8854d9df65a35670b0b34db371442aa5353c42a5,"Waiting, Banning, and Embracing: An Empirical Analysis of Adapting Policies for Generative AI in Higher Education","Generative AI tools such as ChatGPT have recently gained significant attention in higher education. This study aims to understand how universities establish policies regarding the use of AI tools and explore the factors that influence their decisions. Our study examines ChatGPT policies implemented at universities around the world, including their existence, content, and issuance dates. Specifically, we analyzed the top 500 universities according to the 2022 QS World University Rankings. Our findings indicate that there is significant variation in university policies. Less than one-third of the universities included in the study had implemented ChatGPT policies. Of the universities with ChatGPT policies, approximately 67 percent embraced ChatGPT in teaching and learning, more than twice the number of universities that banned it. The majority of the universities that ban the use of ChatGPT in assessments allow individual instructors to deviate from this restrictive policy. Our empirical analysis identifies several factors that are significantly and positively correlated with a university's likelihood of having a ChatGPT policy, including the university's academic reputation score, being in an English-speaking country, and the general public attitudes toward ChatGPT. In addition, we found that a university's likelihood of having a ban policy is positively associated with faculty student ratio, citations, and the English-speaking country dummy, while negatively associated with the number of peer universities within the same country that have banned ChatGPT. We discuss the challenges faced by universities based our empirical findings.",2023,"[{'authorId': '2069588611', 'name': 'Ping Xiao'}, {'authorId': '1519042387', 'name': 'Yuanyuan Chen'}, {'authorId': '1738345169', 'name': 'Weining Bao'}]","{'url': 'https://arxiv.org/pdf/2305.18617', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2305.18617, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative ai tools such as chatgpt have recently gained significant attention in higher education. this study aims to understand how universities establish policies regarding the use of ai tools and explore the factors that influence their decisions. our study examines chatgpt policies implemented at universities around the world, including their existence, content, and issuance dates. specifically, we analyzed the top 500 universities according to the 2022 qs world university rankings. our findings indicate that there is significant variation in university policies. less than one-third of the universities included in the study had implemented chatgpt policies. of the universities with chatgpt policies, approximately 67 percent embraced chatgpt in teaching and learning, more than twice the number of universities that banned it. the majority of the universities that ban the use of chatgpt in assessments allow individual instructors to deviate from this restrictive policy. our empirical analysis identifies several factors that are significantly and positively correlated with a university's likelihood of having a chatgpt policy, including the university's academic reputation score, being in an english-speaking country, and the general public attitudes toward chatgpt. in addition, we found that a university's likelihood of having a ban policy is positively associated with faculty student ratio, citations, and the english-speaking country dummy, while negatively associated with the number of peer universities within the same country that have banned chatgpt. we discuss the challenges faced by universities based our empirical findings.",https://arxiv.org/pdf/2305.18617
5818893a360d2030c68d1386b6311832ab3fd96a,Generative AI in Computer Science Education,"Generative AI has the potential to become disruptive technology for computer science education. Therefore, computer science educators must be familiar with the threats they should deal with and with the opportunities that generative-AI opens for the computer science education community. In the workshop, we explore the integration of several generative-AI tools and applications in computer science education. Activities include lesson design, code development, test design and assessment. We address the students' and the educators' perspectives. In addition, we explore computer science practices and soft skills to be applied with these tools as well as immediate and future applications and implications for computer science education and for the society. AT the end of the workshop, the participants will be able to use these generative AI tools in their daily educational computer science activities and beyond.",2024,"[{'authorId': '1738207', 'name': 'O. Hazzan'}, {'authorId': '2838770', 'name': 'Yael Erez'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3626253.3633409?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3626253.3633409, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative ai has the potential to become disruptive technology for computer science education. therefore, computer science educators must be familiar with the threats they should deal with and with the opportunities that generative-ai opens for the computer science education community. in the workshop, we explore the integration of several generative-ai tools and applications in computer science education. activities include lesson design, code development, test design and assessment. we address the students' and the educators' perspectives. in addition, we explore computer science practices and soft skills to be applied with these tools as well as immediate and future applications and implications for computer science education and for the society. at the end of the workshop, the participants will be able to use these generative ai tools in their daily educational computer science activities and beyond.",
950054b41a181e14b48c2f9de559f27e2096c89e,Fostering social-emotional learning through human-centered use of generative AI in business research education: an insider case study,"PurposeThis exploratory study innovates the pedagogy of undergraduate business research courses by integrating Generative Artificial Intelligence (GAI) tools, guided by human-centered artificial intelligence, social-emotional learning, and authenticity principles.Design/methodology/approachAn insider case study approach was employed to examine an undergraduate business research course where 72 students utilized GAI for coursework. Thematic analysis was applied to their meta-reflective journals.FindingsStudents leverage GAI tools as brainstorming partners, co-writers, and co-readers, enhancing research efficiency and comprehension. They exhibit authenticity and human-centered AI principles in their GAI engagement. GAI integration imparts relevant AI skills to students.Research limitations/implicationsFuture research could explore how teams collectively interact with GAI tools.Practical implicationsIncorporating meta-reflections can promote responsible GAI usage and develop students' self-awareness, critical thinking, and ethical engagement.Social implicationsOpen discussions about social perceptions and emotional responses surrounding GAI use are necessary. Educators can foster a learning environment that nurtures students' holistic development, preparing them for technological challenges while preserving human learning and growth.Originality/valueThis study fills a gap in exploring the delivery and outcomes of AI-integrated undergraduate education, prioritizing student perspectives over the prevalent focus on educators' viewpoints. Additionally, it examines the teaching and application of AI for undergraduate research, diverging from current studies that primarily focus on research applications for academics.",2024,"[{'authorId': '114833188', 'name': 'P. Aure'}, {'authorId': '2305927428', 'name': 'Oriana Cuenca'}]","{'url': 'https://doi.org/10.1108/jrit-03-2024-0076', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/jrit-03-2024-0076?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/jrit-03-2024-0076, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purposethis exploratory study innovates the pedagogy of undergraduate business research courses by integrating generative artificial intelligence (gai) tools, guided by human-centered artificial intelligence, social-emotional learning, and authenticity principles.design/methodology/approachan insider case study approach was employed to examine an undergraduate business research course where 72 students utilized gai for coursework. thematic analysis was applied to their meta-reflective journals.findingsstudents leverage gai tools as brainstorming partners, co-writers, and co-readers, enhancing research efficiency and comprehension. they exhibit authenticity and human-centered ai principles in their gai engagement. gai integration imparts relevant ai skills to students.research limitations/implicationsfuture research could explore how teams collectively interact with gai tools.practical implicationsincorporating meta-reflections can promote responsible gai usage and develop students' self-awareness, critical thinking, and ethical engagement.social implicationsopen discussions about social perceptions and emotional responses surrounding gai use are necessary. educators can foster a learning environment that nurtures students' holistic development, preparing them for technological challenges while preserving human learning and growth.originality/valuethis study fills a gap in exploring the delivery and outcomes of ai-integrated undergraduate education, prioritizing student perspectives over the prevalent focus on educators' viewpoints. additionally, it examines the teaching and application of ai for undergraduate research, diverging from current studies that primarily focus on research applications for academics.",https://doi.org/10.1108/jrit-03-2024-0076
aa9ebe78fb46ad9db10c6991004d31ced843d0bc,Exploring generative AI in higher education: a RAG system to enhance student engagement with scientific literature,"Introduction This study explores the implementation and evaluation of OwlMentor, an AI-powered learning environment designed to assist university students in comprehending scientific texts. OwlMentor was developed participatorily and then integrated into a course, with development and evaluation taking place over two semesters. It offers features like document-based chats, automatic question generation, and quiz creation. Methods We used the Technology Acceptance Model to assess system acceptance, examined learning outcomes, and explored the influence of general self-efficacy on system acceptance and OwlMentor use. Results The results indicated complex relationships between perceived ease of use, perceived usefulness, and actual use, suggesting the need for more dynamic models of system acceptance. Although no direct correlation between OwlMentor use and learning gains was found, descriptive results indicated higher gains among users compared to non-users. Additionally, general self-efficacy was strongly related to perceived usefulness, intention to use, and actual use of the system. Discussion These findings highlight the importance of aligning AI tools with students’ needs and existing learning strategies to maximize their educational benefits.",2024,"[{'authorId': '2325678827', 'name': 'Dominik Thüs'}, {'authorId': '5515892', 'name': 'Sarah Malone'}, {'authorId': '2791184', 'name': 'Roland Brünken'}]","{'url': '', 'status': None, 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11502405, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","introduction this study explores the implementation and evaluation of owlmentor, an ai-powered learning environment designed to assist university students in comprehending scientific texts. owlmentor was developed participatorily and then integrated into a course, with development and evaluation taking place over two semesters. it offers features like document-based chats, automatic question generation, and quiz creation. methods we used the technology acceptance model to assess system acceptance, examined learning outcomes, and explored the influence of general self-efficacy on system acceptance and owlmentor use. results the results indicated complex relationships between perceived ease of use, perceived usefulness, and actual use, suggesting the need for more dynamic models of system acceptance. although no direct correlation between owlmentor use and learning gains was found, descriptive results indicated higher gains among users compared to non-users. additionally, general self-efficacy was strongly related to perceived usefulness, intention to use, and actual use of the system. discussion these findings highlight the importance of aligning ai tools with students’ needs and existing learning strategies to maximize their educational benefits.",
6f85eeb10da66f7ec35b00a69401ce24036def8e,An Inquiry Into the Use of Generative AI and Its Implications in Education,"The emergence of generative AI technologies has provoked considerable debate among educators regarding their role in education. This study is an investigation of the benefits, disadvantages, and potential strategies for integrating generative AI in educational settings by analyzing societal impacts based on a literature review. We have surveyed the influence of generative AI in education through sources from peer-reviewed journals. The main findings show that generative AI can enhance accessibility and customization in learning for individual learners' needs and pacing. But there are problems with algorithmic biases, discrimination, and data privacy issues, too. This study advocates for mitigating bias, data transparency, and promotion and evaluation of AI policy and research. Generative AI in education hinges on how it is responsibly integrated and observes ethical guidelines, by way of the constant assessment that will guarantee its potential in revolutionizing learning.",2024,"[{'authorId': '2312970491', 'name': 'Eun Ok Baek'}, {'authorId': '2314550765', 'name': 'Romina Villaflor Wilson'}]","{'url': 'https://www.igi-global.com/ViewTitle.aspx?TitleId=349233&isxn=9798369325636', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4018/ijaet.349233?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4018/ijaet.349233, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the emergence of generative ai technologies has provoked considerable debate among educators regarding their role in education. this study is an investigation of the benefits, disadvantages, and potential strategies for integrating generative ai in educational settings by analyzing societal impacts based on a literature review. we have surveyed the influence of generative ai in education through sources from peer-reviewed journals. the main findings show that generative ai can enhance accessibility and customization in learning for individual learners' needs and pacing. but there are problems with algorithmic biases, discrimination, and data privacy issues, too. this study advocates for mitigating bias, data transparency, and promotion and evaluation of ai policy and research. generative ai in education hinges on how it is responsibly integrated and observes ethical guidelines, by way of the constant assessment that will guarantee its potential in revolutionizing learning.",https://www.igi-global.com/ViewTitle.aspx?TitleId=349233&isxn=9798369325636
e8259b5eb429afdb963248dbf1328477baf80951,Media Competence is the key requirement when using Generative AI in Academic Education in a meaningful way,"With the release of ChatGPT, Pandora’s box of generative AI has been opened and the new technology is here to stay. This also impacts academic education, where it provides new opportunities while also bearing certain challenges. Students and educators alike will have to adapt to the newly available technology and find ways to use it in a meaningful and profitable way. Summarized, this means that both parties need to develop media competence in using generative AI on their end in academic education. New ways of learning and teaching are required, as well as a change in how educators grade the students’ learning status. While the latter should be made aware of the opportunities that generative AI provides them with, educators should actively make use of it in their courses in order to enhance their teaching.",2024,"[{'authorId': '1968343', 'name': 'Florian Schimanke'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/aixheart62327.2024.00015?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/aixheart62327.2024.00015, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with the release of chatgpt, pandora’s box of generative ai has been opened and the new technology is here to stay. this also impacts academic education, where it provides new opportunities while also bearing certain challenges. students and educators alike will have to adapt to the newly available technology and find ways to use it in a meaningful and profitable way. summarized, this means that both parties need to develop media competence in using generative ai on their end in academic education. new ways of learning and teaching are required, as well as a change in how educators grade the students’ learning status. while the latter should be made aware of the opportunities that generative ai provides them with, educators should actively make use of it in their courses in order to enhance their teaching.",
79bc4f92fce3284f7fb5eaaf580583901d2eff07,"The Generative AI Landscape in Education: Mapping the Terrain of Opportunities, Challenges, and Student Perception","Generative AI (GAI) technologies like ChatGPT are permanently changing academic education. Their integration opens up vast opportunities for bespoke learning and better student interaction but also brings about academic honesty issues and the application of real-life educators. This study aims to fill the literature gap regarding the use of multiple GAI tools and their effect on academic outcomes via a comprehensive review. A systematic literature review was performed following PRISMA guidelines to synthesize results on the potential and drawbacks of GAI in educational domains. We included theoretical and empirical papers that used qualitative, quantitative, or mixed-methods study designs. We have also explored conceptual frameworks and the most creative AI applications with a special emphasis on uniqueness and practicability. Experiences, and Perceptions Concerning To compile the information needed we gathered insights into what students were going through by conducting the survey which contains 200 respondents of undergraduate university students gathering insights into the college students’ experiences and perceptions related to GAI used for educational purposes. At the basic level, GAI comprises areas like personalization, task automation, teacher assistance, and efficiency among others, and respective solutions for the immersion of a learner in learning processes to reform directions. However, it generates plenty of challenges such as the question of assessment integrity, the risk that too much automated grading could overwhelm educational value, and relevantly the veracity of AI-generated content as well as the potential disruption to skills like critical thinking, in addition to data privacy and ethical issues. Student Perception Survey the text also indicates that most students, as per the student perception survey found AI systems useful in academic support. However, they also know the other side of the coin and are very familiar with the technology constraints and challenges.",2024,"[{'authorId': '2265807839', 'name': 'Zishan Ahmed'}, {'authorId': '2218513880', 'name': 'Shakib Sadat Shanto'}, {'authorId': '2326497913', 'name': 'Most. Humayra Khanom Rime'}, {'authorId': '1575405660', 'name': 'Md. Kishor Morol'}, {'authorId': '2287976859', 'name': 'Nafiz Fahad'}, {'authorId': '152920803', 'name': 'Md.Jakir Hossen'}, {'authorId': '2280578567', 'name': 'Md. Abdullah-Al-Jubair'}]","{'url': 'https://doi.org/10.1109/access.2024.3461874', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2024.3461874?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2024.3461874, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative ai (gai) technologies like chatgpt are permanently changing academic education. their integration opens up vast opportunities for bespoke learning and better student interaction but also brings about academic honesty issues and the application of real-life educators. this study aims to fill the literature gap regarding the use of multiple gai tools and their effect on academic outcomes via a comprehensive review. a systematic literature review was performed following prisma guidelines to synthesize results on the potential and drawbacks of gai in educational domains. we included theoretical and empirical papers that used qualitative, quantitative, or mixed-methods study designs. we have also explored conceptual frameworks and the most creative ai applications with a special emphasis on uniqueness and practicability. experiences, and perceptions concerning to compile the information needed we gathered insights into what students were going through by conducting the survey which contains 200 respondents of undergraduate university students gathering insights into the college students’ experiences and perceptions related to gai used for educational purposes. at the basic level, gai comprises areas like personalization, task automation, teacher assistance, and efficiency among others, and respective solutions for the immersion of a learner in learning processes to reform directions. however, it generates plenty of challenges such as the question of assessment integrity, the risk that too much automated grading could overwhelm educational value, and relevantly the veracity of ai-generated content as well as the potential disruption to skills like critical thinking, in addition to data privacy and ethical issues. student perception survey the text also indicates that most students, as per the student perception survey found ai systems useful in academic support. however, they also know the other side of the coin and are very familiar with the technology constraints and challenges.",https://doi.org/10.1109/access.2024.3461874
4528cdefb03cb84dabdf33ba874dd68a75a8040b,Enhancing Soft Skills through Generative AI in Sustainable Fashion Textile Design Education,"This study explores the significance of incorporating soft skill training in fashion design education through the use of artificial intelligence (AI) technology and examines various AI-based approaches for sustainable fashion textile design education employing a multifaceted methodology that encompasses empirical, quantitative, and qualitative methods. We investigate the aspects of Design Sprints, identify key soft skills that help students meet the complex demands of contemporary fashion design workplaces, propose a curriculum guide for AI textile design programs, and evaluate the soft skill training process. Participants included students who had completed basic fashion design courses over three to four semesters and had experience with the fashion design process. The findings confirmed that participants’ soft skills improved across four areas—digital competence, sense of initiative and entrepreneurship, problem-solving and thinking skills, and communication—through the AI-based fashion textile design curriculum. This study validates the importance of integrating AI technology into educational programs to enhance essential soft skills in the digital fashion industry environment. Additionally, it emphasizes the necessity of developing AI technology-specialized design prompts while maintaining a balance between traditional design education and digital design education for sustainable fashion design education.",2024,"[{'authorId': '2280468262', 'name': 'Dawool Jung'}, {'authorId': '2280430151', 'name': 'Sungeun Suh'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su16166973?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su16166973, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study explores the significance of incorporating soft skill training in fashion design education through the use of artificial intelligence (ai) technology and examines various ai-based approaches for sustainable fashion textile design education employing a multifaceted methodology that encompasses empirical, quantitative, and qualitative methods. we investigate the aspects of design sprints, identify key soft skills that help students meet the complex demands of contemporary fashion design workplaces, propose a curriculum guide for ai textile design programs, and evaluate the soft skill training process. participants included students who had completed basic fashion design courses over three to four semesters and had experience with the fashion design process. the findings confirmed that participants’ soft skills improved across four areas—digital competence, sense of initiative and entrepreneurship, problem-solving and thinking skills, and communication—through the ai-based fashion textile design curriculum. this study validates the importance of integrating ai technology into educational programs to enhance essential soft skills in the digital fashion industry environment. additionally, it emphasizes the necessity of developing ai technology-specialized design prompts while maintaining a balance between traditional design education and digital design education for sustainable fashion design education.",
377a4e0a141eb16b77a7f63bb36e6ae6fe4125dc,Generative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions,"This study investigates how LLMs, specifically GPT-3.5 and GPT-4, can develop tailored questions for Grade 9 math, aligning with active learning principles. By utilizing an iterative method, these models adjust questions based on difficulty and content, responding to feedback from a simulated 'student' model. A novel aspect of the research involved using GPT-4 as a 'teacher' to create complex questions, with GPT-3.5 as the 'student' responding to these challenges. This setup mirrors active learning, promoting deeper engagement. The findings demonstrate GPT-4's superior ability to generate precise, challenging questions and notable improvements in GPT-3.5's ability to handle more complex problems after receiving instruction from GPT-4. These results underscore the potential of LLMs to mimic and enhance active learning scenarios, offering a promising path for AI in customized education. This research contributes to understanding how AI can support personalized learning experiences, highlighting the need for further exploration in various educational contexts",2024,"[{'authorId': '2307469177', 'name': 'Hamdireza Rouzegar'}, {'authorId': '2277529590', 'name': 'Masoud Makrehchi'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2406.13903, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study investigates how llms, specifically gpt-3.5 and gpt-4, can develop tailored questions for grade 9 math, aligning with active learning principles. by utilizing an iterative method, these models adjust questions based on difficulty and content, responding to feedback from a simulated 'student' model. a novel aspect of the research involved using gpt-4 as a 'teacher' to create complex questions, with gpt-3.5 as the 'student' responding to these challenges. this setup mirrors active learning, promoting deeper engagement. the findings demonstrate gpt-4's superior ability to generate precise, challenging questions and notable improvements in gpt-3.5's ability to handle more complex problems after receiving instruction from gpt-4. these results underscore the potential of llms to mimic and enhance active learning scenarios, offering a promising path for ai in customized education. this research contributes to understanding how ai can support personalized learning experiences, highlighting the need for further exploration in various educational contexts",
540edd16e21cf8c684c6334696bd87eb19ed4763,Unveiling Generative AI in Higher Education: Insights from Engineering Students and Professors,"The widespread use of Generative Artificial Intelligence (GenAI) tools in higher education, particularly among university students, has raised ethical concerns regarding unintentional plagiarism. Although these tools offer benefits such as time-saving and improved quality, with over 100 available applications, they may inadvertently include borrowed content, posing challenges to academic integrity. Ethical concerns arise within educational institutions, faculty, and integrity committees, complicating evaluations of originality. To address these concerns, universities must establish clear guidelines and educational programs for responsible use of GenAI applications. Educators need to remain current with the latest AI technologies, become proficient in their use, and utilize advanced techniques to teach students how to use them appropriately. This mixed-methods study examines undergraduate engineering students' understanding of GenAI, its usage and ethical implications. The findings demonstrate that ChatGPT is the most popular GenAI application among the students, but also highlight the professors' unfavorable attitudes towards GenAI. The study endeavors to improve understanding of perspectives on GenAI in higher education, facilitating responsible technology integration in classrooms and fostering students' ethical growth. The investigation provides valuable insights for professors, institutions, and research communities engaged in student development and educational advancement. This study also shows a panorama of strategies that could be implemented by teachers to incorporate GenAI in higher education.",2024,"[{'authorId': '2048824308', 'name': 'Nicia Guillén Yparrea'}, {'authorId': '2227718307', 'name': 'Felipe Hernández-Rodríguez'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/EDUCON60312.2024.10578876?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/EDUCON60312.2024.10578876, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the widespread use of generative artificial intelligence (genai) tools in higher education, particularly among university students, has raised ethical concerns regarding unintentional plagiarism. although these tools offer benefits such as time-saving and improved quality, with over 100 available applications, they may inadvertently include borrowed content, posing challenges to academic integrity. ethical concerns arise within educational institutions, faculty, and integrity committees, complicating evaluations of originality. to address these concerns, universities must establish clear guidelines and educational programs for responsible use of genai applications. educators need to remain current with the latest ai technologies, become proficient in their use, and utilize advanced techniques to teach students how to use them appropriately. this mixed-methods study examines undergraduate engineering students' understanding of genai, its usage and ethical implications. the findings demonstrate that chatgpt is the most popular genai application among the students, but also highlight the professors' unfavorable attitudes towards genai. the study endeavors to improve understanding of perspectives on genai in higher education, facilitating responsible technology integration in classrooms and fostering students' ethical growth. the investigation provides valuable insights for professors, institutions, and research communities engaged in student development and educational advancement. this study also shows a panorama of strategies that could be implemented by teachers to incorporate genai in higher education.",
a40dca801310badf6516bc97138d1ea4dba7f9ad,Co-creating digital art with generative AI in K-9 education: Socio-material insights,"The rise of image-generating artificial intelligence (AI) tools has triggered changes in digital art and graphic design, provoking debates in the creative industry. However, scant research exists about children’s and youths’ insights into and encounters with generative AI. Building on sociocultural and new materialist perspectives, this exploratory study proposed to address this gap by exploring middle schoolers’ (N = 10) creative interaction with generative AI, particularly with text-to-image generative models. Qualitative content analyses of emerging learning activities evidenced how generative AI-formed relations were externalized through novel digital artefacts and collaborative discussions. Ideas evolved through peer collaboration organized around creative making with AI. Teachers facilitated relations between people and technology using dialogic teaching, providing room for unpredictability and critical reflection on the impacts of generative AI, especially authorship and copyright. The study concludes with a discussion of the potential uses of generative AI in future art education research and practice.",2023,"[{'authorId': '2405282', 'name': 'Henriikka Vartiainen'}, {'authorId': '144523037', 'name': 'M. Tedre'}, {'authorId': '1791529', 'name': 'I. Jormanainen'}]","{'url': 'https://doi.org/10.1386/eta_00143_1', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1386/eta_00143_1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1386/eta_00143_1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the rise of image-generating artificial intelligence (ai) tools has triggered changes in digital art and graphic design, provoking debates in the creative industry. however, scant research exists about children’s and youths’ insights into and encounters with generative ai. building on sociocultural and new materialist perspectives, this exploratory study proposed to address this gap by exploring middle schoolers’ (n = 10) creative interaction with generative ai, particularly with text-to-image generative models. qualitative content analyses of emerging learning activities evidenced how generative ai-formed relations were externalized through novel digital artefacts and collaborative discussions. ideas evolved through peer collaboration organized around creative making with ai. teachers facilitated relations between people and technology using dialogic teaching, providing room for unpredictability and critical reflection on the impacts of generative ai, especially authorship and copyright. the study concludes with a discussion of the potential uses of generative ai in future art education research and practice.",https://doi.org/10.1386/eta_00143_1
a473daa76804522c3cf2b3eb0ec1733a5522a889,Generative AI in CS Education: Literature Review through a SWOT Lens,"The rapid growth of generative artificial intelligence (AI) models introduced challenges for educators, students and administrators across the academic sphere related to how to manage and regulate these tools. While some oppose their use, many researchers have begun to approach the topic of educational AI use from a different perspective. Despite being in its early stages; this field of research has produced notable insights into the capabilities and limitations of models like ChatGPT. This paper utilizes a SWOT analysis framework to analyze and consolidate existing literature, with a specific focus on Computer Science education. Through the analysis of this literature, we have created a set of use cases and guidelines to aid in the future development of strategies and tools within this field. Our findings indicate that while some concerns are valid, such as AI's ability to generate plagiarized work, we identified several promising avenues and opportunities for careful integration of this technology into education.",2024,"[{'authorId': '2307998488', 'name': 'Jordan Roberts'}, {'authorId': '2307989641', 'name': 'Abdallah Mohamed'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3660650.3660657?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3660650.3660657, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the rapid growth of generative artificial intelligence (ai) models introduced challenges for educators, students and administrators across the academic sphere related to how to manage and regulate these tools. while some oppose their use, many researchers have begun to approach the topic of educational ai use from a different perspective. despite being in its early stages; this field of research has produced notable insights into the capabilities and limitations of models like chatgpt. this paper utilizes a swot analysis framework to analyze and consolidate existing literature, with a specific focus on computer science education. through the analysis of this literature, we have created a set of use cases and guidelines to aid in the future development of strategies and tools within this field. our findings indicate that while some concerns are valid, such as ai's ability to generate plagiarized work, we identified several promising avenues and opportunities for careful integration of this technology into education.",
93f5ad3da6c289e7973519ebe81f97ff272e6224,Explore Public's Perspectives on Generative AI in Computer Science (CS) Education: A Social Media Data Analysis,"This research-to-practice full paper aims to analyze the public's comments on generative artificial intelligence (GAI) in computer science (CS) education, by the BERT-based model and Large Language Model (LLM) approaches to sentiment analysis and contextualize the results within broader educational and technological landscapes. Artificial intelligence (AI) has played a crucial role in advancing technical development throughout many areas. Evidence points toward the likelihood of major developmental breakthroughs unfolding soon in those sectors. Education is one such area. While there is certainly a possibility for hype and unfulfilled promises, the advent of available GAI platforms, such as ChatGPT, has caused a surge of scholarly interest in the impact of these technologies on CS education. Amid the growing debate, both the potential benefits and concerns of GAI in this sector are increasingly coming to the fore as people grapple with the tradeoffs associated with these technologies when applied in education settings. One can imagine the range of conversations around the topic, but that is difficult to use as input for policymakers and administrators without a more concrete understanding. To wit, there remain open questions about which benefits and concerns people tend to focus on when discussing GAI in education. This large-scale qualitative study addresses that gap by exploring the public's perspectives on GAI in CS education. We engage in this work by collecting and analyzing data from social media platforms, specifically Reddit comments. The social media dataset was analyzed using machine learning (ML) techniques to identify topics based on sentiment analysis. The study's objective was to document and characterize the public's perspectives concerning the general characteristics of GAI, its features related to learning, and its usability in educational settings. Through sentiment analysis using Large Language Models (LLM), the study revealed an overall positive public perception toward using generative AI in CS education, with over 57% of comments being favorable, while also identifying prominent topics of interest and concerns, such as the potential benefits of personalized learning support and automated grading, as well as issues like academic dishonesty, perpetuation of biases, over-reliance on AI hindering critical thinking, displacement of human instructors, and the need for updated curricula. The insights gleaned from the analysis will be instrumental in computing educators gaining a more profound comprehension of GAI 'srole in education and the subsequent development of GAI -enriched curricula.",2024,"[{'authorId': '2347335347', 'name': 'Sunggyeol Oh'}, {'authorId': '2347395871', 'name': 'Yi Cao'}, {'authorId': '2271693389', 'name': 'Andrew Katz'}, {'authorId': '2347442756', 'name': 'Jialu Zhao'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/FIE61694.2024.10893102?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/FIE61694.2024.10893102, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this research-to-practice full paper aims to analyze the public's comments on generative artificial intelligence (gai) in computer science (cs) education, by the bert-based model and large language model (llm) approaches to sentiment analysis and contextualize the results within broader educational and technological landscapes. artificial intelligence (ai) has played a crucial role in advancing technical development throughout many areas. evidence points toward the likelihood of major developmental breakthroughs unfolding soon in those sectors. education is one such area. while there is certainly a possibility for hype and unfulfilled promises, the advent of available gai platforms, such as chatgpt, has caused a surge of scholarly interest in the impact of these technologies on cs education. amid the growing debate, both the potential benefits and concerns of gai in this sector are increasingly coming to the fore as people grapple with the tradeoffs associated with these technologies when applied in education settings. one can imagine the range of conversations around the topic, but that is difficult to use as input for policymakers and administrators without a more concrete understanding. to wit, there remain open questions about which benefits and concerns people tend to focus on when discussing gai in education. this large-scale qualitative study addresses that gap by exploring the public's perspectives on gai in cs education. we engage in this work by collecting and analyzing data from social media platforms, specifically reddit comments. the social media dataset was analyzed using machine learning (ml) techniques to identify topics based on sentiment analysis. the study's objective was to document and characterize the public's perspectives concerning the general characteristics of gai, its features related to learning, and its usability in educational settings. through sentiment analysis using large language models (llm), the study revealed an overall positive public perception toward using generative ai in cs education, with over 57% of comments being favorable, while also identifying prominent topics of interest and concerns, such as the potential benefits of personalized learning support and automated grading, as well as issues like academic dishonesty, perpetuation of biases, over-reliance on ai hindering critical thinking, displacement of human instructors, and the need for updated curricula. the insights gleaned from the analysis will be instrumental in computing educators gaining a more profound comprehension of gai 'srole in education and the subsequent development of gai -enriched curricula.",
265f224956509bf10a69e7a64c2df70a67e82008,"Unleashing the Potential of Generative AI, Conversational Agents and Chatbots in Educational Praxis: A Systematic Review and Bibliometric Analysis of GenAI in Education","In the rapidly evolving landscape of education, the pivotal axis around which transformation revolves is human-AI interaction. In this sense, this paper adopts a data mining and analytic approach to understand what the related literature tells us regarding the trends and patterns of generative AI research in educational praxis. Accordingly",2023,"[{'authorId': '2257383429', 'name': 'Aras Bozkurt'}]","{'url': 'https://storage.googleapis.com/jnl-up-j-op-files/journals/1/articles/609/655cc015844da.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.55982/openpraxis.15.4.609?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55982/openpraxis.15.4.609, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the rapidly evolving landscape of education, the pivotal axis around which transformation revolves is human-ai interaction. in this sense, this paper adopts a data mining and analytic approach to understand what the related literature tells us regarding the trends and patterns of generative ai research in educational praxis. accordingly",https://storage.googleapis.com/jnl-up-j-op-files/journals/1/articles/609/655cc015844da.pdf
e4da28797bdef76e449f9adc9e605b656f878df3,Introduction to Generative AI and its application in Education,"Abstract: Generative AI has made significant progress in re- cent years, with a growing range of applications in a variety of fields. Generative AI applications have catalyzed a new erain the synthesis and manipulation of digital content. Genera- tive AIis very recent technology which changed the way tradi-tional search engines work. The search engines work on the principles of information retrieval. However, openGL came up with use of Artificial Intelligence (AI) for synthesis of digital content and launched well known asChatGPT. The GenerativeAI differsfrom traditional AL as it takes text ,audio ,video andusing knowledge it generates new content in any form namely the text, audio or video. The generative AI has many profound applications. Generative AI is a rapidly developing field with the potential to revolutionize many industries and aspects of our lives. As the technology continues to advance, we can ex- pect to see even more groundbreaking and transformative ap-plications emerge. In this paper the introduction to GenerativeAI is detailed along with how generative AI can be used in ed-ucation.",2024,"[{'authorId': '2280221085', 'name': 'Mr. Rohit B. Uppin'}]","{'url': 'https://doi.org/10.22214/ijraset.2024.57563', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.22214/ijraset.2024.57563?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.22214/ijraset.2024.57563, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract: generative ai has made significant progress in re- cent years, with a growing range of applications in a variety of fields. generative ai applications have catalyzed a new erain the synthesis and manipulation of digital content. genera- tive aiis very recent technology which changed the way tradi-tional search engines work. the search engines work on the principles of information retrieval. however, opengl came up with use of artificial intelligence (ai) for synthesis of digital content and launched well known aschatgpt. the generativeai differsfrom traditional al as it takes text ,audio ,video andusing knowledge it generates new content in any form namely the text, audio or video. the generative ai has many profound applications. generative ai is a rapidly developing field with the potential to revolutionize many industries and aspects of our lives. as the technology continues to advance, we can ex- pect to see even more groundbreaking and transformative ap-plications emerge. in this paper the introduction to generativeai is detailed along with how generative ai can be used in ed-ucation.",https://doi.org/10.22214/ijraset.2024.57563
2ad4b8e914798f8e258ca55f0b233c70bc8a45de,Generative AI in the Australian education system: An open data set of stakeholder recommendations and emerging analysis from a public inquiry,"The launch of new tools in late 2022 heralded significant growth in attention to the impacts of generative AI (GenAI) in education. Claims of the potential impact on education are contested, but there are clear risks of inappropriate use particularly where GenAI aligns poorly with learning aims. In response, in mid-2023, the Australian Federal Government held an inquiry, calling for public submissions. This inquiry offers a lens onto the policy framing of GenAI in education and provides the object of investigation for this paper. We use the inquiry submissions, extracting structured claims from each. This extraction is provided as an open data set for further research, while this paper focuses on our analysis of the policy recommendations made.
Implications for practice or policy

For practitioners, policymakers, and researchers. the paper provides an overview and synthesis of submission recommendations and their themes, by source type.
For respondents to the inquiry (sources), the paper supports reflection regarding synergies and gaps in recommendations, pointing to opportunity for collaboration and policy development.
For stakeholders with responsibility for aspects of policy delivery and/or those applying a critical lens to the inquiry and recommendation framing(s), the paper offers actionable insight.
",2023,"[{'authorId': '2276083195', 'name': 'Simon Knight'}, {'authorId': '2276098724', 'name': 'Camille Dickson-Deane'}, {'authorId': '67126957', 'name': 'Keith Heggart'}, {'authorId': '3030366', 'name': 'Kirsty Kitto'}, {'authorId': '2276084705', 'name': 'Dilek Çetindamar Kozanoğlu'}, {'authorId': '2276080478', 'name': 'Damian Maher'}, {'authorId': '35105737', 'name': 'Bhuva Narayan'}, {'authorId': '1580486778', 'name': 'Forooq Zarrabi'}]","{'url': 'https://ajet.org.au/index.php/AJET/article/download/8922/2052', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.14742/ajet.8922?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.14742/ajet.8922, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the launch of new tools in late 2022 heralded significant growth in attention to the impacts of generative ai (genai) in education. claims of the potential impact on education are contested, but there are clear risks of inappropriate use particularly where genai aligns poorly with learning aims. in response, in mid-2023, the australian federal government held an inquiry, calling for public submissions. this inquiry offers a lens onto the policy framing of genai in education and provides the object of investigation for this paper. we use the inquiry submissions, extracting structured claims from each. this extraction is provided as an open data set for further research, while this paper focuses on our analysis of the policy recommendations made. implications for practice or policy for practitioners, policymakers, and researchers. the paper provides an overview and synthesis of submission recommendations and their themes, by source type. for respondents to the inquiry (sources), the paper supports reflection regarding synergies and gaps in recommendations, pointing to opportunity for collaboration and policy development. for stakeholders with responsibility for aspects of policy delivery and/or those applying a critical lens to the inquiry and recommendation framing(s), the paper offers actionable insight.",https://ajet.org.au/index.php/AJET/article/download/8922/2052
ee880472b182ccd810e762f82b6f39e74cd5dc80,Hybrid design for sports data visualization using AI and big data analytics,"In sports data analysis and visualization, understanding collective tactical behavior has become an integral part. Interactive and automatic data analysis is instrumental in making use of growing amounts of compound information. In professional team sports, gathering and analyzing sportsperson monitoring data are common practice, intending to evaluate fatigue and succeeding adaptation responses, analyze performance potential, and reduce injury and illness risk. Data visualization technology born in the era of big data analytics provides a good foundation for further developing fitness tools based on artificial intelligence (AI). Hence, this study proposed a video-based effective visualization framework (VEVF) based on artificial intelligence and big data analytics. This study uses the machine learning method to categorize the sports video by extracting both the videos' temporal and spatial features. Our system is based on convolutional neural networks united with temporal pooling layers. The experimental outcomes demonstrate that the recommended VEVF model enhances the accuracy ratio of 98.7%, recall ratio of 94.5%, F1-score ratio of 97.9%, the precision ratio of 96.7%, the error rate of 29.1%, the performance ratio of 95.2%, an efficiency ratio of 96.1% compared to other existing models.",2021,"[{'authorId': '46263395', 'name': 'Aijun Liu'}, {'authorId': '9114530', 'name': 'R. Mahapatra'}, {'authorId': '9408508', 'name': 'A. Mayuri'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s40747-021-00557-w.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s40747-021-00557-w?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s40747-021-00557-w, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in sports data analysis and visualization, understanding collective tactical behavior has become an integral part. interactive and automatic data analysis is instrumental in making use of growing amounts of compound information. in professional team sports, gathering and analyzing sportsperson monitoring data are common practice, intending to evaluate fatigue and succeeding adaptation responses, analyze performance potential, and reduce injury and illness risk. data visualization technology born in the era of big data analytics provides a good foundation for further developing fitness tools based on artificial intelligence (ai). hence, this study proposed a video-based effective visualization framework (vevf) based on artificial intelligence and big data analytics. this study uses the machine learning method to categorize the sports video by extracting both the videos' temporal and spatial features. our system is based on convolutional neural networks united with temporal pooling layers. the experimental outcomes demonstrate that the recommended vevf model enhances the accuracy ratio of 98.7%, recall ratio of 94.5%, f1-score ratio of 97.9%, the precision ratio of 96.7%, the error rate of 29.1%, the performance ratio of 95.2%, an efficiency ratio of 96.1% compared to other existing models.",https://link.springer.com/content/pdf/10.1007/s40747-021-00557-w.pdf
5b2a735425993daafe7234fae8cd9d3aa2959023,Sports Analytics Using Probabilistic Model Checking and Deep Learning,"Sports analytics encompasses the use of data science, AI, psychology, and IoT devices to improve sports performance, strategy, and decision-making. It involves collecting, processing, and interpreting data from various sources such as video recordings and scouting reports. The data is used to evaluate player and team performance, prevent injuries, and help coaches make informed decisions in game and training. We adopt Probabilistic Model Checking (PMC), a method commonly used in reliability analysis for complex safety systems, and explain how this method can be applied to sports strategy analytics to increase the chance of winning by taking into account the reliability of a player’s specific sub-skill sets. This paper describes how we have integrated PMC, machine learning, and computer vision to develop a new and complex system for sports strategy analytics. Finally, we discuss the vision of a new series of international sports analytics conferences (https://formal-analysis.com/isace/2023/).",2023,"[{'authorId': '2152487387', 'name': 'J. Dong'}, {'authorId': '2052123792', 'name': 'Kan Jiang'}, {'authorId': '2267876688', 'name': 'Zhaoyu Liu'}, {'authorId': '2268203771', 'name': 'Chen Dong'}, {'authorId': '2267761050', 'name': 'Zhe Hou'}, {'authorId': '2182246298', 'name': 'Rajdeep Singh Hundal'}, {'authorId': '2267951226', 'name': 'Jingyu Guo'}, {'authorId': '2268019310', 'name': 'Yun Lin'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICECCS59891.2023.00011?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICECCS59891.2023.00011, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","sports analytics encompasses the use of data science, ai, psychology, and iot devices to improve sports performance, strategy, and decision-making. it involves collecting, processing, and interpreting data from various sources such as video recordings and scouting reports. the data is used to evaluate player and team performance, prevent injuries, and help coaches make informed decisions in game and training. we adopt probabilistic model checking (pmc), a method commonly used in reliability analysis for complex safety systems, and explain how this method can be applied to sports strategy analytics to increase the chance of winning by taking into account the reliability of a player’s specific sub-skill sets. this paper describes how we have integrated pmc, machine learning, and computer vision to develop a new and complex system for sports strategy analytics. finally, we discuss the vision of a new series of international sports analytics conferences (https://formal-analysis.com/isace/2023/).",
23e794183ab08e000d74b2cdc76c2067d326b5d1,AI Powered Predictive Analytics in Fantasy Sports and Gambling,"Artificial Intelligence is being leveraged by many sports organizations today to enhance fan engagement and loyalty. AL and ML are two power houses that take fantasy sports and gambling to an unimaginable extent. Machine Learning and Predictive Analytics are subsets of Artificial Intelligence. This paper will discuss how Predictive Analytics plays a role in sports enthusiasts, some limitations to its application and overall recommendations. Sports industry today stands to benefit from effectively using the data that AI collects and processes; this paper shows some case studies that illustrates the application.",2024,"[{'authorId': '2351364214', 'name': 'Srinivas Balasubramanian'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.54660/.ijmrge.2024.5.1.1422-1424?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.54660/.ijmrge.2024.5.1.1422-1424, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","artificial intelligence is being leveraged by many sports organizations today to enhance fan engagement and loyalty. al and ml are two power houses that take fantasy sports and gambling to an unimaginable extent. machine learning and predictive analytics are subsets of artificial intelligence. this paper will discuss how predictive analytics plays a role in sports enthusiasts, some limitations to its application and overall recommendations. sports industry today stands to benefit from effectively using the data that ai collects and processes; this paper shows some case studies that illustrates the application.",
71fd81b5f9158055603c96556e97de5d8e17edf6,The Role of Artificial Intelligence in Enhancing Sports Analytics and Training,"The impact of artificial intelligence (AI) is clear and highly influential in many areas of sports, helping to improve team and player results. Not only that, but artificial intelligence has been introduced into the areas of training and analysis of data and results, emulating and presenting potential hypothetical scenarios through the capabilities employed in artificial intelligence to enable accurate and effective training in emergency and critical situations. Another major benefit of using AI in sports is to analyze data and game stats to improve team performance in future games. Improved good decision making capability has made using artificial intelligence applications to gain huge popularity and attention in both academia and industry especially in sports industry. The main problem associated with using Artificial Intelligence applications is sports is that the usefulness of AI for many sports viewers, experts, coaches, team managers, and policy makers is not clear especially when they are not particularly familiar or expert in the field of AI. Similarly, for many, the reasons for employing AI and machine learning (ML) models for mathematical analysis in areas such as sports remain lackluster or unclear. In this research paper the authors present a review in the importance of using AI applications in sports for the people involved in the sports industry in general and especially for the Iraqi academic staff and those working in the sports field. The stake holders and the parties involved need to learn how to use the principles of AI knowledge, and conduct research to improve the performance of Iraqi teams and player.",2024,"[{'authorId': '2150435826', 'name': 'Adil H. Mohammed'}, {'authorId': '2174695370', 'name': 'Zhian J. Othman'}, {'authorId': '2309138281', 'name': 'Abdulqadir I. Abdullah'}]","{'url': 'https://journals.cihanuniversity.edu.iq/index.php/cuesj/article/download/1155/405', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.24086/cuesj.v8n1y2024.pp58-62?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.24086/cuesj.v8n1y2024.pp58-62, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the impact of artificial intelligence (ai) is clear and highly influential in many areas of sports, helping to improve team and player results. not only that, but artificial intelligence has been introduced into the areas of training and analysis of data and results, emulating and presenting potential hypothetical scenarios through the capabilities employed in artificial intelligence to enable accurate and effective training in emergency and critical situations. another major benefit of using ai in sports is to analyze data and game stats to improve team performance in future games. improved good decision making capability has made using artificial intelligence applications to gain huge popularity and attention in both academia and industry especially in sports industry. the main problem associated with using artificial intelligence applications is sports is that the usefulness of ai for many sports viewers, experts, coaches, team managers, and policy makers is not clear especially when they are not particularly familiar or expert in the field of ai. similarly, for many, the reasons for employing ai and machine learning (ml) models for mathematical analysis in areas such as sports remain lackluster or unclear. in this research paper the authors present a review in the importance of using ai applications in sports for the people involved in the sports industry in general and especially for the iraqi academic staff and those working in the sports field. the stake holders and the parties involved need to learn how to use the principles of ai knowledge, and conduct research to improve the performance of iraqi teams and player.",https://journals.cihanuniversity.edu.iq/index.php/cuesj/article/download/1155/405
0b41ffc38da09fb832646e9813f4344ebfa6dee5,A novel explainable artificial intelligence framework using knockoffs techniques with applications to sports analytics,"
 The rapid integration of black-box Machine Learning (ML) models into critical decision-making scenarios has triggered an urgent call for transparency from stakeholders in Artificial Intelligence (AI). This call stems from growing concerns about the deployment of models whose decisions lack justification, legitimacy, and detailed explanations of their behavior. To address these concerns, Explainable Artificial Intelligence (XAI) has emerged as a crucial field, focusing on methods and processes that enable the comprehension of how AI systems make decisions, generate predictions, and execute their functions. The importance of XAI lies in its ability to provide explanations that justify a model’s outputs, thereby ensuring trust and accountability in AI systems. In this work, we propose a novel XAI framework that leverages state-of-the-art statistical knockoff techniques to identify the most informative predictors while maintaining a controlled False Discovery Rate (FDR). This framework enhances informed decision-making by ensuring robust and interpretable insights. We validate our approach through synthetic data experiments, demonstrating that it can effectively identify important features with high power while providing finite-sample FDR control across various scenarios. We demonstrate the efficacy of our approach by applying it to predict the outcomes of National Football League (NFL) playoffs, a domain of significant importance in sports analytics. Our method provides invaluable insights that support strategic decision-making in the highly competitive field of professional football.",2025,"[{'authorId': '2357716739', 'name': 'Tingting Zhao'}, {'authorId': '2354789520', 'name': 'Jeffrey Cabral'}, {'authorId': '2260842796', 'name': 'Guangyu Zhu'}]","{'url': 'https://doi.org/10.1007/s10479-025-06575-y', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10479-025-06575-y?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10479-025-06575-y, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the rapid integration of black-box machine learning (ml) models into critical decision-making scenarios has triggered an urgent call for transparency from stakeholders in artificial intelligence (ai). this call stems from growing concerns about the deployment of models whose decisions lack justification, legitimacy, and detailed explanations of their behavior. to address these concerns, explainable artificial intelligence (xai) has emerged as a crucial field, focusing on methods and processes that enable the comprehension of how ai systems make decisions, generate predictions, and execute their functions. the importance of xai lies in its ability to provide explanations that justify a model’s outputs, thereby ensuring trust and accountability in ai systems. in this work, we propose a novel xai framework that leverages state-of-the-art statistical knockoff techniques to identify the most informative predictors while maintaining a controlled false discovery rate (fdr). this framework enhances informed decision-making by ensuring robust and interpretable insights. we validate our approach through synthetic data experiments, demonstrating that it can effectively identify important features with high power while providing finite-sample fdr control across various scenarios. we demonstrate the efficacy of our approach by applying it to predict the outcomes of national football league (nfl) playoffs, a domain of significant importance in sports analytics. our method provides invaluable insights that support strategic decision-making in the highly competitive field of professional football.",https://doi.org/10.1007/s10479-025-06575-y
7eaadd7b27b1924100ce5a4957efec61aa556b98,Analysis of Unsupervised Consumption Anomaly Detection in Sports Facilities using Artificial Intelligence-Based Data Analytics: A Case Study,"Sports facilities have exceptionally high energy demand due to the extensive operational requirements and high-occupancy seasonal rates. Towards promoting efficient energy usage and minimal losses, consumption anomaly detection in sports facilities is addressed in this work using Artificial intelligence (AI)-based analytics approaches. Traditional AI-based data analytics approaches are applied in a practical context for a local sports complex. The actual unlabeled operation data of the facility are used and a case-specific comparative analysis of the various approaches is presented where AI-based data labeling is used. The characteristics of the different algorithms are contextually discussed. It was found that the size and distribution of the training datasets influence the performance of the different algorithms. This study represents preliminary findings on the topic with a promising potential for further research.",2023,"[{'authorId': '32424055', 'name': 'Mariam Elnour'}, {'authorId': '47647355', 'name': 'F. Fadli'}, {'authorId': '1919083', 'name': 'N. Meskin'}, {'authorId': '48585368', 'name': 'I. Petri'}, {'authorId': '1757067', 'name': 'Y. Rezgui'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3587716.3587749?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3587716.3587749, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","sports facilities have exceptionally high energy demand due to the extensive operational requirements and high-occupancy seasonal rates. towards promoting efficient energy usage and minimal losses, consumption anomaly detection in sports facilities is addressed in this work using artificial intelligence (ai)-based analytics approaches. traditional ai-based data analytics approaches are applied in a practical context for a local sports complex. the actual unlabeled operation data of the facility are used and a case-specific comparative analysis of the various approaches is presented where ai-based data labeling is used. the characteristics of the different algorithms are contextually discussed. it was found that the size and distribution of the training datasets influence the performance of the different algorithms. this study represents preliminary findings on the topic with a promising potential for further research.",
3ff5653c82841f700ca5997091119cad0ea11d6d,Cricket Match Analytics Using the Big Data Approach,"Cricket is one of the most liked, played, encouraged, and exciting sports in today’s time that requires a proper advancement with machine learning and artificial intelligence (AI) to attain more accuracy. With the increasing number of matches with time, the data related to cricket matches and the individual player are increasing rapidly. Moreover, the need of using big data analytics and the opportunities of utilizing this big data effectively in many beneficial ways are also increasing, such as the selection process of players in the team, predicting the winner of the match, and many more future predictions using some machine learning models or big data techniques. We applied the machine learning linear regression model to predict the team scores without big data and the big data framework Spark ML. The experimental results are measured through accuracy, the root mean square error (RMSE), mean square error (MSE), and mean absolute error (MAE), respectively 95%, 30.2, 1350.34, and 28.2 after applying linear regression in Spark ML. Furthermore, our approach can be applied to other sports.",2021,"[{'authorId': '1476819061', 'name': 'Mazhar Javed Awan'}, {'authorId': '2133747890', 'name': 'Syed Arbaz Haider Gilani'}, {'authorId': '2133746995', 'name': 'Hamza Ramzan'}, {'authorId': '2185882168', 'name': 'Haitham Nobanee'}, {'authorId': '2090326025', 'name': 'Awais Yasin'}, {'authorId': '1768864', 'name': 'A. Zain'}, {'authorId': '49529822', 'name': 'R. Javed'}]","{'url': 'https://www.mdpi.com/2079-9292/10/19/2350/pdf?version=1632731546', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/electronics10192350?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/electronics10192350, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cricket is one of the most liked, played, encouraged, and exciting sports in today’s time that requires a proper advancement with machine learning and artificial intelligence (ai) to attain more accuracy. with the increasing number of matches with time, the data related to cricket matches and the individual player are increasing rapidly. moreover, the need of using big data analytics and the opportunities of utilizing this big data effectively in many beneficial ways are also increasing, such as the selection process of players in the team, predicting the winner of the match, and many more future predictions using some machine learning models or big data techniques. we applied the machine learning linear regression model to predict the team scores without big data and the big data framework spark ml. the experimental results are measured through accuracy, the root mean square error (rmse), mean square error (mse), and mean absolute error (mae), respectively 95%, 30.2, 1350.34, and 28.2 after applying linear regression in spark ml. furthermore, our approach can be applied to other sports.",https://www.mdpi.com/2079-9292/10/19/2350/pdf?version=1632731546
37f9614ce4ddf6a0992ba4a6f506abf69e265d86,"Algorithmic fandom: how generative AI is reshaping sports marketing, fan engagement, and the integrity of sport","Generative artificial intelligence (AI) is rapidly transforming the landscape of sports marketing by enabling hyper-personalised fan engagement, real-time content delivery, and data-driven commercial strategies. Leveraging technologies such as machine learning, predictive analytics, and automated content generation, sports organisations are increasingly able to tailor fan experiences, anticipate behaviour, and optimise revenue models. While these advancements offer significant opportunities for enhancing interactivity and commercial growth, they also introduce complex ethical, psychological, and regulatory challenges. This paper critically examines the dual nature of generative AI in sports marketing, with a particular focus on consumer autonomy, data monetisation, and the influence of AI-driven personalisation on fan behaviour. Using narrative literature review approach, the paper draws on emerging research, industry cases, and interdisciplinary literature, and explores how algorithmic recommendation systems can manipulate fan decisions, reinforce digital echo chambers, and marginalise underrepresented sports. Special attention is given to the impact of AI on children and adolescents, who are particularly vulnerable to targeted content, gamification, and AI-curated betting environments. The integration of AI in gambling platforms and the commercialisation of fan data raise significant concerns around privacy, consent, and long-term wellbeing. The paper concludes by offering some implementation guidance for sport ecosystem stakeholders. It also outlines a future research agenda that calls for empirical investigations into the long-term effects of AI on fan behaviour, the development of regulatory frameworks to safeguard consumer rights, and interdisciplinary collaboration to design ethical AI systems. By identifying these critical issues, the paper aims to support a more inclusive, transparent, and integrity-focused application of AI in sport.",2025,"[{'authorId': '2359938638', 'name': 'Hans Westerbeek'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3389/fspor.2025.1597444?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3389/fspor.2025.1597444, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generative artificial intelligence (ai) is rapidly transforming the landscape of sports marketing by enabling hyper-personalised fan engagement, real-time content delivery, and data-driven commercial strategies. leveraging technologies such as machine learning, predictive analytics, and automated content generation, sports organisations are increasingly able to tailor fan experiences, anticipate behaviour, and optimise revenue models. while these advancements offer significant opportunities for enhancing interactivity and commercial growth, they also introduce complex ethical, psychological, and regulatory challenges. this paper critically examines the dual nature of generative ai in sports marketing, with a particular focus on consumer autonomy, data monetisation, and the influence of ai-driven personalisation on fan behaviour. using narrative literature review approach, the paper draws on emerging research, industry cases, and interdisciplinary literature, and explores how algorithmic recommendation systems can manipulate fan decisions, reinforce digital echo chambers, and marginalise underrepresented sports. special attention is given to the impact of ai on children and adolescents, who are particularly vulnerable to targeted content, gamification, and ai-curated betting environments. the integration of ai in gambling platforms and the commercialisation of fan data raise significant concerns around privacy, consent, and long-term wellbeing. the paper concludes by offering some implementation guidance for sport ecosystem stakeholders. it also outlines a future research agenda that calls for empirical investigations into the long-term effects of ai on fan behaviour, the development of regulatory frameworks to safeguard consumer rights, and interdisciplinary collaboration to design ethical ai systems. by identifying these critical issues, the paper aims to support a more inclusive, transparent, and integrity-focused application of ai in sport.",
2052d04cccdfc0441b9381099051c94b379d25d3,Ball Trajectory Inference from Multi-Agent Sports Contexts Using Set Transformer and Hierarchical Bi-LSTM,"As artificial intelligence spreads out to numerous fields, the application of AI to sports analytics is also in the spotlight. However, one of the major challenges is the difficulty of automated acquisition of continuous movement data during sports matches. In particular, it is a conundrum to reliably track a tiny ball on a wide soccer pitch with obstacles such as occlusion and imitations. Tackling the problem, this paper proposes an inference framework of ball trajectory from player trajectories as a cost-efficient alternative to ball tracking. We combine Set Transformers to get permutation-invariant and equivariant representations of the multi-agent contexts with a hierarchical architecture that intermediately predicts the player ball possession to support the final trajectory inference. Also, we introduce the reality loss term and postprocessing to secure the estimated trajectories to be physically realistic. The experimental results show that our model provides natural and accurate trajectories as well as admissible player ball possession at the same time. Lastly, we suggest several practical applications of our framework including missing trajectory imputation, semi-automated pass annotation, automated zoom-in for match broadcasting, and calculating possession-wise running performance metrics.",2023,"[{'authorId': '2118020700', 'name': 'Hyunsung Kim'}, {'authorId': '2220130957', 'name': 'Han-Jun Choi'}, {'authorId': '2211035249', 'name': 'C. Kim'}, {'authorId': '2144029', 'name': 'Jinsung Yoon'}, {'authorId': '3297022', 'name': 'Sang-Ki Ko'}]","{'url': 'https://arxiv.org/pdf/2306.08206', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2306.08206, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","as artificial intelligence spreads out to numerous fields, the application of ai to sports analytics is also in the spotlight. however, one of the major challenges is the difficulty of automated acquisition of continuous movement data during sports matches. in particular, it is a conundrum to reliably track a tiny ball on a wide soccer pitch with obstacles such as occlusion and imitations. tackling the problem, this paper proposes an inference framework of ball trajectory from player trajectories as a cost-efficient alternative to ball tracking. we combine set transformers to get permutation-invariant and equivariant representations of the multi-agent contexts with a hierarchical architecture that intermediately predicts the player ball possession to support the final trajectory inference. also, we introduce the reality loss term and postprocessing to secure the estimated trajectories to be physically realistic. the experimental results show that our model provides natural and accurate trajectories as well as admissible player ball possession at the same time. lastly, we suggest several practical applications of our framework including missing trajectory imputation, semi-automated pass annotation, automated zoom-in for match broadcasting, and calculating possession-wise running performance metrics.",https://arxiv.org/pdf/2306.08206
3053f6a823a587d1b7f5f697515fb8675820046b,Design and implementation of an intelligent sports management system (ISMS) using wireless sensor networks,"In recent years, growth in technology has significantly impacted various industries, including sports, health, e-commerce, and agriculture. Among these industries, the sports sector is experiencing significant transformation, which needs support in accurately monitoring athlete predicting and performance injuries arising due to traditional methods’ limitations. Keeping the above in mind, in this article, we present the Intelligent Sports Management System (ISMS) with the integration of wireless sensor networks (WSNs) and neural networks (NNs), which enhance athlete monitoring and injury prediction. Our proposed ISMS consists of several layers: user interface, business logic layer, data management layer, integration layer, analytics and AI layer, IoT layer, and security layer. To facilitate interactions for athletes, coaches, and administrators, our planned ISMS integrates a user-friendly interface accessible through web and mobile applications. Besides, scheduling and event management are managed by the business logic layer. Similarly, the data management layer can process and store comprehensive data from various sources. To ensure smooth data exchange, the integration layer connects the ISMS with third-party services, and the analytics and AI layer leverages machine learning to provide actionable insights on performance and outcomes. In addition, the IoT layer collects real-time data from sensors and wearable devices, which is essential for performance analysis and injury prevention. Finally, the security layer ensures data integrity and confidentiality with robust encryption and access controls. To evaluate the system performance in different scenarios, we performed many experiments, which show that the proposed ISMS model shows the system efficacy in improving accuracy (0.94), specificity (0.97), recall (0.91), precision (0.93), F1 score (0.95), mean absolute error (MAE) (0.6), mean square error (MSE) (0.8), and root mean square error (RMSE) (0.9), compared to traditional methods. From these results, it is clear that our suggested approach improves athlete performance monitoring, injury prevention plans, and training schedules by presenting a complete and novel solution for recent sports management.",2025,"[{'authorId': '2343725881', 'name': 'ZhiGuo Zhu'}]","{'url': 'https://doi.org/10.7717/peerj-cs.2637', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11888851, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent years, growth in technology has significantly impacted various industries, including sports, health, e-commerce, and agriculture. among these industries, the sports sector is experiencing significant transformation, which needs support in accurately monitoring athlete predicting and performance injuries arising due to traditional methods’ limitations. keeping the above in mind, in this article, we present the intelligent sports management system (isms) with the integration of wireless sensor networks (wsns) and neural networks (nns), which enhance athlete monitoring and injury prediction. our proposed isms consists of several layers: user interface, business logic layer, data management layer, integration layer, analytics and ai layer, iot layer, and security layer. to facilitate interactions for athletes, coaches, and administrators, our planned isms integrates a user-friendly interface accessible through web and mobile applications. besides, scheduling and event management are managed by the business logic layer. similarly, the data management layer can process and store comprehensive data from various sources. to ensure smooth data exchange, the integration layer connects the isms with third-party services, and the analytics and ai layer leverages machine learning to provide actionable insights on performance and outcomes. in addition, the iot layer collects real-time data from sensors and wearable devices, which is essential for performance analysis and injury prevention. finally, the security layer ensures data integrity and confidentiality with robust encryption and access controls. to evaluate the system performance in different scenarios, we performed many experiments, which show that the proposed isms model shows the system efficacy in improving accuracy (0.94), specificity (0.97), recall (0.91), precision (0.93), f1 score (0.95), mean absolute error (mae) (0.6), mean square error (mse) (0.8), and root mean square error (rmse) (0.9), compared to traditional methods. from these results, it is clear that our suggested approach improves athlete performance monitoring, injury prevention plans, and training schedules by presenting a complete and novel solution for recent sports management.",https://doi.org/10.7717/peerj-cs.2637
51f3bbc5f42b47027964bc713cb3b87ef0c9ae83,Digital Transformation in Physical Education: The Application of Intelligent Technology in Enhancing the Effectiveness of Sports Teaching,"With the deep development of digital transformation, intelligent technology has become a key force in promoting the innovation and development of physical education. This study aims to explore the application of intelligent technologies such as Virtual Reality (VR), Augmented Reality (AR), Artificial Intelligence (AI), and big data analytics in physical education, as well as how these technologies optimize teaching methods, improve learning efficiency, and stimulate student interest. Through literature review and questionnaire survey, this paper systematically assesses the current application and challenges of intelligent technology in sports teaching. Furthermore, using qualitative and quantitative research methods, the teaching effects of utilizing intelligent technology versus traditional teaching methods in different educational environments were collected and analyzed. The study finds that the integration of intelligent technology significantly enhances the interactivity and personalization of sports teaching, helps to increase student motivation and participation, and promotes the improvement of learning outcomes. However, there are challenges such as resource limitations, teacher training, and student adaptability in the process of implementing technology. The paper concludes with strategies and suggestions for these challenges, aiming to provide reference and guidance for the digital transformation of future physical education.",2024,"[{'authorId': '2295818048', 'name': 'Leqiang Zhang, Gang Liu'}]","{'url': 'https://journal.esrgroups.org/jes/article/download/1365/1368', 'status': 'HYBRID', 'license': 'CCBYND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.52783/jes.1365?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.52783/jes.1365, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with the deep development of digital transformation, intelligent technology has become a key force in promoting the innovation and development of physical education. this study aims to explore the application of intelligent technologies such as virtual reality (vr), augmented reality (ar), artificial intelligence (ai), and big data analytics in physical education, as well as how these technologies optimize teaching methods, improve learning efficiency, and stimulate student interest. through literature review and questionnaire survey, this paper systematically assesses the current application and challenges of intelligent technology in sports teaching. furthermore, using qualitative and quantitative research methods, the teaching effects of utilizing intelligent technology versus traditional teaching methods in different educational environments were collected and analyzed. the study finds that the integration of intelligent technology significantly enhances the interactivity and personalization of sports teaching, helps to increase student motivation and participation, and promotes the improvement of learning outcomes. however, there are challenges such as resource limitations, teacher training, and student adaptability in the process of implementing technology. the paper concludes with strategies and suggestions for these challenges, aiming to provide reference and guidance for the digital transformation of future physical education.",https://journal.esrgroups.org/jes/article/download/1365/1368
a3f27337ac2905bc642ccec946099c78e4dca741,Exploring the Intersection of Big Data and Legal Analytics: A Survey of its Application in the Legal Industry,"Over the last decade, we have witnessed exponential growth in the usage of Big Data in a wide range of domains such as the entertainment industry, sports industry, financial industry etc. The legal industry is starting to take notice of Big Data analytics in their field. Lawyers have been using big data analytics tools for their daily purposes which include billing, marketing and customer relations functions. For the survey, ""Legal Analytics"" was defined as software that uses artificial intelligence to search through massive amounts of data and identify trends that are useful to lawyers. The connection between Big Data (BD) and law can be visualised in several ways. More and more law firms are turning to Big Data to identify which cases are likely to be straightforward and which cases will have hidden hurdles to overcome. In this paper, we have attempted to compare and take a deeper look at some of the algorithms and platforms built and developed for data analytics, namely Auto-Regressive Integrated Moving Average (ARIMA), Structural Equation Modelling (SEM), Long Short – Term Memory (LSTM) and a platform known as many Laws which is used for fetching queries and specific laws through a vast database of European laws and regulations. We have further studied how different parameters have affected the results in the case of models such as ARIMA and have taken a look into a text extractor architecture that incorporates the use of LSTM in one of its layers to extract relevant information.",2023,"[{'authorId': '2211572900', 'name': 'Anvay Bhure'}, {'authorId': '46688893', 'name': 'S. Desai'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.46610/jbdtba.2023.v02i01.002?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.46610/jbdtba.2023.v02i01.002, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","over the last decade, we have witnessed exponential growth in the usage of big data in a wide range of domains such as the entertainment industry, sports industry, financial industry etc. the legal industry is starting to take notice of big data analytics in their field. lawyers have been using big data analytics tools for their daily purposes which include billing, marketing and customer relations functions. for the survey, ""legal analytics"" was defined as software that uses artificial intelligence to search through massive amounts of data and identify trends that are useful to lawyers. the connection between big data (bd) and law can be visualised in several ways. more and more law firms are turning to big data to identify which cases are likely to be straightforward and which cases will have hidden hurdles to overcome. in this paper, we have attempted to compare and take a deeper look at some of the algorithms and platforms built and developed for data analytics, namely auto-regressive integrated moving average (arima), structural equation modelling (sem), long short – term memory (lstm) and a platform known as many laws which is used for fetching queries and specific laws through a vast database of european laws and regulations. we have further studied how different parameters have affected the results in the case of models such as arima and have taken a look into a text extractor architecture that incorporates the use of lstm in one of its layers to extract relevant information.",
9536791b76ef4e42d48ed50ed87095d8f5159f83,"Customer Satisfaction and Service Excellence in India's Hospitality, Leisure, Sports, and Tourism Sectors"," This study explores the evolving dynamics of service quality and customer satisfaction (SQCS) in India's hospitality, leisure, sport, and tourism sectors, with an emphasis on the role of emerging technologies and modern business norms. Using bibliometric analysis of literature indexed in Web of Science, the research identifies new trends, key challenges, and region-specific issues such as cultural diversity, the rise of domestic tourism, and the impact of recent policy shifts. The study highlights critical challenges facing India, including the need for enhanced workforce training, infrastructure improvements, and the integration of digital innovations such as AI, automation, and IoT to elevate customer experiences. Key themes such as destination loyalty, hyper-personalized services powered by data analytics, and the growing demand for immersive regional tourism experiences are highlighted as crucial factors influencing customer satisfaction. The research underscores how digital transformation is reshaping customer interactions and service delivery, emphasizing the shift toward a more tech-driven and sustainable tourism industry​",2024,"[{'authorId': '2335145939', 'name': 'Abhishek Maikhuri'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.52783/tjjpt.v45.i04.8498?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.52783/tjjpt.v45.i04.8498, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study explores the evolving dynamics of service quality and customer satisfaction (sqcs) in india's hospitality, leisure, sport, and tourism sectors, with an emphasis on the role of emerging technologies and modern business norms. using bibliometric analysis of literature indexed in web of science, the research identifies new trends, key challenges, and region-specific issues such as cultural diversity, the rise of domestic tourism, and the impact of recent policy shifts. the study highlights critical challenges facing india, including the need for enhanced workforce training, infrastructure improvements, and the integration of digital innovations such as ai, automation, and iot to elevate customer experiences. key themes such as destination loyalty, hyper-personalized services powered by data analytics, and the growing demand for immersive regional tourism experiences are highlighted as crucial factors influencing customer satisfaction. the research underscores how digital transformation is reshaping customer interactions and service delivery, emphasizing the shift toward a more tech-driven and sustainable tourism industry​",
2a95f34da75d268113f5dc0e762e945701d3a444,AI-SPOT: a Novel Artificial Intelligence-enabled Sport Optimization Tracker to Enhance Performance and Prevent Injury in Elite Footballers,"This study introduces AI-SPOT, a novel artificial intelligence tool for optimizing performance and preventing injuries in elite footballers. Data were collected from four Singapore Premiere League clubs and the National Team, encompassing 68 male footballers over two seasons (2021–2022). The comprehensive dataset included diverse metrics, injury records, and automated live match data from established databases. AI-SPOT employs Python's scikit-learn for predictive analytics, using techniques like logistic regression and XGBoost, and was further developed with TensorFlow. Its effectiveness in injury prediction and performance assessment was validated with extensive local and international data sources. The system's potential for broader sports applications was underscored by user experience assessments, indicating a significant shift towards AI-driven strategies in sports management. Despite its reliance on high-quality, sport-specific data, AI-SPOT's adaptability highlights its role as a transformative tool in sports analytics, paving the way for advanced, data-driven approaches in sports management and strategy formulation.",2024,"[{'authorId': '2317662495', 'name': 'Aaron Chen Angus'}, {'authorId': '2317663365', 'name': 'Dinesh Sirisena'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.29313/gmhc.v12i1.12788?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.29313/gmhc.v12i1.12788, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study introduces ai-spot, a novel artificial intelligence tool for optimizing performance and preventing injuries in elite footballers. data were collected from four singapore premiere league clubs and the national team, encompassing 68 male footballers over two seasons (2021–2022). the comprehensive dataset included diverse metrics, injury records, and automated live match data from established databases. ai-spot employs python's scikit-learn for predictive analytics, using techniques like logistic regression and xgboost, and was further developed with tensorflow. its effectiveness in injury prediction and performance assessment was validated with extensive local and international data sources. the system's potential for broader sports applications was underscored by user experience assessments, indicating a significant shift towards ai-driven strategies in sports management. despite its reliance on high-quality, sport-specific data, ai-spot's adaptability highlights its role as a transformative tool in sports analytics, paving the way for advanced, data-driven approaches in sports management and strategy formulation.",
4a8b831abac5031ed14077b2525e06e4820d241e,Sports nutrition as an example of effective implementation of innovative trends in nutrition: personalization and digitalization (literature review),"The nutritional status in an athlete depends on the individual genetic characteristics of the body, the level of physical and psycho-emotional stress, and a balanced diet with the inclusion of specialized food products and dietary supplements. The development of big data analytics and artificial intelligence can contribute to the development of nutritional recommendations at the individual or stratified level. 
The purpose of the review is to analyze and summarize research papers devoted to the possibilities of using digital technologies, deep machine learning techniques, and artificial intelligence in the field of sports nutrition to ensure a personalized approach to improving professional success. There were studied papers published in 2004–2024 in domestic and foreign electronic databases: Web of Science, Scopus, eLIBRARY.RU, Russian State Library, library collection of the Federal State Budgetary Scientific Institution “Federal Research Center of Nutrition and Biotechnology”. 
The potential for AI-based technologies in sports nutrition is extremely diverse: dietary assessment, recognition and tracking of food diversity, predictive modelling of athletic performance and non-communicable diseases, and selection of personalized diets. To ensure sustainable growth in the coverage of digital products and technologies, further directions for their application in sports medicine should be aimed at improving the quality and standardization of data and reducing algorithmic bias.",2025,"[{'authorId': '91130002', 'name': 'D. B. Nikitjuk'}, {'authorId': '12106318', 'name': 'M. Korosteleva'}, {'authorId': '95403815', 'name': 'I. Tarmaeva'}]","{'url': 'https://doi.org/10.47470/0044-197x-2025-69-1-65-69', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.47470/0044-197x-2025-69-1-65-69?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.47470/0044-197x-2025-69-1-65-69, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the nutritional status in an athlete depends on the individual genetic characteristics of the body, the level of physical and psycho-emotional stress, and a balanced diet with the inclusion of specialized food products and dietary supplements. the development of big data analytics and artificial intelligence can contribute to the development of nutritional recommendations at the individual or stratified level. the purpose of the review is to analyze and summarize research papers devoted to the possibilities of using digital technologies, deep machine learning techniques, and artificial intelligence in the field of sports nutrition to ensure a personalized approach to improving professional success. there were studied papers published in 2004–2024 in domestic and foreign electronic databases: web of science, scopus, elibrary.ru, russian state library, library collection of the federal state budgetary scientific institution “federal research center of nutrition and biotechnology”. the potential for ai-based technologies in sports nutrition is extremely diverse: dietary assessment, recognition and tracking of food diversity, predictive modelling of athletic performance and non-communicable diseases, and selection of personalized diets. to ensure sustainable growth in the coverage of digital products and technologies, further directions for their application in sports medicine should be aimed at improving the quality and standardization of data and reducing algorithmic bias.",https://doi.org/10.47470/0044-197x-2025-69-1-65-69
220a96b104f229ee2416f41f0df7fdb31eb99c1e,Harnessing the Power of Transformer Networks in AI-Driven Decision Support Systems for Badminton Action Recognition,"This research explores the application of hybrid transformer networks for video-based action recognition in sports specifically for badminton. This research aims to capture and classify badminton player movements with high accuracy. The novelty of this study lies in its hybrid transformer approach, a sophisticated blend of transformer architectures and self-supervised pretraining tasks, designed to process sequential image data, leveraging the spatial-temporal capabilities of transformer models to enhance feature extraction and reduce computational complexity. Initial experiments were conducted using a curated VideoBadminton dataset, achieving 86.2% CS accuracy and 92.9% CV accuracy, a promising increase in precision compared to traditional convolutional neural networks. This breakthrough indicates that hybrid transformer networks can significantly improve the accuracy in video-based badminton action recognition. The findings suggest a scalable path forward for integrating advanced AI methodologies into sports analytics for AI driven decision support system, offering substantial benefits for performance assessment and athlete development.",2024,"[{'authorId': '83197950', 'name': 'Riska Dhenabayu'}, {'authorId': '2334756729', 'name': 'Nanang Hoesen Hidroes Abbrori'}, {'authorId': '117194977', 'name': 'Hujjatullah Fazlurrahman'}, {'authorId': '2334757120', 'name': 'Achmad Fitro'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/CITSM64103.2024.10775332?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CITSM64103.2024.10775332, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this research explores the application of hybrid transformer networks for video-based action recognition in sports specifically for badminton. this research aims to capture and classify badminton player movements with high accuracy. the novelty of this study lies in its hybrid transformer approach, a sophisticated blend of transformer architectures and self-supervised pretraining tasks, designed to process sequential image data, leveraging the spatial-temporal capabilities of transformer models to enhance feature extraction and reduce computational complexity. initial experiments were conducted using a curated videobadminton dataset, achieving 86.2% cs accuracy and 92.9% cv accuracy, a promising increase in precision compared to traditional convolutional neural networks. this breakthrough indicates that hybrid transformer networks can significantly improve the accuracy in video-based badminton action recognition. the findings suggest a scalable path forward for integrating advanced ai methodologies into sports analytics for ai driven decision support system, offering substantial benefits for performance assessment and athlete development.",
e0e49525cd67af5172ebcbea9ec55cbed11576f4,AI-Powered Badminton Shot Classification,"AI technology has catalyzed new frontiers across numerous domains, including sports analytics. Due to the diversity of sports, certain areas remain under-explored. This work will focus on bringing AI-driven analysis to the sport of Badminton. By leveraging computer vision techniques and ML models, we can analyze athlete performance by identifying shot selection. By examining their stroke preparation for conducting a type of shot, which differs subtly between shots, we can gain insights to their strengths and weaknesses. We developed two ML models for shot classification using official match data from BWF, categorizing shots into ‘lob’, ‘smash’, and ‘net’. Our results show that the Keras-Mediapipe model outperforms the YOLO-NAS model in shot classification, however, still requires further improvements to be applicable.",2024,"[{'authorId': '2333655568', 'name': 'Michael Arsen Salim'}, {'authorId': '2190886963', 'name': 'Winly Williamdy'}, {'authorId': '2190861014', 'name': 'Eden Steven'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICTIIA61827.2024.10761547?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICTIIA61827.2024.10761547, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ai technology has catalyzed new frontiers across numerous domains, including sports analytics. due to the diversity of sports, certain areas remain under-explored. this work will focus on bringing ai-driven analysis to the sport of badminton. by leveraging computer vision techniques and ml models, we can analyze athlete performance by identifying shot selection. by examining their stroke preparation for conducting a type of shot, which differs subtly between shots, we can gain insights to their strengths and weaknesses. we developed two ml models for shot classification using official match data from bwf, categorizing shots into ‘lob’, ‘smash’, and ‘net’. our results show that the keras-mediapipe model outperforms the yolo-nas model in shot classification, however, still requires further improvements to be applicable.",
a7cca5bd85c240ba074224a4fc6c1e28f81e3ede,Identifying Key Factors for Securing a Champions League Position in French Ligue 1 Using Explainable Machine Learning Techniques,"Introduction: Performance analysis is essential for coaches and a topic of extensive research. The advancement of technology and Artificial Intelligence (AI) techniques has revolutionized sports analytics. Aim: The primary aim of this article is to present a robust, explainable machine learning (ML) model that identifies the key factors that contribute to securing one of the top three positions in the standings of the French Ligue 1, ensuring participation in the UEFA Champions League for the following season. Materials and Methods: This retrospective observational study analyzed data from all 380 matches of the 2022–23 French Ligue 1 season. The data were obtained from the publicly-accessed website “whoscored” and included 34 performance indicators. This study employed Sequential Forward Feature Selection (SFFS) and various ML algorithms, including XGBoost, Support Vector Machine (SVM), and Logistic Regression (LR), to create a robust, explainable model. The SHAP (SHapley Additive Explanations) model was used to enhance model interpretability. Results: The K-means Cluster Analysis categorized teams into groups (TOP TEAMS, 3 teams/REST TEAMS, 17 teams), and the ML models provided significant insights into the factors influencing league standings. The LR classifier was the best-performing classifier, achieving an accuracy of 75.13%, a recall of 76.32%, an F1-score of 48.03%, and a precision of 35.17%. “SHORT PASSES” and “THROUGH BALLS” were features found to positively influence the model’s predictions, while “TACKLES ATTEMPTED” and “LONG BALLS” had a negative impact. Conclusions: Our model provided satisfactory predictive accuracy and clear interpretability of results, which gave useful information to stakeholders. Specifically, our model suggests adopting a strategy during the ball possession phase that relies on short passes (avoiding long ones) and aiming to enter the attacking third and the opponent’s penalty area with through balls.",2024,"[{'authorId': '1821053', 'name': 'Spyridon Plakias'}, {'authorId': '1453644086', 'name': 'Christos Kokkotis'}, {'authorId': '12984197', 'name': 'Michalis Mitrotasios'}, {'authorId': '2302636994', 'name': 'Vasileios Armatas'}, {'authorId': '5805013', 'name': 'Themistoklis Tsatalas'}, {'authorId': '2289989531', 'name': 'Giannis Giakas'}]","{'url': 'https://doi.org/10.3390/app14188375', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app14188375?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app14188375, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","introduction: performance analysis is essential for coaches and a topic of extensive research. the advancement of technology and artificial intelligence (ai) techniques has revolutionized sports analytics. aim: the primary aim of this article is to present a robust, explainable machine learning (ml) model that identifies the key factors that contribute to securing one of the top three positions in the standings of the french ligue 1, ensuring participation in the uefa champions league for the following season. materials and methods: this retrospective observational study analyzed data from all 380 matches of the 2022–23 french ligue 1 season. the data were obtained from the publicly-accessed website “whoscored” and included 34 performance indicators. this study employed sequential forward feature selection (sffs) and various ml algorithms, including xgboost, support vector machine (svm), and logistic regression (lr), to create a robust, explainable model. the shap (shapley additive explanations) model was used to enhance model interpretability. results: the k-means cluster analysis categorized teams into groups (top teams, 3 teams/rest teams, 17 teams), and the ml models provided significant insights into the factors influencing league standings. the lr classifier was the best-performing classifier, achieving an accuracy of 75.13%, a recall of 76.32%, an f1-score of 48.03%, and a precision of 35.17%. “short passes” and “through balls” were features found to positively influence the model’s predictions, while “tackles attempted” and “long balls” had a negative impact. conclusions: our model provided satisfactory predictive accuracy and clear interpretability of results, which gave useful information to stakeholders. specifically, our model suggests adopting a strategy during the ball possession phase that relies on short passes (avoiding long ones) and aiming to enter the attacking third and the opponent’s penalty area with through balls.",https://doi.org/10.3390/app14188375
3d01468b51e00239bb09be65a260cf9d65c9c7e4,Enhancing IPL Match Outcome Prediction With Privacy-preserving Using Machine Learning Techniques,"Privacy-preserving methods in IPL winning prediction represent a paradigm shift in how AI is seamlessly integrated into cricket analytics while addressing critical concerns regarding data security. These innovative techniques encompass a range of advanced methodologies, including federated learning, differential privacy, and secure multi-party computation. By leveraging these techniques, teams can collaborate securely and derive accurate predictions without compromising sensitive player statistics or confidential information. AI deployment in sports analytics. As data privacy regulations continue to evolve, the adoption of privacypreserving methods becomes increasingly crucial for IPL teams to remain compliant while utilizing AI to its fullest extent for competitive advantage and strategic decision-making. Ultimately, these developments highlight the significance of privacy and data protection in the digital world of sports analytics and open the door to a more ethical, safe, and successful era of AI-driven IPL winning predictions. Notably, the Random Forest algorithm demonstrates exceptional accuracy of 93.59%, surpassing other models and showcasing the power of ensemble learning within the PPML framework.",2024,"[{'authorId': '2329399954', 'name': 'C.Jamunadevi'}, {'authorId': '2329405617', 'name': 'S.Pandikumar'}, {'authorId': '2329400540', 'name': 'N.Rajasekaran'}, {'authorId': '2329302818', 'name': 'G.Sree Sabarish'}, {'authorId': '2329400162', 'name': 'K.P.Narendra Prasanth'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCCNT61001.2024.10724746?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCCNT61001.2024.10724746, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","privacy-preserving methods in ipl winning prediction represent a paradigm shift in how ai is seamlessly integrated into cricket analytics while addressing critical concerns regarding data security. these innovative techniques encompass a range of advanced methodologies, including federated learning, differential privacy, and secure multi-party computation. by leveraging these techniques, teams can collaborate securely and derive accurate predictions without compromising sensitive player statistics or confidential information. ai deployment in sports analytics. as data privacy regulations continue to evolve, the adoption of privacypreserving methods becomes increasingly crucial for ipl teams to remain compliant while utilizing ai to its fullest extent for competitive advantage and strategic decision-making. ultimately, these developments highlight the significance of privacy and data protection in the digital world of sports analytics and open the door to a more ethical, safe, and successful era of ai-driven ipl winning predictions. notably, the random forest algorithm demonstrates exceptional accuracy of 93.59%, surpassing other models and showcasing the power of ensemble learning within the ppml framework.",
5eb3c75701c31d3e3d474c8d032c5012bfc6b0e5,Training and testing an artificial intelligence model for action recognition using the MMAction2 toolkit,"In recent decades, artificial intelligence (AI) has become an indispensable tool in various fields of human activity, including action recognition. With the advancements in machine learning and deep learning technologies, AI's capabilities in analyzing and interpreting actions performed by humans or objects in video and audio recordings have significantly increased. This progress has led to the development of numerous applications such as surveillance systems, human-computer interaction, sports analytics, and autonomous driving, where understanding and recognizing actions is crucial. Traditional methods of action recognition relied heavily on handcrafted features and classical machine learning algorithms, which often struggled with the variability and complexity of real-world scenarios. The emergence of deep learning, particularly convolutional neural networks (CNNs) and recurrent neural networks (RNNs), has revolutionized this field by enabling models to learn hierarchical representations directly from raw data, thus improving performance and robustness. In this paper, we describe the process of training and testing an artificial intelligence model in an action recognition task using the MMAction2 toolkit.",2024,"[{'authorId': '2327814709', 'name': 'Alina Mangusheva'}, {'authorId': '2327814701', 'name': 'Margarita Obukhova'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1051/e3sconf/202458306016?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1051/e3sconf/202458306016, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent decades, artificial intelligence (ai) has become an indispensable tool in various fields of human activity, including action recognition. with the advancements in machine learning and deep learning technologies, ai's capabilities in analyzing and interpreting actions performed by humans or objects in video and audio recordings have significantly increased. this progress has led to the development of numerous applications such as surveillance systems, human-computer interaction, sports analytics, and autonomous driving, where understanding and recognizing actions is crucial. traditional methods of action recognition relied heavily on handcrafted features and classical machine learning algorithms, which often struggled with the variability and complexity of real-world scenarios. the emergence of deep learning, particularly convolutional neural networks (cnns) and recurrent neural networks (rnns), has revolutionized this field by enabling models to learn hierarchical representations directly from raw data, thus improving performance and robustness. in this paper, we describe the process of training and testing an artificial intelligence model in an action recognition task using the mmaction2 toolkit.",
768d7d843a359051e9c2aea3a30abbad4be3c162,Blind scouting: using artificial intelligence to alleviate bias in selection,"PurposeTalent scouting is recognized as a vital activity for professional sports organizations to establish a competitive advantage on the field. It remains, however, an imperfect science marred with bias and stereotypes. Technology – such as data analytics and artificial intelligence (AI) – is a promising avenue to deal with these issues. Yet, much like in the broader HRM literature, little is known about its ability to effectively alleviate bias and on how to successfully make it co-exist with human recruiters.Design/methodology/approachIn collaboration with a professional North American soccer (football) team, this experimental study investigates the impact of using AI-anonymized game footage on scouts’ assessments. In addition to quantitative ratings, it uses a “think-aloud” or verbal cognition methodology to capture changes in the scouts’ assessments.FindingsThe results demonstrate how a “blind scouting” approach stands to alleviate bias and leads to more robust scouting assessments. Namely, the findings indicate that using de-identified footage through AI increases the scouts’ focus on tactical abilities and decreases observations on potentially problematic physiological considerations.Originality/valueThis study provides valuable insights on scouts’ cognition and moves past the prevailing AI vs Human dichotomy by demonstrating how the technology can improve processes without removing the need for experts. It also speaks to AI’s benefits beyond cost or time savings and suggests other potential HRM-related applications for AI.",2025,"[{'authorId': '153451153', 'name': 'Louis-Etienne Dubois'}, {'authorId': '2347611042', 'name': 'Laurel Walzak'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/pr-02-2024-0130?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/pr-02-2024-0130, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purposetalent scouting is recognized as a vital activity for professional sports organizations to establish a competitive advantage on the field. it remains, however, an imperfect science marred with bias and stereotypes. technology – such as data analytics and artificial intelligence (ai) – is a promising avenue to deal with these issues. yet, much like in the broader hrm literature, little is known about its ability to effectively alleviate bias and on how to successfully make it co-exist with human recruiters.design/methodology/approachin collaboration with a professional north american soccer (football) team, this experimental study investigates the impact of using ai-anonymized game footage on scouts’ assessments. in addition to quantitative ratings, it uses a “think-aloud” or verbal cognition methodology to capture changes in the scouts’ assessments.findingsthe results demonstrate how a “blind scouting” approach stands to alleviate bias and leads to more robust scouting assessments. namely, the findings indicate that using de-identified footage through ai increases the scouts’ focus on tactical abilities and decreases observations on potentially problematic physiological considerations.originality/valuethis study provides valuable insights on scouts’ cognition and moves past the prevailing ai vs human dichotomy by demonstrating how the technology can improve processes without removing the need for experts. it also speaks to ai’s benefits beyond cost or time savings and suggests other potential hrm-related applications for ai.",
d36327a985f63010d098ef08408ca815408dba3c,Multi-Factors Analysis Using Visualizations and SHAP: Comprehensive Case Analysis of Tennis Results Forecasting,"—Explainable Artificial Intelligence (XAI) enhances interpretability in data-driven models, providing valuable insights into complex decision-making processes. By ensuring transparency, XAI bridges the gap between advanced Artificial Intelligence (AI) techniques and their practical applications, fostering trust and enabling data-informed strategies. In the realm of sports analytics, XAI proves particularly significant, as it unravels the multifaceted nature of factors influencing athletic performance. This work uses a rich data analysis flow that includes descriptive, predictive, and prescriptive analysis for the tennis match outcomes. Descriptive analysis uses XAI techniques such as SHAP (SHapley Additive exPlanations) with diverse factors such as physical, geographical, surface level and skill disparities. Top players are ranked; the trend of country-wise winning is presented for the last many decades. Correlation analysis presents inter-dependence of factors. Correlation analysis presents inter-dependence of factors. Predictive analysis makes use of machine learning models, the highest overall accuracy of 80% according to the K-Nearest Neighbors classifier. Lastly, prescriptive analysis recommends specific details which can be helpful for players and coaches as well as for overall strategies planning and performance enhancement. The research underscores the significance of AI-driven insights in sports analytics, particularly for a fast-paced and strategic sport like tennis. By leveraging advanced data analytics methods, this study offers a nuanced understanding of the interplay between player attributes, match contexts, and historical trends, paving the way for enhanced performance and informed strategic planning in professional tennis.",2025,"[{'authorId': '2343954907', 'name': 'Yuan Zhang'}]","{'url': 'https://doi.org/10.14569/ijacsa.2025.0160114', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.14569/ijacsa.2025.0160114?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.14569/ijacsa.2025.0160114, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","—explainable artificial intelligence (xai) enhances interpretability in data-driven models, providing valuable insights into complex decision-making processes. by ensuring transparency, xai bridges the gap between advanced artificial intelligence (ai) techniques and their practical applications, fostering trust and enabling data-informed strategies. in the realm of sports analytics, xai proves particularly significant, as it unravels the multifaceted nature of factors influencing athletic performance. this work uses a rich data analysis flow that includes descriptive, predictive, and prescriptive analysis for the tennis match outcomes. descriptive analysis uses xai techniques such as shap (shapley additive explanations) with diverse factors such as physical, geographical, surface level and skill disparities. top players are ranked; the trend of country-wise winning is presented for the last many decades. correlation analysis presents inter-dependence of factors. correlation analysis presents inter-dependence of factors. predictive analysis makes use of machine learning models, the highest overall accuracy of 80% according to the k-nearest neighbors classifier. lastly, prescriptive analysis recommends specific details which can be helpful for players and coaches as well as for overall strategies planning and performance enhancement. the research underscores the significance of ai-driven insights in sports analytics, particularly for a fast-paced and strategic sport like tennis. by leveraging advanced data analytics methods, this study offers a nuanced understanding of the interplay between player attributes, match contexts, and historical trends, paving the way for enhanced performance and informed strategic planning in professional tennis.",https://doi.org/10.14569/ijacsa.2025.0160114
d1fa744c049c645bd4fd15a8268105f5631fc908,Real-Time Football Analysis System using YOLO and OpenCV,"AI and ML technologies have increasingly dominated sports analytics, allowing new real-time data processing capabilities. This paper proposes a new Real-Time Football analysis system using YOLOv5 and OpenCV to respond to issues revolving round accurate Player and Ball detection with occlusion and illumination changes. To accomplish the methodology, object detection is performed, SORT algorithm for tracking and Kalman filtering for improving the tracking while compensating the camera movement using optical flow. The results demonstrate high accuracy in player and ball detection (precision: 92. It outperforms other methods (precision: 5%, recall: 89. 8%, mAP: 91. 1%) while implementing a real-time analysis at 28.5 Frames Per Second. Speed, distance covered, team possession, and more, are displayed, making the system excellent for detailed tactical analysis, potential improvement of individual player or team performances, and even rising enthusiasts’ engagement. In conclusion, this work presents a high-quality real time eight-layer analysis solution for football that can open the way to higher level predictive models in the future.",2025,"[{'authorId': '108454154', 'name': 'S. Dedgaonkar'}, {'authorId': '2287976901', 'name': 'Pravin R. Futane'}, {'authorId': '2330333828', 'name': 'Ratnamala Bhimanpallewar'}, {'authorId': '2352460629', 'name': 'Pratham Dedgaonkar'}, {'authorId': '2352462973', 'name': 'Arjun Deokule'}, {'authorId': '2352463667', 'name': 'Amodini Dhadge'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICISCN64258.2025.10934234?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICISCN64258.2025.10934234, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ai and ml technologies have increasingly dominated sports analytics, allowing new real-time data processing capabilities. this paper proposes a new real-time football analysis system using yolov5 and opencv to respond to issues revolving round accurate player and ball detection with occlusion and illumination changes. to accomplish the methodology, object detection is performed, sort algorithm for tracking and kalman filtering for improving the tracking while compensating the camera movement using optical flow. the results demonstrate high accuracy in player and ball detection (precision: 92. it outperforms other methods (precision: 5%, recall: 89. 8%, map: 91. 1%) while implementing a real-time analysis at 28.5 frames per second. speed, distance covered, team possession, and more, are displayed, making the system excellent for detailed tactical analysis, potential improvement of individual player or team performances, and even rising enthusiasts’ engagement. in conclusion, this work presents a high-quality real time eight-layer analysis solution for football that can open the way to higher level predictive models in the future.",
ba3f2695e341dc149da4a10997379f27ba47f296,AI Coach for Badminton,"In this competitive world of sports, to become an ideal player, one must maintain his nutrition and physique. Every motion involved in the sport must be efficiently carried out to employ the active muscles and eventually sustain energy depletion levels. Badminton is one sport where player movements are relatively easier to track using video analytics. The stroke movements captured through the camera can be used to examine the hand and hip coordination, placement of the leg and the varied upper bound and lower bound angles of the strokes. The prediction of a much better stance and orientation of the muscles, erroneous playing techniques, joint fatigue and several such aspects can be forecasted through an intelligent system as a recommendation. This research focuses on various techniques of neural networks to analyse the image retrieved from a badminton game. Ideal and efficient data is vastly available on the World Wide Web, and a series of data is then be taken down as per the requirements of the subjects, i.e., taking into consideration, player’s body type and consecutively keeping the subjects diet and physique under observation while noting down the muscles which get activated during the execution of the said stroke.",2022,"[{'authorId': '2404552', 'name': 'Durga Toshniwal'}, {'authorId': '2150918855', 'name': 'Arpit Patil'}, {'authorId': '2135840622', 'name': 'Nancy Vachhani'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2403.08956, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this competitive world of sports, to become an ideal player, one must maintain his nutrition and physique. every motion involved in the sport must be efficiently carried out to employ the active muscles and eventually sustain energy depletion levels. badminton is one sport where player movements are relatively easier to track using video analytics. the stroke movements captured through the camera can be used to examine the hand and hip coordination, placement of the leg and the varied upper bound and lower bound angles of the strokes. the prediction of a much better stance and orientation of the muscles, erroneous playing techniques, joint fatigue and several such aspects can be forecasted through an intelligent system as a recommendation. this research focuses on various techniques of neural networks to analyse the image retrieved from a badminton game. ideal and efficient data is vastly available on the world wide web, and a series of data is then be taken down as per the requirements of the subjects, i.e., taking into consideration, player’s body type and consecutively keeping the subjects diet and physique under observation while noting down the muscles which get activated during the execution of the said stroke.",
0d885f5ab49034ada43a1fc94374371710dc829f,Using artificial intelligence-enhanced video feedback for reflective practice in coach development: benefits and potential drawbacks,"ABSTRACT Sports coaching has used video feedback for decades to improve athlete and coach performance. More recently, artificial intelligence (AI) and machine-learning technologies have enabled analytics alongside visual review to accelerate development further. So too in coaching conversations, software allows the implementation of behavioural analytics, tracking speech patterns, body language and facial expressions to deliver performance data measured against core coaching competencies. In this study, we interviewed 15 coaches who used AI-enhanced video review software in coaching sessions with clients over several weeks and reflected on those sessions using the recordings and AI-generated data. Our aim was to discover the benefits and drawbacks of using such an approach in reflective practice. Clear benefits emerged: insights gained from video and data analysis drove deeper reflection and heightened self-awareness; coaches focused on skills development, made specific changes to their practice, developed over time and gained in confidence. Challenges included coaches’ nervousness around using new technology, viewing and analysing their own performance, and a sense that the software does not understand the subtle nuances and context of conversations. Limitations are discussed as well as the implications for coach training, reflective practice and supervision. We suggest possibilities for further study in this area.",2023,"[{'authorId': '1572468126', 'name': 'Jamie M Bridgeman'}, {'authorId': '2000851078', 'name': 'Andrea Giraldez-Hayes'}]","{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/17521882.2023.2228416?needAccess=true&role=button', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/17521882.2023.2228416?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/17521882.2023.2228416, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract sports coaching has used video feedback for decades to improve athlete and coach performance. more recently, artificial intelligence (ai) and machine-learning technologies have enabled analytics alongside visual review to accelerate development further. so too in coaching conversations, software allows the implementation of behavioural analytics, tracking speech patterns, body language and facial expressions to deliver performance data measured against core coaching competencies. in this study, we interviewed 15 coaches who used ai-enhanced video review software in coaching sessions with clients over several weeks and reflected on those sessions using the recordings and ai-generated data. our aim was to discover the benefits and drawbacks of using such an approach in reflective practice. clear benefits emerged: insights gained from video and data analysis drove deeper reflection and heightened self-awareness; coaches focused on skills development, made specific changes to their practice, developed over time and gained in confidence. challenges included coaches’ nervousness around using new technology, viewing and analysing their own performance, and a sense that the software does not understand the subtle nuances and context of conversations. limitations are discussed as well as the implications for coach training, reflective practice and supervision. we suggest possibilities for further study in this area.",https://www.tandfonline.com/doi/pdf/10.1080/17521882.2023.2228416?needAccess=true&role=button
db419ba30b8d2bc516d8c808e02ed45fbb6017ed,Analysis of IPL Auction Dataset Using Explainable Machine Learning with Lime and H2O AutoML,"The global sports market, one of the biggest markets in the world, grew from $354.96 billion in 2021 to $496.52 billion in 2022, according to research from a business research organization. Sports teams are becoming increasingly devoted to investing in sports data analytics to gain a competitive edge as spending on the global sports market rises; as a result, it is predicted that the sports analytics industry will exceed $4.5 billion by 2025. It is the study of athletic performance and business health to maximize a sports organization's processes and results. Explainable machine learning (XML) is a key part of machine learning and AI because it explains how machine learning models create predictions. To establish trust and ensure accountability in AI systems, it is crucial to be able to comprehend and evaluate a model's predictions.",2023,"[{'authorId': '2221121356', 'name': 'Aradya Garg'}, {'authorId': '49084568', 'name': 'A. Chaudhary'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICIEM59379.2023.10167124?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICIEM59379.2023.10167124, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the global sports market, one of the biggest markets in the world, grew from $354.96 billion in 2021 to $496.52 billion in 2022, according to research from a business research organization. sports teams are becoming increasingly devoted to investing in sports data analytics to gain a competitive edge as spending on the global sports market rises; as a result, it is predicted that the sports analytics industry will exceed $4.5 billion by 2025. it is the study of athletic performance and business health to maximize a sports organization's processes and results. explainable machine learning (xml) is a key part of machine learning and ai because it explains how machine learning models create predictions. to establish trust and ensure accountability in ai systems, it is crucial to be able to comprehend and evaluate a model's predictions.",
ca5b293f11416dc8d2bd17c466e528149865a130,Football Event Classification Using Convolutional Autoencoder and Multilayer Extreme Learning Machine,"Event detection and classification in sports are particularly important in the field of sports data analytics. In this era, various AI methods are utilized to detect events in a football (soccer) game. The use of advanced computational techniques in this area can help to achieve higher accuracy in detecting events. This letter proposes a novel architecture to classify events in a football game. The dataset, which is used, consists of numerous images pertaining to different events in a regular football match. From this dataset, the objective is to detect specific and semantically meaningful events, such as pass, dribble, or shoot. The proposed model consists of a convolutional autoencoder (AE) coupled with a multilayer extreme learning machine to classify the given images into defined events. The convolutional AE module is placed before the extreme learning machine (ELM) in the model pipeline as it helps with data compression and dimensionality reduction so as to ensure fast computation. Thereby, a multilayer extreme learning machine achieves better performance compared with the other existing approaches.",2022,"[{'authorId': '38986955', 'name': 'Mohammad Farukh Hashmi'}, {'authorId': '2186213671', 'name': 'Tejas Bhat Bellare'}, {'authorId': '2181733381', 'name': 'Ankith Suresh'}, {'authorId': '2125247128', 'name': 'Banoth Thulasya Naik'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/LSENS.2022.3209366?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/LSENS.2022.3209366, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","event detection and classification in sports are particularly important in the field of sports data analytics. in this era, various ai methods are utilized to detect events in a football (soccer) game. the use of advanced computational techniques in this area can help to achieve higher accuracy in detecting events. this letter proposes a novel architecture to classify events in a football game. the dataset, which is used, consists of numerous images pertaining to different events in a regular football match. from this dataset, the objective is to detect specific and semantically meaningful events, such as pass, dribble, or shoot. the proposed model consists of a convolutional autoencoder (ae) coupled with a multilayer extreme learning machine to classify the given images into defined events. the convolutional ae module is placed before the extreme learning machine (elm) in the model pipeline as it helps with data compression and dimensionality reduction so as to ensure fast computation. thereby, a multilayer extreme learning machine achieves better performance compared with the other existing approaches.",
87c0409885e6c0cc05d54930209377cdf271c917,The CoachAI Badminton Environment: Bridging the Gap between a Reinforcement Learning Environment and Real-World Badminton Games,"We present the CoachAI Badminton Environment, a reinforcement learning (RL) environment tailored for AI-driven sports analytics. In contrast to traditional environments using rule-based opponents or simplistic physics-based randomness, our environment integrates authentic opponent AIs and realistic randomness derived from real-world matches data to bridge the performance gap encountered in real-game deployments. This novel feature enables RL agents to seamlessly adapt to genuine scenarios. The CoachAI Badminton Environment empowers researchers to validate strategies in intricate real-world settings, offering: i) Realistic opponent simulation for RL training; ii) Visualizations for evaluation; and iii) Performance benchmarks for assessing agent capabilities. By bridging the RL environment with actual badminton games, our environment is able to advance the discovery of winning strategies for players. Our code is available at https://github.com/wywyWang/CoachAI-Projects/tree/main/Strategic%20Environment.",2024,"[{'authorId': '2191872767', 'name': 'Kuang-Da Wang'}, {'authorId': '2293558731', 'name': 'Yu-Tse Chen'}, {'authorId': '2293549566', 'name': 'Yu-Heng Lin'}, {'authorId': '2108447165', 'name': 'Wei-Yao Wang'}, {'authorId': '2131643233', 'name': 'Wenjie Peng'}]","{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/30584/32746', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1609/aaai.v38i21.30584?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/aaai.v38i21.30584, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we present the coachai badminton environment, a reinforcement learning (rl) environment tailored for ai-driven sports analytics. in contrast to traditional environments using rule-based opponents or simplistic physics-based randomness, our environment integrates authentic opponent ais and realistic randomness derived from real-world matches data to bridge the performance gap encountered in real-game deployments. this novel feature enables rl agents to seamlessly adapt to genuine scenarios. the coachai badminton environment empowers researchers to validate strategies in intricate real-world settings, offering: i) realistic opponent simulation for rl training; ii) visualizations for evaluation; and iii) performance benchmarks for assessing agent capabilities. by bridging the rl environment with actual badminton games, our environment is able to advance the discovery of winning strategies for players. our code is available at https://github.com/wywywang/coachai-projects/tree/main/strategic%20environment.",https://ojs.aaai.org/index.php/AAAI/article/download/30584/32746
f23ec2102374845539b8fe493b4e281079b3e97f,A Review of YOLO Models for Soccer-Based Object Detection,"The application of AI-driven computer vision techniques to sports footage for the purpose of automatic insight generation is a growing area of research and development. The ability to detect players of various teams along with other entities is a foundational component of such activities. This paper describes the machine learning-based detection of soccer players, balls, goalkeepers, referees, assistant referees, and other attendees from multiple teams which form the initial steps for soccer analytics. This study performs an empirical analysis of various versions of the computer vision model YOLO (You Only Look Once) using the open source soccer dataset named SoccerNet. The images contained within are trained on YOLO V3, V5, V8 and V9 with epoch configurations 1, 5, 10, 25, and 50 to facilitate a broad review of the capabilities of YOLO models. The results are evaluated using mAP50 and mAP50-95 (Mean Average Precision) metrics. YOLOv9-(9c, 9e) weights exhibited a similar level of performance to those of YOLOv8(8l, 8x), which both outperformed versions V3 and V5. However, YOLOv9 resulted in a higher true positive rate than YOLOv8, which suggests that a multi-metric analysis is pertinent for model ranking. The results of each model variant utilised are reported and visualized for reproducibility and to form a benchmark supporting future studies. The implementation was performed using the Python-based Ultralytics library.",2024,"[{'authorId': '2332380211', 'name': 'Peter Sunny Shanthveer Markappa'}, {'authorId': '1410433106', 'name': 'Christian O’Leary'}, {'authorId': '2064381908', 'name': 'Conor Lynch'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICDS62089.2024.10756443?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICDS62089.2024.10756443, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the application of ai-driven computer vision techniques to sports footage for the purpose of automatic insight generation is a growing area of research and development. the ability to detect players of various teams along with other entities is a foundational component of such activities. this paper describes the machine learning-based detection of soccer players, balls, goalkeepers, referees, assistant referees, and other attendees from multiple teams which form the initial steps for soccer analytics. this study performs an empirical analysis of various versions of the computer vision model yolo (you only look once) using the open source soccer dataset named soccernet. the images contained within are trained on yolo v3, v5, v8 and v9 with epoch configurations 1, 5, 10, 25, and 50 to facilitate a broad review of the capabilities of yolo models. the results are evaluated using map50 and map50-95 (mean average precision) metrics. yolov9-(9c, 9e) weights exhibited a similar level of performance to those of yolov8(8l, 8x), which both outperformed versions v3 and v5. however, yolov9 resulted in a higher true positive rate than yolov8, which suggests that a multi-metric analysis is pertinent for model ranking. the results of each model variant utilised are reported and visualized for reproducibility and to form a benchmark supporting future studies. the implementation was performed using the python-based ultralytics library.",
d1e415d5fd5cdc7dfdde4928e9c71245e3b1db6f,Winner prediction in an ongoing one day international cricket match,"Cricket is a team sport with an intricate set of rules, where players specialize in multiple skills such as batting, bowling, and fielding. Playing conditions and home advantage also impact the game. Thus, it is quite challenging to build an accurate quantitative model for the game. In this paper, we provide a data driven approach to predict the winner of a cricket match. We divide the ongoing match into various states and provide a prediction for each state using supervised machine learning models. We employ dynamic features that account for the current match situation, together with the static features like team strength, winner of the toss, and the home advantage. We also use SHAP scores—an explainable AI technique—to interpret the proposed prediction model. We use ball-by-ball data from 1359 men’s one day international cricket matches played between January 2004 to January 2022 to present our results. We achieved the best in-play prediction accuracy of about 85% . SHAP scores reveal that during initial phases of the match, the model treats static features like team strength more important than others, in making the predictions. But as the match progresses, dynamic features capturing the current match situation become exceedingly important. Our work may be useful in preparing tools for in-play winner prediction for live cricket matches that can be used in websites and mobile applications covering the sport, in providing analytics during live television commentary, and in legal betting platforms.",2024,"[{'authorId': '2279629585', 'name': 'Yash Agrawal'}, {'authorId': '2072537', 'name': 'Kundan Kandhway'}]","{'url': 'https://content.iospress.com:443/download/journal-of-sports-analytics/jsa220735?id=journal-of-sports-analytics%2Fjsa220735', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3233/jsa-220735?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3233/jsa-220735, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cricket is a team sport with an intricate set of rules, where players specialize in multiple skills such as batting, bowling, and fielding. playing conditions and home advantage also impact the game. thus, it is quite challenging to build an accurate quantitative model for the game. in this paper, we provide a data driven approach to predict the winner of a cricket match. we divide the ongoing match into various states and provide a prediction for each state using supervised machine learning models. we employ dynamic features that account for the current match situation, together with the static features like team strength, winner of the toss, and the home advantage. we also use shap scores—an explainable ai technique—to interpret the proposed prediction model. we use ball-by-ball data from 1359 men’s one day international cricket matches played between january 2004 to january 2022 to present our results. we achieved the best in-play prediction accuracy of about 85% . shap scores reveal that during initial phases of the match, the model treats static features like team strength more important than others, in making the predictions. but as the match progresses, dynamic features capturing the current match situation become exceedingly important. our work may be useful in preparing tools for in-play winner prediction for live cricket matches that can be used in websites and mobile applications covering the sport, in providing analytics during live television commentary, and in legal betting platforms.",https://content.iospress.com:443/download/journal-of-sports-analytics/jsa220735?id=journal-of-sports-analytics%2Fjsa220735
5c7bea04e9596352fcb71e766ed0f447b3986c81,A Novel Methodology for Automating Spatio-Temporal Data Classification in Basketball Using Active Learning,"The use of machine learning on spatio-temporal datasets has generated significant interest in a range of applications, including vehicular traffic modelling and urban planning. One of the most prolific application domains is sports analytics due to the availability of real-world multi-agent datasets, where such techniques are used to recognize and predict offensive and defensive strategies in a range of team sports. However, the use of advanced machine learning techniques requires the large datasets to be annotated by domain experts, which is a time-consuming task. Active learning is a methodology that significantly cuts down the data-annotation time on large datasets. In this paper, we investigate active learning strategies to annotate spatio-temporal datasets for the purpose of classification model building. The proposed algorithms are demonstrated on a dataset obtained from professional basketball games to classify an offensive strategy known as ‘Pick-and-Roll’. Several neural network architectures are investigated for the classification of more than 900 segments of basketball plays. The results obtained suggest that the proposed, preferred, methodology is well suited for annotating large spatio-temporal datasets and has the potential to be applicable across a range of team sports and non-sports usage scenarios.",2021,"[{'authorId': '2125239463', 'name': 'Shaojun Ai'}, {'authorId': '2066524543', 'name': 'Jiaming Na'}, {'authorId': '32031702', 'name': 'V. D. Silva'}, {'authorId': '153471361', 'name': 'M. Caine'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/PRML52754.2021.9520715?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/PRML52754.2021.9520715, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the use of machine learning on spatio-temporal datasets has generated significant interest in a range of applications, including vehicular traffic modelling and urban planning. one of the most prolific application domains is sports analytics due to the availability of real-world multi-agent datasets, where such techniques are used to recognize and predict offensive and defensive strategies in a range of team sports. however, the use of advanced machine learning techniques requires the large datasets to be annotated by domain experts, which is a time-consuming task. active learning is a methodology that significantly cuts down the data-annotation time on large datasets. in this paper, we investigate active learning strategies to annotate spatio-temporal datasets for the purpose of classification model building. the proposed algorithms are demonstrated on a dataset obtained from professional basketball games to classify an offensive strategy known as ‘pick-and-roll’. several neural network architectures are investigated for the classification of more than 900 segments of basketball plays. the results obtained suggest that the proposed, preferred, methodology is well suited for annotating large spatio-temporal datasets and has the potential to be applicable across a range of team sports and non-sports usage scenarios.",
a406d154d86d0636b6b04fea5e9002009a74e7d2,Cricket Score Forecasting using Neural Networks,"Today, Sports is not what it used to be a decade ago. Technologies like Machine Learning and Artificial Intelligence have dominated it. Now there are sensors in all types of sports equipment like cricket bats, stumps, flannels, etc., which analyse the data and provide analytics, which may or may not be helpful, but we, as spectators, thoroughly enjoy the game. The terms such as Cric-Science (Cricket + Data Science) and Cricket Analytics are the fruit of ML/AI. In the last decade alone, cricket has witnessed many changes, such as the addition of a new format like T10, which is yet to be recognised by ICC, along with the introduction of many other international leagues such as IPL, BBL, PSL, CPL, apart from the widely recognised formats like Test Match, One day International and T20. With so much cricket played, the data generated is also massive. But even with these technological advancements, run rate is conventionally used to predict a team’s score in the upcoming overs. So, in this research paper, we aim to predict a team’s score using Neural Network by using the data from past balls.",2021,"[{'authorId': '1571223116', 'name': 'Prateek Gupta'}, {'authorId': '2089745577', 'name': 'Navya Sanjna Joshi'}, {'authorId': '2089728017', 'name': 'Raghuvansh Tahlan'}, {'authorId': '2153327515', 'name': 'Darpan Gupta'}, {'authorId': '2125276836', 'name': 'Ms. Saakshi Agrawal'}]","{'url': 'https://doi.org/10.35940/ijeat.e2821.0610521', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.35940/ijeat.e2821.0610521?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.35940/ijeat.e2821.0610521, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","today, sports is not what it used to be a decade ago. technologies like machine learning and artificial intelligence have dominated it. now there are sensors in all types of sports equipment like cricket bats, stumps, flannels, etc., which analyse the data and provide analytics, which may or may not be helpful, but we, as spectators, thoroughly enjoy the game. the terms such as cric-science (cricket + data science) and cricket analytics are the fruit of ml/ai. in the last decade alone, cricket has witnessed many changes, such as the addition of a new format like t10, which is yet to be recognised by icc, along with the introduction of many other international leagues such as ipl, bbl, psl, cpl, apart from the widely recognised formats like test match, one day international and t20. with so much cricket played, the data generated is also massive. but even with these technological advancements, run rate is conventionally used to predict a team’s score in the upcoming overs. so, in this research paper, we aim to predict a team’s score using neural network by using the data from past balls.",https://doi.org/10.35940/ijeat.e2821.0610521
0106d78bee8e9b946d03a762b89db99d01365aca,Learning from the Pros: Extracting Professional Goalkeeper Technique from Broadcast Footage,"Over the past few years there has been an increase in research into improving sports analytics using artificial intelligence (AI)-based techniques [1]. Much of this research has focused on extracting contributions of outfield players [2,3] or around team tactics [4,5]. However, there are fewer examples of research focused on the analysis of player technique, and in particular the technique of goalkeepers in soccer. This is especially the case when it comes to looking at lowerlevel players in grassroots sports where there are millions of players across the world rather than just creating models for the top 1% in the professional game.",2022,"[{'authorId': '2156115228', 'name': 'Matthew Wear'}, {'authorId': '2047291317', 'name': 'Ryan Beal'}, {'authorId': '2066165068', 'name': 'Tim Matthews'}, {'authorId': '2058402319', 'name': 'Tim Norman'}, {'authorId': '1805612', 'name': 'S. Ramchurn'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2202.12259, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","over the past few years there has been an increase in research into improving sports analytics using artificial intelligence (ai)-based techniques [1]. much of this research has focused on extracting contributions of outfield players [2,3] or around team tactics [4,5]. however, there are fewer examples of research focused on the analysis of player technique, and in particular the technique of goalkeepers in soccer. this is especially the case when it comes to looking at lowerlevel players in grassroots sports where there are millions of players across the world rather than just creating models for the top 1% in the professional game.",
e0c89902d7b89cea788f3b2de247ca0033b720a7,Valuing Player Actions in Counter-Strike: Global Offensive,"Esports, despite its expanding interest, lacks fundamental sports analytics resources such as accessible data or proven and reproducible analytical frameworks. Even Counter-Strike: Global Offensive (CSGO), the second most popular esport, suffers from these problems. Thus, quantitative evaluation of CSGO players, a task important to teams, media, bettors and fans, is difficult. To address this, we introduce (1) a data model for CSGO with an open-source implementation; (2) a graph distance measure for defining distances in CSGO; and (3) a context-aware framework to value players’ actions based on changes in their team’s chances of winning. Using over 70 million in-game CSGO events, we demonstrate our framework’s consistency and independence compared to existing valuation frameworks. We also provide use cases demonstrating high-impact play identification and uncertainty estimation.",2020,"[{'authorId': '8981628', 'name': 'Peter Xenopoulos'}, {'authorId': '2163458', 'name': 'Harish Doraiswamy'}, {'authorId': '77129956', 'name': 'Cláudio T. Silva'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2011.01324, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","esports, despite its expanding interest, lacks fundamental sports analytics resources such as accessible data or proven and reproducible analytical frameworks. even counter-strike: global offensive (csgo), the second most popular esport, suffers from these problems. thus, quantitative evaluation of csgo players, a task important to teams, media, bettors and fans, is difficult. to address this, we introduce (1) a data model for csgo with an open-source implementation; (2) a graph distance measure for defining distances in csgo; and (3) a context-aware framework to value players’ actions based on changes in their team’s chances of winning. using over 70 million in-game csgo events, we demonstrate our framework’s consistency and independence compared to existing valuation frameworks. we also provide use cases demonstrating high-impact play identification and uncertainty estimation.",
c93b67d8428725326a71e065f46c3278b0d34728,Computing an Optimal Pitching Strategy in a Baseball At-Bat,"The field of quantitative analytics has transformed the worldof sports over the last decade. To date, these analytic ap-proaches are statistical at their core, characterizing what isand what was, while using this information to drive decisionsabout what to do in the future. However, as we often viewteam sports, such as soccer, hockey, and baseball, as pairwisewin-lose encounters, it seems natural to model these as zero-sum games. We propose such a model for a baseball at-bat,which is a matchup between a pitcher and a batter. Specifi-cally, we propose a novel model of this encounter as a zero-sum stochastic game, in which the goal of the batter is to geton base, an outcome the pitcher aims to prevent. The valueof this game is the on-base percentage (i.e., the probabilitythat the batter gets on base). In principle, this stochastic gamecan be solved using classical approaches. The main techni-cal challenges lie in predicting the distribution of pitch loca-tions as a function of pitcher intention, predicting the distri-bution of outcomes if the batter decides to swing at a pitch,and characterizing the level of patience of a particular batter.We address these challenges by proposing novel pitcher andbatter representations as well as a novel deep neural networkarchitecture for outcome prediction. Our experiments usingKaggle data from the 2015 to 2018 Major League Baseballseasons demonstrate the efficacy of the proposed approach.",2021,"[{'authorId': '2131846644', 'name': 'Connor Douglas'}, {'authorId': '2131876781', 'name': 'Everett Witt'}, {'authorId': '2131857505', 'name': 'Mia Bendy'}, {'authorId': '1699600', 'name': 'Yevgeniy Vorobeychik'}]","{'url': 'https://journals.flvc.org/FLAIRS/article/download/133346/137669', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2110.04321, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the field of quantitative analytics has transformed the worldof sports over the last decade. to date, these analytic ap-proaches are statistical at their core, characterizing what isand what was, while using this information to drive decisionsabout what to do in the future. however, as we often viewteam sports, such as soccer, hockey, and baseball, as pairwisewin-lose encounters, it seems natural to model these as zero-sum games. we propose such a model for a baseball at-bat,which is a matchup between a pitcher and a batter. specifi-cally, we propose a novel model of this encounter as a zero-sum stochastic game, in which the goal of the batter is to geton base, an outcome the pitcher aims to prevent. the valueof this game is the on-base percentage (i.e., the probabilitythat the batter gets on base). in principle, this stochastic gamecan be solved using classical approaches. the main techni-cal challenges lie in predicting the distribution of pitch loca-tions as a function of pitcher intention, predicting the distri-bution of outcomes if the batter decides to swing at a pitch,and characterizing the level of patience of a particular batter.we address these challenges by proposing novel pitcher andbatter representations as well as a novel deep neural networkarchitecture for outcome prediction. our experiments usingkaggle data from the 2015 to 2018 major league baseballseasons demonstrate the efficacy of the proposed approach.",https://journals.flvc.org/FLAIRS/article/download/133346/137669
84484f89993094747f302163c2da1b9491721c16,Predictive analytics for market trends using AI: A study in consumer behavior,"Predictive analytics, driven by artificial intelligence (AI), is revolutionizing the understanding and forecasting of market trends, particularly in the realm of consumer behavior. This study explores the application of AIpowered predictive analytics to anticipate market dynamics and consumer preferences, offering insights that enable businesses to make informed strategic decisions. By leveraging vast datasets, AI algorithms analyze historical data, detect patterns, and predict future trends with remarkable accuracy. This capability is especially pertinent in today's fastpaced market environment, where consumer behavior is increasingly influenced by diverse factors ranging from economic conditions to social media trends. The study examines various AI techniques such as machine learning, natural language processing, and deep learning, highlighting their roles in enhancing predictive accuracy. Machine learning algorithms, for instance, can process complex and largescale data to uncover hidden correlations and forecast consumer demand. Natural language processing enables the analysis of textual data from social media, reviews, and other sources, providing a deeper understanding of consumer sentiments and emerging trends. Deep learning models, with their advanced neural networks, further refine predictions by learning intricate patterns in data. Several case studies are presented to illustrate the practical applications and benefits of AI in predictive analytics. For example, retail companies utilize AI to predict inventory needs and optimize stock levels, thereby reducing costs and improving customer satisfaction. Similarly, the study discusses how ecommerce platforms analyze browsing and purchasing patterns to personalize recommendations, enhancing user engagement and boosting sales. However, the implementation of AIdriven predictive analytics also presents challenges. Data quality and integration, privacy concerns, and the need for specialized skills in data science and AI are significant hurdles that businesses must overcome. The study emphasizes the importance of addressing these challenges to fully harness the potential of AI in predictive analytics. In conclusion, predictive analytics using AI offers transformative capabilities for understanding and forecasting market trends. By providing precise and actionable insights into consumer behavior, it enables businesses to stay ahead of the competition and cater effectively to evolving market demands. The study underscores the need for continued research and development to further enhance the accuracy and applicability of AIdriven predictive analytics in diverse market contexts.",2024,"[{'authorId': '2344372314', 'name': 'Daniel Ajiga'}, {'authorId': '2319252862', 'name': 'Patrick Azuka Okeleke'}, {'authorId': '2287925238', 'name': 'S. Folorunsho'}, {'authorId': '2319254316', 'name': 'Chinedu Ezeigweneme'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.53430/ijeru.2024.7.1.0032?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.53430/ijeru.2024.7.1.0032, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","predictive analytics, driven by artificial intelligence (ai), is revolutionizing the understanding and forecasting of market trends, particularly in the realm of consumer behavior. this study explores the application of aipowered predictive analytics to anticipate market dynamics and consumer preferences, offering insights that enable businesses to make informed strategic decisions. by leveraging vast datasets, ai algorithms analyze historical data, detect patterns, and predict future trends with remarkable accuracy. this capability is especially pertinent in today's fastpaced market environment, where consumer behavior is increasingly influenced by diverse factors ranging from economic conditions to social media trends. the study examines various ai techniques such as machine learning, natural language processing, and deep learning, highlighting their roles in enhancing predictive accuracy. machine learning algorithms, for instance, can process complex and largescale data to uncover hidden correlations and forecast consumer demand. natural language processing enables the analysis of textual data from social media, reviews, and other sources, providing a deeper understanding of consumer sentiments and emerging trends. deep learning models, with their advanced neural networks, further refine predictions by learning intricate patterns in data. several case studies are presented to illustrate the practical applications and benefits of ai in predictive analytics. for example, retail companies utilize ai to predict inventory needs and optimize stock levels, thereby reducing costs and improving customer satisfaction. similarly, the study discusses how ecommerce platforms analyze browsing and purchasing patterns to personalize recommendations, enhancing user engagement and boosting sales. however, the implementation of aidriven predictive analytics also presents challenges. data quality and integration, privacy concerns, and the need for specialized skills in data science and ai are significant hurdles that businesses must overcome. the study emphasizes the importance of addressing these challenges to fully harness the potential of ai in predictive analytics. in conclusion, predictive analytics using ai offers transformative capabilities for understanding and forecasting market trends. by providing precise and actionable insights into consumer behavior, it enables businesses to stay ahead of the competition and cater effectively to evolving market demands. the study underscores the need for continued research and development to further enhance the accuracy and applicability of aidriven predictive analytics in diverse market contexts.",
7a7ef69eb55295b16e009eec6af916c4578d2726,Orientation and Decision-Making for Soccer Based on Sports Analytics and AI: A Systematic Review,"Due to ever-growing soccer data collection approaches and progressing artificial intelligence (AI) methods, soccer analysis, evaluation, and decision-making have received increasing interest from not only the professional sports analytics realm but also the academic AI research community. AI brings game-changing approaches for soccer analytics where soccer has been a typical benchmark for AI research. The combination has been an emerging topic. In this paper, soccer match analytics are taken as a complete observation-orientation-decision-action (OODA) loop. In addition, as in AI frameworks such as that for reinforcement learning, interacting with a virtual environment enables an evolving model. Therefore, both soccer analytics in the real world and virtual domains are discussed. With the intersection of the OODA loop and the real-virtual domains, available soccer data, including event and tracking data, and diverse orientation and decision-making models for both real-world and virtual soccer matches are comprehensively reviewed. Finally, some promising directions in this interdisciplinary area are pointed out. It is claimed that paradigms for both professional sports analytics and AI research could be combined. Moreover, it is quite promising to bridge the gap between the real and virtual domains for soccer match analysis and decision-making.",2024,"[{'authorId': '2243334210', 'name': 'Zhiqiang Pu'}, {'authorId': '2226481104', 'name': 'Yi Pan'}, {'authorId': '2274051487', 'name': 'Shijie Wang'}, {'authorId': '2274485649', 'name': 'Boyin Liu'}, {'authorId': '2226688421', 'name': 'Min Chen'}, {'authorId': '2279256622', 'name': 'Hao Ma'}, {'authorId': '2274719029', 'name': 'Yixiong Cui'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JAS.2023.123807?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JAS.2023.123807, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","due to ever-growing soccer data collection approaches and progressing artificial intelligence (ai) methods, soccer analysis, evaluation, and decision-making have received increasing interest from not only the professional sports analytics realm but also the academic ai research community. ai brings game-changing approaches for soccer analytics where soccer has been a typical benchmark for ai research. the combination has been an emerging topic. in this paper, soccer match analytics are taken as a complete observation-orientation-decision-action (ooda) loop. in addition, as in ai frameworks such as that for reinforcement learning, interacting with a virtual environment enables an evolving model. therefore, both soccer analytics in the real world and virtual domains are discussed. with the intersection of the ooda loop and the real-virtual domains, available soccer data, including event and tracking data, and diverse orientation and decision-making models for both real-world and virtual soccer matches are comprehensively reviewed. finally, some promising directions in this interdisciplinary area are pointed out. it is claimed that paradigms for both professional sports analytics and ai research could be combined. moreover, it is quite promising to bridge the gap between the real and virtual domains for soccer match analysis and decision-making.",
7f39fb821ead23ca65bb2bba11ac61cb84d09075,AI in Higher Education: Insights from Student Surveys and Predictive Analytics using PSO-Guided WOA and Linear Regression,"Artificial intelligence (AI) and machine learning (ML) prediction can change education in a drastic way, where there can be both improvements and regressions concerning the way learning is approached. With individualized learning experiences, being able to spot the students who are falling behind",2024,"[{'authorId': '2213155699', 'name': 'S. Towfek'}, {'authorId': '2244713847', 'name': 'Nima Khodadadi'}, {'authorId': '7833679', 'name': 'L. Abualigah'}, {'authorId': '2275001309', 'name': 'Faris H. Rizk'}]","{'url': 'https://jaiep.journals.ekb.eg/article_354003_19fe159da1d32d8628a13261bd5d9309.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.21608/jaiep.2024.354003?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.21608/jaiep.2024.354003, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",ai in higher education: insights from student surveys and predictive analytics using pso-guided woa and linear regression,https://jaiep.journals.ekb.eg/article_354003_19fe159da1d32d8628a13261bd5d9309.pdf
4c9b0b8e011ce89ffcb7bc8b2184e5924a73206b,Efficient resource allocation in cloud computing environments using AI-driven predictive analytics,"This paper proposes an innovative AI-driven approach for efficient resource allocation in cloud computing environments using predictive analytics. The study addresses the critical challenge of optimizing resource utilization while maintaining high quality of service in dynamic cloud infrastructures. A hybrid predictive model combining XGBoost and LSTM networks is developed to forecast workload patterns across various time horizons. The model leverages historical data from a large-scale cloud environment, encompassing 1000 servers and over 52 million data points. A dynamic resource scaling algorithm is introduced, which integrates the predictive model outputs with real-time system state information to make proactive allocation decisions. The proposed framework incorporates advanced techniques such as workload consolidation, resource oversubscription, and elastic resource pools to maximize utilization efficiency. Experimental results demonstrate significant improvements in key performance indicators, including increasing resource utilization from 65% to 83%, reducing SLA violation rates from 2.5% to 0.8%, and enhancing energy efficiency, with PUE improving from 1.4 to 1.18. Comparative analysis shows that the proposed model outperforms existing prediction accuracy and resource allocation efficiency methods. The study contributes to the field by presenting a comprehensive, AI-driven solution that addresses the complexities of modern cloud environments and paves the way for more intelligent and autonomous cloud resource management systems.",2024,"[{'authorId': '2293771020', 'name': 'Haotian Zheng'}, {'authorId': '2316297229', 'name': 'Kangming Xu'}, {'authorId': '2319390719', 'name': 'Mingxuan Zhang'}, {'authorId': '2320735390', 'name': 'Hao Tan'}, {'authorId': '2316030613', 'name': 'Hanzhe Li'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.54254/2755-2721/82/2024glg0055?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.54254/2755-2721/82/2024glg0055, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper proposes an innovative ai-driven approach for efficient resource allocation in cloud computing environments using predictive analytics. the study addresses the critical challenge of optimizing resource utilization while maintaining high quality of service in dynamic cloud infrastructures. a hybrid predictive model combining xgboost and lstm networks is developed to forecast workload patterns across various time horizons. the model leverages historical data from a large-scale cloud environment, encompassing 1000 servers and over 52 million data points. a dynamic resource scaling algorithm is introduced, which integrates the predictive model outputs with real-time system state information to make proactive allocation decisions. the proposed framework incorporates advanced techniques such as workload consolidation, resource oversubscription, and elastic resource pools to maximize utilization efficiency. experimental results demonstrate significant improvements in key performance indicators, including increasing resource utilization from 65% to 83%, reducing sla violation rates from 2.5% to 0.8%, and enhancing energy efficiency, with pue improving from 1.4 to 1.18. comparative analysis shows that the proposed model outperforms existing prediction accuracy and resource allocation efficiency methods. the study contributes to the field by presenting a comprehensive, ai-driven solution that addresses the complexities of modern cloud environments and paves the way for more intelligent and autonomous cloud resource management systems.",
dcb7e06482def9f7dcfe4a0cceb4f655700933cd,Injury Patterns and Impact on Performance in the NBA League Using Sports Analytics,"This research paper examines Sports Analytics, focusing on injury patterns in the National Basketball Association (NBA) and their impact on players’ performance. It employs a unique dataset to identify common NBA injuries, determine the most affected anatomical areas, and analyze how these injuries influence players’ post-recovery performance. This study’s novelty lies in its integrative approach that combines injury data with performance metrics and salary data, providing new insights into the relationship between injuries and economic and on-court performance. It investigates the periodicity and seasonality of injuries, seeking patterns related to time and external factors. Additionally, it examines the effect of specific injuries on players’ per-match analytics and performance, offering perspectives on the implications of injury rehabilitation for player performance. This paper contributes significantly to sports analytics, assisting coaches, sports medicine professionals, and team management in developing injury prevention strategies, optimizing player rotations, and creating targeted rehabilitation plans. Its findings illuminate the interplay between injuries, salaries, and performance in the NBA, aiming to enhance player welfare and the league’s overall competitiveness. With a comprehensive and sophisticated analysis, this research offers unprecedented insights into the dynamics of injuries and their long-term effects on athletes.",2024,"[{'authorId': '1742409056', 'name': 'Vangelis Sarlis'}, {'authorId': '2274387490', 'name': 'George Papageorgiou'}, {'authorId': '2133997497', 'name': 'Christos Tjortjis'}]","{'url': 'https://www.mdpi.com/2079-3197/12/2/36/pdf?version=1708072653', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/computation12020036?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/computation12020036, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this research paper examines sports analytics, focusing on injury patterns in the national basketball association (nba) and their impact on players’ performance. it employs a unique dataset to identify common nba injuries, determine the most affected anatomical areas, and analyze how these injuries influence players’ post-recovery performance. this study’s novelty lies in its integrative approach that combines injury data with performance metrics and salary data, providing new insights into the relationship between injuries and economic and on-court performance. it investigates the periodicity and seasonality of injuries, seeking patterns related to time and external factors. additionally, it examines the effect of specific injuries on players’ per-match analytics and performance, offering perspectives on the implications of injury rehabilitation for player performance. this paper contributes significantly to sports analytics, assisting coaches, sports medicine professionals, and team management in developing injury prevention strategies, optimizing player rotations, and creating targeted rehabilitation plans. its findings illuminate the interplay between injuries, salaries, and performance in the nba, aiming to enhance player welfare and the league’s overall competitiveness. with a comprehensive and sophisticated analysis, this research offers unprecedented insights into the dynamics of injuries and their long-term effects on athletes.",https://www.mdpi.com/2079-3197/12/2/36/pdf?version=1708072653
5e4e07d278bb38e05a1cdcda3fab7ac5fcca9ed4,Revolutionizing Sports Education using AI & ML,"In the realm of sports education and performance analysis, there exists a pressing need to overcome barriers such as geographical limitations, cost constraints, and time constraints inherent in traditional teaching methodologies. In response to these challenges, this paper presents a novel sports education system leveraging artificial intelligence (AI) technologies. This allinclusive system allows for easy access to sports academies and training facilities based on geographic proximity by introducing an innovative teaching platform driven by AI and GPS integration. Moreover, it offers an extensive library of sports laws, sophisticated strategies, and professional advice, encouraging ongoing skill development. Setting goals and closely observing performance are made easier by the system's integration of AI-driven forecasts, such as victory probabilities. The central aim of this initiative is to redefine the landscape of sports education by offering a convenient, cost-effective, and highly efficient solution accessible to individuals at all proficiency levels. In addition to its educational advantages, the system is poised to make significant contributions to sports analytics, supplying extensive data and insights for both researchers and practitioners. This proposal advocates a progressive approach that moves beyond traditional methods, heralding a new era in sports education and performance analytics",2024,"[{'authorId': '2330128572', 'name': 'Shreyash Andhale'}, {'authorId': '2330130159', 'name': 'Om Salunke'}, {'authorId': '2330129674', 'name': 'Tirse Siddhesh'}, {'authorId': '2330127573', 'name': 'Kasar Vivek'}, {'authorId': '2330126718', 'name': 'Thorat Vaibhav'}, {'authorId': '2274597090', 'name': 'Prof. Ravindra Pandit'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.48175/ijarsct-22102?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.48175/ijarsct-22102, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the realm of sports education and performance analysis, there exists a pressing need to overcome barriers such as geographical limitations, cost constraints, and time constraints inherent in traditional teaching methodologies. in response to these challenges, this paper presents a novel sports education system leveraging artificial intelligence (ai) technologies. this allinclusive system allows for easy access to sports academies and training facilities based on geographic proximity by introducing an innovative teaching platform driven by ai and gps integration. moreover, it offers an extensive library of sports laws, sophisticated strategies, and professional advice, encouraging ongoing skill development. setting goals and closely observing performance are made easier by the system's integration of ai-driven forecasts, such as victory probabilities. the central aim of this initiative is to redefine the landscape of sports education by offering a convenient, cost-effective, and highly efficient solution accessible to individuals at all proficiency levels. in addition to its educational advantages, the system is poised to make significant contributions to sports analytics, supplying extensive data and insights for both researchers and practitioners. this proposal advocates a progressive approach that moves beyond traditional methods, heralding a new era in sports education and performance analytics",
06db2d30d79a8504cba5cb801dc28c2bd7cabac4,"Methodology and evaluation in sports analytics: challenges, approaches, and lessons learned","There has been an explosion of data collected about sports. Because such data is extremely rich and complex, machine learning is increasingly being used to extract actionable insights from it. Typically, machine learning is used to build models and indicators that capture the skills, capabilities, and tendencies of athletes and teams. Such indicators and models are in turn used to inform decision-making at professional clubs. Designing these indicators requires paying careful attention to a number of subtle issues from a methodological and evaluation perspective. In this paper, we highlight these challenges in sports and discuss a variety of approaches for handling them. Methodologically, we highlight that dependencies affect how to perform data partitioning for evaluation as well as the need to consider contextual factors. From an evaluation perspective, we draw a distinction between evaluating the developed indicators themselves versus the underlying models that power them. We argue that both aspects must be considered, but that they require different approaches. We hope that this article helps bridge the gap between traditional sports expertise and modern data analytics by providing a structured framework with practical examples.",2024,"[{'authorId': '2266030791', 'name': 'Jesse Davis'}, {'authorId': '51911758', 'name': 'L. Bransen'}, {'authorId': '1393693474', 'name': 'Laurens Devos'}, {'authorId': '2311928272', 'name': 'Arne Jaspers'}, {'authorId': '2143963033', 'name': 'Wannes Meert'}, {'authorId': '66744334', 'name': 'Pieter Robberechts'}, {'authorId': '2127528576', 'name': 'Jan Van Haaren'}, {'authorId': '2227571395', 'name': 'Maaike Van Roy'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s10994-024-06585-0.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10994-024-06585-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10994-024-06585-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","there has been an explosion of data collected about sports. because such data is extremely rich and complex, machine learning is increasingly being used to extract actionable insights from it. typically, machine learning is used to build models and indicators that capture the skills, capabilities, and tendencies of athletes and teams. such indicators and models are in turn used to inform decision-making at professional clubs. designing these indicators requires paying careful attention to a number of subtle issues from a methodological and evaluation perspective. in this paper, we highlight these challenges in sports and discuss a variety of approaches for handling them. methodologically, we highlight that dependencies affect how to perform data partitioning for evaluation as well as the need to consider contextual factors. from an evaluation perspective, we draw a distinction between evaluating the developed indicators themselves versus the underlying models that power them. we argue that both aspects must be considered, but that they require different approaches. we hope that this article helps bridge the gap between traditional sports expertise and modern data analytics by providing a structured framework with practical examples.",https://link.springer.com/content/pdf/10.1007/s10994-024-06585-0.pdf
686c2bb5ec3d60f2d0795271bc0697e9a4559414,Using AI for Predictive Analytics in Financial Management,"The use of artificial intelligence (AI) in financial management for predictive analytics is a rapidly emerging topic. This research study investigates the numerous ways in which artificial intelligence (AI) might be utilized to enhance financial forecasting and decision-making. The article opens by addressing the benefits of utilizing AI for predictive analytics, such as the capacity to manage vast volumes of data, find patterns and trends, and produce high-accuracy forecasts. The study then delves into numerous particular uses of artificial intelligence in financial management, such as credit risk analysis, portfolio management, and fraud detection. Finally, the study discusses the problems and limits of employing AI for predictive analytics in financial management, as well as future research objectives in this field. Overall, this study article indicates how artificial intelligence (AI) has the potential to change financial management by delivering more accurate and efficient decision-making tools.",2023,"[{'authorId': '2060268388', 'name': 'M. Goel'}, {'authorId': '2224752090', 'name': 'P. K. Tomar'}, {'authorId': '2199255962', 'name': 'Lakshmipriya Vinjamuri'}, {'authorId': '2224954287', 'name': 'G. Swamy Reddy'}, {'authorId': '2224771125', 'name': 'Mustafa Al-Taee'}, {'authorId': '97852614', 'name': 'M. Alazzam'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICACITE57410.2023.10182711?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICACITE57410.2023.10182711, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the use of artificial intelligence (ai) in financial management for predictive analytics is a rapidly emerging topic. this research study investigates the numerous ways in which artificial intelligence (ai) might be utilized to enhance financial forecasting and decision-making. the article opens by addressing the benefits of utilizing ai for predictive analytics, such as the capacity to manage vast volumes of data, find patterns and trends, and produce high-accuracy forecasts. the study then delves into numerous particular uses of artificial intelligence in financial management, such as credit risk analysis, portfolio management, and fraud detection. finally, the study discusses the problems and limits of employing ai for predictive analytics in financial management, as well as future research objectives in this field. overall, this study article indicates how artificial intelligence (ai) has the potential to change financial management by delivering more accurate and efficient decision-making tools.",
d7348e5f84da71c2441c323f5c72b8084150651e,AI-Embedded Motion Sensors for Sports Performance Analytics,"Motion sensing technology is widely used in healthcare, sports, consumer electronics, etc. On the other hand, Artificial intelligence (AI) enables the development of wearable sensors that can recognize and analyze human motions. In this study, we developed a wearable wireless motion sensing system with AI-embedded inertial measurement units (AIMUs), combined with visual analysis, to evaluate and optimize athletes’ performance in sports such as gymnastics. In the experiment, a gymnast performed an entire vaulting routine while wearing 11 AIMUs, and the motion data were transmitted to a cloud server through Bluetooth gateways. This system can achieve the segmentation of vaulting phases and the evaluation of detailed movements. The experimental results showed a 4.57% estimation error in flight height. This AI-embedded motion sensor system has the potential to provide an intuitive and easy-to-understand way to present athlete performance to coaches and athletes themselves. Furthermore, its continued development could assist athletes’ training, provide quantitative sports performance indicators, significantly improve elite athletes’ training efficiency, and monitor their health regularly.",2024,"[{'authorId': '2307836076', 'name': 'Xiaodong Yu'}, {'authorId': '2307608572', 'name': 'Yushen Chai'}, {'authorId': '2302308442', 'name': 'Meng Chen'}, {'authorId': '46266490', 'name': 'Guanglie Zhang'}, {'authorId': '2307609080', 'name': 'Fei Fei'}, {'authorId': '2275772648', 'name': 'Yuliang Zhao'}, {'authorId': '2307681630', 'name': 'W. Li'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/NSENS62142.2024.10561438?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/NSENS62142.2024.10561438, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","motion sensing technology is widely used in healthcare, sports, consumer electronics, etc. on the other hand, artificial intelligence (ai) enables the development of wearable sensors that can recognize and analyze human motions. in this study, we developed a wearable wireless motion sensing system with ai-embedded inertial measurement units (aimus), combined with visual analysis, to evaluate and optimize athletes’ performance in sports such as gymnastics. in the experiment, a gymnast performed an entire vaulting routine while wearing 11 aimus, and the motion data were transmitted to a cloud server through bluetooth gateways. this system can achieve the segmentation of vaulting phases and the evaluation of detailed movements. the experimental results showed a 4.57% estimation error in flight height. this ai-embedded motion sensor system has the potential to provide an intuitive and easy-to-understand way to present athlete performance to coaches and athletes themselves. furthermore, its continued development could assist athletes’ training, provide quantitative sports performance indicators, significantly improve elite athletes’ training efficiency, and monitor their health regularly.",
954df3a78b1069ba2b4a36ccd00f516983471c3e,Construction of Sports Training Management Information System Using AI Action Recognition,"With the development of science and technology, more and more fields have begun to use AI to provide convenient services for humans. Artificial intelligence (AI) refers to a new technology that uses human thinking to respond accordingly through computers and robots to assist human beings. Action recognition is an important research project that needs to be broken through in many industries, such as security system, martial arts instruction, and dance training. This paper aims to study a method for action recognition using AI technology and to build a sports training management information system. In this paper, a recognition model and related algorithms using a convolutional neural network (CNN) are proposed, and an intelligent sports training management information system is constructed. The system and the model are tested, the action recognition effect of 60 athletes in a university is tested, and the comparison with the traditional recognition algorithm is carried out. The results show that the CNN recognition accuracy test results used in this paper are generally more than 90%, while the traditional recognition accuracy rate is only about 75%, and the highest is not more than 86%; the training management information system of this paper takes about 15.7 s, and the maximum time is not more than 10 s, while the traditional recognition system takes about 15.7 s, which is about twice the time of the system in this paper. Therefore, it shows that the CNN recognition method in this paper has a significantly better effect on the recognition of athletes’ movements, and the sports training management information system constructed in this paper is less time-consuming and faster and has certain feasibility.",2022,"[{'authorId': '2173375255', 'name': 'Dali Cheng'}, {'authorId': '48017245', 'name': 'Hong Wang'}, {'authorId': '2173158370', 'name': 'Min Li'}]","{'url': 'https://downloads.hindawi.com/journals/sp/2022/8393612.pdf', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1155/2022/8393612?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1155/2022/8393612, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with the development of science and technology, more and more fields have begun to use ai to provide convenient services for humans. artificial intelligence (ai) refers to a new technology that uses human thinking to respond accordingly through computers and robots to assist human beings. action recognition is an important research project that needs to be broken through in many industries, such as security system, martial arts instruction, and dance training. this paper aims to study a method for action recognition using ai technology and to build a sports training management information system. in this paper, a recognition model and related algorithms using a convolutional neural network (cnn) are proposed, and an intelligent sports training management information system is constructed. the system and the model are tested, the action recognition effect of 60 athletes in a university is tested, and the comparison with the traditional recognition algorithm is carried out. the results show that the cnn recognition accuracy test results used in this paper are generally more than 90%, while the traditional recognition accuracy rate is only about 75%, and the highest is not more than 86%; the training management information system of this paper takes about 15.7 s, and the maximum time is not more than 10 s, while the traditional recognition system takes about 15.7 s, which is about twice the time of the system in this paper. therefore, it shows that the cnn recognition method in this paper has a significantly better effect on the recognition of athletes’ movements, and the sports training management information system constructed in this paper is less time-consuming and faster and has certain feasibility.",https://downloads.hindawi.com/journals/sp/2022/8393612.pdf
9855170663400947ee4ef102db259d0c18fd16d6,Utilizing Artificial Intelligence for Enhancing Performance and Preventing Injuries in Sports Analytics,"The sports sector could see a revolution in player performance enhancement and injury prevention, especially with recent developments in artificial intelligence (AI). In order to identify areas for improvement and potential injury risks, this proposed work aims to utilize the potential of AI techniques, such as XGBoost, to evaluate extensive player data, including movement patterns, biomechanics, and physical condition. This strategy is unusual because it combines real-time feedback systems with AI-powered predictive modeling to offer athletes and coaches individualized training advice and early warnings about potential injury risks. Cleaning and normalization were done during the preparation phase to make sure the data was suitable for analysis. Utilizing XGBoost for feature extraction allowed for the identification of critical factors affecting efficiency and injury risk. In sports analytics, the suggested XGBoost-AI system was compared to other AI-based techniques for improving performance and avoiding injuries. The study’s findings show that the XGBoost classifier significantly improves performance accuracy, which may reach 96%. This is in contrast to conventional approaches that depend on subjective evaluations and human data analysis, which can result in errors and inefficiencies. Python is used to implement the suggested work. AI-driven sports analytics platform can improve game strategy, fan engagement, and data-driven decision-making for sports organizations, enhancing competitiveness and sustainability in the sports industry.",2024,"[{'authorId': '2196325332', 'name': 'T. Shukla'}, {'authorId': '2327224072', 'name': 'Divya Nimma'}, {'authorId': '1767023', 'name': 'K. S. Pokkuluri'}, {'authorId': '2322588629', 'name': 'Syed Najmusaqib'}, {'authorId': '2344253817', 'name': 'K.K. Sivakumar'}, {'authorId': '2274692894', 'name': 'B. K. Bala'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/IC-SIT63503.2024.10862063?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IC-SIT63503.2024.10862063, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the sports sector could see a revolution in player performance enhancement and injury prevention, especially with recent developments in artificial intelligence (ai). in order to identify areas for improvement and potential injury risks, this proposed work aims to utilize the potential of ai techniques, such as xgboost, to evaluate extensive player data, including movement patterns, biomechanics, and physical condition. this strategy is unusual because it combines real-time feedback systems with ai-powered predictive modeling to offer athletes and coaches individualized training advice and early warnings about potential injury risks. cleaning and normalization were done during the preparation phase to make sure the data was suitable for analysis. utilizing xgboost for feature extraction allowed for the identification of critical factors affecting efficiency and injury risk. in sports analytics, the suggested xgboost-ai system was compared to other ai-based techniques for improving performance and avoiding injuries. the study’s findings show that the xgboost classifier significantly improves performance accuracy, which may reach 96%. this is in contrast to conventional approaches that depend on subjective evaluations and human data analysis, which can result in errors and inefficiencies. python is used to implement the suggested work. ai-driven sports analytics platform can improve game strategy, fan engagement, and data-driven decision-making for sports organizations, enhancing competitiveness and sustainability in the sports industry.",
01b1930f79c9995e58677525890634a002e082bc,Big Data Analytics Using Artificial Intelligence,Data analytics using artificial intelligence is the process of leveraging advanced AI techniques to extract insights and knowledge from large and complex datasets [...],2023,"[{'authorId': '2238700690', 'name': 'Amir H. Gandomi'}, {'authorId': '2149500413', 'name': 'Fang Chen'}, {'authorId': '7833679', 'name': 'L. Abualigah'}]","{'url': 'https://www.mdpi.com/2079-9292/12/4/957/pdf?version=1676441943', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/electronics12040957?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/electronics12040957, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",big data analytics using artificial intelligence,https://www.mdpi.com/2079-9292/12/4/957/pdf?version=1676441943
7c994dc270f8a8ae1ca023a2a41222c10ce3b615,Security Testing for Mobile Applications Using AI and ML Algorithms,"Mobile apps have revolutionized the digital world, making mobile devices essential to billions of users' everyday lives. This growth in mobile use has also increased security concerns to mobile apps, from data breaches to malicious software assaults. Traditional security testing methodologies, although useful, sometimes fail to address these attackers' sophistication and evolution. This study examines the use of AI and ML algorithms in mobile application security testing to improve vulnerability discovery, analysis, and mitigation.AI and ML algorithms use massive volumes of data and real-time analytics to spot vulnerabilities faster and more accurately than conventional security testing techniques. These technologies enable automated code analysis, anomaly detection, behavioral analysis, and penetration testing, creating a proactive and adaptive security framework. Automation employing AI and ML may find source code security flaws by learning from a massive database of known vulnerabilities and applying it to fresh code. This speeds up manual code checks and improves vulnerability detection. Anomaly detection techniques may monitor application user behavior for abnormalities that may signal security issues like illegal access or data exfiltration.By identifying unusual user behavior and highlighting it, behavioral analysis improves application security. This method detects suspicious activity in real time, allowing fast threat action. AI-driven penetration testing may also mimic complex attacks to find application defensive gaps that hostile actors might exploit.Due to frequent app updates and feature additions, AI and ML in mobile application security testing provide continuous security evaluation. These algorithms can learn and adapt to new risks, keeping security testing current and effective as threats change. Implementing AI and ML in security testing is difficult. AI systems may falsely label normal actions as security risks, which is a major worry. This might cause unneeded interruptions and diminish system dependability. Large datasets used to train AI algorithms present privacy and ethical problems. Despite these limitations, AI and ML in mobile app security assessment have substantial advantages. These technologies are crucial in the fight against mobile security risks because they can analyze massive volumes of data, discover complicated patterns, and respond to emerging threats in real time. AI and ML in security testing will likely become mainstream as mobile apps become more complicated and important, assuring user security and reliability. This article indicates that AI and ML in mobile application security testing advances cybersecurity. These solutions solve mobile app security issues by improving security testing accuracy, speed, and flexibility. To properly secure mobile apps using AI and ML, future research should address security testing difficulties including false positives and data privacy.",2024,"[{'authorId': '2318499010', 'name': 'Vijay Bhasker Reddy Bhimanapati'}, {'authorId': '2319195695', 'name': 'Shalu Jain'}, {'authorId': '2318498814', 'name': 'Pandi Kirupa Gopalakrishna Pandian'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.36676/jqst.v1.i2.15?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.36676/jqst.v1.i2.15, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mobile apps have revolutionized the digital world, making mobile devices essential to billions of users' everyday lives. this growth in mobile use has also increased security concerns to mobile apps, from data breaches to malicious software assaults. traditional security testing methodologies, although useful, sometimes fail to address these attackers' sophistication and evolution. this study examines the use of ai and ml algorithms in mobile application security testing to improve vulnerability discovery, analysis, and mitigation.ai and ml algorithms use massive volumes of data and real-time analytics to spot vulnerabilities faster and more accurately than conventional security testing techniques. these technologies enable automated code analysis, anomaly detection, behavioral analysis, and penetration testing, creating a proactive and adaptive security framework. automation employing ai and ml may find source code security flaws by learning from a massive database of known vulnerabilities and applying it to fresh code. this speeds up manual code checks and improves vulnerability detection. anomaly detection techniques may monitor application user behavior for abnormalities that may signal security issues like illegal access or data exfiltration.by identifying unusual user behavior and highlighting it, behavioral analysis improves application security. this method detects suspicious activity in real time, allowing fast threat action. ai-driven penetration testing may also mimic complex attacks to find application defensive gaps that hostile actors might exploit.due to frequent app updates and feature additions, ai and ml in mobile application security testing provide continuous security evaluation. these algorithms can learn and adapt to new risks, keeping security testing current and effective as threats change. implementing ai and ml in security testing is difficult. ai systems may falsely label normal actions as security risks, which is a major worry. this might cause unneeded interruptions and diminish system dependability. large datasets used to train ai algorithms present privacy and ethical problems. despite these limitations, ai and ml in mobile app security assessment have substantial advantages. these technologies are crucial in the fight against mobile security risks because they can analyze massive volumes of data, discover complicated patterns, and respond to emerging threats in real time. ai and ml in security testing will likely become mainstream as mobile apps become more complicated and important, assuring user security and reliability. this article indicates that ai and ml in mobile application security testing advances cybersecurity. these solutions solve mobile app security issues by improving security testing accuracy, speed, and flexibility. to properly secure mobile apps using ai and ml, future research should address security testing difficulties including false positives and data privacy.",
a488ec9d53d410945c9e63da120da5b6f3d095e6,A Survey of AI Techniques in IoT Applications with Use Case Investigations in the Smart Environmental Monitoring and Analytics in Real-Time IoT Platform,"In this paper, we have developed the SEMAR (Smart Environmental Monitoring and Analytics in Real-Time) IoT application server platform for fast deployments of IoT application systems. It provides various integration capabilities for the collection, display, and analysis of sensor data on a single platform. Recently, Artificial Intelligence (AI) has become very popular and widely used in various applications including IoT. To support this growth, the integration of AI into SEMAR is essential to enhance its capabilities after identifying the current trends of applicable AI technologies in IoT applications. In this paper, we first provide a comprehensive review of IoT applications using AI techniques in the literature. They cover predictive analytics, image classification, object detection, text spotting, auditory perception, Natural Language Processing (NLP), and collaborative AI. Next, we identify the characteristics of each technique by considering the key parameters, such as software requirements, input/output (I/O) data types, processing methods, and computations. Third, we design the integration of AI techniques into SEMAR based on the findings. Finally, we discuss use cases of SEMAR for IoT applications with AI techniques. The implementation of the proposed design in SEMAR and its use to IoT applications will be in future works.",2024,"[{'authorId': '72313304', 'name': 'Y. Panduman'}, {'authorId': '2258398294', 'name': 'Nobuo Funabiki'}, {'authorId': '2222309372', 'name': 'Evianita Dewi Fajrianti'}, {'authorId': '2223505837', 'name': 'Shihao Fang'}, {'authorId': '1831245', 'name': 'S. Sukaridhoto'}]","{'url': 'https://www.mdpi.com/2078-2489/15/3/153/pdf?version=1709979648', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/info15030153?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/info15030153, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this paper, we have developed the semar (smart environmental monitoring and analytics in real-time) iot application server platform for fast deployments of iot application systems. it provides various integration capabilities for the collection, display, and analysis of sensor data on a single platform. recently, artificial intelligence (ai) has become very popular and widely used in various applications including iot. to support this growth, the integration of ai into semar is essential to enhance its capabilities after identifying the current trends of applicable ai technologies in iot applications. in this paper, we first provide a comprehensive review of iot applications using ai techniques in the literature. they cover predictive analytics, image classification, object detection, text spotting, auditory perception, natural language processing (nlp), and collaborative ai. next, we identify the characteristics of each technique by considering the key parameters, such as software requirements, input/output (i/o) data types, processing methods, and computations. third, we design the integration of ai techniques into semar based on the findings. finally, we discuss use cases of semar for iot applications with ai techniques. the implementation of the proposed design in semar and its use to iot applications will be in future works.",https://www.mdpi.com/2078-2489/15/3/153/pdf?version=1709979648
7494c120ab3f3a37f0007cbfccd687aa76d91f8f,COVID-19 prediction using AI analytics for South Korea,"The severe spread of the COVID-19 pandemic has created a situation of public health emergency and global awareness. In our research, we analyzed the demographical factors affecting the global pandemic spread along with the features that lead to death due to the infection. Modeling results stipulate that the mortality rate increase as the age increase and it is found that most of the death cases belong to the age group 60–80. Cluster-based analysis of age groups is also conducted to analyze the maximum targeted age-groups. An association between positive COVID-19 cases and deceased cases are also presented, with the impact on male and female death cases due to corona. Additionally, we have also presented an artificial intelligence-based statistical approach to predict the survival chances of corona infected people in South Korea with the analysis of the impact on the exploratory factors, including age-groups, gender, temporal evolution, etc. To analyze the coronavirus cases, we applied machine learning with hyperparameters tuning and deep learning models with an autoencoder-based approach for estimating the influence of the disparate features on the spread of the disease and predict the survival possibilities of the quarantined patients in isolation. The model calibrated in the study is based on positive corona infection cases and presents the analysis over different aspects that proven to be impactful to analyze the temporal trends in the current situation along with the exploration of deceased cases due to coronavirus. Analysis delineates key points in the outbreak spreading, indicating that the models driven by machine intelligence and deep learning can be effective in providing a quantitative view of the epidemical outbreak.",2021,"[{'authorId': '2314074', 'name': 'Adwitiya Sinha'}, {'authorId': '50344400', 'name': 'Megha Rathi'}]","{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8027716', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8027716, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the severe spread of the covid-19 pandemic has created a situation of public health emergency and global awareness. in our research, we analyzed the demographical factors affecting the global pandemic spread along with the features that lead to death due to the infection. modeling results stipulate that the mortality rate increase as the age increase and it is found that most of the death cases belong to the age group 60–80. cluster-based analysis of age groups is also conducted to analyze the maximum targeted age-groups. an association between positive covid-19 cases and deceased cases are also presented, with the impact on male and female death cases due to corona. additionally, we have also presented an artificial intelligence-based statistical approach to predict the survival chances of corona infected people in south korea with the analysis of the impact on the exploratory factors, including age-groups, gender, temporal evolution, etc. to analyze the coronavirus cases, we applied machine learning with hyperparameters tuning and deep learning models with an autoencoder-based approach for estimating the influence of the disparate features on the spread of the disease and predict the survival possibilities of the quarantined patients in isolation. the model calibrated in the study is based on positive corona infection cases and presents the analysis over different aspects that proven to be impactful to analyze the temporal trends in the current situation along with the exploration of deceased cases due to coronavirus. analysis delineates key points in the outbreak spreading, indicating that the models driven by machine intelligence and deep learning can be effective in providing a quantitative view of the epidemical outbreak.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8027716
0a66086a2f23ef968f65395f88cdb2f4d458923a,Progressive statistics for studies in sports medicine and exercise science.,"Statistical guidelines and expert statements are now available to assist in the analysis and reporting of studies in some biomedical disciplines. We present here a more progressive resource for sample-based studies, meta-analyses, and case studies in sports medicine and exercise science. We offer forthright advice on the following controversial or novel issues: using precision of estimation for inferences about population effects in preference to null-hypothesis testing, which is inadequate for assessing clinical or practical importance; justifying sample size via acceptable precision or confidence for clinical decisions rather than via adequate power for statistical significance; showing SD rather than SEM, to better communicate the magnitude of differences in means and nonuniformity of error; avoiding purely nonparametric analyses, which cannot provide inferences about magnitude and are unnecessary; using regression statistics in validity studies, in preference to the impractical and biased limits of agreement; making greater use of qualitative methods to enrich sample-based quantitative projects; and seeking ethics approval for public access to the depersonalized raw data of a study, to address the need for more scrutiny of research and better meta-analyses. Advice on less contentious issues includes the following: using covariates in linear models to adjust for confounders, to account for individual differences, and to identify potential mechanisms of an effect; using log transformation to deal with nonuniformity of effects and error; identifying and deleting outliers; presenting descriptive, effect, and inferential statistics in appropriate formats; and contending with bias arising from problems with sampling, assignment, blinding, measurement error, and researchers' prejudices. This article should advance the field by stimulating debate, promoting innovative approaches, and serving as a useful checklist for authors, reviewers, and editors.",2009,"[{'authorId': '3670885', 'name': 'W. Hopkins'}, {'authorId': '2076754', 'name': 'S. Marshall'}, {'authorId': '144267727', 'name': 'A. Batterham'}, {'authorId': '13905381', 'name': 'J. Hanin'}]","{'url': 'https://doi.org/10.1249/mss.0b013e31818cb278', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1249/MSS.0b013e31818cb278?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1249/MSS.0b013e31818cb278, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","statistical guidelines and expert statements are now available to assist in the analysis and reporting of studies in some biomedical disciplines. we present here a more progressive resource for sample-based studies, meta-analyses, and case studies in sports medicine and exercise science. we offer forthright advice on the following controversial or novel issues: using precision of estimation for inferences about population effects in preference to null-hypothesis testing, which is inadequate for assessing clinical or practical importance; justifying sample size via acceptable precision or confidence for clinical decisions rather than via adequate power for statistical significance; showing sd rather than sem, to better communicate the magnitude of differences in means and nonuniformity of error; avoiding purely nonparametric analyses, which cannot provide inferences about magnitude and are unnecessary; using regression statistics in validity studies, in preference to the impractical and biased limits of agreement; making greater use of qualitative methods to enrich sample-based quantitative projects; and seeking ethics approval for public access to the depersonalized raw data of a study, to address the need for more scrutiny of research and better meta-analyses. advice on less contentious issues includes the following: using covariates in linear models to adjust for confounders, to account for individual differences, and to identify potential mechanisms of an effect; using log transformation to deal with nonuniformity of effects and error; identifying and deleting outliers; presenting descriptive, effect, and inferential statistics in appropriate formats; and contending with bias arising from problems with sampling, assignment, blinding, measurement error, and researchers' prejudices. this article should advance the field by stimulating debate, promoting innovative approaches, and serving as a useful checklist for authors, reviewers, and editors.",https://doi.org/10.1249/mss.0b013e31818cb278
5c520467148f333008fba63fbf8b4fbb7600c9f5,"American College of Sports Medicine position stand. Quantity and quality of exercise for developing and maintaining cardiorespiratory, musculoskeletal, and neuromotor fitness in apparently healthy adults: guidance for prescribing exercise.","The purpose of this Position Stand is to provide guidance to professionals who counsel and prescribe individualized exercise to apparently healthy adults of all ages. These recommendations also may apply to adults with certain chronic diseases or disabilities, when appropriately evaluated and advised by a health professional. This document supersedes the 1998 American College of Sports Medicine (ACSM) Position Stand, ""The Recommended Quantity and Quality of Exercise for Developing and Maintaining Cardiorespiratory and Muscular Fitness, and Flexibility in Healthy Adults."" The scientific evidence demonstrating the beneficial effects of exercise is indisputable, and the benefits of exercise far outweigh the risks in most adults. A program of regular exercise that includes cardiorespiratory, resistance, flexibility, and neuromotor exercise training beyond activities of daily living to improve and maintain physical fitness and health is essential for most adults. The ACSM recommends that most adults engage in moderate-intensity cardiorespiratory exercise training for ≥30 min·d on ≥5 d·wk for a total of ≥150 min·wk, vigorous-intensity cardiorespiratory exercise training for ≥20 min·d on ≥3 d·wk (≥75 min·wk), or a combination of moderate- and vigorous-intensity exercise to achieve a total energy expenditure of ≥500-1000 MET·min·wk. On 2-3 d·wk, adults should also perform resistance exercises for each of the major muscle groups, and neuromotor exercise involving balance, agility, and coordination. Crucial to maintaining joint range of movement, completing a series of flexibility exercises for each the major muscle-tendon groups (a total of 60 s per exercise) on ≥2 d·wk is recommended. The exercise program should be modified according to an individual's habitual physical activity, physical function, health status, exercise responses, and stated goals. Adults who are unable or unwilling to meet the exercise targets outlined here still can benefit from engaging in amounts of exercise less than recommended. In addition to exercising regularly, there are health benefits in concurrently reducing total time engaged in sedentary pursuits and also by interspersing frequent, short bouts of standing and physical activity between periods of sedentary activity, even in physically active adults. Behaviorally based exercise interventions, the use of behavior change strategies, supervision by an experienced fitness instructor, and exercise that is pleasant and enjoyable can improve adoption and adherence to prescribed exercise programs. Educating adults about and screening for signs and symptoms of CHD and gradual progression of exercise intensity and volume may reduce the risks of exercise. Consultations with a medical professional and diagnostic exercise testing for CHD are useful when clinically indicated but are not recommended for universal screening to enhance the safety of exercise.",2011,"[{'authorId': '5533454', 'name': 'C. Garber'}, {'authorId': '4768135', 'name': 'B. Blissmer'}, {'authorId': '5584709', 'name': 'M. Deschenes'}, {'authorId': '5936906', 'name': 'B. Franklin'}, {'authorId': '2369066', 'name': 'M. LaMonte'}, {'authorId': '6597940', 'name': 'I. Lee'}, {'authorId': '5972652', 'name': 'D. Nieman'}, {'authorId': '1901219', 'name': 'D. Swain'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1249/MSS.0b013e318213fefb?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1249/MSS.0b013e318213fefb, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the purpose of this position stand is to provide guidance to professionals who counsel and prescribe individualized exercise to apparently healthy adults of all ages. these recommendations also may apply to adults with certain chronic diseases or disabilities, when appropriately evaluated and advised by a health professional. this document supersedes the 1998 american college of sports medicine (acsm) position stand, ""the recommended quantity and quality of exercise for developing and maintaining cardiorespiratory and muscular fitness, and flexibility in healthy adults."" the scientific evidence demonstrating the beneficial effects of exercise is indisputable, and the benefits of exercise far outweigh the risks in most adults. a program of regular exercise that includes cardiorespiratory, resistance, flexibility, and neuromotor exercise training beyond activities of daily living to improve and maintain physical fitness and health is essential for most adults. the acsm recommends that most adults engage in moderate-intensity cardiorespiratory exercise training for ≥30 min·d on ≥5 d·wk for a total of ≥150 min·wk, vigorous-intensity cardiorespiratory exercise training for ≥20 min·d on ≥3 d·wk (≥75 min·wk), or a combination of moderate- and vigorous-intensity exercise to achieve a total energy expenditure of ≥500-1000 met·min·wk. on 2-3 d·wk, adults should also perform resistance exercises for each of the major muscle groups, and neuromotor exercise involving balance, agility, and coordination. crucial to maintaining joint range of movement, completing a series of flexibility exercises for each the major muscle-tendon groups (a total of 60 s per exercise) on ≥2 d·wk is recommended. the exercise program should be modified according to an individual's habitual physical activity, physical function, health status, exercise responses, and stated goals. adults who are unable or unwilling to meet the exercise targets outlined here still can benefit from engaging in amounts of exercise less than recommended. in addition to exercising regularly, there are health benefits in concurrently reducing total time engaged in sedentary pursuits and also by interspersing frequent, short bouts of standing and physical activity between periods of sedentary activity, even in physically active adults. behaviorally based exercise interventions, the use of behavior change strategies, supervision by an experienced fitness instructor, and exercise that is pleasant and enjoyable can improve adoption and adherence to prescribed exercise programs. educating adults about and screening for signs and symptoms of chd and gradual progression of exercise intensity and volume may reduce the risks of exercise. consultations with a medical professional and diagnostic exercise testing for chd are useful when clinically indicated but are not recommended for universal screening to enhance the safety of exercise.",
be75109902f5689f7114e9e0fa783a12ceaa9b3a,Physical activity and public health: updated recommendation for adults from the American College of Sports Medicine and the American Heart Association.,"SUMMARY
In 1995 the American College of Sports Medicine and the Centers for Disease Control and Prevention published national guidelines on Physical Activity and Public Health. The Committee on Exercise and Cardiac Rehabilitation of the American Heart Association endorsed and supported these recommendations. The purpose of the present report is to update and clarify the 1995 recommendations on the types and amounts of physical activity needed by healthy adults to improve and maintain health. Development of this document was by an expert panel of scientists, including physicians, epidemiologists, exercise scientists, and public health specialists. This panel reviewed advances in pertinent physiologic, epidemiologic, and clinical scientific data, including primary research articles and reviews published since the original recommendation was issued in 1995. Issues considered by the panel included new scientific evidence relating physical activity to health, physical activity recommendations by various organizations in the interim, and communications issues. Key points related to updating the physical activity recommendation were outlined and writing groups were formed. A draft manuscript was prepared and circulated for review to the expert panel as well as to outside experts. Comments were integrated into the final recommendation.


PRIMARY RECOMMENDATION
To promote and maintain health, all healthy adults aged 18 to 65 yr need moderate-intensity aerobic (endurance) physical activity for a minimum of 30 min on five days each week or vigorous-intensity aerobic physical activity for a minimum of 20 min on three days each week. [I (A)] Combinations of moderate- and vigorous-intensity activity can be performed to meet this recommendation. [IIa (B)] For example, a person can meet the recommendation by walking briskly for 30 min twice during the week and then jogging for 20 min on two other days. Moderate-intensity aerobic activity, which is generally equivalent to a brisk walk and noticeably accelerates the heart rate, can be accumulated toward the 30-min minimum by performing bouts each lasting 10 or more minutes. [I (B)] Vigorous-intensity activity is exemplified by jogging, and causes rapid breathing and a substantial increase in heart rate. In addition, every adult should perform activities that maintain or increase muscular strength and endurance a minimum of two days each week. [IIa (A)] Because of the dose-response relation between physical activity and health, persons who wish to further improve their personal fitness, reduce their risk for chronic diseases and disabilities or prevent unhealthy weight gain may benefit by exceeding the minimum recommended amounts of physical activity. [I (A)]",2007,"[{'authorId': '2796639', 'name': 'W. Haskell'}, {'authorId': '6597940', 'name': 'I. Lee'}, {'authorId': '8599311', 'name': 'R. Pate'}, {'authorId': '2022266', 'name': 'K. Powell'}, {'authorId': '6377701', 'name': 'S. Blair'}, {'authorId': '5936906', 'name': 'B. Franklin'}, {'authorId': '4676581', 'name': 'C. Macera'}, {'authorId': '6609272', 'name': 'G. Heath'}, {'authorId': '35038737', 'name': 'P. Thompson'}, {'authorId': '144127421', 'name': 'A. Bauman'}]","{'url': 'https://www.ahajournals.org/doi/pdf/10.1161/CIRCULATIONAHA.107.185649', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1161/CIRCULATIONAHA.107.185649?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1161/CIRCULATIONAHA.107.185649, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","summary in 1995 the american college of sports medicine and the centers for disease control and prevention published national guidelines on physical activity and public health. the committee on exercise and cardiac rehabilitation of the american heart association endorsed and supported these recommendations. the purpose of the present report is to update and clarify the 1995 recommendations on the types and amounts of physical activity needed by healthy adults to improve and maintain health. development of this document was by an expert panel of scientists, including physicians, epidemiologists, exercise scientists, and public health specialists. this panel reviewed advances in pertinent physiologic, epidemiologic, and clinical scientific data, including primary research articles and reviews published since the original recommendation was issued in 1995. issues considered by the panel included new scientific evidence relating physical activity to health, physical activity recommendations by various organizations in the interim, and communications issues. key points related to updating the physical activity recommendation were outlined and writing groups were formed. a draft manuscript was prepared and circulated for review to the expert panel as well as to outside experts. comments were integrated into the final recommendation. primary recommendation to promote and maintain health, all healthy adults aged 18 to 65 yr need moderate-intensity aerobic (endurance) physical activity for a minimum of 30 min on five days each week or vigorous-intensity aerobic physical activity for a minimum of 20 min on three days each week. [i (a)] combinations of moderate- and vigorous-intensity activity can be performed to meet this recommendation. [iia (b)] for example, a person can meet the recommendation by walking briskly for 30 min twice during the week and then jogging for 20 min on two other days. moderate-intensity aerobic activity, which is generally equivalent to a brisk walk and noticeably accelerates the heart rate, can be accumulated toward the 30-min minimum by performing bouts each lasting 10 or more minutes. [i (b)] vigorous-intensity activity is exemplified by jogging, and causes rapid breathing and a substantial increase in heart rate. in addition, every adult should perform activities that maintain or increase muscular strength and endurance a minimum of two days each week. [iia (a)] because of the dose-response relation between physical activity and health, persons who wish to further improve their personal fitness, reduce their risk for chronic diseases and disabilities or prevent unhealthy weight gain may benefit by exceeding the minimum recommended amounts of physical activity. [i (a)]",https://www.ahajournals.org/doi/pdf/10.1161/CIRCULATIONAHA.107.185649
0588b721a655327ec6a70bee072b62db323658c8,Physical Activity and Public Health: A Recommendation From the Centers for Disease Control and Prevention and the American College of Sports Medicine,"Objective. —To encourage increased participation in physical activity among Americans of all ages by issuing a public health recommendation on the types and amounts of physical activity needed for health promotion and disease prevention. Participants. —A planning committee of five scientists was established by the Centers for Disease Control and Prevention and the American College of Sports Medicine to organize a workshop. This committee selected 15 other workshop discussants on the basis of their research expertise in issues related to the health implications of physical activity. Several relevant professional or scientific organizations and federal agencies also were represented. Evidence. —The panel of experts reviewed the pertinent physiological, epidemiologic, and clinical evidence, including primary research articles and recent review articles. Consensus Process. —Major issues related to physical activity and health were outlined, and selected members of the expert panel drafted sections of the paper from this outline. A draft manuscript was prepared by the planning committee and circulated to the full panel in advance of the 2-day workshop. During the workshop, each section of the manuscript was reviewed by the expert panel. Primary attention was given to achieving group consensus concerning the recommended types and amounts of physical activity. A concise ""public health message"" was developed to express the recommendations of the panel. During the ensuing months, the consensus statement was further reviewed and revised and was formally endorsed by both the Centers for Disease Control and Prevention and the American College of Sports Medicine. Conclusion. —Every US adult should accumulate 30 minutes or more of moderate-intensity physical activity on most, preferably all, days of the week. ( JAMA . 1995;273:402-407)",1995,"[{'authorId': '8599311', 'name': 'R. Pate'}, {'authorId': '2054131879', 'name': 'M. Pratt'}, {'authorId': '6377701', 'name': 'S. Blair'}, {'authorId': '2796639', 'name': 'W. Haskell'}, {'authorId': '4676581', 'name': 'C. Macera'}, {'authorId': '144072297', 'name': 'C. Bouchard'}, {'authorId': '2072493560', 'name': 'D. Buchner'}, {'authorId': '4597883', 'name': 'W. Ettinger'}, {'authorId': '6609272', 'name': 'G. Heath'}, {'authorId': '145994734', 'name': 'A. King'}, {'authorId': '32061245', 'name': 'A. Kriska'}, {'authorId': '2224898762', 'name': 'Arther S. Leon'}, {'authorId': '2716596', 'name': 'B. Marcus'}, {'authorId': '2109474888', 'name': 'Jeremy N. Morris'}, {'authorId': '6686027', 'name': 'R. Paffenbarger'}, {'authorId': '144772905', 'name': 'K. Patrick'}, {'authorId': '2057252', 'name': 'M. Pollock'}, {'authorId': '4590863', 'name': 'J. Rippe'}, {'authorId': '3027397', 'name': 'J. Sallis'}, {'authorId': '3485441', 'name': 'J. Wilmore'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1001/JAMA.1995.03520290054029?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1001/JAMA.1995.03520290054029, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objective. —to encourage increased participation in physical activity among americans of all ages by issuing a public health recommendation on the types and amounts of physical activity needed for health promotion and disease prevention. participants. —a planning committee of five scientists was established by the centers for disease control and prevention and the american college of sports medicine to organize a workshop. this committee selected 15 other workshop discussants on the basis of their research expertise in issues related to the health implications of physical activity. several relevant professional or scientific organizations and federal agencies also were represented. evidence. —the panel of experts reviewed the pertinent physiological, epidemiologic, and clinical evidence, including primary research articles and recent review articles. consensus process. —major issues related to physical activity and health were outlined, and selected members of the expert panel drafted sections of the paper from this outline. a draft manuscript was prepared by the planning committee and circulated to the full panel in advance of the 2-day workshop. during the workshop, each section of the manuscript was reviewed by the expert panel. primary attention was given to achieving group consensus concerning the recommended types and amounts of physical activity. a concise ""public health message"" was developed to express the recommendations of the panel. during the ensuing months, the consensus statement was further reviewed and revised and was formally endorsed by both the centers for disease control and prevention and the american college of sports medicine. conclusion. —every us adult should accumulate 30 minutes or more of moderate-intensity physical activity on most, preferably all, days of the week. ( jama . 1995;273:402-407)",
418516bbea55b3b66594158d6808be66f05baba2,Medicine and Science in Sports and Exercise,ض;;;عب ى;;;لع ة;;;بكرملا تابيرد;;;تلا ريثا;;;ت فر;;;عتلا ى;;;لإ ث;;;حبلا اذ;;;ھ فد;;;ھي يوتسملاو ةيندبلا و ةيئايميكويبلا تاريغتملا ةحابسل يمقرلا 50 م ي;لع فحز نطبلا وذ ي;بيرجتلا ميم;صتلا مادخت;ساب ي;بيرجتلا جھنملا ثحابلا مدختسإ دقو ، ةدحاو ةيبيرجت ةعومجمل ىدعبلا يلبقلا سايقلا ، مھددع ناكو ) 15 ( بعO  نم يدانلا يبعO Oا نيبام مھرامعأ تحوارت ، يلھ ) 13  15 ( ما;ع داعبت;سا م;تو ،  ) 5 ( T نيئشان نيحابس ث;حبلا ةنيع حبصتل ،مھيلع ةيع7طتسOا ةساردلا ءارج ةيساسZا  ) 10 ( و ،نيئشان نيحابس ــق ت مت د ـ ط ـيب لا ق ـب ع جمانر ـ ىل  نيع ـ ة  اھددعو ثحبلا ) 10 ( ى;لإ نيم;سقم جما;نربلل نيرھ;ش دد;ع يلا;مجإب نيبعO ) 8 ( ع;قاوب عيبا;سأ ) 32 ( ،جمانربلا يف ةيبيردت ةدحو ) 3 ( بسZا يف ةيبيردت تادحو جمانربلا نأ جئاتنلا مھأ نم ناكو ، عو ة;;يندبلا و ة;;يئايميكويبلا تار;;يغتملا ض;;عب ى;;لع ا;;يباجيإ اريثأ;;ت ر;;ثأ ة;;بكرملا تابيرد;;تلا بول;;سأب حر;;تقملا ً ً ةحابسل يمقرلا يوتسملاو 50 ة;يمنتل ة;ساردلا هذ;ھ ل;ثم قيبطتب ثحابلا يصويو ، نطبلا يلع فحز م انل ىرخأ ةيندبو ةيئايميكويب تاريغتم هذيفنتو ةحابسلا يئش يرخZا ةينسلا لحارملا ىلع اضيأ ً .,1981,"[{'authorId': '11592166', 'name': 'Sung Gyoo Park'}]","{'url': 'https://doi.org/10.1249/00005768-198410000-00018', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1249/00005768-198410000-00018?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1249/00005768-198410000-00018, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",ض;;;عب ى;;;لع ة;;;بكرملا تابيرد;;;تلا ريثا;;;ت فر;;;عتلا ى;;;لإ ث;;;حبلا اذ;;;ھ فد;;;ھي يوتسملاو ةيندبلا و ةيئايميكويبلا تاريغتملا ةحابسل يمقرلا 50 م ي;لع فحز نطبلا وذ ي;بيرجتلا ميم;صتلا مادخت;ساب ي;بيرجتلا جھنملا ثحابلا مدختسإ دقو ، ةدحاو ةيبيرجت ةعومجمل ىدعبلا يلبقلا سايقلا ، مھددع ناكو ) 15 ( بعo نم يدانلا يبعo oا نيبام مھرامعأ تحوارت ، يلھ ) 13 15 ( ما;ع داعبت;سا م;تو ، ) 5 ( t نيئشان نيحابس ث;حبلا ةنيع حبصتل ،مھيلع ةيع7طتسoا ةساردلا ءارج ةيساسzا ) 10 ( و ،نيئشان نيحابس ــق ت مت د ـ ط ـيب لا ق ـب ع جمانر ـ ىل نيع ـ ة اھددعو ثحبلا ) 10 ( ى;لإ نيم;سقم جما;نربلل نيرھ;ش دد;ع يلا;مجإب نيبعo ) 8 ( ع;قاوب عيبا;سأ ) 32 ( ،جمانربلا يف ةيبيردت ةدحو ) 3 ( بسzا يف ةيبيردت تادحو جمانربلا نأ جئاتنلا مھأ نم ناكو ، عو ة;;يندبلا و ة;;يئايميكويبلا تار;;يغتملا ض;;عب ى;;لع ا;;يباجيإ اريثأ;;ت ر;;ثأ ة;;بكرملا تابيرد;;تلا بول;;سأب حر;;تقملا ً ً ةحابسل يمقرلا يوتسملاو 50 ة;يمنتل ة;ساردلا هذ;ھ ل;ثم قيبطتب ثحابلا يصويو ، نطبلا يلع فحز م انل ىرخأ ةيندبو ةيئايميكويب تاريغتم هذيفنتو ةحابسلا يئش يرخzا ةينسلا لحارملا ىلع اضيأ ً .,https://doi.org/10.1249/00005768-198410000-00018
66a586cc77c0f01d5f481c644d58e8f1931b120a,Physical activity and public health in older adults: recommendation from the American College of Sports Medicine and the American Heart Association.,"OBJECTIVE
To issue a recommendation on the types and amounts of physical activity needed to improve and maintain health in older adults.


PARTICIPANTS
A panel of scientists with expertise in public health, behavioral science, epidemiology, exercise science, medicine, and gerontology.


EVIDENCE
The expert panel reviewed existing consensus statements and relevant evidence from primary research articles and reviews of the literature.


PROCESS
After drafting a recommendation for the older adult population and reviewing drafts of the Updated Recommendation from the American College of Sports Medicine (ACSM) and the American Heart Association (AHA) for Adults, the panel issued a final recommendation on physical activity for older adults.


SUMMARY
The recommendation for older adults is similar to the updated ACSM/AHA recommendation for adults, but has several important differences including: the recommended intensity of aerobic activity takes into account the older adult's aerobic fitness; activities that maintain or increase flexibility are recommended; and balance exercises are recommended for older adults at risk of falls. In addition, older adults should have an activity plan for achieving recommended physical activity that integrates preventive and therapeutic recommendations. The promotion of physical activity in older adults should emphasize moderate-intensity aerobic activity, muscle-strengthening activity, reducing sedentary behavior, and risk management.",2007,"[{'authorId': '2944698', 'name': 'M. Nelson'}, {'authorId': '144778095', 'name': 'W. Rejeski'}, {'authorId': '6377701', 'name': 'S. Blair'}, {'authorId': '1718600', 'name': 'P. Duncan'}, {'authorId': '40128424', 'name': 'J. Judge'}, {'authorId': '145994734', 'name': 'A. King'}, {'authorId': '4676581', 'name': 'C. Macera'}, {'authorId': '1403266745', 'name': 'C. Castaneda-Sceppa'}]","{'url': 'https://www.ahajournals.org/doi/pdf/10.1161/CIRCULATIONAHA.107.185650', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1161/CIRCULATIONAHA.107.185650?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1161/CIRCULATIONAHA.107.185650, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objective to issue a recommendation on the types and amounts of physical activity needed to improve and maintain health in older adults. participants a panel of scientists with expertise in public health, behavioral science, epidemiology, exercise science, medicine, and gerontology. evidence the expert panel reviewed existing consensus statements and relevant evidence from primary research articles and reviews of the literature. process after drafting a recommendation for the older adult population and reviewing drafts of the updated recommendation from the american college of sports medicine (acsm) and the american heart association (aha) for adults, the panel issued a final recommendation on physical activity for older adults. summary the recommendation for older adults is similar to the updated acsm/aha recommendation for adults, but has several important differences including: the recommended intensity of aerobic activity takes into account the older adult's aerobic fitness; activities that maintain or increase flexibility are recommended; and balance exercises are recommended for older adults at risk of falls. in addition, older adults should have an activity plan for achieving recommended physical activity that integrates preventive and therapeutic recommendations. the promotion of physical activity in older adults should emphasize moderate-intensity aerobic activity, muscle-strengthening activity, reducing sedentary behavior, and risk management.",https://www.ahajournals.org/doi/pdf/10.1161/CIRCULATIONAHA.107.185650
885817ddcc08e2b2e41d12dc3cff7deec7ebe936,International society of sports nutrition position stand: caffeine and exercise performance,"Following critical evaluation of the available literature to date, The International Society of Sports Nutrition (ISSN) position regarding caffeine intake is as follows: 1. Supplementation with caffeine has been shown to acutely enhance various aspects of exercise performance in many but not all studies. Small to moderate benefits of caffeine use include, but are not limited to: muscular endurance, movement velocity and muscular strength, sprinting, jumping, and throwing performance, as well as a wide range of aerobic and anaerobic sport-specific actions. 2. Aerobic endurance appears to be the form of exercise with the most consistent moderate-to-large benefits from caffeine use, although the magnitude of its effects differs between individuals. 3. Caffeine has consistently been shown to improve exercise performance when consumed in doses of 3–6 mg/kg body mass. Minimal effective doses of caffeine currently remain unclear but they may be as low as 2 mg/kg body mass. Very high doses of caffeine (e.g. 9 mg/kg) are associated with a high incidence of side-effects and do not seem to be required to elicit an ergogenic effect. 4. The most commonly used timing of caffeine supplementation is 60 min pre-exercise. Optimal timing of caffeine ingestion likely depends on the source of caffeine. For example, as compared to caffeine capsules, caffeine chewing gums may require a shorter waiting time from consumption to the start of the exercise session. 5. Caffeine appears to improve physical performance in both trained and untrained individuals. 6. Inter-individual differences in sport and exercise performance as well as adverse effects on sleep or feelings of anxiety following caffeine ingestion may be attributed to genetic variation associated with caffeine metabolism, and physical and psychological response. Other factors such as habitual caffeine intake also may play a role in between-individual response variation. 7. Caffeine has been shown to be ergogenic for cognitive function, including attention and vigilance, in most individuals. 8. Caffeine may improve cognitive and physical performance in some individuals under conditions of sleep deprivation. 9. The use of caffeine in conjunction with endurance exercise in the heat and at altitude is well supported when dosages range from 3 to 6 mg/kg and 4–6 mg/kg, respectively. 10. Alternative sources of caffeine such as caffeinated chewing gum, mouth rinses, energy gels and chews have been shown to improve performance, primarily in aerobic exercise. 11. Energy drinks and pre-workout supplements containing caffeine have been demonstrated to enhance both anaerobic and aerobic performance.",2021,"[{'authorId': '5388759', 'name': 'Nanci S. Guest'}, {'authorId': '6039312', 'name': 'Trisha A. VanDusseldorp'}, {'authorId': '2074104625', 'name': 'Michael T. Nelson'}, {'authorId': '35168203', 'name': 'J. Grgic'}, {'authorId': '2354452', 'name': 'B. Schoenfeld'}, {'authorId': '39643790', 'name': 'Nathaniel D M Jenkins'}, {'authorId': '5611357', 'name': 'S. Arent'}, {'authorId': '66053606', 'name': 'J. Antonio'}, {'authorId': '153233032', 'name': 'Jeffrey R. Stout'}, {'authorId': '3596997', 'name': 'Eric T Trexler'}, {'authorId': '15821634', 'name': 'A. Smith‐Ryan'}, {'authorId': '32189467', 'name': 'E. Goldstein'}, {'authorId': '46541084', 'name': 'D. Kalman'}, {'authorId': '31889971', 'name': 'B. Campbell'}]","{'url': 'https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-020-00383-4', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7777221, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","following critical evaluation of the available literature to date, the international society of sports nutrition (issn) position regarding caffeine intake is as follows: 1. supplementation with caffeine has been shown to acutely enhance various aspects of exercise performance in many but not all studies. small to moderate benefits of caffeine use include, but are not limited to: muscular endurance, movement velocity and muscular strength, sprinting, jumping, and throwing performance, as well as a wide range of aerobic and anaerobic sport-specific actions. 2. aerobic endurance appears to be the form of exercise with the most consistent moderate-to-large benefits from caffeine use, although the magnitude of its effects differs between individuals. 3. caffeine has consistently been shown to improve exercise performance when consumed in doses of 3–6 mg/kg body mass. minimal effective doses of caffeine currently remain unclear but they may be as low as 2 mg/kg body mass. very high doses of caffeine (e.g. 9 mg/kg) are associated with a high incidence of side-effects and do not seem to be required to elicit an ergogenic effect. 4. the most commonly used timing of caffeine supplementation is 60 min pre-exercise. optimal timing of caffeine ingestion likely depends on the source of caffeine. for example, as compared to caffeine capsules, caffeine chewing gums may require a shorter waiting time from consumption to the start of the exercise session. 5. caffeine appears to improve physical performance in both trained and untrained individuals. 6. inter-individual differences in sport and exercise performance as well as adverse effects on sleep or feelings of anxiety following caffeine ingestion may be attributed to genetic variation associated with caffeine metabolism, and physical and psychological response. other factors such as habitual caffeine intake also may play a role in between-individual response variation. 7. caffeine has been shown to be ergogenic for cognitive function, including attention and vigilance, in most individuals. 8. caffeine may improve cognitive and physical performance in some individuals under conditions of sleep deprivation. 9. the use of caffeine in conjunction with endurance exercise in the heat and at altitude is well supported when dosages range from 3 to 6 mg/kg and 4–6 mg/kg, respectively. 10. alternative sources of caffeine such as caffeinated chewing gum, mouth rinses, energy gels and chews have been shown to improve performance, primarily in aerobic exercise. 11. energy drinks and pre-workout supplements containing caffeine have been demonstrated to enhance both anaerobic and aerobic performance.",https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-020-00383-4
fd701949b9dae38d588ed56fc1bb017b6b0fcb63,American College of Sports Medicine position stand. Progression models in resistance training for healthy adults.,"In order to stimulate further adaptation toward specific training goals, progressive resistance training (RT) protocols are necessary. The optimal characteristics of strength-specific programs include the use of concentric (CON), eccentric (ECC), and isometric muscle actions and the performance of bilateral and unilateral single- and multiple-joint exercises. In addition, it is recommended that strength programs sequence exercises to optimize the preservation of exercise intensity (large before small muscle group exercises, multiple-joint exercises before single-joint exercises, and higher-intensity before lower-intensity exercises). For novice (untrained individuals with no RT experience or who have not trained for several years) training, it is recommended that loads correspond to a repetition range of an 8-12 repetition maximum (RM). For intermediate (individuals with approximately 6 months of consistent RT experience) to advanced (individuals with years of RT experience) training, it is recommended that individuals use a wider loading range from 1 to 12 RM in a periodized fashion with eventual emphasis on heavy loading (1-6 RM) using 3- to 5-min rest periods between sets performed at a moderate contraction velocity (1-2 s CON; 1-2 s ECC). When training at a specific RM load, it is recommended that 2-10% increase in load be applied when the individual can perform the current workload for one to two repetitions over the desired number. The recommendation for training frequency is 2-3 d x wk(-1) for novice training, 3-4 d x wk(-1) for intermediate training, and 4-5 d x wk(-1) for advanced training. Similar program designs are recommended for hypertrophy training with respect to exercise selection and frequency. For loading, it is recommended that loads corresponding to 1-12 RM be used in periodized fashion with emphasis on the 6-12 RM zone using 1- to 2-min rest periods between sets at a moderate velocity. Higher volume, multiple-set programs are recommended for maximizing hypertrophy. Progression in power training entails two general loading strategies: 1) strength training and 2) use of light loads (0-60% of 1 RM for lower body exercises; 30-60% of 1 RM for upper body exercises) performed at a fast contraction velocity with 3-5 min of rest between sets for multiple sets per exercise (three to five sets). It is also recommended that emphasis be placed on multiple-joint exercises especially those involving the total body. For local muscular endurance training, it is recommended that light to moderate loads (40-60% of 1 RM) be performed for high repetitions (>15) using short rest periods (<90 s). In the interpretation of this position stand as with prior ones, recommendations should be applied in context and should be contingent upon an individual's target goals, physical capacity, and training status.",2011,"[{'authorId': '74871909', 'name': 'Position Stand'}]","{'url': 'https://journals.lww.com/acsm-msse/fulltext/2009/03000/progression_models_in_resistance_training_for.26.aspx', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1249/MSS.0b013e3181915670?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1249/MSS.0b013e3181915670, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in order to stimulate further adaptation toward specific training goals, progressive resistance training (rt) protocols are necessary. the optimal characteristics of strength-specific programs include the use of concentric (con), eccentric (ecc), and isometric muscle actions and the performance of bilateral and unilateral single- and multiple-joint exercises. in addition, it is recommended that strength programs sequence exercises to optimize the preservation of exercise intensity (large before small muscle group exercises, multiple-joint exercises before single-joint exercises, and higher-intensity before lower-intensity exercises). for novice (untrained individuals with no rt experience or who have not trained for several years) training, it is recommended that loads correspond to a repetition range of an 8-12 repetition maximum (rm). for intermediate (individuals with approximately 6 months of consistent rt experience) to advanced (individuals with years of rt experience) training, it is recommended that individuals use a wider loading range from 1 to 12 rm in a periodized fashion with eventual emphasis on heavy loading (1-6 rm) using 3- to 5-min rest periods between sets performed at a moderate contraction velocity (1-2 s con; 1-2 s ecc). when training at a specific rm load, it is recommended that 2-10% increase in load be applied when the individual can perform the current workload for one to two repetitions over the desired number. the recommendation for training frequency is 2-3 d x wk(-1) for novice training, 3-4 d x wk(-1) for intermediate training, and 4-5 d x wk(-1) for advanced training. similar program designs are recommended for hypertrophy training with respect to exercise selection and frequency. for loading, it is recommended that loads corresponding to 1-12 rm be used in periodized fashion with emphasis on the 6-12 rm zone using 1- to 2-min rest periods between sets at a moderate velocity. higher volume, multiple-set programs are recommended for maximizing hypertrophy. progression in power training entails two general loading strategies: 1) strength training and 2) use of light loads (0-60% of 1 rm for lower body exercises; 30-60% of 1 rm for upper body exercises) performed at a fast contraction velocity with 3-5 min of rest between sets for multiple sets per exercise (three to five sets). it is also recommended that emphasis be placed on multiple-joint exercises especially those involving the total body. for local muscular endurance training, it is recommended that light to moderate loads (40-60% of 1 rm) be performed for high repetitions (>15) using short rest periods (<90 s). in the interpretation of this position stand as with prior ones, recommendations should be applied in context and should be contingent upon an individual's target goals, physical capacity, and training status.",https://journals.lww.com/acsm-msse/fulltext/2009/03000/progression_models_in_resistance_training_for.26.aspx
12adddf35505e057560309f0d1122fefad693506,American College of Sports Medicine position stand. Exercise and physical activity for older adults.,"The purpose of this Position Stand is to provide an overview of issues critical to understanding the importance of exercise and physical activity in older adult populations. The Position Stand is divided into three sections: Section 1 briefly reviews the structural and functional changes that characterize normal human aging, Section 2 considers the extent to which exercise and physical activity can influence the aging process, and Section 3 summarizes the benefits of both long-term exercise and physical activity and shorter-duration exercise programs on health and functional capacity. Although no amount of physical activity can stop the biological aging process, there is evidence that regular exercise can minimize the physiological effects of an otherwise sedentary lifestyle and increase active life expectancy by limiting the development and progression of chronic disease and disabling conditions. There is also emerging evidence for significant psychological and cognitive benefits accruing from regular exercise participation by older adults. Ideally, exercise prescription for older adults should include aerobic exercise, muscle strengthening exercises, and flexibility exercises. The evidence reviewed in this Position Stand is generally consistent with prior American College of Sports Medicine statements on the types and amounts of physical activity recommended for older adults as well as the recently published 2008 Physical Activity Guidelines for Americans. All older adults should engage in regular physical activity and avoid an inactive lifestyle.",2009,"[{'authorId': '1390041868', 'name': 'W. Chodzko-Zajko'}, {'authorId': '3152233', 'name': 'D. Proctor'}, {'authorId': '6196027', 'name': 'M. Fiatarone Singh'}, {'authorId': '4793612', 'name': 'C. Minson'}, {'authorId': '5540973', 'name': 'C. Nigg'}, {'authorId': '13802468', 'name': 'G. Salem'}, {'authorId': '2020755', 'name': 'J. Skinner'}]","{'url': 'https://journals.lww.com/acsm-msse/fulltext/2009/07000/exercise_and_physical_activity_for_older_adults.20.aspx', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1249/MSS.0b013e3181a0c95c?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1249/MSS.0b013e3181a0c95c, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the purpose of this position stand is to provide an overview of issues critical to understanding the importance of exercise and physical activity in older adult populations. the position stand is divided into three sections: section 1 briefly reviews the structural and functional changes that characterize normal human aging, section 2 considers the extent to which exercise and physical activity can influence the aging process, and section 3 summarizes the benefits of both long-term exercise and physical activity and shorter-duration exercise programs on health and functional capacity. although no amount of physical activity can stop the biological aging process, there is evidence that regular exercise can minimize the physiological effects of an otherwise sedentary lifestyle and increase active life expectancy by limiting the development and progression of chronic disease and disabling conditions. there is also emerging evidence for significant psychological and cognitive benefits accruing from regular exercise participation by older adults. ideally, exercise prescription for older adults should include aerobic exercise, muscle strengthening exercises, and flexibility exercises. the evidence reviewed in this position stand is generally consistent with prior american college of sports medicine statements on the types and amounts of physical activity recommended for older adults as well as the recently published 2008 physical activity guidelines for americans. all older adults should engage in regular physical activity and avoid an inactive lifestyle.",https://journals.lww.com/acsm-msse/fulltext/2009/07000/exercise_and_physical_activity_for_older_adults.20.aspx
67e18007ba3ac16753b9e1657e266f064c5687d1,The Triboelectric Nanogenerator as an Innovative Technology toward Intelligent Sports,"In the new era of the Internet‐of‐Things, athletic big data collection and analysis based on widely distributed sensing networks are particularly important in the development of intelligent sports. Conventional sensors usually require an external power supply, with limitations such as limited lifetime and high maintenance cost. As a newly developed mechanical energy harvesting and self‐powered sensing technology, the triboelectric nanogenerator (TENG) shows great potential to overcome these limitations. Most importantly, TENGs can be fabricated using wood, paper, fibers, and polymers, which are the most frequently used materials for sports. Recent progress on the development of TENGs for the field of intelligent sports is summarized. First, the working mechanism of TENG and its association with athletic big data are introduced. Subsequently, the development of TENG‐based sports sensing systems, including smart sports facilities and wearable equipment is highlighted. At last, the remaining challenges and open opportunities are also discussed.",2021,"[{'authorId': '145194157', 'name': 'Jianjun Luo'}, {'authorId': '2153706110', 'name': 'W. Gao'}, {'authorId': '1390879413', 'name': 'Zhong Lin Wang'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/adma.202004178?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/adma.202004178, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the new era of the internet‐of‐things, athletic big data collection and analysis based on widely distributed sensing networks are particularly important in the development of intelligent sports. conventional sensors usually require an external power supply, with limitations such as limited lifetime and high maintenance cost. as a newly developed mechanical energy harvesting and self‐powered sensing technology, the triboelectric nanogenerator (teng) shows great potential to overcome these limitations. most importantly, tengs can be fabricated using wood, paper, fibers, and polymers, which are the most frequently used materials for sports. recent progress on the development of tengs for the field of intelligent sports is summarized. first, the working mechanism of teng and its association with athletic big data are introduced. subsequently, the development of teng‐based sports sensing systems, including smart sports facilities and wearable equipment is highlighted. at last, the remaining challenges and open opportunities are also discussed.",
28021dd0005ec8e3373744b11af5de369a84454f,Physical Activity and Sports—Real Health Benefits: A Review with Insight into the Public Health of Sweden,"Positive effects from sports are achieved primarily through physical activity, but secondary effects bring health benefits such as psychosocial and personal development and less alcohol consumption. Negative effects, such as the risk of failure, injuries, eating disorders, and burnout, are also apparent. Because physical activity is increasingly conducted in an organized manner, sport’s role in society has become increasingly important over the years, not only for the individual but also for public health. In this paper, we intend to describe sport’s physiological and psychosocial health benefits, stemming both from physical activity and from sport participation per se. This narrative review summarizes research and presents health-related data from Swedish authorities. It is discussed that our daily lives are becoming less physically active, while organized exercise and training increases. Average energy intake is increasing, creating an energy surplus, and thus, we are seeing an increasing number of people who are overweight, which is a strong contributor to health problems. Physical activity and exercise have significant positive effects in preventing or alleviating mental illness, including depressive symptoms and anxiety- or stress-related disease. In conclusion, sports can be evolving, if personal capacities, social situation, and biological and psychological maturation are taken into account. Evidence suggests a dose–response relationship such that being active, even to a modest level, is superior to being inactive or sedentary. Recommendations for healthy sports are summarized.",2019,"[{'authorId': '35136157', 'name': 'C. Malm'}, {'authorId': '145883981', 'name': 'Johan Jakobsson'}, {'authorId': '21834477', 'name': 'A. Isaksson'}]","{'url': 'https://www.mdpi.com/2075-4663/7/5/127/pdf?version=1558614169', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6572041, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","positive effects from sports are achieved primarily through physical activity, but secondary effects bring health benefits such as psychosocial and personal development and less alcohol consumption. negative effects, such as the risk of failure, injuries, eating disorders, and burnout, are also apparent. because physical activity is increasingly conducted in an organized manner, sport’s role in society has become increasingly important over the years, not only for the individual but also for public health. in this paper, we intend to describe sport’s physiological and psychosocial health benefits, stemming both from physical activity and from sport participation per se. this narrative review summarizes research and presents health-related data from swedish authorities. it is discussed that our daily lives are becoming less physically active, while organized exercise and training increases. average energy intake is increasing, creating an energy surplus, and thus, we are seeing an increasing number of people who are overweight, which is a strong contributor to health problems. physical activity and exercise have significant positive effects in preventing or alleviating mental illness, including depressive symptoms and anxiety- or stress-related disease. in conclusion, sports can be evolving, if personal capacities, social situation, and biological and psychological maturation are taken into account. evidence suggests a dose–response relationship such that being active, even to a modest level, is superior to being inactive or sedentary. recommendations for healthy sports are summarized.",https://www.mdpi.com/2075-4663/7/5/127/pdf?version=1558614169
330d9ad8ef92f78f4309fd4272808cfb6698dbd3,ISSN exercise & sports nutrition review update: research & recommendations,"BackgroundSports nutrition is a constantly evolving field with hundreds of research papers published annually. In the year 2017 alone, 2082 articles were published under the key words ‘sport nutrition’. Consequently, staying current with the relevant literature is often difficult.MethodsThis paper is an ongoing update of the sports nutrition review article originally published as the lead paper to launch the Journal of the International Society of Sports Nutrition in 2004 and updated in 2010. It presents a well-referenced overview of the current state of the science related to optimization of training and performance enhancement through exercise training and nutrition. Notably, due to the accelerated pace and size at which the literature base in this research area grows, the topics discussed will focus on muscle hypertrophy and performance enhancement. As such, this paper provides an overview of: 1.) How ergogenic aids and dietary supplements are defined in terms of governmental regulation and oversight; 2.) How dietary supplements are legally regulated in the United States; 3.) How to evaluate the scientific merit of nutritional supplements; 4.) General nutritional strategies to optimize performance and enhance recovery; and, 5.) An overview of our current understanding of nutritional approaches to augment skeletal muscle hypertrophy and the potential ergogenic value of various dietary and supplemental approaches.ConclusionsThis updated review is to provide ISSN members and individuals interested in sports nutrition with information that can be implemented in educational, research or practical settings and serve as a foundational basis for determining the efficacy and safety of many common sport nutrition products and their ingredients.",2018,"[{'authorId': '5352831', 'name': 'C. Kerksick'}, {'authorId': '5031930', 'name': 'C. Wilborn'}, {'authorId': '20322660', 'name': 'M. Roberts'}, {'authorId': '15821634', 'name': 'A. Smith‐Ryan'}, {'authorId': '3239731', 'name': 'S. Kleiner'}, {'authorId': '34905148', 'name': 'R. Jäger'}, {'authorId': '40346694', 'name': 'Rick Collins'}, {'authorId': '38990102', 'name': 'Mathew Cooke'}, {'authorId': '145819231', 'name': 'Jaci N. Davis'}, {'authorId': '39456676', 'name': 'E. Galvan'}, {'authorId': '40642089', 'name': 'M. Greenwood'}, {'authorId': '41201458', 'name': 'L. Lowery'}, {'authorId': '38464914', 'name': 'R. Wildman'}, {'authorId': '66053606', 'name': 'J. Antonio'}, {'authorId': '3762776', 'name': 'R. Kreider'}]","{'url': 'https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-018-0242-y', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6090881, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","backgroundsports nutrition is a constantly evolving field with hundreds of research papers published annually. in the year 2017 alone, 2082 articles were published under the key words ‘sport nutrition’. consequently, staying current with the relevant literature is often difficult.methodsthis paper is an ongoing update of the sports nutrition review article originally published as the lead paper to launch the journal of the international society of sports nutrition in 2004 and updated in 2010. it presents a well-referenced overview of the current state of the science related to optimization of training and performance enhancement through exercise training and nutrition. notably, due to the accelerated pace and size at which the literature base in this research area grows, the topics discussed will focus on muscle hypertrophy and performance enhancement. as such, this paper provides an overview of: 1.) how ergogenic aids and dietary supplements are defined in terms of governmental regulation and oversight; 2.) how dietary supplements are legally regulated in the united states; 3.) how to evaluate the scientific merit of nutritional supplements; 4.) general nutritional strategies to optimize performance and enhance recovery; and, 5.) an overview of our current understanding of nutritional approaches to augment skeletal muscle hypertrophy and the potential ergogenic value of various dietary and supplemental approaches.conclusionsthis updated review is to provide issn members and individuals interested in sports nutrition with information that can be implemented in educational, research or practical settings and serve as a foundational basis for determining the efficacy and safety of many common sport nutrition products and their ingredients.",https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-018-0242-y
efd028b141df6ce6857c3d9bdec8886da0aaf2f2,"Position of the Academy of Nutrition and Dietetics, Dietitians of Canada, and the American College of Sports Medicine: Nutrition and Athletic Performance.","It is the position of the Academy of Nutrition and Dietetics, Dietitians of Canada, and the American College of Sports Medicine that the performance of, and recovery from, sporting activities are enhanced by well-chosen nutrition strategies. These organizations provide guidelines for the appropriate type, amount, and timing of intake of food, fluids, and supplements to promote optimal health and performance across different scenarios of training and competitive sport. This position paper was prepared for members of the Academy of Nutrition and Dietetics, Dietitians of Canada (DC), and American College of Sports Medicine (ACSM), other professional associations, government agencies, industry, and the public. It outlines the Academy's, DC's and ACSM's stance on nutrition factors that have been determined to influence athletic performance and emerging trends in the field of sports nutrition. Athletes should be referred to a registered dietitian/nutritionist for a personalized nutrition plan. In the United States and in Canada, the Certified Specialist in Sports Dietetics (CSSD) is a registered dietitian/nutritionist and a credentialed sports nutrition expert.",2016,[],"{'url': 'https://dcjournal.ca/doi/pdf/10.3148/cjdpr-2015-047', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3148/cjdpr-2015-047?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3148/cjdpr-2015-047, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","it is the position of the academy of nutrition and dietetics, dietitians of canada, and the american college of sports medicine that the performance of, and recovery from, sporting activities are enhanced by well-chosen nutrition strategies. these organizations provide guidelines for the appropriate type, amount, and timing of intake of food, fluids, and supplements to promote optimal health and performance across different scenarios of training and competitive sport. this position paper was prepared for members of the academy of nutrition and dietetics, dietitians of canada (dc), and american college of sports medicine (acsm), other professional associations, government agencies, industry, and the public. it outlines the academy's, dc's and acsm's stance on nutrition factors that have been determined to influence athletic performance and emerging trends in the field of sports nutrition. athletes should be referred to a registered dietitian/nutritionist for a personalized nutrition plan. in the united states and in canada, the certified specialist in sports dietetics (cssd) is a registered dietitian/nutritionist and a credentialed sports nutrition expert.",https://dcjournal.ca/doi/pdf/10.3148/cjdpr-2015-047
0258a2f14da7dcffed9b39ecf9bd24ff48c72912,American College of Sports Medicine roundtable on exercise guidelines for cancer survivors.,"Early detection and improved treatments for cancer have resulted in roughly 12 million survivors alive in the United States today. This growing population faces unique challenges from their disease and treatments, including risk for recurrent cancer, other chronic diseases, and persistent adverse effects on physical functioning and quality of life. Historically, clinicians advised cancer patients to rest and to avoid activity; however, emerging research on exercise has challenged this recommendation. To this end, a roundtable was convened by American College of Sports Medicine to distill the literature on the safety and efficacy of exercise training during and after adjuvant cancer therapy and to provide guidelines. The roundtable concluded that exercise training is safe during and after cancer treatments and results in improvements in physical functioning, quality of life, and cancer-related fatigue in several cancer survivor groups. Implications for disease outcomes and survival are still unknown. Nevertheless, the benefits to physical functioning and quality of life are sufficient for the recommendation that cancer survivors follow the 2008 Physical Activity Guidelines for Americans, with specific exercise programming adaptations based on disease and treatment-related adverse effects. The advice to ""avoid inactivity,"" even in cancer patients with existing disease or undergoing difficult treatments, is likely helpful.",2010,"[{'authorId': '118708988', 'name': 'K. Schmitz'}, {'authorId': '4555100', 'name': 'K. Courneya'}, {'authorId': '2064528513', 'name': 'Charles Matthews'}, {'authorId': '1398199397', 'name': 'W. Demark-Wahnefried'}, {'authorId': '15521228', 'name': 'D. Galvão'}, {'authorId': '34568413', 'name': 'B. Pinto'}, {'authorId': '31873085', 'name': 'M. Irwin'}, {'authorId': '6158047', 'name': 'K. Wolin'}, {'authorId': '153656219', 'name': 'R. Segal'}, {'authorId': '143987633', 'name': 'A. Lucia'}, {'authorId': '4772145', 'name': 'C. Schneider'}, {'authorId': '5324209', 'name': 'V. V. von Gruenigen'}, {'authorId': '2149607613', 'name': 'A. Schwartz'}]","{'url': 'https://doi.org/10.1249/mss.0b013e3181e0c112', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1249/MSS.0b013e3181e0c112?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1249/MSS.0b013e3181e0c112, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","early detection and improved treatments for cancer have resulted in roughly 12 million survivors alive in the united states today. this growing population faces unique challenges from their disease and treatments, including risk for recurrent cancer, other chronic diseases, and persistent adverse effects on physical functioning and quality of life. historically, clinicians advised cancer patients to rest and to avoid activity; however, emerging research on exercise has challenged this recommendation. to this end, a roundtable was convened by american college of sports medicine to distill the literature on the safety and efficacy of exercise training during and after adjuvant cancer therapy and to provide guidelines. the roundtable concluded that exercise training is safe during and after cancer treatments and results in improvements in physical functioning, quality of life, and cancer-related fatigue in several cancer survivor groups. implications for disease outcomes and survival are still unknown. nevertheless, the benefits to physical functioning and quality of life are sufficient for the recommendation that cancer survivors follow the 2008 physical activity guidelines for americans, with specific exercise programming adaptations based on disease and treatment-related adverse effects. the advice to ""avoid inactivity,"" even in cancer patients with existing disease or undergoing difficult treatments, is likely helpful.",https://doi.org/10.1249/mss.0b013e3181e0c112
820d675ac8516c76beff892869a1b08ad7de93d3,American College of Sports Medicine Position Stand. Appropriate physical activity intervention strategies for weight loss and prevention of weight regain for adults.,"Overweight and obesity affects more than 66% of the adult population and is associated with a variety of chronic diseases. Weight reduction reduces health risks associated with chronic diseases and is therefore encouraged by major health agencies. Guidelines of the National Heart, Lung, and Blood Institute (NHLBI) encourage a 10% reduction in weight, although considerable literature indicates reduction in health risk with 3% to 5% reduction in weight. Physical activity (PA) is recommended as a component of weight management for prevention of weight gain, for weight loss, and for prevention of weight regain after weight loss. In 2001, the American College of Sports Medicine (ACSM) published a Position Stand that recommended a minimum of 150 min wk(-1) of moderate-intensity PA for overweight and obese adults to improve health; however, 200-300 min wk(-1) was recommended for long-term weight loss. More recent evidence has supported this recommendation and has indicated more PA may be necessary to prevent weight regain after weight loss. To this end, we have reexamined the evidence from 1999 to determine whether there is a level at which PA is effective for prevention of weight gain, for weight loss, and prevention of weight regain. Evidence supports moderate-intensity PA between 150 and 250 min wk(-1) to be effective to prevent weight gain. Moderate-intensity PA between 150 and 250 min wk(-1) will provide only modest weight loss. Greater amounts of PA (>250 min wk(-1)) have been associated with clinically significant weight loss. Moderate-intensity PA between 150 and 250 min wk(-1) will improve weight loss in studies that use moderate diet restriction but not severe diet restriction. Cross-sectional and prospective studies indicate that after weight loss, weight maintenance is improved with PA >250 min wk(-1). However, no evidence from well-designed randomized controlled trials exists to judge the effectiveness of PA for prevention of weight regain after weight loss. Resistance training does not enhance weight loss but may increase fat-free mass and increase loss of fat mass and is associated with reductions in health risk. Existing evidence indicates that endurance PA or resistance training without weight loss improves health risk. There is inadequate evidence to determine whether PA prevents or attenuates detrimental changes in chronic disease risk during weight gain.",2009,"[{'authorId': '144446120', 'name': 'J. Donnelly'}, {'authorId': '6377701', 'name': 'S. Blair'}, {'authorId': '4518926', 'name': 'J. Jakicic'}, {'authorId': '5749507', 'name': 'M. Manore'}, {'authorId': '3813232', 'name': 'J. Rankin'}, {'authorId': '119825761', 'name': 'Bryan K. Smith'}]","{'url': 'https://journals.lww.com/acsm-msse/fulltext/2009/07000/appropriate_physical_activity_intervention.23.aspx', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1249/MSS.0b013e3181949333?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1249/MSS.0b013e3181949333, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","overweight and obesity affects more than 66% of the adult population and is associated with a variety of chronic diseases. weight reduction reduces health risks associated with chronic diseases and is therefore encouraged by major health agencies. guidelines of the national heart, lung, and blood institute (nhlbi) encourage a 10% reduction in weight, although considerable literature indicates reduction in health risk with 3% to 5% reduction in weight. physical activity (pa) is recommended as a component of weight management for prevention of weight gain, for weight loss, and for prevention of weight regain after weight loss. in 2001, the american college of sports medicine (acsm) published a position stand that recommended a minimum of 150 min wk(-1) of moderate-intensity pa for overweight and obese adults to improve health; however, 200-300 min wk(-1) was recommended for long-term weight loss. more recent evidence has supported this recommendation and has indicated more pa may be necessary to prevent weight regain after weight loss. to this end, we have reexamined the evidence from 1999 to determine whether there is a level at which pa is effective for prevention of weight gain, for weight loss, and prevention of weight regain. evidence supports moderate-intensity pa between 150 and 250 min wk(-1) to be effective to prevent weight gain. moderate-intensity pa between 150 and 250 min wk(-1) will provide only modest weight loss. greater amounts of pa (>250 min wk(-1)) have been associated with clinically significant weight loss. moderate-intensity pa between 150 and 250 min wk(-1) will improve weight loss in studies that use moderate diet restriction but not severe diet restriction. cross-sectional and prospective studies indicate that after weight loss, weight maintenance is improved with pa >250 min wk(-1). however, no evidence from well-designed randomized controlled trials exists to judge the effectiveness of pa for prevention of weight regain after weight loss. resistance training does not enhance weight loss but may increase fat-free mass and increase loss of fat mass and is associated with reductions in health risk. existing evidence indicates that endurance pa or resistance training without weight loss improves health risk. there is inadequate evidence to determine whether pa prevents or attenuates detrimental changes in chronic disease risk during weight gain.",https://journals.lww.com/acsm-msse/fulltext/2009/07000/appropriate_physical_activity_intervention.23.aspx
61faf0a5e928faba8d9b542ad044b6f12d945bff,Tracking Systems in Team Sports: A Narrative Review of Applications of the Data and Sport Specific Analysis,"Seeking to obtain a competitive advantage and manage the risk of injury, team sport organisations are investing in tracking systems that can quantify training and competition characteristics. It is expected that such information can support objective decision-making for the prescription and manipulation of training load. This narrative review aims to summarise, and critically evaluate, different tracking systems and their use within team sports. The selection of systems should be dependent upon the context of the sport and needs careful consideration by practitioners. The selection of metrics requires a critical process to be able to describe, plan, monitor and evaluate training and competition characteristics of each sport. An emerging consideration for tracking systems data is the selection of suitable time analysis, such as temporal durations, peak demands or time series segmentation, whose best use depends on the temporal characteristics of the sport. Finally, examples of characteristics and the application of tracking data across seven popular team sports are presented. Practitioners working in specific team sports are advised to follow a critical thinking process, with a healthy dose of scepticism and awareness of appropriate theoretical frameworks, where possible, when creating new or selecting an existing metric to profile team sport athletes.",2022,"[{'authorId': '1401868870', 'name': 'L. Torres-Ronda'}, {'authorId': '1399032031', 'name': 'Emma Beanland'}, {'authorId': '2072730597', 'name': 'S. Whitehead'}, {'authorId': '8003145', 'name': 'Alice J. Sweeting'}, {'authorId': '51169183', 'name': 'J. Clubb'}]","{'url': 'https://sportsmedicine-open.springeropen.com/track/pdf/10.1186/s40798-022-00408-z', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8789973, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","seeking to obtain a competitive advantage and manage the risk of injury, team sport organisations are investing in tracking systems that can quantify training and competition characteristics. it is expected that such information can support objective decision-making for the prescription and manipulation of training load. this narrative review aims to summarise, and critically evaluate, different tracking systems and their use within team sports. the selection of systems should be dependent upon the context of the sport and needs careful consideration by practitioners. the selection of metrics requires a critical process to be able to describe, plan, monitor and evaluate training and competition characteristics of each sport. an emerging consideration for tracking systems data is the selection of suitable time analysis, such as temporal durations, peak demands or time series segmentation, whose best use depends on the temporal characteristics of the sport. finally, examples of characteristics and the application of tracking data across seven popular team sports are presented. practitioners working in specific team sports are advised to follow a critical thinking process, with a healthy dose of scepticism and awareness of appropriate theoretical frameworks, where possible, when creating new or selecting an existing metric to profile team sport athletes.",https://sportsmedicine-open.springeropen.com/track/pdf/10.1186/s40798-022-00408-z
5fecb6875708353f79986e228faf0b8af1ede91a,International Society of Sports Nutrition Position Stand: protein and exercise,"Position statementThe International Society of Sports Nutrition (ISSN) provides an objective and critical review related to the intake of protein for healthy, exercising individuals. Based on the current available literature, the position of the Society is as follows:1)An acute exercise stimulus, particularly resistance exercise, and protein ingestion both stimulate muscle protein synthesis (MPS) and are synergistic when protein consumption occurs before or after resistance exercise.2)For building muscle mass and for maintaining muscle mass through a positive muscle protein balance, an overall daily protein intake in the range of 1.4–2.0 g protein/kg body weight/day (g/kg/d) is sufficient for most exercising individuals, a value that falls in line within the Acceptable Macronutrient Distribution Range published by the Institute of Medicine for protein.3)There is novel evidence that suggests higher protein intakes (>3.0 g/kg/d) may have positive effects on body composition in resistance-trained individuals (i.e., promote loss of fat mass).4)Recommendations regarding the optimal protein intake per serving for athletes to maximize MPS are mixed and are dependent upon age and recent resistance exercise stimuli. General recommendations are 0.25 g of a high-quality protein per kg of body weight, or an absolute dose of 20–40 g.5)Acute protein doses should strive to contain 700–3000 mg of leucine and/or a higher relative leucine content, in addition to a balanced array of the essential amino acids (EAAs).6)These protein doses should ideally be evenly distributed, every 3–4 h, across the day.7)The optimal time period during which to ingest protein is likely a matter of individual tolerance, since benefits are derived from pre- or post-workout ingestion; however, the anabolic effect of exercise is long-lasting (at least 24 h), but likely diminishes with increasing time post-exercise.8)While it is possible for physically active individuals to obtain their daily protein requirements through the consumption of whole foods, supplementation is a practical way of ensuring intake of adequate protein quality and quantity, while minimizing caloric intake, particularly for athletes who typically complete high volumes of training.9)Rapidly digested proteins that contain high proportions of essential amino acids (EAAs) and adequate leucine, are most effective in stimulating MPS.10)Different types and quality of protein can affect amino acid bioavailability following protein supplementation.11)Athletes should consider focusing on whole food sources of protein that contain all of the EAAs (i.e., it is the EAAs that are required to stimulate MPS).12)Endurance athletes should focus on achieving adequate carbohydrate intake to promote optimal performance; the addition of protein may help to offset muscle damage and promote recovery.13)Pre-sleep casein protein intake (30–40 g) provides increases in overnight MPS and metabolic rate without influencing lipolysis.",2017,"[{'authorId': '34905148', 'name': 'R. Jäger'}, {'authorId': '5352831', 'name': 'C. Kerksick'}, {'authorId': '31889971', 'name': 'B. Campbell'}, {'authorId': '3864988', 'name': 'Paul J Cribb'}, {'authorId': '9044038', 'name': 'Shawn D. Wells'}, {'authorId': '52168251', 'name': 'Tim M. Skwiat'}, {'authorId': '3962156', 'name': 'M. Purpura'}, {'authorId': '31482783', 'name': 'T. Ziegenfuss'}, {'authorId': '152229834', 'name': 'A. Ferrando'}, {'authorId': '5611357', 'name': 'S. Arent'}, {'authorId': '15821634', 'name': 'A. Smith‐Ryan'}, {'authorId': '153233032', 'name': 'Jeffrey R. Stout'}, {'authorId': '6233040', 'name': 'P. Arciero'}, {'authorId': '3775412', 'name': 'M. Ormsbee'}, {'authorId': '31888131', 'name': 'L. Taylor'}, {'authorId': '5031930', 'name': 'C. Wilborn'}, {'authorId': '46541084', 'name': 'D. Kalman'}, {'authorId': '3762776', 'name': 'R. Kreider'}, {'authorId': '145351801', 'name': 'D. Willoughby'}, {'authorId': '2521940', 'name': 'J. Hoffman'}, {'authorId': '52141471', 'name': 'J. Krzykowski'}, {'authorId': '66053606', 'name': 'J. Antonio'}]","{'url': 'https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-017-0177-8', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5477153, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","position statementthe international society of sports nutrition (issn) provides an objective and critical review related to the intake of protein for healthy, exercising individuals. based on the current available literature, the position of the society is as follows:1)an acute exercise stimulus, particularly resistance exercise, and protein ingestion both stimulate muscle protein synthesis (mps) and are synergistic when protein consumption occurs before or after resistance exercise.2)for building muscle mass and for maintaining muscle mass through a positive muscle protein balance, an overall daily protein intake in the range of 1.4–2.0 g protein/kg body weight/day (g/kg/d) is sufficient for most exercising individuals, a value that falls in line within the acceptable macronutrient distribution range published by the institute of medicine for protein.3)there is novel evidence that suggests higher protein intakes (>3.0 g/kg/d) may have positive effects on body composition in resistance-trained individuals (i.e., promote loss of fat mass).4)recommendations regarding the optimal protein intake per serving for athletes to maximize mps are mixed and are dependent upon age and recent resistance exercise stimuli. general recommendations are 0.25 g of a high-quality protein per kg of body weight, or an absolute dose of 20–40 g.5)acute protein doses should strive to contain 700–3000 mg of leucine and/or a higher relative leucine content, in addition to a balanced array of the essential amino acids (eaas).6)these protein doses should ideally be evenly distributed, every 3–4 h, across the day.7)the optimal time period during which to ingest protein is likely a matter of individual tolerance, since benefits are derived from pre- or post-workout ingestion; however, the anabolic effect of exercise is long-lasting (at least 24 h), but likely diminishes with increasing time post-exercise.8)while it is possible for physically active individuals to obtain their daily protein requirements through the consumption of whole foods, supplementation is a practical way of ensuring intake of adequate protein quality and quantity, while minimizing caloric intake, particularly for athletes who typically complete high volumes of training.9)rapidly digested proteins that contain high proportions of essential amino acids (eaas) and adequate leucine, are most effective in stimulating mps.10)different types and quality of protein can affect amino acid bioavailability following protein supplementation.11)athletes should consider focusing on whole food sources of protein that contain all of the eaas (i.e., it is the eaas that are required to stimulate mps).12)endurance athletes should focus on achieving adequate carbohydrate intake to promote optimal performance; the addition of protein may help to offset muscle damage and promote recovery.13)pre-sleep casein protein intake (30–40 g) provides increases in overnight mps and metabolic rate without influencing lipolysis.",https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-017-0177-8
f53a225c0fa3e9c0c23d12ecde04a6c767ce35bf,"Implementing the 27 PRISMA 2020 Statement items for systematic reviews in the sport and exercise medicine, musculoskeletal rehabilitation and sports science fields: the PERSiST (implementing Prisma in Exercise, Rehabilitation, Sport medicine and SporTs science) guidance","Poor reporting of medical and healthcare systematic reviews is a problem from which the sports and exercise medicine, musculoskeletal rehabilitation, and sports science fields are not immune. Transparent, accurate and comprehensive systematic review reporting helps researchers replicate methods, readers understand what was done and why, and clinicians and policy-makers implement results in practice. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) Statement and its accompanying Explanation and Elaboration document provide general reporting examples for systematic reviews of healthcare interventions. However, implementation guidance for sport and exercise medicine, musculoskeletal rehabilitation, and sports science does not exist. The Prisma in Exercise, Rehabilitation, Sport medicine and SporTs science (PERSiST) guidance attempts to address this problem. Nineteen content experts collaborated with three methods experts to identify examples of exemplary reporting in systematic reviews in sport and exercise medicine (including physical activity), musculoskeletal rehabilitation (including physiotherapy), and sports science, for each of the PRISMA 2020 Statement items. PERSiST aims to help: (1) systematic reviewers improve the transparency and reporting of systematic reviews and (2) journal editors and peer reviewers make informed decisions about systematic review reporting quality.",2021,"[{'authorId': '4503130', 'name': 'C. Ardern'}, {'authorId': '37572112', 'name': 'F. Büttner'}, {'authorId': '33799203', 'name': 'R. Andrade'}, {'authorId': '77142951', 'name': 'A. Weir'}, {'authorId': '3847529', 'name': 'M. Ashe'}, {'authorId': '48703261', 'name': 'S. Holden'}, {'authorId': '4708915', 'name': 'F. Impellizzeri'}, {'authorId': '2761337', 'name': 'E. Delahunt'}, {'authorId': '47321187', 'name': 'H. Dijkstra'}, {'authorId': '3725270', 'name': 'Stephanie Mathieson'}, {'authorId': '3756658', 'name': 'M. Rathleff'}, {'authorId': '5593245', 'name': 'G. Reurink'}, {'authorId': '144483863', 'name': 'C. Sherrington'}, {'authorId': '2773188', 'name': 'E. Stamatakis'}, {'authorId': '47373812', 'name': 'B. Vicenzino'}, {'authorId': '40628911', 'name': 'J. L. Whittaker'}, {'authorId': '10214277', 'name': 'A. Wright'}, {'authorId': '143996020', 'name': 'M. Clarke'}, {'authorId': '1825473', 'name': 'D. Moher'}, {'authorId': '37175314', 'name': 'M. Page'}, {'authorId': '114008189', 'name': 'K. Khan'}, {'authorId': '38833271', 'name': 'Marinus Winters'}]","{'url': 'https://bjsm.bmj.com/content/bjsports/56/4/175.full.pdf', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8862073, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","poor reporting of medical and healthcare systematic reviews is a problem from which the sports and exercise medicine, musculoskeletal rehabilitation, and sports science fields are not immune. transparent, accurate and comprehensive systematic review reporting helps researchers replicate methods, readers understand what was done and why, and clinicians and policy-makers implement results in practice. the preferred reporting items for systematic reviews and meta-analyses (prisma) statement and its accompanying explanation and elaboration document provide general reporting examples for systematic reviews of healthcare interventions. however, implementation guidance for sport and exercise medicine, musculoskeletal rehabilitation, and sports science does not exist. the prisma in exercise, rehabilitation, sport medicine and sports science (persist) guidance attempts to address this problem. nineteen content experts collaborated with three methods experts to identify examples of exemplary reporting in systematic reviews in sport and exercise medicine (including physical activity), musculoskeletal rehabilitation (including physiotherapy), and sports science, for each of the prisma 2020 statement items. persist aims to help: (1) systematic reviewers improve the transparency and reporting of systematic reviews and (2) journal editors and peer reviewers make informed decisions about systematic review reporting quality.",https://bjsm.bmj.com/content/bjsports/56/4/175.full.pdf
3767faf60096a446d07d95c70dfe879fb650a96b,Physical activity and public health: updated recommendation for adults from the American College of Sports Medicine and the American Heart Association.,"SUMMARY
In 1995 the American College of Sports Medicine and the Centers for Disease Control and Prevention published national guidelines on Physical Activity and Public Health. The Committee on Exercise and Cardiac Rehabilitation of the American Heart Association endorsed and supported these recommendations. The purpose of the present report is to update and clarify the 1995 recommendations on the types and amounts of physical activity needed by healthy adults to improve and maintain health. Development of this document was by an expert panel of scientists, including physicians, epidemiologists, exercise scientists, and public health specialists. This panel reviewed advances in pertinent physiologic, epidemiologic, and clinical scientific data, including primary research articles and reviews published since the original recommendation was issued in 1995. Issues considered by the panel included new scientific evidence relating physical activity to health, physical activity recommendations by various organizations in the interim, and communications issues. Key points related to updating the physical activity recommendation were outlined and writing groups were formed. A draft manuscript was prepared and circulated for review to the expert panel as well as to outside experts. Comments were integrated into the final recommendation.


PRIMARY RECOMMENDATION
To promote and maintain health, all healthy adults aged 18 to 65 yr need moderate-intensity aerobic (endurance) physical activity for a minimum of 30 min on five days each week or vigorous-intensity aerobic physical activity for a minimum of 20 min on three days each week. [I (A)] Combinations of moderate- and vigorous-intensity activity can be performed to meet this recommendation. [IIa (B)] For example, a person can meet the recommendation by walking briskly for 30 min twice during the week and then jogging for 20 min on two other days. Moderate-intensity aerobic activity, which is generally equivalent to a brisk walk and noticeably accelerates the heart rate, can be accumulated toward the 30-min minimum by performing bouts each lasting 10 or more minutes. [I (B)] Vigorous-intensity activity is exemplified by jogging, and causes rapid breathing and a substantial increase in heart rate. In addition, every adult should perform activities that maintain or increase muscular strength and endurance a minimum of two days each week. [IIa (A)] Because of the dose-response relation between physical activity and health, persons who wish to further improve their personal fitness, reduce their risk for chronic diseases and disabilities or prevent unhealthy weight gain may benefit by exceeding the minimum recommended amounts of physical activity. [I (A)].",2007,"[{'authorId': '2796639', 'name': 'W. Haskell'}, {'authorId': '6597940', 'name': 'I. Lee'}, {'authorId': '8599311', 'name': 'R. Pate'}, {'authorId': '2022266', 'name': 'K. Powell'}, {'authorId': '6377701', 'name': 'S. Blair'}, {'authorId': '5936906', 'name': 'B. Franklin'}, {'authorId': '4676581', 'name': 'C. Macera'}, {'authorId': '6609272', 'name': 'G. Heath'}, {'authorId': '35038737', 'name': 'P. Thompson'}, {'authorId': '144127421', 'name': 'A. Bauman'}]","{'url': 'https://doi.org/10.1249/mss.0b013e3180616b27', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1249/mss.0b013e3180616b27?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1249/mss.0b013e3180616b27, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","summary in 1995 the american college of sports medicine and the centers for disease control and prevention published national guidelines on physical activity and public health. the committee on exercise and cardiac rehabilitation of the american heart association endorsed and supported these recommendations. the purpose of the present report is to update and clarify the 1995 recommendations on the types and amounts of physical activity needed by healthy adults to improve and maintain health. development of this document was by an expert panel of scientists, including physicians, epidemiologists, exercise scientists, and public health specialists. this panel reviewed advances in pertinent physiologic, epidemiologic, and clinical scientific data, including primary research articles and reviews published since the original recommendation was issued in 1995. issues considered by the panel included new scientific evidence relating physical activity to health, physical activity recommendations by various organizations in the interim, and communications issues. key points related to updating the physical activity recommendation were outlined and writing groups were formed. a draft manuscript was prepared and circulated for review to the expert panel as well as to outside experts. comments were integrated into the final recommendation. primary recommendation to promote and maintain health, all healthy adults aged 18 to 65 yr need moderate-intensity aerobic (endurance) physical activity for a minimum of 30 min on five days each week or vigorous-intensity aerobic physical activity for a minimum of 20 min on three days each week. [i (a)] combinations of moderate- and vigorous-intensity activity can be performed to meet this recommendation. [iia (b)] for example, a person can meet the recommendation by walking briskly for 30 min twice during the week and then jogging for 20 min on two other days. moderate-intensity aerobic activity, which is generally equivalent to a brisk walk and noticeably accelerates the heart rate, can be accumulated toward the 30-min minimum by performing bouts each lasting 10 or more minutes. [i (b)] vigorous-intensity activity is exemplified by jogging, and causes rapid breathing and a substantial increase in heart rate. in addition, every adult should perform activities that maintain or increase muscular strength and endurance a minimum of two days each week. [iia (a)] because of the dose-response relation between physical activity and health, persons who wish to further improve their personal fitness, reduce their risk for chronic diseases and disabilities or prevent unhealthy weight gain may benefit by exceeding the minimum recommended amounts of physical activity. [i (a)].",https://doi.org/10.1249/mss.0b013e3180616b27
30e9d72e128f1779a061e4bcd4d15b3a418ac8f0,Wearable Sensors for Real-Time Kinematics Analysis in Sports: A Review,"Wearable Inertial sensors have revolutionised the way kinematics analysis is performed in sports. This paper aims to present a comprehensive review of the literature related to the use of wearable inertial sensors for performance analysis in various games. Kinematics analysis using wearable sensors can provide real-time feedback to the players about their adopted techniques in their respective sports and thus help them to perform efficiently. This article reviews the key technologies (IMU sensors, communication technology, data fusion and data analysis techniques) that enable the implementation of wearable sensors for performance analysis in sports. The review focuses on research papers, commercial sports sensors and 3D motion tracking products to provide a holistic and systematic categorisation & analysis of the wearable sensors in sports. The review identifies the importance of sensors classification, applications and performance parameters in sports for structured analysis. The survey also reviews the technology concerning sensor architecture, network and communication protocols, covers various data fusion algorithms and their accuracy while throwing light on essential performance matrices for an athlete. This review paper will assist both end-users and the researchers to have a comprehensive glimpse of the wearable technology pertaining to designing sensors and solutions for athletes in different sports.",2021,"[{'authorId': '38915986', 'name': 'Manju Rana'}, {'authorId': '46662272', 'name': 'Vikas Mittal'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JSEN.2020.3019016?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JSEN.2020.3019016, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","wearable inertial sensors have revolutionised the way kinematics analysis is performed in sports. this paper aims to present a comprehensive review of the literature related to the use of wearable inertial sensors for performance analysis in various games. kinematics analysis using wearable sensors can provide real-time feedback to the players about their adopted techniques in their respective sports and thus help them to perform efficiently. this article reviews the key technologies (imu sensors, communication technology, data fusion and data analysis techniques) that enable the implementation of wearable sensors for performance analysis in sports. the review focuses on research papers, commercial sports sensors and 3d motion tracking products to provide a holistic and systematic categorisation & analysis of the wearable sensors in sports. the review identifies the importance of sensors classification, applications and performance parameters in sports for structured analysis. the survey also reviews the technology concerning sensor architecture, network and communication protocols, covers various data fusion algorithms and their accuracy while throwing light on essential performance matrices for an athlete. this review paper will assist both end-users and the researchers to have a comprehensive glimpse of the wearable technology pertaining to designing sensors and solutions for athletes in different sports.",
f931ee2e0c431126b2ed661c8d6412874748b73f,International Olympic Committee Consensus Statement: Methods for Recording and Reporting of Epidemiological Data on Injury and Illness in Sports 2020 (Including the STROBE Extension for Sports Injury and Illness Surveillance (STROBE-SIIS)),"Background: Injury and illness surveillance, and epidemiological studies, are fundamental elements of concerted efforts to protect the health of the athlete. To encourage consistency in the definitions and methodology used, and to enable data across studies to be compared, research groups have published 11 sport- or setting-specific consensus statements on sports injury (and, eventually, illnesses) epidemiology to date. Objective: To further strengthen consistency in data collection, injury definitions, and research reporting through an updated set of recommendations for sports injury and illness studies, including a new Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) checklist extension. Study Design: Consensus statement of the International Olympic Committee (IOC). Methods: The IOC invited a working group of international experts to review relevant literature and provide recommendations. The procedure included an open online survey, several stages of text drafting and consultation by working groups, and a 3-day consensus meeting in October 2019. Results: This statement includes recommendations for data collection and research reporting covering key components: defining and classifying health problems, severity of health problems, capturing and reporting athlete exposure, expressing risk, burden of health problems, study population characteristics, and data collection methods. Based on these, we also developed a new reporting guideline as a STROBE extension—the STROBE Sports Injury and Illness Surveillance (STROBE-SIIS). Conclusion: The IOC encourages ongoing in- and out-of-competition surveillance programs and studies to describe injury and illness trends and patterns, understand their causes, and develop measures to protect the health of the athlete. The implementation of the methods outlined in this statement will advance consistency in data collection and research reporting.",2020,"[{'authorId': '144905842', 'name': 'R. Bahr'}, {'authorId': '13075031', 'name': 'B. Clarsen'}, {'authorId': '144450830', 'name': 'W. Derman'}, {'authorId': '46408363', 'name': 'J. Dvořák'}, {'authorId': '8170719', 'name': 'C. Emery'}, {'authorId': '34582833', 'name': 'C. Finch'}, {'authorId': '35158477', 'name': 'M. Hägglund'}, {'authorId': '84609852', 'name': 'A. Junge'}, {'authorId': '1399027607', 'name': 'S. Kemp'}, {'authorId': '114008189', 'name': 'K. Khan'}, {'authorId': '2076754', 'name': 'S. Marshall'}, {'authorId': '4754782', 'name': 'W. Meeuwisse'}, {'authorId': '3888843', 'name': 'M. Mountjoy'}, {'authorId': '37569219', 'name': 'J. Orchard'}, {'authorId': '5762429', 'name': 'B. Pluim'}, {'authorId': '4718091', 'name': 'K. Quarrie'}, {'authorId': '6593115', 'name': 'B. Reider'}, {'authorId': '145291654', 'name': 'M. Schwellnus'}, {'authorId': '3605551', 'name': 'T. Soligard'}, {'authorId': '2574817', 'name': 'K. Stokes'}, {'authorId': '1775216', 'name': 'T. Timpka'}, {'authorId': '145026133', 'name': 'E. Verhagen'}, {'authorId': '97621951', 'name': 'Abhinav Bindra'}, {'authorId': '145777847', 'name': 'R. Budgett'}, {'authorId': '144074665', 'name': 'L. Engebretsen'}, {'authorId': '6690428', 'name': 'U. Erdener'}, {'authorId': '5446245', 'name': 'K. Chamari'}]","{'url': 'https://europepmc.org/articles/pmc7029549?pdf=render', 'status': 'GREEN', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7029549, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background: injury and illness surveillance, and epidemiological studies, are fundamental elements of concerted efforts to protect the health of the athlete. to encourage consistency in the definitions and methodology used, and to enable data across studies to be compared, research groups have published 11 sport- or setting-specific consensus statements on sports injury (and, eventually, illnesses) epidemiology to date. objective: to further strengthen consistency in data collection, injury definitions, and research reporting through an updated set of recommendations for sports injury and illness studies, including a new strengthening the reporting of observational studies in epidemiology (strobe) checklist extension. study design: consensus statement of the international olympic committee (ioc). methods: the ioc invited a working group of international experts to review relevant literature and provide recommendations. the procedure included an open online survey, several stages of text drafting and consultation by working groups, and a 3-day consensus meeting in october 2019. results: this statement includes recommendations for data collection and research reporting covering key components: defining and classifying health problems, severity of health problems, capturing and reporting athlete exposure, expressing risk, burden of health problems, study population characteristics, and data collection methods. based on these, we also developed a new reporting guideline as a strobe extension—the strobe sports injury and illness surveillance (strobe-siis). conclusion: the ioc encourages ongoing in- and out-of-competition surveillance programs and studies to describe injury and illness trends and patterns, understand their causes, and develop measures to protect the health of the athlete. the implementation of the methods outlined in this statement will advance consistency in data collection and research reporting.",https://europepmc.org/articles/pmc7029549?pdf=render
d1555ce704884cd8875e4d75836441ea151d212c,The Impacts of Sports Schools on Holistic Athlete Development: A Mixed Methods Systematic Review,"To understand the multiple and wide-ranging impacts of intensified youth sport, the need for a holistic approach to athlete development has recently been advocated. Sports schools are an increasingly popular operationalisation of intensified youth sport, aiming to offer an optimal environment for holistic development by combining sport and education. Yet, no study has systematically explored the impacts associated with sports schools. The aims of this mixed method systematic review were to (1) determine the characteristics and features of sports schools; (2) identify the methods used to evaluate sports school impacts, and (3) evaluate the positive and negative holistic athlete development impacts associated with sports school programme involvement. Adhering to PRISMA guidelines, eight electronic databases were searched until the final return in February 2021. Forty-six articles satisfied the inclusion criteria, were analysed thematically, and synthesised using a narrative approach. The methodological quality of included studies was assessed using the Mixed Methods Appraisal Tool. Findings indicated (1) sports school student-athletes receive considerable support in terms of academic and athletic services, more intensified training and competition schedules with high-level training partners, but regularly miss school; (2) multiple methods have been used to evaluate student-athlete impacts, making comparison across studies and developing consensus on the impacts of sports schools difficult; and (3) there are a multitude of immediate, short- and long-term positive and negative impacts associated with the academic/vocational, athletic/physical, psychosocial and psychological development of sports school student-athletes. This study is the first to systematically review the research literature to understand the impacts associated with sports schools in terms of holistic athlete development. Practitioners should be aware that they can promote (positive) and negate (negative) health impacts through the design of an appropriate learning environment that simultaneously balances multiple training, academic, psychosocial and psychological factors that can be challenging for youth athletes. We recommend that practitioners aim to design and implement monitoring and evaluation tools that assess the holistic development of student-athletes within their sports schools to ensure they are promoting all-round and healthy youth athlete development.",2022,"[{'authorId': '2157979392', 'name': 'Ffion Thompson'}, {'authorId': '50237084', 'name': 'F. Rongen'}, {'authorId': '25149047', 'name': 'I. Cowburn'}, {'authorId': '5378912', 'name': 'K. Till'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s40279-022-01664-5.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9325842, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","to understand the multiple and wide-ranging impacts of intensified youth sport, the need for a holistic approach to athlete development has recently been advocated. sports schools are an increasingly popular operationalisation of intensified youth sport, aiming to offer an optimal environment for holistic development by combining sport and education. yet, no study has systematically explored the impacts associated with sports schools. the aims of this mixed method systematic review were to (1) determine the characteristics and features of sports schools; (2) identify the methods used to evaluate sports school impacts, and (3) evaluate the positive and negative holistic athlete development impacts associated with sports school programme involvement. adhering to prisma guidelines, eight electronic databases were searched until the final return in february 2021. forty-six articles satisfied the inclusion criteria, were analysed thematically, and synthesised using a narrative approach. the methodological quality of included studies was assessed using the mixed methods appraisal tool. findings indicated (1) sports school student-athletes receive considerable support in terms of academic and athletic services, more intensified training and competition schedules with high-level training partners, but regularly miss school; (2) multiple methods have been used to evaluate student-athlete impacts, making comparison across studies and developing consensus on the impacts of sports schools difficult; and (3) there are a multitude of immediate, short- and long-term positive and negative impacts associated with the academic/vocational, athletic/physical, psychosocial and psychological development of sports school student-athletes. this study is the first to systematically review the research literature to understand the impacts associated with sports schools in terms of holistic athlete development. practitioners should be aware that they can promote (positive) and negate (negative) health impacts through the design of an appropriate learning environment that simultaneously balances multiple training, academic, psychosocial and psychological factors that can be challenging for youth athletes. we recommend that practitioners aim to design and implement monitoring and evaluation tools that assess the holistic development of student-athletes within their sports schools to ensure they are promoting all-round and healthy youth athlete development.",https://link.springer.com/content/pdf/10.1007/s40279-022-01664-5.pdf
864944a082e0a6de24fd1a08f51cbb8d7d1d2f56,Inequalities in the Evaluation of Male Versus Female Athletes in Sports Medicine Research: A Systematic Review,"Background: Female sports participation continues to rise; however, inequalities between male and female athletes still exist in many areas and may extend into medical research. Purpose: The purpose of this study was to (1) compare the number of published studies evaluating male versus female athletes in various sports and (2) identify which co-ed sports currently underrepresent female athletes in the sports medicine literature. Study Design: Systematic review; Level of evidence, 4. Methods: All nonreview research studies published from 2017 to 2021 in 6 top sports medicine journals were considered for inclusion. Sports medicine studies were included that isolated athletes, reported study outcomes specific to male and/or female patients, provided study outcomes for specific sports, and evaluated ≤3 different sports. The total number of studies reporting on male and/or female athletes were compared for all sports, and odds ratios (ORs) were calculated. Comparisons of study design, level of sports participation, outcomes assessed, and study quality were also made according to participant sex. Results: Overall, 669 studies were included the systematic review. Most studies isolated male athletes (70.7%), while 8.8% isolated female athletes and 20.5% included male and female athletes. Female athletes were more frequently studied in softball and volleyball, while male athletes were more commonly researched in baseball, soccer, American football, basketball, rugby, hockey, and Australian football. Notably, male athletes were largely favored in baseball/softball (91% vs 5%; OR = 18.2), rugby (72% vs 5%; OR = 14.4), soccer (65% vs 15%; OR = 4.3), and basketball (58% vs 18%; OR = 3.2). Conclusion: Sports medicine research has favored the evaluation of male athletes in most sports, including the majority of co-ed sports. Potential reasons for this inequality of research evaluation include availability of public data and database data, financial and promotional incentives, a high percentage of male sports medicine clinicians and researchers, and sex biases in sport. While the causes of these differences are multifaceted, researchers should consider both sexes for study inclusion whenever possible, and journals should support a more balanced representation of research publications regarding male and female athletes.",2022,"[{'authorId': '1491134366', 'name': 'Ryan W. Paul'}, {'authorId': '1491282729', 'name': 'J. Sonnier'}, {'authorId': '145545820', 'name': 'E. Johnson'}, {'authorId': '2052950840', 'name': 'Anya T. Hall'}, {'authorId': '2142983013', 'name': 'Alim Osman'}, {'authorId': '2191887694', 'name': 'Gregory Connors'}, {'authorId': '4088747', 'name': 'K. Freedman'}, {'authorId': '145528220', 'name': 'M. Bishop'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/03635465221131281?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/03635465221131281, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background: female sports participation continues to rise; however, inequalities between male and female athletes still exist in many areas and may extend into medical research. purpose: the purpose of this study was to (1) compare the number of published studies evaluating male versus female athletes in various sports and (2) identify which co-ed sports currently underrepresent female athletes in the sports medicine literature. study design: systematic review; level of evidence, 4. methods: all nonreview research studies published from 2017 to 2021 in 6 top sports medicine journals were considered for inclusion. sports medicine studies were included that isolated athletes, reported study outcomes specific to male and/or female patients, provided study outcomes for specific sports, and evaluated ≤3 different sports. the total number of studies reporting on male and/or female athletes were compared for all sports, and odds ratios (ors) were calculated. comparisons of study design, level of sports participation, outcomes assessed, and study quality were also made according to participant sex. results: overall, 669 studies were included the systematic review. most studies isolated male athletes (70.7%), while 8.8% isolated female athletes and 20.5% included male and female athletes. female athletes were more frequently studied in softball and volleyball, while male athletes were more commonly researched in baseball, soccer, american football, basketball, rugby, hockey, and australian football. notably, male athletes were largely favored in baseball/softball (91% vs 5%; or = 18.2), rugby (72% vs 5%; or = 14.4), soccer (65% vs 15%; or = 4.3), and basketball (58% vs 18%; or = 3.2). conclusion: sports medicine research has favored the evaluation of male athletes in most sports, including the majority of co-ed sports. potential reasons for this inequality of research evaluation include availability of public data and database data, financial and promotional incentives, a high percentage of male sports medicine clinicians and researchers, and sex biases in sport. while the causes of these differences are multifaceted, researchers should consider both sexes for study inclusion whenever possible, and journals should support a more balanced representation of research publications regarding male and female athletes.",
f1e6247d70e54d608c72b37dd426b7b23004ff84,American College of Sports Medicine position stand. Progression models in resistance training for healthy adults.,"In order to stimulate further adaptation toward a specific training goal(s), progression in the type of resistance training protocol used is necessary. The optimal characteristics of strength-specific programs include the use of both concentric and eccentric muscle actions and the performance of both single- and multiple-joint exercises. It is also recommended that the strength program sequence exercises to optimize the quality of the exercise intensity (large before small muscle group exercises, multiple-joint exercises before single-joint exercises, and higher intensity before lower intensity exercises). For initial resistances, it is recommended that loads corresponding to 8-12 repetition maximum (RM) be used in novice training. For intermediate to advanced training, it is recommended that individuals use a wider loading range, from 1-12 RM in a periodized fashion, with eventual emphasis on heavy loading (1-6 RM) using at least 3-min rest periods between sets performed at a moderate contraction velocity (1-2 s concentric, 1-2 s eccentric). When training at a specific RM load, it is recommended that 2-10% increase in load be applied when the individual can perform the current workload for one to two repetitions over the desired number. The recommendation for training frequency is 2-3 d x wk(-1) for novice and intermediate training and 4-5 d x wk(-1) for advanced training. Similar program designs are recommended for hypertrophy training with respect to exercise selection and frequency. For loading, it is recommended that loads corresponding to 1-12 RM be used in periodized fashion, with emphasis on the 6-12 RM zone using 1- to 2-min rest periods between sets at a moderate velocity. Higher volume, multiple-set programs are recommended for maximizing hypertrophy. Progression in power training entails two general loading strategies: 1) strength training, and 2) use of light loads (30-60% of 1 RM) performed at a fast contraction velocity with 2-3 min of rest between sets for multiple sets per exercise. It is also recommended that emphasis be placed on multiple-joint exercises, especially those involving the total body. For local muscular endurance training, it is recommended that light to moderate loads (40-60% of 1 RM) be performed for high repetitions (> 15) using short rest periods (< 90 s). In the interpretation of this position stand, as with prior ones, the recommendations should be viewed in context of the individual's target goals, physical capacity, and training status.",2002,"[{'authorId': '1851458', 'name': 'W. Kraemer'}, {'authorId': '144235600', 'name': 'K. Adams'}, {'authorId': '6269018', 'name': 'E. Cafarelli'}, {'authorId': '2454872', 'name': 'G. Dudley'}, {'authorId': '4406652', 'name': 'C. Dooly'}, {'authorId': '8963946', 'name': 'M. Feigenbaum'}, {'authorId': '7731560', 'name': 'S. Fleck'}, {'authorId': '5936906', 'name': 'B. Franklin'}, {'authorId': '5211395', 'name': 'A. Fry'}, {'authorId': '2521940', 'name': 'J. Hoffman'}, {'authorId': '29781539', 'name': 'R. Newton'}, {'authorId': '6381812', 'name': 'J. Potteiger'}, {'authorId': '2246312871', 'name': 'M. Stone'}, {'authorId': '3537875', 'name': 'N. Ratamess'}, {'authorId': '1403253288', 'name': 'T. Triplett-mcbride'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1097/00005768-200202000-00027?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1097/00005768-200202000-00027, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in order to stimulate further adaptation toward a specific training goal(s), progression in the type of resistance training protocol used is necessary. the optimal characteristics of strength-specific programs include the use of both concentric and eccentric muscle actions and the performance of both single- and multiple-joint exercises. it is also recommended that the strength program sequence exercises to optimize the quality of the exercise intensity (large before small muscle group exercises, multiple-joint exercises before single-joint exercises, and higher intensity before lower intensity exercises). for initial resistances, it is recommended that loads corresponding to 8-12 repetition maximum (rm) be used in novice training. for intermediate to advanced training, it is recommended that individuals use a wider loading range, from 1-12 rm in a periodized fashion, with eventual emphasis on heavy loading (1-6 rm) using at least 3-min rest periods between sets performed at a moderate contraction velocity (1-2 s concentric, 1-2 s eccentric). when training at a specific rm load, it is recommended that 2-10% increase in load be applied when the individual can perform the current workload for one to two repetitions over the desired number. the recommendation for training frequency is 2-3 d x wk(-1) for novice and intermediate training and 4-5 d x wk(-1) for advanced training. similar program designs are recommended for hypertrophy training with respect to exercise selection and frequency. for loading, it is recommended that loads corresponding to 1-12 rm be used in periodized fashion, with emphasis on the 6-12 rm zone using 1- to 2-min rest periods between sets at a moderate velocity. higher volume, multiple-set programs are recommended for maximizing hypertrophy. progression in power training entails two general loading strategies: 1) strength training, and 2) use of light loads (30-60% of 1 rm) performed at a fast contraction velocity with 2-3 min of rest between sets for multiple sets per exercise. it is also recommended that emphasis be placed on multiple-joint exercises, especially those involving the total body. for local muscular endurance training, it is recommended that light to moderate loads (40-60% of 1 rm) be performed for high repetitions (> 15) using short rest periods (< 90 s). in the interpretation of this position stand, as with prior ones, the recommendations should be viewed in context of the individual's target goals, physical capacity, and training status.",
02271c2bea5b53332da89361a9e4d94a5c45f971,High-Intensity Acceleration and Deceleration Demands in Elite Team Sports Competitive Match Play: A Systematic Review and Meta-Analysis of Observational Studies,"The external movement loads imposed on players during competitive team sports are commonly measured using global positioning system devices. Information gleaned from analyses is employed to calibrate physical conditioning and injury prevention strategies with the external loads imposed during match play. Intense accelerations and decelerations are considered particularly important indicators of external load. However, to date, no prior meta-analysis has compared high and very high intensity acceleration and deceleration demands in elite team sports during competitive match play. The objective of this systematic review and meta-analysis was to quantify and compare high and very high intensity acceleration vs. deceleration demands occurring during competitive match play in elite team sport contexts. A systematic review of four electronic databases (CINAHL, MEDLINE, SPORTDiscus, Web of Science) was conducted to identify peer-reviewed articles published between January 2010 and April 2018 that had reported higher intensity (> 2.5 m·s−2) accelerations and decelerations concurrently in elite team sports competitive match play. A Boolean search phrase was developed using key words synonymous to team sports (population), acceleration and deceleration (comparators) and match play (outcome). Articles only eligible for meta-analysis were those that reported either or both high (> 2.5 m·s−2) and very high (> 3.5 m·s−2) intensity accelerations and decelerations concurrently using global positioning system devices (sampling rate: ≥ 5 Hz) during elite able-bodied (mean age: ≥ 18 years) team sports competitive match play (match time: ≥ 75%). Separate inverse random-effects meta-analyses were conducted to compare: (1) standardised mean differences (SMDs) in the frequency of high and very high intensity accelerations and decelerations occurring during match play, and (2) SMDs of temporal changes in high and very high intensity accelerations and decelerations across first and second half periods of match play. Using recent guidelines recommended for the collection, processing and reporting of global positioning system data, a checklist was produced to help inform a judgement about the methodological limitations (risk of detection bias) aligned to ‘data collection’, ‘data processing’ and ‘normative profile’ for each eligible study. For each study, each outcome was rated as either ‘low’, ‘unclear’ or ‘high’ risk of bias. A total of 19 studies met the eligibility criteria, comprising seven team sports including American Football (n = 1), Australian Football (n = 2), hockey (n = 1), rugby league (n = 4), rugby sevens (n = 3), rugby union (n = 2) and soccer (n = 6) with a total of 469 male participants (mean age: 18–29 years). Analysis showed only American Football reported a greater frequency of high (SMD = 1.26; 95% confidence interval [CI] 1.06–1.43) and very high (SMD = 0.19; 95% CI − 0.42 to 0.80) intensity accelerations compared to decelerations. All other sports had a greater frequency of high and very high intensity decelerations compared to accelerations, with soccer demonstrating the greatest difference for both the high (SMD = − 1.74; 95% CI − 1.28 to − 2.21) and very high (SMD = − 3.19; 95% CI − 2.05 to − 4.33) intensity categories. When examining the temporal changes from the first to the second half periods of match play, there was a small decrease in both the frequency of high and very high intensity accelerations (SMD = 0.50 and 0.49, respectively) and decelerations (SMD = 0.42 and 0.46, respectively). The greatest risk of bias (40% ‘high’ risk of bias) observed across studies was in the ‘data collection’ procedures. The lowest risk of bias (35% ‘low’ risk of bias) was found in the development of a ‘normative profile’. To ensure that elite players are optimally prepared for the high-intensity accelerations and decelerations imposed during competitive match play, it is imperative that players are exposed to comparable demands under controlled training conditions. The results of this meta-analysis, accordingly, can inform practical training designs. Finally, guidelines and recommendations for conducting future research, using global positioning system devices, are suggested.",2019,"[{'authorId': '51066767', 'name': 'Damian J. Harper'}, {'authorId': '113359379', 'name': 'C. Carling'}, {'authorId': '144276680', 'name': 'J. Kiely'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s40279-019-01170-1.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6851047, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the external movement loads imposed on players during competitive team sports are commonly measured using global positioning system devices. information gleaned from analyses is employed to calibrate physical conditioning and injury prevention strategies with the external loads imposed during match play. intense accelerations and decelerations are considered particularly important indicators of external load. however, to date, no prior meta-analysis has compared high and very high intensity acceleration and deceleration demands in elite team sports during competitive match play. the objective of this systematic review and meta-analysis was to quantify and compare high and very high intensity acceleration vs. deceleration demands occurring during competitive match play in elite team sport contexts. a systematic review of four electronic databases (cinahl, medline, sportdiscus, web of science) was conducted to identify peer-reviewed articles published between january 2010 and april 2018 that had reported higher intensity (> 2.5 m·s−2) accelerations and decelerations concurrently in elite team sports competitive match play. a boolean search phrase was developed using key words synonymous to team sports (population), acceleration and deceleration (comparators) and match play (outcome). articles only eligible for meta-analysis were those that reported either or both high (> 2.5 m·s−2) and very high (> 3.5 m·s−2) intensity accelerations and decelerations concurrently using global positioning system devices (sampling rate: ≥ 5 hz) during elite able-bodied (mean age: ≥ 18 years) team sports competitive match play (match time: ≥ 75%). separate inverse random-effects meta-analyses were conducted to compare: (1) standardised mean differences (smds) in the frequency of high and very high intensity accelerations and decelerations occurring during match play, and (2) smds of temporal changes in high and very high intensity accelerations and decelerations across first and second half periods of match play. using recent guidelines recommended for the collection, processing and reporting of global positioning system data, a checklist was produced to help inform a judgement about the methodological limitations (risk of detection bias) aligned to ‘data collection’, ‘data processing’ and ‘normative profile’ for each eligible study. for each study, each outcome was rated as either ‘low’, ‘unclear’ or ‘high’ risk of bias. a total of 19 studies met the eligibility criteria, comprising seven team sports including american football (n = 1), australian football (n = 2), hockey (n = 1), rugby league (n = 4), rugby sevens (n = 3), rugby union (n = 2) and soccer (n = 6) with a total of 469 male participants (mean age: 18–29 years). analysis showed only american football reported a greater frequency of high (smd = 1.26; 95% confidence interval [ci] 1.06–1.43) and very high (smd = 0.19; 95% ci − 0.42 to 0.80) intensity accelerations compared to decelerations. all other sports had a greater frequency of high and very high intensity decelerations compared to accelerations, with soccer demonstrating the greatest difference for both the high (smd = − 1.74; 95% ci − 1.28 to − 2.21) and very high (smd = − 3.19; 95% ci − 2.05 to − 4.33) intensity categories. when examining the temporal changes from the first to the second half periods of match play, there was a small decrease in both the frequency of high and very high intensity accelerations (smd = 0.50 and 0.49, respectively) and decelerations (smd = 0.42 and 0.46, respectively). the greatest risk of bias (40% ‘high’ risk of bias) observed across studies was in the ‘data collection’ procedures. the lowest risk of bias (35% ‘low’ risk of bias) was found in the development of a ‘normative profile’. to ensure that elite players are optimally prepared for the high-intensity accelerations and decelerations imposed during competitive match play, it is imperative that players are exposed to comparable demands under controlled training conditions. the results of this meta-analysis, accordingly, can inform practical training designs. finally, guidelines and recommendations for conducting future research, using global positioning system devices, are suggested.",https://link.springer.com/content/pdf/10.1007/s40279-019-01170-1.pdf
84d5009c9c480e3512a822d38d7bc1d0dcb07afd,American Medical Society for Sports Medicine position statement on concussion in sport,"Sport-related concussion (SRC) is a common injury in recreational and organised sport. Over the past 30 years, there has been significant progress in our scientific understanding of SRC, which in turn has driven the development of clinical guidelines for diagnosis, assessment and management of SRC. In addition to a growing need for knowledgeable healthcare professionals to provide evidence-based care for athletes with SRC, media attention and legislation have created awareness and, in some cases, fear about many issues and unknowns surrounding SRC. The American Medical Society for Sports Medicine (AMSSM) formed a writing group to review the existing literature on SRC, update its previous position statement, and to address current evidence and knowledge gaps regarding SRC. The absence of definitive outcomes-based data is challenging and requires relying on the best available evidence integrated with clinical experience and patient values. This statement reviews the definition, pathophysiology and epidemiology of SRC, the diagnosis and management of both acute and persistent concussion symptoms, the short-term and long-term risks of SRC and repetitive head impact exposure, SRC prevention strategies, and potential future directions for SRC research. The AMSSM is committed to best clinical practices, evidence-based research and educational initiatives that positively impact the health and safety of athletes.",2019,"[{'authorId': '5322280', 'name': 'K. Harmon'}, {'authorId': '4383115', 'name': 'J. Clugston'}, {'authorId': '40436748', 'name': 'K. Dec'}, {'authorId': '51973743', 'name': 'B. Hainline'}, {'authorId': '2498504', 'name': 'S. Herring'}, {'authorId': '48309868', 'name': 'Shawn F. Kane'}, {'authorId': '1891443', 'name': 'A. Kontos'}, {'authorId': '2947688', 'name': 'J. Leddy'}, {'authorId': '145331942', 'name': 'M. McCrea'}, {'authorId': '28720300', 'name': 'S. Poddar'}, {'authorId': '5412259', 'name': 'M. Putukian'}, {'authorId': '2109338984', 'name': 'Julie C. Wilson'}, {'authorId': '34700142', 'name': 'W. Roberts'}]","{'url': 'https://bjsm.bmj.com/content/bjsports/53/4/213.full.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1136/bjsports-2018-100338?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1136/bjsports-2018-100338, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","sport-related concussion (src) is a common injury in recreational and organised sport. over the past 30 years, there has been significant progress in our scientific understanding of src, which in turn has driven the development of clinical guidelines for diagnosis, assessment and management of src. in addition to a growing need for knowledgeable healthcare professionals to provide evidence-based care for athletes with src, media attention and legislation have created awareness and, in some cases, fear about many issues and unknowns surrounding src. the american medical society for sports medicine (amssm) formed a writing group to review the existing literature on src, update its previous position statement, and to address current evidence and knowledge gaps regarding src. the absence of definitive outcomes-based data is challenging and requires relying on the best available evidence integrated with clinical experience and patient values. this statement reviews the definition, pathophysiology and epidemiology of src, the diagnosis and management of both acute and persistent concussion symptoms, the short-term and long-term risks of src and repetitive head impact exposure, src prevention strategies, and potential future directions for src research. the amssm is committed to best clinical practices, evidence-based research and educational initiatives that positively impact the health and safety of athletes.",https://bjsm.bmj.com/content/bjsports/53/4/213.full.pdf
975f06d13e68025f8897f6ef4d61bb5df50ceedc,American Medical Society for Sports Medicine position statement: concussion in sport,"Purpose of the statement ▸ To provide an evidence-based, best practises summary to assist physicians with the evaluation and management of sports concussion. ▸ To establish the level of evidence, knowledge gaps and areas requiring additional research. Importance of an AMSSM statement ▸ Sports medicine physicians are frequently involved in the care of patients with sports concussion. ▸ Sports medicine physicians are specifically trained to provide care along the continuum of sports concussion from the acute injury to return-to-play (RTP) decisions. ▸ The care of athletes with sports concussion is ideally performed by healthcare professionals with specific training and experience in the assessment and management of concussion. Competence should be determined by training and experience, not dictated by specialty. ▸ While this statement is directed towards sports medicine physicians, it may also assist other physicians and healthcare professionals in the care of patients with sports concussion. Definition ▸ Concussion is defined as a traumatically induced transient disturbance of brain function and involves a complex pathophysiological process. Concussion is a subset of mild traumatic brain injury (MTBI) which is generally self-limited and at the less-severe end of the brain injury spectrum. Pathophysiology ▸ Animal and human studies support the concept of postconcussive vulnerability, showing that a second blow before the brain has recovered results in worsening metabolic changes within the cell. ▸ Experimental evidence suggests the concussed brain is less responsive to usual neural activation and when premature cognitive or physical activity occurs before complete recovery the brain may be vulnerable to prolonged dysfunction. Incidence ▸ It is estimated that as many as 3.8 million concussions occur in the USA per year during competitive sports and recreational activities; however, as many as 50% of the concussions may go unreported. ▸ Concussions occur in all sports with the highest incidence in football, hockey, rugby, soccer and basketball. Risk factors for sport-related concussion ▸ A history of concussion is associated with a higher risk of sustaining another concussion. ▸ A greater number, severity and duration of symptoms after a concussion are predictors of a prolonged recovery. ▸ In sports with similar playing rules, the reported incidence of concussion is higher in female athletes than in male athletes. ▸ Certain sports, positions and individual playing styles have a greater risk of concussion. ▸ Youth athletes may have a more prolonged recovery and are more susceptible to a concussion accompanied by a catastrophic injury. ▸ Preinjury mood disorders, learning disorders, attention-deficit disorders (ADD/ADHD) and migraine headaches complicate diagnosis and management of a concussion. Diagnosis of concussion ▸ Concussion remains a clinical diagnosis ideally made by a healthcare provider familiar with the athlete and knowledgeable in the recognition and evaluation of concussion. ▸ Graded symptom checklists provide an objective tool for assessing a variety of symptoms related to concussions, while also tracking the severity of those symptoms over serial evaluations. ▸ Standardised assessment tools provide a helpful structure for the evaluation of concussion, although limited validation of these assessment tools is available. ‘Sideline’ evaluation and management ▸ Any athlete suspected of having a concussion should be stopped from playing and assessed by a licenced healthcare provider trained in the evaluation and management of concussions. ▸ Recognition and initial assessment of a concussion should be guided by a symptoms checklist, cognitive evaluation (including orientation, past and immediate memory, new learning and concentration), balance tests and further neurological physical examination. ▸ While standardised sideline tests are a useful framework for examination, the sensitivity, specificity, validity and reliability of these tests among different age groups, cultural groups and settings is largely undefined. Their practical usefulness with or without an individual baseline test is also largely unknown. ▸ Balance disturbance is a specific indicator of a concussion, but not very sensitive. Balance testing on the sideline may be substantially different than baseline tests because of differences in shoe/cleat-type or surface, use of ankle tape or braces, or the presence of other lower extremity injury. ▸ Imaging is reserved for athletes where intracerebral bleeding is suspected. ▸ There is no same day RTP for an athlete diagnosed with a concussion. ▸ Athletes suspected or diagnosed with a concussion should be monitored for deteriorating physical or mental status. Neuropsychological testing ▸ Neuropsychological (NP) tests are an objective measure of brain–behaviour relationships and are more sensitive for subtle cognitive impairment than clinical exam. ▸ Most concussions can be managed appropriately without the use of NP testing. ▸ Computerised neuropsychological (CNP) testing should be interpreted by healthcare professionals trained and familiar with the type of test and the individual test limitations, including a knowledgeable assessment of the reliable change index, baseline variability and false-positive and false-negative rates. ▸ Paper and pencil NP tests can be more comprehensive, test different domains and assess for other conditions which may masquerade as or complicate assessment of concussion. ▸ NP testing should be used only as part of a comprehensive concussion management strategy and should not be used in isolation. ▸ The ideal timing, frequency and type of NP testing have not been determined. ▸ In some cases, properly administered and interpreted NP testing provides an added value to assess cognitive function and recovery in the management of sports concussions. ▸ It is unknown if use of NP testing in the management of sports concussion helps prevent recurrent concussion, catastrophic injury or long-term complications. ▸ Comprehensive NP evaluation is helpful in the post-concussion management of athletes with persistent symptoms or complicated courses. Return to class ▸ Students will require cognitive rest and may require academic accommodations such as reduced workload and extended time for tests while recovering from a concussion. Return to play ▸ Concussion symptoms should be resolved before returning to exercise. ▸ A RTP progression involves a gradual, step-wise increase in physical demands, sports-specific activities and the risk for contact. ▸ If symptoms occur with activity, the progression should be halted and restarted at the preceding symptom-free step. ▸ RTP after concussion should occur only with medical clearance from a licenced healthcare provider trained in the evaluation and management of concussions. Short-term risks of premature RTP ▸ The primary concern with early RTP is decreased reaction time leading to an increased risk of a repeat concussion or other injury and prolongation of symptoms. Long-term effects ▸ There is an increasing concern that head impact exposure and recurrent concussions contribute to long-term neurological sequelae. ▸ Some studies have suggested an association between prior concussions and chronic cognitive dysfunction. Large-scale epidemiological studies are needed to more clearly define risk factors and causation of any long-term neurological impairment. Disqualification from sport ▸ There are no evidence-based guidelines for disqualifying/retiring an athlete from a sport after a concussion. Each case should be carefully deliberated and an individualised approach to determining disqualification taken. Education ▸ Greater efforts are needed to educate involved parties, including athletes, parents, coaches, officials, school administrators and healthcare providers to improve concussion recognition, management and prevention. ▸ Physicians should be prepared to provide counselling regarding potential long-term consequences of a concussion and recurrent concussions. Prevention ▸ Primary prevention of some injuries may be possible with modification and enforcement of the rules and fair play. ▸ Helmets, both hard (football, lacrosse and hockey) and soft (soccer, rugby) are best suited to prevent impact injuries (fracture, bleeding, laceration, etc.) but have not been shown to reduce the incidence and severity of concussions. ▸ There is no current evidence that mouth guards can reduce the severity of or prevent concussions. ▸ Secondary prevention may be possible by appropriate RTP management. Legislation ▸ Legislative efforts provide a uniform standard for scholastic and non-scholastic sports organisations regarding concussion safety and management. Future directions ▸ Additional research is needed to validate current assessment tools, delineate the role of NP testing and improve identification of those at risk of prolonged post-concussive symptoms or other long-term complications. ▸ Evolving technologies for the diagnosis of concussion, such as newer neuroimaging techniques or biological markers, may provide new insights into the evaluation and management of sports concussion.",2012,"[{'authorId': '5322280', 'name': 'K. Harmon'}, {'authorId': '4512610', 'name': 'J. Drezner'}, {'authorId': '46392709', 'name': 'Matthew R. Gammons'}, {'authorId': '3978024', 'name': 'K. Guskiewicz'}, {'authorId': '32149296', 'name': 'M. Halstead'}, {'authorId': '2498504', 'name': 'S. Herring'}, {'authorId': '8298247', 'name': 'J. Kutcher'}, {'authorId': '32397537', 'name': 'Andrea Pana'}, {'authorId': '5412259', 'name': 'M. Putukian'}, {'authorId': '34700142', 'name': 'W. Roberts'}]","{'url': 'https://bjsm.bmj.com/content/bjsports/47/1/15.full.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1136/bjsports-2012-091941?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1136/bjsports-2012-091941, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose of the statement ▸ to provide an evidence-based, best practises summary to assist physicians with the evaluation and management of sports concussion. ▸ to establish the level of evidence, knowledge gaps and areas requiring additional research. importance of an amssm statement ▸ sports medicine physicians are frequently involved in the care of patients with sports concussion. ▸ sports medicine physicians are specifically trained to provide care along the continuum of sports concussion from the acute injury to return-to-play (rtp) decisions. ▸ the care of athletes with sports concussion is ideally performed by healthcare professionals with specific training and experience in the assessment and management of concussion. competence should be determined by training and experience, not dictated by specialty. ▸ while this statement is directed towards sports medicine physicians, it may also assist other physicians and healthcare professionals in the care of patients with sports concussion. definition ▸ concussion is defined as a traumatically induced transient disturbance of brain function and involves a complex pathophysiological process. concussion is a subset of mild traumatic brain injury (mtbi) which is generally self-limited and at the less-severe end of the brain injury spectrum. pathophysiology ▸ animal and human studies support the concept of postconcussive vulnerability, showing that a second blow before the brain has recovered results in worsening metabolic changes within the cell. ▸ experimental evidence suggests the concussed brain is less responsive to usual neural activation and when premature cognitive or physical activity occurs before complete recovery the brain may be vulnerable to prolonged dysfunction. incidence ▸ it is estimated that as many as 3.8 million concussions occur in the usa per year during competitive sports and recreational activities; however, as many as 50% of the concussions may go unreported. ▸ concussions occur in all sports with the highest incidence in football, hockey, rugby, soccer and basketball. risk factors for sport-related concussion ▸ a history of concussion is associated with a higher risk of sustaining another concussion. ▸ a greater number, severity and duration of symptoms after a concussion are predictors of a prolonged recovery. ▸ in sports with similar playing rules, the reported incidence of concussion is higher in female athletes than in male athletes. ▸ certain sports, positions and individual playing styles have a greater risk of concussion. ▸ youth athletes may have a more prolonged recovery and are more susceptible to a concussion accompanied by a catastrophic injury. ▸ preinjury mood disorders, learning disorders, attention-deficit disorders (add/adhd) and migraine headaches complicate diagnosis and management of a concussion. diagnosis of concussion ▸ concussion remains a clinical diagnosis ideally made by a healthcare provider familiar with the athlete and knowledgeable in the recognition and evaluation of concussion. ▸ graded symptom checklists provide an objective tool for assessing a variety of symptoms related to concussions, while also tracking the severity of those symptoms over serial evaluations. ▸ standardised assessment tools provide a helpful structure for the evaluation of concussion, although limited validation of these assessment tools is available. ‘sideline’ evaluation and management ▸ any athlete suspected of having a concussion should be stopped from playing and assessed by a licenced healthcare provider trained in the evaluation and management of concussions. ▸ recognition and initial assessment of a concussion should be guided by a symptoms checklist, cognitive evaluation (including orientation, past and immediate memory, new learning and concentration), balance tests and further neurological physical examination. ▸ while standardised sideline tests are a useful framework for examination, the sensitivity, specificity, validity and reliability of these tests among different age groups, cultural groups and settings is largely undefined. their practical usefulness with or without an individual baseline test is also largely unknown. ▸ balance disturbance is a specific indicator of a concussion, but not very sensitive. balance testing on the sideline may be substantially different than baseline tests because of differences in shoe/cleat-type or surface, use of ankle tape or braces, or the presence of other lower extremity injury. ▸ imaging is reserved for athletes where intracerebral bleeding is suspected. ▸ there is no same day rtp for an athlete diagnosed with a concussion. ▸ athletes suspected or diagnosed with a concussion should be monitored for deteriorating physical or mental status. neuropsychological testing ▸ neuropsychological (np) tests are an objective measure of brain–behaviour relationships and are more sensitive for subtle cognitive impairment than clinical exam. ▸ most concussions can be managed appropriately without the use of np testing. ▸ computerised neuropsychological (cnp) testing should be interpreted by healthcare professionals trained and familiar with the type of test and the individual test limitations, including a knowledgeable assessment of the reliable change index, baseline variability and false-positive and false-negative rates. ▸ paper and pencil np tests can be more comprehensive, test different domains and assess for other conditions which may masquerade as or complicate assessment of concussion. ▸ np testing should be used only as part of a comprehensive concussion management strategy and should not be used in isolation. ▸ the ideal timing, frequency and type of np testing have not been determined. ▸ in some cases, properly administered and interpreted np testing provides an added value to assess cognitive function and recovery in the management of sports concussions. ▸ it is unknown if use of np testing in the management of sports concussion helps prevent recurrent concussion, catastrophic injury or long-term complications. ▸ comprehensive np evaluation is helpful in the post-concussion management of athletes with persistent symptoms or complicated courses. return to class ▸ students will require cognitive rest and may require academic accommodations such as reduced workload and extended time for tests while recovering from a concussion. return to play ▸ concussion symptoms should be resolved before returning to exercise. ▸ a rtp progression involves a gradual, step-wise increase in physical demands, sports-specific activities and the risk for contact. ▸ if symptoms occur with activity, the progression should be halted and restarted at the preceding symptom-free step. ▸ rtp after concussion should occur only with medical clearance from a licenced healthcare provider trained in the evaluation and management of concussions. short-term risks of premature rtp ▸ the primary concern with early rtp is decreased reaction time leading to an increased risk of a repeat concussion or other injury and prolongation of symptoms. long-term effects ▸ there is an increasing concern that head impact exposure and recurrent concussions contribute to long-term neurological sequelae. ▸ some studies have suggested an association between prior concussions and chronic cognitive dysfunction. large-scale epidemiological studies are needed to more clearly define risk factors and causation of any long-term neurological impairment. disqualification from sport ▸ there are no evidence-based guidelines for disqualifying/retiring an athlete from a sport after a concussion. each case should be carefully deliberated and an individualised approach to determining disqualification taken. education ▸ greater efforts are needed to educate involved parties, including athletes, parents, coaches, officials, school administrators and healthcare providers to improve concussion recognition, management and prevention. ▸ physicians should be prepared to provide counselling regarding potential long-term consequences of a concussion and recurrent concussions. prevention ▸ primary prevention of some injuries may be possible with modification and enforcement of the rules and fair play. ▸ helmets, both hard (football, lacrosse and hockey) and soft (soccer, rugby) are best suited to prevent impact injuries (fracture, bleeding, laceration, etc.) but have not been shown to reduce the incidence and severity of concussions. ▸ there is no current evidence that mouth guards can reduce the severity of or prevent concussions. ▸ secondary prevention may be possible by appropriate rtp management. legislation ▸ legislative efforts provide a uniform standard for scholastic and non-scholastic sports organisations regarding concussion safety and management. future directions ▸ additional research is needed to validate current assessment tools, delineate the role of np testing and improve identification of those at risk of prolonged post-concussive symptoms or other long-term complications. ▸ evolving technologies for the diagnosis of concussion, such as newer neuroimaging techniques or biological markers, may provide new insights into the evaluation and management of sports concussion.",https://bjsm.bmj.com/content/bjsports/47/1/15.full.pdf
b3b24003a35dd8bd7939a3d1aa9f0b46d4b8b3fb,"An Integrated, Multifactorial Approach to Periodization for Optimal Performance in Individual and Team Sports.","Sports periodization has traditionally focused on the exercise aspect of athletic preparation, while neglecting the integration of other elements that can impact an athlete's readiness for peak competition performances. Integrated periodization allows the coordinated inclusion of multiple training components best suited for a given training phase into an athlete's program. The aim of this article is to review the available evidence underpinning integrated periodization, focusing on exercise training, recovery, nutrition, psychological skills, and skill acquisition as key factors by which athletic preparation can be periodized. The periodization of heat and altitude adaptation, body composition, and physical therapy is also considered. Despite recent criticism, various methods of exercise training periodization can contribute to performance enhancement in a variety of elite individual and team sports, such as soccer. In the latter, both physical and strategic periodization are useful tools for managing the heavy travel schedule, fatigue, and injuries that occur throughout a competitive season. Recovery interventions should be periodized (ie, withheld or emphasized) to influence acute and chronic training adaptation and performance. Nutrient intake and timing in relation to exercise and as part of the periodization of an athlete's training and competition calendar can also promote physiological adaptations and performance capacity. Psychological skills are a central component of athletic performance, and their periodization should cater to each athlete's individual needs and the needs of the team. Skill acquisition can also be integrated into an athlete's periodized training program to make a significant contribution to competition performance.",2018,"[{'authorId': '3731547', 'name': 'I. Mujika'}, {'authorId': '6806337', 'name': 'S. Halson'}, {'authorId': '3212386', 'name': 'L. Burke'}, {'authorId': '40516705', 'name': 'G. Balagué'}, {'authorId': '145789475', 'name': 'D. Farrow'}]","{'url': 'https://journals.humankinetics.com/doi/pdf/10.1123/ijspp.2018-0093', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1123/ijspp.2018-0093?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1123/ijspp.2018-0093, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","sports periodization has traditionally focused on the exercise aspect of athletic preparation, while neglecting the integration of other elements that can impact an athlete's readiness for peak competition performances. integrated periodization allows the coordinated inclusion of multiple training components best suited for a given training phase into an athlete's program. the aim of this article is to review the available evidence underpinning integrated periodization, focusing on exercise training, recovery, nutrition, psychological skills, and skill acquisition as key factors by which athletic preparation can be periodized. the periodization of heat and altitude adaptation, body composition, and physical therapy is also considered. despite recent criticism, various methods of exercise training periodization can contribute to performance enhancement in a variety of elite individual and team sports, such as soccer. in the latter, both physical and strategic periodization are useful tools for managing the heavy travel schedule, fatigue, and injuries that occur throughout a competitive season. recovery interventions should be periodized (ie, withheld or emphasized) to influence acute and chronic training adaptation and performance. nutrient intake and timing in relation to exercise and as part of the periodization of an athlete's training and competition calendar can also promote physiological adaptations and performance capacity. psychological skills are a central component of athletic performance, and their periodization should cater to each athlete's individual needs and the needs of the team. skill acquisition can also be integrated into an athlete's periodized training program to make a significant contribution to competition performance.",https://journals.humankinetics.com/doi/pdf/10.1123/ijspp.2018-0093
d76db4d508d891250fa0b7aacba83b9adbce92d2,Current Approaches to the Use of Artificial Intelligence for Injury Risk Assessment and Performance Prediction in Team Sports: a Systematic Review,"BackgroundThe application of artificial intelligence (AI) opens an interesting perspective for predicting injury risk and performance in team sports. A better understanding of the techniques of AI employed and of the sports that are using AI is clearly warranted. The purpose of this study is to identify which AI approaches have been applied to investigate sport performance and injury risk and to find out which AI techniques each sport has been using.MethodsSystematic searches through the PubMed, Scopus, and Web of Science online databases were conducted for articles reporting AI techniques or methods applied to team sports athletes.ResultsFifty-eight studies were included in the review with 11 AI techniques or methods being applied in 12 team sports. Pooled sample consisted of 6456 participants (97% male, 25 ± 8 years old; 3% female, 21 ± 10 years old) with 76% of them being professional athletes. The AI techniques or methods most frequently used were artificial neural networks, decision tree classifier, support vector machine, and Markov process with good performance metrics for all of them. Soccer, basketball, handball, and volleyball were the team sports with more applications of AI.ConclusionsThe results of this review suggest a prevalent application of AI methods in team sports based on the number of published studies. The current state of development in the area proposes a promising future with regard to AI use in team sports. Further evaluation research based on prospective methods is warranted to establish the predictive performance of specific AI techniques and methods.",2019,"[{'authorId': '80778762', 'name': 'J. G. Claudino'}, {'authorId': '151370328', 'name': 'Daniel de Oliveira Capanema'}, {'authorId': '2293080174', 'name': 'Thiago Vieira de Souza'}, {'authorId': '1400459072', 'name': 'J. Serrão'}, {'authorId': '151439059', 'name': 'A. C. Machado Pereira'}, {'authorId': '5980093', 'name': 'G. Nassis'}]","{'url': 'https://sportsmedicine-open.springeropen.com/track/pdf/10.1186/s40798-019-0202-3', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6609928, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","backgroundthe application of artificial intelligence (ai) opens an interesting perspective for predicting injury risk and performance in team sports. a better understanding of the techniques of ai employed and of the sports that are using ai is clearly warranted. the purpose of this study is to identify which ai approaches have been applied to investigate sport performance and injury risk and to find out which ai techniques each sport has been using.methodssystematic searches through the pubmed, scopus, and web of science online databases were conducted for articles reporting ai techniques or methods applied to team sports athletes.resultsfifty-eight studies were included in the review with 11 ai techniques or methods being applied in 12 team sports. pooled sample consisted of 6456 participants (97% male, 25 ± 8 years old; 3% female, 21 ± 10 years old) with 76% of them being professional athletes. the ai techniques or methods most frequently used were artificial neural networks, decision tree classifier, support vector machine, and markov process with good performance metrics for all of them. soccer, basketball, handball, and volleyball were the team sports with more applications of ai.conclusionsthe results of this review suggest a prevalent application of ai methods in team sports based on the number of published studies. the current state of development in the area proposes a promising future with regard to ai use in team sports. further evaluation research based on prospective methods is warranted to establish the predictive performance of specific ai techniques and methods.",https://sportsmedicine-open.springeropen.com/track/pdf/10.1186/s40798-019-0202-3
cd3ab07b3f074c5fd54b6186aca9695e49d06277,Consumer acceptance of sports wearable technology: the role of technology readiness,"PurposeThe purpose of this paper is to investigate consumers’ acceptance and use of sports and fitness wearable devices based on technology readiness (TR). In addition, the technology readiness and acceptance model (TRAM) will be used to investigate consumers’ intention to use sports wearable devices (for simplicity, sports wearable devices will be simplified to the term “sports wearables”).Design/methodology/approachConvenience sampling was conducted from Korean consumers (n=247). Data were analyzed by partial least squares–structural equation modeling using SmartPLS 3.0.FindingsThe results found that positive TR has a positive influence on perceived ease of use (PEOU) and perceived usefulness (PU), and negative TR had a negative influence on PEOU and PU. PEOU had a positive influence on perceived usefulness (PU). Both PEOU and PU led to intention to use sports wearable devices. Also, the multi-group analysis found a positive correlation between TR and PEOU for especially male users.Originality/valueThe findings of this study provide a better understanding of consumers’ behavioral intent to use sports wearables. Particularly, it also provides evidence that the TRAM is an appropriate framework for predicting users’ intention to use sports wearables. This study also stresses the important role of TR in consumers’ psychological processes leading up to the actual use of novel sports wearables.",2019,"[{'authorId': '48271137', 'name': 'Taejung Kim'}, {'authorId': '7338128', 'name': 'Weisheng Chiu'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/IJSMS-06-2017-0050?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/IJSMS-06-2017-0050, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purposethe purpose of this paper is to investigate consumers’ acceptance and use of sports and fitness wearable devices based on technology readiness (tr). in addition, the technology readiness and acceptance model (tram) will be used to investigate consumers’ intention to use sports wearable devices (for simplicity, sports wearable devices will be simplified to the term “sports wearables”).design/methodology/approachconvenience sampling was conducted from korean consumers (n=247). data were analyzed by partial least squares–structural equation modeling using smartpls 3.0.findingsthe results found that positive tr has a positive influence on perceived ease of use (peou) and perceived usefulness (pu), and negative tr had a negative influence on peou and pu. peou had a positive influence on perceived usefulness (pu). both peou and pu led to intention to use sports wearable devices. also, the multi-group analysis found a positive correlation between tr and peou for especially male users.originality/valuethe findings of this study provide a better understanding of consumers’ behavioral intent to use sports wearables. particularly, it also provides evidence that the tram is an appropriate framework for predicting users’ intention to use sports wearables. this study also stresses the important role of tr in consumers’ psychological processes leading up to the actual use of novel sports wearables.",
27ac0b0bb54b3cb210bd6933368dcbf87dc94adf,International Society of Sports Nutrition Position Stand: Probiotics,"AbstractPosition statement: The International Society of Sports Nutrition (ISSN) provides an objective and critical review of the mechanisms and use of probiotic supplementation to optimize the health, performance, and recovery of athletes. Based on the current available literature, the conclusions of the ISSN are as follows:
1)Probiotics are live microorganisms that, when administered in adequate amounts, confer a health benefit on the host (FAO/WHO).2)Probiotic administration has been linked to a multitude of health benefits, with gut and immune health being the most researched applications.3)Despite the existence of shared, core mechanisms for probiotic function, health benefits of probiotics are strain- and dose-dependent.4)Athletes have varying gut microbiota compositions that appear to reflect the activity level of the host in comparison to sedentary people, with the differences linked primarily to the volume of exercise and amount of protein consumption. Whether differences in gut microbiota composition affect probiotic efficacy is unknown.5)The main function of the gut is to digest food and absorb nutrients. In athletic populations, certain probiotics strains can increase absorption of key nutrients such as amino acids from protein, and affect the pharmacology and physiological properties of multiple food components.6)Immune depression in athletes worsens with excessive training load, psychological stress, disturbed sleep, and environmental extremes, all of which can contribute to an increased risk of respiratory tract infections. In certain situations, including exposure to crowds, foreign travel and poor hygiene at home, and training or competition venues, athletes’ exposure to pathogens may be elevated leading to increased rates of infections. Approximately 70% of the immune system is located in the gut and probiotic supplementation has been shown to promote a healthy immune response. In an athletic population, specific probiotic strains can reduce the number of episodes, severity and duration of upper respiratory tract infections.7)Intense, prolonged exercise, especially in the heat, has been shown to increase gut permeability which potentially can result in systemic toxemia. Specific probiotic strains can improve the integrity of the gut-barrier function in athletes.8)Administration of selected anti-inflammatory probiotic strains have been linked to improved recovery from muscle-damaging exercise.9)The minimal effective dose and method of administration (potency per serving, single vs. split dose, delivery form) of a specific probiotic strain depends on validation studies for this particular strain. Products that contain probiotics must include the genus, species, and strain of each live microorganism on its label as well as the total estimated quantity of each probiotic strain at the end of the product’s shelf life, as measured by colony forming units (CFU) or live cells.10)Preclinical and early human research has shown potential probiotic benefits relevant to an athletic population that include improved body composition and lean body mass, normalizing age-related declines in testosterone levels, reductions in cortisol levels indicating improved responses to a physical or mental stressor, reduction of exercise-induced lactate, and increased neurotransmitter synthesis, cognition and mood. However, these potential benefits require validation in more rigorous human studies and in an athletic population.",2019,"[{'authorId': '34905148', 'name': 'R. Jäger'}, {'authorId': '47839463', 'name': 'A. Mohr'}, {'authorId': '2828813', 'name': 'K. Carpenter'}, {'authorId': '5352831', 'name': 'C. Kerksick'}, {'authorId': '3962156', 'name': 'M. Purpura'}, {'authorId': '2058902163', 'name': 'Adel Moussa'}, {'authorId': '3298811', 'name': 'Jeremy R. Townsend'}, {'authorId': '3357926', 'name': 'M. Lamprecht'}, {'authorId': '145234245', 'name': 'N. West'}, {'authorId': '4944671', 'name': 'K. Black'}, {'authorId': '7739207', 'name': 'M. Gleeson'}, {'authorId': '1950793', 'name': 'D. Pyne'}, {'authorId': '9044038', 'name': 'Shawn D. Wells'}, {'authorId': '5611357', 'name': 'S. Arent'}, {'authorId': '15821634', 'name': 'A. Smith‐Ryan'}, {'authorId': '3762776', 'name': 'R. Kreider'}, {'authorId': '31889971', 'name': 'B. Campbell'}, {'authorId': '6665413', 'name': 'Laurent G. Bannock'}, {'authorId': '47035646', 'name': 'J. Scheiman'}, {'authorId': '1471209323', 'name': 'Craig J. Wissent'}, {'authorId': '145639304', 'name': 'M. Pane'}, {'authorId': '46541084', 'name': 'D. Kalman'}, {'authorId': '40406843', 'name': 'J. Pugh'}, {'authorId': '1471204200', 'name': 'Jessica A. ter Haar'}, {'authorId': '66053606', 'name': 'J. Antonio'}]","{'url': 'https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-019-0329-0', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6925426, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstractposition statement: the international society of sports nutrition (issn) provides an objective and critical review of the mechanisms and use of probiotic supplementation to optimize the health, performance, and recovery of athletes. based on the current available literature, the conclusions of the issn are as follows: 1)probiotics are live microorganisms that, when administered in adequate amounts, confer a health benefit on the host (fao/who).2)probiotic administration has been linked to a multitude of health benefits, with gut and immune health being the most researched applications.3)despite the existence of shared, core mechanisms for probiotic function, health benefits of probiotics are strain- and dose-dependent.4)athletes have varying gut microbiota compositions that appear to reflect the activity level of the host in comparison to sedentary people, with the differences linked primarily to the volume of exercise and amount of protein consumption. whether differences in gut microbiota composition affect probiotic efficacy is unknown.5)the main function of the gut is to digest food and absorb nutrients. in athletic populations, certain probiotics strains can increase absorption of key nutrients such as amino acids from protein, and affect the pharmacology and physiological properties of multiple food components.6)immune depression in athletes worsens with excessive training load, psychological stress, disturbed sleep, and environmental extremes, all of which can contribute to an increased risk of respiratory tract infections. in certain situations, including exposure to crowds, foreign travel and poor hygiene at home, and training or competition venues, athletes’ exposure to pathogens may be elevated leading to increased rates of infections. approximately 70% of the immune system is located in the gut and probiotic supplementation has been shown to promote a healthy immune response. in an athletic population, specific probiotic strains can reduce the number of episodes, severity and duration of upper respiratory tract infections.7)intense, prolonged exercise, especially in the heat, has been shown to increase gut permeability which potentially can result in systemic toxemia. specific probiotic strains can improve the integrity of the gut-barrier function in athletes.8)administration of selected anti-inflammatory probiotic strains have been linked to improved recovery from muscle-damaging exercise.9)the minimal effective dose and method of administration (potency per serving, single vs. split dose, delivery form) of a specific probiotic strain depends on validation studies for this particular strain. products that contain probiotics must include the genus, species, and strain of each live microorganism on its label as well as the total estimated quantity of each probiotic strain at the end of the product’s shelf life, as measured by colony forming units (cfu) or live cells.10)preclinical and early human research has shown potential probiotic benefits relevant to an athletic population that include improved body composition and lean body mass, normalizing age-related declines in testosterone levels, reductions in cortisol levels indicating improved responses to a physical or mental stressor, reduction of exercise-induced lactate, and increased neurotransmitter synthesis, cognition and mood. however, these potential benefits require validation in more rigorous human studies and in an athletic population.",https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-019-0329-0
122dcc5501d17092c1f60507763688f79f6b2cb7,Deceleration Training in Team Sports: Another Potential ‘Vaccine’ for Sports-Related Injury?,"High-intensity horizontal decelerations occur frequently in team sports and are typically performed to facilitate a reduction in momentum preceding a change of direction manoeuvre or following a sprinting action. The mechanical underpinnings of horizontal deceleration are unique compared to other high-intensity locomotive patterns (e.g., acceleration, maximal sprinting speed), and are characterised by a ground reaction force profile of high impact peaks and loading rates. The high mechanical loading conditions observed when performing rapid horizontal decelerations can lead to tissue damage and neuromuscular fatigue, which may diminish co-ordinative proficiency and an individual’s ability to skilfully dissipate braking loads. Furthermore, repetitive long-term deceleration loading cycles if not managed appropriately may propagate damage accumulation and offer an explanation for chronic aetiological consequences of the ‘mechanical fatigue failure’ phenomenon. Training strategies should look to enhance an athlete’s ability to skilfully dissipate braking loads, develop mechanically robust musculoskeletal structures, and ensure frequent high-intensity horizontal deceleration exposure in order to accustom individuals to the potentially damaging effects of intense decelerations that athletes will frequently perform in competition. Given the apparent importance of horizontal decelerations, in this Current Opinion article we provide considerations for sport science and medicine practitioners around the assessment, training and monitoring of horizontal deceleration. We feel these considerations could lead to new developments in injury-mitigation and physical development strategies in team sports.",2021,"[{'authorId': '89951803', 'name': 'Alistair J. McBurnie'}, {'authorId': '51066767', 'name': 'Damian J. Harper'}, {'authorId': '144447637', 'name': 'Paul A. Jones'}, {'authorId': '1401970744', 'name': 'Thomas Dos’Santos'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s40279-021-01583-x.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8761154, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","high-intensity horizontal decelerations occur frequently in team sports and are typically performed to facilitate a reduction in momentum preceding a change of direction manoeuvre or following a sprinting action. the mechanical underpinnings of horizontal deceleration are unique compared to other high-intensity locomotive patterns (e.g., acceleration, maximal sprinting speed), and are characterised by a ground reaction force profile of high impact peaks and loading rates. the high mechanical loading conditions observed when performing rapid horizontal decelerations can lead to tissue damage and neuromuscular fatigue, which may diminish co-ordinative proficiency and an individual’s ability to skilfully dissipate braking loads. furthermore, repetitive long-term deceleration loading cycles if not managed appropriately may propagate damage accumulation and offer an explanation for chronic aetiological consequences of the ‘mechanical fatigue failure’ phenomenon. training strategies should look to enhance an athlete’s ability to skilfully dissipate braking loads, develop mechanically robust musculoskeletal structures, and ensure frequent high-intensity horizontal deceleration exposure in order to accustom individuals to the potentially damaging effects of intense decelerations that athletes will frequently perform in competition. given the apparent importance of horizontal decelerations, in this current opinion article we provide considerations for sport science and medicine practitioners around the assessment, training and monitoring of horizontal deceleration. we feel these considerations could lead to new developments in injury-mitigation and physical development strategies in team sports.",https://link.springer.com/content/pdf/10.1007/s40279-021-01583-x.pdf
3fef421319fbf0e959d3b1aad4acce7b4191053e,Methodological Recommendations for Menstrual Cycle Research in Sports and Exercise.,"INTRODUCTION
The aim of this review is to provide methodological recommendations for menstrual cycle research in exercise science and sports medicine based on a review of recent literature. Research in this area is growing, but often reports conflicting results and it is proposed that some of this may be explained by methodological issues.


METHODS
This review examined the menstrual cycle verification methodologies used in recent literature on exercise performance over the menstrual cycle identified through a literature search of PubMed and SportDiscus from 2008 until 2018.


RESULTS
Potential changes over the menstrual cycle are likely related to hormone fluctuations, however, only 44% of the selected studies measured the actual concentrations of the female steroid hormones estrogen and progesterone. It was shown that the likely inclusion of participants with anovulatory or luteal phase deficient cycles in combination with small participant numbers has impacted results in recent menstrual cycle research and consequently our understanding of this area.


CONCLUSION
To improve the quality of future menstrual cycle research it is recommended that a combination of three methods is used to verify menstrual cycle phase: the calendar-based counting method combined with urinary luteinizing hormone surge testing and the measurement of serum estrogen and progesterone concentrations at the time of testing. A strict luteal phase verification limit of >16 nmol·L for progesterone should be set. It is also recommended that future research focusses on the inclusion of the late follicular estrogen peak. It is envisaged that these methodological recommendations will assist in clarifying some of the disagreement around the effects of the menstrual cycle on exercise performance and other aspects of exercise science and sports medicine.",2019,"[{'authorId': '9580611', 'name': 'X. J. de Jonge'}, {'authorId': '77509792', 'name': 'B. Thompson'}, {'authorId': '6754702', 'name': 'A. Han'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1249/MSS.0000000000002073?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1249/MSS.0000000000002073, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","introduction the aim of this review is to provide methodological recommendations for menstrual cycle research in exercise science and sports medicine based on a review of recent literature. research in this area is growing, but often reports conflicting results and it is proposed that some of this may be explained by methodological issues. methods this review examined the menstrual cycle verification methodologies used in recent literature on exercise performance over the menstrual cycle identified through a literature search of pubmed and sportdiscus from 2008 until 2018. results potential changes over the menstrual cycle are likely related to hormone fluctuations, however, only 44% of the selected studies measured the actual concentrations of the female steroid hormones estrogen and progesterone. it was shown that the likely inclusion of participants with anovulatory or luteal phase deficient cycles in combination with small participant numbers has impacted results in recent menstrual cycle research and consequently our understanding of this area. conclusion to improve the quality of future menstrual cycle research it is recommended that a combination of three methods is used to verify menstrual cycle phase: the calendar-based counting method combined with urinary luteinizing hormone surge testing and the measurement of serum estrogen and progesterone concentrations at the time of testing. a strict luteal phase verification limit of >16 nmol·l for progesterone should be set. it is also recommended that future research focusses on the inclusion of the late follicular estrogen peak. it is envisaged that these methodological recommendations will assist in clarifying some of the disagreement around the effects of the menstrual cycle on exercise performance and other aspects of exercise science and sports medicine.",
8789d6a496c65ea4eb72603b06d7f30b1f489dc4,"Mental health issues and psychological factors in athletes: detection, management, effect on performance and prevention: American Medical Society for Sports Medicine Position Statement—Executive Summary","The American Medical Society for Sports Medicine convened a panel of experts to provide an evidence-based, best practices document to assist sports medicine physicians and other members of the athletic care network with the detection, treatment and prevention of mental health issues in competitive athletes. This statement discusses how members of the sports medicine team, including team physicians, athletic trainers and mental health providers, work together in providing comprehensive psychological care to athletes. It specifically addresses psychological factors in athletes including personality issues and the psychological response to injury and illness. The statement also examines the athletic culture and environmental factors that commonly impact mental health, including sexuality and gender issues, hazing, bullying, sexual misconduct and transition from sport. Specific mental health disorders in athletes, such as eating disorders/disordered eating, depression and suicide, anxiety and stress, overtraining, sleep disorders and attention-deficit/hyperactivity disorder, are reviewed with a focus on detection, management, the effect on performance and prevention. This document uses the Strength of Recommendation Taxonomy to grade level of evidence.",2019,"[{'authorId': '13939238', 'name': 'Cindy Chang'}, {'authorId': '5412259', 'name': 'M. Putukian'}, {'authorId': '12597762', 'name': 'Giselle A Aerni'}, {'authorId': '20683328', 'name': 'A. Diamond'}, {'authorId': '48375881', 'name': 'Gene Hong'}, {'authorId': '113841349', 'name': 'Yvette M Ingram'}, {'authorId': '3847559', 'name': 'C. Reardon'}, {'authorId': '46591543', 'name': 'Andrew T. Wolanin'}]","{'url': 'https://bjsm.bmj.com/content/bjsports/54/4/216.full.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1136/bjsports-2019-101583?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1136/bjsports-2019-101583, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the american medical society for sports medicine convened a panel of experts to provide an evidence-based, best practices document to assist sports medicine physicians and other members of the athletic care network with the detection, treatment and prevention of mental health issues in competitive athletes. this statement discusses how members of the sports medicine team, including team physicians, athletic trainers and mental health providers, work together in providing comprehensive psychological care to athletes. it specifically addresses psychological factors in athletes including personality issues and the psychological response to injury and illness. the statement also examines the athletic culture and environmental factors that commonly impact mental health, including sexuality and gender issues, hazing, bullying, sexual misconduct and transition from sport. specific mental health disorders in athletes, such as eating disorders/disordered eating, depression and suicide, anxiety and stress, overtraining, sleep disorders and attention-deficit/hyperactivity disorder, are reviewed with a focus on detection, management, the effect on performance and prevention. this document uses the strength of recommendation taxonomy to grade level of evidence.",https://bjsm.bmj.com/content/bjsports/54/4/216.full.pdf
bd0a729cd14edf331c30249fc6d8d42cc00941b5,Epidemiology of Concussions in National Collegiate Athletic Association (NCAA) Sports: 2014/15-2018/19,"Background: Updated epidemiology studies examining sports-related concussions (SRCs) are critical in evaluating recent efforts aimed at reducing the incidence of SRCs in National Collegiate Athletic Association (NCAA) sports. Purpose: To describe the epidemiology of SRCs in 23 NCAA sports during the 2014/15-2018/19 academic years. Study Design: Descriptive epidemiology study. Methods: SRC and exposure data collected in the NCAA Injury Surveillance Program were analyzed. Injury counts, rates, and proportions were used to describe injury characteristics by sport, event type (practices, competitions), injury mechanism (player contact, surface contact, equipment/apparatus contact), and injury history (new, recurrent). Injury rate ratios (IRRs) were used to examine differential injury rates, and injury proportion ratios (IPRs) were used to examine differential distributions. Results: A total of 3497 SRCs from 8,474,400 athlete-exposures (AEs) were reported during the study period (4.13 per 10,000 AEs); the competition-related SRC rate was higher than was the practice-related SRC rate (IRR, 4.12; 95% CI, 3.86-4.41). The highest SRC rates were observed in men’s ice hockey (7.35 per 10,000 AEs) and women’s soccer (7.15 per 10,000 AEs); rates in women’s soccer and volleyball increased during 2015/16-2018/19. Player contact was the most prevalently reported mechanism in men’s sports (77.0%), whereas equipment/apparatus contact was the most prevalently reported mechanism in women’s sports (39.2%). Sex-related differences were observed in soccer, basketball, softball/baseball, and swimming and diving. Most SRCs reported in men’s sports (84.3%) and women’s sports (81.1%) were reported as new injuries. Conclusion: Given the increasing SRC rates observed in women’s soccer and volleyball during the latter years of the study, these results indicate the need to direct further attention toward trajectories of SRC incidence in these sports. The prevalence of equipment/apparatus contact SRCs in women’s sports also suggests that SRC mechanisms in women’s sports warrant further investigation. As most SRCs during the study period were reported as new injuries, the prevalence of recurrent SRCs in men’s and women’s ice hockey is also noteworthy.",2021,"[{'authorId': '16026536', 'name': 'A. Chandran'}, {'authorId': '35660608', 'name': 'A. Boltz'}, {'authorId': '48218154', 'name': 'Sarah N. Morris'}, {'authorId': '84164404', 'name': 'H. Robison'}, {'authorId': '150914069', 'name': 'Aliza K. Nedimyer'}, {'authorId': '2232975386', 'name': 'C. Collins'}, {'authorId': '1398874627', 'name': 'J. Register-Mihalik'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/03635465211060340?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/03635465211060340, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background: updated epidemiology studies examining sports-related concussions (srcs) are critical in evaluating recent efforts aimed at reducing the incidence of srcs in national collegiate athletic association (ncaa) sports. purpose: to describe the epidemiology of srcs in 23 ncaa sports during the 2014/15-2018/19 academic years. study design: descriptive epidemiology study. methods: src and exposure data collected in the ncaa injury surveillance program were analyzed. injury counts, rates, and proportions were used to describe injury characteristics by sport, event type (practices, competitions), injury mechanism (player contact, surface contact, equipment/apparatus contact), and injury history (new, recurrent). injury rate ratios (irrs) were used to examine differential injury rates, and injury proportion ratios (iprs) were used to examine differential distributions. results: a total of 3497 srcs from 8,474,400 athlete-exposures (aes) were reported during the study period (4.13 per 10,000 aes); the competition-related src rate was higher than was the practice-related src rate (irr, 4.12; 95% ci, 3.86-4.41). the highest src rates were observed in men’s ice hockey (7.35 per 10,000 aes) and women’s soccer (7.15 per 10,000 aes); rates in women’s soccer and volleyball increased during 2015/16-2018/19. player contact was the most prevalently reported mechanism in men’s sports (77.0%), whereas equipment/apparatus contact was the most prevalently reported mechanism in women’s sports (39.2%). sex-related differences were observed in soccer, basketball, softball/baseball, and swimming and diving. most srcs reported in men’s sports (84.3%) and women’s sports (81.1%) were reported as new injuries. conclusion: given the increasing src rates observed in women’s soccer and volleyball during the latter years of the study, these results indicate the need to direct further attention toward trajectories of src incidence in these sports. the prevalence of equipment/apparatus contact srcs in women’s sports also suggests that src mechanisms in women’s sports warrant further investigation. as most srcs during the study period were reported as new injuries, the prevalence of recurrent srcs in men’s and women’s ice hockey is also noteworthy.",
60c07615e95bef5a28db39fdb0122dbb4c70f9b0,Sports Medicine and Artificial Intelligence: A Primer,"Artificial intelligence (AI) represents the fourth industrial revolution and the next frontier in medicine poised to transform the field of orthopaedics and sports medicine, though widespread understanding of the fundamental principles and adoption of applications remain nascent. Recent research efforts into implementation of AI in the field of orthopaedic surgery and sports medicine have demonstrated great promise in predicting athlete injury risk, interpreting advanced imaging, evaluating patient-reported outcomes, reporting value-based metrics, and augmenting the patient experience. Not unlike the recent emphasis thrust upon physicians to understand the business of medicine, the future practice of sports medicine specialists will require a fundamental working knowledge of the strengths, limitations, and applications of AI-based tools. With appreciation, caution, and experience applying AI to sports medicine, the potential to automate tasks and improve data-driven insights may be realized to fundamentally improve patient care. In this Current Concepts review, we discuss the definitions, strengths, limitations, and applications of AI from the current literature as it relates to orthopaedic sports medicine.",2021,"[{'authorId': '2570281', 'name': 'P. Ramkumar'}, {'authorId': '150044827', 'name': 'Bryan C. Luu'}, {'authorId': '11590373', 'name': 'Heather S. Haeberle'}, {'authorId': '48121327', 'name': 'J. Karnuta'}, {'authorId': '5969055', 'name': 'Benedict U. Nwachukwu'}, {'authorId': '2110328413', 'name': 'Riley J. Williams'}]","{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/03635465211008648', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/03635465211008648?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/03635465211008648, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","artificial intelligence (ai) represents the fourth industrial revolution and the next frontier in medicine poised to transform the field of orthopaedics and sports medicine, though widespread understanding of the fundamental principles and adoption of applications remain nascent. recent research efforts into implementation of ai in the field of orthopaedic surgery and sports medicine have demonstrated great promise in predicting athlete injury risk, interpreting advanced imaging, evaluating patient-reported outcomes, reporting value-based metrics, and augmenting the patient experience. not unlike the recent emphasis thrust upon physicians to understand the business of medicine, the future practice of sports medicine specialists will require a fundamental working knowledge of the strengths, limitations, and applications of ai-based tools. with appreciation, caution, and experience applying ai to sports medicine, the potential to automate tasks and improve data-driven insights may be realized to fundamentally improve patient care. in this current concepts review, we discuss the definitions, strengths, limitations, and applications of ai from the current literature as it relates to orthopaedic sports medicine.",https://journals.sagepub.com/doi/pdf/10.1177/03635465211008648
4fbc2ea87a6e00a05e7c0526e11e58b4eddb4dc3,"Organized Sports for Children, Preadolescents, and Adolescents","Interest and participation in organized sports for children, preadolescents, and adolescents continue to grow. Because of increased participation, and younger entry age, in organized sports, appropriate practice, game schedules, and content become more important, taking into account athlete developmental stage and skills. Parental support for organized sports in general, with focus on development and fun instead of winning, has emerged as a key factor in the athlete’s enjoyment of sports. Schools and community sports organizations who support multiple levels of sport (eg, recreational, competitive, elite) can include more youth who want to play sports and combat sport dropout. This report reviews the benefits and risks of organized sports as well as the roles of schools, community organizations, parents, and coaches in organized sports. It is designed to complement the American Academy of Pediatrics clinical reports “Physical Activity Assessment and Counseling in Pediatric Clinical Settings” and “Sports Specialization and Intensive Training in Young Athletes” by reviewing relevant literature on healthy organized sports for youth and providing guidance on organized sport readiness and entry. The report also provides guidance for pediatricians on counseling parents and advocating for healthy organized sports participation.",2019,"[{'authorId': '49124645', 'name': 'K. Logan'}, {'authorId': '12537884', 'name': 'Steven Cuff'}]","{'url': 'https://pediatrics.aappublications.org/content/pediatrics/143/6/e20190997.full.pdf', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1542/peds.2019-0997?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1542/peds.2019-0997, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","interest and participation in organized sports for children, preadolescents, and adolescents continue to grow. because of increased participation, and younger entry age, in organized sports, appropriate practice, game schedules, and content become more important, taking into account athlete developmental stage and skills. parental support for organized sports in general, with focus on development and fun instead of winning, has emerged as a key factor in the athlete’s enjoyment of sports. schools and community sports organizations who support multiple levels of sport (eg, recreational, competitive, elite) can include more youth who want to play sports and combat sport dropout. this report reviews the benefits and risks of organized sports as well as the roles of schools, community organizations, parents, and coaches in organized sports. it is designed to complement the american academy of pediatrics clinical reports “physical activity assessment and counseling in pediatric clinical settings” and “sports specialization and intensive training in young athletes” by reviewing relevant literature on healthy organized sports for youth and providing guidance on organized sport readiness and entry. the report also provides guidance for pediatricians on counseling parents and advocating for healthy organized sports participation.",https://pediatrics.aappublications.org/content/pediatrics/143/6/e20190997.full.pdf
c7c46da1296e9df613e88e68903ba580184c2fde,"The Influence of Sports Participation on Body Image, Self-Efficacy, and Self-Esteem in College Students","Objectives This study aimed to explore the relationship between body image, self-efficacy, self-esteem, and sports participation by gender, grade, and specialty and then to provide a reference for promoting participation in sports and physical activities in college students. Methods Using stratified random sampling, undergraduate students in western China were selected as participants. The data obtained in this study were processed by SPSS 19.0 and AMOS 21.0 statistical software. Results Body image was significantly positively correlated with self-efficacy, self-esteem, and sports participation. Self-efficacy was significantly positively correlated with self-esteem and sports participation. Self-esteem was significantly positively correlated with sports participation. Body image had a direct effect on sports participation, with an effect value of 0.124. Furthermore, the mediating effects of self-efficacy (0.079) and self-esteem (0.108) were significant in the relationship between body image and sports participation. Meanwhile, the chain mediating role of self-efficacy–self-esteem was also obvious (0.035). Conclusion Body image, self-efficacy, and self-esteem had significant influence on sports participation in college students. At the same time, the mediating effect of self-efficacy, self-esteem, and self-efficacy–self-esteem on body image and sports participation were established, and self-esteem was the key factor to sports participation.",2020,"[{'authorId': '2070558303', 'name': 'Yiyi Ouyang'}, {'authorId': '1739174095', 'name': 'Kun Wang'}, {'authorId': '35146145', 'name': 'Tingran Zhang'}, {'authorId': '2117698802', 'name': 'Liao Peng'}, {'authorId': '2072633601', 'name': 'Gang Song'}, {'authorId': '46789010', 'name': 'Jiong Luo'}]","{'url': 'https://fjfsdata01prod.blob.core.windows.net/articles/files/499087/pubmed-zip/.versions/1/.package-entries/fpsyg-10-03039/fpsyg-10-03039.pdf?sv=2018-03-28&sr=b&sig=XHeiCyxmOTg%2F9m1Fl3VWGbK81qijDNj7iacjmWKF4y4%3D&se=2021-02-17T11%3A56%3A11Z&sp=r&rscd=attachment%3B%20filename%2A%3DUTF-8%27%27fpsyg-10-03039.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7012809, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objectives this study aimed to explore the relationship between body image, self-efficacy, self-esteem, and sports participation by gender, grade, and specialty and then to provide a reference for promoting participation in sports and physical activities in college students. methods using stratified random sampling, undergraduate students in western china were selected as participants. the data obtained in this study were processed by spss 19.0 and amos 21.0 statistical software. results body image was significantly positively correlated with self-efficacy, self-esteem, and sports participation. self-efficacy was significantly positively correlated with self-esteem and sports participation. self-esteem was significantly positively correlated with sports participation. body image had a direct effect on sports participation, with an effect value of 0.124. furthermore, the mediating effects of self-efficacy (0.079) and self-esteem (0.108) were significant in the relationship between body image and sports participation. meanwhile, the chain mediating role of self-efficacy–self-esteem was also obvious (0.035). conclusion body image, self-efficacy, and self-esteem had significant influence on sports participation in college students. at the same time, the mediating effect of self-efficacy, self-esteem, and self-efficacy–self-esteem on body image and sports participation were established, and self-esteem was the key factor to sports participation.",https://fjfsdata01prod.blob.core.windows.net/articles/files/499087/pubmed-zip/.versions/1/.package-entries/fpsyg-10-03039/fpsyg-10-03039.pdf?sv=2018-03-28&sr=b&sig=XHeiCyxmOTg%2F9m1Fl3VWGbK81qijDNj7iacjmWKF4y4%3D&se=2021-02-17T11%3A56%3A11Z&sp=r&rscd=attachment%3B%20filename%2A%3DUTF-8%27%27fpsyg-10-03039.pdf
b6946f78445a16d42005be3e89162f961ef7cb74,Context Matters: Revisiting the First Step of the ‘Sequence of Prevention’ of Sports Injuries,"It is possible to prevent sports injuries. Unfortunately, the demonstrated efficacy and effectiveness of injury prevention approaches are not translated into lasting real-world effects. Contemporary views in sports medicine and injury prevention suggest that sports injuries are ‘complex’ phenomena. If the problem we aim to prevent is complex, then the first step in the ‘sequence of prevention’ that defines the ‘injury problem’ already needs to have considered this. The purpose of this paper is to revisit the first step of the ‘sequence of prevention’, and to explore new perspectives that acknowledge the complexity of the sports injury problem. First, this paper provides a retrospective of the ‘sequence of prevention’, acknowledging contemporary views on sports injuries and their prevention. Thereafter, from the perspective of the socioecological model, we demonstrate the need for taking into account the complex nature of sports injuries in the first step. Finally, we propose an alternative approach to explore and understand injury context through qualitative research methods. A better understanding of the injury problem in context will guide more context-sensitive studies, thus providing a new perspective for sports injury prevention research.",2018,"[{'authorId': '34637790', 'name': 'C. Bolling'}, {'authorId': '6780326', 'name': 'W. van Mechelen'}, {'authorId': '2242161650', 'name': 'H. Pasman'}, {'authorId': '145026133', 'name': 'E. Verhagen'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s40279-018-0953-x.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6132444, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","it is possible to prevent sports injuries. unfortunately, the demonstrated efficacy and effectiveness of injury prevention approaches are not translated into lasting real-world effects. contemporary views in sports medicine and injury prevention suggest that sports injuries are ‘complex’ phenomena. if the problem we aim to prevent is complex, then the first step in the ‘sequence of prevention’ that defines the ‘injury problem’ already needs to have considered this. the purpose of this paper is to revisit the first step of the ‘sequence of prevention’, and to explore new perspectives that acknowledge the complexity of the sports injury problem. first, this paper provides a retrospective of the ‘sequence of prevention’, acknowledging contemporary views on sports injuries and their prevention. thereafter, from the perspective of the socioecological model, we demonstrate the need for taking into account the complex nature of sports injuries in the first step. finally, we propose an alternative approach to explore and understand injury context through qualitative research methods. a better understanding of the injury problem in context will guide more context-sensitive studies, thus providing a new perspective for sports injury prevention research.",https://link.springer.com/content/pdf/10.1007/s40279-018-0953-x.pdf
66f606a7d11c2652659be7f1360737a59cd102d1,Sports Specialization and Intensive Training in Young Athletes,"Sports specialization is becoming the norm in youth sports for a variety of reasons. When sports specialization occurs too early, detrimental effects may occur, both physically and psychologically. If the timing is correct and sports specialization is performed under the correct conditions, the athlete may be successful in reaching specific goals. Young athletes who train intensively, whether specialized or not, can also be at risk of adverse effects on the mind and body. The purpose of this clinical report is to assist pediatricians in counseling their young athlete patients and their parents regarding sports specialization and intensive training. This report supports the American Academy of Pediatrics clinical report “Overuse Injuries, Overtraining, and Burnout in Child and Adolescent Athletes.”",2016,"[{'authorId': '145082643', 'name': 'J. Brenner'}]","{'url': 'https://pediatrics.aappublications.org/content/pediatrics/138/3/e20162148.full.pdf', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1542/peds.2016-2148?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1542/peds.2016-2148, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","sports specialization is becoming the norm in youth sports for a variety of reasons. when sports specialization occurs too early, detrimental effects may occur, both physically and psychologically. if the timing is correct and sports specialization is performed under the correct conditions, the athlete may be successful in reaching specific goals. young athletes who train intensively, whether specialized or not, can also be at risk of adverse effects on the mind and body. the purpose of this clinical report is to assist pediatricians in counseling their young athlete patients and their parents regarding sports specialization and intensive training. this report supports the american academy of pediatrics clinical report “overuse injuries, overtraining, and burnout in child and adolescent athletes.”",https://pediatrics.aappublications.org/content/pediatrics/138/3/e20162148.full.pdf
f6c694dd39e9ecf7f0c048001067d272731840a9,"Epidemiology of Recurrent Anterior Cruciate Ligament Injuries in National Collegiate Athletic Association Sports: The Injury Surveillance Program, 2004-2014","Background: An anterior cruciate ligament (ACL) rupture is a serious injury that can be career-ending in collegiate athletics. A rerupture after primary ACL reconstruction occurs in 1% to 11% of all athletes. Purpose: To describe the epidemiology of recurrent ACL ruptures in the 25 National Collegiate Athletic Association (NCAA) sports in the NCAA Injury Surveillance Program (ISP) and to identify and compare sport-specific risk factors for a recurrent ACL rupture. Study Design: Descriptive epidemiology study. Methods: Athletes who experienced a primary or recurrent ACL rupture between 2004 and 2014 were identified using data from the NCAA ISP. ACL ruptures occurred in 12 of 25 sports during the study period. We assessed the rates and patterns of primary and recurrent ACL ruptures and reported them as events per 10,000 athlete-exposures (AEs). Sex-comparable sports were compared using rate ratios. Rupture rates were compared using odds ratios, with P values <.05 indicating significance. Regular-season and postseason data were combined because of low counts of postseason events. Results: Of 350,416 AEs, there were 1105 ACL ruptures, 126 of which were recurrent. The highest rates of recurrent ACL ruptures (per 10,000 AEs) were among male football players (15), female gymnasts (8.2), and female soccer players (5.2). Of sports played by athletes of both sexes, women’s soccer had a significantly higher rate of recurrent ACL ruptures than men’s soccer (rate ratio, 3.8 [95% CI, 1.3-15]). Among all sports, men had a significantly higher rate of recurrent ACL ruptures (4.3) than women (3.0) (P = .04). Overall, the ratio of recurrent to primary ACL ruptures decreased over the 10-year study period. Both women and men had a decreasing trend of recurrent to primary ACL ruptures, although women had a steeper decrease. Conclusion: These data can help identify athletes who are most at risk of recurrent ACL ruptures after ACL reconstruction and who may benefit from injury prevention programs.",2018,"[{'authorId': '4761837', 'name': 'Itai Gans'}, {'authorId': '1395062375', 'name': 'J. Retzky'}, {'authorId': '66674772', 'name': 'L. Jones'}, {'authorId': '47675469', 'name': 'Miho J. Tanaka'}]","{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/2325967118777823', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6024527, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background: an anterior cruciate ligament (acl) rupture is a serious injury that can be career-ending in collegiate athletics. a rerupture after primary acl reconstruction occurs in 1% to 11% of all athletes. purpose: to describe the epidemiology of recurrent acl ruptures in the 25 national collegiate athletic association (ncaa) sports in the ncaa injury surveillance program (isp) and to identify and compare sport-specific risk factors for a recurrent acl rupture. study design: descriptive epidemiology study. methods: athletes who experienced a primary or recurrent acl rupture between 2004 and 2014 were identified using data from the ncaa isp. acl ruptures occurred in 12 of 25 sports during the study period. we assessed the rates and patterns of primary and recurrent acl ruptures and reported them as events per 10,000 athlete-exposures (aes). sex-comparable sports were compared using rate ratios. rupture rates were compared using odds ratios, with p values <.05 indicating significance. regular-season and postseason data were combined because of low counts of postseason events. results: of 350,416 aes, there were 1105 acl ruptures, 126 of which were recurrent. the highest rates of recurrent acl ruptures (per 10,000 aes) were among male football players (15), female gymnasts (8.2), and female soccer players (5.2). of sports played by athletes of both sexes, women’s soccer had a significantly higher rate of recurrent acl ruptures than men’s soccer (rate ratio, 3.8 [95% ci, 1.3-15]). among all sports, men had a significantly higher rate of recurrent acl ruptures (4.3) than women (3.0) (p = .04). overall, the ratio of recurrent to primary acl ruptures decreased over the 10-year study period. both women and men had a decreasing trend of recurrent to primary acl ruptures, although women had a steeper decrease. conclusion: these data can help identify athletes who are most at risk of recurrent acl ruptures after acl reconstruction and who may benefit from injury prevention programs.",https://journals.sagepub.com/doi/pdf/10.1177/2325967118777823
7cf77b6056ac2139625abb12a1ddecea00bc5b73,"Prevalence, knowledge and attitudes towards using sports supplements among young athletes","BackgroundThe aim of this international study was to investigate the prevalence of the use of sports supplements among young athletes, as well as their knowledge and attitudes towards sports supplementation.MethodsOrganized survey study testing the level of knowledge, attitudes, beliefs and practices concerning the use of sports supplements was administered to 348 athletes, 15–18 year olds from 4 countries competing in 18 sports at the international level.ResultsThe prevalence rate of the intake of sports supplements was 82.2%, with the protein supplements being predominant (54.5%). Coaches were identified as the primary source of information regarding supplementation (41.4%). The enhancement of athletic performance (35.4%) was the major motivation for the supplements intake. The majority of athletes (72.1%) were aware of associated health risks. The young athletes possess varying levels of knowledge regarding their own supplementation. The obtained data about the level of knowledge were statistically analyzed using the correspondence analysis. Less than 40% of athletes had the knowledge about the proper and intended use of protein, creatine, amino acids, beta alanine and glutamine, while they had greater understanding about vitamins and minerals, sports drinks and caffeine. The athletes in developed countries had greater access and utilization of professional resources such as dieticians. Young athletes are still unfamiliar with WADA regulations (55.5%), and the misuse of sports supplements represents an ethical dilemma for some.ConclusionThese findings indicate the necessity of a comprehensive education of all team members about sports supplements and careful supervision of the athletic development of young athletes.",2019,"[{'authorId': '7815004', 'name': 'P. Jovanov'}, {'authorId': '51118279', 'name': 'Višnja Đorđić'}, {'authorId': '4247523', 'name': 'B. Obradović'}, {'authorId': '3128817', 'name': 'O. Barak'}, {'authorId': '15882744', 'name': 'L. Pezo'}, {'authorId': '97566266', 'name': 'A. Marić'}, {'authorId': '77242442', 'name': 'M. Sakač'}]","{'url': 'https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-019-0294-7', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6611041, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","backgroundthe aim of this international study was to investigate the prevalence of the use of sports supplements among young athletes, as well as their knowledge and attitudes towards sports supplementation.methodsorganized survey study testing the level of knowledge, attitudes, beliefs and practices concerning the use of sports supplements was administered to 348 athletes, 15–18 year olds from 4 countries competing in 18 sports at the international level.resultsthe prevalence rate of the intake of sports supplements was 82.2%, with the protein supplements being predominant (54.5%). coaches were identified as the primary source of information regarding supplementation (41.4%). the enhancement of athletic performance (35.4%) was the major motivation for the supplements intake. the majority of athletes (72.1%) were aware of associated health risks. the young athletes possess varying levels of knowledge regarding their own supplementation. the obtained data about the level of knowledge were statistically analyzed using the correspondence analysis. less than 40% of athletes had the knowledge about the proper and intended use of protein, creatine, amino acids, beta alanine and glutamine, while they had greater understanding about vitamins and minerals, sports drinks and caffeine. the athletes in developed countries had greater access and utilization of professional resources such as dieticians. young athletes are still unfamiliar with wada regulations (55.5%), and the misuse of sports supplements represents an ethical dilemma for some.conclusionthese findings indicate the necessity of a comprehensive education of all team members about sports supplements and careful supervision of the athletic development of young athletes.",https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-019-0294-7
818fe506c31545b957db41c0bcefdebcf8feb590,Return to Play and Long-term Participation in Pivoting Sports After Anterior Cruciate Ligament Reconstruction,"Background: Rupture of the anterior cruciate ligament (ACL) is a common and feared injury among athletes because of its potential effect on further sports participation. Reported rates of return to pivoting sports after ACL reconstruction (ACLR) vary in the literature, and the long-term consequences of returning have rarely been studied. Purpose: To examine the rate and level of return to pivoting sports after ACLR, the duration of sports participation, and long-term consequences of returning to pivoting sports. Study Design: Cohort study; Level of evidence, 2. Methods: All primary ACLRs with a bone–patellar tendon–bone autograft between 1987 and 1994 (N = 234) in athletes participating in team handball, basketball, or soccer before injury were selected from a single-center quality database. A long-term evaluation (median, 25 years; range, 22-30 years) was performed using a questionnaire focusing on return to pivoting sports, the duration of sports activity after surgery, later contralateral ACL injuries, revision surgery, and knee replacement surgery. Participants were stratified into 2 groups depending on the time between injury and surgery (early, <24 months; late, ≥24 months). Results: A total of 93% of patients (n = 217) responded to the questionnaire. Although 83% of patients returned to pivoting sports after early ACLR, only 53% returned to preinjury level. Similar return-to-sport rates were observed in males and females (P > .05), but males had longer sports careers (median, 10 years; range, 1-23 years) than females (median, 4 years; range, 1-25 years; P < .001). The incidence of contralateral ACL injuries was 28% among athletes who returned to sports versus 4% among athletes who did not return (P = .017) after early ACLR. The pooled reinjury rate after return to preinjury level of sports was 41% (30%, contralateral injuries; 11%, revision surgery). The incidence of contralateral ACL injuries was 32% among females versus 23% among males (P > .05) and, for revision surgery, was 12% among females versus 7% among males (P > .05) after returning to sports. Having a late ACLR was associated with an increased risk of knee replacement surgery (9% vs 3%; P = .049) when compared with having an early ACLR. Conclusion: ACLR does not necessarily enable a return to preinjury sports participation. By returning to pivoting sports after ACLR, athletes are also facing a high risk of contralateral ACL injuries. Long-term evaluations in risk assessments after ACLR are important, as a significant number of subsequent ACL injuries occur later than the routine follow-up.",2019,"[{'authorId': '1417532593', 'name': 'Line Lindanger'}, {'authorId': '40309442', 'name': 'T. Strand'}, {'authorId': '11816460', 'name': 'A. Mølster'}, {'authorId': '38743125', 'name': 'Eirik Solheim'}, {'authorId': '15279097', 'name': 'E. Inderhaug'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/0363546519878159?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/0363546519878159, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background: rupture of the anterior cruciate ligament (acl) is a common and feared injury among athletes because of its potential effect on further sports participation. reported rates of return to pivoting sports after acl reconstruction (aclr) vary in the literature, and the long-term consequences of returning have rarely been studied. purpose: to examine the rate and level of return to pivoting sports after aclr, the duration of sports participation, and long-term consequences of returning to pivoting sports. study design: cohort study; level of evidence, 2. methods: all primary aclrs with a bone–patellar tendon–bone autograft between 1987 and 1994 (n = 234) in athletes participating in team handball, basketball, or soccer before injury were selected from a single-center quality database. a long-term evaluation (median, 25 years; range, 22-30 years) was performed using a questionnaire focusing on return to pivoting sports, the duration of sports activity after surgery, later contralateral acl injuries, revision surgery, and knee replacement surgery. participants were stratified into 2 groups depending on the time between injury and surgery (early, .05), but males had longer sports careers (median, 10 years; range, 1-23 years) than females (median, 4 years; range, 1-25 years; p .05) and, for revision surgery, was 12% among females versus 7% among males (p > .05) after returning to sports. having a late aclr was associated with an increased risk of knee replacement surgery (9% vs 3%; p = .049) when compared with having an early aclr. conclusion: aclr does not necessarily enable a return to preinjury sports participation. by returning to pivoting sports after aclr, athletes are also facing a high risk of contralateral acl injuries. long-term evaluations in risk assessments after aclr are important, as a significant number of subsequent acl injuries occur later than the routine follow-up.",
b7e06145821a4dce0b630e6dedcd659a17cf9a0f,State of the Art of Sports Data Visualization,"In this report, we organize and reflect on recent advances and challenges in the field of sports data visualization. The exponentially‐growing body of visualization research based on sports data is a prime indication of the importance and timeliness of this report. Sports data visualization research encompasses the breadth of visualization tasks and goals: exploring the design of new visualization techniques; adapting existing visualizations to a novel domain; and conducting design studies and evaluations in close collaboration with experts, including practitioners, enthusiasts, and journalists. Frequently this research has impact beyond sports in both academia and in industry because it is i) grounded in realistic, highly heterogeneous data, ii) applied to real‐world problems, and iii) designed in close collaboration with domain experts. In this report, we analyze current research contributions through the lens of three categories of sports data: box score data (data containing statistical summaries of a sport event such as a game), tracking data (data about in‐game actions and trajectories), and meta‐data (data about the sport and its participants but not necessarily a given game). We conclude this report with a high‐level discussion of sports visualization research informed by our analysis—identifying critical research gaps and valuable opportunities for the visualization community. More information is available at the STAR's website: https://sportsdataviz.github.io/.",2018,"[{'authorId': '35221881', 'name': 'Charles Perin'}, {'authorId': '1683275', 'name': 'Romain Vuillemot'}, {'authorId': '3245569', 'name': 'Charles D. Stolper'}, {'authorId': '1691661', 'name': 'J. Stasko'}, {'authorId': '2289024047', 'name': 'J. Wood'}, {'authorId': '144189259', 'name': 'M. Carpendale'}]","{'url': 'https://openaccess.city.ac.uk/id/eprint/19857/8/2018_eurovis_sportsstar.pdf', 'status': 'GREEN', 'license': 'public-domain', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/cgf.13447?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/cgf.13447, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this report, we organize and reflect on recent advances and challenges in the field of sports data visualization. the exponentially‐growing body of visualization research based on sports data is a prime indication of the importance and timeliness of this report. sports data visualization research encompasses the breadth of visualization tasks and goals: exploring the design of new visualization techniques; adapting existing visualizations to a novel domain; and conducting design studies and evaluations in close collaboration with experts, including practitioners, enthusiasts, and journalists. frequently this research has impact beyond sports in both academia and in industry because it is i) grounded in realistic, highly heterogeneous data, ii) applied to real‐world problems, and iii) designed in close collaboration with domain experts. in this report, we analyze current research contributions through the lens of three categories of sports data: box score data (data containing statistical summaries of a sport event such as a game), tracking data (data about in‐game actions and trajectories), and meta‐data (data about the sport and its participants but not necessarily a given game). we conclude this report with a high‐level discussion of sports visualization research informed by our analysis—identifying critical research gaps and valuable opportunities for the visualization community. more information is available at the star's website: https://sportsdataviz.github.io/.",https://openaccess.city.ac.uk/id/eprint/19857/8/2018_eurovis_sportsstar.pdf
ad66ac31fb4f861134ddea2b2dd6fe5550cd3947,"Fascial tissue research in sports medicine: from molecules to tissue adaptation, injury and diagnostics: consensus statement","The fascial system builds a three-dimensional continuum of soft, collagen-containing, loose and dense fibrous connective tissue that permeates the body and enables all body systems to operate in an integrated manner. Injuries to the fascial system cause a significant loss of performance in recreational exercise as well as high-performance sports, and could have a potential role in the development and perpetuation of musculoskeletal disorders, including lower back pain. Fascial tissues deserve more detailed attention in the field of sports medicine. A better understanding of their adaptation dynamics to mechanical loading as well as to biochemical conditions promises valuable improvements in terms of injury prevention, athletic performance and sports-related rehabilitation. This consensus statement reflects the state of knowledge regarding the role of fascial tissues in the discipline of sports medicine. It aims to (1) provide an overview of the contemporary state of knowledge regarding the fascial system from the microlevel (molecular and cellular responses) to the macrolevel (mechanical properties), (2) summarise the responses of the fascial system to altered loading (physical exercise), to injury and other physiological challenges including ageing, (3) outline the methods available to study the fascial system, and (4) highlight the contemporary view of interventions that target fascial tissue in sport and exercise medicine. Advancing this field will require a coordinated effort of researchers and clinicians combining mechanobiology, exercise physiology and improved assessment technologies.",2018,"[{'authorId': '5131046', 'name': 'M. Zügel'}, {'authorId': '5490644', 'name': 'C. Maganaris'}, {'authorId': '48974619', 'name': 'J. Wilke'}, {'authorId': '1398714564', 'name': 'K. Jurkat-Rott'}, {'authorId': '2083665', 'name': 'W. Klingler'}, {'authorId': '5050787', 'name': 'S. Wearing'}, {'authorId': '2170178', 'name': 'T. Findley'}, {'authorId': '50235472', 'name': 'M. Barbe'}, {'authorId': '3275714', 'name': 'J. Steinacker'}, {'authorId': '4009375', 'name': 'A. Vleeming'}, {'authorId': '144489133', 'name': 'W. Bloch'}, {'authorId': '4191153', 'name': 'R. Schleip'}, {'authorId': '145678181', 'name': 'P. Hodges'}]","{'url': 'https://bjsm.bmj.com/content/bjsports/52/23/1497.full.pdf', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6241620, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the fascial system builds a three-dimensional continuum of soft, collagen-containing, loose and dense fibrous connective tissue that permeates the body and enables all body systems to operate in an integrated manner. injuries to the fascial system cause a significant loss of performance in recreational exercise as well as high-performance sports, and could have a potential role in the development and perpetuation of musculoskeletal disorders, including lower back pain. fascial tissues deserve more detailed attention in the field of sports medicine. a better understanding of their adaptation dynamics to mechanical loading as well as to biochemical conditions promises valuable improvements in terms of injury prevention, athletic performance and sports-related rehabilitation. this consensus statement reflects the state of knowledge regarding the role of fascial tissues in the discipline of sports medicine. it aims to (1) provide an overview of the contemporary state of knowledge regarding the fascial system from the microlevel (molecular and cellular responses) to the macrolevel (mechanical properties), (2) summarise the responses of the fascial system to altered loading (physical exercise), to injury and other physiological challenges including ageing, (3) outline the methods available to study the fascial system, and (4) highlight the contemporary view of interventions that target fascial tissue in sport and exercise medicine. advancing this field will require a coordinated effort of researchers and clinicians combining mechanobiology, exercise physiology and improved assessment technologies.",https://bjsm.bmj.com/content/bjsports/52/23/1497.full.pdf
eb4636c0b59d19f4c5123b4cf978feb5ce2b241c,Impact of Adaptive Sports Participation on Quality of Life,"The health benefits of regular recreational physical activity are well known in reducing secondary health consequences of a sedentary lifestyle in the general population. However, individuals with physical disabilities participate less frequently in recreational activity compared with those without disabilities. Although evidence on the impact of recreational physical activity on quality of life in this population is in its infancy, regular recreational and sports activity participation has shown to have a positive association with improvements in quality of life, life satisfaction, community reintegration, mood, and employment in those with disabilities. Facilitators of participating in adaptive sports include a desire to improve social support, physical fitness, health, and fun. Unfortunately, those with disabilities face numerous barriers to participate in adaptive sports including accessibility, transportation, awareness, finances, and physical and cognitive impairments. Further studies are needed to investigate facilitators and barriers to participating in adaptive sports to capitalize on the physical and psychosocial benefits of regular recreational activity. The aim of this article is to review the available literature on the effects of adaptive sports participation on quality of life.",2019,"[{'authorId': '46708800', 'name': 'Robert Diaz'}, {'authorId': '47533144', 'name': 'Emily K. Miller'}, {'authorId': '46592912', 'name': 'Emily A Kraus'}, {'authorId': '5040075', 'name': 'M. Fredericson'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1097/JSA.0000000000000242?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1097/JSA.0000000000000242, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the health benefits of regular recreational physical activity are well known in reducing secondary health consequences of a sedentary lifestyle in the general population. however, individuals with physical disabilities participate less frequently in recreational activity compared with those without disabilities. although evidence on the impact of recreational physical activity on quality of life in this population is in its infancy, regular recreational and sports activity participation has shown to have a positive association with improvements in quality of life, life satisfaction, community reintegration, mood, and employment in those with disabilities. facilitators of participating in adaptive sports include a desire to improve social support, physical fitness, health, and fun. unfortunately, those with disabilities face numerous barriers to participate in adaptive sports including accessibility, transportation, awareness, finances, and physical and cognitive impairments. further studies are needed to investigate facilitators and barriers to participating in adaptive sports to capitalize on the physical and psychosocial benefits of regular recreational activity. the aim of this article is to review the available literature on the effects of adaptive sports participation on quality of life.",
73e94d35ab9ff44ca8528bd9a540a27c7305bc54,Herbal medicine for sports: a review,"The use of herbal medicinal products and supplements has increased during last decades. At present, some herbs are used to enhance muscle strength and body mass. Emergent evidence suggests that the health benefits from plants are attributed to their bioactive compounds such as Polyphenols, Terpenoids, and Alkaloids which have several physiological effects on the human body. At times, manufacturers launch numerous products with banned ingredient inside with inappropriate amounts or fake supplement inducing harmful side effect. Unfortunately up to date, there is no guarantee that herbal supplements are safe for anyone to use and it has not helped to clear the confusion surrounding the herbal use in sport field especially. Hence, the purpose of this review is to provide guidance on the efficacy and side effect of most used plants in sport. We have identified plants according to the following categories: Ginseng, alkaloids, and other purported herbal ergogenics such as Tribulus Terrestris, Cordyceps Sinensis. We found that most herbal supplement effects are likely due to activation of the central nervous system via stimulation of catecholamines. Ginseng was used as an endurance performance enhancer, while alkaloids supplementation resulted in improvements in sprint and cycling intense exercises. Despite it is prohibited, small amount of ephedrine was usually used in combination with caffeine to enhance muscle strength in trained individuals. Some other alkaloids such as green tea extracts have been used to improve body mass and composition in athletes. Other herb (i.e. Rhodiola, Astragalus) help relieve muscle and joint pain, but results about their effects on exercise performance are missing.",2018,"[{'authorId': '48932567', 'name': 'M. Sellami'}, {'authorId': '11782892', 'name': 'O. Slimeni'}, {'authorId': '4419097', 'name': 'A. Pokrywka'}, {'authorId': '10679450', 'name': 'Goran Kuvačić'}, {'authorId': '47433921', 'name': 'Lawrence D Hayes'}, {'authorId': '2241809', 'name': 'M. Milić'}, {'authorId': '4923405', 'name': 'J. Padulo'}]","{'url': 'https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-018-0218-y', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5856322, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the use of herbal medicinal products and supplements has increased during last decades. at present, some herbs are used to enhance muscle strength and body mass. emergent evidence suggests that the health benefits from plants are attributed to their bioactive compounds such as polyphenols, terpenoids, and alkaloids which have several physiological effects on the human body. at times, manufacturers launch numerous products with banned ingredient inside with inappropriate amounts or fake supplement inducing harmful side effect. unfortunately up to date, there is no guarantee that herbal supplements are safe for anyone to use and it has not helped to clear the confusion surrounding the herbal use in sport field especially. hence, the purpose of this review is to provide guidance on the efficacy and side effect of most used plants in sport. we have identified plants according to the following categories: ginseng, alkaloids, and other purported herbal ergogenics such as tribulus terrestris, cordyceps sinensis. we found that most herbal supplement effects are likely due to activation of the central nervous system via stimulation of catecholamines. ginseng was used as an endurance performance enhancer, while alkaloids supplementation resulted in improvements in sprint and cycling intense exercises. despite it is prohibited, small amount of ephedrine was usually used in combination with caffeine to enhance muscle strength in trained individuals. some other alkaloids such as green tea extracts have been used to improve body mass and composition in athletes. other herb (i.e. rhodiola, astragalus) help relieve muscle and joint pain, but results about their effects on exercise performance are missing.",https://jissn.biomedcentral.com/track/pdf/10.1186/s12970-018-0218-y
7e841138b6a63c3c1bc949cb7aa6d2e5f62801bf,"Letting the cat out of the bag: athletes, coaches and physiotherapists share their perspectives on injury prevention in elite sports","Objectives To explore how sports injury prevention takes place in elite sport practice and to describe the perspectives of athletes, coaches and physiotherapists regarding the most critical factors that help prevent injury in the elite sports context. Methods Qualitative study. Semistructured interviews with 19 international level athletes, coaches and physiotherapists, from different Olympic sports. Interviews were transcribed verbatim and analysed using comparative data analysis based on Grounded Theory. Results The participants perceived injury risk as an inherent part of elite sports, because athletes try to enhance performance by pushing their limits. Participants described injury prevention as a learning process that changed over time, based on their sports experience and the injuries that they had sustained along their career. Communication among the athletes, coaches and physiotherapists was described as a key component of the injury prevention process. Study participants emphasised the relevance of teamwork and shared responsibility. Performance was presented as the core of the athlete’s daily practice, indicating that injury prevention can be a means to that end but is not a goal in itself for this community. Conclusion Participants perceive injury prevention as part of elite sports and thus embrace the need for injury prevention. Injury prevention strategies in elite sports were described as a learning process, following the dynamic nature of training for maximal performance. Performance is the participants’ main goal.",2019,"[{'authorId': '34637790', 'name': 'C. Bolling'}, {'authorId': '7029651', 'name': 'Saulo Delfino Barboza'}, {'authorId': '6780326', 'name': 'W. van Mechelen'}, {'authorId': '144207349', 'name': 'H. Pasman'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1136/bjsports-2019-100773?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1136/bjsports-2019-100773, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objectives to explore how sports injury prevention takes place in elite sport practice and to describe the perspectives of athletes, coaches and physiotherapists regarding the most critical factors that help prevent injury in the elite sports context. methods qualitative study. semistructured interviews with 19 international level athletes, coaches and physiotherapists, from different olympic sports. interviews were transcribed verbatim and analysed using comparative data analysis based on grounded theory. results the participants perceived injury risk as an inherent part of elite sports, because athletes try to enhance performance by pushing their limits. participants described injury prevention as a learning process that changed over time, based on their sports experience and the injuries that they had sustained along their career. communication among the athletes, coaches and physiotherapists was described as a key component of the injury prevention process. study participants emphasised the relevance of teamwork and shared responsibility. performance was presented as the core of the athlete’s daily practice, indicating that injury prevention can be a means to that end but is not a goal in itself for this community. conclusion participants perceive injury prevention as part of elite sports and thus embrace the need for injury prevention. injury prevention strategies in elite sports were described as a learning process, following the dynamic nature of training for maximal performance. performance is the participants’ main goal.",
003f610b51ade369332e4ad6132e0210a022cc2c,Spatio-Temporal Analysis of Team Sports,"Team-based invasion sports such as football, basketball, and hockey are similar in the sense that the players are able to move freely around the playing area and that player and team performance cannot be fully analysed without considering the movements and interactions of all players as a group. State-of-the-art object tracking systems now produce spatio-temporal traces of player trajectories with high definition and high frequency, and this, in turn, has facilitated a variety of research efforts, across many disciplines, to extract insight from the trajectories. We survey recent research efforts that use spatio-temporal data from team sports as input and involve non-trivial computation. This article categorises the research efforts in a coherent framework and identifies a number of open research questions.",2016,"[{'authorId': '1696160', 'name': 'Joachim Gudmundsson'}, {'authorId': '46934079', 'name': 'M. Horton'}]","{'url': 'https://arxiv.org/pdf/1602.06994', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1602.06994, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","team-based invasion sports such as football, basketball, and hockey are similar in the sense that the players are able to move freely around the playing area and that player and team performance cannot be fully analysed without considering the movements and interactions of all players as a group. state-of-the-art object tracking systems now produce spatio-temporal traces of player trajectories with high definition and high frequency, and this, in turn, has facilitated a variety of research efforts, across many disciplines, to extract insight from the trajectories. we survey recent research efforts that use spatio-temporal data from team sports as input and involve non-trivial computation. this article categorises the research efforts in a coherent framework and identifies a number of open research questions.",https://arxiv.org/pdf/1602.06994
0e564482b81a2650f56dfec51660b74878230b9b,E-sports are Not Sports,"Abstract The conclusion of this paper will be that e-sports are not sports. I begin by offering a stipulation and a definition. I stipulate that what I have in mind, when thinking about the concept of sport, is ‘Olympic’ sport. And I define an Olympic Sport as an institutionalised, rule-governed contest of human physical skill. The justification for the stipulation lies partly in that it is uncontroversial. Whatever else people might think of as sport, no-one denies that Olympic Sport is sport. This seeks to ensure that those who might wish to dispute my conclusion might stay with the argument at least for as long as possible. Secondly, the justification for the stipulation lies partly in its normativity—I have chosen an Olympic conception of sport just because it seems to me to offer some kind of desirable version of what sport is and might become. Thirdly, I give examples which show how prominent promoters of e-sports agree with my stipulation, as evidenced by their strenuous attempts to comply with it in order to join the Olympic club. The justification for the definition lies in the conceptual analysis offered—an ‘exhibition-analysis’ which clarifies the concept of sport by offering ‘construals’ of the six first-level terms. The conclusion is that e-sports are not sports because they are inadequately ‘human’; they lack direct physicality; they fail to employ decisive whole-body control and whole-body skills, and cannot contribute to the development of the whole human; and because their patterns of creation, production, ownership and promotion place serious constraints on the emergence of the kind of stable and persisting institutions characteristic of sports governance. Competitive computer games do not qualify as sports, no matter what ‘resemblances’ may be claimed. Computer games are just that—games.",2018,"[{'authorId': '144001634', 'name': 'J. Parry'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/17511321.2018.1489419?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/17511321.2018.1489419, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the conclusion of this paper will be that e-sports are not sports. i begin by offering a stipulation and a definition. i stipulate that what i have in mind, when thinking about the concept of sport, is ‘olympic’ sport. and i define an olympic sport as an institutionalised, rule-governed contest of human physical skill. the justification for the stipulation lies partly in that it is uncontroversial. whatever else people might think of as sport, no-one denies that olympic sport is sport. this seeks to ensure that those who might wish to dispute my conclusion might stay with the argument at least for as long as possible. secondly, the justification for the stipulation lies partly in its normativity—i have chosen an olympic conception of sport just because it seems to me to offer some kind of desirable version of what sport is and might become. thirdly, i give examples which show how prominent promoters of e-sports agree with my stipulation, as evidenced by their strenuous attempts to comply with it in order to join the olympic club. the justification for the definition lies in the conceptual analysis offered—an ‘exhibition-analysis’ which clarifies the concept of sport by offering ‘construals’ of the six first-level terms. the conclusion is that e-sports are not sports because they are inadequately ‘human’; they lack direct physicality; they fail to employ decisive whole-body control and whole-body skills, and cannot contribute to the development of the whole human; and because their patterns of creation, production, ownership and promotion place serious constraints on the emergence of the kind of stable and persisting institutions characteristic of sports governance. competitive computer games do not qualify as sports, no matter what ‘resemblances’ may be claimed. computer games are just that—games.",
3c8a456509e6c0805354bd40a35e3f2dbf8069b1,"PyTorch: An Imperative Style, High-Performance Deep Learning Library","Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.",2019,"[{'authorId': '3407277', 'name': 'Adam Paszke'}, {'authorId': '39793298', 'name': 'Sam Gross'}, {'authorId': '1403239967', 'name': 'Francisco Massa'}, {'authorId': '1977806', 'name': 'Adam Lerer'}, {'authorId': '2065251344', 'name': 'James Bradbury'}, {'authorId': '114250963', 'name': 'Gregory Chanan'}, {'authorId': '2059271276', 'name': 'Trevor Killeen'}, {'authorId': '3370429', 'name': 'Zeming Lin'}, {'authorId': '3365851', 'name': 'N. Gimelshein'}, {'authorId': '3029482', 'name': 'L. Antiga'}, {'authorId': '3050846', 'name': 'Alban Desmaison'}, {'authorId': '1473151134', 'name': 'Andreas Köpf'}, {'authorId': '2052812305', 'name': 'E. Yang'}, {'authorId': '2253681376', 'name': 'Zachary DeVito'}, {'authorId': '10707709', 'name': 'Martin Raison'}, {'authorId': '41203992', 'name': 'Alykhan Tejani'}, {'authorId': '22236100', 'name': 'Sasank Chilamkurthy'}, {'authorId': '32163737', 'name': 'Benoit Steiner'}, {'authorId': '152599430', 'name': 'Lu Fang'}, {'authorId': '2113829116', 'name': 'Junjie Bai'}, {'authorId': '2127604', 'name': 'Soumith Chintala'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1912.01703, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep learning frameworks have often focused on either usability or speed, but not both. pytorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as gpus. in this paper, we detail the principles that drove the implementation of pytorch and how they are reflected in its architecture. we emphasize that every aspect of pytorch is a regular python program under the full control of its user. we also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. we demonstrate the efficiency of individual subsystems, as well as the overall speed of pytorch on several commonly used benchmarks.",
7aa38b85fa8cba64d6a4010543f6695dbf5f1386,Towards Deep Learning Models Resistant to Adversarial Attacks,"Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at this https URL and this https URL.",2017,"[{'authorId': '143826246', 'name': 'A. Madry'}, {'authorId': '17775913', 'name': 'Aleksandar Makelov'}, {'authorId': '152772922', 'name': 'Ludwig Schmidt'}, {'authorId': '2754804', 'name': 'Dimitris Tsipras'}, {'authorId': '2869958', 'name': 'Adrian Vladu'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1706.06083, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. in fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. to address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. this approach provides us with a broad and unifying view on much of the prior work on this topic. its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. in particular, they specify a concrete security guarantee that would protect against any adversary. these methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. they also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. we believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. code and pre-trained models are available at this https url and this https url.",
0084f3cb0a1754272151c5268a783f24bf5676a0,"Review of deep learning: concepts, CNN architectures, challenges, applications, future directions","In the last few years, the deep learning (DL) computing paradigm has been deemed the Gold Standard in the machine learning (ML) community. Moreover, it has gradually become the most widely used computational approach in the field of ML, thus achieving outstanding results on several complex cognitive tasks, matching or even beating those provided by human performance. One of the benefits of DL is the ability to learn massive amounts of data. The DL field has grown fast in the last few years and it has been extensively used to successfully address a wide range of traditional applications. More importantly, DL has outperformed well-known ML techniques in many domains, e.g., cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, among many others. Despite it has been contributed several works reviewing the State-of-the-Art on DL, all of them only tackled one aspect of the DL, which leads to an overall lack of knowledge about it. Therefore, in this contribution, we propose using a more holistic approach in order to provide a more suitable starting point from which to develop a full understanding of DL. Specifically, this review attempts to provide a more comprehensive survey of the most important aspects of DL and including those enhancements recently added to the field. In particular, this paper outlines the importance of DL, presents the types of DL techniques and networks. It then presents convolutional neural networks (CNNs) which the most utilized DL network type and describes the development of CNNs architectures together with their main features, e.g., starting with the AlexNet network and closing with the High-Resolution network (HR.Net). Finally, we further present the challenges and suggested solutions to help researchers understand the existing research gaps. It is followed by a list of the major DL applications. Computational tools including FPGA, GPU, and CPU are summarized along with a description of their influence on DL. The paper ends with the evolution matrix, benchmark datasets, and summary and conclusion.",2021,"[{'authorId': '2281247548', 'name': 'Laith Alzubaidi'}, {'authorId': '1754598', 'name': 'Jinglan Zhang'}, {'authorId': '2073994643', 'name': 'A. Humaidi'}, {'authorId': '1409267833', 'name': 'Ayad Al-dujaili'}, {'authorId': '145013346', 'name': 'Y. Duan'}, {'authorId': '1410016448', 'name': 'O. Al-Shamma'}, {'authorId': '2146732191', 'name': 'José I. Santamaría'}, {'authorId': '1412407676', 'name': 'M. Fadhel'}, {'authorId': '1412958882', 'name': 'Muthana Al-Amidie'}, {'authorId': '144121680', 'name': 'Laith Farhan'}]","{'url': 'https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-021-00444-8', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8010506, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the last few years, the deep learning (dl) computing paradigm has been deemed the gold standard in the machine learning (ml) community. moreover, it has gradually become the most widely used computational approach in the field of ml, thus achieving outstanding results on several complex cognitive tasks, matching or even beating those provided by human performance. one of the benefits of dl is the ability to learn massive amounts of data. the dl field has grown fast in the last few years and it has been extensively used to successfully address a wide range of traditional applications. more importantly, dl has outperformed well-known ml techniques in many domains, e.g., cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, among many others. despite it has been contributed several works reviewing the state-of-the-art on dl, all of them only tackled one aspect of the dl, which leads to an overall lack of knowledge about it. therefore, in this contribution, we propose using a more holistic approach in order to provide a more suitable starting point from which to develop a full understanding of dl. specifically, this review attempts to provide a more comprehensive survey of the most important aspects of dl and including those enhancements recently added to the field. in particular, this paper outlines the importance of dl, presents the types of dl techniques and networks. it then presents convolutional neural networks (cnns) which the most utilized dl network type and describes the development of cnns architectures together with their main features, e.g., starting with the alexnet network and closing with the high-resolution network (hr.net). finally, we further present the challenges and suggested solutions to help researchers understand the existing research gaps. it is followed by a list of the major dl applications. computational tools including fpga, gpu, and cpu are summarized along with a description of their influence on dl. the paper ends with the evolution matrix, benchmark datasets, and summary and conclusion.",https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-021-00444-8
ff7bcaa4556cb13fc7bf03e477172493546172cd,What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?,"There are two major types of uncertainty one can model. Aleatoric uncertainty captures noise inherent in the observations. On the other hand, epistemic uncertainty accounts for uncertainty in the model - uncertainty which can be explained away given enough data. Traditionally it has been difficult to model epistemic uncertainty in computer vision, but with new Bayesian deep learning tools this is now possible. We study the benefits of modeling epistemic vs. aleatoric uncertainty in Bayesian deep learning models for vision tasks. For this we present a Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty. We study models under the framework with per-pixel semantic segmentation and depth regression tasks. Further, our explicit uncertainty formulation leads to new loss functions for these tasks, which can be interpreted as learned attenuation. This makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.",2017,"[{'authorId': '47645184', 'name': 'Alex Kendall'}, {'authorId': '2681954', 'name': 'Y. Gal'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1703.04977, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","there are two major types of uncertainty one can model. aleatoric uncertainty captures noise inherent in the observations. on the other hand, epistemic uncertainty accounts for uncertainty in the model - uncertainty which can be explained away given enough data. traditionally it has been difficult to model epistemic uncertainty in computer vision, but with new bayesian deep learning tools this is now possible. we study the benefits of modeling epistemic vs. aleatoric uncertainty in bayesian deep learning models for vision tasks. for this we present a bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty. we study models under the framework with per-pixel semantic segmentation and depth regression tasks. further, our explicit uncertainty formulation leads to new loss functions for these tasks, which can be interpreted as learned attenuation. this makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.",
3813b88a4ec3c63919df47e9694b577f4691f7e5,A survey on Image Data Augmentation for Deep Learning,"Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.",2019,"[{'authorId': '150064574', 'name': 'Connor Shorten'}, {'authorId': '1725285', 'name': 'T. Khoshgoftaar'}]","{'url': 'https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-019-0197-0', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1186/s40537-019-0197-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/s40537-019-0197-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep convolutional neural networks have performed remarkably well on many computer vision tasks. however, these networks are heavily reliant on big data to avoid overfitting. overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. unfortunately, many application domains do not have access to big data, such as medical image analysis. this survey focuses on data augmentation, a data-space solution to the problem of limited data. data augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better deep learning models can be built using them. the image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. the application of augmentation methods based on gans are heavily covered in this survey. in addition to augmentation techniques, this paper will briefly discuss other characteristics of data augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. this survey will present existing methods for data augmentation, promising developments, and meta-level decisions for implementing data augmentation. readers will understand how data augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.",https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-019-0197-0
e9a986c8ff6c2f381d026fe014f6aaa865f34da7,Deep Learning with Differential Privacy,"Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.",2016,"[{'authorId': '2057642721', 'name': 'Martín Abadi'}, {'authorId': '1396184193', 'name': 'Andy Chu'}, {'authorId': '153440022', 'name': 'I. Goodfellow'}, {'authorId': '145057514', 'name': 'H. B. McMahan'}, {'authorId': '145591745', 'name': 'Ilya Mironov'}, {'authorId': '35210462', 'name': 'Kunal Talwar'}, {'authorId': '2152832173', 'name': 'Li Zhang'}]","{'url': 'https://arxiv.org/pdf/1607.00133', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1607.00133, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. the models should not expose private information in these datasets. addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.",https://arxiv.org/pdf/1607.00133
f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6,Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning,"Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.",2015,"[{'authorId': '2681954', 'name': 'Y. Gal'}, {'authorId': '1744700', 'name': 'Zoubin Ghahramani'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1506.02142, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep learning tools have gained tremendous attention in applied machine learning. however such tools for regression and classification do not capture model uncertainty. in comparison, bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. in this paper we develop a new theoretical framework casting dropout training in deep neural networks (nns) as approximate bayesian inference in deep gaussian processes. a direct result of this theory gives us tools to model uncertainty with dropout nns -- extracting information from existing models that has been thrown away so far. this mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. we perform an extensive study of the properties of dropout's uncertainty. various network architectures and non-linearities are assessed on tasks of regression and classification, using mnist as an example. we show a considerable improvement in predictive log-likelihood and rmse compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.",
5c45a5d05ac564adb67811eeb9d41d6460c70135,Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs.,"Importance
Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation.


Objective
To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs.


Design and Setting
A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data sets, both graded by at least 7 US board-certified ophthalmologists with high intragrader consistency.


Exposure
Deep learning-trained algorithm.


Main Outcomes and Measures
The sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy (RDR), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. The algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity.


Results
The EyePACS-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2% women; prevalence of RDR, 683/8878 fully gradable images [7.8%]); the Messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6% women; prevalence of RDR, 254/1745 fully gradable images [14.6%]). For detecting RDR, the algorithm had an area under the receiver operating curve of 0.991 (95% CI, 0.988-0.993) for EyePACS-1 and 0.990 (95% CI, 0.986-0.995) for Messidor-2. Using the first operating cut point with high specificity, for EyePACS-1, the sensitivity was 90.3% (95% CI, 87.5%-92.7%) and the specificity was 98.1% (95% CI, 97.8%-98.5%). For Messidor-2, the sensitivity was 87.0% (95% CI, 81.1%-91.0%) and the specificity was 98.5% (95% CI, 97.7%-99.1%). Using a second operating point with high sensitivity in the development set, for EyePACS-1 the sensitivity was 97.5% and specificity was 93.4% and for Messidor-2 the sensitivity was 96.1% and specificity was 93.9%.


Conclusions and Relevance
In this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. Further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment.",2016,"[{'authorId': '3236386', 'name': 'Varun Gulshan'}, {'authorId': '49506408', 'name': 'L. Peng'}, {'authorId': '2229081', 'name': 'Marc Coram'}, {'authorId': '2924473', 'name': 'Martin C. Stumpe'}, {'authorId': '97874426', 'name': 'Derek J. Wu'}, {'authorId': '50484974', 'name': 'Arunachalam Narayanaswamy'}, {'authorId': '1811430', 'name': 'Subhashini Venugopalan'}, {'authorId': '10777941', 'name': 'Kasumi Widner'}, {'authorId': '10688956', 'name': 'T. Madams'}, {'authorId': '50162175', 'name': 'Jorge A Cuadros'}, {'authorId': '3423678', 'name': 'R. Kim'}, {'authorId': '2035210', 'name': 'R. Raman'}, {'authorId': '2057376568', 'name': 'Philip Nelson'}, {'authorId': '5791678', 'name': 'J. Mega'}, {'authorId': '47191829', 'name': 'D. Webster'}]","{'url': 'https://jamanetwork.com/journals/jama/articlepdf/2588763/joi160132.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1001/jama.2016.17216?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1001/jama.2016.17216, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","importance deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. application of these methods to medical imaging requires further assessment and validation. objective to apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs. design and setting a specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 us licensed ophthalmologists and ophthalmology senior residents between may and december 2015. the resultant algorithm was validated in january and february 2016 using 2 separate data sets, both graded by at least 7 us board-certified ophthalmologists with high intragrader consistency. exposure deep learning-trained algorithm. main outcomes and measures the sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy (rdr), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. the algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity. results the eyepacs-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2% women; prevalence of rdr, 683/8878 fully gradable images [7.8%]); the messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6% women; prevalence of rdr, 254/1745 fully gradable images [14.6%]). for detecting rdr, the algorithm had an area under the receiver operating curve of 0.991 (95% ci, 0.988-0.993) for eyepacs-1 and 0.990 (95% ci, 0.986-0.995) for messidor-2. using the first operating cut point with high specificity, for eyepacs-1, the sensitivity was 90.3% (95% ci, 87.5%-92.7%) and the specificity was 98.1% (95% ci, 97.8%-98.5%). for messidor-2, the sensitivity was 87.0% (95% ci, 81.1%-91.0%) and the specificity was 98.5% (95% ci, 97.7%-99.1%). using a second operating point with high sensitivity in the development set, for eyepacs-1 the sensitivity was 97.5% and specificity was 93.4% and for messidor-2 the sensitivity was 96.1% and specificity was 93.9%. conclusions and relevance in this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment.",https://jamanetwork.com/journals/jama/articlepdf/2588763/joi160132.pdf
5b6ec746d309b165f9f9def873a2375b6fb40f3d,Xception: Deep Learning with Depthwise Separable Convolutions,"We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.",2016,"[{'authorId': '1565641737', 'name': 'François Chollet'}]","{'url': 'https://arxiv.org/pdf/1610.02357', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1610.02357, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we present an interpretation of inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). in this light, a depthwise separable convolution can be understood as an inception module with a maximally large number of towers. this observation leads us to propose a novel deep convolutional neural network architecture inspired by inception, where inception modules have been replaced with depthwise separable convolutions. we show that this architecture, dubbed xception, slightly outperforms inception v3 on the imagenet dataset (which inception v3 was designed for), and significantly outperforms inception v3 on a larger image classification dataset comprising 350 million images and 17,000 classes. since the xception architecture has the same number of parameters as inception v3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.",https://arxiv.org/pdf/1610.02357
6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4,Deep Learning Face Attributes in the Wild,"Predicting face attributes in the wild is challenging due to complex face variations. We propose a novel deep learning framework for attribute prediction in the wild. It cascades two CNNs, LNet and ANet, which are fine-tuned jointly with attribute tags, but pre-trained differently. LNet is pre-trained by massive general object categories for face localization, while ANet is pre-trained by massive face identities for attribute prediction. This framework not only outperforms the state-of-the-art with a large margin, but also reveals valuable facts on learning face representation. (1) It shows how the performances of face localization (LNet) and attribute prediction (ANet) can be improved by different pre-training strategies. (2) It reveals that although the filters of LNet are fine-tuned only with image-level attribute tags, their response maps over entire images have strong indication of face locations. This fact enables training LNet for face localization with only image-level annotations, but without face bounding boxes or landmarks, which are required by all attribute recognition works. (3) It also demonstrates that the high-level hidden neurons of ANet automatically discover semantic concepts after pre-training with massive face identities, and such concepts are significantly enriched after fine-tuning with attribute tags. Each attribute can be well explained with a sparse linear combination of these concepts.",2014,"[{'authorId': '2117940996', 'name': 'Ziwei Liu'}, {'authorId': '47571885', 'name': 'Ping Luo'}, {'authorId': '31843833', 'name': 'Xiaogang Wang'}, {'authorId': '50295995', 'name': 'Xiaoou Tang'}]","{'url': 'http://arxiv.org/pdf/1411.7766', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1411.7766, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","predicting face attributes in the wild is challenging due to complex face variations. we propose a novel deep learning framework for attribute prediction in the wild. it cascades two cnns, lnet and anet, which are fine-tuned jointly with attribute tags, but pre-trained differently. lnet is pre-trained by massive general object categories for face localization, while anet is pre-trained by massive face identities for attribute prediction. this framework not only outperforms the state-of-the-art with a large margin, but also reveals valuable facts on learning face representation. (1) it shows how the performances of face localization (lnet) and attribute prediction (anet) can be improved by different pre-training strategies. (2) it reveals that although the filters of lnet are fine-tuned only with image-level attribute tags, their response maps over entire images have strong indication of face locations. this fact enables training lnet for face localization with only image-level annotations, but without face bounding boxes or landmarks, which are required by all attribute recognition works. (3) it also demonstrates that the high-level hidden neurons of anet automatically discover semantic concepts after pre-training with massive face identities, and such concepts are significantly enriched after fine-tuning with attribute tags. each attribute can be well explained with a sparse linear combination of these concepts.",http://arxiv.org/pdf/1411.7766
d997beefc0922d97202789d2ac307c55c2c52fba,PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,"Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.",2016,"[{'authorId': '144329939', 'name': 'C. Qi'}, {'authorId': '144914140', 'name': 'Hao Su'}, {'authorId': '2216377', 'name': 'Kaichun Mo'}, {'authorId': '51352814', 'name': 'L. Guibas'}]","{'url': 'https://arxiv.org/pdf/1612.00593', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1612.00593, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","point cloud is an important type of geometric data structure. due to its irregular format, most researchers transform such data to regular 3d voxel grids or collections of images. this, however, renders data unnecessarily voluminous and causes issues. in this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. our network, named pointnet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. though simple, pointnet is highly efficient and effective. empirically, it shows strong performance on par or even better than state of the art. theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.",https://arxiv.org/pdf/1612.00593
54ddb00fa691728944fd8becea90a373d21597cf,Understanding deep learning requires rethinking generalization,"Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. 
Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. 
We interpret our experimental findings by comparison with traditional models.",2016,"[{'authorId': '151505981', 'name': 'Chiyuan Zhang'}, {'authorId': '1751569', 'name': 'Samy Bengio'}, {'authorId': '1775622', 'name': 'Moritz Hardt'}, {'authorId': '9229182', 'name': 'B. Recht'}, {'authorId': '1689108', 'name': 'O. Vinyals'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1611.03530, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. this phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. we corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. we interpret our experimental findings by comparison with traditional models.",
6001895c2fcf69528d01306e9d293d9d2a4cc67b,DeepLabCut: markerless pose estimation of user-defined body parts with deep learning,"Quantifying behavior is crucial for many applications in neuroscience. Videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. In motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, but markers are intrusive, and the number and location of the markers must be determined a priori. Here we present an efficient method for markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results with minimal training data. We demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors. Remarkably, even when only a small number of frames are labeled (~200), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy. Using a deep learning approach to track user-defined body parts during various behaviors across multiple species, the authors show that their toolbox, called DeepLabCut, can achieve human accuracy with only a few hundred frames of training data.",2018,"[{'authorId': '2068891', 'name': 'Alexander Mathis'}, {'authorId': '41020817', 'name': 'Pranav Mamidanna'}, {'authorId': '50283382', 'name': 'Kevin M. Cury'}, {'authorId': '39107109', 'name': 'Taiga Abe'}, {'authorId': '144440610', 'name': 'V. Murthy'}, {'authorId': '4058359', 'name': 'Mackenzie W. Mathis'}, {'authorId': '1731199', 'name': 'M. Bethge'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1804.03142, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","quantifying behavior is crucial for many applications in neuroscience. videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. in motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, but markers are intrusive, and the number and location of the markers must be determined a priori. here we present an efficient method for markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results with minimal training data. we demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors. remarkably, even when only a small number of frames are labeled (~200), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy. using a deep learning approach to track user-defined body parts during various behaviors across multiple species, the authors show that their toolbox, called deeplabcut, can achieve human accuracy with only a few hundred frames of training data.",
c7bbeaef75fa64c7e9cdf1b68bb487b9f8cd9a7d,Image Segmentation Using Deep Learning: A Survey,"Image segmentation is a key task in computer vision and image processing with important applications such as scene understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among others, and numerous segmentation algorithms are found in the literature. Against this backdrop, the broad success of deep learning (DL) has prompted the development of new image segmentation approaches leveraging DL models. We provide a comprehensive review of this recent literature, covering the spectrum of pioneering efforts in semantic and instance segmentation, including convolutional pixel-labeling networks, encoder-decoder architectures, multiscale and pyramid-based approaches, recurrent networks, visual attention models, and generative models in adversarial settings. We investigate the relationships, strengths, and challenges of these DL-based segmentation models, examine the widely used datasets, compare performances, and discuss promising research directions.",2020,"[{'authorId': '2164604', 'name': 'Shervin Minaee'}, {'authorId': '1692688', 'name': 'Yuri Boykov'}, {'authorId': '29905643', 'name': 'F. Porikli'}, {'authorId': '143767945', 'name': 'A. Plaza'}, {'authorId': '30567641', 'name': 'N. Kehtarnavaz'}, {'authorId': '1750924', 'name': 'Demetri Terzopoulos'}]","{'url': 'https://arxiv.org/pdf/2001.05566', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2001.05566, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","image segmentation is a key task in computer vision and image processing with important applications such as scene understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among others, and numerous segmentation algorithms are found in the literature. against this backdrop, the broad success of deep learning (dl) has prompted the development of new image segmentation approaches leveraging dl models. we provide a comprehensive review of this recent literature, covering the spectrum of pioneering efforts in semantic and instance segmentation, including convolutional pixel-labeling networks, encoder-decoder architectures, multiscale and pyramid-based approaches, recurrent networks, visual attention models, and generative models in adversarial settings. we investigate the relationships, strengths, and challenges of these dl-based segmentation models, examine the widely used datasets, compare performances, and discuss promising research directions.",https://arxiv.org/pdf/2001.05566
7998468d99ab07bb982294d1c9b53a3bf3934fa6,Object Detection With Deep Learning: A Review,"Due to object detection’s close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles that combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy, and optimization function. In this paper, we provide a review of deep learning-based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely, the convolutional neural network. Then, we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection, and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network-based learning systems.",2018,"[{'authorId': '33698309', 'name': 'Zhong-Qiu Zhao'}, {'authorId': None, 'name': 'Peng Zheng'}, {'authorId': '51132438', 'name': 'Shou-tao Xu'}, {'authorId': '1748808', 'name': 'Xindong Wu'}]","{'url': 'http://arxiv.org/pdf/1807.05511', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1807.05511, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","due to object detection’s close relationship with video analysis and image understanding, it has attracted much research attention in recent years. traditional object detection methods are built on handcrafted features and shallow trainable architectures. their performance easily stagnates by constructing complex ensembles that combine multiple low-level image features with high-level context from object detectors and scene classifiers. with the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. these models behave differently in network architecture, training strategy, and optimization function. in this paper, we provide a review of deep learning-based object detection frameworks. our review begins with a brief introduction on the history of deep learning and its representative tool, namely, the convolutional neural network. then, we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. as distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection, and pedestrian detection. experimental analyses are also provided to compare various methods and draw some meaningful conclusions. finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network-based learning systems.",http://arxiv.org/pdf/1807.05511
657fbf29ea0b4904a3e98d1556f9acf38dddae5f,Wide & Deep Learning for Recommender Systems,"Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide & Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide & Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow.",2016,"[{'authorId': '2061550', 'name': 'Heng-Tze Cheng'}, {'authorId': '40338695', 'name': 'L. Koc'}, {'authorId': '2066076307', 'name': 'Jeremiah Harmsen'}, {'authorId': '3296031', 'name': 'T. Shaked'}, {'authorId': '2073806959', 'name': 'Tushar Chandra'}, {'authorId': '3312922', 'name': 'H. Aradhye'}, {'authorId': '2064997996', 'name': 'Glen Anderson'}, {'authorId': '32131713', 'name': 'G. Corrado'}, {'authorId': '2055400243', 'name': 'Wei Chai'}, {'authorId': '37413761', 'name': 'M. Ispir'}, {'authorId': '1508890387', 'name': 'Rohan Anil'}, {'authorId': '50730596', 'name': 'Zakaria Haque'}, {'authorId': '2217278', 'name': 'Lichan Hong'}, {'authorId': '20048351', 'name': 'Vihan Jain'}, {'authorId': '2109059862', 'name': 'Xiaobing Liu'}, {'authorId': '2068799083', 'name': 'Hemal Shah'}]","{'url': 'http://dl.acm.org/ft_gateway.cfm?id=2988454&type=pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1606.07792, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. with less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. however, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. in this paper, we present wide & deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. we productionized and evaluated the system on google play, a commercial mobile app store with over one billion active users and over one million apps. online experiment results show that wide & deep significantly increased app acquisitions compared with wide-only and deep-only models. we have also open-sourced our implementation in tensorflow.",http://dl.acm.org/ft_gateway.cfm?id=2988454&type=pdf
3a58efcc4558727cc5c131c44923635da4524f33,"Relational inductive biases, deep learning, and graph networks","Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. 
The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between ""hand-engineering"" and ""end-to-end"" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.",2018,"[{'authorId': '2019153', 'name': 'P. Battaglia'}, {'authorId': '2158860', 'name': 'Jessica B. Hamrick'}, {'authorId': '2603033', 'name': 'V. Bapst'}, {'authorId': '1398105826', 'name': 'Alvaro Sanchez-Gonzalez'}, {'authorId': '3133079', 'name': 'V. Zambaldi'}, {'authorId': '145478807', 'name': 'Mateusz Malinowski'}, {'authorId': '2844530', 'name': 'Andrea Tacchetti'}, {'authorId': '143724694', 'name': 'David Raposo'}, {'authorId': '35030998', 'name': 'Adam Santoro'}, {'authorId': None, 'name': 'Ryan Faulkner'}, {'authorId': '1854385', 'name': 'Çaglar Gülçehre'}, {'authorId': '2107148568', 'name': 'H. F. Song'}, {'authorId': '5055381', 'name': 'A. J. Ballard'}, {'authorId': '2058362', 'name': 'J. Gilmer'}, {'authorId': '35188630', 'name': 'George E. Dahl'}, {'authorId': '40348417', 'name': 'Ashish Vaswani'}, {'authorId': '145254624', 'name': 'Kelsey R. Allen'}, {'authorId': '36942233', 'name': 'C. Nash'}, {'authorId': '2066201331', 'name': 'Victoria Langston'}, {'authorId': '1745899', 'name': 'Chris Dyer'}, {'authorId': '2801204', 'name': 'N. Heess'}, {'authorId': '1688276', 'name': 'D. Wierstra'}, {'authorId': '143967473', 'name': 'Pushmeet Kohli'}, {'authorId': '46378362', 'name': 'M. Botvinick'}, {'authorId': '1689108', 'name': 'O. Vinyals'}, {'authorId': '47002813', 'name': 'Yujia Li'}, {'authorId': '1996134', 'name': 'Razvan Pascanu'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1806.01261, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","artificial intelligence (ai) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. this has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. however, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. in particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern ai. the following is part position paper, part review, and part unification. we argue that combinatorial generalization must be a top priority for ai to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. just as biology uses nature and nurture cooperatively, we reject the false choice between ""hand-engineering"" and ""end-to-end"" learning, and instead advocate for an approach which benefits from their complementary strengths. we explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. we present a new building block for the ai toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. we discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. as a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.",
2f65c6ac06bfcd992d4dd75f0099a072f5c3cc8c,Understanding deep learning (still) requires rethinking generalization,"Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small gap between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models. We supplement this republication with a new section at the end summarizing recent progresses in the field since the original version of this paper.",2021,"[{'authorId': '151505981', 'name': 'Chiyuan Zhang'}, {'authorId': '1751569', 'name': 'Samy Bengio'}, {'authorId': '1775622', 'name': 'Moritz Hardt'}, {'authorId': '9229182', 'name': 'B. Recht'}, {'authorId': '1689108', 'name': 'O. Vinyals'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3446776', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3446776?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3446776, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","despite their massive size, successful deep artificial neural networks can exhibit a remarkably small gap between training and test performance. conventional wisdom attributes small generalization error either to properties of the model family or to the regularization techniques used during training. through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. this phenomenon is qualitatively unaffected by explicit regularization and occurs even if we replace the true images by completely unstructured random noise. we corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. we interpret our experimental findings by comparison with traditional models. we supplement this republication with a new section at the end summarizing recent progresses in the field since the original version of this paper.",https://dl.acm.org/doi/pdf/10.1145/3446776
819167ace2f0caae7745d2f25a803979be5fbfae,The Limitations of Deep Learning in Adversarial Settings,"Deep learning takes advantage of large datasets and computationally efficient training algorithms to outperform other approaches at various machine learning tasks. However, imperfections in the training phase of deep neural networks make them vulnerable to adversarial samples: inputs crafted by adversaries with the intent of causing deep neural networks to misclassify. In this work, we formalize the space of adversaries against deep neural networks (DNNs) and introduce a novel class of algorithms to craft adversarial samples based on a precise understanding of the mapping between inputs and outputs of DNNs. In an application to computer vision, we show that our algorithms can reliably produce samples correctly classified by human subjects but misclassified in specific targets by a DNN with a 97% adversarial success rate while only modifying on average 4.02% of the input features per sample. We then evaluate the vulnerability of different sample classes to adversarial perturbations by defining a hardness measure. Finally, we describe preliminary work outlining defenses against adversarial samples by defining a predictive measure of distance between a benign input and a target classification.",2015,"[{'authorId': '1967156', 'name': 'Nicolas Papernot'}, {'authorId': '144061974', 'name': 'P. Mcdaniel'}, {'authorId': '1680133', 'name': 'S. Jha'}, {'authorId': '2623167', 'name': 'Matt Fredrikson'}, {'authorId': '144643812', 'name': 'Z. B. Celik'}, {'authorId': '144231976', 'name': 'A. Swami'}]","{'url': 'http://arxiv.org/pdf/1511.07528', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1511.07528, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep learning takes advantage of large datasets and computationally efficient training algorithms to outperform other approaches at various machine learning tasks. however, imperfections in the training phase of deep neural networks make them vulnerable to adversarial samples: inputs crafted by adversaries with the intent of causing deep neural networks to misclassify. in this work, we formalize the space of adversaries against deep neural networks (dnns) and introduce a novel class of algorithms to craft adversarial samples based on a precise understanding of the mapping between inputs and outputs of dnns. in an application to computer vision, we show that our algorithms can reliably produce samples correctly classified by human subjects but misclassified in specific targets by a dnn with a 97% adversarial success rate while only modifying on average 4.02% of the input features per sample. we then evaluate the vulnerability of different sample classes to adversarial perturbations by defining a hardness measure. finally, we describe preliminary work outlining defenses against adversarial samples by defining a predictive measure of distance between a benign input and a target classification.",http://arxiv.org/pdf/1511.07528
8674494bd7a076286b905912d26d47f7501c4046,PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space,"Few prior works study deep learning on point sets. PointNet by Qi et al. is a pioneer in this direction. However, by design PointNet does not capture local structures induced by the metric space points live in, limiting its ability to recognize fine-grained patterns and generalizability to complex scenes. In this work, we introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set. By exploiting metric space distances, our network is able to learn local features with increasing contextual scales. With further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales. Experiments show that our network called PointNet++ is able to learn deep point set features efficiently and robustly. In particular, results significantly better than state-of-the-art have been obtained on challenging benchmarks of 3D point clouds.",2017,"[{'authorId': '144329939', 'name': 'C. Qi'}, {'authorId': '47782132', 'name': 'L. Yi'}, {'authorId': '144914140', 'name': 'Hao Su'}, {'authorId': '51352814', 'name': 'L. Guibas'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1706.02413, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","few prior works study deep learning on point sets. pointnet by qi et al. is a pioneer in this direction. however, by design pointnet does not capture local structures induced by the metric space points live in, limiting its ability to recognize fine-grained patterns and generalizability to complex scenes. in this work, we introduce a hierarchical neural network that applies pointnet recursively on a nested partitioning of the input point set. by exploiting metric space distances, our network is able to learn local features with increasing contextual scales. with further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales. experiments show that our network called pointnet++ is able to learn deep point set features efficiently and robustly. in particular, results significantly better than state-of-the-art have been obtained on challenging benchmarks of 3d point clouds.",
1c2efb418f79b5d29913e014a1dfd78865221c39,Deep learning for time series classification: a review,"Time Series Classification (TSC) is an important and challenging problem in data mining. With the increase of time series data availability, hundreds of TSC algorithms have been proposed. Among these methods, only a few have considered Deep Neural Networks (DNNs) to perform this task. This is surprising as deep learning has seen very successful applications in the last years. DNNs have indeed revolutionized the field of computer vision especially with the advent of novel deeper architectures such as Residual and Convolutional Neural Networks. Apart from images, sequential data such as text and audio can also be processed with DNNs to reach state-of-the-art performance for document classification and speech recognition. In this article, we study the current state-of-the-art performance of deep learning algorithms for TSC by presenting an empirical study of the most recent DNN architectures for TSC. We give an overview of the most successful deep learning applications in various time series domains under a unified taxonomy of DNNs for TSC. We also provide an open source deep learning framework to the TSC community where we implemented each of the compared approaches and evaluated them on a univariate TSC benchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By training 8730 deep learning models on 97 time series datasets, we propose the most exhaustive study of DNNs for TSC to date.",2018,"[{'authorId': '19302914', 'name': 'Hassan Ismail Fawaz'}, {'authorId': '2318564', 'name': 'G. Forestier'}, {'authorId': '152947675', 'name': 'J. Weber'}, {'authorId': '3482237', 'name': 'L. Idoumghar'}, {'authorId': '145344693', 'name': 'Pierre-Alain Muller'}]","{'url': 'https://arxiv.org/pdf/1809.04356', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1809.04356, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","time series classification (tsc) is an important and challenging problem in data mining. with the increase of time series data availability, hundreds of tsc algorithms have been proposed. among these methods, only a few have considered deep neural networks (dnns) to perform this task. this is surprising as deep learning has seen very successful applications in the last years. dnns have indeed revolutionized the field of computer vision especially with the advent of novel deeper architectures such as residual and convolutional neural networks. apart from images, sequential data such as text and audio can also be processed with dnns to reach state-of-the-art performance for document classification and speech recognition. in this article, we study the current state-of-the-art performance of deep learning algorithms for tsc by presenting an empirical study of the most recent dnn architectures for tsc. we give an overview of the most successful deep learning applications in various time series domains under a unified taxonomy of dnns for tsc. we also provide an open source deep learning framework to the tsc community where we implemented each of the compared approaches and evaluated them on a univariate tsc benchmark (the ucr/uea archive) and 12 multivariate time series datasets. by training 8730 deep learning models on 97 time series datasets, we propose the most exhaustive study of dnns for tsc to date.",https://arxiv.org/pdf/1809.04356
b79e5e4622a95417deec313cd543617b19611bea,Deep Learning using Rectified Linear Units (ReLU),"We introduce the use of rectified linear units (ReLU) as the classification function in a deep neural network (DNN). Conventionally, ReLU is used as an activation function in DNNs, with Softmax function as their classification function. However, there have been several studies on using a classification function other than Softmax, and this study is an addition to those. We accomplish this by taking the activation of the penultimate layer $h_{n - 1}$ in a neural network, then multiply it by weight parameters $\theta$ to get the raw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$, i.e. $f(o) = \max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide class predictions $\hat{y}$ through argmax function, i.e. argmax $f(x)$.",2018,"[{'authorId': '26412983', 'name': 'Abien Fred Agarap'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1803.08375, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we introduce the use of rectified linear units (relu) as the classification function in a deep neural network (dnn). conventionally, relu is used as an activation function in dnns, with softmax function as their classification function. however, there have been several studies on using a classification function other than softmax, and this study is an addition to those. we accomplish this by taking the activation of the penultimate layer $h_{n - 1}$ in a neural network, then multiply it by weight parameters $\theta$ to get the raw scores $o_{i}$. afterwards, we threshold the raw scores $o_{i}$ by $0$, i.e. $f(o) = \max(0, o_{i})$, where $f(o)$ is the relu function. we provide class predictions $\hat{y}$ through argmax function, i.e. argmax $f(x)$.",
811df72e210e20de99719539505da54762a11c6d,Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,"Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",2018,"[{'authorId': '2587648', 'name': 'Tuomas Haarnoja'}, {'authorId': '35499972', 'name': 'Aurick Zhou'}, {'authorId': '1689992', 'name': 'P. Abbeel'}, {'authorId': '1736651', 'name': 'S. Levine'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1801.01290, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","model-free deep reinforcement learning (rl) algorithms have been demonstrated on a range of challenging decision making and control tasks. however, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. both of these challenges severely limit the applicability of such methods to complex, real-world domains. in this paper, we propose soft actor-critic, an off-policy actor-critic deep rl algorithm based on the maximum entropy reinforcement learning framework. in this framework, the actor aims to maximize expected reward while also maximizing entropy. that is, to succeed at the task while acting as randomly as possible. prior deep rl methods based on this framework have been formulated as q-learning methods. by combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",
d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea,Energy and Policy Considerations for Deep Learning in NLP,"Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.",2019,"[{'authorId': '2268272', 'name': 'Emma Strubell'}, {'authorId': '47079359', 'name': 'Ananya Ganesh'}, {'authorId': '143753639', 'name': 'A. McCallum'}]","{'url': 'https://www.aclweb.org/anthology/P19-1355.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1906.02243, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. these models have obtained notable gains in accuracy across many nlp tasks. however, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. as a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. in this paper we bring this issue to the attention of nlp researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for nlp. based on these findings, we propose actionable recommendations to reduce costs and improve equity in nlp research and practice.",https://www.aclweb.org/anthology/P19-1355.pdf
ca011427853d34ce4ec9ccafde8a70c9eacc3e21,Deep Learning for Computer Vision: A Brief Review,"Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.",2018,"[{'authorId': '2594647', 'name': 'A. Voulodimos'}, {'authorId': '120205775', 'name': 'N. Doulamis'}, {'authorId': '1746705', 'name': 'A. Doulamis'}, {'authorId': '1806369', 'name': 'Eftychios E. Protopapadakis'}]","{'url': 'http://downloads.hindawi.com/journals/cin/2018/7068349.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5816885, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. this review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, convolutional neural networks, deep boltzmann machines and deep belief networks, and stacked denoising autoencoders. a brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.",http://downloads.hindawi.com/journals/cin/2018/7068349.pdf
98926d43356e87c22c82efc132dcaaac1ff40ebe,Robust deep learning based protein sequence design using ProteinMPNN,"While deep learning has revolutionized protein structure prediction, almost all experimentally characterized de novo protein designs have been generated using physically based approaches such as Rosetta. Here we describe a deep learning based protein sequence design method, ProteinMPNN, with outstanding performance in both in silico and experimental tests. The amino acid sequence at different positions can be coupled between single or multiple chains, enabling application to a wide range of current protein design challenges. On native protein backbones, ProteinMPNN has a sequence recovery of 52.4%, compared to 32.9% for Rosetta. Incorporation of noise during training improves sequence recovery on protein structure models, and produces sequences which more robustly encode their structures as assessed using structure prediction algorithms. We demonstrate the broad utility and high accuracy of ProteinMPNN using X-ray crystallography, cryoEM and functional studies by rescuing previously failed designs, made using Rosetta or AlphaFold, of protein monomers, cyclic homo-oligomers, tetrahedral nanoparticles, and target binding proteins. One-sentence summary A deep learning based protein sequence design method is described that is widely applicable to current design challenges and shows outstanding performance in both in silico and experimental tests.",2022,"[{'authorId': '35318911', 'name': 'J. Dauparas'}, {'authorId': '3175827', 'name': 'I. Anishchenko'}, {'authorId': '2160034551', 'name': 'N. Bennett'}, {'authorId': '2067573099', 'name': 'H. Bai'}, {'authorId': '150282231', 'name': 'R. Ragotte'}, {'authorId': '3741725', 'name': 'L. Milles'}, {'authorId': '50616282', 'name': 'B. Wicky'}, {'authorId': '8672839', 'name': 'A. Courbet'}, {'authorId': '118290811', 'name': 'R. D. de Haas'}, {'authorId': '2163188451', 'name': 'N. Bethel'}, {'authorId': '2168033577', 'name': 'P. J. Leung'}, {'authorId': '5517739', 'name': 'T. Huddy'}, {'authorId': '14938784', 'name': 'S. Pellock'}, {'authorId': '3802539', 'name': 'D. Tischer'}, {'authorId': '2143533108', 'name': 'F. Chan'}, {'authorId': '5198610', 'name': 'B. Koepnick'}, {'authorId': '2290127622', 'name': 'H. Nguyen'}, {'authorId': '2063965257', 'name': 'A. Kang'}, {'authorId': '6126402', 'name': 'B. Sankaran'}, {'authorId': '6135880', 'name': 'A. Bera'}, {'authorId': '12909814', 'name': 'N. King'}, {'authorId': '2118773845', 'name': 'D. Baker'}]","{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9997061', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9997061, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","while deep learning has revolutionized protein structure prediction, almost all experimentally characterized de novo protein designs have been generated using physically based approaches such as rosetta. here we describe a deep learning based protein sequence design method, proteinmpnn, with outstanding performance in both in silico and experimental tests. the amino acid sequence at different positions can be coupled between single or multiple chains, enabling application to a wide range of current protein design challenges. on native protein backbones, proteinmpnn has a sequence recovery of 52.4%, compared to 32.9% for rosetta. incorporation of noise during training improves sequence recovery on protein structure models, and produces sequences which more robustly encode their structures as assessed using structure prediction algorithms. we demonstrate the broad utility and high accuracy of proteinmpnn using x-ray crystallography, cryoem and functional studies by rescuing previously failed designs, made using rosetta or alphafold, of protein monomers, cyclic homo-oligomers, tetrahedral nanoparticles, and target binding proteins. one-sentence summary a deep learning based protein sequence design method is described that is widely applicable to current design challenges and shows outstanding performance in both in silico and experimental tests.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9997061
4e08141db0f2aa01afe903d312011c7d3d7acc46,Scaling deep learning for materials discovery,"Novel functional materials enable fundamental breakthroughs across technological applications from clean energy to information processing^ 1 – 11 . From microchips to batteries and photovoltaics, discovery of inorganic crystals has been bottlenecked by expensive trial-and-error approaches. Concurrently, deep-learning models for language, vision and biology have showcased emergent predictive capabilities with increasing data and computation^ 12 – 14 . Here we show that graph networks trained at scale can reach unprecedented levels of generalization, improving the efficiency of materials discovery by an order of magnitude. Building on 48,000 stable crystals identified in continuing studies^ 15 – 17 , improved efficiency enables the discovery of 2.2 million structures below the current convex hull, many of which escaped previous human chemical intuition. Our work represents an order-of-magnitude expansion in stable materials known to humanity. Stable discoveries that are on the final convex hull will be made available to screen for technological applications, as we demonstrate for layered materials and solid-electrolyte candidates. Of the stable structures, 736 have already been independently experimentally realized. The scale and diversity of hundreds of millions of first-principles calculations also unlock modelling capabilities for downstream applications, leading in particular to highly accurate and robust learned interatomic potentials that can be used in condensed-phase molecular-dynamics simulations and high-fidelity zero-shot prediction of ionic conductivity. A protocol using large-scale training of graph networks enables high-throughput discovery of novel stable structures and led to the identification of 2.2 million crystal structures, of which 381,000 are newly discovered stable materials.",2023,"[{'authorId': '1411034322', 'name': 'Amil Merchant'}, {'authorId': '2268751984', 'name': 'Simon Batzner'}, {'authorId': '2601641', 'name': 'S. Schoenholz'}, {'authorId': '7995028', 'name': 'Muratahan Aykol'}, {'authorId': '2268315391', 'name': 'Gowoon Cheon'}, {'authorId': '8132903', 'name': 'E. D. Cubuk'}]","{'url': 'https://www.nature.com/articles/s41586-023-06735-9.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10700131, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","novel functional materials enable fundamental breakthroughs across technological applications from clean energy to information processing^ 1 – 11 . from microchips to batteries and photovoltaics, discovery of inorganic crystals has been bottlenecked by expensive trial-and-error approaches. concurrently, deep-learning models for language, vision and biology have showcased emergent predictive capabilities with increasing data and computation^ 12 – 14 . here we show that graph networks trained at scale can reach unprecedented levels of generalization, improving the efficiency of materials discovery by an order of magnitude. building on 48,000 stable crystals identified in continuing studies^ 15 – 17 , improved efficiency enables the discovery of 2.2 million structures below the current convex hull, many of which escaped previous human chemical intuition. our work represents an order-of-magnitude expansion in stable materials known to humanity. stable discoveries that are on the final convex hull will be made available to screen for technological applications, as we demonstrate for layered materials and solid-electrolyte candidates. of the stable structures, 736 have already been independently experimentally realized. the scale and diversity of hundreds of millions of first-principles calculations also unlock modelling capabilities for downstream applications, leading in particular to highly accurate and robust learned interatomic potentials that can be used in condensed-phase molecular-dynamics simulations and high-fidelity zero-shot prediction of ionic conductivity. a protocol using large-scale training of graph networks enables high-throughput discovery of novel stable structures and led to the identification of 2.2 million crystal structures, of which 381,000 are newly discovered stable materials.",https://www.nature.com/articles/s41586-023-06735-9.pdf
df70977e0347b76fb049c17c3956f643bcb43a55,"Understanding of Machine Learning with Deep Learning: Architectures, Workflow, Applications and Future Directions","In recent years, deep learning (DL) has been the most popular computational approach in the field of machine learning (ML), achieving exceptional results on a variety of complex cognitive tasks, matching or even surpassing human performance. Deep learning technology, which grew out of artificial neural networks (ANN), has become a big deal in computing because it can learn from data. The ability to learn enormous volumes of data is one of the benefits of deep learning. In the past few years, the field of deep learning has grown quickly, and it has been used successfully in a wide range of traditional fields. In numerous disciplines, including cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, deep learning has outperformed well-known machine learning approaches. In order to provide a more ideal starting point from which to create a comprehensive understanding of deep learning, also, this article aims to provide a more detailed overview of the most significant facets of deep learning, including the most current developments in the field. Moreover, this paper discusses the significance of deep learning and the various deep learning techniques and networks. Additionally, it provides an overview of real-world application areas where deep learning techniques can be utilised. We conclude by identifying possible characteristics for future generations of deep learning modelling and providing research suggestions. On the same hand, this article intends to provide a comprehensive overview of deep learning modelling that can serve as a resource for academics and industry people alike. Lastly, we provide additional issues and recommended solutions to assist researchers in comprehending the existing research gaps. Various approaches, deep learning architectures, strategies, and applications are discussed in this work.",2023,"[{'authorId': '2013359', 'name': 'Mohammad Mustafa Taye'}]","{'url': 'https://www.mdpi.com/2073-431X/12/5/91/pdf?version=1682405138', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/computers12050091?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/computers12050091, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent years, deep learning (dl) has been the most popular computational approach in the field of machine learning (ml), achieving exceptional results on a variety of complex cognitive tasks, matching or even surpassing human performance. deep learning technology, which grew out of artificial neural networks (ann), has become a big deal in computing because it can learn from data. the ability to learn enormous volumes of data is one of the benefits of deep learning. in the past few years, the field of deep learning has grown quickly, and it has been used successfully in a wide range of traditional fields. in numerous disciplines, including cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, deep learning has outperformed well-known machine learning approaches. in order to provide a more ideal starting point from which to create a comprehensive understanding of deep learning, also, this article aims to provide a more detailed overview of the most significant facets of deep learning, including the most current developments in the field. moreover, this paper discusses the significance of deep learning and the various deep learning techniques and networks. additionally, it provides an overview of real-world application areas where deep learning techniques can be utilised. we conclude by identifying possible characteristics for future generations of deep learning modelling and providing research suggestions. on the same hand, this article intends to provide a comprehensive overview of deep learning modelling that can serve as a resource for academics and industry people alike. lastly, we provide additional issues and recommended solutions to assist researchers in comprehending the existing research gaps. various approaches, deep learning architectures, strategies, and applications are discussed in this work.",https://www.mdpi.com/2073-431X/12/5/91/pdf?version=1682405138
db6ad6ded1cfa26fdc7437f27fb823ec533e96fe,"Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions","Deep learning (DL), a branch of machine learning (ML) and artificial intelligence (AI) is nowadays considered as a core technology of today’s Fourth Industrial Revolution (4IR or Industry 4.0). Due to its learning capabilities from data, DL technology originated from artificial neural network (ANN), has become a hot topic in the context of computing, and is widely applied in various application areas like healthcare, visual recognition, text analytics, cybersecurity, and many more. However, building an appropriate DL model is a challenging task, due to the dynamic nature and variations in real-world problems and data. Moreover, the lack of core understanding turns DL methods into black-box machines that hamper development at the standard level. This article presents a structured and comprehensive view on DL techniques including a taxonomy considering various types of real-world tasks like supervised or unsupervised. In our taxonomy, we take into account deep networks for supervised or discriminative learning, unsupervised or generative learning as well as hybrid learning and relevant others. We also summarize real-world application areas where deep learning techniques can be used. Finally, we point out ten potential aspects for future generation DL modeling with research directions. Overall, this article aims to draw a big picture on DL modeling that can be used as a reference guide for both academia and industry professionals.",2021,"[{'authorId': '3456687', 'name': 'Iqbal H. Sarker'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s42979-021-00815-1.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8372231, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep learning (dl), a branch of machine learning (ml) and artificial intelligence (ai) is nowadays considered as a core technology of today’s fourth industrial revolution (4ir or industry 4.0). due to its learning capabilities from data, dl technology originated from artificial neural network (ann), has become a hot topic in the context of computing, and is widely applied in various application areas like healthcare, visual recognition, text analytics, cybersecurity, and many more. however, building an appropriate dl model is a challenging task, due to the dynamic nature and variations in real-world problems and data. moreover, the lack of core understanding turns dl methods into black-box machines that hamper development at the standard level. this article presents a structured and comprehensive view on dl techniques including a taxonomy considering various types of real-world tasks like supervised or unsupervised. in our taxonomy, we take into account deep networks for supervised or discriminative learning, unsupervised or generative learning as well as hybrid learning and relevant others. we also summarize real-world application areas where deep learning techniques can be used. finally, we point out ten potential aspects for future generation dl modeling with research directions. overall, this article aims to draw a big picture on dl modeling that can be used as a reference guide for both academia and industry professionals.",https://link.springer.com/content/pdf/10.1007/s42979-021-00815-1.pdf
a6bba5ce9867c978210e3d056691b5c1e769b760,Deep Learning for Person Re-Identification: A Survey and Outlook,"Person re-identification (Re-ID) aims at retrieving a person of interest across multiple non-overlapping cameras. With the advancement of deep neural networks and increasing demand of intelligent video surveillance, it has gained significantly increased interest in the computer vision community. By dissecting the involved components in developing a person Re-ID system, we categorize it into the closed-world and open-world settings. The widely studied closed-world setting is usually applied under various research-oriented assumptions, and has achieved inspiring success using deep learning techniques on a number of datasets. We first conduct a comprehensive overview with in-depth analysis for closed-world person Re-ID from three different perspectives, including deep feature representation learning, deep metric learning and ranking optimization. With the performance saturation under closed-world setting, the research focus for person Re-ID has recently shifted to the open-world setting, facing more challenging issues. This setting is closer to practical applications under specific scenarios. We summarize the open-world Re-ID in terms of five different aspects. By analyzing the advantages of existing methods, we design a powerful AGW baseline, achieving state-of-the-art or at least comparable performance on twelve datasets for four different Re-ID tasks. Meanwhile, we introduce a new evaluation metric (mINP) for person Re-ID, indicating the cost for finding all the correct matches, which provides an additional criteria to evaluate the Re-ID system for real applications. Finally, some important yet under-investigated open issues are discussed.",2020,"[{'authorId': '2676247', 'name': 'Mang Ye'}, {'authorId': '145953515', 'name': 'Jianbing Shen'}, {'authorId': '2004689620', 'name': 'Gaojie Lin'}, {'authorId': '145406421', 'name': 'T. Xiang'}, {'authorId': '144082425', 'name': 'Ling Shao'}, {'authorId': '1741126', 'name': 'S. Hoi'}]","{'url': 'https://ink.library.smu.edu.sg/sis_research/6961', 'status': 'GREEN', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2001.04193, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","person re-identification (re-id) aims at retrieving a person of interest across multiple non-overlapping cameras. with the advancement of deep neural networks and increasing demand of intelligent video surveillance, it has gained significantly increased interest in the computer vision community. by dissecting the involved components in developing a person re-id system, we categorize it into the closed-world and open-world settings. the widely studied closed-world setting is usually applied under various research-oriented assumptions, and has achieved inspiring success using deep learning techniques on a number of datasets. we first conduct a comprehensive overview with in-depth analysis for closed-world person re-id from three different perspectives, including deep feature representation learning, deep metric learning and ranking optimization. with the performance saturation under closed-world setting, the research focus for person re-id has recently shifted to the open-world setting, facing more challenging issues. this setting is closer to practical applications under specific scenarios. we summarize the open-world re-id in terms of five different aspects. by analyzing the advantages of existing methods, we design a powerful agw baseline, achieving state-of-the-art or at least comparable performance on twelve datasets for four different re-id tasks. meanwhile, we introduce a new evaluation metric (minp) for person re-id, indicating the cost for finding all the correct matches, which provides an additional criteria to evaluate the re-id system for real applications. finally, some important yet under-investigated open issues are discussed.",https://ink.library.smu.edu.sg/sis_research/6961
d1dbf643447405984eeef098b1b320dee0b3b8a7,Communication-Efficient Learning of Deep Networks from Decentralized Data,"Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. 
We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent.",2016,"[{'authorId': '145057514', 'name': 'H. B. McMahan'}, {'authorId': '31449330', 'name': 'Eider Moore'}, {'authorId': '1878835', 'name': 'Daniel Ramage'}, {'authorId': '37089174', 'name': 'S. Hampson'}, {'authorId': '2661025', 'name': 'B. A. Y. Arcas'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1602.05629, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. for example, language models can improve speech recognition and text entry, and image models can automatically select good photos. however, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. we advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. we term this decentralized approach federated learning. we present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. these experiments demonstrate the approach is robust to the unbalanced and non-iid data distributions that are a defining characteristic of this setting. communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent.",
69e76e16740ed69f4dc55361a3d319ac2f1293dd,Asynchronous Methods for Deep Reinforcement Learning,"We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.",2016,"[{'authorId': '3255983', 'name': 'Volodymyr Mnih'}, {'authorId': '36045539', 'name': 'Adrià Puigdomènech Badia'}, {'authorId': '153583218', 'name': 'Mehdi Mirza'}, {'authorId': '1753223', 'name': 'Alex Graves'}, {'authorId': '2542999', 'name': 'T. Lillicrap'}, {'authorId': '3367786', 'name': 'Tim Harley'}, {'authorId': '145824029', 'name': 'David Silver'}, {'authorId': '2645384', 'name': 'K. Kavukcuoglu'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1602.01783, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. we present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. the best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the atari domain while training for half the time on a single multi-core cpu instead of a gpu. furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3d mazes using a visual input.",
14014c024674991149f3ecf9314c93f7e029ef1a,"Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges","The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation. While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications. Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.",2021,"[{'authorId': '1732570', 'name': 'M. Bronstein'}, {'authorId': '143627859', 'name': 'Joan Bruna'}, {'authorId': '2056266', 'name': 'Taco Cohen'}, {'authorId': '1742197495', 'name': ""Petar Velivckovi'c""}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2104.13478, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing go, or protein folding -- are in fact feasible with appropriate computational scale. remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation. while learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. this text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications. such a 'geometric unification' endeavour, in the spirit of felix klein's erlangen program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as cnns, rnns, gnns, and transformers. on the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.",
0c00a328fa7cd56ee60338c54e89bd48310db80b,Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising,"The discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (DnCNNs) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. Specifically, residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. Different from the existing discriminative denoising models which usually train a specific model for additive white Gaussian noise at a certain noise level, our DnCNN model is able to handle Gaussian denoising with unknown noise level (i.e., blind Gaussian denoising). With the residual learning strategy, DnCNN implicitly removes the latent clean image in the hidden layers. This property motivates us to train a single DnCNN model to tackle with several general image denoising tasks, such as Gaussian denoising, single image super-resolution, and JPEG image deblocking. Our extensive experiments demonstrate that our DnCNN model can not only exhibit high effectiveness in several general image denoising tasks, but also be efficiently implemented by benefiting from GPU computing.",2016,"[{'authorId': '144110274', 'name': 'K. Zhang'}, {'authorId': '1724520', 'name': 'W. Zuo'}, {'authorId': '39773686', 'name': 'Yunjin Chen'}, {'authorId': '1803714', 'name': 'Deyu Meng'}, {'authorId': '36685537', 'name': 'Lei Zhang'}]","{'url': 'http://arxiv.org/pdf/1608.03981', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1608.03981, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. in this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (dncnns) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. specifically, residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. different from the existing discriminative denoising models which usually train a specific model for additive white gaussian noise at a certain noise level, our dncnn model is able to handle gaussian denoising with unknown noise level (i.e., blind gaussian denoising). with the residual learning strategy, dncnn implicitly removes the latent clean image in the hidden layers. this property motivates us to train a single dncnn model to tackle with several general image denoising tasks, such as gaussian denoising, single image super-resolution, and jpeg image deblocking. our extensive experiments demonstrate that our dncnn model can not only exhibit high effectiveness in several general image denoising tasks, but also be efficiently implemented by benefiting from gpu computing.",http://arxiv.org/pdf/1608.03981
e30d9b8ce108d982169621b88a5e3fb69fec70e1,Using Deep Learning for Image-Based Plant Disease Detection,"Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.",2016,"[{'authorId': '24178944', 'name': 'S. Mohanty'}, {'authorId': '2068146094', 'name': 'David P. Hughes'}, {'authorId': '3046313', 'name': 'M. Salathé'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fpls.2016.01419/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1604.03169, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. the combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). the trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.",https://www.frontiersin.org/articles/10.3389/fpls.2016.01419/pdf
c889d6f98e6d79b89c3a6adf8a921f88fa6ba518,Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks,"We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.",2017,"[{'authorId': '46881670', 'name': 'Chelsea Finn'}, {'authorId': '1689992', 'name': 'P. Abbeel'}, {'authorId': '1736651', 'name': 'S. Levine'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1703.03400, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. the goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. in our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. in effect, our method trains the model to be easy to fine-tune. we demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.",
8ec5896b4490c6e127d1718ffc36a3439d84cb81,On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima,"The stochastic gradient descent (SGD) method and its variants are algorithms of choice for many Deep Learning tasks. These methods operate in a small-batch regime wherein a fraction of the training data, say $32$-$512$ data points, is sampled to compute an approximation to the gradient. It has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize. We investigate the cause for this generalization drop in the large-batch regime and present numerical evidence that supports the view that large-batch methods tend to converge to sharp minimizers of the training and testing functions - and as is well known, sharp minima lead to poorer generalization. In contrast, small-batch methods consistently converge to flat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation. We discuss several strategies to attempt to help large-batch methods eliminate this generalization gap.",2016,"[{'authorId': '2844898', 'name': 'N. Keskar'}, {'authorId': '2205699', 'name': 'Dheevatsa Mudigere'}, {'authorId': '2784955', 'name': 'J. Nocedal'}, {'authorId': '1711231', 'name': 'M. Smelyanskiy'}, {'authorId': '144669504', 'name': 'P. T. P. Tang'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1609.04836, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the stochastic gradient descent (sgd) method and its variants are algorithms of choice for many deep learning tasks. these methods operate in a small-batch regime wherein a fraction of the training data, say $32$-$512$ data points, is sampled to compute an approximation to the gradient. it has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize. we investigate the cause for this generalization drop in the large-batch regime and present numerical evidence that supports the view that large-batch methods tend to converge to sharp minimizers of the training and testing functions - and as is well known, sharp minima lead to poorer generalization. in contrast, small-batch methods consistently converge to flat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation. we discuss several strategies to attempt to help large-batch methods eliminate this generalization gap.",
78989616eeeac55b202e3e4205225e7135054185,An Introduction to Deep Learning for the Physical Layer,"We present and discuss several novel applications of deep learning for the physical layer. By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about communications system design as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process. We show how this idea can be extended to networks of multiple transmitters and receivers and present the concept of radio transformer networks as a means to incorporate expert domain knowledge in the machine learning model. Lastly, we demonstrate the application of convolutional neural networks on raw IQ samples for modulation classification which achieves competitive accuracy with respect to traditional schemes relying on expert features. This paper is concluded with a discussion of open challenges and areas for future investigation.",2017,"[{'authorId': '1388350203', 'name': ""Tim O'Shea""}, {'authorId': '1749686', 'name': 'J. Hoydis'}]","{'url': 'https://arxiv.org/pdf/1702.00832', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1702.00832, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we present and discuss several novel applications of deep learning for the physical layer. by interpreting a communications system as an autoencoder, we develop a fundamental new way to think about communications system design as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process. we show how this idea can be extended to networks of multiple transmitters and receivers and present the concept of radio transformer networks as a means to incorporate expert domain knowledge in the machine learning model. lastly, we demonstrate the application of convolutional neural networks on raw iq samples for modulation classification which achieves competitive accuracy with respect to traditional schemes relying on expert features. this paper is concluded with a discussion of open challenges and areas for future investigation.",https://arxiv.org/pdf/1702.00832
5fa06d856ba6ae9cd1366888f8134d7fd0db75b9,Revisiting Deep Learning Models for Tabular Data,"The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports competitive results on various datasets. However, the proposed models are usually not properly compared to each other and existing works often use different benchmarks and experiment protocols. As a result, it is unclear for both researchers and practitioners what models perform best. Additionally, the field still lacks effective baselines, that is, the easy-to-use models that provide competitive performance across different problems. In this work, we perform an overview of the main families of DL architectures for tabular data and raise the bar of baselines in tabular DL by identifying two simple and powerful deep architectures. The first one is a ResNet-like architecture which turns out to be a strong baseline that is often missing in prior works. The second model is our simple adaptation of the Transformer architecture for tabular data, which outperforms other solutions on most tasks. Both models are compared to many existing architectures on a diverse set of tasks under the same training and tuning protocols. We also compare the best DL models with Gradient Boosted Decision Trees and conclude that there is still no universally superior solution.",2021,"[{'authorId': '102481418', 'name': 'Yu. V. Gorishniy'}, {'authorId': '2114431113', 'name': 'Ivan Rubachev'}, {'authorId': '10662951', 'name': 'Valentin Khrulkov'}, {'authorId': '143743802', 'name': 'Artem Babenko'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2106.11959, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports competitive results on various datasets. however, the proposed models are usually not properly compared to each other and existing works often use different benchmarks and experiment protocols. as a result, it is unclear for both researchers and practitioners what models perform best. additionally, the field still lacks effective baselines, that is, the easy-to-use models that provide competitive performance across different problems. in this work, we perform an overview of the main families of dl architectures for tabular data and raise the bar of baselines in tabular dl by identifying two simple and powerful deep architectures. the first one is a resnet-like architecture which turns out to be a strong baseline that is often missing in prior works. the second model is our simple adaptation of the transformer architecture for tabular data, which outperforms other solutions on most tasks. both models are compared to many existing architectures on a diverse set of tasks under the same training and tuning protocols. we also compare the best dl models with gradient boosted decision trees and conclude that there is still no universally superior solution.",
7536bce1007a765fd097a7cc8ea62208a8c89b85,Deep Learning for Generic Object Detection: A Survey,"Object detection, one of the most fundamental and challenging problems in computer vision, seeks to locate object instances from a large number of predefined categories in natural images. Deep learning techniques have emerged as a powerful strategy for learning feature representations directly from data and have led to remarkable breakthroughs in the field of generic object detection. Given this period of rapid evolution, the goal of this paper is to provide a comprehensive survey of the recent achievements in this field brought about by deep learning techniques. More than 300 research contributions are included in this survey, covering many aspects of generic object detection: detection frameworks, object feature representation, object proposal generation, context modeling, training strategies, and evaluation metrics. We finish the survey by identifying promising directions for future research.",2018,"[{'authorId': '39695518', 'name': 'Li Liu'}, {'authorId': '3001348', 'name': 'Wanli Ouyang'}, {'authorId': '31843833', 'name': 'Xiaogang Wang'}, {'authorId': '1731709', 'name': 'P. Fieguth'}, {'authorId': '50762381', 'name': 'Jie Chen'}, {'authorId': '2108754292', 'name': 'Xinwang Liu'}, {'authorId': '145962204', 'name': 'M. Pietikäinen'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11263-019-01247-4.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1809.02165, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","object detection, one of the most fundamental and challenging problems in computer vision, seeks to locate object instances from a large number of predefined categories in natural images. deep learning techniques have emerged as a powerful strategy for learning feature representations directly from data and have led to remarkable breakthroughs in the field of generic object detection. given this period of rapid evolution, the goal of this paper is to provide a comprehensive survey of the recent achievements in this field brought about by deep learning techniques. more than 300 research contributions are included in this survey, covering many aspects of generic object detection: detection frameworks, object feature representation, object proposal generation, context modeling, training strategies, and evaluation metrics. we finish the survey by identifying promising directions for future research.",https://link.springer.com/content/pdf/10.1007/s11263-019-01247-4.pdf
0e779fd59353a7f1f5b559b9d65fa4bfe367890c,Geometric Deep Learning: Going beyond Euclidean data,"Many scientific fields study data with an underlying structure that is non-Euclidean. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions) and are natural targets for machine-learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural-language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure and in cases where the invariances of these structures are built into networks used to model them.",2016,"[{'authorId': '1732570', 'name': 'M. Bronstein'}, {'authorId': '143627859', 'name': 'Joan Bruna'}, {'authorId': '1688882', 'name': 'Yann LeCun'}, {'authorId': '3149531', 'name': 'Arthur Szlam'}, {'authorId': '1697397', 'name': 'P. Vandergheynst'}]","{'url': 'http://arxiv.org/pdf/1611.08097', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1611.08097, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","many scientific fields study data with an underlying structure that is non-euclidean. some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. in many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions) and are natural targets for machine-learning techniques. in particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural-language processing, and audio analysis. however, these tools have been most successful on data with an underlying euclidean or grid-like structure and in cases where the invariances of these structures are built into networks used to model them.",http://arxiv.org/pdf/1611.08097
9d6acac70b2d1fdb861a08b00766ef263109cd7f,Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks,"The growing energy and performance costs of deep learning have driven the community to reduce the size of neural networks by selectively pruning components. Similarly to their biological counterparts, sparse networks generalize just as well, if not better than, the original dense networks. Sparsity can reduce the memory footprint of regular networks to fit mobile devices, as well as shorten training time for ever growing networks. In this paper, we survey prior work on sparsity in deep learning and provide an extensive tutorial of sparsification for both inference and training. We describe approaches to remove and add elements of neural networks, different training strategies to achieve model sparsity, and mechanisms to exploit sparsity in practice. Our work distills ideas from more than 300 research papers and provides guidance to practitioners who wish to utilize sparsity today, as well as to researchers whose goal is to push the frontier forward. We include the necessary background on mathematical methods in sparsification, describe phenomena such as early structure adaptation, the intricate relations between sparsity and the training process, and show techniques for achieving acceleration on real hardware. We also define a metric of pruned parameter efficiency that could serve as a baseline for comparison of different sparse networks. We close by speculating on how sparsity can improve future workloads and outline major open problems in the field.",2021,"[{'authorId': '1713648', 'name': 'T. Hoefler'}, {'authorId': '3311387', 'name': 'Dan Alistarh'}, {'authorId': '1402921119', 'name': 'Tal Ben-Nun'}, {'authorId': '2134146', 'name': 'Nikoli Dryden'}, {'authorId': '3341722', 'name': 'Alexandra Peste'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2102.00554, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the growing energy and performance costs of deep learning have driven the community to reduce the size of neural networks by selectively pruning components. similarly to their biological counterparts, sparse networks generalize just as well, if not better than, the original dense networks. sparsity can reduce the memory footprint of regular networks to fit mobile devices, as well as shorten training time for ever growing networks. in this paper, we survey prior work on sparsity in deep learning and provide an extensive tutorial of sparsification for both inference and training. we describe approaches to remove and add elements of neural networks, different training strategies to achieve model sparsity, and mechanisms to exploit sparsity in practice. our work distills ideas from more than 300 research papers and provides guidance to practitioners who wish to utilize sparsity today, as well as to researchers whose goal is to push the frontier forward. we include the necessary background on mathematical methods in sparsification, describe phenomena such as early structure adaptation, the intricate relations between sparsity and the training process, and show techniques for achieving acceleration on real hardware. we also define a metric of pruned parameter efficiency that could serve as a baseline for comparison of different sparse networks. we close by speculating on how sparsity can improve future workloads and outline major open problems in the field.",
7b9b756ab509cb9f52dbac95e3e901d571f0784f,A Survey of the Usages of Deep Learning for Natural Language Processing,"Over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models. This article provides a brief introduction to the field and a quick overview of deep learning architectures and methods. It then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions. Analyzed research areas include several core linguistic processing issues in addition to many applications of computational linguistics. A discussion of the current state of the art is then provided along with recommendations for future research in the field.",2020,"[{'authorId': '153004464', 'name': 'Dan Otter'}, {'authorId': '144932816', 'name': 'Julian R. Medina'}, {'authorId': '34694214', 'name': 'J. Kalita'}]","{'url': 'https://doi.org/10.1109/tnnls.2020.2979670', 'status': 'BRONZE', 'license': 'publisher-specific-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNNLS.2020.2979670?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNNLS.2020.2979670, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models. this article provides a brief introduction to the field and a quick overview of deep learning architectures and methods. it then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions. analyzed research areas include several core linguistic processing issues in addition to many applications of computational linguistics. a discussion of the current state of the art is then provided along with recommendations for future research in the field.",https://doi.org/10.1109/tnnls.2020.2979670
b8e1914c78c0b616e7d081759b1343cbfead42ad,CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning,"We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists. Our algorithm, CheXNet, is a 121-layer convolutional neural network trained on ChestX-ray14, currently the largest publicly available chest X-ray dataset, containing over 100,000 frontal-view X-ray images with 14 diseases. Four practicing academic radiologists annotate a test set, on which we compare the performance of CheXNet to that of radiologists. We find that CheXNet exceeds average radiologist performance on the F1 metric. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and achieve state of the art results on all 14 diseases.",2017,"[{'authorId': '2706258', 'name': 'Pranav Rajpurkar'}, {'authorId': '46559852', 'name': 'J. Irvin'}, {'authorId': '29972904', 'name': 'Kaylie Zhu'}, {'authorId': '145951921', 'name': 'Brandon Yang'}, {'authorId': '3776937', 'name': 'Hershel Mehta'}, {'authorId': '15069782', 'name': 'Tony Duan'}, {'authorId': '51235411', 'name': 'D. Ding'}, {'authorId': '30043065', 'name': 'Aarti Bagul'}, {'authorId': '2356307', 'name': 'C. Langlotz'}, {'authorId': '3474704', 'name': 'K. Shpanskaya'}, {'authorId': '4204731', 'name': 'M. Lungren'}, {'authorId': '34699434', 'name': 'A. Ng'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1711.05225, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we develop an algorithm that can detect pneumonia from chest x-rays at a level exceeding practicing radiologists. our algorithm, chexnet, is a 121-layer convolutional neural network trained on chestx-ray14, currently the largest publicly available chest x-ray dataset, containing over 100,000 frontal-view x-ray images with 14 diseases. four practicing academic radiologists annotate a test set, on which we compare the performance of chexnet to that of radiologists. we find that chexnet exceeds average radiologist performance on the f1 metric. we extend chexnet to detect all 14 diseases in chestx-ray14 and achieve state of the art results on all 14 diseases.",
ce2d5b5856bb6c9ab5c2390eb8b180c75a162055,Recent Trends in Deep Learning Based Natural Language Processing,"Deep learning methods employ multiple processing layers to learn hierarchical representations of data and have produced state-of-the-art results in many domains. Recently, a variety of model designs and methods have blossomed in the context of natural language processing (NLP). In this paper, we review significant deep learning related models and methods that have been employed for numerous NLP tasks and provide a walk-through of their evolution. We also summarize, compare and contrast the various models and put forward a detailed understanding of the past, present and future of deep learning in NLP.",2017,"[{'authorId': '2061649994', 'name': 'Tom Young'}, {'authorId': '8223433', 'name': 'Devamanyu Hazarika'}, {'authorId': '1746416', 'name': 'Soujanya Poria'}, {'authorId': '49943757', 'name': 'E. Cambria'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1708.02709, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep learning methods employ multiple processing layers to learn hierarchical representations of data and have produced state-of-the-art results in many domains. recently, a variety of model designs and methods have blossomed in the context of natural language processing (nlp). in this paper, we review significant deep learning related models and methods that have been employed for numerous nlp tasks and provide a walk-through of their evolution. we also summarize, compare and contrast the various models and put forward a detailed understanding of the past, present and future of deep learning in nlp.",
024006d4c2a89f7acacc6e4438d156525b60a98f,Continuous control with deep reinforcement learning,"We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs.",2015,"[{'authorId': '2542999', 'name': 'T. Lillicrap'}, {'authorId': '2323922', 'name': 'Jonathan J. Hunt'}, {'authorId': '1863250', 'name': 'A. Pritzel'}, {'authorId': '2801204', 'name': 'N. Heess'}, {'authorId': '1968210', 'name': 'Tom Erez'}, {'authorId': '2109481', 'name': 'Yuval Tassa'}, {'authorId': '145824029', 'name': 'David Silver'}, {'authorId': '1688276', 'name': 'D. Wierstra'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1509.02971, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we adapt the ideas underlying the success of deep q-learning to the continuous action domain. we present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. we further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs.",
8388f1be26329fa45e5807e968a641ce170ea078,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,"In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.",2015,"[{'authorId': '38909097', 'name': 'Alec Radford'}, {'authorId': '2096458', 'name': 'Luke Metz'}, {'authorId': '2127604', 'name': 'Soumith Chintala'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1511.06434, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent years, supervised learning with convolutional networks (cnns) has seen huge adoption in computer vision applications. comparatively, unsupervised learning with cnns has received less attention. in this work we hope to help bridge the gap between the success of cnns for supervised learning and unsupervised learning. we introduce a class of cnns called deep convolutional generative adversarial networks (dcgans), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.",
2c03df8b48bf3fa39054345bafabfeff15bfd11d,Deep Residual Learning for Image Recognition,"Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",2015,"[{'authorId': '39353098', 'name': 'Kaiming He'}, {'authorId': '1771551', 'name': 'X. Zhang'}, {'authorId': '3080683', 'name': 'Shaoqing Ren'}, {'authorId': None, 'name': 'Jian Sun'}]","{'url': 'https://repositorio.unal.edu.co/bitstream/unal/81443/1/98670607.2022.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1512.03385, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deeper neural networks are more difficult to train. we present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. we explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. we provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. on the imagenet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than vgg nets [40] but still having lower complexity. an ensemble of these residual nets achieves 3.57% error on the imagenet test set. this result won the 1st place on the ilsvrc 2015 classification task. we also present analysis on cifar-10 with 100 and 1000 layers. the depth of representations is of central importance for many visual recognition tasks. solely due to our extremely deep representations, we obtain a 28% relative improvement on the coco object detection dataset. deep residual nets are foundations of our submissions to ilsvrc & coco 2015 competitions1, where we also won the 1st places on the tasks of imagenet detection, imagenet localization, coco detection, and coco segmentation.",https://repositorio.unal.edu.co/bitstream/unal/81443/1/98670607.2022.pdf
8760bc7631c0cb04e7138254e9fd6451b7def8ca,Revisiting Unreasonable Effectiveness of Data in Deep Learning Era,"The success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. Since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of GPUs. But the size of the biggest dataset has surprisingly remained constant. What will happen if we increase the dataset size by 10 × or 100 × ? This paper takes a step towards clearing the clouds of mystery surrounding the relationship between ‘enormous data’ and visual deep learning. By exploiting the JFT-300M dataset which has more than 375M noisy labels for 300M images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. Our paper delivers some surprising (and some expected) findings. First, we find that the performance on vision tasks increases logarithmically based on volume of training data size. Second, we show that representation learning (or pre-training) still holds a lot of promise. One can improve performance on many vision tasks by just training a better base model. Finally, as expected, we present new state-of-the-art results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. Our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets.",2017,"[{'authorId': '1491624845', 'name': 'Chen Sun'}, {'authorId': '1781242', 'name': 'Abhinav Shrivastava'}, {'authorId': '2108498897', 'name': 'Saurabh Singh'}, {'authorId': '1726095131', 'name': 'A. Gupta'}]","{'url': 'https://arxiv.org/pdf/1707.02968', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1707.02968, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of gpus. but the size of the biggest dataset has surprisingly remained constant. what will happen if we increase the dataset size by 10 × or 100 × ? this paper takes a step towards clearing the clouds of mystery surrounding the relationship between ‘enormous data’ and visual deep learning. by exploiting the jft-300m dataset which has more than 375m noisy labels for 300m images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. our paper delivers some surprising (and some expected) findings. first, we find that the performance on vision tasks increases logarithmically based on volume of training data size. second, we show that representation learning (or pre-training) still holds a lot of promise. one can improve performance on many vision tasks by just training a better base model. finally, as expected, we present new state-of-the-art results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets.",https://arxiv.org/pdf/1707.02968
c468bbde6a22d961829e1970e6ad5795e05418d1,The Unreasonable Effectiveness of Deep Features as a Perceptual Metric,"While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called ""perceptual losses""? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.",2018,"[{'authorId': '2844849', 'name': 'Richard Zhang'}, {'authorId': '2094770', 'name': 'Phillip Isola'}, {'authorId': '1763086', 'name': 'Alexei A. Efros'}, {'authorId': '2177801', 'name': 'Eli Shechtman'}, {'authorId': '39231399', 'name': 'Oliver Wang'}]","{'url': 'https://arxiv.org/pdf/1801.03924', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1801.03924, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","while it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. despite this, the most widely used perceptual metrics today, such as psnr and ssim, are simple, shallow functions, and fail to account for many nuances of human perception. recently, the deep learning community has found that features of the vgg network trained on imagenet classification has been remarkably useful as a training loss for image synthesis. but how perceptual are these so-called ""perceptual losses""? what elements are critical for their success? to answer these questions, we introduce a new dataset of human perceptual similarity judgments. we systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. we find that deep features outperform all previous metrics by large margins on our dataset. more surprisingly, this result is not restricted to imagenet-trained vgg features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). our results suggest that perceptual similarity is an emergent property shared across deep visual representations.",https://arxiv.org/pdf/1801.03924
23ffaa0fe06eae05817f527a47ac3291077f9e58,Rethinking the Inception Architecture for Computer Vision,"Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set.",2015,"[{'authorId': '2574060', 'name': 'Christian Szegedy'}, {'authorId': '2657155', 'name': 'Vincent Vanhoucke'}, {'authorId': '2054165706', 'name': 'Sergey Ioffe'}, {'authorId': '1789737', 'name': 'Jonathon Shlens'}, {'authorId': '3282833', 'name': 'Z. Wojna'}]","{'url': 'http://arxiv.org/pdf/1512.00567', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1512.00567, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. we benchmark our methods on the ilsvrc 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. with an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set.",http://arxiv.org/pdf/1512.00567
290f40b6e5ad78a7f5c2cb226e48f98132843d9f,Design and Development of Cost-Effective Child Surveillance System using Computer Vision Technology,"The project's primary goal is to ensure child surveillance, continuous monitor and alert system for safety. Pre-defined navigation is one of the primary challenges in the robotic industry. Many technologies have been developed to overcome these problems. The project utilizes a high-quality night vision camera that is installed on a navigation robot that moves in the pre-defined path. The night vision camera captures the image and video of child activity, and transmits the data to the main system. The navigation robot is also equipped with the passive infrared (PIR) sensor to monitor any unauthorized human face intervention for child abuduction, and sound sensor for cry detection. The sound sensor detects the crying of the child and gives alert to the parent for immediate assistance.re will be developed using Python in the Google Colab.",2022,"[{'authorId': '2246733587', 'name': 'Vedavyas Peddiraju'}, {'authorId': '2246728148', 'name': 'Ramchandar Rao Pamulaparthi'}, {'authorId': '2246732982', 'name': 'Chakaradhar Adupa'}, {'authorId': '31074981', 'name': 'Laxman Raju Thoutam'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICMACC54824.2022.10093561?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICMACC54824.2022.10093561, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the project's primary goal is to ensure child surveillance, continuous monitor and alert system for safety. pre-defined navigation is one of the primary challenges in the robotic industry. many technologies have been developed to overcome these problems. the project utilizes a high-quality night vision camera that is installed on a navigation robot that moves in the pre-defined path. the night vision camera captures the image and video of child activity, and transmits the data to the main system. the navigation robot is also equipped with the passive infrared (pir) sensor to monitor any unauthorized human face intervention for child abuduction, and sound sensor for cry detection. the sound sensor detects the crying of the child and gives alert to the parent for immediate assistance.re will be developed using python in the google colab.",
913d86a84afae61b51281a1bce2edbd72b7c7acb,A Comprehensive Review of YOLO Architectures in Computer Vision: From YOLOv1 to YOLOv8 and YOLO-NAS,"YOLO has become a central real-time object detection system for robotics, driverless cars, and video monitoring applications. We present a comprehensive analysis of YOLO’s evolution, examining the innovations and contributions in each iteration from the original YOLO up to YOLOv8, YOLO-NAS, and YOLO with transformers. We start by describing the standard metrics and postprocessing; then, we discuss the major changes in network architecture and training tricks for each model. Finally, we summarize the essential lessons from YOLO’s development and provide a perspective on its future, highlighting potential research directions to enhance real-time object detection systems.",2023,"[{'authorId': '3161727', 'name': 'Juan R. Terven'}, {'authorId': '1401168034', 'name': 'Diana-Margarita Córdova-Esparza'}, {'authorId': '1659266659', 'name': 'J. Romero-González'}]","{'url': 'https://www.mdpi.com/2504-4990/5/4/83/pdf?version=1700497489', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2304.00501, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","yolo has become a central real-time object detection system for robotics, driverless cars, and video monitoring applications. we present a comprehensive analysis of yolo’s evolution, examining the innovations and contributions in each iteration from the original yolo up to yolov8, yolo-nas, and yolo with transformers. we start by describing the standard metrics and postprocessing; then, we discuss the major changes in network architecture and training tricks for each model. finally, we summarize the essential lessons from yolo’s development and provide a perspective on its future, highlighting potential research directions to enhance real-time object detection systems.",https://www.mdpi.com/2504-4990/5/4/83/pdf?version=1700497489
ad06c8a5fd292af518f878c7ced132b61739cdd8,A review of convolutional neural networks in computer vision,"In computer vision, a series of exemplary advances have been made in several areas involving image classification, semantic segmentation, object detection, and image super-resolution reconstruction with the rapid development of deep convolutional neural network (CNN). The CNN has superior features for autonomous learning and expression, and feature extraction from original input data can be realized by means of training CNN models that match practical applications. Due to the rapid progress in deep learning technology, the structure of CNN is becoming more and more complex and diverse. Consequently, it gradually replaces the traditional machine learning methods. This paper presents an elementary understanding of CNN components and their functions, including input layers, convolution layers, pooling layers, activation functions, batch normalization, dropout, fully connected layers, and output layers. On this basis, this paper gives a comprehensive overview of the past and current research status of the applications of CNN models in computer vision fields, e.g., image classification, object detection, and video prediction. In addition, we summarize the challenges and solutions of the deep CNN, and future research directions are also discussed.",2024,"[{'authorId': '2293238597', 'name': 'Xia Zhao'}, {'authorId': '2109120601', 'name': 'Limin Wang'}, {'authorId': '2119103829', 'name': 'Yufei Zhang'}, {'authorId': '2240291356', 'name': 'Xuming Han'}, {'authorId': '2293234507', 'name': 'Muhammet Deveci'}, {'authorId': '2293221909', 'name': 'Milan Parmar'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s10462-024-10721-6.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10462-024-10721-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10462-024-10721-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in computer vision, a series of exemplary advances have been made in several areas involving image classification, semantic segmentation, object detection, and image super-resolution reconstruction with the rapid development of deep convolutional neural network (cnn). the cnn has superior features for autonomous learning and expression, and feature extraction from original input data can be realized by means of training cnn models that match practical applications. due to the rapid progress in deep learning technology, the structure of cnn is becoming more and more complex and diverse. consequently, it gradually replaces the traditional machine learning methods. this paper presents an elementary understanding of cnn components and their functions, including input layers, convolution layers, pooling layers, activation functions, batch normalization, dropout, fully connected layers, and output layers. on this basis, this paper gives a comprehensive overview of the past and current research status of the applications of cnn models in computer vision fields, e.g., image classification, object detection, and video prediction. in addition, we summarize the challenges and solutions of the deep cnn, and future research directions are also discussed.",https://link.springer.com/content/pdf/10.1007/s10462-024-10721-6.pdf
c8b25fab5608c3e033d34b4483ec47e68ba109b7,Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,"This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at https://github.com/microsoft/Swin-Transformer.",2021,"[{'authorId': '2109371439', 'name': 'Ze Liu'}, {'authorId': '51091819', 'name': 'Yutong Lin'}, {'authorId': '2112823372', 'name': 'Yue Cao'}, {'authorId': '1823518756', 'name': 'Han Hu'}, {'authorId': '2107995927', 'name': 'Yixuan Wei'}, {'authorId': '2148904543', 'name': 'Zheng Zhang'}, {'authorId': '145676588', 'name': 'Stephen Lin'}, {'authorId': '2261753424', 'name': 'B. Guo'}]","{'url': 'http://arxiv.org/pdf/2103.14030', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2103.14030, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper presents a new vision transformer, called swin transformer, that capably serves as a general-purpose backbone for computer vision. challenges in adapting transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. to address these differences, we propose a hierarchical transformer whose representation is computed with shifted windows. the shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. this hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. these qualities of swin transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on imagenet-1k) and dense prediction tasks such as object detection (58.7 box ap and 51.1 mask ap on coco test-dev) and semantic segmentation (53.5 miou on ade20k val). its performance surpasses the previous state-of-the-art by a large margin of +2.7 box ap and +2.6 mask ap on coco, and +3.2 miou on ade20k, demonstrating the potential of transformer-based models as vision backbones. the hierarchical design and the shifted window approach also prove beneficial for all-mlp architectures. the code and models are publicly available at https://github.com/microsoft/swin-transformer.",http://arxiv.org/pdf/2103.14030
6351ebb4a3287f5f3e1273464b3b91e5df5a16d7,Masked Autoencoders Are Scalable Vision Learners,"This paper shows that masked autoencoders (MAE) are scalable self-supervised learners for computer vision. Our MAE approach is simple: we mask random patches of the input image and reconstruct the missing pixels. It is based on two core designs. First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens. Second, we find that masking a high proportion of the input image, e.g., 75%, yields a nontrivial and meaningful self-supervisory task. Coupling these two designs enables us to train large models efficiently and effectively: we accelerate training (by 3× or more) and improve accuracy. Our scalable approach allows for learning high-capacity models that generalize well: e.g., a vanilla ViT-Huge model achieves the best accuracy (87.8%) among methods that use only ImageNet-1K data. Transfer performance in downstream tasks outperforms supervised pretraining and shows promising scaling behavior.",2021,"[{'authorId': '2058350112', 'name': 'Kaiming He'}, {'authorId': '39717886', 'name': 'Xinlei Chen'}, {'authorId': '1817030', 'name': 'Saining Xie'}, {'authorId': '3128506', 'name': 'Yanghao Li'}, {'authorId': '2065731243', 'name': ""Piotr Doll'ar""}, {'authorId': '2983898', 'name': 'Ross B. Girshick'}]","{'url': 'https://arxiv.org/pdf/2111.06377', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2111.06377, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper shows that masked autoencoders (mae) are scalable self-supervised learners for computer vision. our mae approach is simple: we mask random patches of the input image and reconstruct the missing pixels. it is based on two core designs. first, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens. second, we find that masking a high proportion of the input image, e.g., 75%, yields a nontrivial and meaningful self-supervisory task. coupling these two designs enables us to train large models efficiently and effectively: we accelerate training (by 3× or more) and improve accuracy. our scalable approach allows for learning high-capacity models that generalize well: e.g., a vanilla vit-huge model achieves the best accuracy (87.8%) among methods that use only imagenet-1k data. transfer performance in downstream tasks outperforms supervised pretraining and shows promising scaling behavior.",https://arxiv.org/pdf/2111.06377
45f686be3b96302ede327645227134e1c304dbab,Attention mechanisms in computer vision: A survey,"Humans can naturally and effectively find salient regions in complex scenes. Motivated by this observation, attention mechanisms were introduced into computer vision with the aim of imitating this aspect of the human visual system. Such an attention mechanism can be regarded as a dynamic weight adjustment process based on features of the input image. Attention mechanisms have achieved great success in many visual tasks, including image classification, object detection, semantic segmentation, video understanding, image generation, 3D vision, multimodal tasks, and self-supervised learning. In this survey, we provide a comprehensive review of various attention mechanisms in computer vision and categorize them according to approach, such as channel attention, spatial attention, temporal attention, and branch attention; a related repository https://github.com/MenghaoGuo/Awesome-Vision-Attentions is dedicated to collecting related work. We also suggest future directions for attention mechanism research.",2021,"[{'authorId': '2088775481', 'name': 'Meng-Hao Guo'}, {'authorId': '2093923811', 'name': 'Tianhan Xu'}, {'authorId': '2119612440', 'name': 'Jiangjiang Liu'}, {'authorId': '79305819', 'name': 'Zheng-Ning Liu'}, {'authorId': '41022152', 'name': 'Peng-Tao Jiang'}, {'authorId': '31471368', 'name': 'Tai-Jiang Mu'}, {'authorId': '7671691', 'name': 'Song-Hai Zhang'}, {'authorId': '2404014', 'name': 'Ralph Robert Martin'}, {'authorId': '37535930', 'name': 'Ming-Ming Cheng'}, {'authorId': '145140922', 'name': 'Shimin Hu'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s41095-022-0271-y.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2111.07624, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","humans can naturally and effectively find salient regions in complex scenes. motivated by this observation, attention mechanisms were introduced into computer vision with the aim of imitating this aspect of the human visual system. such an attention mechanism can be regarded as a dynamic weight adjustment process based on features of the input image. attention mechanisms have achieved great success in many visual tasks, including image classification, object detection, semantic segmentation, video understanding, image generation, 3d vision, multimodal tasks, and self-supervised learning. in this survey, we provide a comprehensive review of various attention mechanisms in computer vision and categorize them according to approach, such as channel attention, spatial attention, temporal attention, and branch attention; a related repository https://github.com/menghaoguo/awesome-vision-attentions is dedicated to collecting related work. we also suggest future directions for attention mechanism research.",https://link.springer.com/content/pdf/10.1007/s41095-022-0271-y.pdf
21ec90872abd986c12afe39bebe807732ffa70c9,Florence: A New Foundation Model for Computer Vision,"Automated visual understanding of our diverse and open world demands computer vision models to generalize well with minimal customization for specific tasks, similar to human vision. Computer vision foundation models, which are trained on diverse, large-scale dataset and can be adapted to a wide range of downstream tasks, are critical for this mission to solve real-world computer vision applications. While existing vision foundation models such as CLIP, ALIGN, and Wu Dao 2.0 focus mainly on mapping images and textual representations to a cross-modal shared representation, we introduce a new computer vision foundation model, Florence, to expand the representations from coarse (scene) to fine (object), from static (images) to dynamic (videos), and from RGB to multiple modalities (caption, depth). By incorporating universal visual-language representations from Web-scale image-text data, our Florence model can be easily adapted for various computer vision tasks, such as classification, retrieval, object detection, VQA, image caption, video retrieval and action recognition. Moreover, Florence demonstrates outstanding performance in many types of transfer learning: fully sampled fine-tuning, linear probing, few-shot transfer and zero-shot transfer for novel images and objects. All of these properties are critical for our vision foundation model to serve general purpose vision tasks. Florence achieves new state-of-the-art results in majority of 44 representative benchmarks, e.g., ImageNet-1K zero-shot classification with top-1 accuracy of 83.74 and the top-5 accuracy of 97.18, 62.4 mAP on COCO fine tuning, 80.36 on VQA, and 87.8 on Kinetics-600.",2021,"[{'authorId': '145347147', 'name': 'Lu Yuan'}, {'authorId': '49025801', 'name': 'Dongdong Chen'}, {'authorId': '2109182290', 'name': 'Yi-Ling Chen'}, {'authorId': '40589056', 'name': 'N. Codella'}, {'authorId': '3386593', 'name': 'Xiyang Dai'}, {'authorId': '48441311', 'name': 'Jianfeng Gao'}, {'authorId': '35431603', 'name': 'Houdong Hu'}, {'authorId': '144531812', 'name': 'Xuedong Huang'}, {'authorId': None, 'name': 'Boxin Li'}, {'authorId': '2109737569', 'name': 'Chunyuan Li'}, {'authorId': '2107890439', 'name': 'Ce Liu'}, {'authorId': '2152968847', 'name': 'Mengchen Liu'}, {'authorId': '2145253136', 'name': 'Zicheng Liu'}, {'authorId': '2143520239', 'name': 'Yumao Lu'}, {'authorId': '1844953096', 'name': 'Yu Shi'}, {'authorId': '29957038', 'name': 'Lijuan Wang'}, {'authorId': '2124948371', 'name': 'Jianfeng Wang'}, {'authorId': '2054421528', 'name': 'Bin Xiao'}, {'authorId': '2158780631', 'name': 'Zhen Xiao'}, {'authorId': '120157163', 'name': 'Jianwei Yang'}, {'authorId': '48262024', 'name': 'Michael Zeng'}, {'authorId': '2116644664', 'name': 'Luowei Zhou'}, {'authorId': '9325940', 'name': 'Pengchuan Zhang'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2111.11432, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","automated visual understanding of our diverse and open world demands computer vision models to generalize well with minimal customization for specific tasks, similar to human vision. computer vision foundation models, which are trained on diverse, large-scale dataset and can be adapted to a wide range of downstream tasks, are critical for this mission to solve real-world computer vision applications. while existing vision foundation models such as clip, align, and wu dao 2.0 focus mainly on mapping images and textual representations to a cross-modal shared representation, we introduce a new computer vision foundation model, florence, to expand the representations from coarse (scene) to fine (object), from static (images) to dynamic (videos), and from rgb to multiple modalities (caption, depth). by incorporating universal visual-language representations from web-scale image-text data, our florence model can be easily adapted for various computer vision tasks, such as classification, retrieval, object detection, vqa, image caption, video retrieval and action recognition. moreover, florence demonstrates outstanding performance in many types of transfer learning: fully sampled fine-tuning, linear probing, few-shot transfer and zero-shot transfer for novel images and objects. all of these properties are critical for our vision foundation model to serve general purpose vision tasks. florence achieves new state-of-the-art results in majority of 44 representative benchmarks, e.g., imagenet-1k zero-shot classification with top-1 accuracy of 83.74 and the top-5 accuracy of 97.18, 62.4 map on coco fine tuning, 80.36 on vqa, and 87.8 on kinetics-600.",
59694d8b594ac2bb0f91dd4a0d681133f976939a,A Review on Machine Learning Styles in Computer Vision—Techniques and Future Directions,"Computer applications have considerably shifted from single data processing to machine learning in recent years due to the accessibility and availability of massive volumes of data obtained through the internet and various sources. Machine learning is automating human assistance by training an algorithm on relevant data. Supervised, Unsupervised, and Reinforcement Learning are the three fundamental categories of machine learning techniques. In this paper, we have discussed the different learning styles used in the field of Computer vision, Deep Learning, Neural networks, and machine learning. Some of the most recent applications of machine learning in computer vision include object identification, object classification, and extracting usable information from images, graphic documents, and videos. Some machine learning techniques frequently include zero-shot learning, active learning, contrastive learning, self-supervised learning, life-long learning, semi-supervised learning, ensemble learning, sequential learning, and multi-view learning used in computer vision until now. There is a lack of systematic reviews about all learning styles. This paper presents literature analysis of how different machine learning styles evolved in the field of Artificial Intelligence (AI) for computer vision. This research examines and evaluates machine learning applications in computer vision and future forecasting. This paper will be helpful for researchers working with learning styles as it gives a deep insight into future directions.",2022,"[{'authorId': '2186253530', 'name': 'Supriya V. Mahadevkar'}, {'authorId': '80492640', 'name': 'Bharti Khemani'}, {'authorId': '90630252', 'name': 'S. Patil'}, {'authorId': '1794896', 'name': 'K. Kotecha'}, {'authorId': '70303173', 'name': 'D. Vora'}, {'authorId': '2064038678', 'name': 'Ajith Abraham'}, {'authorId': '2140516', 'name': 'L. Gabralla'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/6514899/09903420.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2022.3209825?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2022.3209825, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","computer applications have considerably shifted from single data processing to machine learning in recent years due to the accessibility and availability of massive volumes of data obtained through the internet and various sources. machine learning is automating human assistance by training an algorithm on relevant data. supervised, unsupervised, and reinforcement learning are the three fundamental categories of machine learning techniques. in this paper, we have discussed the different learning styles used in the field of computer vision, deep learning, neural networks, and machine learning. some of the most recent applications of machine learning in computer vision include object identification, object classification, and extracting usable information from images, graphic documents, and videos. some machine learning techniques frequently include zero-shot learning, active learning, contrastive learning, self-supervised learning, life-long learning, semi-supervised learning, ensemble learning, sequential learning, and multi-view learning used in computer vision until now. there is a lack of systematic reviews about all learning styles. this paper presents literature analysis of how different machine learning styles evolved in the field of artificial intelligence (ai) for computer vision. this research examines and evaluates machine learning applications in computer vision and future forecasting. this paper will be helpful for researchers working with learning styles as it gives a deep insight into future directions.",https://ieeexplore.ieee.org/ielx7/6287639/6514899/09903420.pdf
c3df199cbca74763c4ae9889409bbd4aa29b6255,Deep learning-enabled medical computer vision,"A decade of unprecedented progress in artificial intelligence (AI) has demonstrated the potential for many fields—including medicine—to benefit from the insights that AI techniques can extract from data. Here we survey recent progress in the development of modern computer vision techniques—powered by deep learning—for medical applications, focusing on medical imaging, medical video, and clinical deployment. We start by briefly summarizing a decade of progress in convolutional neural networks, including the vision tasks they enable, in the context of healthcare. Next, we discuss several example medical imaging applications that stand to benefit—including cardiology, pathology, dermatology, ophthalmology–and propose new avenues for continued work. We then expand into general medical video, highlighting ways in which clinical workflows can integrate computer vision to enhance care. Finally, we discuss the challenges and hurdles required for real-world clinical deployment of these technologies.",2021,"[{'authorId': '1811529', 'name': 'A. Esteva'}, {'authorId': '2055632320', 'name': 'Katherine Chou'}, {'authorId': '34149749', 'name': 'Serena Yeung'}, {'authorId': '2047256670', 'name': 'N. Naik'}, {'authorId': '145822841', 'name': 'Ali Madani'}, {'authorId': '145934658', 'name': 'A. Mottaghi'}, {'authorId': '2118113191', 'name': 'Yun Liu'}, {'authorId': '144758045', 'name': 'E. Topol'}, {'authorId': '48448318', 'name': 'J. Dean'}, {'authorId': '2166511', 'name': 'R. Socher'}]","{'url': 'https://www.nature.com/articles/s41746-020-00376-2.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7794558, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a decade of unprecedented progress in artificial intelligence (ai) has demonstrated the potential for many fields—including medicine—to benefit from the insights that ai techniques can extract from data. here we survey recent progress in the development of modern computer vision techniques—powered by deep learning—for medical applications, focusing on medical imaging, medical video, and clinical deployment. we start by briefly summarizing a decade of progress in convolutional neural networks, including the vision tasks they enable, in the context of healthcare. next, we discuss several example medical imaging applications that stand to benefit—including cardiology, pathology, dermatology, ophthalmology–and propose new avenues for continued work. we then expand into general medical video, highlighting ways in which clinical workflows can integrate computer vision to enhance care. finally, we discuss the challenges and hurdles required for real-world clinical deployment of these technologies.",https://www.nature.com/articles/s41746-020-00376-2.pdf
327109fdbc6291c231dc4a7c3c2515e77202f894,"CNN Variants for Computer Vision: History, Architecture, Application, Challenges and Future Scope","Computer vision is becoming an increasingly trendy word in the area of image processing. With the emergence of computer vision applications, there is a significant demand to recognize objects automatically. Deep CNN (convolution neural network) has benefited the computer vision community by producing excellent results in video processing, object recognition, picture classification and segmentation, natural language processing, speech recognition, and many other fields. Furthermore, the introduction of large amounts of data and readily available hardware has opened new avenues for CNN study. Several inspirational concepts for the progress of CNN have been investigated, including alternative activation functions, regularization, parameter optimization, and architectural advances. Furthermore, achieving innovations in architecture results in a tremendous enhancement in the capacity of the deep CNN. Significant emphasis has been given to leveraging channel and spatial information, with a depth of architecture and information processing via multi-path. This survey paper focuses mainly on the primary taxonomy and newly released deep CNN architectures, and it divides numerous recent developments in CNN architectures into eight groups. Spatial exploitation, multi-path, depth, breadth, dimension, channel boosting, feature-map exploitation, and attention-based CNN are the eight categories. The main contribution of this manuscript is in comparing various architectural evolutions in CNN by its architectural change, strengths, and weaknesses. Besides, it also includes an explanation of the CNN’s components, the strengths and weaknesses of various CNN variants, research gap or open challenges, CNN applications, and the future research direction.",2021,"[{'authorId': '70675870', 'name': 'Dulari Bhatt'}, {'authorId': '144350339', 'name': 'Chirag I. Patel'}, {'authorId': '69915242', 'name': 'Hardik N. Talsania'}, {'authorId': '2070427277', 'name': 'Jigar Patel'}, {'authorId': '2138460273', 'name': 'Rasmika Vaghela'}, {'authorId': '47706103', 'name': 'Sharnil Pandya'}, {'authorId': '9179008', 'name': 'Kirit J. Modi'}, {'authorId': '3424424', 'name': 'H. Ghayvat'}]","{'url': 'https://www.mdpi.com/2079-9292/10/20/2470/pdf?version=1633955851', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/electronics10202470?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/electronics10202470, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","computer vision is becoming an increasingly trendy word in the area of image processing. with the emergence of computer vision applications, there is a significant demand to recognize objects automatically. deep cnn (convolution neural network) has benefited the computer vision community by producing excellent results in video processing, object recognition, picture classification and segmentation, natural language processing, speech recognition, and many other fields. furthermore, the introduction of large amounts of data and readily available hardware has opened new avenues for cnn study. several inspirational concepts for the progress of cnn have been investigated, including alternative activation functions, regularization, parameter optimization, and architectural advances. furthermore, achieving innovations in architecture results in a tremendous enhancement in the capacity of the deep cnn. significant emphasis has been given to leveraging channel and spatial information, with a depth of architecture and information processing via multi-path. this survey paper focuses mainly on the primary taxonomy and newly released deep cnn architectures, and it divides numerous recent developments in cnn architectures into eight groups. spatial exploitation, multi-path, depth, breadth, dimension, channel boosting, feature-map exploitation, and attention-based cnn are the eight categories. the main contribution of this manuscript is in comparing various architectural evolutions in cnn by its architectural change, strengths, and weaknesses. besides, it also includes an explanation of the cnn’s components, the strengths and weaknesses of various cnn variants, research gap or open challenges, cnn applications, and the future research direction.",https://www.mdpi.com/2079-9292/10/20/2470/pdf?version=1633955851
b514949ad8344071c0f342f182390d2d88bcc26d,Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey,"Deep learning is at the heart of the current rise of artificial intelligence. In the field of computer vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. Whereas, deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. Adversarial attacks pose a serious threat to the success of deep learning in practice. This fact has recently led to a large influx of contributions in this direction. This paper presents the first comprehensive survey on adversarial attacks on deep learning in computer vision. We review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them. To emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios. Finally, drawing on the reviewed literature, we provide a broader outlook of this research direction.",2018,"[{'authorId': '47398812', 'name': 'Naveed Akhtar'}, {'authorId': '1747500', 'name': 'A. Mian'}]","{'url': 'https://doi.org/10.1109/access.2018.2807385', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1801.00553, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep learning is at the heart of the current rise of artificial intelligence. in the field of computer vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. whereas, deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. for images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. adversarial attacks pose a serious threat to the success of deep learning in practice. this fact has recently led to a large influx of contributions in this direction. this paper presents the first comprehensive survey on adversarial attacks on deep learning in computer vision. we review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them. to emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios. finally, drawing on the reviewed literature, we provide a broader outlook of this research direction.",https://doi.org/10.1109/access.2018.2807385
1b3142ee576017e5aa34aac94c658f948b75dbcd,Leveling Down in Computer Vision: Pareto Inefficiencies in Fair Deep Classifiers,"Algorithmic fairness is frequently motivated in terms of a trade-off in which overall performance is decreased so as to improve performance on disadvantaged groups where the algorithm would otherwise be less accurate. Contrary to this, we find that applying existing fairness approaches to computer vision improve fairness by degrading the performance of classifiers across all groups (with increased degradation on the best performing groups). Extending the bias-variance decomposition for classification to fairness, we theoretically explain why the majority of fairness methods designed for low capacity models should not be used in settings involving high-capacity models, a scenario common to computer vision. We corroborate this analysis with extensive experimental support that shows that many of the fairness heuristics used in computer vision also degrade performance on the most disadvantaged groups. Building on these insights, we propose an adaptive augmentation strategy that, uniquely, of all methods tested, improves performance for the disadvantaged groups.",2022,"[{'authorId': '52306341', 'name': 'Dominik Zietlow'}, {'authorId': '147521198', 'name': 'Michael Lohaus'}, {'authorId': '47231927', 'name': 'Guha Balakrishnan'}, {'authorId': '2871632', 'name': 'Matthäus Kleindessner'}, {'authorId': '9557137', 'name': 'Francesco Locatello'}, {'authorId': '1707625', 'name': 'B. Scholkopf'}, {'authorId': '145485799', 'name': 'Chris Russell'}]","{'url': 'https://arxiv.org/pdf/2203.04913', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2203.04913, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","algorithmic fairness is frequently motivated in terms of a trade-off in which overall performance is decreased so as to improve performance on disadvantaged groups where the algorithm would otherwise be less accurate. contrary to this, we find that applying existing fairness approaches to computer vision improve fairness by degrading the performance of classifiers across all groups (with increased degradation on the best performing groups). extending the bias-variance decomposition for classification to fairness, we theoretically explain why the majority of fairness methods designed for low capacity models should not be used in settings involving high-capacity models, a scenario common to computer vision. we corroborate this analysis with extensive experimental support that shows that many of the fairness heuristics used in computer vision also degrade performance on the most disadvantaged groups. building on these insights, we propose an adaptive augmentation strategy that, uniquely, of all methods tested, improves performance for the disadvantaged groups.",https://arxiv.org/pdf/2203.04913
2a9b33f66ccc3806af58bdab2319559f4f9d2c5e,"A survey on deep multimodal learning for computer vision: advances, trends, applications, and datasets","The research progress in multimodal learning has grown rapidly over the last decade in several areas, especially in computer vision. The growing potential of multimodal data streams and deep learning algorithms has contributed to the increasing universality of deep multimodal learning. This involves the development of models capable of processing and analyzing the multimodal information uniformly. Unstructured real-world data can inherently take many forms, also known as modalities, often including visual and textual content. Extracting relevant patterns from this kind of data is still a motivating goal for researchers in deep learning. In this paper, we seek to improve the understanding of key concepts and algorithms of deep multimodal learning for the computer vision community by exploring how to generate deep models that consider the integration and combination of heterogeneous visual cues across sensory modalities. In particular, we summarize six perspectives from the current literature on deep multimodal learning, namely: multimodal data representation, multimodal fusion (i.e., both traditional and deep learning-based schemes), multitask learning, multimodal alignment, multimodal transfer learning, and zero-shot learning. We also survey current multimodal applications and present a collection of benchmark datasets for solving problems in various vision domains. Finally, we highlight the limitations and challenges of deep multimodal learning and provide insights and directions for future research.",2021,"[{'authorId': '1858133629', 'name': 'Khaled Bayoudh'}, {'authorId': '2111646642', 'name': 'Raja Knani'}, {'authorId': '2675904', 'name': 'F. Hamdaoui'}, {'authorId': '1804206', 'name': 'A. Mtibaa'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s00371-021-02166-7.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8192112, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the research progress in multimodal learning has grown rapidly over the last decade in several areas, especially in computer vision. the growing potential of multimodal data streams and deep learning algorithms has contributed to the increasing universality of deep multimodal learning. this involves the development of models capable of processing and analyzing the multimodal information uniformly. unstructured real-world data can inherently take many forms, also known as modalities, often including visual and textual content. extracting relevant patterns from this kind of data is still a motivating goal for researchers in deep learning. in this paper, we seek to improve the understanding of key concepts and algorithms of deep multimodal learning for the computer vision community by exploring how to generate deep models that consider the integration and combination of heterogeneous visual cues across sensory modalities. in particular, we summarize six perspectives from the current literature on deep multimodal learning, namely: multimodal data representation, multimodal fusion (i.e., both traditional and deep learning-based schemes), multitask learning, multimodal alignment, multimodal transfer learning, and zero-shot learning. we also survey current multimodal applications and present a collection of benchmark datasets for solving problems in various vision domains. finally, we highlight the limitations and challenges of deep multimodal learning and provide insights and directions for future research.",https://link.springer.com/content/pdf/10.1007/s00371-021-02166-7.pdf
224ecc21a917dd246420d2da0b3edee5834f3391,Vision Transformers in Medical Computer Vision - A Contemplative Retrospection,"Recent escalation in the field of computer vision underpins a huddle of algorithms with the magnificent potential to unravel the information contained within images. These computer vision algorithms are being practised in medical image analysis and are transfiguring the perception and interpretation of Imaging data. Among these algorithms, Vision Transformers are evolved as one of the most contemporary and dominant architectures that are being used in the field of computer vision. These are immensely utilized by a plenty of researchers to perform new as well as former experiments. Here, in this article we investigate the intersection of Vision Transformers and Medical images and proffered an overview of various ViTs based frameworks that are being used by different researchers in order to decipher the obstacles in Medical Computer Vision. We surveyed the application of Vision transformers in different areas of medical computer vision such as image-based disease classification, anatomical structure segmentation, registration, region-based lesion Detection, captioning, report generation, reconstruction using multiple medical imaging modalities that greatly assist in medical diagnosis and hence treatment process. Along with this, we also demystify several imaging modalities used in Medical Computer Vision. Moreover, to get more insight and deeper understanding, self-attention mechanism of transformers is also explained briefly. Conclusively, we also put some light on available data sets, adopted methodology, their performance measures, challenges and their solutions in form of discussion. We hope that this review article will open future directions for researchers in medical computer vision.",2022,"[{'authorId': '2160629993', 'name': 'Arshi Parvaiz'}, {'authorId': '2160630451', 'name': 'Muhammad Anwaar Khalid'}, {'authorId': '2160629668', 'name': 'Rukhsana Zafar'}, {'authorId': '2160631008', 'name': 'Huma Ameer'}, {'authorId': '2160629976', 'name': 'M. Ali'}, {'authorId': '1756409', 'name': 'M. Fraz'}]","{'url': 'http://arxiv.org/pdf/2203.15269', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2203.15269, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent escalation in the field of computer vision underpins a huddle of algorithms with the magnificent potential to unravel the information contained within images. these computer vision algorithms are being practised in medical image analysis and are transfiguring the perception and interpretation of imaging data. among these algorithms, vision transformers are evolved as one of the most contemporary and dominant architectures that are being used in the field of computer vision. these are immensely utilized by a plenty of researchers to perform new as well as former experiments. here, in this article we investigate the intersection of vision transformers and medical images and proffered an overview of various vits based frameworks that are being used by different researchers in order to decipher the obstacles in medical computer vision. we surveyed the application of vision transformers in different areas of medical computer vision such as image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, reconstruction using multiple medical imaging modalities that greatly assist in medical diagnosis and hence treatment process. along with this, we also demystify several imaging modalities used in medical computer vision. moreover, to get more insight and deeper understanding, self-attention mechanism of transformers is also explained briefly. conclusively, we also put some light on available data sets, adopted methodology, their performance measures, challenges and their solutions in form of discussion. we hope that this review article will open future directions for researchers in medical computer vision.",http://arxiv.org/pdf/2203.15269
f2d32b9a81b78dbbccfa1616c019bbc32b2a8efb,Large image datasets: A pyrrhic win for computer vision?,"In this paper we investigate problematic practices and consequences of large scale vision datasets (LSVDs). We examine broad issues such as the question of consent and justice as well as specific concerns such as the inclusion of verifiably pornographic images in datasets. Taking the ImageNet-ILSVRC-2012 dataset as an example, we perform a cross-sectional model-based quantitative census covering factors such as age, gender, NSFW content scoring, class- wise accuracy, human-cardinality-analysis, and the semanticity of the image class information in order to statistically investigate the extent and subtleties of ethical transgressions. We then use the census to help hand-curate a look-up-table of images in the ImageNet-ILSVRC-2012 dataset that fall into the categories of verifiably pornographic: shot in a non-consensual setting (up-skirt), beach voyeuristic, and exposed private parts. We survey the landscape of harm and threats both the society at large and individuals face due to uncritical and ill-considered dataset curation practices. We then propose possible courses of correction and critique their pros and cons. We have duly open-sourced all of the code and the census meta-datasets generated in this endeavor for the computer vision community to build on. By unveiling the severity of the threats, our hope is to motivate the constitution of mandatory Institutional Review Boards (IRB) for large scale dataset curation.",2020,"[{'authorId': '2670978', 'name': 'Vinay Uday Prabhu'}, {'authorId': '8318698', 'name': 'Abeba Birhane'}]","{'url': 'https://arxiv.org/pdf/2006.16923', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2006.16923, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this paper we investigate problematic practices and consequences of large scale vision datasets (lsvds). we examine broad issues such as the question of consent and justice as well as specific concerns such as the inclusion of verifiably pornographic images in datasets. taking the imagenet-ilsvrc-2012 dataset as an example, we perform a cross-sectional model-based quantitative census covering factors such as age, gender, nsfw content scoring, class- wise accuracy, human-cardinality-analysis, and the semanticity of the image class information in order to statistically investigate the extent and subtleties of ethical transgressions. we then use the census to help hand-curate a look-up-table of images in the imagenet-ilsvrc-2012 dataset that fall into the categories of verifiably pornographic: shot in a non-consensual setting (up-skirt), beach voyeuristic, and exposed private parts. we survey the landscape of harm and threats both the society at large and individuals face due to uncritical and ill-considered dataset curation practices. we then propose possible courses of correction and critique their pros and cons. we have duly open-sourced all of the code and the census meta-datasets generated in this endeavor for the computer vision community to build on. by unveiling the severity of the threats, our hope is to motivate the constitution of mandatory institutional review boards (irb) for large scale dataset curation.",https://arxiv.org/pdf/2006.16923
0c3a18ec9165932dc585e5682323853f80875fec,Mixed Differential Privacy in Computer Vision,"We introduce AdaMix, an adaptive differentially private algorithm for training deep neural network classifiers using both private and public image data. While pre-training language models on large public datasets has enabled strong differential privacy (DP) guarantees with minor loss of accuracy, a similar practice yields punishing trade-offs in vision tasks. A few-shot or even zero-shot learning baseline that ignores private data can outperform fine-tuning on a large private dataset. AdaMix incorporates few-shot training, or cross-modal zero-shot learning, on public data prior to private fine-tuning, to improve the trade-off. AdaMix reduces the error increase from the non-private upper bound from the 167–311% of the baseline, on average across 6 datasets, to 68-92% depending on the desired privacy level selected by the user. AdaMix tackles the trade-off arising in visual classification, whereby the most privacy sensitive data, corresponding to isolated points in representation space, are also critical for high classification accuracy. In addition, AdaMix comes with strong theoretical privacy guarantees and convergence analysis.",2022,"[{'authorId': '35838711', 'name': 'Aditya Golatkar'}, {'authorId': '16163297', 'name': 'A. Achille'}, {'authorId': '2040617', 'name': 'Yu-Xiang Wang'}, {'authorId': '1682008', 'name': 'Aaron Roth'}, {'authorId': '81338045', 'name': 'Michael Kearns'}, {'authorId': '1715959', 'name': 'Stefano Soatto'}]","{'url': 'https://arxiv.org/pdf/2203.11481', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2203.11481, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we introduce adamix, an adaptive differentially private algorithm for training deep neural network classifiers using both private and public image data. while pre-training language models on large public datasets has enabled strong differential privacy (dp) guarantees with minor loss of accuracy, a similar practice yields punishing trade-offs in vision tasks. a few-shot or even zero-shot learning baseline that ignores private data can outperform fine-tuning on a large private dataset. adamix incorporates few-shot training, or cross-modal zero-shot learning, on public data prior to private fine-tuning, to improve the trade-off. adamix reduces the error increase from the non-private upper bound from the 167–311% of the baseline, on average across 6 datasets, to 68-92% depending on the desired privacy level selected by the user. adamix tackles the trade-off arising in visual classification, whereby the most privacy sensitive data, corresponding to isolated points in representation space, are also critical for high classification accuracy. in addition, adamix comes with strong theoretical privacy guarantees and convergence analysis.",https://arxiv.org/pdf/2203.11481
a0185d4f32dde88aa1749f3a8000ed4721787b65,Visual Transformers: Token-based Image Representation and Processing for Computer Vision,"Computer vision has achieved great success using standardized image representations -- pixel arrays, and the corresponding deep learning operators -- convolutions. In this work, we challenge this paradigm: we instead (a) represent images as a set of visual tokens and (b) apply visual transformers to find relationships between visual semantic concepts. Given an input image, we dynamically extract a set of visual tokens from the image to obtain a compact representation for high-level semantics. We then use visual transformers to operate over the visual tokens to densely model relationships between them. We find that this paradigm of token-based image representation and processing drastically outperforms its convolutional counterparts on image classification and semantic segmentation. To demonstrate the power of this approach on ImageNet classification, we use ResNet as a convenient baseline and use visual transformers to replace the last stage of convolutions. This reduces the stage's MACs by up to 6.9x, while attaining up to 4.53 points higher top-1 accuracy. For semantic segmentation, we use a visual-transformer-based FPN (VT-FPN) module to replace a convolution-based FPN, saving 6.5x fewer MACs while achieving up to 0.35 points higher mIoU on LIP and COCO-stuff.",2020,"[{'authorId': '3130257', 'name': 'Bichen Wu'}, {'authorId': '1490695028', 'name': 'Chenfeng Xu'}, {'authorId': '4527324', 'name': 'Xiaoliang Dai'}, {'authorId': '144546548', 'name': 'Alvin Wan'}, {'authorId': '2918780', 'name': 'Peizhao Zhang'}, {'authorId': '1680165', 'name': 'M. Tomizuka'}, {'authorId': '1732330', 'name': 'K. Keutzer'}, {'authorId': '48682997', 'name': 'Péter Vajda'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2006.03677, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","computer vision has achieved great success using standardized image representations -- pixel arrays, and the corresponding deep learning operators -- convolutions. in this work, we challenge this paradigm: we instead (a) represent images as a set of visual tokens and (b) apply visual transformers to find relationships between visual semantic concepts. given an input image, we dynamically extract a set of visual tokens from the image to obtain a compact representation for high-level semantics. we then use visual transformers to operate over the visual tokens to densely model relationships between them. we find that this paradigm of token-based image representation and processing drastically outperforms its convolutional counterparts on image classification and semantic segmentation. to demonstrate the power of this approach on imagenet classification, we use resnet as a convenient baseline and use visual transformers to replace the last stage of convolutions. this reduces the stage's macs by up to 6.9x, while attaining up to 4.53 points higher top-1 accuracy. for semantic segmentation, we use a visual-transformer-based fpn (vt-fpn) module to replace a convolution-based fpn, saving 6.5x fewer macs while achieving up to 0.35 points higher miou on lip and coco-stuff.",
b4efbd4e0885d8a2e98acb5a23acbc134e08e8d1,Hand Gesture Recognition Based on Computer Vision: A Review of Techniques,"Hand gestures are a form of nonverbal communication that can be used in several fields such as communication between deaf-mute people, robot control, human–computer interaction (HCI), home automation and medical applications. Research papers based on hand gestures have adopted many different techniques, including those based on instrumented sensor technology and computer vision. In other words, the hand sign can be classified under many headings, such as posture and gesture, as well as dynamic and static, or a hybrid of the two. This paper focuses on a review of the literature on hand gesture techniques and introduces their merits and limitations under different circumstances. In addition, it tabulates the performance of these methods, focusing on computer vision techniques that deal with the similarity and difference points, technique of hand segmentation used, classification algorithms and drawbacks, number and types of gestures, dataset used, detection range (distance) and type of camera used. This paper is a thorough general overview of hand gesture methods with a brief discussion of some possible applications.",2020,"[{'authorId': '1908807827', 'name': 'M. Oudah'}, {'authorId': '123156822', 'name': 'A. Al-Naji'}, {'authorId': '144608860', 'name': 'J. Chahl'}]","{'url': 'https://www.mdpi.com/2313-433X/6/8/73/pdf?version=1595503383', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8321080, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","hand gestures are a form of nonverbal communication that can be used in several fields such as communication between deaf-mute people, robot control, human–computer interaction (hci), home automation and medical applications. research papers based on hand gestures have adopted many different techniques, including those based on instrumented sensor technology and computer vision. in other words, the hand sign can be classified under many headings, such as posture and gesture, as well as dynamic and static, or a hybrid of the two. this paper focuses on a review of the literature on hand gesture techniques and introduces their merits and limitations under different circumstances. in addition, it tabulates the performance of these methods, focusing on computer vision techniques that deal with the similarity and difference points, technique of hand segmentation used, classification algorithms and drawbacks, number and types of gestures, dataset used, detection range (distance) and type of camera used. this paper is a thorough general overview of hand gesture methods with a brief discussion of some possible applications.",https://www.mdpi.com/2313-433X/6/8/73/pdf?version=1595503383
1a0829a7bef8ea3ecb33b55871b4498dd328ff68,Advances in adversarial attacks and defenses in computer vision: A survey,"Deep Learning is the most widely used tool in the contemporary field of computer vision. Its ability to accurately solve complex problems is employed in vision research to learn deep neural models for a variety of tasks, including security critical applications. However, it is now known that deep learning is vulnerable to adversarial attacks that can manipulate its predictions by introducing visually imperceptible perturbations in images and videos. Since the discovery of this phenomenon in 2013, it has attracted significant attention of researchers from multiple sub-fields of machine intelligence. In 2018, we published the first-ever review of the contributions made by the computer vision community in adversarial attacks on deep learning (and their defenses). Many of those contributions have inspired new directions in this area, which has matured significantly since witnessing the first generation methods. Hence, as a legacy sequel of our first literature survey, this review article focuses on the advances in this area since 2018. We thoroughly discuss the first generation attacks and comprehensively cover the modern attacks and their defenses appearing in the prestigious sources of computer vision and machine learning research. Besides offering the most comprehensive literature review of adversarial attacks and defenses to date, the article also provides concise definitions of technical terminologies for the non-experts. Finally, it discusses challenges and future outlook of this direction based on the literature since the advent of this research direction.",2021,"[{'authorId': '47398812', 'name': 'Naveed Akhtar'}, {'authorId': '1747500', 'name': 'A. Mian'}, {'authorId': '3469167', 'name': 'Navid Kardan'}, {'authorId': '2111863589', 'name': 'M. Shah'}]","{'url': 'https://doi.org/10.1109/access.2021.3127960', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2108.00401, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep learning is the most widely used tool in the contemporary field of computer vision. its ability to accurately solve complex problems is employed in vision research to learn deep neural models for a variety of tasks, including security critical applications. however, it is now known that deep learning is vulnerable to adversarial attacks that can manipulate its predictions by introducing visually imperceptible perturbations in images and videos. since the discovery of this phenomenon in 2013, it has attracted significant attention of researchers from multiple sub-fields of machine intelligence. in 2018, we published the first-ever review of the contributions made by the computer vision community in adversarial attacks on deep learning (and their defenses). many of those contributions have inspired new directions in this area, which has matured significantly since witnessing the first generation methods. hence, as a legacy sequel of our first literature survey, this review article focuses on the advances in this area since 2018. we thoroughly discuss the first generation attacks and comprehensively cover the modern attacks and their defenses appearing in the prestigious sources of computer vision and machine learning research. besides offering the most comprehensive literature review of adversarial attacks and defenses to date, the article also provides concise definitions of technical terminologies for the non-experts. finally, it discusses challenges and future outlook of this direction based on the literature since the advent of this research direction.",https://doi.org/10.1109/access.2021.3127960
08cc923c0386cdc92630bcc3cb00a337a0d91212,A review of computer vision–based structural health monitoring at local and global levels,"Structural health monitoring at local and global levels using computer vision technologies has gained much attention in the structural health monitoring community in research and practice. Due to the computer vision technology application advantages such as non-contact, long distance, rapid, low cost and labor, and low interference to the daily operation of structures, it is promising to consider computer vision–structural health monitoring as a complement to the conventional structural health monitoring. This article presents a general overview of the concepts, approaches, and real-life practice of computer vision–structural health monitoring along with some relevant literature that is rapidly accumulating. The computer vision–structural health monitoring covered in this article at local level includes applications such as crack, spalling, delamination, rust, and loose bolt detection. At the global level, applications include displacement measurement, structural behavior analysis, vibration serviceability, modal identification, model updating, damage detection, cable force monitoring, load factor estimation, and structural identification using input–output information. The current research studies and applications of computer vision–structural health monitoring mainly focus on the implementation and integration of two-dimensional computer vision techniques to solve structural health monitoring problems and the projective geometry methods implemented are utilized to convert the three-dimensional problems into two-dimensional problems. This review mainly puts emphasis on two-dimensional computer vision–structural health monitoring applications. Subsequently, a brief review of representative developments of three-dimensional computer vision in the area of civil engineering is presented along with the challenges and opportunities of two-dimensional and three-dimensional computer vision–structural health monitoring. Finally, the article presents a forward look to the future of computer vision–structural health monitoring.",2020,"[{'authorId': '98102517', 'name': 'C. Dong'}, {'authorId': '3027982', 'name': 'N. Catbas'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/1475921720935585?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/1475921720935585, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","structural health monitoring at local and global levels using computer vision technologies has gained much attention in the structural health monitoring community in research and practice. due to the computer vision technology application advantages such as non-contact, long distance, rapid, low cost and labor, and low interference to the daily operation of structures, it is promising to consider computer vision–structural health monitoring as a complement to the conventional structural health monitoring. this article presents a general overview of the concepts, approaches, and real-life practice of computer vision–structural health monitoring along with some relevant literature that is rapidly accumulating. the computer vision–structural health monitoring covered in this article at local level includes applications such as crack, spalling, delamination, rust, and loose bolt detection. at the global level, applications include displacement measurement, structural behavior analysis, vibration serviceability, modal identification, model updating, damage detection, cable force monitoring, load factor estimation, and structural identification using input–output information. the current research studies and applications of computer vision–structural health monitoring mainly focus on the implementation and integration of two-dimensional computer vision techniques to solve structural health monitoring problems and the projective geometry methods implemented are utilized to convert the three-dimensional problems into two-dimensional problems. this review mainly puts emphasis on two-dimensional computer vision–structural health monitoring applications. subsequently, a brief review of representative developments of three-dimensional computer vision in the area of civil engineering is presented along with the challenges and opportunities of two-dimensional and three-dimensional computer vision–structural health monitoring. finally, the article presents a forward look to the future of computer vision–structural health monitoring.",
7cc3414b8c0791f1d5e8f82ee65cb99a7a876774,Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development,"Data is a crucial component of machine learning. The field is reliant on data to train, validate, and test models. With increased technical capabilities, machine learning research has boomed in both academic and industry settings, and one major focus has been on computer vision. Computer vision is a popular domain of machine learning increasingly pertinent to real-world applications, from facial recognition in policing to object detection for autonomous vehicles. Given computer vision's propensity to shape machine learning research and impact human life, we seek to understand disciplinary practices around dataset documentation - how data is collected, curated, annotated, and packaged into datasets for computer vision researchers and practitioners to use for model tuning and development. Specifically, we examine what dataset documentation communicates about the underlying values of vision data and the larger practices and goals of computer vision as a field. To conduct this study, we collected a corpus of about 500 computer vision datasets, from which we sampled 114 dataset publications across different vision tasks. Through both a structured and thematic content analysis, we document a number of values around accepted data practices, what makes desirable data, and the treatment of humans in the dataset construction process. We discuss how computer vision datasets authors value efficiency at the expense of care; universality at the expense of contextuality; impartiality at the expense of positionality; and model work at the expense of data work. Many of the silenced values we identify sit in opposition with social computing practices. We conclude with suggestions on how to better incorporate silenced values into the dataset creation and curation process.",2021,"[{'authorId': '10691918', 'name': 'M. Scheuerman'}, {'authorId': '40081727', 'name': 'Emily L. Denton'}, {'authorId': '40540250', 'name': 'A. Hanna'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3476058', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2108.04308, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","data is a crucial component of machine learning. the field is reliant on data to train, validate, and test models. with increased technical capabilities, machine learning research has boomed in both academic and industry settings, and one major focus has been on computer vision. computer vision is a popular domain of machine learning increasingly pertinent to real-world applications, from facial recognition in policing to object detection for autonomous vehicles. given computer vision's propensity to shape machine learning research and impact human life, we seek to understand disciplinary practices around dataset documentation - how data is collected, curated, annotated, and packaged into datasets for computer vision researchers and practitioners to use for model tuning and development. specifically, we examine what dataset documentation communicates about the underlying values of vision data and the larger practices and goals of computer vision as a field. to conduct this study, we collected a corpus of about 500 computer vision datasets, from which we sampled 114 dataset publications across different vision tasks. through both a structured and thematic content analysis, we document a number of values around accepted data practices, what makes desirable data, and the treatment of humans in the dataset construction process. we discuss how computer vision datasets authors value efficiency at the expense of care; universality at the expense of contextuality; impartiality at the expense of positionality; and model work at the expense of data work. many of the silenced values we identify sit in opposition with social computing practices. we conclude with suggestions on how to better incorporate silenced values into the dataset creation and curation process.",https://dl.acm.org/doi/pdf/10.1145/3476058
7d547f848566eab79b88781d58ac63f16e6a1201,Review of Weed Detection Methods Based on Computer Vision,"Weeds are one of the most important factors affecting agricultural production. The waste and pollution of farmland ecological environment caused by full-coverage chemical herbicide spraying are becoming increasingly evident. With the continuous improvement in the agricultural production level, accurately distinguishing crops from weeds and achieving precise spraying only for weeds are important. However, precise spraying depends on accurately identifying and locating weeds and crops. In recent years, some scholars have used various computer vision methods to achieve this purpose. This review elaborates the two aspects of using traditional image-processing methods and deep learning-based methods to solve weed detection problems. It provides an overview of various methods for weed detection in recent years, analyzes the advantages and disadvantages of existing methods, and introduces several related plant leaves, weed datasets, and weeding machinery. Lastly, the problems and difficulties of the existing weed detection methods are analyzed, and the development trend of future research is prospected.",2021,"[{'authorId': '2044485399', 'name': 'Zhangnan Wu'}, {'authorId': '2154736357', 'name': 'Yajun Chen'}, {'authorId': '2112525789', 'name': 'Bo Zhao'}, {'authorId': '2523453', 'name': 'Xiao-bing Kang'}, {'authorId': '2142354653', 'name': 'Yuanyuan Ding'}]","{'url': 'https://www.mdpi.com/1424-8220/21/11/3647/pdf?version=1621853863', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8197187, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","weeds are one of the most important factors affecting agricultural production. the waste and pollution of farmland ecological environment caused by full-coverage chemical herbicide spraying are becoming increasingly evident. with the continuous improvement in the agricultural production level, accurately distinguishing crops from weeds and achieving precise spraying only for weeds are important. however, precise spraying depends on accurately identifying and locating weeds and crops. in recent years, some scholars have used various computer vision methods to achieve this purpose. this review elaborates the two aspects of using traditional image-processing methods and deep learning-based methods to solve weed detection problems. it provides an overview of various methods for weed detection in recent years, analyzes the advantages and disadvantages of existing methods, and introduces several related plant leaves, weed datasets, and weeding machinery. lastly, the problems and difficulties of the existing weed detection methods are analyzed, and the development trend of future research is prospected.",https://www.mdpi.com/1424-8220/21/11/3647/pdf?version=1621853863
8fe44af15f0e31c090c0dde4b606e91360a6fb74,Deep reinforcement learning in computer vision: a comprehensive survey,"Deep reinforcement learning augments the reinforcement learning framework and utilizes the powerful representation of deep neural networks. Recent works have demonstrated the remarkable successes of deep reinforcement learning in various domains including finance, medicine, healthcare, video games, robotics, and computer vision. In this work, we provide a detailed review of recent and state-of-the-art research advances of deep reinforcement learning in computer vision. We start with comprehending the theories of deep learning, reinforcement learning, and deep reinforcement learning. We then propose a categorization of deep reinforcement learning methodologies and discuss their advantages and limitations. In particular, we divide deep reinforcement learning into seven main categories according to their applications in computer vision, i.e. (i) landmark localization (ii) object detection; (iii) object tracking; (iv) registration on both 2D image and 3D image volumetric data (v) image segmentation; (vi) videos analysis; and (vii) other applications. Each of these categories is further analyzed with reinforcement learning techniques, network design, and performance. Moreover, we provide a comprehensive analysis of the existing publicly available datasets and examine source code availability. Finally, we present some open issues and discuss future research directions on deep reinforcement learning in computer vision.",2021,"[{'authorId': '144556913', 'name': 'Ngan T. H. Le'}, {'authorId': '2051808036', 'name': 'V. Rathour'}, {'authorId': '1556433845', 'name': 'Kashu Yamazaki'}, {'authorId': '1769788', 'name': 'Khoa Luu'}, {'authorId': '1794486', 'name': 'M. Savvides'}]","{'url': 'https://arxiv.org/pdf/2108.11510', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2108.11510, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep reinforcement learning augments the reinforcement learning framework and utilizes the powerful representation of deep neural networks. recent works have demonstrated the remarkable successes of deep reinforcement learning in various domains including finance, medicine, healthcare, video games, robotics, and computer vision. in this work, we provide a detailed review of recent and state-of-the-art research advances of deep reinforcement learning in computer vision. we start with comprehending the theories of deep learning, reinforcement learning, and deep reinforcement learning. we then propose a categorization of deep reinforcement learning methodologies and discuss their advantages and limitations. in particular, we divide deep reinforcement learning into seven main categories according to their applications in computer vision, i.e. (i) landmark localization (ii) object detection; (iii) object tracking; (iv) registration on both 2d image and 3d image volumetric data (v) image segmentation; (vi) videos analysis; and (vii) other applications. each of these categories is further analyzed with reinforcement learning techniques, network design, and performance. moreover, we provide a comprehensive analysis of the existing publicly available datasets and examine source code availability. finally, we present some open issues and discuss future research directions on deep reinforcement learning in computer vision.",https://arxiv.org/pdf/2108.11510
89e5e7665e3b8bf9bf675400fa31d23300d62ea5,Learning to Resize Images for Computer Vision Tasks,"For all the ways convolutional neural nets have revolutionized computer vision in recent years, one important aspect has received surprisingly little attention: the effect of image size on the accuracy of tasks being trained for. Typically, to be efficient, the input images are resized to a relatively small spatial resolution (e.g. 224 × 224), and both training and inference are carried out at this resolution. The actual mechanism for this re-scaling has been an afterthought: Namely, off-the-shelf image re sizers such as bilinear and bicubic are commonly used in most machine learning software frameworks. But do these re sizers limit the on-task performance of the trained networks? The answer is yes. Indeed, we show that the typical linear re sizer can be replaced with learned resizers that can substantially improve performance. Importantly, while the classical re-sizers typically result in better perceptual quality of the downscaled images, our proposed learned resizers do not necessarily give better visual quality, but instead improve task performance.Our learned image resizer is jointly trained with a base-line vision model. This learned CNN-based resizer creates machine friendly visual manipulations that lead to a consistent improvement of the end task metric over the baseline model. Specifically, here we focus on the classification task with the ImageNet dataset [26], and experiment with four different models to learn resizers adapted to each model. Moreover, we show that the proposed resizer can also be useful for fine-tuning the classification baselines for other vision tasks. To this end, we experiment with three different baselines to develop image quality assessment (IQA) models on the AVA dataset [24].",2021,"[{'authorId': '1980498754', 'name': 'Hossein Talebi'}, {'authorId': '1718280', 'name': 'P. Milanfar'}]","{'url': 'https://arxiv.org/pdf/2103.09950', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2103.09950, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","for all the ways convolutional neural nets have revolutionized computer vision in recent years, one important aspect has received surprisingly little attention: the effect of image size on the accuracy of tasks being trained for. typically, to be efficient, the input images are resized to a relatively small spatial resolution (e.g. 224 × 224), and both training and inference are carried out at this resolution. the actual mechanism for this re-scaling has been an afterthought: namely, off-the-shelf image re sizers such as bilinear and bicubic are commonly used in most machine learning software frameworks. but do these re sizers limit the on-task performance of the trained networks? the answer is yes. indeed, we show that the typical linear re sizer can be replaced with learned resizers that can substantially improve performance. importantly, while the classical re-sizers typically result in better perceptual quality of the downscaled images, our proposed learned resizers do not necessarily give better visual quality, but instead improve task performance.our learned image resizer is jointly trained with a base-line vision model. this learned cnn-based resizer creates machine friendly visual manipulations that lead to a consistent improvement of the end task metric over the baseline model. specifically, here we focus on the classification task with the imagenet dataset [26], and experiment with four different models to learn resizers adapted to each model. moreover, we show that the proposed resizer can also be useful for fine-tuning the classification baselines for other vision tasks. to this end, we experiment with three different baselines to develop image quality assessment (iqa) models on the ava dataset [24].",https://arxiv.org/pdf/2103.09950
4ec9edd7b2e3eb9b93ed131e1753bd403e2354f8,Tensor Methods in Computer Vision and Deep Learning,"Tensors, or multidimensional arrays, are data structures that can naturally represent visual data of multiple dimensions. Inherently able to efficiently capture structured, latent semantic spaces and high-order interactions, tensors have a long history of applications in a wide span of computer vision problems. With the advent of the deep learning paradigm shift in computer vision, tensors have become even more fundamental. Indeed, essential ingredients in modern deep learning architectures, such as convolutions and attention mechanisms, can readily be considered as tensor mappings. In effect, tensor methods are increasingly finding significant applications in deep learning, including the design of memory and compute efficient network architectures, improving robustness to random noise and adversarial attacks, and aiding the theoretical understanding of deep networks. This article provides an in-depth and practical review of tensors and tensor methods in the context of representation learning and deep learning, with a particular focus on visual data analysis and computer vision applications. Concretely, besides fundamental work in tensor-based visual data analysis methods, we focus on recent developments that have brought on a gradual increase in tensor methods, especially in deep learning architectures and their implications in computer vision applications. To further enable the newcomer to grasp such concepts quickly, we provide companion Python notebooks, covering key aspects of this article and implementing them, step-by-step with TensorLy.",2021,"[{'authorId': '1780393', 'name': 'Yannis Panagakis'}, {'authorId': '3125761', 'name': 'Jean Kossaifi'}, {'authorId': '34586458', 'name': 'Grigorios G. Chrysos'}, {'authorId': '2059960629', 'name': 'James Oldfield'}, {'authorId': '1752913', 'name': 'M. Nicolaou'}, {'authorId': '2047844', 'name': 'Anima Anandkumar'}, {'authorId': '1776444', 'name': 'S. Zafeiriou'}]","{'url': 'https://authors.library.caltech.edu/records/gaad6-9qt19/files/2107.03436.pdf?download=1', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2107.03436, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","tensors, or multidimensional arrays, are data structures that can naturally represent visual data of multiple dimensions. inherently able to efficiently capture structured, latent semantic spaces and high-order interactions, tensors have a long history of applications in a wide span of computer vision problems. with the advent of the deep learning paradigm shift in computer vision, tensors have become even more fundamental. indeed, essential ingredients in modern deep learning architectures, such as convolutions and attention mechanisms, can readily be considered as tensor mappings. in effect, tensor methods are increasingly finding significant applications in deep learning, including the design of memory and compute efficient network architectures, improving robustness to random noise and adversarial attacks, and aiding the theoretical understanding of deep networks. this article provides an in-depth and practical review of tensors and tensor methods in the context of representation learning and deep learning, with a particular focus on visual data analysis and computer vision applications. concretely, besides fundamental work in tensor-based visual data analysis methods, we focus on recent developments that have brought on a gradual increase in tensor methods, especially in deep learning architectures and their implications in computer vision applications. to further enable the newcomer to grasp such concepts quickly, we provide companion python notebooks, covering key aspects of this article and implementing them, step-by-step with tensorly.",https://authors.library.caltech.edu/records/gaad6-9qt19/files/2107.03436.pdf?download=1
5f40686bd093728e0ddcb267039572d6eeb12457,Practices and Applications of Convolutional Neural Network-Based Computer Vision Systems in Animal Farming: A Review,"Convolutional neural network (CNN)-based computer vision systems have been increasingly applied in animal farming to improve animal management, but current knowledge, practices, limitations, and solutions of the applications remain to be expanded and explored. The objective of this study is to systematically review applications of CNN-based computer vision systems on animal farming in terms of the five deep learning computer vision tasks: image classification, object detection, semantic/instance segmentation, pose estimation, and tracking. Cattle, sheep/goats, pigs, and poultry were the major farm animal species of concern. In this research, preparations for system development, including camera settings, inclusion of variations for data recordings, choices of graphics processing units, image preprocessing, and data labeling were summarized. CNN architectures were reviewed based on the computer vision tasks in animal farming. Strategies of algorithm development included distribution of development data, data augmentation, hyperparameter tuning, and selection of evaluation metrics. Judgment of model performance and performance based on architectures were discussed. Besides practices in optimizing CNN-based computer vision systems, system applications were also organized based on year, country, animal species, and purposes. Finally, recommendations on future research were provided to develop and improve CNN-based computer vision systems for improved welfare, environment, engineering, genetics, and management of farm animals.",2021,"[{'authorId': '47949516', 'name': 'Guoming Li'}, {'authorId': '2145432632', 'name': 'Yanbo Huang'}, {'authorId': '2051964675', 'name': 'Zhiqian Chen'}, {'authorId': '1381451508', 'name': 'G. D. Chesser'}, {'authorId': '6972682', 'name': 'J. Purswell'}, {'authorId': '89370261', 'name': 'J. Linhoss'}, {'authorId': '2118834154', 'name': 'Yang Zhao'}]","{'url': 'https://www.mdpi.com/1424-8220/21/4/1492/pdf?version=1614326070', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7926480, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","convolutional neural network (cnn)-based computer vision systems have been increasingly applied in animal farming to improve animal management, but current knowledge, practices, limitations, and solutions of the applications remain to be expanded and explored. the objective of this study is to systematically review applications of cnn-based computer vision systems on animal farming in terms of the five deep learning computer vision tasks: image classification, object detection, semantic/instance segmentation, pose estimation, and tracking. cattle, sheep/goats, pigs, and poultry were the major farm animal species of concern. in this research, preparations for system development, including camera settings, inclusion of variations for data recordings, choices of graphics processing units, image preprocessing, and data labeling were summarized. cnn architectures were reviewed based on the computer vision tasks in animal farming. strategies of algorithm development included distribution of development data, data augmentation, hyperparameter tuning, and selection of evaluation metrics. judgment of model performance and performance based on architectures were discussed. besides practices in optimizing cnn-based computer vision systems, system applications were also organized based on year, country, animal species, and purposes. finally, recommendations on future research were provided to develop and improve cnn-based computer vision systems for improved welfare, environment, engineering, genetics, and management of farm animals.",https://www.mdpi.com/1424-8220/21/4/1492/pdf?version=1614326070
ec5094f9f0ca1b349f00539306ec842c1a4ea535,Unity Perception: Generate Synthetic Data for Computer Vision,"We introduce the Unity Perception package which aims to simplify and accelerate the process of generating synthetic datasets for computer vision tasks by offering an easy-to-use and highly customizable toolset. This open-source package extends the Unity Editor and engine components to generate perfectly annotated examples for several common computer vision tasks. Additionally, it offers an extensible Randomization framework that lets the user quickly construct and configure randomized simulation parameters in order to introduce variation into the generated datasets. We provide an overview of the provided tools and how they work, and demonstrate the value of the generated synthetic datasets by training a 2D object detection model. The model trained with mostly synthetic data outperforms the model trained using only real data.",2021,"[{'authorId': '69451765', 'name': 'S. Borkman'}, {'authorId': '68973547', 'name': 'A. Crespi'}, {'authorId': '2060909485', 'name': 'S. Dhakad'}, {'authorId': '6347014', 'name': 'Sujoy Ganguly'}, {'authorId': '2118832929', 'name': 'Jonathan Hogins'}, {'authorId': '102083558', 'name': 'Y. Jhang'}, {'authorId': '3065320', 'name': 'Mohsen Kamalzadeh'}, {'authorId': '2132475639', 'name': 'Bowen Li'}, {'authorId': '2118876490', 'name': 'Steven Leal'}, {'authorId': '2118872082', 'name': 'Pete Parisi'}, {'authorId': '2118870845', 'name': 'Cesar Romero'}, {'authorId': '2148597253', 'name': 'Wesley Smith'}, {'authorId': '2118881121', 'name': 'Alex Thaman'}, {'authorId': '2119161385', 'name': 'Samuel Warren'}, {'authorId': '2118871896', 'name': 'Nupur Yadav'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2107.04259, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we introduce the unity perception package which aims to simplify and accelerate the process of generating synthetic datasets for computer vision tasks by offering an easy-to-use and highly customizable toolset. this open-source package extends the unity editor and engine components to generate perfectly annotated examples for several common computer vision tasks. additionally, it offers an extensible randomization framework that lets the user quickly construct and configure randomized simulation parameters in order to introduce variation into the generated datasets. we provide an overview of the provided tools and how they work, and demonstrate the value of the generated synthetic datasets by training a 2d object detection model. the model trained with mostly synthetic data outperforms the model trained using only real data.",
15d6e1512089b07a66a3e5260848359cad79dbca,Recent Advances of Continual Learning in Computer Vision: An Overview,"In contrast to batch learning where all training data is available at once, continual learning represents a family of methods that accumulate knowledge and learn continuously with data available in sequential order. Similar to the human learning process with the ability of learning, fusing and accumulating new knowledge acquired at different time steps, continual learning is considered to have high practical significance. Hence, continual learning has been studied in various artificial intelligence tasks. In this paper, we present a comprehensive review of the recent progress of continual learning in computer vision. In particular, the works are grouped by their representative techniques, including regularisation, knowledge distillation, memory, generative replay, parameter isolation and a combination of the above techniques. For each category of these techniques, both its characteristics and applications in computer vision are presented. At the end of this overview, several subareas, where continuous knowledge accumulation is potentially helpful while continual learning has not been well studied, are discussed.",2021,"[{'authorId': '2149526655', 'name': 'Haoxuan Qu'}, {'authorId': '151475004', 'name': 'Hossein Rahmani'}, {'authorId': '2112318242', 'name': 'Li Xu'}, {'authorId': '2125614516', 'name': 'Bryan M. Williams'}, {'authorId': '9756930', 'name': 'Jun Liu'}]","{'url': 'https://doi.org/10.1049/cvi2.70013', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2109.11369, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in contrast to batch learning where all training data is available at once, continual learning represents a family of methods that accumulate knowledge and learn continuously with data available in sequential order. similar to the human learning process with the ability of learning, fusing and accumulating new knowledge acquired at different time steps, continual learning is considered to have high practical significance. hence, continual learning has been studied in various artificial intelligence tasks. in this paper, we present a comprehensive review of the recent progress of continual learning in computer vision. in particular, the works are grouped by their representative techniques, including regularisation, knowledge distillation, memory, generative replay, parameter isolation and a combination of the above techniques. for each category of these techniques, both its characteristics and applications in computer vision are presented. at the end of this overview, several subareas, where continuous knowledge accumulation is potentially helpful while continual learning has not been well studied, are discussed.",https://doi.org/10.1049/cvi2.70013
4fd9bc4c8622ffdb8ee44444173472561bd660df,Deep learning and computer vision will transform entomology,"Most animal species on Earth are insects, and recent reports suggest that their abundance is in drastic decline. Although these reports come from a wide range of insect taxa and regions, the evidence to assess the extent of the phenomenon is sparse. Insect populations are challenging to study, and most monitoring methods are labor intensive and inefficient. Advances in computer vision and deep learning provide potential new solutions to this global challenge. Cameras and other sensors can effectively, continuously, and noninvasively perform entomological observations throughout diurnal and seasonal cycles. The physical appearance of specimens can also be captured by automated imaging in the laboratory. When trained on these data, deep learning models can provide estimates of insect abundance, biomass, and diversity. Further, deep learning models can quantify variation in phenotypic traits, behavior, and interactions. Here, we connect recent developments in deep learning and computer vision to the urgent demand for more cost-efficient monitoring of insects and other invertebrates. We present examples of sensor-based monitoring of insects. We show how deep learning tools can be applied to exceptionally large datasets to derive ecological information and discuss the challenges that lie ahead for the implementation of such solutions in entomology. We identify four focal areas, which will facilitate this transformation: 1) validation of image-based taxonomic identification; 2) generation of sufficient training data; 3) development of public, curated reference databases; and 4) solutions to integrate deep learning and molecular tools.",2020,"[{'authorId': '1403067350', 'name': 'T. Høye'}, {'authorId': '92505853', 'name': 'J. Ärje'}, {'authorId': '2130652', 'name': 'K. Bjerge'}, {'authorId': '34210665', 'name': 'O. L. P. Hansen'}, {'authorId': '3074923', 'name': 'Alexandros Iosifidis'}, {'authorId': '2081855', 'name': 'F. Leese'}, {'authorId': '1796326231', 'name': 'Hjalte M. R. Mann'}, {'authorId': '48338905', 'name': 'Kristian Meissner'}, {'authorId': '90927515', 'name': 'C. Melvad'}, {'authorId': '2495016', 'name': 'Jenni Raitoharju'}]","{'url': 'https://www.pnas.org/content/pnas/118/2/e2002545117.full.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1101/2020.07.03.187252?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1101/2020.07.03.187252, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","most animal species on earth are insects, and recent reports suggest that their abundance is in drastic decline. although these reports come from a wide range of insect taxa and regions, the evidence to assess the extent of the phenomenon is sparse. insect populations are challenging to study, and most monitoring methods are labor intensive and inefficient. advances in computer vision and deep learning provide potential new solutions to this global challenge. cameras and other sensors can effectively, continuously, and noninvasively perform entomological observations throughout diurnal and seasonal cycles. the physical appearance of specimens can also be captured by automated imaging in the laboratory. when trained on these data, deep learning models can provide estimates of insect abundance, biomass, and diversity. further, deep learning models can quantify variation in phenotypic traits, behavior, and interactions. here, we connect recent developments in deep learning and computer vision to the urgent demand for more cost-efficient monitoring of insects and other invertebrates. we present examples of sensor-based monitoring of insects. we show how deep learning tools can be applied to exceptionally large datasets to derive ecological information and discuss the challenges that lie ahead for the implementation of such solutions in entomology. we identify four focal areas, which will facilitate this transformation: 1) validation of image-based taxonomic identification; 2) generation of sufficient training data; 3) development of public, curated reference databases; and 4) solutions to integrate deep learning and molecular tools.",https://www.pnas.org/content/pnas/118/2/e2002545117.full.pdf
d1f64cf30613f073989df7edb3241f9d2b86d063,Computer Vision Techniques in Manufacturing,"Computer vision (CV) techniques have played an important role in promoting the informatization, digitization, and intelligence of industrial manufacturing systems. Considering the rapid development of CV techniques, we present a comprehensive review of the state of the art of these techniques and their applications in manufacturing industries. We survey the most common methods, including feature detection, recognition, segmentation, and three-dimensional modeling. A system framework of CV in the manufacturing environment is proposed, consisting of a lighting module, a manufacturing system, a sensing module, CV algorithms, a decision-making module, and an actuator. Applications of CV to different stages of the entire product life cycle are then explored, including product design, modeling and simulation, planning and scheduling, the production process, inspection and quality control, assembly, transportation, and disassembly. Challenges include algorithm implementation, data preprocessing, data labeling, and benchmarks. Future directions include building benchmarks, developing methods for nonannotated data processing, developing effective data preprocessing mechanisms, customizing CV models, and opportunities aroused by 5G.",2021,"[{'authorId': '8009148', 'name': 'Longfei Zhou'}, {'authorId': '2155488841', 'name': 'Lin Zhang'}, {'authorId': '2092037701', 'name': 'N. Konz'}]","{'url': 'https://www.techrxiv.org/articles/preprint/Computer_Vision_Techniques_in_Manufacturing/17125652/2/files/35020939.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TSMC.2022.3166397?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TSMC.2022.3166397, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","computer vision (cv) techniques have played an important role in promoting the informatization, digitization, and intelligence of industrial manufacturing systems. considering the rapid development of cv techniques, we present a comprehensive review of the state of the art of these techniques and their applications in manufacturing industries. we survey the most common methods, including feature detection, recognition, segmentation, and three-dimensional modeling. a system framework of cv in the manufacturing environment is proposed, consisting of a lighting module, a manufacturing system, a sensing module, cv algorithms, a decision-making module, and an actuator. applications of cv to different stages of the entire product life cycle are then explored, including product design, modeling and simulation, planning and scheduling, the production process, inspection and quality control, assembly, transportation, and disassembly. challenges include algorithm implementation, data preprocessing, data labeling, and benchmarks. future directions include building benchmarks, developing methods for nonannotated data processing, developing effective data preprocessing mechanisms, customizing cv models, and opportunities aroused by 5g.",https://www.techrxiv.org/articles/preprint/Computer_Vision_Techniques_in_Manufacturing/17125652/2/files/35020939.pdf
de2d4b3ab30585597b40ede0199a218e829b2986,Computer vision syndrome,"Kemajuan di bidang teknologi saat ini menyebabkan tingginya pengguna perangkat elektronik pada semua kelompok umur. Terdapat perbedaan kebutuhan visual ketika seseorang melihat tampilan dilayar perangkat elektronik dibandingkan dengan materi cetak. Mata harus bekerja lebih keras saat melihat tampilan di layar perangkat elektronik, sehingga penggunaan perangkat elektronik dalam waktu lama dapat menyebabkan sekelompok keluhan pada mata yaitu kelelahan mata, iritasi, kemerahan, kekeringan, penglihatan kabur dan ganda yang disebut juga dengan computer vision syndrome. Menghilangkan faktor penyebab merupakan pengelolaan paling penting dalam mengatasi computer vision syndrome. Tinjauan pustaka ini bertujuan untuk menganalisis informasi terkini tentang prevalensi, gejala, patogenesis dan penatalaksanaan computer vision syndrome. Kesimpulan dari studi ini yaitu computer vision syndrome merupakan salah satu masalah kesehatan masyarakat utama yang berdampak besar pada penurunan kualitas hidup dan efisiensi di tempat kerja yang dapat dicegah dengan pemeriksaan mata rutin, menjaga kesehatan mata, posisi ergonomis dan lingkungan yang mendukung.",2020,"[{'authorId': '2247541388', 'name': 'Daniel Bell'}, {'authorId': '2146682231', 'name': 'Candace Moore'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1201/9781420032055-4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1201/9781420032055-4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","kemajuan di bidang teknologi saat ini menyebabkan tingginya pengguna perangkat elektronik pada semua kelompok umur. terdapat perbedaan kebutuhan visual ketika seseorang melihat tampilan dilayar perangkat elektronik dibandingkan dengan materi cetak. mata harus bekerja lebih keras saat melihat tampilan di layar perangkat elektronik, sehingga penggunaan perangkat elektronik dalam waktu lama dapat menyebabkan sekelompok keluhan pada mata yaitu kelelahan mata, iritasi, kemerahan, kekeringan, penglihatan kabur dan ganda yang disebut juga dengan computer vision syndrome. menghilangkan faktor penyebab merupakan pengelolaan paling penting dalam mengatasi computer vision syndrome. tinjauan pustaka ini bertujuan untuk menganalisis informasi terkini tentang prevalensi, gejala, patogenesis dan penatalaksanaan computer vision syndrome. kesimpulan dari studi ini yaitu computer vision syndrome merupakan salah satu masalah kesehatan masyarakat utama yang berdampak besar pada penurunan kualitas hidup dan efisiensi di tempat kerja yang dapat dicegah dengan pemeriksaan mata rutin, menjaga kesehatan mata, posisi ergonomis dan lingkungan yang mendukung.",
b8cb9c0b02da96a9908665ae67692a6da4dd25a4,SCENIC: A JAX Library for Computer Vision Research and Beyond,"Scenic is an open-source11https://github.com/google-research/scenic JAX library with a focus on transformer-based models for computer vision research and beyond. The goal of this toolkit is to facilitate rapid experimentation, prototyping, and research of new architectures and models. Scenic supports a diverse range of tasks (e.g., classification, segmentation, detection) and facilitates working on multi-modal problems, along with GPU/TPU support for large-scale, multi-host and multi-device training. Scenic also offers optimized implementations of state-of-the-art research models spanning a wide range of modalities. Scenic has been successfully used for numerous projects and published papers and continues serving as the library of choice for rapid prototyping and publication of new research ideas.",2021,"[{'authorId': '3226635', 'name': 'Mostafa Dehghani'}, {'authorId': '2194424', 'name': 'A. Gritsenko'}, {'authorId': '31638576', 'name': 'Anurag Arnab'}, {'authorId': '46352821', 'name': 'Matthias Minderer'}, {'authorId': '97947517', 'name': 'Yi Tay'}]","{'url': 'https://arxiv.org/pdf/2110.11403', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2110.11403, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","scenic is an open-source11https://github.com/google-research/scenic jax library with a focus on transformer-based models for computer vision research and beyond. the goal of this toolkit is to facilitate rapid experimentation, prototyping, and research of new architectures and models. scenic supports a diverse range of tasks (e.g., classification, segmentation, detection) and facilitates working on multi-modal problems, along with gpu/tpu support for large-scale, multi-host and multi-device training. scenic also offers optimized implementations of state-of-the-art research models spanning a wide range of modalities. scenic has been successfully used for numerous projects and published papers and continues serving as the library of choice for rapid prototyping and publication of new research ideas.",https://arxiv.org/pdf/2110.11403
95e74beb9f54e0312f7356391ba7c699b05ebdb0,A survey on generative adversarial networks for imbalance problems in computer vision tasks,"Any computer vision application development starts off by acquiring images and data, then preprocessing and pattern recognition steps to perform a task. When the acquired images are highly imbalanced and not adequate, the desired task may not be achievable. Unfortunately, the occurrence of imbalance problems in acquired image datasets in certain complex real-world problems such as anomaly detection, emotion recognition, medical image analysis, fraud detection, metallic surface defect detection, disaster prediction, etc., are inevitable. The performance of computer vision algorithms can significantly deteriorate when the training dataset is imbalanced. In recent years, Generative Adversarial Neural Networks (GANs) have gained immense attention by researchers across a variety of application domains due to their capability to model complex real-world image data. It is particularly important that GANs can not only be used to generate synthetic images, but also its fascinating adversarial learning idea showed good potential in restoring balance in imbalanced datasets. In this paper, we examine the most recent developments of GANs based techniques for addressing imbalance problems in image data. The real-world challenges and implementations of synthetic image generation based on GANs are extensively covered in this survey. Our survey first introduces various imbalance problems in computer vision tasks and its existing solutions, and then examines key concepts such as deep generative image models and GANs. After that, we propose a taxonomy to summarize GANs based techniques for addressing imbalance problems in computer vision tasks into three major categories: 1. Image level imbalances in classification, 2. object level imbalances in object detection and 3. pixel level imbalances in segmentation tasks. We elaborate the imbalance problems of each group, and provide GANs based solutions in each group. Readers will understand how GANs based techniques can handle the problem of imbalances and boost performance of the computer vision algorithms.",2020,"[{'authorId': '2093752362', 'name': 'Vignesh Sampath'}, {'authorId': '1765904', 'name': 'I. Maurtua'}, {'authorId': '96734640', 'name': 'Juan José Aguilar Martín'}, {'authorId': '2068311795', 'name': 'Aitor Gutierrez'}]","{'url': 'https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-021-00414-0', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7845583, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","any computer vision application development starts off by acquiring images and data, then preprocessing and pattern recognition steps to perform a task. when the acquired images are highly imbalanced and not adequate, the desired task may not be achievable. unfortunately, the occurrence of imbalance problems in acquired image datasets in certain complex real-world problems such as anomaly detection, emotion recognition, medical image analysis, fraud detection, metallic surface defect detection, disaster prediction, etc., are inevitable. the performance of computer vision algorithms can significantly deteriorate when the training dataset is imbalanced. in recent years, generative adversarial neural networks (gans) have gained immense attention by researchers across a variety of application domains due to their capability to model complex real-world image data. it is particularly important that gans can not only be used to generate synthetic images, but also its fascinating adversarial learning idea showed good potential in restoring balance in imbalanced datasets. in this paper, we examine the most recent developments of gans based techniques for addressing imbalance problems in image data. the real-world challenges and implementations of synthetic image generation based on gans are extensively covered in this survey. our survey first introduces various imbalance problems in computer vision tasks and its existing solutions, and then examines key concepts such as deep generative image models and gans. after that, we propose a taxonomy to summarize gans based techniques for addressing imbalance problems in computer vision tasks into three major categories: 1. image level imbalances in classification, 2. object level imbalances in object detection and 3. pixel level imbalances in segmentation tasks. we elaborate the imbalance problems of each group, and provide gans based solutions in each group. readers will understand how gans based techniques can handle the problem of imbalances and boost performance of the computer vision algorithms.",https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-021-00414-0
934d7bffdba0b560a80a518b99a791a16b3e198c,A Fourier Perspective on Model Robustness in Computer Vision,"Achieving robustness to distributional shift is a longstanding and challenging goal of computer vision. Data augmentation is a commonly used approach for improving robustness, however robustness gains are typically not uniform across corruption types. Indeed increasing performance in the presence of random noise is often met with reduced performance on other corruptions such as contrast change. Understanding when and why these sorts of trade-offs occur is a crucial step towards mitigating them. Towards this end, we investigate recently observed trade-offs caused by Gaussian data augmentation and adversarial training. We find that both methods improve robustness to corruptions that are concentrated in the high frequency domain while reducing robustness to corruptions that are concentrated in the low frequency domain. This suggests that one way to mitigate these trade-offs via data augmentation is to use a more diverse set of augmentations. Towards this end we observe that AutoAugment, a recently proposed data augmentation policy optimized for clean accuracy, achieves state-of-the-art robustness on the CIFAR-10-C benchmark.",2019,"[{'authorId': '50559902', 'name': 'Dong Yin'}, {'authorId': '143826364', 'name': 'Raphael Gontijo Lopes'}, {'authorId': '1789737', 'name': 'Jonathon Shlens'}, {'authorId': '8132903', 'name': 'E. D. Cubuk'}, {'authorId': '2058362', 'name': 'J. Gilmer'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1906.08988, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","achieving robustness to distributional shift is a longstanding and challenging goal of computer vision. data augmentation is a commonly used approach for improving robustness, however robustness gains are typically not uniform across corruption types. indeed increasing performance in the presence of random noise is often met with reduced performance on other corruptions such as contrast change. understanding when and why these sorts of trade-offs occur is a crucial step towards mitigating them. towards this end, we investigate recently observed trade-offs caused by gaussian data augmentation and adversarial training. we find that both methods improve robustness to corruptions that are concentrated in the high frequency domain while reducing robustness to corruptions that are concentrated in the low frequency domain. this suggests that one way to mitigate these trade-offs via data augmentation is to use a more diverse set of augmentations. towards this end we observe that autoaugment, a recently proposed data augmentation policy optimized for clean accuracy, achieves state-of-the-art robustness on the cifar-10-c benchmark.",
92e4ef5575f3f22f3f22526cd1fdfd2d0397d094,Deep Learning vs. Traditional Computer Vision,"Deep Learning has pushed the limits of what was possible in the domain of Digital Image Processing. However, that is not to say that the traditional computer vision techniques which had been undergoing progressive development in years prior to the rise of DL have become obsolete. This paper will analyse the benefits and drawbacks of each approach. The aim of this paper is to promote a discussion on whether knowledge of classical computer vision techniques should be maintained. The paper will also explore how the two sides of computer vision can be combined. Several recent hybrid methodologies are reviewed which have demonstrated the ability to improve computer vision performance and to tackle problems not suited to Deep Learning. For example, combining traditional computer vision techniques with Deep Learning has been popular in emerging domains such as Panoramic Vision and 3D vision for which Deep Learning models have not yet been fully optimised.",2019,"[{'authorId': '3692743', 'name': ""Niall O' Mahony""}, {'authorId': '145911154', 'name': 'S. Campbell'}, {'authorId': '133574842', 'name': 'A. Carvalho'}, {'authorId': '116338962', 'name': 'S. Harapanahalli'}, {'authorId': '1390095040', 'name': 'G. Velasco-Hernández'}, {'authorId': '15909050', 'name': 'L. Krpalkova'}, {'authorId': '50207148', 'name': 'Daniel Riordan'}, {'authorId': '145975195', 'name': 'Joseph Walsh'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1910.13796, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep learning has pushed the limits of what was possible in the domain of digital image processing. however, that is not to say that the traditional computer vision techniques which had been undergoing progressive development in years prior to the rise of dl have become obsolete. this paper will analyse the benefits and drawbacks of each approach. the aim of this paper is to promote a discussion on whether knowledge of classical computer vision techniques should be maintained. the paper will also explore how the two sides of computer vision can be combined. several recent hybrid methodologies are reviewed which have demonstrated the ability to improve computer vision performance and to tackle problems not suited to deep learning. for example, combining traditional computer vision techniques with deep learning has been popular in emerging domains such as panoramic vision and 3d vision for which deep learning models have not yet been fully optimised.",
308a1e7d4f33ca251e075347bbe11c2ef9381714,HoloLens 2 Research Mode as a Tool for Computer Vision Research,"Mixed reality headsets, such as the Microsoft HoloLens 2, are powerful sensing devices with integrated compute capabilities, which makes it an ideal platform for computer vision research. In this technical report, we present HoloLens 2 Research Mode, an API and a set of tools enabling access to the raw sensor streams. We provide an overview of the API and explain how it can be used to build mixed reality applications based on processing sensor data. We also show how to combine the Research Mode sensor data with the built-in eye and hand tracking capabilities provided by HoloLens 2. By releasing the Research Mode API and a set of open-source tools, we aim to foster further research in the fields of computer vision as well as robotics and encourage contributions from the research community.",2020,"[{'authorId': '153210127', 'name': 'Dorin Ungureanu'}, {'authorId': '2988774', 'name': 'Federica Bogo'}, {'authorId': '2762033', 'name': 'Silvano Galliani'}, {'authorId': '1908421546', 'name': 'Pooja Sama'}, {'authorId': '2067780931', 'name': 'Xin Duan'}, {'authorId': '1830693', 'name': 'Casey Meekhof'}, {'authorId': '2438339', 'name': 'Jan Stühmer'}, {'authorId': '29688302', 'name': 'T. Cashman'}, {'authorId': '39307390', 'name': 'Bugra Tekin'}, {'authorId': '3010882', 'name': 'Johannes L. Schönberger'}, {'authorId': '1908486645', 'name': 'Pawel Olszta'}, {'authorId': '1742208', 'name': 'M. Pollefeys'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2008.11239, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mixed reality headsets, such as the microsoft hololens 2, are powerful sensing devices with integrated compute capabilities, which makes it an ideal platform for computer vision research. in this technical report, we present hololens 2 research mode, an api and a set of tools enabling access to the raw sensor streams. we provide an overview of the api and explain how it can be used to build mixed reality applications based on processing sensor data. we also show how to combine the research mode sensor data with the built-in eye and hand tracking capabilities provided by hololens 2. by releasing the research mode api and a set of open-source tools, we aim to foster further research in the fields of computer vision as well as robotics and encourage contributions from the research community.",
c8726966d87a2719b1726cedadd323874742083b,COVID-19 Control by Computer Vision Approaches: A Survey,"The COVID-19 pandemic has triggered an urgent call to contribute to the fight against an immense threat to the human population. Computer Vision, as a subfield of artificial intelligence, has enjoyed recent success in solving various complex problems in health care and has the potential to contribute to the fight of controlling COVID-19. In response to this call, computer vision researchers are putting their knowledge base at test to devise effective ways to counter COVID-19 challenge and serve the global community. New contributions are being shared with every passing day. It motivated us to review the recent work, collect information about available research resources, and an indication of future research directions. We want to make it possible for computer vision researchers to find existing and future research directions. This survey article presents a preliminary review of the literature on research community efforts against COVID-19 pandemic.",2020,"[{'authorId': '35035828', 'name': 'A. Ulhaq'}, {'authorId': '2062641025', 'name': 'Jannis Born'}, {'authorId': '1992746329', 'name': 'Asim Khan'}, {'authorId': '2060299012', 'name': 'D. Gomes'}, {'authorId': '1889816', 'name': 'Subrata Chakraborty'}, {'authorId': '145328424', 'name': 'M. Paul'}]","{'url': 'https://doi.org/10.1109/access.2020.3027685', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2004.09420, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the covid-19 pandemic has triggered an urgent call to contribute to the fight against an immense threat to the human population. computer vision, as a subfield of artificial intelligence, has enjoyed recent success in solving various complex problems in health care and has the potential to contribute to the fight of controlling covid-19. in response to this call, computer vision researchers are putting their knowledge base at test to devise effective ways to counter covid-19 challenge and serve the global community. new contributions are being shared with every passing day. it motivated us to review the recent work, collect information about available research resources, and an indication of future research directions. we want to make it possible for computer vision researchers to find existing and future research directions. this survey article presents a preliminary review of the literature on research community efforts against covid-19 pandemic.",https://doi.org/10.1109/access.2020.3027685
a23fbf6e7c224e696662b948163cb27e52188356,Events-To-Video: Bringing Modern Computer Vision to Event Cameras,"Event cameras are novel sensors that report brightness changes in the form of asynchronous ""events"" instead of intensity frames. They have significant advantages over conventional cameras: high temporal resolution, high dynamic range, and no motion blur. Since the output of event cameras is fundamentally different from conventional cameras, it is commonly accepted that they require the development of specialized algorithms to accommodate the particular nature of events. In this work, we take a different view and propose to apply existing, mature computer vision techniques to videos reconstructed from event data. We propose a novel, recurrent neural network to reconstruct videos from a stream of events and train it on a large amount of simulated event data. Our experiments show that our approach surpasses state-of-the-art reconstruction methods by a large margin (> 20%) in terms of image quality. We further apply off-the-shelf computer vision algorithms to videos reconstructed from event data on tasks such as object classification and visual-inertial odometry, and show that this strategy consistently outperforms algorithms that were specifically designed for event data. We believe that our approach opens the door to bringing the outstanding properties of event cameras to an entirely new range of tasks.",2019,"[{'authorId': '3414274', 'name': 'Henri Rebecq'}, {'authorId': '2774325', 'name': 'René Ranftl'}, {'authorId': '145231047', 'name': 'V. Koltun'}, {'authorId': '2075371', 'name': 'D. Scaramuzza'}]","{'url': 'https://www.zora.uzh.ch/id/eprint/197731/1/CVPR19_Rebecq.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1904.08298, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","event cameras are novel sensors that report brightness changes in the form of asynchronous ""events"" instead of intensity frames. they have significant advantages over conventional cameras: high temporal resolution, high dynamic range, and no motion blur. since the output of event cameras is fundamentally different from conventional cameras, it is commonly accepted that they require the development of specialized algorithms to accommodate the particular nature of events. in this work, we take a different view and propose to apply existing, mature computer vision techniques to videos reconstructed from event data. we propose a novel, recurrent neural network to reconstruct videos from a stream of events and train it on a large amount of simulated event data. our experiments show that our approach surpasses state-of-the-art reconstruction methods by a large margin (> 20%) in terms of image quality. we further apply off-the-shelf computer vision algorithms to videos reconstructed from event data on tasks such as object classification and visual-inertial odometry, and show that this strategy consistently outperforms algorithms that were specifically designed for event data. we believe that our approach opens the door to bringing the outstanding properties of event cameras to an entirely new range of tasks.",https://www.zora.uzh.ch/id/eprint/197731/1/CVPR19_Rebecq.pdf
5f6fccc32953f57fe29b2316eb8351e84b0179dc,The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models,"The computer vision world has been re-gaining enthusiasm in various pre-trained models, including both classical ImageNet supervised pre-training and recently emerged self-supervised pre-training such as simCLR [10] and MoCo [40]. Pre-trained weights often boost a wide range of downstream tasks including classification, detection, and segmentation. Latest studies suggest that pre-training benefits from gigantic model capacity [11]. We are hereby curious and ask: after pre-training, does a pre-trained model indeed have to stay large for its downstream transferability? In this paper, we examine supervised and self-supervised pre-trained models through the lens of the lottery ticket hypothesis (LTH) [31]. LTH identifies highly sparse matching subnetworks that can be trained in isolation from (nearly) scratch yet still reach the full models' performance. We extend the scope of LTH and question whether matching subnetworks still exist in pre-trained computer vision models, that enjoy the same downstream transfer performance. Our extensive experiments convey an overall positive message: from all pre-trained weights obtained by ImageNet classification, simCLR, and MoCo, we are consistently able to locate such matching subnetworks at 59.04% to 96.48% sparsity that transfer universally to multiple downstream tasks, whose performance see no degradation compared to using full pre-trained weights. Further analyses reveal that subnetworks found from different pre-training tend to yield diverse mask structures and perturbation sensitivities. We conclude that the core LTH observations remain generally relevant in the pre-training paradigm of computer vision, but more delicate discussions are needed in some cases. Codes and pre-trained models will be made available at: https://github.com/VITA-Group/CV_LTH_Pre-training.",2020,"[{'authorId': '2648459', 'name': 'Tianlong Chen'}, {'authorId': '25581960', 'name': 'Jonathan Frankle'}, {'authorId': '3307026', 'name': 'Shiyu Chang'}, {'authorId': '30986714', 'name': 'Sijia Liu'}, {'authorId': '37873860', 'name': 'Yang Zhang'}, {'authorId': '1701041', 'name': 'Michael Carbin'}, {'authorId': '2969311', 'name': 'Zhangyang Wang'}]","{'url': 'https://arxiv.org/pdf/2012.06908', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2012.06908, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the computer vision world has been re-gaining enthusiasm in various pre-trained models, including both classical imagenet supervised pre-training and recently emerged self-supervised pre-training such as simclr [10] and moco [40]. pre-trained weights often boost a wide range of downstream tasks including classification, detection, and segmentation. latest studies suggest that pre-training benefits from gigantic model capacity [11]. we are hereby curious and ask: after pre-training, does a pre-trained model indeed have to stay large for its downstream transferability? in this paper, we examine supervised and self-supervised pre-trained models through the lens of the lottery ticket hypothesis (lth) [31]. lth identifies highly sparse matching subnetworks that can be trained in isolation from (nearly) scratch yet still reach the full models' performance. we extend the scope of lth and question whether matching subnetworks still exist in pre-trained computer vision models, that enjoy the same downstream transfer performance. our extensive experiments convey an overall positive message: from all pre-trained weights obtained by imagenet classification, simclr, and moco, we are consistently able to locate such matching subnetworks at 59.04% to 96.48% sparsity that transfer universally to multiple downstream tasks, whose performance see no degradation compared to using full pre-trained weights. further analyses reveal that subnetworks found from different pre-training tend to yield diverse mask structures and perturbation sensitivities. we conclude that the core lth observations remain generally relevant in the pre-training paradigm of computer vision, but more delicate discussions are needed in some cases. codes and pre-trained models will be made available at: https://github.com/vita-group/cv_lth_pre-training.",https://arxiv.org/pdf/2012.06908
5dbd7c2ba7bc494e94e840241d7d5468b230e78f,Fabric Defect Detection Using Computer Vision Techniques: A Comprehensive Review,"There are different applications of computer vision and digital image processing in various applied domains and automated production process. In textile industry, fabric defect detection is considered as a challenging task as the quality and the price of any textile product are dependent on the efficiency and effectiveness of the automatic defect detection. Previously, manual human efforts are applied in textile industry to detect the defects in the fabric production process. Lack of concentration, human fatigue, and time consumption are the main drawbacks associated with the manual fabric defect detection process. Applications based on computer vision and digital image processing can address the abovementioned limitations and drawbacks. Since the last two decades, various computer vision-based applications are proposed in various research articles to address these limitations. In this review article, we aim to present a detailed study about various computer vision-based approaches with application in textile industry to detect fabric defects. The proposed study presents a detailed overview of histogram-based approaches, color-based approaches, image segmentation-based approaches, frequency domain operations, texture-based defect detection, sparse feature-based operation, image morphology operations, and recent trends of deep learning. The performance evaluation criteria for automatic fabric defect detection is also presented and discussed. The drawbacks and limitations associated with the existing published research are discussed in detail, and possible future research directions are also mentioned. This research study provides comprehensive details about computer vision and digital image processing applications to detect different types of fabric defects.",2020,"[{'authorId': '2052894437', 'name': 'A. Rasheed'}, {'authorId': '32063462', 'name': 'Bushra Zafar'}, {'authorId': '2143259733', 'name': 'A. Rasheed'}, {'authorId': '5633418', 'name': 'N. Ali'}, {'authorId': '2025474888', 'name': 'M. Sajid'}, {'authorId': '51275372', 'name': 'Saadat Hanif Dar'}, {'authorId': '2126324255', 'name': 'Usman Habib'}, {'authorId': '30583571', 'name': 'Tehmina Shehryar'}, {'authorId': '49725394', 'name': 'M. Mahmood'}]","{'url': 'https://downloads.hindawi.com/journals/mpe/2020/8189403.pdf', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1155/2020/8189403?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1155/2020/8189403, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","there are different applications of computer vision and digital image processing in various applied domains and automated production process. in textile industry, fabric defect detection is considered as a challenging task as the quality and the price of any textile product are dependent on the efficiency and effectiveness of the automatic defect detection. previously, manual human efforts are applied in textile industry to detect the defects in the fabric production process. lack of concentration, human fatigue, and time consumption are the main drawbacks associated with the manual fabric defect detection process. applications based on computer vision and digital image processing can address the abovementioned limitations and drawbacks. since the last two decades, various computer vision-based applications are proposed in various research articles to address these limitations. in this review article, we aim to present a detailed study about various computer vision-based approaches with application in textile industry to detect fabric defects. the proposed study presents a detailed overview of histogram-based approaches, color-based approaches, image segmentation-based approaches, frequency domain operations, texture-based defect detection, sparse feature-based operation, image morphology operations, and recent trends of deep learning. the performance evaluation criteria for automatic fabric defect detection is also presented and discussed. the drawbacks and limitations associated with the existing published research are discussed in detail, and possible future research directions are also mentioned. this research study provides comprehensive details about computer vision and digital image processing applications to detect different types of fabric defects.",https://downloads.hindawi.com/journals/mpe/2020/8189403.pdf
7301b2a1c8156d7072c7eddbc780f45091004168,An Overview of the Attention Mechanisms in Computer Vision,"Deep convolutional neural network (CNN) plays an important role in the field of computer vision and image processing. In order to further improve the performance of CNN, scholars have conducted a series of new explorations, such as the improvement of activation functions, the construction of new loss functions, the regularization of parameters and the development of new network structures. However, every breakthrough of CNN comes from the innovation of network structure, whose design can be inspired by exploring the cognitive process of human brain. As one of the important features of human visual system, visual attention mechanism is essential in image generation, scene classification, target detection and tracking when applied in the field of computer vision. Focusing on the models of attention mechanisms commonly used in computer vision, their categorizations, principles, and outlook are summarized in this overview.",2020,"[{'authorId': '48520620', 'name': 'X. Yang'}]","{'url': 'https://doi.org/10.1088/1742-6596/1693/1/012173', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1088/1742-6596/1693/1/012173?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/1742-6596/1693/1/012173, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep convolutional neural network (cnn) plays an important role in the field of computer vision and image processing. in order to further improve the performance of cnn, scholars have conducted a series of new explorations, such as the improvement of activation functions, the construction of new loss functions, the regularization of parameters and the development of new network structures. however, every breakthrough of cnn comes from the innovation of network structure, whose design can be inspired by exploring the cognitive process of human brain. as one of the important features of human visual system, visual attention mechanism is essential in image generation, scene classification, target detection and tracking when applied in the field of computer vision. focusing on the models of attention mechanisms commonly used in computer vision, their categorizations, principles, and outlook are summarized in this overview.",https://doi.org/10.1088/1742-6596/1693/1/012173
c920b70c96cee7f96957679190453c6758bed0e4,Introduction to computer vision,NOTE: THIS IS A DRAFT DOCUMENT,2021,"[{'authorId': '1399493563', 'name': 'Rafael G. González-Acuña'}, {'authorId': '1399493574', 'name': 'Héctor A. Chaparro-Romo'}, {'authorId': '1413081862', 'name': 'I. Melendez-Montoya'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1088/978-0-7503-3707-6ch2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/978-0-7503-3707-6ch2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",introduction to computer vision,
cf1f166d3fe7a40117764c0c415055cf518e08e1,Computer vision in autism spectrum disorder research: a systematic review of published studies from 2009 to 2019,"The current state of computer vision methods applied to autism spectrum disorder (ASD) research has not been well established. Increasing evidence suggests that computer vision techniques have a strong impact on autism research. The primary objective of this systematic review is to examine how computer vision analysis has been useful in ASD diagnosis, therapy and autism research in general. A systematic review of publications indexed on PubMed, IEEE Xplore and ACM Digital Library was conducted from 2009 to 2019. Search terms included [‘autis*’ AND (‘computer vision’ OR ‘behavio* imaging’ OR ‘behavio* analysis’ OR ‘affective computing’)]. Results are reported according to PRISMA statement. A total of 94 studies are included in the analysis. Eligible papers are categorised based on the potential biological/behavioural markers quantified in each study. Then, different computer vision approaches that were employed in the included papers are described. Different publicly available datasets are also reviewed in order to rapidly familiarise researchers with datasets applicable to their field and to accelerate both new behavioural and technological work on autism research. Finally, future research directions are outlined. The findings in this review suggest that computer vision analysis is useful for the quantification of behavioural/biological markers which can further lead to a more objective analysis in autism research.",2020,"[{'authorId': '47860605', 'name': 'Ryan Anthony J. de Belen'}, {'authorId': '2342389', 'name': 'T. Bednarz'}, {'authorId': '145313633', 'name': 'A. Sowmya'}, {'authorId': '15165202', 'name': 'Dennis Del Favero'}]","{'url': 'https://www.nature.com/articles/s41398-020-01015-w.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7528087, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the current state of computer vision methods applied to autism spectrum disorder (asd) research has not been well established. increasing evidence suggests that computer vision techniques have a strong impact on autism research. the primary objective of this systematic review is to examine how computer vision analysis has been useful in asd diagnosis, therapy and autism research in general. a systematic review of publications indexed on pubmed, ieee xplore and acm digital library was conducted from 2009 to 2019. search terms included [‘autis*’ and (‘computer vision’ or ‘behavio* imaging’ or ‘behavio* analysis’ or ‘affective computing’)]. results are reported according to prisma statement. a total of 94 studies are included in the analysis. eligible papers are categorised based on the potential biological/behavioural markers quantified in each study. then, different computer vision approaches that were employed in the included papers are described. different publicly available datasets are also reviewed in order to rapidly familiarise researchers with datasets applicable to their field and to accelerate both new behavioural and technological work on autism research. finally, future research directions are outlined. the findings in this review suggest that computer vision analysis is useful for the quantification of behavioural/biological markers which can further lead to a more objective analysis in autism research.",https://www.nature.com/articles/s41398-020-01015-w.pdf
45db7f95f7eb60f480b659b6203f992235f0397f,Fashion Meets Computer Vision,"Fashion is the way we present ourselves to the world and has become one of the world’s largest industries. Fashion, mainly conveyed by vision, has thus attracted much attention from computer vision researchers in recent years. Given the rapid development, this article provides a comprehensive survey of more than 200 major fashion-related works covering four main aspects for enabling intelligent fashion: (1) Fashion detection includes landmark detection, fashion parsing, and item retrieval; (2) Fashion analysis contains attribute recognition, style learning, and popularity prediction; (3) Fashion synthesis involves style transfer, pose transformation, and physical simulation; and (4) Fashion recommendation comprises fashion compatibility, outfit matching, and hairstyle suggestion. For each task, the benchmark datasets and the evaluation protocols are summarized. Furthermore, we highlight promising directions for future research.",2020,"[{'authorId': '1711298', 'name': 'Wen-Huang Cheng'}, {'authorId': '3384254', 'name': 'Sijie Song'}, {'authorId': '2109637140', 'name': 'Chieh-Yun Chen'}, {'authorId': '3413443', 'name': 'S. Hidayati'}, {'authorId': '41127426', 'name': 'Jiaying Liu'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3447239', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2003.13988, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","fashion is the way we present ourselves to the world and has become one of the world’s largest industries. fashion, mainly conveyed by vision, has thus attracted much attention from computer vision researchers in recent years. given the rapid development, this article provides a comprehensive survey of more than 200 major fashion-related works covering four main aspects for enabling intelligent fashion: (1) fashion detection includes landmark detection, fashion parsing, and item retrieval; (2) fashion analysis contains attribute recognition, style learning, and popularity prediction; (3) fashion synthesis involves style transfer, pose transformation, and physical simulation; and (4) fashion recommendation comprises fashion compatibility, outfit matching, and hairstyle suggestion. for each task, the benchmark datasets and the evaluation protocols are summarized. furthermore, we highlight promising directions for future research.",https://dl.acm.org/doi/pdf/10.1145/3447239
056eaaeec68420286a80c3f593b7711d5cc17ef6,Kornia: an Open Source Differentiable Computer Vision Library for PyTorch,"This work presents Kornia – an open source computer vision library which consists of a set of differentiable routines and modules to solve generic computer vision problems. The package uses PyTorch as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions. Inspired by OpenCV, Kornia is composed of a set of modules containing operators that can be inserted inside neural networks to train models to perform image transformations, camera calibration, epipolar geometry, and low level image processing techniques, such as filtering and edge detection that operate directly on high dimensional tensor representations. Examples of classical vision problems implemented using our framework are provided including a benchmark comparing to existing vision libraries.",2019,"[{'authorId': '10044589', 'name': 'Edgar Riba'}, {'authorId': '40369725', 'name': 'Dmytro Mishkin'}, {'authorId': '1786419', 'name': 'D. Ponsa'}, {'authorId': '2383373', 'name': 'Ethan Rublee'}, {'authorId': '1720184', 'name': 'Gary R. Bradski'}]","{'url': 'https://arxiv.org/pdf/1910.02190', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1910.02190, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this work presents kornia – an open source computer vision library which consists of a set of differentiable routines and modules to solve generic computer vision problems. the package uses pytorch as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions. inspired by opencv, kornia is composed of a set of modules containing operators that can be inserted inside neural networks to train models to perform image transformations, camera calibration, epipolar geometry, and low level image processing techniques, such as filtering and edge detection that operate directly on high dimensional tensor representations. examples of classical vision problems implemented using our framework are provided including a benchmark comparing to existing vision libraries.",https://arxiv.org/pdf/1910.02190
cf10baf30fdaf9fbf212faa79fe038eea679ab7a,Pothole Detection Using Computer Vision and Learning,"Techniques for identifying potholes on road surfaces aim at developing strategies for real-time or offline identification of potholes, to support real-time control of a vehicle (for driver assistance or autonomous driving) or offline data collection for road maintenance. For these reasons, research around the world has comprehensively explored strategies for the identification of potholes on roads. This paper starts with a brief review of the field; it classifies developed strategies into several categories. We, then, present our contributions to this field by implementing strategies for automatic identification of potholes. We developed and studied two techniques based on stereo-vision analysis of road environments ahead of the vehicle; we also designed two models for deep-learning-based pothole detection. An experimental evaluation of those four designed methods is provided, and conclusions are drawn about particular benefits of these methods.",2020,"[{'authorId': '51043467', 'name': 'Amita Dhiman'}, {'authorId': '1729664', 'name': 'R. Klette'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TITS.2019.2931297?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TITS.2019.2931297, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","techniques for identifying potholes on road surfaces aim at developing strategies for real-time or offline identification of potholes, to support real-time control of a vehicle (for driver assistance or autonomous driving) or offline data collection for road maintenance. for these reasons, research around the world has comprehensively explored strategies for the identification of potholes on roads. this paper starts with a brief review of the field; it classifies developed strategies into several categories. we, then, present our contributions to this field by implementing strategies for automatic identification of potholes. we developed and studied two techniques based on stereo-vision analysis of road environments ahead of the vehicle; we also designed two models for deep-learning-based pothole detection. an experimental evaluation of those four designed methods is provided, and conclusions are drawn about particular benefits of these methods.",
c7d6f073d89f31e6584450713013c1fd85138090,A Guide to Convolutional Neural Networks for Computer Vision,"Computer vision has become increasingly important and effective in recent years due to its wide-ranging applications in areas as diverse as smart surveillance and monitoring, health and medicine, sports and recreation, robotics, drones, and self-driving cars. Visual recognition tasks, such as image classification, localization, and detection, are the core building blocks of many of these applications, and recent developments in Convolutional Neural Networks (CNNs) have led to outstanding performance in these state-of-the-art visual recognition tasks and systems. As a result, CNNs now form the crux of deep learning algorithms in computer vision. This self-contained guide will benefit those who seek to both understand the theory behind CNNs and to gain hands-on experience on the application of CNNs in computer vision. It provides a comprehensive introduction to CNNs starting with the essential concepts behind neural networks: training, regularization, and optimization of CNNs. The book also discusses a wide range of loss functions, network layers, and popular CNN architectures, reviews the different techniques for the evaluation of CNNs, and presents some popular CNN tools and libraries that are commonly used in computer vision. Further, this text describes and discusses case studies that are related to the application of CNN in computer vision, including image classification, object detection, semantic segmentation, scene understanding, and image generation. This book is ideal for undergraduate and graduate students, as no prior background knowledge in the field is required to follow the material, as well as new researchers, developers, engineers, and practitioners who are interested in gaining a quick understanding of CNN models.",2018,"[{'authorId': '152973423', 'name': 'Salman Hameed Khan'}, {'authorId': '1877377', 'name': 'H. Rahmani'}, {'authorId': '2112405071', 'name': 'S. A. A. Shah'}, {'authorId': '1698675', 'name': 'Bennamoun'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2200/s00822ed1v01y201712cov015?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2200/s00822ed1v01y201712cov015, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","computer vision has become increasingly important and effective in recent years due to its wide-ranging applications in areas as diverse as smart surveillance and monitoring, health and medicine, sports and recreation, robotics, drones, and self-driving cars. visual recognition tasks, such as image classification, localization, and detection, are the core building blocks of many of these applications, and recent developments in convolutional neural networks (cnns) have led to outstanding performance in these state-of-the-art visual recognition tasks and systems. as a result, cnns now form the crux of deep learning algorithms in computer vision. this self-contained guide will benefit those who seek to both understand the theory behind cnns and to gain hands-on experience on the application of cnns in computer vision. it provides a comprehensive introduction to cnns starting with the essential concepts behind neural networks: training, regularization, and optimization of cnns. the book also discusses a wide range of loss functions, network layers, and popular cnn architectures, reviews the different techniques for the evaluation of cnns, and presents some popular cnn tools and libraries that are commonly used in computer vision. further, this text describes and discusses case studies that are related to the application of cnn in computer vision, including image classification, object detection, semantic segmentation, scene understanding, and image generation. this book is ideal for undergraduate and graduate students, as no prior background knowledge in the field is required to follow the material, as well as new researchers, developers, engineers, and practitioners who are interested in gaining a quick understanding of cnn models.",
9a4382bc7aad5b0f33360e7b119929b95eb04f00,Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision: A Survey,"Deep Learning is a state-of-the-art technique to make inference on extensive or complex data. As a black box model due to their multilayer nonlinear structure, Deep Neural Networks are often criticized as being non-transparent and their predictions not traceable by humans. Furthermore, the models learn from artificially generated datasets, which often do not reflect reality. By basing decision-making algorithms on Deep Neural Networks, prejudice and unfairness may be promoted unknowingly due to a lack of transparency. Hence, several so-called explanators, or explainers, have been developed. Explainers try to give insight into the inner structure of machine learning black boxes by analyzing the connection between the input and output. In this survey, we present the mechanisms and properties of explaining systems for Deep Neural Networks for Computer Vision tasks. We give a comprehensive overview about the taxonomy of related studies and compare several survey papers that deal with explainability in general. We work out the drawbacks and gaps and summarize further research ideas.",2019,"[{'authorId': '1396402510', 'name': 'Vanessa Buhrmester'}, {'authorId': '31556032', 'name': 'David Münch'}, {'authorId': '2431669', 'name': 'Michael Arens'}]","{'url': 'https://www.mdpi.com/2504-4990/3/4/48/pdf?version=1640275931', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1911.12116, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep learning is a state-of-the-art technique to make inference on extensive or complex data. as a black box model due to their multilayer nonlinear structure, deep neural networks are often criticized as being non-transparent and their predictions not traceable by humans. furthermore, the models learn from artificially generated datasets, which often do not reflect reality. by basing decision-making algorithms on deep neural networks, prejudice and unfairness may be promoted unknowingly due to a lack of transparency. hence, several so-called explanators, or explainers, have been developed. explainers try to give insight into the inner structure of machine learning black boxes by analyzing the connection between the input and output. in this survey, we present the mechanisms and properties of explaining systems for deep neural networks for computer vision tasks. we give a comprehensive overview about the taxonomy of related studies and compare several survey papers that deal with explainability in general. we work out the drawbacks and gaps and summarize further research ideas.",https://www.mdpi.com/2504-4990/3/4/48/pdf?version=1640275931
c6e4516912e31ceca7151781b71e13e41dc50b84,Evaluating Scalable Bayesian Deep Learning Methods for Robust Computer Vision,"While deep neural networks have become the go-to approach in computer vision, the vast majority of these models fail to properly capture the uncertainty inherent in their predictions. Estimating this predictive uncertainty can be crucial, for example in automotive applications. In Bayesian deep learning, predictive uncertainty is commonly decomposed into the distinct types of aleatoric and epistemic uncertainty. The former can be estimated by letting a neural network output the parameters of a certain probability distribution. Epistemic uncertainty estimation is a more challenging problem, and while different scalable methods recently have emerged, no extensive comparison has been performed in a real-world setting. We therefore accept this task and propose a comprehensive evaluation framework for scalable epistemic uncertainty estimation methods in deep learning. Our proposed framework is specifically designed to test the robustness required in real-world computer vision applications. We also apply this framework to provide the first properly extensive and conclusive comparison of the two current state-of-the- art scalable methods: ensembling and MC-dropout. Our comparison demonstrates that ensembling consistently provides more reliable and practically useful uncertainty estimates. Code is available at https://github.com/fregu856/evaluating_bdl.",2019,"[{'authorId': '143710447', 'name': 'F. Gustafsson'}, {'authorId': '2488938', 'name': 'Martin Danelljan'}, {'authorId': '1802623', 'name': 'Thomas Bo Schön'}]","{'url': 'http://arxiv.org/pdf/1906.01620', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1906.01620, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","while deep neural networks have become the go-to approach in computer vision, the vast majority of these models fail to properly capture the uncertainty inherent in their predictions. estimating this predictive uncertainty can be crucial, for example in automotive applications. in bayesian deep learning, predictive uncertainty is commonly decomposed into the distinct types of aleatoric and epistemic uncertainty. the former can be estimated by letting a neural network output the parameters of a certain probability distribution. epistemic uncertainty estimation is a more challenging problem, and while different scalable methods recently have emerged, no extensive comparison has been performed in a real-world setting. we therefore accept this task and propose a comprehensive evaluation framework for scalable epistemic uncertainty estimation methods in deep learning. our proposed framework is specifically designed to test the robustness required in real-world computer vision applications. we also apply this framework to provide the first properly extensive and conclusive comparison of the two current state-of-the- art scalable methods: ensembling and mc-dropout. our comparison demonstrates that ensembling consistently provides more reliable and practically useful uncertainty estimates. code is available at https://github.com/fregu856/evaluating_bdl.",http://arxiv.org/pdf/1906.01620
50004c086ffd6a201a4b782281aaa930fbfe6ecf,V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation,"Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes. In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once. We introduce a novel objective function, that we optimise during training, based on Dice coefficient. In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.",2016,"[{'authorId': '1877512', 'name': 'F. Milletarì'}, {'authorId': '145587209', 'name': 'N. Navab'}, {'authorId': '145774206', 'name': 'Seyed-Ahmad Ahmadi'}]","{'url': 'http://arxiv.org/pdf/1606.04797', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1606.04797, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","convolutional neural networks (cnns) have been recently employed to solve problems from both the computer vision and medical image analysis fields. despite their popularity, most approaches are only able to process 2d images while most medical data used in clinical practice consists of 3d volumes. in this work we propose an approach to 3d image segmentation based on a volumetric, fully convolutional, neural network. our cnn is trained end-to-end on mri volumes depicting prostate, and learns to predict segmentation for the whole volume at once. we introduce a novel objective function, that we optimise during training, based on dice coefficient. in this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. to cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. we show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.",http://arxiv.org/pdf/1606.04797
2af15dd679b9c3c91030e2bf2047abbca0194d94,M3D: Advancing 3D Medical Image Analysis with Multi-Modal Large Language Models,"Medical image analysis is essential to clinical diagnosis and treatment, which is increasingly supported by multi-modal large language models (MLLMs). However, previous research has primarily focused on 2D medical images, leaving 3D images under-explored, despite their richer spatial information. This paper aims to advance 3D medical image analysis with MLLMs. To this end, we present a large-scale 3D multi-modal medical dataset, M3D-Data, comprising 120K image-text pairs and 662K instruction-response pairs specifically tailored for various 3D medical tasks, such as image-text retrieval, report generation, visual question answering, positioning, and segmentation. Additionally, we propose M3D-LaMed, a versatile multi-modal large language model for 3D medical image analysis. Furthermore, we introduce a new 3D multi-modal medical benchmark, M3D-Bench, which facilitates automatic evaluation across eight tasks. Through comprehensive evaluation, our method proves to be a robust model for 3D medical image analysis, outperforming existing solutions. All code, data, and models are publicly available at: https://github.com/BAAI-DCAI/M3D.",2024,"[{'authorId': '2267723472', 'name': 'Fan Bai'}, {'authorId': '2267873208', 'name': 'Yuxin Du'}, {'authorId': '2267863496', 'name': 'Tiejun Huang'}, {'authorId': '2258439096', 'name': 'Max Q.‐H. Meng'}, {'authorId': '2268224900', 'name': 'Bo Zhao'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2404.00578, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","medical image analysis is essential to clinical diagnosis and treatment, which is increasingly supported by multi-modal large language models (mllms). however, previous research has primarily focused on 2d medical images, leaving 3d images under-explored, despite their richer spatial information. this paper aims to advance 3d medical image analysis with mllms. to this end, we present a large-scale 3d multi-modal medical dataset, m3d-data, comprising 120k image-text pairs and 662k instruction-response pairs specifically tailored for various 3d medical tasks, such as image-text retrieval, report generation, visual question answering, positioning, and segmentation. additionally, we propose m3d-lamed, a versatile multi-modal large language model for 3d medical image analysis. furthermore, we introduce a new 3d multi-modal medical benchmark, m3d-bench, which facilitates automatic evaluation across eight tasks. through comprehensive evaluation, our method proves to be a robust model for 3d medical image analysis, outperforming existing solutions. all code, data, and models are publicly available at: https://github.com/baai-dcai/m3d.",
ccdc50de7a0602d3df5ed9bd9782565bbff2a8eb,Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?,"Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that 1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; 2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.",2016,"[{'authorId': '1930128', 'name': 'Nima Tajbakhsh'}, {'authorId': '143638713', 'name': 'Jae Y. Shin'}, {'authorId': '2419800', 'name': 'S. Gurudu'}, {'authorId': '145945198', 'name': 'R. T. Hurst'}, {'authorId': '50758261', 'name': 'Christopher B. Kendall'}, {'authorId': '1777226', 'name': 'M. Gotway'}, {'authorId': '2674518', 'name': 'Jianming Liang'}]","{'url': 'http://arxiv.org/pdf/1706.00712', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1706.00712, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","training a deep convolutional neural network (cnn) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. a promising alternative is to fine-tune a cnn that has been pre-trained using, for instance, a large set of labeled natural images. however, the substantial differences between natural and medical images may advise against such knowledge transfer. in this paper, we seek to answer the following central question in the context of medical image analysis: can the use of pre-trained deep cnns with sufficient fine-tuning eliminate the need for training a deep cnn from scratch? to address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep cnns trained from scratch compared with the pre-trained cnns fine-tuned in a layer-wise manner. our experiments consistently demonstrated that 1) the use of a pre-trained cnn with adequate fine-tuning outperformed or, in the worst case, performed as well as a cnn trained from scratch; 2) fine-tuned cnns were more robust to the size of training sets than cnns trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.",http://arxiv.org/pdf/1706.00712
8d79c921a87711c43990547e02e1ab601d5209e0,Comparison of Vision Transformers and Convolutional Neural Networks in Medical Image Analysis: A Systematic Review,"In the rapidly evolving field of medical image analysis utilizing artificial intelligence (AI), the selection of appropriate computational models is critical for accurate diagnosis and patient care. This literature review provides a comprehensive comparison of vision transformers (ViTs) and convolutional neural networks (CNNs), the two leading techniques in the field of deep learning in medical imaging. We conducted a survey systematically. Particular attention was given to the robustness, computational efficiency, scalability, and accuracy of these models in handling complex medical datasets. The review incorporates findings from 36 studies and indicates a collective trend that transformer-based models, particularly ViTs, exhibit significant potential in diverse medical imaging tasks, showcasing superior performance when contrasted with conventional CNN models. Additionally, it is evident that pre-training is important for transformer applications. We expect this work to help researchers and practitioners select the most appropriate model for specific medical image analysis tasks, accounting for the current state of the art and future trends in the field.",2024,"[{'authorId': '2289809626', 'name': 'Satoshi Takahashi'}, {'authorId': '2320753961', 'name': 'Yusuke Sakaguchi'}, {'authorId': '2131030816', 'name': 'Nobuji Kouno'}, {'authorId': '1478848793', 'name': 'Ken Takasawa'}, {'authorId': '2330891952', 'name': 'Kenichi Ishizu'}, {'authorId': '2274931371', 'name': 'Yu Akagi'}, {'authorId': '2164462424', 'name': 'R. Aoyama'}, {'authorId': '2320756127', 'name': 'Naoki Teraya'}, {'authorId': '1447071344', 'name': 'Amina Bolatkan'}, {'authorId': '1478918397', 'name': 'Norio Shinkai'}, {'authorId': '31971482', 'name': 'Hidenori Machino'}, {'authorId': '2150044858', 'name': 'Kazuma Kobayashi'}, {'authorId': '2065451253', 'name': 'Ken Asada'}, {'authorId': '2003184297', 'name': 'M. Komatsu'}, {'authorId': '6207609', 'name': 'S. Kaneko'}, {'authorId': '2320762460', 'name': 'Masashi Sugiyama'}, {'authorId': '2134290249', 'name': 'R. Hamamoto'}]","{'url': 'https://doi.org/10.1007/s10916-024-02105-8', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11393140, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the rapidly evolving field of medical image analysis utilizing artificial intelligence (ai), the selection of appropriate computational models is critical for accurate diagnosis and patient care. this literature review provides a comprehensive comparison of vision transformers (vits) and convolutional neural networks (cnns), the two leading techniques in the field of deep learning in medical imaging. we conducted a survey systematically. particular attention was given to the robustness, computational efficiency, scalability, and accuracy of these models in handling complex medical datasets. the review incorporates findings from 36 studies and indicates a collective trend that transformer-based models, particularly vits, exhibit significant potential in diverse medical imaging tasks, showcasing superior performance when contrasted with conventional cnn models. additionally, it is evident that pre-training is important for transformer applications. we expect this work to help researchers and practitioners select the most appropriate model for specific medical image analysis tasks, accounting for the current state of the art and future trends in the field.",https://doi.org/10.1007/s10916-024-02105-8
1eeb88f29783f4da1c904a1e1efcac59cbcf0cff,Deep Learning Approaches for Medical Image Analysis and Diagnosis,"In addition to enhancing diagnostic accuracy, deep learning techniques offer the potential to streamline workflows, reduce interpretation time, and ultimately improve patient outcomes. The scalability and adaptability of deep learning algorithms enable their deployment across diverse clinical settings, ranging from radiology departments to point-of-care facilities. Furthermore, ongoing research efforts focus on addressing the challenges of data heterogeneity, model interpretability, and regulatory compliance, paving the way for seamless integration of deep learning solutions into routine clinical practice. As the field continues to evolve, collaborations between clinicians, data scientists, and industry stakeholders will be paramount in harnessing the full potential of deep learning for advancing medical image analysis and diagnosis. Furthermore, the integration of deep learning algorithms with other technologies, including natural language processing and computer vision, may foster multimodal medical data analysis and clinical decision support systems to improve patient care. The future of deep learning in medical image analysis and diagnosis is promising. With each success and advancement, this technology is getting closer to being leveraged for medical purposes. Beyond medical image analysis, patient care pathways like multimodal imaging, imaging genomics, and intelligent operating rooms or intensive care units can benefit from deep learning models.",2024,"[{'authorId': '2265158659', 'name': 'Gopal Kumar Thakur'}, {'authorId': '2279732675', 'name': 'Abhishek Thakur'}, {'authorId': '2299617854', 'name': 'Shridhar Kulkarni'}, {'authorId': '2299915363', 'name': 'Naseebia Khan'}, {'authorId': '2305795759', 'name': 'Shahnawaz Khan'}]","{'url': '', 'status': None, 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11144045, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in addition to enhancing diagnostic accuracy, deep learning techniques offer the potential to streamline workflows, reduce interpretation time, and ultimately improve patient outcomes. the scalability and adaptability of deep learning algorithms enable their deployment across diverse clinical settings, ranging from radiology departments to point-of-care facilities. furthermore, ongoing research efforts focus on addressing the challenges of data heterogeneity, model interpretability, and regulatory compliance, paving the way for seamless integration of deep learning solutions into routine clinical practice. as the field continues to evolve, collaborations between clinicians, data scientists, and industry stakeholders will be paramount in harnessing the full potential of deep learning for advancing medical image analysis and diagnosis. furthermore, the integration of deep learning algorithms with other technologies, including natural language processing and computer vision, may foster multimodal medical data analysis and clinical decision support systems to improve patient care. the future of deep learning in medical image analysis and diagnosis is promising. with each success and advancement, this technology is getting closer to being leveraged for medical purposes. beyond medical image analysis, patient care pathways like multimodal imaging, imaging genomics, and intelligent operating rooms or intensive care units can benefit from deep learning models.",
076a8e778f2e9efb3c2fd45fed534ae9e6035f1b,Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis,"Vision Transformers (ViT)s have shown great performance in self-supervised learning of global and local representations that can be transferred to downstream applications. Inspired by these results, we introduce a novel self-supervised learning framework with tailored proxy tasks for medical image analysis. Specifically, we propose: (i) a new 3D transformer-based model, dubbed Swin UNEt TRansformers (Swin UNETR), with a hierarchical encoder for self-supervised pretraining; (ii) tailored proxy tasks for learning the underlying pattern of human anatomy. We demonstrate successful pre-training of the proposed model on 5,050 publicly available computed tomography (CT) images from various body organs. The effectiveness of our approach is validated by fine-tuning the pre-trained models on the Beyond the Cranial Vault (BTCV) Segmentation Challenge with 13 abdominal organs and segmentation tasks from the Medical Segmentation Decathlon (MSD) dataset. Our model is currently the state-of-the-art on the public test leaderboards of both MSD11https://decathlon-10.grand-challenge.org/evaluation/challenge/leaderboard/ and BTCV 22https://www.synapse.org/#!Synapse:syn3193805/wiki/217785/ datasets. Code: https://monai.io/research/swin-unetr.",2021,"[{'authorId': '46556781', 'name': 'Yucheng Tang'}, {'authorId': '144041873', 'name': 'Dong Yang'}, {'authorId': '2108730532', 'name': 'Wenqi Li'}, {'authorId': '144531567', 'name': 'H. Roth'}, {'authorId': '1699344', 'name': 'B. Landman'}, {'authorId': '3262394', 'name': 'Daguang Xu'}, {'authorId': '10751841', 'name': 'V. Nath'}, {'authorId': '31374559', 'name': 'Ali Hatamizadeh'}]","{'url': 'https://arxiv.org/pdf/2111.14791', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2111.14791, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","vision transformers (vit)s have shown great performance in self-supervised learning of global and local representations that can be transferred to downstream applications. inspired by these results, we introduce a novel self-supervised learning framework with tailored proxy tasks for medical image analysis. specifically, we propose: (i) a new 3d transformer-based model, dubbed swin unet transformers (swin unetr), with a hierarchical encoder for self-supervised pretraining; (ii) tailored proxy tasks for learning the underlying pattern of human anatomy. we demonstrate successful pre-training of the proposed model on 5,050 publicly available computed tomography (ct) images from various body organs. the effectiveness of our approach is validated by fine-tuning the pre-trained models on the beyond the cranial vault (btcv) segmentation challenge with 13 abdominal organs and segmentation tasks from the medical segmentation decathlon (msd) dataset. our model is currently the state-of-the-art on the public test leaderboards of both msd11https://decathlon-10.grand-challenge.org/evaluation/challenge/leaderboard/ and btcv 22https://www.synapse.org/#!synapse:syn3193805/wiki/217785/ datasets. code: https://monai.io/research/swin-unetr.",https://arxiv.org/pdf/2111.14791
ea7cfe7f2340584cbe653da6077ee7c213e49b92,Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation,"In the past few years, convolutional neural networks (CNNs) have achieved milestones in medical image analysis. Especially, the deep neural networks based on U-shaped architecture and skip-connections have been widely applied in a variety of medical image tasks. However, although CNN has achieved excellent performance, it cannot learn global and long-range semantic information interaction well due to the locality of the convolution operation. In this paper, we propose Swin-Unet, which is an Unet-like pure Transformer for medical image segmentation. The tokenized image patches are fed into the Transformer-based U-shaped Encoder-Decoder architecture with skip-connections for local-global semantic feature learning. Specifically, we use hierarchical Swin Transformer with shifted windows as the encoder to extract context features. And a symmetric Swin Transformer-based decoder with patch expanding layer is designed to perform the up-sampling operation to restore the spatial resolution of the feature maps. Under the direct down-sampling and up-sampling of the inputs and outputs by 4x, experiments on multi-organ and cardiac segmentation tasks demonstrate that the pure Transformer-based U-shaped Encoder-Decoder network outperforms those methods with full-convolution or the combination of transformer and convolution. The codes and trained models will be publicly available at https://github.com/HuCaoFighting/Swin-Unet.",2021,"[{'authorId': '40223253', 'name': 'Hu Cao'}, {'authorId': '2115849834', 'name': 'Yueyue Wang'}, {'authorId': '90972805', 'name': 'Jieneng Chen'}, {'authorId': '49731273', 'name': 'Dongsheng Jiang'}, {'authorId': '2108250420', 'name': 'Xiaopeng Zhang'}, {'authorId': '1400120070', 'name': 'Qi Tian'}, {'authorId': '40532896', 'name': 'Manning Wang'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2105.05537, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the past few years, convolutional neural networks (cnns) have achieved milestones in medical image analysis. especially, the deep neural networks based on u-shaped architecture and skip-connections have been widely applied in a variety of medical image tasks. however, although cnn has achieved excellent performance, it cannot learn global and long-range semantic information interaction well due to the locality of the convolution operation. in this paper, we propose swin-unet, which is an unet-like pure transformer for medical image segmentation. the tokenized image patches are fed into the transformer-based u-shaped encoder-decoder architecture with skip-connections for local-global semantic feature learning. specifically, we use hierarchical swin transformer with shifted windows as the encoder to extract context features. and a symmetric swin transformer-based decoder with patch expanding layer is designed to perform the up-sampling operation to restore the spatial resolution of the feature maps. under the direct down-sampling and up-sampling of the inputs and outputs by 4x, experiments on multi-organ and cardiac segmentation tasks demonstrate that the pure transformer-based u-shaped encoder-decoder network outperforms those methods with full-convolution or the combination of transformer and convolution. the codes and trained models will be publicly available at https://github.com/hucaofighting/swin-unet.",
8b0357f1bceb9cf7a5629b0ba3acb5660edf90b2,Advances in Medical Image Analysis with Vision Transformers: A Comprehensive Review,"The remarkable performance of the Transformer architecture in natural language processing has recently also triggered broad interest in Computer Vision. Among other merits, Transformers are witnessed as capable of learning long-range dependencies and spatial correlations, which is a clear advantage over convolutional neural networks (CNNs), which have been the de facto standard in Computer Vision problems so far. Thus, Transformers have become an integral part of modern medical image analysis. In this review, we provide an encyclopedic review of the applications of Transformers in medical imaging. Specifically, we present a systematic and thorough review of relevant recent Transformer literature for different medical image analysis tasks, including classification, segmentation, detection, registration, synthesis, and clinical report generation. For each of these applications, we investigate the novelty, strengths and weaknesses of the different proposed strategies and develop taxonomies highlighting key properties and contributions. Further, if applicable, we outline current benchmarks on different datasets. Finally, we summarize key challenges and discuss different future research directions. In addition, we have provided cited papers with their corresponding implementations in https://github.com/mindflow-institue/Awesome-Transformer.",2023,"[{'authorId': '1763181', 'name': 'Reza Azad'}, {'authorId': '2131612425', 'name': 'A. Kazerouni'}, {'authorId': '1491490451', 'name': 'Moein Heidari'}, {'authorId': '1411236504', 'name': 'Ehsan Khodapanah Aghdam'}, {'authorId': '2167168779', 'name': 'Amir Molaei'}, {'authorId': '2192610282', 'name': 'Yiwei Jia'}, {'authorId': '145895943', 'name': 'Abin Jose'}, {'authorId': '2190045909', 'name': 'Rijo Roy'}, {'authorId': '1737693', 'name': 'D. Merhof'}]","{'url': 'http://arxiv.org/pdf/2301.03505', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2301.03505, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the remarkable performance of the transformer architecture in natural language processing has recently also triggered broad interest in computer vision. among other merits, transformers are witnessed as capable of learning long-range dependencies and spatial correlations, which is a clear advantage over convolutional neural networks (cnns), which have been the de facto standard in computer vision problems so far. thus, transformers have become an integral part of modern medical image analysis. in this review, we provide an encyclopedic review of the applications of transformers in medical imaging. specifically, we present a systematic and thorough review of relevant recent transformer literature for different medical image analysis tasks, including classification, segmentation, detection, registration, synthesis, and clinical report generation. for each of these applications, we investigate the novelty, strengths and weaknesses of the different proposed strategies and develop taxonomies highlighting key properties and contributions. further, if applicable, we outline current benchmarks on different datasets. finally, we summarize key challenges and discuss different future research directions. in addition, we have provided cited papers with their corresponding implementations in https://github.com/mindflow-institue/awesome-transformer.",http://arxiv.org/pdf/2301.03505
cac375bc0a49cbe44deca79ba992160b2dd9d288,Medical image analysis using deep learning algorithms,"In the field of medical image analysis within deep learning (DL), the importance of employing advanced DL techniques cannot be overstated. DL has achieved impressive results in various areas, making it particularly noteworthy for medical image analysis in healthcare. The integration of DL with medical image analysis enables real-time analysis of vast and intricate datasets, yielding insights that significantly enhance healthcare outcomes and operational efficiency in the industry. This extensive review of existing literature conducts a thorough examination of the most recent deep learning (DL) approaches designed to address the difficulties faced in medical healthcare, particularly focusing on the use of deep learning algorithms in medical image analysis. Falling all the investigated papers into five different categories in terms of their techniques, we have assessed them according to some critical parameters. Through a systematic categorization of state-of-the-art DL techniques, such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Generative Adversarial Networks (GANs), Long Short-term Memory (LSTM) models, and hybrid models, this study explores their underlying principles, advantages, limitations, methodologies, simulation environments, and datasets. Based on our results, Python was the most frequent programming language used for implementing the proposed methods in the investigated papers. Notably, the majority of the scrutinized papers were published in 2021, underscoring the contemporaneous nature of the research. Moreover, this review accentuates the forefront advancements in DL techniques and their practical applications within the realm of medical image analysis, while simultaneously addressing the challenges that hinder the widespread implementation of DL in image analysis within the medical healthcare domains. These discerned insights serve as compelling impetuses for future studies aimed at the progressive advancement of image analysis in medical healthcare research. The evaluation metrics employed across the reviewed articles encompass a broad spectrum of features, encompassing accuracy, sensitivity, specificity, F-score, robustness, computational complexity, and generalizability.",2023,"[{'authorId': '2265952804', 'name': 'Mengfang Li'}, {'authorId': '2266011906', 'name': 'Yuanyuan Jiang'}, {'authorId': '2266004994', 'name': 'Yanzhou Zhang'}, {'authorId': '2266017999', 'name': 'Haisheng Zhu'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fpubh.2023.1273253/pdf?isPublishedV2=False', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10662291, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the field of medical image analysis within deep learning (dl), the importance of employing advanced dl techniques cannot be overstated. dl has achieved impressive results in various areas, making it particularly noteworthy for medical image analysis in healthcare. the integration of dl with medical image analysis enables real-time analysis of vast and intricate datasets, yielding insights that significantly enhance healthcare outcomes and operational efficiency in the industry. this extensive review of existing literature conducts a thorough examination of the most recent deep learning (dl) approaches designed to address the difficulties faced in medical healthcare, particularly focusing on the use of deep learning algorithms in medical image analysis. falling all the investigated papers into five different categories in terms of their techniques, we have assessed them according to some critical parameters. through a systematic categorization of state-of-the-art dl techniques, such as convolutional neural networks (cnns), recurrent neural networks (rnns), generative adversarial networks (gans), long short-term memory (lstm) models, and hybrid models, this study explores their underlying principles, advantages, limitations, methodologies, simulation environments, and datasets. based on our results, python was the most frequent programming language used for implementing the proposed methods in the investigated papers. notably, the majority of the scrutinized papers were published in 2021, underscoring the contemporaneous nature of the research. moreover, this review accentuates the forefront advancements in dl techniques and their practical applications within the realm of medical image analysis, while simultaneously addressing the challenges that hinder the widespread implementation of dl in image analysis within the medical healthcare domains. these discerned insights serve as compelling impetuses for future studies aimed at the progressive advancement of image analysis in medical healthcare research. the evaluation metrics employed across the reviewed articles encompass a broad spectrum of features, encompassing accuracy, sensitivity, specificity, f-score, robustness, computational complexity, and generalizability.",https://www.frontiersin.org/articles/10.3389/fpubh.2023.1273253/pdf?isPublishedV2=False
7ab0f0da686cd4094fd96f5a30e0b6072525fd09,Deep Learning in Medical Image Analysis.,"This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement.",2017,"[{'authorId': '144986260', 'name': 'D. Shen'}, {'authorId': '46531894', 'name': 'Guorong Wu'}, {'authorId': '143802908', 'name': 'Heung-Il Suk'}]","{'url': 'https://www.annualreviews.org/doi/pdf/10.1146/annurev-bioeng-071516-044442', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1146/annurev-bioeng-071516-044442?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/annurev-bioeng-071516-044442, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this review covers computer-assisted analysis of images in the field of medical imaging. recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. at the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. we introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. we conclude by discussing research issues and suggesting future directions for further improvement.",https://www.annualreviews.org/doi/pdf/10.1146/annurev-bioeng-071516-044442
fed150a219f9c31bdb4920e615c7c9264c634736,On the Challenges and Perspectives of Foundation Models for Medical Image Analysis,"This article discusses the opportunities, applications and future directions of large-scale pretrained models, i.e., foundation models, which promise to significantly improve the analysis of medical images. Medical foundation models have immense potential in solving a wide range of downstream tasks, as they can help to accelerate the development of accurate and robust models, reduce the dependence on large amounts of labeled data, preserve the privacy and confidentiality of patient data. Specifically, we illustrate the ""spectrum"" of medical foundation models, ranging from general imaging models, modality-specific models, to organ/task-specific models, and highlight their challenges, opportunities and applications. We also discuss how foundation models can be leveraged in downstream medical tasks to enhance the accuracy and efficiency of medical image analysis, leading to more precise diagnosis and treatment decisions.",2023,"[{'authorId': '48692127', 'name': 'Shaoting Zhang'}, {'authorId': '1711560', 'name': 'Dimitris N. Metaxas'}]","{'url': 'http://arxiv.org/pdf/2306.05705', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2306.05705, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this article discusses the opportunities, applications and future directions of large-scale pretrained models, i.e., foundation models, which promise to significantly improve the analysis of medical images. medical foundation models have immense potential in solving a wide range of downstream tasks, as they can help to accelerate the development of accurate and robust models, reduce the dependence on large amounts of labeled data, preserve the privacy and confidentiality of patient data. specifically, we illustrate the ""spectrum"" of medical foundation models, ranging from general imaging models, modality-specific models, to organ/task-specific models, and highlight their challenges, opportunities and applications. we also discuss how foundation models can be leveraged in downstream medical tasks to enhance the accuracy and efficiency of medical image analysis, leading to more precise diagnosis and treatment decisions.",http://arxiv.org/pdf/2306.05705
b545c5922114bbca666e25b8b6b26ba510f7997b,Federated Learning for Medical Image Analysis: A Survey,"Machine learning in medical imaging often faces a fundamental dilemma, namely, the small sample size problem. Many recent studies suggest using multi-domain data pooled from different acquisition sites/centers to improve statistical power. However, medical images from different sites cannot be easily shared to build large datasets for model training due to privacy protection reasons. As a promising solution, federated learning, which enables collaborative training of machine learning models based on data from different sites without cross-site data sharing, has attracted considerable attention recently. In this paper, we conduct a comprehensive survey of the recent development of federated learning methods in medical image analysis. We have systematically gathered research papers on federated learning and its applications in medical image analysis published between 2017 and 2023. Our search and compilation were conducted using databases from IEEE Xplore, ACM Digital Library, Science Direct, Springer Link, Web of Science, Google Scholar, and PubMed. In this survey, we first introduce the background of federated learning for dealing with privacy protection and collaborative learning issues. We then present a comprehensive review of recent advances in federated learning methods for medical image analysis. Specifically, existing methods are categorized based on three critical aspects of a federated learning system, including client end, server end, and communication techniques. In each category, we summarize the existing federated learning methods according to specific research problems in medical image analysis and also provide insights into the motivations of different approaches. In addition, we provide a review of existing benchmark medical imaging datasets and software platforms for current federated learning research. We also conduct an experimental study to empirically evaluate typical federated learning methods for medical image analysis. This survey can help to better understand the current research status, challenges, and potential research opportunities in this promising research field.",2023,"[{'authorId': None, 'name': 'Hao Guan'}, {'authorId': '7830359', 'name': 'Mingxia Liu'}]","{'url': 'https://arxiv.org/pdf/2306.05980', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2306.05980, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","machine learning in medical imaging often faces a fundamental dilemma, namely, the small sample size problem. many recent studies suggest using multi-domain data pooled from different acquisition sites/centers to improve statistical power. however, medical images from different sites cannot be easily shared to build large datasets for model training due to privacy protection reasons. as a promising solution, federated learning, which enables collaborative training of machine learning models based on data from different sites without cross-site data sharing, has attracted considerable attention recently. in this paper, we conduct a comprehensive survey of the recent development of federated learning methods in medical image analysis. we have systematically gathered research papers on federated learning and its applications in medical image analysis published between 2017 and 2023. our search and compilation were conducted using databases from ieee xplore, acm digital library, science direct, springer link, web of science, google scholar, and pubmed. in this survey, we first introduce the background of federated learning for dealing with privacy protection and collaborative learning issues. we then present a comprehensive review of recent advances in federated learning methods for medical image analysis. specifically, existing methods are categorized based on three critical aspects of a federated learning system, including client end, server end, and communication techniques. in each category, we summarize the existing federated learning methods according to specific research problems in medical image analysis and also provide insights into the motivations of different approaches. in addition, we provide a review of existing benchmark medical imaging datasets and software platforms for current federated learning research. we also conduct an experimental study to empirically evaluate typical federated learning methods for medical image analysis. this survey can help to better understand the current research status, challenges, and potential research opportunities in this promising research field.",https://arxiv.org/pdf/2306.05980
4dde26103f1f134f268dc0be3336e5391d8bea91,Deep Learning Attention Mechanism in Medical Image Analysis: Basics and Beyonds,"Survey/review study
Deep Learning Attention Mechanism in Medical Image Analysis: Basics and Beyonds

Xiang Li 1, Minglei Li 1, Pengfei Yan 1, Guanyi Li 1, Yuchen Jiang 1, Hao Luo 1,*, and Shen Yin 2


1 Department of Control Science and Engineering, Harbin Institute of Technology, Harbin 150001, China
2 Department of Mechanical and Industrial Engineering, Faculty of Engineering, Norwegian University of Science and Technology, Trondheim 7034, Norway
* Correspondence: hao.luo@hit.edu.cn
 
 
Received: 16 October 2022
Accepted: 25 November 2022
Published: 
 

Abstract: With the improvement of hardware computing power and the development of deep learning algorithms, a revolution of ""artificial intelligence (AI) + medical image"" is taking place. Benefiting from diversified modern medical measurement equipment, a large number of medical images will be produced in the clinical process. These images improve the diagnostic accuracy of doctors, but also increase the labor burden of doctors. Deep learning technology is expected to realize an auxiliary diagnosis and improve diagnostic efficiency. At present, the method of deep learning technology combined with attention mechanism is a research hotspot and has achieved state-of-the-art results in many medical image tasks. This paper reviews the deep learning attention methods in medical image analysis. A comprehensive literature survey is first conducted to analyze the keywords and literature. Then, we introduce the development and technical characteristics of the attention mechanism. For its application in medical image analysis, we summarize the related methods in medical image classification, segmentation, detection, and enhancement. The remaining challenges, potential solutions, and future research directions are also discussed.",2023,"[{'authorId': '47057383', 'name': 'Xiang Li'}, {'authorId': '2155331523', 'name': 'Minglei Li'}, {'authorId': '2068880788', 'name': 'Pengfei Yan'}, {'authorId': '1910178', 'name': 'Guanyi Li'}, {'authorId': '7911993', 'name': 'Yuchen Jiang'}, {'authorId': '145639696', 'name': 'Hao Luo'}, {'authorId': '2087552576', 'name': 'Shen Yin'}]","{'url': 'https://www.sciltp.com/journals/ijndi/article/download/173/107', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.53941/ijndi0201006?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.53941/ijndi0201006, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","survey/review study deep learning attention mechanism in medical image analysis: basics and beyonds xiang li 1, minglei li 1, pengfei yan 1, guanyi li 1, yuchen jiang 1, hao luo 1,*, and shen yin 2 1 department of control science and engineering, harbin institute of technology, harbin 150001, china 2 department of mechanical and industrial engineering, faculty of engineering, norwegian university of science and technology, trondheim 7034, norway * correspondence: hao.luo@hit.edu.cn received: 16 october 2022 accepted: 25 november 2022 published: abstract: with the improvement of hardware computing power and the development of deep learning algorithms, a revolution of ""artificial intelligence (ai) + medical image"" is taking place. benefiting from diversified modern medical measurement equipment, a large number of medical images will be produced in the clinical process. these images improve the diagnostic accuracy of doctors, but also increase the labor burden of doctors. deep learning technology is expected to realize an auxiliary diagnosis and improve diagnostic efficiency. at present, the method of deep learning technology combined with attention mechanism is a research hotspot and has achieved state-of-the-art results in many medical image tasks. this paper reviews the deep learning attention methods in medical image analysis. a comprehensive literature survey is first conducted to analyze the keywords and literature. then, we introduce the development and technical characteristics of the attention mechanism. for its application in medical image analysis, we summarize the related methods in medical image classification, segmentation, detection, and enhancement. the remaining challenges, potential solutions, and future research directions are also discussed.",https://www.sciltp.com/journals/ijndi/article/download/173/107
1476ebf98c198999dda49a0a6d65ea4eaceb7072,A Unified Visual Information Preservation Framework for Self-supervised Pre-Training in Medical Image Analysis,"Recent advances in self-supervised learning (SSL) in computer vision are primarily comparative, whose goal is to preserve invariant and discriminative semantics in latent representations by comparing siamese image views. However, the preserved high-level semantics do not contain enough local information, which is vital in medical image analysis (e.g., image-based diagnosis and tumor segmentation). To mitigate the locality problem of comparative SSL, we propose to incorporate the task of pixel restoration for explicitly encoding more pixel-level information into high-level semantics. We also address the preservation of scale information, a powerful tool in aiding image understanding but has not drawn much attention in SSL. The resulting framework can be formulated as a multi-task optimization problem on the feature pyramid. Specifically, we conduct multi-scale pixel restoration and siamese feature comparison in the pyramid. In addition, we propose non-skip U-Net to build the feature pyramid and develop sub-crop to replace multi-crop in 3D medical imaging. The proposed unified SSL framework (PCRLv2) surpasses its self-supervised counterparts on various tasks, including brain tumor segmentation (BraTS 2018), chest pathology identification (ChestX-ray, CheXpert), pulmonary nodule detection (LUNA), and abdominal organ segmentation (LiTS), sometimes outperforming them by large margins with limited annotations. Codes and models are available at https://github.com/RL4M/PCRLv2.",2023,"[{'authorId': '2157473801', 'name': 'Hong-Yu Zhou'}, {'authorId': '2110037818', 'name': 'Chi-Ken Lu'}, {'authorId': '2145762695', 'name': 'Chaoqi Chen'}, {'authorId': '2143750519', 'name': 'Sibei Yang'}, {'authorId': '1841911', 'name': 'Yizhou Yu'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2301.00772, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent advances in self-supervised learning (ssl) in computer vision are primarily comparative, whose goal is to preserve invariant and discriminative semantics in latent representations by comparing siamese image views. however, the preserved high-level semantics do not contain enough local information, which is vital in medical image analysis (e.g., image-based diagnosis and tumor segmentation). to mitigate the locality problem of comparative ssl, we propose to incorporate the task of pixel restoration for explicitly encoding more pixel-level information into high-level semantics. we also address the preservation of scale information, a powerful tool in aiding image understanding but has not drawn much attention in ssl. the resulting framework can be formulated as a multi-task optimization problem on the feature pyramid. specifically, we conduct multi-scale pixel restoration and siamese feature comparison in the pyramid. in addition, we propose non-skip u-net to build the feature pyramid and develop sub-crop to replace multi-crop in 3d medical imaging. the proposed unified ssl framework (pcrlv2) surpasses its self-supervised counterparts on various tasks, including brain tumor segmentation (brats 2018), chest pathology identification (chestx-ray, chexpert), pulmonary nodule detection (luna), and abdominal organ segmentation (lits), sometimes outperforming them by large margins with limited annotations. codes and models are available at https://github.com/rl4m/pcrlv2.",
1820715b0c5bb0d9a13c7c678ff82182d19e857d,Challenges of Deep Learning in Medical Image Analysis—Improving Explainability and Trust,"Deep learning has revolutionized the detection of diseases and is helping the healthcare sector break barriers in terms of accuracy and robustness to achieve efficient and robust computer-aided diagnostic systems. The application of deep learning techniques empowers automated AI-based utilities requiring minimal human supervision to perform any task related to medical diagnosis of fractures, tumors, and internal hemorrhage; preoperative planning; intra-operative guidance, etc. However, deep learning faces some major threats to the flourishing healthcare domain. This paper traverses the major challenges that the deep learning community of researchers and engineers faces, particularly in medical image diagnosis, like the unavailability of balanced annotated medical image data, adversarial attacks faced by deep neural networks and architectures due to noisy medical image data, a lack of trustability among users and patients, and ethical and privacy issues related to medical data. This study explores the possibilities of AI autonomy in healthcare by overcoming the concerns about trust that society has in autonomous intelligent systems.",2023,"[{'authorId': '2142731474', 'name': 'Tribikram Dhar'}, {'authorId': '71212644', 'name': 'N. Dey'}, {'authorId': '47795554', 'name': 'Surekha Borra'}, {'authorId': '145165793', 'name': 'R. Sherratt'}]","{'url': 'https://centaur.reading.ac.uk/109789/1/Challenges%20of%20Deep%20Learning%20in%20Medical%20Image%20Analysis%20%E2%80%93%20Improving%20Explainability%20and%20Trust%20_%20Full%20Text.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TTS.2023.3234203?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TTS.2023.3234203, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deep learning has revolutionized the detection of diseases and is helping the healthcare sector break barriers in terms of accuracy and robustness to achieve efficient and robust computer-aided diagnostic systems. the application of deep learning techniques empowers automated ai-based utilities requiring minimal human supervision to perform any task related to medical diagnosis of fractures, tumors, and internal hemorrhage; preoperative planning; intra-operative guidance, etc. however, deep learning faces some major threats to the flourishing healthcare domain. this paper traverses the major challenges that the deep learning community of researchers and engineers faces, particularly in medical image diagnosis, like the unavailability of balanced annotated medical image data, adversarial attacks faced by deep neural networks and architectures due to noisy medical image data, a lack of trustability among users and patients, and ethical and privacy issues related to medical data. this study explores the possibilities of ai autonomy in healthcare by overcoming the concerns about trust that society has in autonomous intelligent systems.",https://centaur.reading.ac.uk/109789/1/Challenges%20of%20Deep%20Learning%20in%20Medical%20Image%20Analysis%20%E2%80%93%20Improving%20Explainability%20and%20Trust%20_%20Full%20Text.pdf
d00eeb07d4215c2664db41315ae0a4b1254a2307,Federated Learning for Medical Image Analysis with Deep Neural Networks,"Medical image analysis using deep neural networks (DNN) has demonstrated state-of-the-art performance in image classification and segmentation tasks, aiding disease diagnosis. The accuracy of the DNN is largely governed by the quality and quantity of the data used to train the model. However, for the medical images, the critical security and privacy concerns regarding sharing of local medical data across medical establishments precludes exploiting the full DNN potential for clinical diagnosis. The federated learning (FL) approach enables the use of local model’s parameters to train a global model, while ensuring data privacy and security. In this paper, we review the federated learning applications in medical image analysis with DNNs, highlight the security concerns, cover some efforts to improve FL model performance, and describe the challenges and future research directions.",2023,"[{'authorId': '3249141', 'name': 'S. Nazir'}, {'authorId': '143943094', 'name': 'Mohammad Kaleem'}]","{'url': 'https://www.mdpi.com/2075-4418/13/9/1532/pdf?version=1682337976', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10177193, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","medical image analysis using deep neural networks (dnn) has demonstrated state-of-the-art performance in image classification and segmentation tasks, aiding disease diagnosis. the accuracy of the dnn is largely governed by the quality and quantity of the data used to train the model. however, for the medical images, the critical security and privacy concerns regarding sharing of local medical data across medical establishments precludes exploiting the full dnn potential for clinical diagnosis. the federated learning (fl) approach enables the use of local model’s parameters to train a global model, while ensuring data privacy and security. in this paper, we review the federated learning applications in medical image analysis with dnns, highlight the security concerns, cover some efforts to improve fl model performance, and describe the challenges and future research directions.",https://www.mdpi.com/2075-4418/13/9/1532/pdf?version=1682337976
24a89953c24ac4dc6b262a1f5441aa98a864ece8,Parameter-Efficient Fine-Tuning for Medical Image Analysis: The Missed Opportunity,"Foundation models have significantly advanced medical image analysis through the pre-train fine-tune paradigm. Among various fine-tuning algorithms, Parameter-Efficient Fine-Tuning (PEFT) is increasingly utilized for knowledge transfer across diverse tasks, including vision-language and text-to-image generation. However, its application in medical image analysis is relatively unexplored due to the lack of a structured benchmark for evaluating PEFT methods. This study fills this gap by evaluating 17 distinct PEFT algorithms across convolutional and transformer-based networks on image classification and text-to-image generation tasks using six medical datasets of varying size, modality, and complexity. Through a battery of over 700 controlled experiments, our findings demonstrate PEFT's effectiveness, particularly in low data regimes common in medical imaging, with performance gains of up to 22% in discriminative and generative tasks. These recommendations can assist the community in incorporating PEFT into their workflows and facilitate fair comparisons of future PEFT methods, ensuring alignment with advancements in other areas of machine learning and AI.",2023,"[{'authorId': '1380599312', 'name': 'Raman Dutt'}, {'authorId': '37151799', 'name': 'Linus Ericsson'}, {'authorId': '2130572313', 'name': 'Pedro Sanchez'}, {'authorId': '1919157', 'name': 'S. Tsaftaris'}, {'authorId': '1697755', 'name': 'Timothy M. Hospedales'}]","{'url': 'http://arxiv.org/pdf/2305.08252', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2305.08252, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","foundation models have significantly advanced medical image analysis through the pre-train fine-tune paradigm. among various fine-tuning algorithms, parameter-efficient fine-tuning (peft) is increasingly utilized for knowledge transfer across diverse tasks, including vision-language and text-to-image generation. however, its application in medical image analysis is relatively unexplored due to the lack of a structured benchmark for evaluating peft methods. this study fills this gap by evaluating 17 distinct peft algorithms across convolutional and transformer-based networks on image classification and text-to-image generation tasks using six medical datasets of varying size, modality, and complexity. through a battery of over 700 controlled experiments, our findings demonstrate peft's effectiveness, particularly in low data regimes common in medical imaging, with performance gains of up to 22% in discriminative and generative tasks. these recommendations can assist the community in incorporating peft into their workflows and facilitate fair comparisons of future peft methods, ensuring alignment with advancements in other areas of machine learning and ai.",http://arxiv.org/pdf/2305.08252
deaffe6e9f664bf74885ce873b19b0c84dc132f9,A Systematic Review on Federated Learning in Medical Image Analysis,"Federated Learning (FL) obtained a lot of attention to the academic and industrial stakeholders from the beginning of its invention. The eye-catching feature of FL is handling data in a decentralized manner which creates a privacy preserving environment in Artificial Intelligence (AI) applications. As we know medical data includes marginal private information of patients which demands excessive data protection from disclosure to unexpected destinations. In this paper, we performed a Systematic Literature Review (SLR) of published research articles on FL based medical image analysis. Firstly, we have collected articles from different databases followed by PRISMA guidelines, then synthesized data from the selected articles, and finally we provided a comprehensive overview on the topic. In order to do that we extracted core information associated with the implementation of FL in medical imaging from the articles. In our findings we briefly presented characteristics of federated data and models, performance achieved by the models and exclusively results comparison with traditional ML models. In addition, we discussed the open issues and challenges of implementing FL and mentioned our recommendations for future direction of this particular research field. We believe this SLR has successfully summarized the state-of-the-art FL methods for medical image analysis using deep learning.",2023,"[{'authorId': '92047412', 'name': 'Md. Fahimuzzman Sohan'}, {'authorId': '1746395', 'name': 'Anas Basalamah'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/6514899/10077569.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2023.3260027?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2023.3260027, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","federated learning (fl) obtained a lot of attention to the academic and industrial stakeholders from the beginning of its invention. the eye-catching feature of fl is handling data in a decentralized manner which creates a privacy preserving environment in artificial intelligence (ai) applications. as we know medical data includes marginal private information of patients which demands excessive data protection from disclosure to unexpected destinations. in this paper, we performed a systematic literature review (slr) of published research articles on fl based medical image analysis. firstly, we have collected articles from different databases followed by prisma guidelines, then synthesized data from the selected articles, and finally we provided a comprehensive overview on the topic. in order to do that we extracted core information associated with the implementation of fl in medical imaging from the articles. in our findings we briefly presented characteristics of federated data and models, performance achieved by the models and exclusively results comparison with traditional ml models. in addition, we discussed the open issues and challenges of implementing fl and mentioned our recommendations for future direction of this particular research field. we believe this slr has successfully summarized the state-of-the-art fl methods for medical image analysis using deep learning.",https://ieeexplore.ieee.org/ielx7/6287639/6514899/10077569.pdf
de0a1ab13b625e5e73b26caa450585f1d7b7667d,Implementation of computer vision technology based on artificial intelligence for medical image analysis,"As one of the branches of machine learning, the deep learning model combined with artificial intelligence is widely used in the field of computer vision technology, and the image recognition field represented by medical image analysis is also developing. Its advantage is that it does not rely on human annotation, and the computer can recognize and process the feature information omitted by human beings during the model training process, so as to achieve or even exceed the accuracy of human processing. Based on the general lack of explain ability caused by the unknown data processing process in the deep model, the existing solutions mainly include the establishment of internal explain ability, attention mechanism interpretation of specific models, and the interpretation of unknowable models represented by LIME. The way to quantitatively assess interpretability is still being explored, especially in the interpretative assessment of both doctors and patients in medical decision-related models, several scales have been proposed for reference. The current research on the application of artificial intelligence deep learning models in medical imaging generally pays more attention to accuracy rather than explain ability, resulting in the lack of explain ability, and thus hindering the practical clinical application of deep learning models. Therefore, the need to analyze the development of medical image analysis in the field of artificial intelligence and computer vision technology, and how to balance accuracy and interpretability to develop deep learning models that both doctors and patients can trust will become the research focus of the industry in the future.",2023,"[{'authorId': '2281328129', 'name': 'Danqing Ma'}, {'authorId': '2281169207', 'name': 'Bo Dang'}, {'authorId': '2281528408', 'name': 'Shaojie Li'}, {'authorId': '2281130565', 'name': 'Hengyi Zang'}, {'authorId': '2281129411', 'name': 'Xinqi Dong'}]","{'url': 'https://wepub.org/index.php/IJCSIT/article/download/529/501', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.62051/ijcsit.v1n1.10?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.62051/ijcsit.v1n1.10, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","as one of the branches of machine learning, the deep learning model combined with artificial intelligence is widely used in the field of computer vision technology, and the image recognition field represented by medical image analysis is also developing. its advantage is that it does not rely on human annotation, and the computer can recognize and process the feature information omitted by human beings during the model training process, so as to achieve or even exceed the accuracy of human processing. based on the general lack of explain ability caused by the unknown data processing process in the deep model, the existing solutions mainly include the establishment of internal explain ability, attention mechanism interpretation of specific models, and the interpretation of unknowable models represented by lime. the way to quantitatively assess interpretability is still being explored, especially in the interpretative assessment of both doctors and patients in medical decision-related models, several scales have been proposed for reference. the current research on the application of artificial intelligence deep learning models in medical imaging generally pays more attention to accuracy rather than explain ability, resulting in the lack of explain ability, and thus hindering the practical clinical application of deep learning models. therefore, the need to analyze the development of medical image analysis in the field of artificial intelligence and computer vision technology, and how to balance accuracy and interpretability to develop deep learning models that both doctors and patients can trust will become the research focus of the industry in the future.",https://wepub.org/index.php/IJCSIT/article/download/529/501
1d98839c28886823a3693d07332d8cff013d236f,A Review Paper about Deep Learning for Medical Image Analysis,"Medical imaging refers to the process of obtaining images of internal organs for therapeutic purposes such as discovering or studying diseases. The primary objective of medical image analysis is to improve the efficacy of clinical research and treatment options. Deep learning has revamped medical image analysis, yielding excellent results in image processing tasks such as registration, segmentation, feature extraction, and classification. The prime motivations for this are the availability of computational resources and the resurgence of deep convolutional neural networks. Deep learning techniques are good at observing hidden patterns in images and supporting clinicians in achieving diagnostic perfection. It has proven to be the most effective method for organ segmentation, cancer detection, disease categorization, and computer-assisted diagnosis. Many deep learning approaches have been published to analyze medical images for various diagnostic purposes. In this paper, we review the work exploiting current state-of-the-art deep learning approaches in medical image processing. We begin the survey by providing a synopsis of research works in medical imaging based on convolutional neural networks. Second, we discuss popular pretrained models and general adversarial networks that aid in improving convolutional networks' performance. Finally, to ease direct evaluation, we compile the performance metrics of deep learning models focusing on COVID-19 detection and child bone age prediction.",2023,"[{'authorId': '2219622039', 'name': 'Bagher Sistaninejhad'}, {'authorId': '2086935556', 'name': 'Habib Rasi'}, {'authorId': '2006254571', 'name': 'Parisa Nayeri'}]","{'url': 'https://downloads.hindawi.com/journals/cmmm/2023/7091301.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10241570, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","medical imaging refers to the process of obtaining images of internal organs for therapeutic purposes such as discovering or studying diseases. the primary objective of medical image analysis is to improve the efficacy of clinical research and treatment options. deep learning has revamped medical image analysis, yielding excellent results in image processing tasks such as registration, segmentation, feature extraction, and classification. the prime motivations for this are the availability of computational resources and the resurgence of deep convolutional neural networks. deep learning techniques are good at observing hidden patterns in images and supporting clinicians in achieving diagnostic perfection. it has proven to be the most effective method for organ segmentation, cancer detection, disease categorization, and computer-assisted diagnosis. many deep learning approaches have been published to analyze medical images for various diagnostic purposes. in this paper, we review the work exploiting current state-of-the-art deep learning approaches in medical image processing. we begin the survey by providing a synopsis of research works in medical imaging based on convolutional neural networks. second, we discuss popular pretrained models and general adversarial networks that aid in improving convolutional networks' performance. finally, to ease direct evaluation, we compile the performance metrics of deep learning models focusing on covid-19 detection and child bone age prediction.",https://downloads.hindawi.com/journals/cmmm/2023/7091301.pdf
741c7e78d0bd101b1fbf39d0c47fc519941bd275,Toward fairness in artificial intelligence for medical image analysis: identification and mitigation of potential biases in the roadmap from data collection to model deployment,"Abstract. Purpose To recognize and address various sources of bias essential for algorithmic fairness and trustworthiness and to contribute to a just and equitable deployment of AI in medical imaging, there is an increasing interest in developing medical imaging-based machine learning methods, also known as medical imaging artificial intelligence (AI), for the detection, diagnosis, prognosis, and risk assessment of disease with the goal of clinical implementation. These tools are intended to help improve traditional human decision-making in medical imaging. However, biases introduced in the steps toward clinical deployment may impede their intended function, potentially exacerbating inequities. Specifically, medical imaging AI can propagate or amplify biases introduced in the many steps from model inception to deployment, resulting in a systematic difference in the treatment of different groups. Approach Our multi-institutional team included medical physicists, medical imaging artificial intelligence/machine learning (AI/ML) researchers, experts in AI/ML bias, statisticians, physicians, and scientists from regulatory bodies. We identified sources of bias in AI/ML, mitigation strategies for these biases, and developed recommendations for best practices in medical imaging AI/ML development. Results Five main steps along the roadmap of medical imaging AI/ML were identified: (1) data collection, (2) data preparation and annotation, (3) model development, (4) model evaluation, and (5) model deployment. Within these steps, or bias categories, we identified 29 sources of potential bias, many of which can impact multiple steps, as well as mitigation strategies. Conclusions Our findings provide a valuable resource to researchers, clinicians, and the public at large.",2023,"[{'authorId': '2728244', 'name': 'K. Drukker'}, {'authorId': '2109956489', 'name': 'Weijie Chen'}, {'authorId': '27003959', 'name': 'J. Gichoya'}, {'authorId': '12643475', 'name': 'Nicholas P. Gruszauskas'}, {'authorId': '1401724111', 'name': 'Jayashree Kalpathy-Cramer'}, {'authorId': '123593472', 'name': 'Sanmi Koyejo'}, {'authorId': '2057832523', 'name': 'Kyle Myers'}, {'authorId': '2061600201', 'name': 'Rui C. Sá'}, {'authorId': '1685878', 'name': 'B. Sahiner'}, {'authorId': '2075808689', 'name': 'Heather M. Whitney'}, {'authorId': '2212056864', 'name': 'Zi Zhang'}, {'authorId': '144692532', 'name': 'M. Giger'}]","{'url': 'https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-10/issue-6/061104/Toward-fairness-in-artificial-intelligence-for-medical-image-analysis/10.1117/1.JMI.10.6.061104.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10129875, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract. purpose to recognize and address various sources of bias essential for algorithmic fairness and trustworthiness and to contribute to a just and equitable deployment of ai in medical imaging, there is an increasing interest in developing medical imaging-based machine learning methods, also known as medical imaging artificial intelligence (ai), for the detection, diagnosis, prognosis, and risk assessment of disease with the goal of clinical implementation. these tools are intended to help improve traditional human decision-making in medical imaging. however, biases introduced in the steps toward clinical deployment may impede their intended function, potentially exacerbating inequities. specifically, medical imaging ai can propagate or amplify biases introduced in the many steps from model inception to deployment, resulting in a systematic difference in the treatment of different groups. approach our multi-institutional team included medical physicists, medical imaging artificial intelligence/machine learning (ai/ml) researchers, experts in ai/ml bias, statisticians, physicians, and scientists from regulatory bodies. we identified sources of bias in ai/ml, mitigation strategies for these biases, and developed recommendations for best practices in medical imaging ai/ml development. results five main steps along the roadmap of medical imaging ai/ml were identified: (1) data collection, (2) data preparation and annotation, (3) model development, (4) model evaluation, and (5) model deployment. within these steps, or bias categories, we identified 29 sources of potential bias, many of which can impact multiple steps, as well as mitigation strategies. conclusions our findings provide a valuable resource to researchers, clinicians, and the public at large.",https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-10/issue-6/061104/Toward-fairness-in-artificial-intelligence-for-medical-image-analysis/10.1117/1.JMI.10.6.061104.pdf
0ae5b99f09b7ebacc4aeaed7644aff90534a3aaa,Deep Learning for Medical Image Analysis,"This report describes my research activities in the Hasso Plattner Institute and summarizes my Ph.D. plan and several novels, end-to-end trainable approaches for analyzing medical images using deep learning algorithm. In this report, as an example, we explore different novel methods based on deep learning for brain abnormality detection, recognition, and segmentation. This report prepared for the doctoral consortium in the AIME-2017 conference.",2017,"[{'authorId': '35593430', 'name': 'Mina Rezaei'}, {'authorId': '1688587', 'name': 'Haojin Yang'}, {'authorId': '1708312', 'name': 'C. Meinel'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1708.08987, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this report describes my research activities in the hasso plattner institute and summarizes my ph.d. plan and several novels, end-to-end trainable approaches for analyzing medical images using deep learning algorithm. in this report, as an example, we explore different novel methods based on deep learning for brain abnormality detection, recognition, and segmentation. this report prepared for the doctoral consortium in the aime-2017 conference.",
85842d70f84d9b86f4611ca77fa288ab302242d5,A survey of machine learning-based methods for COVID-19 medical image analysis,"The ongoing COVID-19 pandemic caused by the SARS-CoV-2 virus has already resulted in 6.6 million deaths with more than 637 million people infected after only 30 months since the first occurrences of the disease in December 2019. Hence, rapid and accurate detection and diagnosis of the disease is the first priority all over the world. Researchers have been working on various methods for COVID-19 detection and as the disease infects lungs, lung image analysis has become a popular research area for detecting the presence of the disease. Medical images from chest X-rays (CXR), computed tomography (CT) images, and lung ultrasound images have been used by automated image analysis systems in artificial intelligence (AI)- and machine learning (ML)-based approaches. Various existing and novel ML, deep learning (DL), transfer learning (TL), and hybrid models have been applied for detecting and classifying COVID-19, segmentation of infected regions, assessing the severity, and tracking patient progress from medical images of COVID-19 patients. In this paper, a comprehensive review of some recent approaches on COVID-19-based image analyses is provided surveying the contributions of existing research efforts, the available image datasets, and the performance metrics used in recent works. The challenges and future research scopes to address the progress of the fight against COVID-19 from the AI perspective are also discussed. The main objective of this paper is therefore to provide a summary of the research works done in COVID detection and analysis from medical image datasets using ML, DL, and TL models by analyzing their novelty and efficiency while mentioning other COVID-19-based review/survey researches to deliver a brief overview on the maximum amount of information on COVID-19-based existing researches.",2023,"[{'authorId': '3469813', 'name': 'Kashfia Sailunaz'}, {'authorId': '1732445', 'name': 'Tansel Özyer'}, {'authorId': '1685244', 'name': 'J. Rokne'}, {'authorId': '2185109001', 'name': 'Reda Alhajj'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11517-022-02758-y.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9883138, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the ongoing covid-19 pandemic caused by the sars-cov-2 virus has already resulted in 6.6 million deaths with more than 637 million people infected after only 30 months since the first occurrences of the disease in december 2019. hence, rapid and accurate detection and diagnosis of the disease is the first priority all over the world. researchers have been working on various methods for covid-19 detection and as the disease infects lungs, lung image analysis has become a popular research area for detecting the presence of the disease. medical images from chest x-rays (cxr), computed tomography (ct) images, and lung ultrasound images have been used by automated image analysis systems in artificial intelligence (ai)- and machine learning (ml)-based approaches. various existing and novel ml, deep learning (dl), transfer learning (tl), and hybrid models have been applied for detecting and classifying covid-19, segmentation of infected regions, assessing the severity, and tracking patient progress from medical images of covid-19 patients. in this paper, a comprehensive review of some recent approaches on covid-19-based image analyses is provided surveying the contributions of existing research efforts, the available image datasets, and the performance metrics used in recent works. the challenges and future research scopes to address the progress of the fight against covid-19 from the ai perspective are also discussed. the main objective of this paper is therefore to provide a summary of the research works done in covid detection and analysis from medical image datasets using ml, dl, and tl models by analyzing their novelty and efficiency while mentioning other covid-19-based review/survey researches to deliver a brief overview on the maximum amount of information on covid-19-based existing researches.",https://link.springer.com/content/pdf/10.1007/s11517-022-02758-y.pdf
7c92cced2d958e9f43af88fdd1d9cc2c281a6465,Domain Adaptation for Medical Image Analysis: A Survey,"Machine learning techniques used in computer-aided medical image analysis usually suffer from the domain shift problem caused by different distributions between source/reference data and target data. As a promising solution, domain adaptation has attracted considerable attention in recent years. The aim of this paper is to survey the recent advances of domain adaptation methods in medical image analysis. We first present the motivation of introducing domain adaptation techniques to tackle domain heterogeneity issues for medical image analysis. Then we provide a review of recent domain adaptation models in various medical image analysis tasks. We categorize the existing methods into shallow and deep models, and each of them is further divided into supervised, semi-supervised and unsupervised methods. We also provide a brief summary of the benchmark medical image datasets that support current domain adaptation research. This survey will enable researchers to gain a better understanding of the current status, challenges and future directions of this energetic research field.",2021,"[{'authorId': None, 'name': 'Hao Guan'}, {'authorId': '7830359', 'name': 'Mingxia Liu'}]","{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9011180', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2102.09508, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","machine learning techniques used in computer-aided medical image analysis usually suffer from the domain shift problem caused by different distributions between source/reference data and target data. as a promising solution, domain adaptation has attracted considerable attention in recent years. the aim of this paper is to survey the recent advances of domain adaptation methods in medical image analysis. we first present the motivation of introducing domain adaptation techniques to tackle domain heterogeneity issues for medical image analysis. then we provide a review of recent domain adaptation models in various medical image analysis tasks. we categorize the existing methods into shallow and deep models, and each of them is further divided into supervised, semi-supervised and unsupervised methods. we also provide a brief summary of the benchmark medical image datasets that support current domain adaptation research. this survey will enable researchers to gain a better understanding of the current status, challenges and future directions of this energetic research field.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9011180
49f9882d5fd442f02f9c9dff780336f6dce2da4f,Medical SAM Adapter: Adapting Segment Anything Model for Medical Image Segmentation,"The Segment Anything Model (SAM) has recently gained popularity in the field of image segmentation due to its impressive capabilities in various segmentation tasks and its prompt-based interface. However, recent studies and individual experiments have shown that SAM underperforms in medical image segmentation due to the lack of medical-specific knowledge. This raises the question of how to enhance SAM's segmentation capability for medical images. We propose the Medical SAM Adapter (Med-SA), which is one of the first methods to integrate SAM into medical image segmentation. Med-SA uses a light yet effective adaptation technique instead of fine-tuning the SAM model, incorporating domain-specific medical knowledge into the segmentation model. We also propose Space-Depth Transpose (SD-Trans) to adapt 2D SAM to 3D medical images and Hyper-Prompting Adapter (HyP-Adpt) to achieve prompt-conditioned adaptation. Comprehensive evaluation experiments on 17 medical image segmentation tasks across various modalities demonstrate the superior performance of Med-SA while updating only 2% of the SAM parameters (13M). Our code is released at https://github.com/KidsWithTokens/Medical-SAM-Adapter.",2023,"[{'authorId': '2146668763', 'name': 'Junde Wu'}, {'authorId': '2054309105', 'name': 'Rao Fu'}, {'authorId': '2087117656', 'name': 'Huihui Fang'}, {'authorId': '2375534', 'name': 'Yuanpei Liu'}, {'authorId': '2144715952', 'name': 'Zhao-Yang Wang'}, {'authorId': '98271873', 'name': 'Yanwu Xu'}, {'authorId': '33981465', 'name': 'Yueming Jin'}, {'authorId': '1699104', 'name': 'T. Arbel'}]","{'url': 'http://arxiv.org/pdf/2304.12620', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2304.12620, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the segment anything model (sam) has recently gained popularity in the field of image segmentation due to its impressive capabilities in various segmentation tasks and its prompt-based interface. however, recent studies and individual experiments have shown that sam underperforms in medical image segmentation due to the lack of medical-specific knowledge. this raises the question of how to enhance sam's segmentation capability for medical images. we propose the medical sam adapter (med-sa), which is one of the first methods to integrate sam into medical image segmentation. med-sa uses a light yet effective adaptation technique instead of fine-tuning the sam model, incorporating domain-specific medical knowledge into the segmentation model. we also propose space-depth transpose (sd-trans) to adapt 2d sam to 3d medical images and hyper-prompting adapter (hyp-adpt) to achieve prompt-conditioned adaptation. comprehensive evaluation experiments on 17 medical image segmentation tasks across various modalities demonstrate the superior performance of med-sa while updating only 2% of the sam parameters (13m). our code is released at https://github.com/kidswithtokens/medical-sam-adapter.",http://arxiv.org/pdf/2304.12620
d14465055fdd20022cb2478ab42b89aeaa5f91b1,Pooling in convolutional neural networks for medical image analysis: a survey and an empirical study,"Convolutional neural networks (CNN) are widely used in computer vision and medical image analysis as the state-of-the-art technique. In CNN, pooling layers are included mainly for downsampling the feature maps by aggregating features from local regions. Pooling can help CNN to learn invariant features and reduce computational complexity. Although the max and the average pooling are the widely used ones, various other pooling techniques are also proposed for different purposes, which include techniques to reduce overfitting, to capture higher-order information such as correlation between features, to capture spatial or structural information, etc. As not all of these pooling techniques are well-explored for medical image analysis, this paper provides a comprehensive review of various pooling techniques proposed in the literature of computer vision and medical image analysis. In addition, an extensive set of experiments are conducted to compare a selected set of pooling techniques on two different medical image classification problems, namely HEp-2 cells and diabetic retinopathy image classification. Experiments suggest that the most appropriate pooling mechanism for a particular classification task is related to the scale of the class-specific features with respect to the image size. As this is the first work focusing on pooling techniques for the application of medical image analysis, we believe that this review and the comparative study will provide a guideline to the choice of pooling mechanisms for various medical image analysis tasks. In addition, by carefully choosing the pooling operations with the standard ResNet architecture, we show new state-of-the-art results on both HEp-2 cells and diabetic retinopathy image datasets.",2022,"[{'authorId': '2049039023', 'name': 'Rajendran Nirthika'}, {'authorId': '1960430', 'name': 'Siyamalan Manivannan'}, {'authorId': '34672932', 'name': 'A. Ramanan'}, {'authorId': '2033951', 'name': 'Ruixuan Wang'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s00521-022-06953-8.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8804673, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","convolutional neural networks (cnn) are widely used in computer vision and medical image analysis as the state-of-the-art technique. in cnn, pooling layers are included mainly for downsampling the feature maps by aggregating features from local regions. pooling can help cnn to learn invariant features and reduce computational complexity. although the max and the average pooling are the widely used ones, various other pooling techniques are also proposed for different purposes, which include techniques to reduce overfitting, to capture higher-order information such as correlation between features, to capture spatial or structural information, etc. as not all of these pooling techniques are well-explored for medical image analysis, this paper provides a comprehensive review of various pooling techniques proposed in the literature of computer vision and medical image analysis. in addition, an extensive set of experiments are conducted to compare a selected set of pooling techniques on two different medical image classification problems, namely hep-2 cells and diabetic retinopathy image classification. experiments suggest that the most appropriate pooling mechanism for a particular classification task is related to the scale of the class-specific features with respect to the image size. as this is the first work focusing on pooling techniques for the application of medical image analysis, we believe that this review and the comparative study will provide a guideline to the choice of pooling mechanisms for various medical image analysis tasks. in addition, by carefully choosing the pooling operations with the standard resnet architecture, we show new state-of-the-art results on both hep-2 cells and diabetic retinopathy image datasets.",https://link.springer.com/content/pdf/10.1007/s00521-022-06953-8.pdf
64be9999b68e12d260ba7423f6b55ffd41552ad3,Deep Learning Applications in Medical Image Analysis,"The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. We conclude by discussing research obstacles, emerging trends, and possible future directions.",2018,"[{'authorId': '34812292', 'name': 'Justin Ker'}, {'authorId': '46659335', 'name': 'Lipo Wang'}, {'authorId': '39917910', 'name': 'J. Rao'}, {'authorId': '48508646', 'name': 'Tchoyoson C. C. Lim'}]","{'url': 'https://doi.org/10.1109/access.2017.2788044', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2017.2788044?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2017.2788044, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. this review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. the advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. we cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. we conclude by discussing research obstacles, emerging trends, and possible future directions.",https://doi.org/10.1109/access.2017.2788044
4ec06dda674cd5f93351f0ab5871391671f9b974,Medical Image Analysis using Convolutional Neural Networks: A Review,"The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted.",2017,"[{'authorId': '9514351', 'name': 'A. Qayyum'}, {'authorId': '144608640', 'name': 'S. Anwar'}, {'authorId': '144974259', 'name': 'Muhammad Majid'}, {'authorId': '1387433697', 'name': 'M. Awais'}, {'authorId': '3436574', 'name': 'M. Alnowami'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1709.02250, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. the aim is to extract information in an affective and efficient manner for improved clinical diagnosis. the recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. one of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. this is in contrast to those methods where traditionally hand crafted features are used. the selection and calculation of these features is a challenging task. among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. this includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. in this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. the challenges and potential of these techniques are also highlighted.",
08b30038fe938fb8460dff3085bda9ff6503e4c5,Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation,"In recent advancements in medical image analysis, Convolutional Neural Networks (CNN) and Vision Transformers (ViT) have set significant benchmarks. While the former excels in capturing local features through its convolution operations, the latter achieves remarkable global context understanding by leveraging self-attention mechanisms. However, both architectures exhibit limitations in efficiently modeling long-range dependencies within medical images, which is a critical aspect for precise segmentation. Inspired by the Mamba architecture, known for its proficiency in handling long sequences and global contextual information with enhanced computational efficiency as a State Space Model (SSM), we propose Mamba-UNet, a novel architecture that synergizes the U-Net in medical image segmentation with Mamba's capability. Mamba-UNet adopts a pure Visual Mamba (VMamba)-based encoder-decoder structure, infused with skip connections to preserve spatial information across different scales of the network. This design facilitates a comprehensive feature learning process, capturing intricate details and broader semantic contexts within medical images. We introduce a novel integration mechanism within the VMamba blocks to ensure seamless connectivity and information flow between the encoder and decoder paths, enhancing the segmentation performance. We conducted experiments on publicly available ACDC MRI Cardiac segmentation dataset, and Synapse CT Abdomen segmentation dataset. The results show that Mamba-UNet outperforms several types of UNet in medical image segmentation under the same hyper-parameter setting. The source code and baseline implementations are available.",2024,"[{'authorId': '2240108214', 'name': 'Ziyang Wang'}, {'authorId': '2283338860', 'name': 'Jian-Qing Zheng'}, {'authorId': '2283183768', 'name': 'Yichi Zhang'}, {'authorId': '2283136965', 'name': 'Ge Cui'}, {'authorId': '2338028118', 'name': 'Lei Li'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2402.05079, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent advancements in medical image analysis, convolutional neural networks (cnn) and vision transformers (vit) have set significant benchmarks. while the former excels in capturing local features through its convolution operations, the latter achieves remarkable global context understanding by leveraging self-attention mechanisms. however, both architectures exhibit limitations in efficiently modeling long-range dependencies within medical images, which is a critical aspect for precise segmentation. inspired by the mamba architecture, known for its proficiency in handling long sequences and global contextual information with enhanced computational efficiency as a state space model (ssm), we propose mamba-unet, a novel architecture that synergizes the u-net in medical image segmentation with mamba's capability. mamba-unet adopts a pure visual mamba (vmamba)-based encoder-decoder structure, infused with skip connections to preserve spatial information across different scales of the network. this design facilitates a comprehensive feature learning process, capturing intricate details and broader semantic contexts within medical images. we introduce a novel integration mechanism within the vmamba blocks to ensure seamless connectivity and information flow between the encoder and decoder paths, enhancing the segmentation performance. we conducted experiments on publicly available acdc mri cardiac segmentation dataset, and synapse ct abdomen segmentation dataset. the results show that mamba-unet outperforms several types of unet in medical image segmentation under the same hyper-parameter setting. the source code and baseline implementations are available.",
7fe995a220a9a1f3fad5539b71d12b13ea6c943a,"Computer vision and machine learning for medical image analysis: recent advances, challenges, and way forward","The recent development in the areas of deep learning and deep convolutional neural networks has significantly progressed and advanced the field of computer vision (CV) and image analysis and understanding. Complex tasks such as classifying and segmenting medical images and localising and recognising objects of interest have become much less challenging. This progress has the potential of accelerating research and deployment of multitudes of medical applications that utilise CV. However, in reality, there are limited practical examples being physically deployed into front-line health facilities. In this paper, we examine the current state of the art in CV as applied to the medical domain. We discuss the main challenges in CV and intelligent data-driven medical applications and suggest future directions to accelerate research, development, and deployment of CV applications in health practices. First, we critically review existing literature in the CV domain that addresses complex vision tasks, including: medical image classification; shape and object recognition from images; and medical segmentation. Second, we present an in-depth discussion of the various challenges that are considered barriers to accelerating research, development, and deployment of intelligent CV methods in real-life medical applications and hospitals. Finally, we conclude by discussing future directions.",2022,"[{'authorId': '1807106', 'name': 'Eyad Elyan'}, {'authorId': '6795236', 'name': 'Pattaramon Vuttipittayamongkol'}, {'authorId': '2056620234', 'name': 'Pamela Johnston'}, {'authorId': '2160765307', 'name': 'Kyle Martin'}, {'authorId': '2160761899', 'name': 'Kyle McPherson'}, {'authorId': '1399137626', 'name': 'Carlos Francisco Moreno-García'}, {'authorId': '8683625', 'name': 'Chrisina Jayne'}, {'authorId': '2160761736', 'name': 'Md. Mostafa Kamal Sarker'}]","{'url': 'https://aisjournal.net/article/download/4684', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.20517/ais.2021.15?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.20517/ais.2021.15, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the recent development in the areas of deep learning and deep convolutional neural networks has significantly progressed and advanced the field of computer vision (cv) and image analysis and understanding. complex tasks such as classifying and segmenting medical images and localising and recognising objects of interest have become much less challenging. this progress has the potential of accelerating research and deployment of multitudes of medical applications that utilise cv. however, in reality, there are limited practical examples being physically deployed into front-line health facilities. in this paper, we examine the current state of the art in cv as applied to the medical domain. we discuss the main challenges in cv and intelligent data-driven medical applications and suggest future directions to accelerate research, development, and deployment of cv applications in health practices. first, we critically review existing literature in the cv domain that addresses complex vision tasks, including: medical image classification; shape and object recognition from images; and medical segmentation. second, we present an in-depth discussion of the various challenges that are considered barriers to accelerating research, development, and deployment of intelligent cv methods in real-life medical applications and hospitals. finally, we conclude by discussing future directions.",https://aisjournal.net/article/download/4684
57a7f546d94bbf09141a045bd9783c2f271d18ee,MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis,"We present MedMNIST, a collection of 10 pre-processed medical open datasets. MedMNIST is standardized to perform classification tasks on lightweight 28 $\times$ 28 images, which requires no background knowledge. Covering the primary data modalities in medical image analysis, it is diverse on data scale (from 100 to 100,000) and tasks (binary/multi-class, ordinal regression and multi-label). MedMNIST could be used for educational purpose, rapid prototyping, multi-modal machine learning or AutoML in medical image analysis. Moreover, MedMNIST Classification Decathlon is designed to benchmark AutoML algorithms on all 10 datasets; We have compared several baseline methods, including open-source or commercial AutoML tools. The datasets, evaluation code and baseline methods for MedMNIST are publicly available at https://medmnist.github.io/.",2020,"[{'authorId': '47988339', 'name': 'Jiancheng Yang'}, {'authorId': '2056571624', 'name': 'R. Shi'}, {'authorId': '5796401', 'name': 'Bingbing Ni'}]","{'url': 'https://arxiv.org/pdf/2010.14925', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2010.14925, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we present medmnist, a collection of 10 pre-processed medical open datasets. medmnist is standardized to perform classification tasks on lightweight 28 $\times$ 28 images, which requires no background knowledge. covering the primary data modalities in medical image analysis, it is diverse on data scale (from 100 to 100,000) and tasks (binary/multi-class, ordinal regression and multi-label). medmnist could be used for educational purpose, rapid prototyping, multi-modal machine learning or automl in medical image analysis. moreover, medmnist classification decathlon is designed to benchmark automl algorithms on all 10 datasets; we have compared several baseline methods, including open-source or commercial automl tools. the datasets, evaluation code and baseline methods for medmnist are publicly available at https://medmnist.github.io/.",https://arxiv.org/pdf/2010.14925
278fb59cb65479a7e39abf0ca59af144659a6a0f,Dense Convolutional Network and Its Application in Medical Image Analysis,"Dense convolutional network (DenseNet) is a hot topic in deep learning research in recent years, which has good applications in medical image analysis. In this paper, DenseNet is summarized from the following aspects. First, the basic principle of DenseNet is introduced; second, the development of DenseNet is summarized and analyzed from five aspects: broaden DenseNet structure, lightweight DenseNet structure, dense unit, dense connection mode, and attention mechanism; finally, the application research of DenseNet in the field of medical image analysis is summarized from three aspects: pattern recognition, image segmentation, and object detection. The network structures of DenseNet are systematically summarized in this paper, which has certain positive significance for the research and development of DenseNet.",2022,"[{'authorId': '2114111691', 'name': 'Tao Zhou'}, {'authorId': '2114145177', 'name': 'Xinyu. Ye'}, {'authorId': '2115781353', 'name': 'Huiling Lu'}, {'authorId': '2163862842', 'name': 'Xiaomin Zheng'}, {'authorId': '2055117555', 'name': 'Shi Qiu'}, {'authorId': '2163853197', 'name': 'Yuncan Liu'}]","{'url': 'https://downloads.hindawi.com/journals/bmri/2022/2384830.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9060995, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","dense convolutional network (densenet) is a hot topic in deep learning research in recent years, which has good applications in medical image analysis. in this paper, densenet is summarized from the following aspects. first, the basic principle of densenet is introduced; second, the development of densenet is summarized and analyzed from five aspects: broaden densenet structure, lightweight densenet structure, dense unit, dense connection mode, and attention mechanism; finally, the application research of densenet in the field of medical image analysis is summarized from three aspects: pattern recognition, image segmentation, and object detection. the network structures of densenet are systematically summarized in this paper, which has certain positive significance for the research and development of densenet.",https://downloads.hindawi.com/journals/bmri/2022/2384830.pdf
fad8dd8918a59b63f0f6df8aac31f23a0c7ad26a,Masked Image Modeling Advances 3D Medical Image Analysis,"Recently, masked image modeling (MIM) has gained considerable attention due to its ability to learn from vast amounts of unlabeled data and has been demonstrated to be effective on various vision tasks involving natural images. Meanwhile, the potential of self-supervised learning in modeling 3D medical images is anticipated to be immense due to the high quantities of unlabeled images and the expense and difficulty of quality labels. However, MIM’s applicability to medical images remains uncertain. In this paper, we demonstrate that masked image modeling approaches can also advance 3D medical image analysis in addition to natural images. We study how masked image modeling strategies leverage performance from the viewpoints of 3D medical image segmentation as a representative downstream task: i) when compared to naive contrastive learning, masked image modeling approaches accelerate the convergence of supervised training even faster (1.40×) and ultimately produce a higher dice score; ii) predicting raw voxel values with a high masking ratio and a relatively smaller patch size is nontrivial self-supervised pretext-task for medical images modeling; iii) a lightweight decoder or projection head design for reconstruction is robust for masked image modeling on 3D medical images which speeds up training and reduce cost; iv) finally, we also investigate the effectiveness of MIM methods under different practical scenarios where different image resolutions and labeled data ratios are applied. Anonymized codes are available at https://github.com/ZEKAICHEN/MIM-Med3D.",2022,"[{'authorId': '40834657', 'name': 'Zekai Chen'}, {'authorId': '2057234232', 'name': 'Devansh Agarwal'}, {'authorId': '1404251828', 'name': 'Kshitij Aggarwal'}, {'authorId': '73771836', 'name': 'Wiem Safta'}, {'authorId': '2163449584', 'name': 'Mariann Micsinai Balan'}, {'authorId': '2130917', 'name': 'V. Sethuraman'}, {'authorId': '2163474480', 'name': 'Kevin Brown'}]","{'url': 'https://arxiv.org/pdf/2204.11716', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2204.11716, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recently, masked image modeling (mim) has gained considerable attention due to its ability to learn from vast amounts of unlabeled data and has been demonstrated to be effective on various vision tasks involving natural images. meanwhile, the potential of self-supervised learning in modeling 3d medical images is anticipated to be immense due to the high quantities of unlabeled images and the expense and difficulty of quality labels. however, mim’s applicability to medical images remains uncertain. in this paper, we demonstrate that masked image modeling approaches can also advance 3d medical image analysis in addition to natural images. we study how masked image modeling strategies leverage performance from the viewpoints of 3d medical image segmentation as a representative downstream task: i) when compared to naive contrastive learning, masked image modeling approaches accelerate the convergence of supervised training even faster (1.40×) and ultimately produce a higher dice score; ii) predicting raw voxel values with a high masking ratio and a relatively smaller patch size is nontrivial self-supervised pretext-task for medical images modeling; iii) a lightweight decoder or projection head design for reconstruction is robust for masked image modeling on 3d medical images which speeds up training and reduce cost; iv) finally, we also investigate the effectiveness of mim methods under different practical scenarios where different image resolutions and labeled data ratios are applied. anonymized codes are available at https://github.com/zekaichen/mim-med3d.",https://arxiv.org/pdf/2204.11716
2f577e03684d5149039ee73a669217e7fab4c641,Federated learning and differential privacy for medical image analysis,"The artificial intelligence revolution has been spurred forward by the availability of large-scale datasets. In contrast, the paucity of large-scale medical datasets hinders the application of machine learning in healthcare. The lack of publicly available multi-centric and diverse datasets mainly stems from confidentiality and privacy concerns around sharing medical data. To demonstrate a feasible path forward in medical image imaging, we conduct a case study of applying a differentially private federated learning framework for analysis of histopathology images, the largest and perhaps most complex medical images. We study the effects of IID and non-IID distributions along with the number of healthcare providers, i.e., hospitals and clinics, and the individual dataset sizes, using The Cancer Genome Atlas (TCGA) dataset, a public repository, to simulate a distributed environment. We empirically compare the performance of private, distributed training to conventional training and demonstrate that distributed training can achieve similar performance with strong privacy guarantees. We also study the effect of different source domains for histopathology images by evaluating the performance using external validation. Our work indicates that differentially private federated learning is a viable and reliable framework for the collaborative development of machine learning models in medical image analysis.",2021,"[{'authorId': '40442705', 'name': 'Mohammed Adnan'}, {'authorId': '34992408', 'name': 'S. Kalra'}, {'authorId': '103145485', 'name': 'Jesse C. Cresswell'}, {'authorId': '144639556', 'name': 'Graham W. Taylor'}, {'authorId': '9315255', 'name': 'H. Tizhoosh'}]","{'url': 'https://www.nature.com/articles/s41598-022-05539-7.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8816913, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the artificial intelligence revolution has been spurred forward by the availability of large-scale datasets. in contrast, the paucity of large-scale medical datasets hinders the application of machine learning in healthcare. the lack of publicly available multi-centric and diverse datasets mainly stems from confidentiality and privacy concerns around sharing medical data. to demonstrate a feasible path forward in medical image imaging, we conduct a case study of applying a differentially private federated learning framework for analysis of histopathology images, the largest and perhaps most complex medical images. we study the effects of iid and non-iid distributions along with the number of healthcare providers, i.e., hospitals and clinics, and the individual dataset sizes, using the cancer genome atlas (tcga) dataset, a public repository, to simulate a distributed environment. we empirically compare the performance of private, distributed training to conventional training and demonstrate that distributed training can achieve similar performance with strong privacy guarantees. we also study the effect of different source domains for histopathology images by evaluating the performance using external validation. our work indicates that differentially private federated learning is a viable and reliable framework for the collaborative development of machine learning models in medical image analysis.",https://www.nature.com/articles/s41598-022-05539-7.pdf
f203f52c0f4151b89f0a1797c6be750b64af0a02,Self Pre-training with Masked Autoencoders for Medical Image Analysis,". Masked Autoencoder (MAE) has recently been shown to be eﬀective in pre-training Vision Transformers (ViT) for natural image analysis. By performing the pretext task of reconstructing the original image from only partial observations, the encoder, which is a ViT, is encouraged to aggregate contextual information to infer content in masked image regions. We believe that this context aggregation ability is also essential to the medical image domain where each anatomical structure is functionally and mechanically connected to other structures and regions. However, there is no ImageNet-scale medical image dataset for pre-training. Thus, in this paper, we investigate a self pre-training paradigm with MAE for medical images, i.e., models are pre-trained on the same target dataset. To validate the MAE self pre-training , we consider three diverse medical image tasks including chest X-ray disease classiﬁcation, CT abdomen multi-organ segmentation and MRI brain tumor segmentation. It turns out MAE self pre-training beneﬁts all the tasks markedly. Speciﬁcally, the mAUC on lung disease classiﬁcation is increased by 9.4%. The average DSC on brain tumor segmentation is improved from 77.4% to 78.9%. Most interestingly, on the small-scale multi-organ segmentation dataset (N=30), the average DSC improves from 78.8% to 83.5% and the HD95 is reduced by 60%, indicating its eﬀectiveness in limited data scenarios. The segmentation and classiﬁcation results reveal the promising potential of MAE self pre-training for medical image analysis.",2022,"[{'authorId': '2144764847', 'name': 'Lei Zhou'}, {'authorId': '49957558', 'name': 'Huidong Liu'}, {'authorId': '1782405431', 'name': 'Joseph Bae'}, {'authorId': '1720735918', 'name': 'Junjun He'}, {'authorId': '145654220', 'name': 'D. Samaras'}, {'authorId': '39017169', 'name': 'P. Prasanna'}]","{'url': 'http://arxiv.org/pdf/2203.05573', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.48550/arXiv.2203.05573?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.48550/arXiv.2203.05573, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",". masked autoencoder (mae) has recently been shown to be eﬀective in pre-training vision transformers (vit) for natural image analysis. by performing the pretext task of reconstructing the original image from only partial observations, the encoder, which is a vit, is encouraged to aggregate contextual information to infer content in masked image regions. we believe that this context aggregation ability is also essential to the medical image domain where each anatomical structure is functionally and mechanically connected to other structures and regions. however, there is no imagenet-scale medical image dataset for pre-training. thus, in this paper, we investigate a self pre-training paradigm with mae for medical images, i.e., models are pre-trained on the same target dataset. to validate the mae self pre-training , we consider three diverse medical image tasks including chest x-ray disease classiﬁcation, ct abdomen multi-organ segmentation and mri brain tumor segmentation. it turns out mae self pre-training beneﬁts all the tasks markedly. speciﬁcally, the mauc on lung disease classiﬁcation is increased by 9.4%. the average dsc on brain tumor segmentation is improved from 77.4% to 78.9%. most interestingly, on the small-scale multi-organ segmentation dataset (n=30), the average dsc improves from 78.8% to 83.5% and the hd95 is reduced by 60%, indicating its eﬀectiveness in limited data scenarios. the segmentation and classiﬁcation results reveal the promising potential of mae self pre-training for medical image analysis.",http://arxiv.org/pdf/2203.05573
b18cb2b9c1a605c72d9e4c8d045c945a06fab384,Trustworthy clinical AI solutions: a unified review of uncertainty quantification in deep learning models for medical image analysis,"The full acceptance of Deep Learning (DL) models in the clinical field is rather low with respect to the quantity of high-performing solutions reported in the literature. End users are particularly reluctant to rely on the opaque predictions of DL models. Uncertainty quantification methods have been proposed in the literature as a potential solution, to reduce the black-box effect of DL models and increase the interpretability and the acceptability of the result by the final user. In this review, we propose an overview of the existing methods to quantify uncertainty associated with DL predictions. We focus on applications to medical image analysis, which present specific challenges due to the high dimensionality of images and their variable quality, as well as constraints associated with real-world clinical routine. Moreover, we discuss the concept of structural uncertainty, a corpus of methods to facilitate the alignment of segmentation uncertainty estimates with clinical attention. We then discuss the evaluation protocols to validate the relevance of uncertainty estimates. Finally, we highlight the open challenges for uncertainty quantification in the medical field.",2022,"[{'authorId': '153005347', 'name': 'Benjamin Lambert'}, {'authorId': '2074707664', 'name': 'Florence Forbes'}, {'authorId': '2309000', 'name': 'A. Tucholka'}, {'authorId': '28614542', 'name': 'Senan Doyle'}, {'authorId': '151021114', 'name': 'Harmonie Dehaene'}, {'authorId': '1699302', 'name': 'M. Dojat'}]","{'url': 'http://arxiv.org/pdf/2210.03736', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2210.03736, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the full acceptance of deep learning (dl) models in the clinical field is rather low with respect to the quantity of high-performing solutions reported in the literature. end users are particularly reluctant to rely on the opaque predictions of dl models. uncertainty quantification methods have been proposed in the literature as a potential solution, to reduce the black-box effect of dl models and increase the interpretability and the acceptability of the result by the final user. in this review, we propose an overview of the existing methods to quantify uncertainty associated with dl predictions. we focus on applications to medical image analysis, which present specific challenges due to the high dimensionality of images and their variable quality, as well as constraints associated with real-world clinical routine. moreover, we discuss the concept of structural uncertainty, a corpus of methods to facilitate the alignment of segmentation uncertainty estimates with clinical attention. we then discuss the evaluation protocols to validate the relevance of uncertainty estimates. finally, we highlight the open challenges for uncertainty quantification in the medical field.",http://arxiv.org/pdf/2210.03736
f84756d1747e9dbc967301408c5e1d7e326b39f6,Deep Learning and Medical Image Analysis for COVID-19 Diagnosis and Prediction.,"The coronavirus disease 2019 (COVID-19) pandemic has imposed dramatic challenges to health-care organizations worldwide. To combat the global crisis, the use of thoracic imaging has played a major role in diagnosis, prediction, and management for COVID-19 patients with moderate to severe symptoms or with evidence of worsening respiratory status. In response, the medical image analysis community acted quickly to develop and disseminate deep learning models and tools to meet the urgent need of managing and interpreting large amounts of COVID-19 imaging data. This review aims to not only summarize existing deep learning and medical image analysis methods but also offer in-depth discussions and recommendations for future investigations. We believe that the wide availability of high-quality, curated, and benchmarked COVID-19 imaging data sets offers the great promise of a transformative test bed to develop, validate, and disseminate novel deep learning methods in the frontiers of data science and artificial intelligence. Expected final online publication date for the Annual Review of Biomedical Engineering, Volume 24 is June 2022. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.",2022,"[{'authorId': '2115345993', 'name': 'Tianming Liu'}, {'authorId': '49943135', 'name': 'E. Siegel'}, {'authorId': '2150038187', 'name': 'Dinggang Shen'}]","{'url': 'https://www.annualreviews.org/doi/pdf/10.1146/annurev-bioeng-110220-012203', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1146/annurev-bioeng-110220-012203?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/annurev-bioeng-110220-012203, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the coronavirus disease 2019 (covid-19) pandemic has imposed dramatic challenges to health-care organizations worldwide. to combat the global crisis, the use of thoracic imaging has played a major role in diagnosis, prediction, and management for covid-19 patients with moderate to severe symptoms or with evidence of worsening respiratory status. in response, the medical image analysis community acted quickly to develop and disseminate deep learning models and tools to meet the urgent need of managing and interpreting large amounts of covid-19 imaging data. this review aims to not only summarize existing deep learning and medical image analysis methods but also offer in-depth discussions and recommendations for future investigations. we believe that the wide availability of high-quality, curated, and benchmarked covid-19 imaging data sets offers the great promise of a transformative test bed to develop, validate, and disseminate novel deep learning methods in the frontiers of data science and artificial intelligence. expected final online publication date for the annual review of biomedical engineering, volume 24 is june 2022. please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.",https://www.annualreviews.org/doi/pdf/10.1146/annurev-bioeng-110220-012203
dff829abffea125d72b9a2f2e0c1a0119b72438f,"Reinforcement learning in medical image analysis: Concepts, applications, challenges, and future directions","Abstract Motivation Medical image analysis involves a series of tasks used to assist physicians in qualitative and quantitative analyses of lesions or anatomical structures which can significantly improve the accuracy and reliability of medical diagnoses and prognoses. Traditionally, these tedious tasks were finished by experienced physicians or medical physicists and were marred with two major problems, low efficiency and bias. In the past decade, many machine learning methods have been applied to accelerate and automate the image analysis process. Compared to the enormous deployments of supervised and unsupervised learning models, attempts to use reinforcement learning in medical image analysis are still scarce. We hope that this review article could serve as the stepping stone for related research in the future. Significance We found that although reinforcement learning has gradually gained momentum in recent years, many researchers in the medical analysis field still find it hard to understand and deploy in clinical settings. One possible cause is a lack of well‐organized review articles intended for readers without professional computer science backgrounds. Rather than to provide a comprehensive list of all reinforcement learning models applied in medical image analysis, the aim of this review is to help the readers formulate and solve their medical image analysis research through the lens of reinforcement learning. Approach & Results We selected published articles from Google Scholar and PubMed. Considering the scarcity of related articles, we also included some outstanding newest preprints. The papers were carefully reviewed and categorized according to the type of image analysis task. In this article, we first reviewed the basic concepts and popular models of reinforcement learning. Then, we explored the applications of reinforcement learning models in medical image analysis. Finally, we concluded the article by discussing the reviewed reinforcement learning approaches’ limitations and possible future improvements.",2022,"[{'authorId': '152300562', 'name': 'Mingzhe Hu'}, {'authorId': '3932837', 'name': 'Jiahan Zhang'}, {'authorId': '2141647236', 'name': 'L. Matkovic'}, {'authorId': '145836604', 'name': 'Tian Liu'}, {'authorId': '145418649', 'name': 'Xiaofeng Yang'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/acm2.13898', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2206.14302, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract motivation medical image analysis involves a series of tasks used to assist physicians in qualitative and quantitative analyses of lesions or anatomical structures which can significantly improve the accuracy and reliability of medical diagnoses and prognoses. traditionally, these tedious tasks were finished by experienced physicians or medical physicists and were marred with two major problems, low efficiency and bias. in the past decade, many machine learning methods have been applied to accelerate and automate the image analysis process. compared to the enormous deployments of supervised and unsupervised learning models, attempts to use reinforcement learning in medical image analysis are still scarce. we hope that this review article could serve as the stepping stone for related research in the future. significance we found that although reinforcement learning has gradually gained momentum in recent years, many researchers in the medical analysis field still find it hard to understand and deploy in clinical settings. one possible cause is a lack of well‐organized review articles intended for readers without professional computer science backgrounds. rather than to provide a comprehensive list of all reinforcement learning models applied in medical image analysis, the aim of this review is to help the readers formulate and solve their medical image analysis research through the lens of reinforcement learning. approach & results we selected published articles from google scholar and pubmed. considering the scarcity of related articles, we also included some outstanding newest preprints. the papers were carefully reviewed and categorized according to the type of image analysis task. in this article, we first reviewed the basic concepts and popular models of reinforcement learning. then, we explored the applications of reinforcement learning models in medical image analysis. finally, we concluded the article by discussing the reviewed reinforcement learning approaches’ limitations and possible future improvements.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/acm2.13898
2e3d1ed66a67b424329df6bf3cb2ff089c8e0758,Machine learning and deep learning approach for medical image analysis: diagnosis to detection,"Computer-aided detection using Deep Learning (DL) and Machine Learning (ML) shows tremendous growth in the medical field. Medical images are considered as the actual origin of appropriate information required for diagnosis of disease. Detection of disease at the initial stage, using various modalities, is one of the most important factors to decrease mortality rate occurring due to cancer and tumors. Modalities help radiologists and doctors to study the internal structure of the detected disease for retrieving the required features. ML has limitations with the present modalities due to large amounts of data, whereas DL works efficiently with any amount of data. Hence, DL is considered as the enhanced technique of ML where ML uses the learning techniques and DL acquires details on how machines should react around people. DL uses a multilayered neural network to get more information about the used datasets. This study aims to present a systematic literature review related to applications of ML and DL for the detection along with classification of multiple diseases. A detailed analysis of 40 primary studies acquired from the well-known journals and conferences between Jan 2014–2022 was done. It provides an overview of different approaches based on ML and DL for the detection along with the classification of multiple diseases, modalities for medical imaging, tools and techniques used for the evaluation, description of datasets. Further, experiments are performed using MRI dataset to provide a comparative analysis of ML classifiers and DL models. This study will assist the healthcare community by enabling medical practitioners and researchers to choose an appropriate diagnosis technique for a given disease with reduced time and high accuracy.",2022,"[{'authorId': '2150502523', 'name': 'Meghavi Rana'}, {'authorId': '49602476', 'name': 'Megha Bhushan'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11042-022-14305-w.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9788870, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","computer-aided detection using deep learning (dl) and machine learning (ml) shows tremendous growth in the medical field. medical images are considered as the actual origin of appropriate information required for diagnosis of disease. detection of disease at the initial stage, using various modalities, is one of the most important factors to decrease mortality rate occurring due to cancer and tumors. modalities help radiologists and doctors to study the internal structure of the detected disease for retrieving the required features. ml has limitations with the present modalities due to large amounts of data, whereas dl works efficiently with any amount of data. hence, dl is considered as the enhanced technique of ml where ml uses the learning techniques and dl acquires details on how machines should react around people. dl uses a multilayered neural network to get more information about the used datasets. this study aims to present a systematic literature review related to applications of ml and dl for the detection along with classification of multiple diseases. a detailed analysis of 40 primary studies acquired from the well-known journals and conferences between jan 2014–2022 was done. it provides an overview of different approaches based on ml and dl for the detection along with the classification of multiple diseases, modalities for medical imaging, tools and techniques used for the evaluation, description of datasets. further, experiments are performed using mri dataset to provide a comparative analysis of ml classifiers and dl models. this study will assist the healthcare community by enabling medical practitioners and researchers to choose an appropriate diagnosis technique for a given disease with reduced time and high accuracy.",https://link.springer.com/content/pdf/10.1007/s11042-022-14305-w.pdf
973b4ccaf1e37553f4587374dc354196f0b20b6c,Diffusion Models for Medical Image Analysis: A Comprehensive Survey,"provide a systematic taxonomy of diffusion models in the medical domain and propose a multi-perspective categorization based on their application, imaging modality, organ of interest, and algorithms. To this end, we cover extensive applications of diffusion models in the medical domain, including segmentation, anomaly detection, image-to-image translation, 2/3D generation, reconstruction, denoising, and other medically-related challenges. Furthermore, we emphasize the practical use case of some selected approaches, and then we discuss the limitations of the diffusion models in the medical domain and propose several directions to fulﬁll the demands of this ﬁeld. Finally, we gather the overviewed studies with their available open-source implementations at our GitHub 1 . We aim to update the relevant latest papers within it regularly.",2022,"[{'authorId': '2131612425', 'name': 'A. Kazerouni'}, {'authorId': '1411236504', 'name': 'Ehsan Khodapanah Aghdam'}, {'authorId': '1491490451', 'name': 'Moein Heidari'}, {'authorId': '1763181', 'name': 'Reza Azad'}, {'authorId': None, 'name': 'Mohsen Fayyaz'}, {'authorId': '1836588', 'name': 'I. Hacihaliloglu'}, {'authorId': '1737693', 'name': 'D. Merhof'}]","{'url': 'http://arxiv.org/pdf/2211.07804', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.48550/arXiv.2211.07804?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.48550/arXiv.2211.07804, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","provide a systematic taxonomy of diffusion models in the medical domain and propose a multi-perspective categorization based on their application, imaging modality, organ of interest, and algorithms. to this end, we cover extensive applications of diffusion models in the medical domain, including segmentation, anomaly detection, image-to-image translation, 2/3d generation, reconstruction, denoising, and other medically-related challenges. furthermore, we emphasize the practical use case of some selected approaches, and then we discuss the limitations of the diffusion models in the medical domain and propose several directions to fulﬁll the demands of this ﬁeld. finally, we gather the overviewed studies with their available open-source implementations at our github 1 . we aim to update the relevant latest papers within it regularly.",http://arxiv.org/pdf/2211.07804
a323533f5f50cfce949d47caac97f791cdf1bf92,Medical image analysis based on deep learning approach,"Medical imaging plays a significant role in different clinical applications such as medical procedures used for early detection, monitoring, diagnosis, and treatment evaluation of various medical conditions. Basicsof the principles and implementations of artificial neural networks and deep learning are essential for understanding medical image analysis in computer vision. Deep Learning Approach (DLA) in medical image analysis emerges as a fast-growing research field. DLA has been widely used in medical imaging to detect the presence or absence of the disease. This paper presents the development of artificial neural networks, comprehensive analysis of DLA, which delivers promising medical imaging applications. Most of the DLA implementations concentrate on the X-ray images, computerized tomography, mammography images, and digital histopathology images. It provides a systematic review of the articles for classification, detection, and segmentation of medical images based on DLA. This review guides the researchers to think of appropriate changes in medical image analysis based on DLA.",2021,"[{'authorId': '2089639744', 'name': 'M. Puttagunta'}, {'authorId': '1728012', 'name': 'R. Subban'}]","{'url': 'https://doi.org/10.1007/s11042-021-10707-4', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8023554, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","medical imaging plays a significant role in different clinical applications such as medical procedures used for early detection, monitoring, diagnosis, and treatment evaluation of various medical conditions. basicsof the principles and implementations of artificial neural networks and deep learning are essential for understanding medical image analysis in computer vision. deep learning approach (dla) in medical image analysis emerges as a fast-growing research field. dla has been widely used in medical imaging to detect the presence or absence of the disease. this paper presents the development of artificial neural networks, comprehensive analysis of dla, which delivers promising medical imaging applications. most of the dla implementations concentrate on the x-ray images, computerized tomography, mammography images, and digital histopathology images. it provides a systematic review of the articles for classification, detection, and segmentation of medical images based on dla. this review guides the researchers to think of appropriate changes in medical image analysis based on dla.",https://doi.org/10.1007/s11042-021-10707-4
f92ad8137c1f09af7381a6b14e1bd7d225cfe46e,Prospects of Structural Similarity Index for Medical Image Analysis,"An image quality matrix provides a significant principle for objectively observing an image based on an alteration between the original and distorted images. During the past two decades, a novel universal image quality assessment has been developed with the ability of adaptation with human visual perception for measuring the difference of a degraded image from the reference image, namely a structural similarity index. Structural similarity has since been widely used in various sectors, including medical image evaluation. Although numerous studies have reported the use of structural similarity as an evaluation strategy for computer-based medical images, reviews on the prospects of using structural similarity for medical imaging applications have been rare. This paper presents previous studies implementing structural similarity in analyzing medical images from various imaging modalities. In addition, this review describes structural similarity from the perspective of a family’s historical background, as well as progress made from the original to the recent structural similarity, and its strengths and drawbacks. Additionally, potential research directions in applying such similarities related to medical image analyses are described. This review will be beneficial in guiding researchers toward the discovery of potential medical image examination methods that can be improved through structural similarity index.",2022,"[{'authorId': '74508051', 'name': 'Vicky Mudeng'}, {'authorId': '2162023984', 'name': 'Minseok Kim'}, {'authorId': '5638921', 'name': 'S. Choe'}]","{'url': 'https://www.mdpi.com/2076-3417/12/8/3754/pdf?version=1649476691', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app12083754?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app12083754, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","an image quality matrix provides a significant principle for objectively observing an image based on an alteration between the original and distorted images. during the past two decades, a novel universal image quality assessment has been developed with the ability of adaptation with human visual perception for measuring the difference of a degraded image from the reference image, namely a structural similarity index. structural similarity has since been widely used in various sectors, including medical image evaluation. although numerous studies have reported the use of structural similarity as an evaluation strategy for computer-based medical images, reviews on the prospects of using structural similarity for medical imaging applications have been rare. this paper presents previous studies implementing structural similarity in analyzing medical images from various imaging modalities. in addition, this review describes structural similarity from the perspective of a family’s historical background, as well as progress made from the original to the recent structural similarity, and its strengths and drawbacks. additionally, potential research directions in applying such similarities related to medical image analyses are described. this review will be beneficial in guiding researchers toward the discovery of potential medical image examination methods that can be improved through structural similarity index.",https://www.mdpi.com/2076-3417/12/8/3754/pdf?version=1649476691
8f09c361f0f0df94c0deca17d1fa5ac68839ed92,Computational Technique Based on Machine Learning and Image Processing for Medical Image Analysis of Breast Cancer Diagnosis,"Breast cancer is the most lethal type of cancer for all women worldwide. At the moment, there are no effective techniques for preventing or curing breast cancer, as the source of the disease is unclear. Early diagnosis is a highly successful means of detecting and managing breast cancer, and early identification may result in a greater likelihood of complete recovery. Mammography is the most effective method of detecting breast cancer early. Additionally, this instrument enables the detection of additional illnesses and may provide information about the nature of cancer, such as benign, malignant, or normal. This article discusses an evolutionary approach for classifying and detecting breast cancer that is based on machine learning and image processing. This model combines image preprocessing, feature extraction, feature selection, and machine learning techniques to aid in the classification and identification of skin diseases. To enhance the image’s quality, a geometric mean filter is used. AlexNet is used for extracting features. Feature selection is performed using the relief algorithm. For disease categorization and detection, the model makes use of the machine learning techniques such as least square support vector machine, KNN, random forest, and Naïve Bayes. The experimental investigation makes use of MIAS data collection. This proposed technology is advantageous for accurately identifying breast cancer disease using image analysis.",2022,"[{'authorId': '2265531647', 'name': 'V. Durga'}, {'authorId': '2265534643', 'name': 'Prasad Jasti'}, {'authorId': '67145327', 'name': 'A. S. Zamani'}, {'authorId': '2099076331', 'name': 'K. Arumugam'}, {'authorId': '120968374', 'name': 'M. Naved'}, {'authorId': '2120705465', 'name': 'Harikumar Pallathadka'}, {'authorId': '2157605968', 'name': 'F. Sammy'}, {'authorId': '9710574', 'name': 'Abhishek Raghuvanshi'}, {'authorId': '145142173', 'name': 'K. Kaliyaperumal'}]","{'url': 'https://downloads.hindawi.com/journals/scn/2022/1918379.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1155/2022/1918379?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1155/2022/1918379, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","breast cancer is the most lethal type of cancer for all women worldwide. at the moment, there are no effective techniques for preventing or curing breast cancer, as the source of the disease is unclear. early diagnosis is a highly successful means of detecting and managing breast cancer, and early identification may result in a greater likelihood of complete recovery. mammography is the most effective method of detecting breast cancer early. additionally, this instrument enables the detection of additional illnesses and may provide information about the nature of cancer, such as benign, malignant, or normal. this article discusses an evolutionary approach for classifying and detecting breast cancer that is based on machine learning and image processing. this model combines image preprocessing, feature extraction, feature selection, and machine learning techniques to aid in the classification and identification of skin diseases. to enhance the image’s quality, a geometric mean filter is used. alexnet is used for extracting features. feature selection is performed using the relief algorithm. for disease categorization and detection, the model makes use of the machine learning techniques such as least square support vector machine, knn, random forest, and naïve bayes. the experimental investigation makes use of mias data collection. this proposed technology is advantageous for accurately identifying breast cancer disease using image analysis.",https://downloads.hindawi.com/journals/scn/2022/1918379.pdf
2979b4a59d3aa847b2e2b3254d351060dff50e55,Survey on natural language processing in medical image analysis.,"Recent advancement in natural language processing (NLP) and medical imaging empowers the wide applicability of deep learning models. These developments have increased not only data understanding, but also knowledge of state-of-the-art architectures and their real-world potentials. Medical imaging researchers have recognized the limitations of only targeting images, as well as the importance of integrating multimodal inputs into medical image analysis. The lack of comprehensive surveys of the current literature, however, impedes the progress of this domain. Existing research perspectives, as well as the architectures, tasks, datasets, and performance measures examined in the present literature, are reviewed in this work, and we also provide a brief description of possible future directions in the field, aiming to provide researchers and healthcare professionals with a detailed summary of existing academic research and to provide rational insights to facilitate future research.",2022,"[{'authorId': '70995262', 'name': 'Zheng-Long Liu'}, {'authorId': '2165762495', 'name': 'Mengshen He'}, {'authorId': '2184750732', 'name': 'Zuowei Jiang'}, {'authorId': '47039788', 'name': 'Zihao Wu'}, {'authorId': '29944950', 'name': 'Haixing Dai'}, {'authorId': '2146645863', 'name': 'Lian-Cheng Zhang'}, {'authorId': '2114031329', 'name': 'Siyi Luo'}, {'authorId': '2184719751', 'name': 'Tianle Han'}, {'authorId': '2144438902', 'name': 'Xiang Li'}, {'authorId': '143796247', 'name': 'Xi Jiang'}, {'authorId': '2181182', 'name': 'Dajiang Zhu'}, {'authorId': '2149789733', 'name': 'Xiaoyan Cai'}, {'authorId': '144691205', 'name': 'Bao Ge'}, {'authorId': '46641573', 'name': 'W. Liu'}, {'authorId': '49722346', 'name': 'Jun Liu'}, {'authorId': '2150038187', 'name': 'Dinggang Shen'}, {'authorId': '2115345993', 'name': 'Tianming Liu'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.11817/j.issn.1672-7347.2022.220376?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.11817/j.issn.1672-7347.2022.220376, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent advancement in natural language processing (nlp) and medical imaging empowers the wide applicability of deep learning models. these developments have increased not only data understanding, but also knowledge of state-of-the-art architectures and their real-world potentials. medical imaging researchers have recognized the limitations of only targeting images, as well as the importance of integrating multimodal inputs into medical image analysis. the lack of comprehensive surveys of the current literature, however, impedes the progress of this domain. existing research perspectives, as well as the architectures, tasks, datasets, and performance measures examined in the present literature, are reviewed in this work, and we also provide a brief description of possible future directions in the field, aiming to provide researchers and healthcare professionals with a detailed summary of existing academic research and to provide rational insights to facilitate future research.",
0e7b682d55d9f102b98c7824313e4806d847bb63,"DiRA: Discriminative, Restorative, and Adversarial Learning for Self-supervised Medical Image Analysis","Discriminative learning, restorative learning, and adversarial learning have proven beneficial for self-supervised learning schemes in computer vision and medical imaging. Existing efforts, however, omit their synergistic effects on each other in a ternary setup, which, we envision, can sig-nificantly benefit deep semantic representation learning. To realize this vision, we have developed DiRA, thefirstframework that unites discriminative, restorative, and adversarial learning in a unified manner to collaboratively glean complementary visual information from unlabeled medical images for fine-grained semantic representation learning. Our extensive experiments demonstrate that DiRA (1) encourages collaborative learning among three learning ingredients, resulting in more generalizable representation across organs, diseases, and modalities; (2) outperforms fully supervised ImageNet models and increases robustness in small data regimes, reducing annotation cost across multiple medical imaging applications; (3) learns fine-grained semantic representation, facilitating accurate lesion localization with only image-level annotation; and (4) enhances state-of-the-art restorative approaches, revealing that DiRA is a general mechanism for united representation learning. All code and pretrained models are available at https://github.com/JLiangLab/DiRA.",2022,"[{'authorId': '2073573316', 'name': 'F. Haghighi'}, {'authorId': '21811029', 'name': 'M. Taher'}, {'authorId': '1777226', 'name': 'M. Gotway'}, {'authorId': '1485304039', 'name': 'Jianming Liang'}]","{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9615927', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2204.10437, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","discriminative learning, restorative learning, and adversarial learning have proven beneficial for self-supervised learning schemes in computer vision and medical imaging. existing efforts, however, omit their synergistic effects on each other in a ternary setup, which, we envision, can sig-nificantly benefit deep semantic representation learning. to realize this vision, we have developed dira, thefirstframework that unites discriminative, restorative, and adversarial learning in a unified manner to collaboratively glean complementary visual information from unlabeled medical images for fine-grained semantic representation learning. our extensive experiments demonstrate that dira (1) encourages collaborative learning among three learning ingredients, resulting in more generalizable representation across organs, diseases, and modalities; (2) outperforms fully supervised imagenet models and increases robustness in small data regimes, reducing annotation cost across multiple medical imaging applications; (3) learns fine-grained semantic representation, facilitating accurate lesion localization with only image-level annotation; and (4) enhances state-of-the-art restorative approaches, revealing that dira is a general mechanism for united representation learning. all code and pretrained models are available at https://github.com/jlianglab/dira.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9615927
60f484f0769a2916fb6706160990a134f6b4ca0b,A review on deep learning in medical image analysis,"Ongoing improvements in AI, particularly concerning deep learning techniques, are assisting to identify, classify, and quantify patterns in clinical images. Deep learning is the quickest developing field in artificial intelligence and is effectively utilized lately in numerous areas, including medication. A brief outline is given on studies carried out on the region of application: neuro, brain, retinal, pneumonic, computerized pathology, bosom, heart, breast, bone, stomach, and musculoskeletal. For information exploration, knowledge deployment, and knowledge-based prediction, deep learning networks can be successfully applied to big data. In the field of medical image processing methods and analysis, fundamental information and state-of-the-art approaches with deep learning are presented in this paper. The primary goals of this paper are to present research on medical image processing as well as to define and implement the key guidelines that are identified and addressed.",2021,"[{'authorId': '70137278', 'name': 'S. Suganyadevi'}, {'authorId': '148318113', 'name': 'V. Seethalakshmi'}, {'authorId': '9210990', 'name': 'K. Balasamy'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s13735-021-00218-1.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8417661, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ongoing improvements in ai, particularly concerning deep learning techniques, are assisting to identify, classify, and quantify patterns in clinical images. deep learning is the quickest developing field in artificial intelligence and is effectively utilized lately in numerous areas, including medication. a brief outline is given on studies carried out on the region of application: neuro, brain, retinal, pneumonic, computerized pathology, bosom, heart, breast, bone, stomach, and musculoskeletal. for information exploration, knowledge deployment, and knowledge-based prediction, deep learning networks can be successfully applied to big data. in the field of medical image processing methods and analysis, fundamental information and state-of-the-art approaches with deep learning are presented in this paper. the primary goals of this paper are to present research on medical image processing as well as to define and implement the key guidelines that are identified and addressed.",https://link.springer.com/content/pdf/10.1007/s13735-021-00218-1.pdf
ba86fd31927a17402c51d3d3fb28426d7a885434,Carbon Footprint of Selecting and Training Deep Learning Models for Medical Image Analysis,"The increasing energy consumption and carbon footprint of deep learning (DL) due to growing compute requirements has become a cause of concern. In this work, we focus on the carbon footprint of developing DL models for medical image analysis (MIA), where volumetric images of high spatial resolution are handled. In this study, we present and compare the features of four tools from literature to quantify the carbon footprint of DL. Using one of these tools we estimate the carbon footprint of medical image segmentation pipelines. We choose nnU-net as the proxy for a medical image segmentation pipeline and experiment on three common datasets. With our work we hope to inform on the increasing energy costs incurred by MIA. We discuss simple strategies to cut-down the environmental impact that can make model selection and training processes more efficient.",2022,"[{'authorId': '36481129', 'name': 'Raghavendra Selvan'}, {'authorId': '145830583', 'name': 'N. Bhagwat'}, {'authorId': '1796297717', 'name': 'Lasse F. Wolff Anthony'}, {'authorId': '1796297710', 'name': 'Benjamin Kanding'}, {'authorId': '49831508', 'name': 'E. Dam'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2203.02202, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the increasing energy consumption and carbon footprint of deep learning (dl) due to growing compute requirements has become a cause of concern. in this work, we focus on the carbon footprint of developing dl models for medical image analysis (mia), where volumetric images of high spatial resolution are handled. in this study, we present and compare the features of four tools from literature to quantify the carbon footprint of dl. using one of these tools we estimate the carbon footprint of medical image segmentation pipelines. we choose nnu-net as the proxy for a medical image segmentation pipeline and experiment on three common datasets. with our work we hope to inform on the increasing energy costs incurred by mia. we discuss simple strategies to cut-down the environmental impact that can make model selection and training processes more efficient.",
18092e6aec7507b58425a99b3c1e42af117aa963,Deep Perceptual Enhancement for Medical Image Analysis,"Due to numerous hardware shortcomings, medical image acquisition devices are susceptible to producing low-quality (i.e., low contrast, inappropriate brightness, noisy, etc.) images. Regrettably, perceptually degraded images directly impact the diagnosis process and make the decision-making manoeuvre of medical practitioners notably complicated. This study proposes to enhance such low-quality images by incorporating end-to-end learning strategies for accelerating medical image analysis tasks. To the best concern, this is the first work in medical imaging which comprehensively tackles perceptual enhancement, including contrast correction, luminance correction, denoising, etc., with a fully convolutional deep network. The proposed network leverages residual blocks and a residual gating mechanism for diminishing visual artefacts and is guided by a multi-term objective function to perceive the perceptually plausible enhanced images. The practicability of the deep medical image enhancement method has been extensively investigated with sophisticated experiments. The experimental outcomes illustrate that the proposed method could outperform the existing enhancement methods for different medical image modalities by 5.00 to 7.00 dB in peak signal-to-noise ratio (PSNR) metrics and 4.00 to 6.00 in DeltaE metrics. Additionally, the proposed method can drastically improve the medical image analysis tasks’ performance and reveal the potentiality of such an enhancement method in real-world applications.",2022,"[{'authorId': '122143632', 'name': 'S. Sharif'}, {'authorId': '8683310', 'name': 'R. A. Naqvi'}, {'authorId': '49509958', 'name': 'Mithun Biswas'}, {'authorId': '145335823', 'name': 'W. Loh'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.08027, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","due to numerous hardware shortcomings, medical image acquisition devices are susceptible to producing low-quality (i.e., low contrast, inappropriate brightness, noisy, etc.) images. regrettably, perceptually degraded images directly impact the diagnosis process and make the decision-making manoeuvre of medical practitioners notably complicated. this study proposes to enhance such low-quality images by incorporating end-to-end learning strategies for accelerating medical image analysis tasks. to the best concern, this is the first work in medical imaging which comprehensively tackles perceptual enhancement, including contrast correction, luminance correction, denoising, etc., with a fully convolutional deep network. the proposed network leverages residual blocks and a residual gating mechanism for diminishing visual artefacts and is guided by a multi-term objective function to perceive the perceptually plausible enhanced images. the practicability of the deep medical image enhancement method has been extensively investigated with sophisticated experiments. the experimental outcomes illustrate that the proposed method could outperform the existing enhancement methods for different medical image modalities by 5.00 to 7.00 db in peak signal-to-noise ratio (psnr) metrics and 4.00 to 6.00 in deltae metrics. additionally, the proposed method can drastically improve the medical image analysis tasks’ performance and reveal the potentiality of such an enhancement method in real-world applications.",
563ac63ef99c8f6416ce4f6463355412d1f20b34,A review on optimization techniques for medical image analysis,"Data mining of medical imaging approaches makes it difficult to determine their value in the disease's insight, analysis, and diagnosis. Image classification presents a significant difficulty in image analysis and plays a vital part in computer‐aided diagnosis. This task concerned the use of optimization techniques for the utilization of image processing, pattern recognition, and classification techniques, as well as the validation of image classification results in medical expert reports. The primary intention of this study is to analyze the performance of optimization techniques explored in the area of medical image analysis. For this motive, the optimization techniques employed in existing literature from 2012 to 2021 are reviewed in this study. The contribution of optimization‐based medical image classification and segmentation utilized image modalities, data sets, and tradeoffs for each technique are also discussed in this review study. Finally, this review study provides the gap analysis of optimization techniques used in medical image analysis with the possible future research direction.",2022,"[{'authorId': '16024524', 'name': 'P. Kaur'}, {'authorId': '2115744151', 'name': 'R. Singh'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/cpe.7443?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/cpe.7443, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","data mining of medical imaging approaches makes it difficult to determine their value in the disease's insight, analysis, and diagnosis. image classification presents a significant difficulty in image analysis and plays a vital part in computer‐aided diagnosis. this task concerned the use of optimization techniques for the utilization of image processing, pattern recognition, and classification techniques, as well as the validation of image classification results in medical expert reports. the primary intention of this study is to analyze the performance of optimization techniques explored in the area of medical image analysis. for this motive, the optimization techniques employed in existing literature from 2012 to 2021 are reviewed in this study. the contribution of optimization‐based medical image classification and segmentation utilized image modalities, data sets, and tradeoffs for each technique are also discussed in this review study. finally, this review study provides the gap analysis of optimization techniques used in medical image analysis with the possible future research direction.",
b732f91b7b0a317d8ee9d5c7b6efe9801442a106,A Review of Causality for Learning Algorithms in Medical Image Analysis,"Medical image analysis is a vibrant research area that offers doctors and medical practitioners invaluable insight and the ability to accurately diagnose and monitor disease. Machine learning provides an additional boost for this area. However, machine learning for medical image analysis is particularly vulnerable to natural biases like domain shifts that affect algorithmic performance and robustness. In this paper we analyze machine learning for medical image analysis within the framework of Technology Readiness Levels and review how causal analysis methods can fill a gap when creating robust and adaptable medical image analysis algorithms.We review methods using causality in medical imaging AI/ML and find that causal analysis has the potential to mitigate critical problems for clinical translation but that uptake and clinical downstream research has been limited so far.",2022,"[{'authorId': '3468426', 'name': 'Athanasios Vlontzos'}, {'authorId': '1717710', 'name': 'D. Rueckert'}, {'authorId': '2015193', 'name': 'Bernhard Kainz'}]","{'url': 'https://arxiv.org/pdf/2206.05498', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2206.05498, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","medical image analysis is a vibrant research area that offers doctors and medical practitioners invaluable insight and the ability to accurately diagnose and monitor disease. machine learning provides an additional boost for this area. however, machine learning for medical image analysis is particularly vulnerable to natural biases like domain shifts that affect algorithmic performance and robustness. in this paper we analyze machine learning for medical image analysis within the framework of technology readiness levels and review how causal analysis methods can fill a gap when creating robust and adaptable medical image analysis algorithms.we review methods using causality in medical imaging ai/ml and find that causal analysis has the potential to mitigate critical problems for clinical translation but that uptake and clinical downstream research has been limited so far.",https://arxiv.org/pdf/2206.05498
94eb4b5f09b5767b3d2f2f0a1c10604f517f2381,OrthoFinder: phylogenetic orthology inference for comparative genomics,"Here, we present a major advance of the OrthoFinder method. This extends OrthoFinder’s high accuracy orthogroup inference to provide phylogenetic inference of orthologs, rooted gene trees, gene duplication events, the rooted species tree, and comparative genomics statistics. Each output is benchmarked on appropriate real or simulated datasets, and where comparable methods exist, OrthoFinder is equivalent to or outperforms these methods. Furthermore, OrthoFinder is the most accurate ortholog inference method on the Quest for Orthologs benchmark test. Finally, OrthoFinder’s comprehensive phylogenetic analysis is achieved with equivalent speed and scalability to the fastest, score-based heuristic methods. OrthoFinder is available at https://github.com/davidemms/OrthoFinder.",2019,"[{'authorId': '2357680', 'name': 'David M. Emms'}, {'authorId': '143753176', 'name': 'S. Kelly'}]","{'url': 'https://doi.org/10.1186/s13059-019-1832-y', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6857279, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","here, we present a major advance of the orthofinder method. this extends orthofinder’s high accuracy orthogroup inference to provide phylogenetic inference of orthologs, rooted gene trees, gene duplication events, the rooted species tree, and comparative genomics statistics. each output is benchmarked on appropriate real or simulated datasets, and where comparable methods exist, orthofinder is equivalent to or outperforms these methods. furthermore, orthofinder is the most accurate ortholog inference method on the quest for orthologs benchmark test. finally, orthofinder’s comprehensive phylogenetic analysis is achieved with equivalent speed and scalability to the fastest, score-based heuristic methods. orthofinder is available at https://github.com/davidemms/orthofinder.",https://doi.org/10.1186/s13059-019-1832-y
eaffef2e8d56d454e77f5b67ecd85ce69e8cc511,Standards and Guidelines for the Interpretation of Sequence Variants: A Joint Consensus Recommendation of the American College of Medical Genetics and Genomics and the Association for Molecular Pathology,"Disclaimer: These ACMG Standards and Guidelines were developed primarily as an educational resource for clinical laboratory geneticists to help them provide quality clinical laboratory services. Adherence to these standards and guidelines is voluntary and does not necessarily assure a successful medical outcome. These Standards and Guidelines should not be considered inclusive of all proper procedures and tests or exclusive of other procedures and tests that are reasonably directed to obtaining the same results. In determining the propriety of any specific procedure or test, the clinical laboratory geneticist should apply his or her own professional judgment to the specific circumstances presented by the individual patient or specimen. Clinical laboratory geneticists are encouraged to document in the patient’s record the rationale for the use of a particular procedure or test, whether or not it is in conformance with these Standards and Guidelines. They also are advised to take notice of the date any particular guideline was adopted and to consider other relevant medical and scientific information that becomes available after that date. It also would be prudent to consider whether intellectual property interests may restrict the performance of certain tests and other procedures.The American College of Medical Genetics and Genomics (ACMG) previously developed guidance for the interpretation of sequence variants.1 In the past decade, sequencing technology has evolved rapidly with the advent of high-throughput next-generation sequencing. By adopting and leveraging next-generation sequencing, clinical laboratories are now performing an ever-increasing catalogue of genetic testing spanning genotyping, single genes, gene panels, exomes, genomes, transcriptomes, and epigenetic assays for genetic disorders. By virtue of increased complexity, this shift in genetic testing has been accompanied by new challenges in sequence interpretation. In this context the ACMG convened a workgroup in 2013 comprising representatives from the ACMG, the Association for Molecular Pathology (AMP), and the College of American Pathologists to revisit and revise the standards and guidelines for the interpretation of sequence variants. The group consisted of clinical laboratory directors and clinicians. This report represents expert opinion of the workgroup with input from ACMG, AMP, and College of American Pathologists stakeholders. These recommendations primarily apply to the breadth of genetic tests used in clinical laboratories, including genotyping, single genes, panels, exomes, and genomes. This report recommends the use of specific standard terminology—“pathogenic,” “likely pathogenic,” “uncertain significance,” “likely benign,” and “benign”—to describe variants identified in genes that cause Mendelian disorders. Moreover, this recommendation describes a process for classifying variants into these five categories based on criteria using typical types of variant evidence (e.g., population data, computational data, functional data, segregation data). Because of the increased complexity of analysis and interpretation of clinical genetic testing described in this report, the ACMG strongly recommends that clinical molecular genetic testing should be performed in a Clinical Laboratory Improvement Amendments–approved laboratory, with results interpreted by a board-certified clinical molecular geneticist or molecular genetic pathologist or the equivalent.Genet Med 17 5, 405–423.",2015,"[{'authorId': '145918615', 'name': 'Sue Richards'}, {'authorId': '46347713', 'name': 'Nazneen Aziz'}, {'authorId': '3007876', 'name': 'S. Bale'}, {'authorId': '143837583', 'name': 'D. Bick'}, {'authorId': '145421902', 'name': 'Soma Das'}, {'authorId': '1397929074', 'name': 'J. Gastier-Foster'}, {'authorId': '4916818', 'name': 'W. Grody'}, {'authorId': '2328053', 'name': 'M. Hegde'}, {'authorId': '144022652', 'name': 'E. Lyon'}, {'authorId': '10020102', 'name': 'E. Spector'}, {'authorId': '2180014', 'name': 'K. Voelkerding'}, {'authorId': '2568693', 'name': 'H. Rehm'}]","{'url': 'https://doi.org/10.1038/gim.2015.30', 'status': 'BRONZE', 'license': 'publisher-specific-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4544753, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","disclaimer: these acmg standards and guidelines were developed primarily as an educational resource for clinical laboratory geneticists to help them provide quality clinical laboratory services. adherence to these standards and guidelines is voluntary and does not necessarily assure a successful medical outcome. these standards and guidelines should not be considered inclusive of all proper procedures and tests or exclusive of other procedures and tests that are reasonably directed to obtaining the same results. in determining the propriety of any specific procedure or test, the clinical laboratory geneticist should apply his or her own professional judgment to the specific circumstances presented by the individual patient or specimen. clinical laboratory geneticists are encouraged to document in the patient’s record the rationale for the use of a particular procedure or test, whether or not it is in conformance with these standards and guidelines. they also are advised to take notice of the date any particular guideline was adopted and to consider other relevant medical and scientific information that becomes available after that date. it also would be prudent to consider whether intellectual property interests may restrict the performance of certain tests and other procedures.the american college of medical genetics and genomics (acmg) previously developed guidance for the interpretation of sequence variants.1 in the past decade, sequencing technology has evolved rapidly with the advent of high-throughput next-generation sequencing. by adopting and leveraging next-generation sequencing, clinical laboratories are now performing an ever-increasing catalogue of genetic testing spanning genotyping, single genes, gene panels, exomes, genomes, transcriptomes, and epigenetic assays for genetic disorders. by virtue of increased complexity, this shift in genetic testing has been accompanied by new challenges in sequence interpretation. in this context the acmg convened a workgroup in 2013 comprising representatives from the acmg, the association for molecular pathology (amp), and the college of american pathologists to revisit and revise the standards and guidelines for the interpretation of sequence variants. the group consisted of clinical laboratory directors and clinicians. this report represents expert opinion of the workgroup with input from acmg, amp, and college of american pathologists stakeholders. these recommendations primarily apply to the breadth of genetic tests used in clinical laboratories, including genotyping, single genes, panels, exomes, and genomes. this report recommends the use of specific standard terminology—“pathogenic,” “likely pathogenic,” “uncertain significance,” “likely benign,” and “benign”—to describe variants identified in genes that cause mendelian disorders. moreover, this recommendation describes a process for classifying variants into these five categories based on criteria using typical types of variant evidence (e.g., population data, computational data, functional data, segregation data). because of the increased complexity of analysis and interpretation of clinical genetic testing described in this report, the acmg strongly recommends that clinical molecular genetic testing should be performed in a clinical laboratory improvement amendments–approved laboratory, with results interpreted by a board-certified clinical molecular geneticist or molecular genetic pathologist or the equivalent.genet med 17 5, 405–423.",https://doi.org/10.1038/gim.2015.30
b8d2639696825d163188eb5cea5582c350987b70,The cBio cancer genomics portal: an open platform for exploring multidimensional cancer genomics data.,"The cBio Cancer Genomics Portal (http://cbioportal.org) is an open-access resource for interactive exploration of multidimensional cancer genomics data sets, currently providing access to data from more than 5,000 tumor samples from 20 cancer studies. The cBio Cancer Genomics Portal significantly lowers the barriers between complex genomic data and cancer researchers who want rapid, intuitive, and high-quality access to molecular profiles and clinical attributes from large-scale cancer genomics projects and empowers researchers to translate these rich data sets into biologic insights and clinical applications.",2012,"[{'authorId': '49248672', 'name': 'E. Cerami'}, {'authorId': '3208622', 'name': 'Jianjiong Gao'}, {'authorId': '2276851', 'name': 'U. Dogrusoz'}, {'authorId': '34762869', 'name': 'Benjamin E. Gross'}, {'authorId': '48666631', 'name': 'S. O. Sumer'}, {'authorId': '6562624', 'name': 'B. A. Aksoy'}, {'authorId': '46315066', 'name': 'A. Jacobsen'}, {'authorId': '2053672816', 'name': 'Caitlin J. Byrne'}, {'authorId': '47026700', 'name': 'M. Heuer'}, {'authorId': '145353250', 'name': 'E. Larsson'}, {'authorId': '4800883', 'name': 'Yevgeniy Antipin'}, {'authorId': '78881029', 'name': 'B. Reva'}, {'authorId': '145555528', 'name': 'A. P. Goldberg'}, {'authorId': '144882390', 'name': 'C. Sander'}, {'authorId': '145687347', 'name': 'N. Schultz'}]","{'url': 'https://repository.bilkent.edu.tr/bitstreams/ed6dbb86-1cf7-4a87-93f4-37dc45773d8e/download', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1158/2159-8290.CD-12-0095?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1158/2159-8290.CD-12-0095, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the cbio cancer genomics portal (http://cbioportal.org) is an open-access resource for interactive exploration of multidimensional cancer genomics data sets, currently providing access to data from more than 5,000 tumor samples from 20 cancer studies. the cbio cancer genomics portal significantly lowers the barriers between complex genomic data and cancer researchers who want rapid, intuitive, and high-quality access to molecular profiles and clinical attributes from large-scale cancer genomics projects and empowers researchers to translate these rich data sets into biologic insights and clinical applications.",https://repository.bilkent.edu.tr/bitstreams/ed6dbb86-1cf7-4a87-93f4-37dc45773d8e/download
e0bdf416f117ecb4ff15a6d3571e105918128934,Integrative Genomics Viewer (IGV): high-performance genomics data visualization and exploration,"Data visualization is an essential component of genomic data analysis. However, the size and diversity of the data sets produced by today’s sequencing and array-based profiling methods present major challenges to visualization tools. The Integrative Genomics Viewer (IGV) is a high-performance viewer that efficiently handles large heterogeneous data sets, while providing a smooth and intuitive user experience at all levels of genome resolution. A key characteristic of IGV is its focus on the integrative nature of genomic studies, with support for both array-based and next-generation sequencing data, and the integration of clinical and phenotypic data. Although IGV is often used to view genomic data from public sources, its primary emphasis is to support researchers who wish to visualize and explore their own data sets or those from colleagues. To that end, IGV supports flexible loading of local and remote data sets, and is optimized to provide high-performance data visualization and exploration on standard desktop systems. IGV is freely available for download from http://www.broadinstitute.org/igv, under a GNU LGPL open-source license.",2012,"[{'authorId': '1925678', 'name': 'H. Thorvaldsdóttir'}, {'authorId': '2115279017', 'name': 'James T. Robinson'}, {'authorId': '1727782', 'name': 'J. Mesirov'}]","{'url': 'https://europepmc.org/articles/pmc3603213?pdf=render', 'status': 'GREEN', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3603213, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","data visualization is an essential component of genomic data analysis. however, the size and diversity of the data sets produced by today’s sequencing and array-based profiling methods present major challenges to visualization tools. the integrative genomics viewer (igv) is a high-performance viewer that efficiently handles large heterogeneous data sets, while providing a smooth and intuitive user experience at all levels of genome resolution. a key characteristic of igv is its focus on the integrative nature of genomic studies, with support for both array-based and next-generation sequencing data, and the integration of clinical and phenotypic data. although igv is often used to view genomic data from public sources, its primary emphasis is to support researchers who wish to visualize and explore their own data sets or those from colleagues. to that end, igv supports flexible loading of local and remote data sets, and is optimized to provide high-performance data visualization and exploration on standard desktop systems. igv is freely available for download from http://www.broadinstitute.org/igv, under a gnu lgpl open-source license.",https://europepmc.org/articles/pmc3603213?pdf=render
630f0cb7242b62d834c23bf85e819f725503af7c,Integrative Genomics Viewer,"Rapid improvements in sequencing and array-based platforms are resulting in a flood of diverse genome-wide data, including data from exome and whole-genome sequencing, epigenetic surveys, expression profiling of coding and noncoding RNAs, single nucleotide polymorphism (SNP) and copy number profiling, and functional assays. Analysis of these large, diverse data sets holds the promise of a more comprehensive understanding of the genome and its relation to human disease. Experienced and knowledgeable human review is an essential component of this process, complementing computational approaches. This calls for efficient and intuitive visualization tools able to scale to very large data sets and to flexibly integrate multiple data types, including clinical data. However, the sheer volume and scope of data pose a significant challenge to the development of such tools.",2011,"[{'authorId': '2115279017', 'name': 'James T. Robinson'}, {'authorId': '1925678', 'name': 'H. Thorvaldsdóttir'}, {'authorId': '2060379', 'name': 'W. Winckler'}, {'authorId': '27694056', 'name': 'M. Guttman'}, {'authorId': '9311320', 'name': 'E. Lander'}, {'authorId': '2110594', 'name': 'G. Getz'}, {'authorId': '1727782', 'name': 'J. Mesirov'}]","{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3346182', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3346182, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","rapid improvements in sequencing and array-based platforms are resulting in a flood of diverse genome-wide data, including data from exome and whole-genome sequencing, epigenetic surveys, expression profiling of coding and noncoding rnas, single nucleotide polymorphism (snp) and copy number profiling, and functional assays. analysis of these large, diverse data sets holds the promise of a more comprehensive understanding of the genome and its relation to human disease. experienced and knowledgeable human review is an essential component of this process, complementing computational approaches. this calls for efficient and intuitive visualization tools able to scale to very large data sets and to flexibly integrate multiple data types, including clinical data. however, the sheer volume and scope of data pose a significant challenge to the development of such tools.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3346182
1823026160626ed2cd47de840d3829a7bb2ebb38,NCBI GEO: archive for functional genomics data sets—update,"The Gene Expression Omnibus (GEO, http://www.ncbi.nlm.nih.gov/geo/) is an international public repository for high-throughput microarray and next-generation sequence functional genomic data sets submitted by the research community. The resource supports archiving of raw data, processed data and metadata which are indexed, cross-linked and searchable. All data are freely available for download in a variety of formats. GEO also provides several web-based tools and strategies to assist users to query, analyse and visualize data. This article reports current status and recent database developments, including the release of GEO2R, an R-based web application that helps users analyse GEO data.",2012,"[{'authorId': '49588046', 'name': 'T. Barrett'}, {'authorId': '2822927', 'name': 'S. E. Wilhite'}, {'authorId': '2069203893', 'name': 'Pierre Ledoux'}, {'authorId': '144913647', 'name': 'Carlos Evangelista'}, {'authorId': '32105076', 'name': 'Irene F. Kim'}, {'authorId': '2594000', 'name': 'Maxim Tomashevsky'}, {'authorId': '87433149', 'name': 'K. A. Marshall'}, {'authorId': '2427959', 'name': 'Katherine H. Phillippy'}, {'authorId': '40125323', 'name': 'Patti M. Sherman'}, {'authorId': '2451164', 'name': 'Michelle Holko'}, {'authorId': '92899487', 'name': 'A. Yefanov'}, {'authorId': '2118423054', 'name': 'H. Lee'}, {'authorId': '3117718', 'name': 'Naigong Zhang'}, {'authorId': '46847647', 'name': 'C. Robertson'}, {'authorId': '2076500806', 'name': 'N. Serova'}, {'authorId': '145019259', 'name': 'Sean Davis'}, {'authorId': '47981624', 'name': 'Alexandra Soboleva'}]","{'url': 'https://academic.oup.com/nar/article-pdf/41/D1/D991/3678141/gks1193.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3531084, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the gene expression omnibus (geo, http://www.ncbi.nlm.nih.gov/geo/) is an international public repository for high-throughput microarray and next-generation sequence functional genomic data sets submitted by the research community. the resource supports archiving of raw data, processed data and metadata which are indexed, cross-linked and searchable. all data are freely available for download in a variety of formats. geo also provides several web-based tools and strategies to assist users to query, analyse and visualize data. this article reports current status and recent database developments, including the release of geo2r, an r-based web application that helps users analyse geo data.",https://academic.oup.com/nar/article-pdf/41/D1/D991/3678141/gks1193.pdf
5a94cedb709e7c7e005f16297a4a3f134b79fcf9,Phytozome: a comparative platform for green plant genomics,"The number of sequenced plant genomes and associated genomic resources is growing rapidly with the advent of both an increased focus on plant genomics from funding agencies, and the application of inexpensive next generation sequencing. To interact with this increasing body of data, we have developed Phytozome (http://www.phytozome.net), a comparative hub for plant genome and gene family data and analysis. Phytozome provides a view of the evolutionary history of every plant gene at the level of sequence, gene structure, gene family and genome organization, while at the same time providing access to the sequences and functional annotations of a growing number (currently 25) of complete plant genomes, including all the land plants and selected algae sequenced at the Joint Genome Institute, as well as selected species sequenced elsewhere. Through a comprehensive plant genome database and web portal, these data and analyses are available to the broader plant science research community, providing powerful comparative genomics tools that help to link model systems with other plants of economic and ecological importance.",2011,"[{'authorId': '2788713', 'name': 'D. Goodstein'}, {'authorId': '39323696', 'name': 'S. Shu'}, {'authorId': '2678462', 'name': 'R. Howson'}, {'authorId': '1910090', 'name': 'R. Neupane'}, {'authorId': '47471821', 'name': 'Richard D. Hayes'}, {'authorId': '3142547', 'name': 'Joni Fazo'}, {'authorId': '1951834', 'name': 'T. Mitros'}, {'authorId': '46678051', 'name': 'W. Dirks'}, {'authorId': '2413935', 'name': 'U. Hellsten'}, {'authorId': '2175688', 'name': 'Nicholas H. Putnam'}, {'authorId': '3001297', 'name': 'D. Rokhsar'}]","{'url': 'https://academic.oup.com/nar/article-pdf/40/D1/D1178/16957607/gkr944.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3245001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the number of sequenced plant genomes and associated genomic resources is growing rapidly with the advent of both an increased focus on plant genomics from funding agencies, and the application of inexpensive next generation sequencing. to interact with this increasing body of data, we have developed phytozome (http://www.phytozome.net), a comparative hub for plant genome and gene family data and analysis. phytozome provides a view of the evolutionary history of every plant gene at the level of sequence, gene structure, gene family and genome organization, while at the same time providing access to the sequences and functional annotations of a growing number (currently 25) of complete plant genomes, including all the land plants and selected algae sequenced at the joint genome institute, as well as selected species sequenced elsewhere. through a comprehensive plant genome database and web portal, these data and analyses are available to the broader plant science research community, providing powerful comparative genomics tools that help to link model systems with other plants of economic and ecological importance.",https://academic.oup.com/nar/article-pdf/40/D1/D1178/16957607/gkr944.pdf
3c181c06a2839fec6e67a9cd8f0825a5a5dc220b,Circos: an information aesthetic for comparative genomics.,"We created a visualization tool called Circos to facilitate the identification and analysis of similarities and differences arising from comparisons of genomes. Our tool is effective in displaying variation in genome structure and, generally, any other kind of positional relationships between genomic intervals. Such data are routinely produced by sequence alignments, hybridization arrays, genome mapping, and genotyping studies. Circos uses a circular ideogram layout to facilitate the display of relationships between pairs of positions by the use of ribbons, which encode the position, size, and orientation of related genomic elements. Circos is capable of displaying data as scatter, line, and histogram plots, heat maps, tiles, connectors, and text. Bitmap or vector images can be created from GFF-style data inputs and hierarchical configuration files, which can be easily generated by automated tools, making Circos suitable for rapid deployment in data analysis and reporting pipelines.",2009,"[{'authorId': '2802123', 'name': 'M. Krzywinski'}, {'authorId': '1910082', 'name': 'J. Schein'}, {'authorId': '144831170', 'name': 'I. Birol'}, {'authorId': '2067444051', 'name': 'J. Connors'}, {'authorId': '2225435', 'name': 'R. Gascoyne'}, {'authorId': '35099992', 'name': 'D. Horsman'}, {'authorId': '2235532848', 'name': 'Steven J. M. Jones'}, {'authorId': '1778564', 'name': 'M. Marra'}]","{'url': 'https://genome.cshlp.org/content/19/9/1639.full.pdf', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1101/gr.092759.109?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1101/gr.092759.109, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we created a visualization tool called circos to facilitate the identification and analysis of similarities and differences arising from comparisons of genomes. our tool is effective in displaying variation in genome structure and, generally, any other kind of positional relationships between genomic intervals. such data are routinely produced by sequence alignments, hybridization arrays, genome mapping, and genotyping studies. circos uses a circular ideogram layout to facilitate the display of relationships between pairs of positions by the use of ribbons, which encode the position, size, and orientation of related genomic elements. circos is capable of displaying data as scatter, line, and histogram plots, heat maps, tiles, connectors, and text. bitmap or vector images can be created from gff-style data inputs and hierarchical configuration files, which can be easily generated by automated tools, making circos suitable for rapid deployment in data analysis and reporting pipelines.",https://genome.cshlp.org/content/19/9/1639.full.pdf
2b2294ae88646efc62eb58d3383b749216f4adc3,miRBase: tools for microRNA genomics,"miRBase is the central online repository for microRNA (miRNA) nomenclature, sequence data, annotation and target prediction. The current release (10.0) contains 5071 miRNA loci from 58 species, expressing 5922 distinct mature miRNA sequences: a growth of over 2000 sequences in the past 2 years. miRBase provides a range of data to facilitate studies of miRNA genomics: all miRNAs are mapped to their genomic coordinates. Clusters of miRNA sequences in the genome are highlighted, and can be defined and retrieved with any inter-miRNA distance. The overlap of miRNA sequences with annotated transcripts, both protein- and non-coding, are described. Finally, graphical views of the locations of a wide range of genomic features in model organisms allow for the first time the prediction of the likely boundaries of many miRNA primary transcripts. miRBase is available at http://microrna.sanger.ac.uk/.",2007,"[{'authorId': '1398461217', 'name': 'S. Griffiths-Jones'}, {'authorId': '1715198', 'name': 'H. Saini'}, {'authorId': '2179767', 'name': 'S. Dongen'}, {'authorId': '1806754', 'name': 'Anton J. Enright'}]","{'url': 'https://academic.oup.com/nar/article-pdf/36/suppl_1/D154/7635053/gkm952.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC2238936, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mirbase is the central online repository for microrna (mirna) nomenclature, sequence data, annotation and target prediction. the current release (10.0) contains 5071 mirna loci from 58 species, expressing 5922 distinct mature mirna sequences: a growth of over 2000 sequences in the past 2 years. mirbase provides a range of data to facilitate studies of mirna genomics: all mirnas are mapped to their genomic coordinates. clusters of mirna sequences in the genome are highlighted, and can be defined and retrieved with any inter-mirna distance. the overlap of mirna sequences with annotated transcripts, both protein- and non-coding, are described. finally, graphical views of the locations of a wide range of genomic features in model organisms allow for the first time the prediction of the likely boundaries of many mirna primary transcripts. mirbase is available at http://microrna.sanger.ac.uk/.",https://academic.oup.com/nar/article-pdf/36/suppl_1/D154/7635053/gkm952.pdf
5d327de6ce85720744a72235f3249b3a0b4f6765,"Open-access bacterial population genomics: BIGSdb software, the PubMLST.org website and their applications","The PubMLST.org website hosts a collection of open-access, curated databases that integrate population sequence data with provenance and phenotype information for over 100 different microbial species and genera. Although the PubMLST website was conceived as part of the development of the first multi-locus sequence typing (MLST) scheme in 1998 the software it uses, the Bacterial Isolate Genome Sequence database (BIGSdb, published in 2010), enables PubMLST to include all levels of sequence data, from single gene sequences up to and including complete, finished genomes. Here we describe developments in the BIGSdb software made from publication to June 2018 and show how the platform realises microbial population genomics for a wide range of applications. The system is based on the gene-by-gene analysis of microbial genomes, with each deposited sequence annotated and curated to identify the genes present and systematically catalogue their variation. Originally intended as a means of characterising isolates with typing schemes, the synthesis of sequences and records of genetic variation with provenance and phenotype data permits highly scalable (whole genome sequence data for tens of thousands of isolates) means of addressing a wide range of functional questions, including: the prediction of antimicrobial resistance; likely cross-reactivity with vaccine antigens; and the functional activities of different variants that lead to key phenotypes. There are no limitations to the number of sequences, genetic loci, allelic variants or schemes (combinations of loci) that can be included, enabling each database to represent an expanding catalogue of the genetic variation of the population in question. In addition to providing web-accessible analyses and links to third-party analysis and visualisation tools, the BIGSdb software includes a RESTful application programming interface (API) that enables access to all the underlying data for third-party applications and data analysis pipelines.",2018,"[{'authorId': '2482090', 'name': 'K. Jolley'}, {'authorId': '13930719', 'name': 'J. Bray'}, {'authorId': '145307659', 'name': 'M. Maiden'}]","{'url': 'https://wellcomeopenresearch.org/articles/3-124/v1/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6192448, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the pubmlst.org website hosts a collection of open-access, curated databases that integrate population sequence data with provenance and phenotype information for over 100 different microbial species and genera. although the pubmlst website was conceived as part of the development of the first multi-locus sequence typing (mlst) scheme in 1998 the software it uses, the bacterial isolate genome sequence database (bigsdb, published in 2010), enables pubmlst to include all levels of sequence data, from single gene sequences up to and including complete, finished genomes. here we describe developments in the bigsdb software made from publication to june 2018 and show how the platform realises microbial population genomics for a wide range of applications. the system is based on the gene-by-gene analysis of microbial genomes, with each deposited sequence annotated and curated to identify the genes present and systematically catalogue their variation. originally intended as a means of characterising isolates with typing schemes, the synthesis of sequences and records of genetic variation with provenance and phenotype data permits highly scalable (whole genome sequence data for tens of thousands of isolates) means of addressing a wide range of functional questions, including: the prediction of antimicrobial resistance; likely cross-reactivity with vaccine antigens; and the functional activities of different variants that lead to key phenotypes. there are no limitations to the number of sequences, genetic loci, allelic variants or schemes (combinations of loci) that can be included, enabling each database to represent an expanding catalogue of the genetic variation of the population in question. in addition to providing web-accessible analyses and links to third-party analysis and visualisation tools, the bigsdb software includes a restful application programming interface (api) that enables access to all the underlying data for third-party applications and data analysis pipelines.",https://wellcomeopenresearch.org/articles/3-124/v1/pdf
152ac06268f9eb385bfc3f3d9a43e89c81db4c5b,The DisGeNET knowledge platform for disease genomics: 2019 update,"Abstract One of the most pressing challenges in genomic medicine is to understand the role played by genetic variation in health and disease. Thanks to the exploration of genomic variants at large scale, hundreds of thousands of disease-associated loci have been uncovered. However, the identification of variants of clinical relevance is a significant challenge that requires comprehensive interrogation of previous knowledge and linkage to new experimental results. To assist in this complex task, we created DisGeNET (http://www.disgenet.org/), a knowledge management platform integrating and standardizing data about disease associated genes and variants from multiple sources, including the scientific literature. DisGeNET covers the full spectrum of human diseases as well as normal and abnormal traits. The current release covers more than 24 000 diseases and traits, 17 000 genes and 117 000 genomic variants. The latest developments of DisGeNET include new sources of data, novel data attributes and prioritization metrics, a redesigned web interface and recently launched APIs. Thanks to the data standardization, the combination of expert curated information with data automatically mined from the scientific literature, and a suite of tools for accessing its publicly available data, DisGeNET is an interoperable resource supporting a variety of applications in genomic medicine and drug R&D.",2019,"[{'authorId': '152990009', 'name': 'J. González'}, {'authorId': '1401376405', 'name': 'J. Ramírez-Anguita'}, {'authorId': '1403595127', 'name': 'Josep Saüch-Pitarch'}, {'authorId': '2178139', 'name': 'Francesco Ronzano'}, {'authorId': '50456926', 'name': 'Emilio Centeno'}, {'authorId': '144452837', 'name': 'F. Sanz'}, {'authorId': '2101003', 'name': 'L. Furlong'}]","{'url': 'https://academic.oup.com/nar/article-pdf/48/D1/D845/31697865/gkz1021.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7145631, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract one of the most pressing challenges in genomic medicine is to understand the role played by genetic variation in health and disease. thanks to the exploration of genomic variants at large scale, hundreds of thousands of disease-associated loci have been uncovered. however, the identification of variants of clinical relevance is a significant challenge that requires comprehensive interrogation of previous knowledge and linkage to new experimental results. to assist in this complex task, we created disgenet (http://www.disgenet.org/), a knowledge management platform integrating and standardizing data about disease associated genes and variants from multiple sources, including the scientific literature. disgenet covers the full spectrum of human diseases as well as normal and abnormal traits. the current release covers more than 24 000 diseases and traits, 17 000 genes and 117 000 genomic variants. the latest developments of disgenet include new sources of data, novel data attributes and prioritization metrics, a redesigned web interface and recently launched apis. thanks to the data standardization, the combination of expert curated information with data automatically mined from the scientific literature, and a suite of tools for accessing its publicly available data, disgenet is an interoperable resource supporting a variety of applications in genomic medicine and drug r&d.",https://academic.oup.com/nar/article-pdf/48/D1/D845/31697865/gkz1021.pdf
e5ba538944747a6b2ba2a59213268ca2f8df5456,From genomics to chemical genomics: new developments in KEGG,"The increasing amount of genomic and molecular information is the basis for understanding higher-order biological systems, such as the cell and the organism, and their interactions with the environment, as well as for medical, industrial and other practical applications. The KEGG resource () provides a reference knowledge base for linking genomes to biological systems, categorized as building blocks in the genomic space (KEGG GENES) and the chemical space (KEGG LIGAND), and wiring diagrams of interaction networks and reaction networks (KEGG PATHWAY). A fourth component, KEGG BRITE, has been formally added to the KEGG suite of databases. This reflects our attempt to computerize functional interpretations as part of the pathway reconstruction process based on the hierarchically structured knowledge about the genomic, chemical and network spaces. In accordance with the new chemical genomics initiatives, the scope of KEGG LIGAND has been significantly expanded to cover both endogenous and exogenous molecules. Specifically, RPAIR contains curated chemical structure transformation patterns extracted from known enzymatic reactions, which would enable analysis of genome-environment interactions, such as the prediction of new reactions and new enzyme genes that would degrade new environmental compounds. Additionally, drug information is now stored separately and linked to new KEGG DRUG structure maps.",2005,"[{'authorId': '87339519', 'name': 'M. Kanehisa'}, {'authorId': '1723007', 'name': 'S. Goto'}, {'authorId': '2148114', 'name': 'M. Hattori'}, {'authorId': '1399291986', 'name': 'Kiyoko F. Aoki-Kinoshita'}, {'authorId': '3333639', 'name': 'M. Itoh'}, {'authorId': '35004671', 'name': 'S. Kawashima'}, {'authorId': '3222277', 'name': 'Toshiaki Katayama'}, {'authorId': '2904823', 'name': 'M. Araki'}, {'authorId': '2986046', 'name': 'M. Hirakawa'}]","{'url': 'https://europepmc.org/articles/pmc1347464?pdf=render', 'status': 'GREEN', 'license': 'unspecified-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC1347464, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the increasing amount of genomic and molecular information is the basis for understanding higher-order biological systems, such as the cell and the organism, and their interactions with the environment, as well as for medical, industrial and other practical applications. the kegg resource () provides a reference knowledge base for linking genomes to biological systems, categorized as building blocks in the genomic space (kegg genes) and the chemical space (kegg ligand), and wiring diagrams of interaction networks and reaction networks (kegg pathway). a fourth component, kegg brite, has been formally added to the kegg suite of databases. this reflects our attempt to computerize functional interpretations as part of the pathway reconstruction process based on the hierarchically structured knowledge about the genomic, chemical and network spaces. in accordance with the new chemical genomics initiatives, the scope of kegg ligand has been significantly expanded to cover both endogenous and exogenous molecules. specifically, rpair contains curated chemical structure transformation patterns extracted from known enzymatic reactions, which would enable analysis of genome-environment interactions, such as the prediction of new reactions and new enzyme genes that would degrade new environmental compounds. additionally, drug information is now stored separately and linked to new kegg drug structure maps.",https://europepmc.org/articles/pmc1347464?pdf=render
d7763cf32f1fc0e023d03bcf680c22f24eeda23d,Genomics of Drug Sensitivity in Cancer (GDSC): a resource for therapeutic biomarker discovery in cancer cells,"Alterations in cancer genomes strongly influence clinical responses to treatment and in many instances are potent biomarkers for response to drugs. The Genomics of Drug Sensitivity in Cancer (GDSC) database (www.cancerRxgene.org) is the largest public resource for information on drug sensitivity in cancer cells and molecular markers of drug response. Data are freely available without restriction. GDSC currently contains drug sensitivity data for almost 75 000 experiments, describing response to 138 anticancer drugs across almost 700 cancer cell lines. To identify molecular markers of drug response, cell line drug sensitivity data are integrated with large genomic datasets obtained from the Catalogue of Somatic Mutations in Cancer database, including information on somatic mutations in cancer genes, gene amplification and deletion, tissue type and transcriptional data. Analysis of GDSC data is through a web portal focused on identifying molecular biomarkers of drug sensitivity based on queries of specific anticancer drugs or cancer genes. Graphical representations of the data are used throughout with links to related resources and all datasets are fully downloadable. GDSC provides a unique resource incorporating large drug sensitivity and genomic datasets to facilitate the discovery of new therapeutic biomarkers for cancer therapies.",2012,"[{'authorId': '49230549', 'name': 'Wanjuan Yang'}, {'authorId': '145730834', 'name': 'Jorge Soares'}, {'authorId': '2548311', 'name': 'Patricia Greninger'}, {'authorId': '40006038', 'name': 'E. Edelman'}, {'authorId': '2074044310', 'name': 'H. Lightfoot'}, {'authorId': '12944583', 'name': 'S. Forbes'}, {'authorId': '3047444', 'name': 'Nidhi Bindal'}, {'authorId': '46400965', 'name': 'D. Beare'}, {'authorId': '2119125236', 'name': 'James A. Smith'}, {'authorId': '144069947', 'name': 'I. R. Thompson'}, {'authorId': '34631654', 'name': 'Sridhar Ramaswamy'}, {'authorId': '1774003', 'name': 'P. Futreal'}, {'authorId': '2253481', 'name': 'D. Haber'}, {'authorId': '144693778', 'name': 'M. Stratton'}, {'authorId': '1714039', 'name': 'C. Benes'}, {'authorId': '2321694', 'name': 'U. McDermott'}, {'authorId': '145959971', 'name': 'M. Garnett'}]","{'url': 'https://academic.oup.com/nar/article-pdf/41/D1/D955/3626591/gks1111.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3531057, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","alterations in cancer genomes strongly influence clinical responses to treatment and in many instances are potent biomarkers for response to drugs. the genomics of drug sensitivity in cancer (gdsc) database (www.cancerrxgene.org) is the largest public resource for information on drug sensitivity in cancer cells and molecular markers of drug response. data are freely available without restriction. gdsc currently contains drug sensitivity data for almost 75 000 experiments, describing response to 138 anticancer drugs across almost 700 cancer cell lines. to identify molecular markers of drug response, cell line drug sensitivity data are integrated with large genomic datasets obtained from the catalogue of somatic mutations in cancer database, including information on somatic mutations in cancer genes, gene amplification and deletion, tissue type and transcriptional data. analysis of gdsc data is through a web portal focused on identifying molecular biomarkers of drug sensitivity based on queries of specific anticancer drugs or cancer genes. graphical representations of the data are used throughout with links to related resources and all datasets are fully downloadable. gdsc provides a unique resource incorporating large drug sensitivity and genomic datasets to facilitate the discovery of new therapeutic biomarkers for cancer therapies.",https://academic.oup.com/nar/article-pdf/41/D1/D955/3626591/gks1111.pdf
24e6c5bfe9bb0751e5708b501d04e860011b2953,Applications of Support Vector Machine (SVM) Learning in Cancer Genomics.,"Machine learning with maximization (support) of separating margin (vector), called support vector machine (SVM) learning, is a powerful classification tool that has been used for cancer genomic classification or subtyping. Today, as advancements in high-throughput technologies lead to production of large amounts of genomic and epigenomic data, the classification feature of SVMs is expanding its use in cancer genomics, leading to the discovery of new biomarkers, new drug targets, and a better understanding of cancer driver genes. Herein we reviewed the recent progress of SVMs in cancer genomic studies. We intend to comprehend the strength of the SVM learning and its future perspective in cancer genomic applications.",2018,"[{'authorId': '47156522', 'name': 'Shujun Huang'}, {'authorId': '27122362', 'name': 'Nianguang Cai'}, {'authorId': '47479574', 'name': 'Pedro Penzuti Pacheco'}, {'authorId': '32286482', 'name': 'Shavira Narrandes'}, {'authorId': None, 'name': 'Yang Wang'}, {'authorId': '50232365', 'name': 'Wayne W. Xu'}]","{'url': 'http://cgp.iiarjournals.org/content/15/1/41.full.pdf', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.21873/CGP.20063?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.21873/CGP.20063, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","machine learning with maximization (support) of separating margin (vector), called support vector machine (svm) learning, is a powerful classification tool that has been used for cancer genomic classification or subtyping. today, as advancements in high-throughput technologies lead to production of large amounts of genomic and epigenomic data, the classification feature of svms is expanding its use in cancer genomics, leading to the discovery of new biomarkers, new drug targets, and a better understanding of cancer driver genes. herein we reviewed the recent progress of svms in cancer genomic studies. we intend to comprehend the strength of the svm learning and its future perspective in cancer genomic applications.",http://cgp.iiarjournals.org/content/15/1/41.full.pdf
2f2d5d169ca3501dac75ff2b8efa4385ed8c862e,Population genomics for wildlife conservation and management,"Biodiversity is under threat worldwide. Over the past decade, the field of population genomics has developed across nonmodel organisms, and the results of this research have begun to be applied in conservation and management of wildlife species. Genomics tools can provide precise estimates of basic features of wildlife populations, such as effective population size, inbreeding, demographic history and population structure, that are critical for conservation efforts. Moreover, population genomics studies can identify particular genetic loci and variants responsible for inbreeding depression or adaptation to changing environments, allowing for conservation efforts to estimate the capacity of populations to evolve and adapt in response to environmental change and to manage for adaptive variation. While connections from basic research to applied wildlife conservation have been slow to develop, these connections are increasingly strengthening. Here we review the primary areas in which population genomics approaches can be applied to wildlife conservation and management, highlight examples of how they have been used, and provide recommendations for building on the progress that has been made in this field.",2020,"[{'authorId': '6680870', 'name': 'Paul A Hohenlohe'}, {'authorId': '39877729', 'name': 'W. Funk'}, {'authorId': '5510322', 'name': 'O. Rajora'}]","{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7894518', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7894518, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","biodiversity is under threat worldwide. over the past decade, the field of population genomics has developed across nonmodel organisms, and the results of this research have begun to be applied in conservation and management of wildlife species. genomics tools can provide precise estimates of basic features of wildlife populations, such as effective population size, inbreeding, demographic history and population structure, that are critical for conservation efforts. moreover, population genomics studies can identify particular genetic loci and variants responsible for inbreeding depression or adaptation to changing environments, allowing for conservation efforts to estimate the capacity of populations to evolve and adapt in response to environmental change and to manage for adaptive variation. while connections from basic research to applied wildlife conservation have been slow to develop, these connections are increasingly strengthening. here we review the primary areas in which population genomics approaches can be applied to wildlife conservation and management, highlight examples of how they have been used, and provide recommendations for building on the progress that has been made in this field.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7894518
81b74385488ab8704ce7e04a332de4971d00a499,Blast2GO: A Comprehensive Suite for Functional Analysis in Plant Genomics,"Functional annotation of novel sequence data is a primary requirement for the utilization of functional genomics approaches in plant research. In this paper, we describe the Blast2GO suite as a comprehensive bioinformatics tool for functional annotation of sequences and data mining on the resulting annotations, primarily based on the gene ontology (GO) vocabulary. Blast2GO optimizes function transfer from homologous sequences through an elaborate algorithm that considers similarity, the extension of the homology, the database of choice, the GO hierarchy, and the quality of the original annotations. The tool includes numerous functions for the visualization, management, and statistical analysis of annotation results, including gene set enrichment analysis. The application supports InterPro, enzyme codes, KEGG pathways, GO direct acyclic graphs (DAGs), and GOSlim. Blast2GO is a suitable tool for plant genomics research because of its versatility, easy installation, and friendly use.",2007,"[{'authorId': '143999762', 'name': 'A. Conesa'}, {'authorId': '2058014973', 'name': 'Stefan Götz'}]","{'url': 'https://downloads.hindawi.com/archive/2008/619832.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC2375974, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","functional annotation of novel sequence data is a primary requirement for the utilization of functional genomics approaches in plant research. in this paper, we describe the blast2go suite as a comprehensive bioinformatics tool for functional annotation of sequences and data mining on the resulting annotations, primarily based on the gene ontology (go) vocabulary. blast2go optimizes function transfer from homologous sequences through an elaborate algorithm that considers similarity, the extension of the homology, the database of choice, the go hierarchy, and the quality of the original annotations. the tool includes numerous functions for the visualization, management, and statistical analysis of annotation results, including gene set enrichment analysis. the application supports interpro, enzyme codes, kegg pathways, go direct acyclic graphs (dags), and goslim. blast2go is a suitable tool for plant genomics research because of its versatility, easy installation, and friendly use.",https://downloads.hindawi.com/archive/2008/619832.pdf
05c376a55c31b6199b6bdf995d54635c00043733,Variant Review with the Integrative Genomics Viewer.,"Manual review of aligned reads for confirmation and interpretation of variant calls is an important step in many variant calling pipelines for next-generation sequencing (NGS) data. Visual inspection can greatly increase the confidence in calls, reduce the risk of false positives, and help characterize complex events. The Integrative Genomics Viewer (IGV) was one of the first tools to provide NGS data visualization, and it currently provides a rich set of tools for inspection, validation, and interpretation of NGS datasets, as well as other types of genomic data. Here, we present a short overview of IGV's variant review features for both single-nucleotide variants and structural variants, with examples from both cancer and germline datasets. IGV is freely available at https://www.igv.org Cancer Res; 77(21); e31-34. ©2017 AACR.",2017,"[{'authorId': '2115279017', 'name': 'James T. Robinson'}, {'authorId': '1925678', 'name': 'H. Thorvaldsdóttir'}, {'authorId': '34845533', 'name': 'A. Wenger'}, {'authorId': '4267940', 'name': 'A. Zehir'}, {'authorId': '1727782', 'name': 'J. Mesirov'}]","{'url': 'https://cancerres.aacrjournals.org/content/canres/77/21/e31.full.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1158/0008-5472.CAN-17-0337?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1158/0008-5472.CAN-17-0337, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","manual review of aligned reads for confirmation and interpretation of variant calls is an important step in many variant calling pipelines for next-generation sequencing (ngs) data. visual inspection can greatly increase the confidence in calls, reduce the risk of false positives, and help characterize complex events. the integrative genomics viewer (igv) was one of the first tools to provide ngs data visualization, and it currently provides a rich set of tools for inspection, validation, and interpretation of ngs datasets, as well as other types of genomic data. here, we present a short overview of igv's variant review features for both single-nucleotide variants and structural variants, with examples from both cancer and germline datasets. igv is freely available at https://www.igv.org cancer res; 77(21); e31-34. ©2017 aacr.",https://cancerres.aacrjournals.org/content/canres/77/21/e31.full.pdf
2e41f08aa01638ff1a6bb802f58ce36ae535258f,The UCSC Xena platform for public and private cancer genomics data visualization and interpretation,"UCSC Xena is a visual exploration resource for both public and private omics data, supported through the web-based Xena Browser and multiple turn-key Xena Hubs. This unique archecture allows researchers to view their own data securely, using private Xena Hubs, simultaneously visualizing large public cancer genomics datasets, including TCGA and the GDC. Data integration occurs only within the Xena Browser, keeping private data private. Xena supports virtually any functional genomics data, including SNVs, INDELs, large structural variants, CNV, expression, DNA methylation, ATAC-seq signals, and phenotypic annotations. Browser features include the Visual Spreadsheet, survival analyses, powerful filtering and subgrouping, statistical analyses, genomic signatures, and bookmarks. Xena differentiates itself from other genomics tools, including its predecessor, the UCSC Cancer Genomics Browser, by its ability to easily and securely view public and private data, its high performance, its broad data type support, and many unique features.",2018,"[{'authorId': '39080699', 'name': 'M. Goldman'}, {'authorId': '145903205', 'name': 'Brian Craft'}, {'authorId': '1712252484', 'name': 'Mim Hastie'}, {'authorId': '1712250118', 'name': 'Kristupas Repečka'}, {'authorId': '1712250084', 'name': 'Fran McDade'}, {'authorId': '143764565', 'name': 'Akhil Kamath'}, {'authorId': '2171436421', 'name': 'Ayan Banerjee'}, {'authorId': '49513427', 'name': 'Yunhai Luo'}, {'authorId': '152791806', 'name': 'Dave Rogers'}, {'authorId': '144329336', 'name': 'Angela N. Brooks'}, {'authorId': '39522737', 'name': 'Jingchun Zhu'}, {'authorId': '1733689', 'name': 'D. Haussler'}]","{'url': 'https://www.biorxiv.org/content/biorxiv/early/2019/09/26/326470.full.pdf', 'status': 'GREEN', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1101/326470?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1101/326470, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ucsc xena is a visual exploration resource for both public and private omics data, supported through the web-based xena browser and multiple turn-key xena hubs. this unique archecture allows researchers to view their own data securely, using private xena hubs, simultaneously visualizing large public cancer genomics datasets, including tcga and the gdc. data integration occurs only within the xena browser, keeping private data private. xena supports virtually any functional genomics data, including snvs, indels, large structural variants, cnv, expression, dna methylation, atac-seq signals, and phenotypic annotations. browser features include the visual spreadsheet, survival analyses, powerful filtering and subgrouping, statistical analyses, genomic signatures, and bookmarks. xena differentiates itself from other genomics tools, including its predecessor, the ucsc cancer genomics browser, by its ability to easily and securely view public and private data, its high performance, its broad data type support, and many unique features.",https://www.biorxiv.org/content/biorxiv/early/2019/09/26/326470.full.pdf
594d5fc22660ff774d28ccc55a47dbdf02439e9f,Genomics of the origin and evolution of Citrus,"The genus Citrus, comprising some of the most widely cultivated fruit crops worldwide, includes an uncertain number of species. Here we describe ten natural citrus species, using genomic, phylogenetic and biogeographic analyses of 60 accessions representing diverse citrus germ plasms, and propose that citrus diversified during the late Miocene epoch through a rapid southeast Asian radiation that correlates with a marked weakening of the monsoons. A second radiation enabled by migration across the Wallace line gave rise to the Australian limes in the early Pliocene epoch. Further identification and analyses of hybrids and admixed genomes provides insights into the genealogy of major commercial cultivars of citrus. Among mandarins and sweet orange, we find an extensive network of relatedness that illuminates the domestication of these groups. Widespread pummelo admixture among these mandarins and its correlation with fruit size and acidity suggests a plausible role of pummelo introgression in the selection of palatable mandarins. This work provides a new evolutionary framework for the genus Citrus.",2018,"[{'authorId': '49553440', 'name': 'G. Wu'}, {'authorId': '145320739', 'name': 'J. Terol'}, {'authorId': '35490211', 'name': 'Victoria Ibanez'}, {'authorId': '1398573765', 'name': 'A. López-García'}, {'authorId': '1399282731', 'name': 'Estela Pérez-Román'}, {'authorId': '35463222', 'name': 'Carles Borredá'}, {'authorId': '5263173', 'name': 'Concha Domingo'}, {'authorId': '40089436', 'name': 'F. Tadeo'}, {'authorId': '1405110159', 'name': 'J. Carbonell-Caballero'}, {'authorId': '2056966664', 'name': 'Roberto Alonso'}, {'authorId': '3507903', 'name': 'Franck Curk'}, {'authorId': '2351838', 'name': 'Dongliang Du'}, {'authorId': '4578604', 'name': 'P. Ollitrault'}, {'authorId': '48478728', 'name': 'M. Roose'}, {'authorId': '145909087', 'name': 'J. Dopazo'}, {'authorId': '80366158', 'name': 'F. Gmitter'}, {'authorId': '3001297', 'name': 'D. Rokhsar'}, {'authorId': '1791142', 'name': 'M. Talón'}]","{'url': 'https://www.nature.com/articles/nature25447.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1038/nature25447?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/nature25447, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the genus citrus, comprising some of the most widely cultivated fruit crops worldwide, includes an uncertain number of species. here we describe ten natural citrus species, using genomic, phylogenetic and biogeographic analyses of 60 accessions representing diverse citrus germ plasms, and propose that citrus diversified during the late miocene epoch through a rapid southeast asian radiation that correlates with a marked weakening of the monsoons. a second radiation enabled by migration across the wallace line gave rise to the australian limes in the early pliocene epoch. further identification and analyses of hybrids and admixed genomes provides insights into the genealogy of major commercial cultivars of citrus. among mandarins and sweet orange, we find an extensive network of relatedness that illuminates the domestication of these groups. widespread pummelo admixture among these mandarins and its correlation with fruit size and acidity suggests a plausible role of pummelo introgression in the selection of palatable mandarins. this work provides a new evolutionary framework for the genus citrus.",https://www.nature.com/articles/nature25447.pdf
b35022dc68754807dcf25bc9177392a11dc72310,Phandango: an interactive viewer for bacterial population genomics,"Summary Fully exploiting the wealth of data in current bacterial population genomics datasets requires synthesising and integrating different types of analysis across millions of base pairs in hundreds or thousands of isolates. Current approaches often use static representations of phylogenetic, epidemiological, statistical and evolutionary analysis results that are difficult to relate to one another. Phandango is an interactive application running in a web browser allowing fast exploration of large-scale population genomics datasets combining the output from multiple genomic analysis methods in an intuitive and interactive manner. Availability Phandango is a web application freely available for use at https://jameshadfield.github.io/phandango and includes a diverse collection of datasets as examples. Source code together with a detailed wiki page is available on GitHub at https://github.com/jameshadfield/phandango Contact jh22@sanger.ac.uk, sh16@sanger.ac.uk",2017,"[{'authorId': '1939094864', 'name': 'J. Hadfield'}, {'authorId': '2962028', 'name': 'N. Croucher'}, {'authorId': '6347951', 'name': 'Richard J. Goater'}, {'authorId': '2517906', 'name': 'Khalil AbuDahab'}, {'authorId': '1717221', 'name': 'D. Aanensen'}, {'authorId': '144875480', 'name': 'S. Harris'}]","{'url': 'https://academic.oup.com/bioinformatics/article-pdf/34/2/292/25114265/btx610.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5860215, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","summary fully exploiting the wealth of data in current bacterial population genomics datasets requires synthesising and integrating different types of analysis across millions of base pairs in hundreds or thousands of isolates. current approaches often use static representations of phylogenetic, epidemiological, statistical and evolutionary analysis results that are difficult to relate to one another. phandango is an interactive application running in a web browser allowing fast exploration of large-scale population genomics datasets combining the output from multiple genomic analysis methods in an intuitive and interactive manner. availability phandango is a web application freely available for use at https://jameshadfield.github.io/phandango and includes a diverse collection of datasets as examples. source code together with a detailed wiki page is available on github at https://github.com/jameshadfield/phandango contact jh22@sanger.ac.uk, sh16@sanger.ac.uk",https://academic.oup.com/bioinformatics/article-pdf/34/2/292/25114265/btx610.pdf
6a23ca4f444df5fee30d0b1bd12c5c73e62e93e9,VISTA: computational tools for comparative genomics,"Comparison of DNA sequences from different species is a fundamental method for identifying functional elements in genomes. Here, we describe the VISTA family of tools created to assist biologists in carrying out this task. Our first VISTA server at http://www-gsd.lbl.gov/vista/ was launched in the summer of 2000 and was designed to align long genomic sequences and visualize these alignments with associated functional annotations. Currently the VISTA site includes multiple comparative genomics tools and provides users with rich capabilities to browse pre-computed whole-genome alignments of large vertebrate genomes and other groups of organisms with VISTA Browser, to submit their own sequences of interest to several VISTA servers for various types of comparative analysis and to obtain detailed comparative analysis results for a set of cardiovascular genes. We illustrate capabilities of the VISTA site by the analysis of a 180 kb interval on human chromosome 5 that encodes for the kinesin family member 3A (KIF3A) protein.",2004,"[{'authorId': '2315409', 'name': 'K. Frazer'}, {'authorId': '2514969', 'name': 'L. Pachter'}, {'authorId': '144324917', 'name': 'Alexander Poliakov'}, {'authorId': '34878336', 'name': 'E. Rubin'}, {'authorId': '2601999', 'name': 'I. Dubchak'}]","{'url': 'https://academic.oup.com/nar/article-pdf/32/suppl_2/W273/6211334/gkh458.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/NAR/GKH458?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/NAR/GKH458, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","comparison of dna sequences from different species is a fundamental method for identifying functional elements in genomes. here, we describe the vista family of tools created to assist biologists in carrying out this task. our first vista server at http://www-gsd.lbl.gov/vista/ was launched in the summer of 2000 and was designed to align long genomic sequences and visualize these alignments with associated functional annotations. currently the vista site includes multiple comparative genomics tools and provides users with rich capabilities to browse pre-computed whole-genome alignments of large vertebrate genomes and other groups of organisms with vista browser, to submit their own sequences of interest to several vista servers for various types of comparative analysis and to obtain detailed comparative analysis results for a set of cardiovascular genes. we illustrate capabilities of the vista site by the analysis of a 180 kb interval on human chromosome 5 that encodes for the kinesin family member 3a (kif3a) protein.",https://academic.oup.com/nar/article-pdf/32/suppl_2/W273/6211334/gkh458.pdf
c27156f9d6f14bc476502367a6655eda2f80b708,Redundancy analysis: A Swiss Army Knife for landscape genomics,"Landscape genomics identifies how spatial and environmental factors structure the amount and distribution of genetic variation among populations. Landscape genomic analyses have been applied across diverse taxonomic groups and ecological settings, and are increasingly used to analyse datasets composed of large numbers of genomic markers and multiple environmental predictors. It is in this context that multivariate methods show their strengths. Redundancy analysis (RDA) is a constrained ordination that, in a landscape genomics framework, models linear relationships among environment predictors and genomic variation, effectively identifying covarying allele frequencies associated with the multivariate environment. RDA can be used at both individual and population levels, can include covariates to account for confounding factors and can be used to directly infer genotype–environment associations on the landscape. The modelling of both multivariate response and explanatory variables allows RDA to accommodate the genomic and environmental complexity found in nature, producing a powerful and efficient tool for landscape genomics. In this review, we outline the diverse uses of RDA in landscape genomics, including variable selection, variance partitioning, genotype–environment associations, and the calculation of adaptive indices and genomic offset. To illustrate these applications, we use a published dataset for lodgepole pine that includes genomic, phenotypic and environmental data. We provide an introduction to the statistical basis of RDA, a tutorial on its use and interpretation in landscape genomics applications, discuss limitations and provide guidelines to avoid misuse. This review and associated tutorial provide a comprehensive resource to the landscape genomics community to improve understanding of RDA as a modelling framework, and encourage the appropriate use of RDA across diverse landscape genomics applications. RDA is truly a Swiss Army Knife for landscape genomics: a multipurpose, adaptable and versatile approach to identifying, evaluating and forecasting relationships between genetic and environmental variation.",2021,"[{'authorId': '13215936', 'name': 'Thibaut Capblancq'}, {'authorId': '6468790', 'name': 'B. Forester'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/2041-210X.13722?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/2041-210X.13722, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","landscape genomics identifies how spatial and environmental factors structure the amount and distribution of genetic variation among populations. landscape genomic analyses have been applied across diverse taxonomic groups and ecological settings, and are increasingly used to analyse datasets composed of large numbers of genomic markers and multiple environmental predictors. it is in this context that multivariate methods show their strengths. redundancy analysis (rda) is a constrained ordination that, in a landscape genomics framework, models linear relationships among environment predictors and genomic variation, effectively identifying covarying allele frequencies associated with the multivariate environment. rda can be used at both individual and population levels, can include covariates to account for confounding factors and can be used to directly infer genotype–environment associations on the landscape. the modelling of both multivariate response and explanatory variables allows rda to accommodate the genomic and environmental complexity found in nature, producing a powerful and efficient tool for landscape genomics. in this review, we outline the diverse uses of rda in landscape genomics, including variable selection, variance partitioning, genotype–environment associations, and the calculation of adaptive indices and genomic offset. to illustrate these applications, we use a published dataset for lodgepole pine that includes genomic, phenotypic and environmental data. we provide an introduction to the statistical basis of rda, a tutorial on its use and interpretation in landscape genomics applications, discuss limitations and provide guidelines to avoid misuse. this review and associated tutorial provide a comprehensive resource to the landscape genomics community to improve understanding of rda as a modelling framework, and encourage the appropriate use of rda across diverse landscape genomics applications. rda is truly a swiss army knife for landscape genomics: a multipurpose, adaptable and versatile approach to identifying, evaluating and forecasting relationships between genetic and environmental variation.",
d728326a9ff4812a5d51e45e6ff659af28f2904c,"Towards a genomics-informed, real-time, global pathogen surveillance system","The recent Ebola and Zika epidemics demonstrate the need for the continuous surveillance, rapid diagnosis and real-time tracking of emerging infectious diseases. Fast, affordable sequencing of pathogen genomes — now a staple of the public health microbiology laboratory in well-resourced settings — can affect each of these areas. Coupling genomic diagnostics and epidemiology to innovative digital disease detection platforms raises the possibility of an open, global, digital pathogen surveillance system. When informed by a One Health approach, in which human, animal and environmental health are considered together, such a genomics-based system has profound potential to improve public health in settings lacking robust laboratory capacity.",2017,"[{'authorId': '2512488', 'name': 'J. Gardy'}, {'authorId': '2950704', 'name': 'N. Loman'}]","{'url': 'https://www.nature.com/articles/nrg.2017.88.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7097748, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the recent ebola and zika epidemics demonstrate the need for the continuous surveillance, rapid diagnosis and real-time tracking of emerging infectious diseases. fast, affordable sequencing of pathogen genomes — now a staple of the public health microbiology laboratory in well-resourced settings — can affect each of these areas. coupling genomic diagnostics and epidemiology to innovative digital disease detection platforms raises the possibility of an open, global, digital pathogen surveillance system. when informed by a one health approach, in which human, animal and environmental health are considered together, such a genomics-based system has profound potential to improve public health in settings lacking robust laboratory capacity.",https://www.nature.com/articles/nrg.2017.88.pdf
dd4c92faf07c989961e5e3a44c95b6842dab942a,A review of deep learning applications in human genomics using next-generation sequencing data,"Genomics is advancing towards data-driven science. Through the advent of high-throughput data generating technologies in human genomics, we are overwhelmed with the heap of genomic data. To extract knowledge and pattern out of this genomic data, artificial intelligence especially deep learning methods has been instrumental. In the current review, we address development and application of deep learning methods/models in different subarea of human genomics. We assessed over- and under-charted area of genomics by deep learning techniques. Deep learning algorithms underlying the genomic tools have been discussed briefly in later part of this review. Finally, we discussed briefly about the late application of deep learning tools in genomic. Conclusively, this review is timely for biotechnology or genomic scientists in order to guide them why, when and how to use deep learning methods to analyse human genomic data.",2022,"[{'authorId': '15868648', 'name': 'Wardah Alharbi'}, {'authorId': '47504015', 'name': 'M. Rashid'}]","{'url': 'https://humgenomics.biomedcentral.com/counter/pdf/10.1186/s40246-022-00396-x', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9317091, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","genomics is advancing towards data-driven science. through the advent of high-throughput data generating technologies in human genomics, we are overwhelmed with the heap of genomic data. to extract knowledge and pattern out of this genomic data, artificial intelligence especially deep learning methods has been instrumental. in the current review, we address development and application of deep learning methods/models in different subarea of human genomics. we assessed over- and under-charted area of genomics by deep learning techniques. deep learning algorithms underlying the genomic tools have been discussed briefly in later part of this review. finally, we discussed briefly about the late application of deep learning tools in genomic. conclusively, this review is timely for biotechnology or genomic scientists in order to guide them why, when and how to use deep learning methods to analyse human genomic data.",https://humgenomics.biomedcentral.com/counter/pdf/10.1186/s40246-022-00396-x
c69f59f163d01e659c63a317e6192b0e8bf30a0e,Pharmacogenomics: translating functional genomics into rational therapeutics.,"Genetic polymorphisms in drug-metabolizing enzymes, transporters, receptors, and other drug targets have been linked to interindividual differences in the efficacy and toxicity of many medications. Pharmacogenomic studies are rapidly elucidating the inherited nature of these differences in drug disposition and effects, thereby enhancing drug discovery and providing a stronger scientific basis for optimizing drug therapy on the basis of each patient's genetic constitution.",1999,"[{'authorId': '144141197', 'name': 'W. Evans'}, {'authorId': '3009230', 'name': 'M. Relling'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1126/SCIENCE.286.5439.487?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/SCIENCE.286.5439.487, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","genetic polymorphisms in drug-metabolizing enzymes, transporters, receptors, and other drug targets have been linked to interindividual differences in the efficacy and toxicity of many medications. pharmacogenomic studies are rapidly elucidating the inherited nature of these differences in drug disposition and effects, thereby enhancing drug discovery and providing a stronger scientific basis for optimizing drug therapy on the basis of each patient's genetic constitution.",
05c7f309c55364ad18c76d24693e6c0c9e5cb188,Integrative Clinical Genomics of Metastatic Cancer,"Metastasis is the primary cause of cancer-related deaths. Although The Cancer Genome Atlas has sequenced primary tumour types obtained from surgical resections, much less comprehensive molecular analysis is available from clinically acquired metastatic cancers. Here we perform whole-exome and -transcriptome sequencing of 500 adult patients with metastatic solid tumours of diverse lineage and biopsy site. The most prevalent genes somatically altered in metastatic cancer included TP53, CDKN2A, PTEN, PIK3CA, and RB1. Putative pathogenic germline variants were present in 12.2% of cases of which 75% were related to defects in DNA repair. RNA sequencing complemented DNA sequencing to identify gene fusions, pathway activation, and immune profiling. Our results show that integrative sequence analysis provides a clinically relevant, multi-dimensional view of the complex molecular landscape and microenvironment of metastatic cancers.",2017,"[{'authorId': '145308212', 'name': 'D. Robinson'}, {'authorId': '47096524', 'name': 'Yi-Mi Wu'}, {'authorId': '2173271', 'name': 'R. Lonigro'}, {'authorId': '152144473', 'name': 'Pankaj Vats'}, {'authorId': '9891617', 'name': 'E. Cobain'}, {'authorId': '21553778', 'name': 'Jessica N Everett'}, {'authorId': '2259620692', 'name': 'Xuhong Cao'}, {'authorId': '22200221', 'name': 'Erica Rabban'}, {'authorId': '1396440493', 'name': 'Chandan Kumar-Sinha'}, {'authorId': '3984401', 'name': 'V. Raymond'}, {'authorId': '6185692', 'name': 'S. Schuetze'}, {'authorId': '143776096', 'name': 'A. Alva'}, {'authorId': '5391938', 'name': 'J. Siddiqui'}, {'authorId': '3704186', 'name': 'R. Chugh'}, {'authorId': '6097928', 'name': 'F. Worden'}, {'authorId': '4912292', 'name': 'M. Zalupski'}, {'authorId': '1735811', 'name': 'J. Innis'}, {'authorId': '2656849', 'name': 'R. Mody'}, {'authorId': '5692215', 'name': 'S. Tomlins'}, {'authorId': '2057701739', 'name': 'David R. Lucas'}, {'authorId': '34743452', 'name': 'L. Baker'}, {'authorId': '4398718', 'name': 'N. Ramnath'}, {'authorId': '6463085', 'name': 'A. Schott'}, {'authorId': '2059437913', 'name': 'Daniel F. Hayes'}, {'authorId': '1765151', 'name': 'J. Vijai'}, {'authorId': '3471877', 'name': 'K. Offit'}, {'authorId': '3461539', 'name': 'E. Stoffel'}, {'authorId': '47605810', 'name': 'J. Roberts'}, {'authorId': '2271981570', 'name': 'David Smith'}, {'authorId': '5778015', 'name': 'L. Kunju'}, {'authorId': '5321920', 'name': 'M. Talpaz'}, {'authorId': '50748126', 'name': 'M. Cieslik'}, {'authorId': '2186786', 'name': 'A. Chinnaiyan'}]","{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5995337', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5995337, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","metastasis is the primary cause of cancer-related deaths. although the cancer genome atlas has sequenced primary tumour types obtained from surgical resections, much less comprehensive molecular analysis is available from clinically acquired metastatic cancers. here we perform whole-exome and -transcriptome sequencing of 500 adult patients with metastatic solid tumours of diverse lineage and biopsy site. the most prevalent genes somatically altered in metastatic cancer included tp53, cdkn2a, pten, pik3ca, and rb1. putative pathogenic germline variants were present in 12.2% of cases of which 75% were related to defects in dna repair. rna sequencing complemented dna sequencing to identify gene fusions, pathway activation, and immune profiling. our results show that integrative sequence analysis provides a clinically relevant, multi-dimensional view of the complex molecular landscape and microenvironment of metastatic cancers.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5995337
2a05fd17d9ff759be825b7adcae65c7160f25594,How the pan-genome is changing crop genomics and improvement,"Crop genomics has seen dramatic advances in recent years due to improvements in sequencing technology, assembly methods, and computational resources. These advances have led to the development of new tools to facilitate crop improvement. The study of structural variation within species and the characterization of the pan-genome has revealed extensive genome content variation among individuals within a species that is paradigm shifting to crop genomics and improvement. Here, we review advances in crop genomics and how utilization of these tools is shifting in light of pan-genomes that are becoming available for many crop species.",2021,"[{'authorId': '80214388', 'name': 'Rafael Della Coletta'}, {'authorId': '81444747', 'name': 'Y. Qiu'}, {'authorId': '38125882', 'name': 'Shujun Ou'}, {'authorId': '5824772', 'name': 'M. Hufford'}, {'authorId': '26412548', 'name': 'C. Hirsch'}]","{'url': 'https://genomebiology.biomedcentral.com/track/pdf/10.1186/s13059-020-02224-8', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7780660, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","crop genomics has seen dramatic advances in recent years due to improvements in sequencing technology, assembly methods, and computational resources. these advances have led to the development of new tools to facilitate crop improvement. the study of structural variation within species and the characterization of the pan-genome has revealed extensive genome content variation among individuals within a species that is paradigm shifting to crop genomics and improvement. here, we review advances in crop genomics and how utilization of these tools is shifting in light of pan-genomes that are becoming available for many crop species.",https://genomebiology.biomedcentral.com/track/pdf/10.1186/s13059-020-02224-8
9c84a998dd67f4ac7e692edc0167ff92ac06b732,Genetics and genomics of pulmonary arterial hypertension,"Since 2000 there have been major advances in our understanding of the genetic and genomics of pulmonary arterial hypertension (PAH), although there remains much to discover. Based on existing knowledge, around 25–30% of patients diagnosed with idiopathic PAH have an underlying Mendelian genetic cause for their condition and should be classified as heritable PAH (HPAH). Here, we summarise the known genetic and genomic drivers of PAH, the insights these provide into pathobiology, and the opportunities afforded for development of novel therapeutic approaches. In addition, factors determining the incomplete penetrance observed in HPAH are discussed. The currently available approaches to genetic testing and counselling, and the impact of a genetic diagnosis on clinical management of the patient with PAH, are presented. Advances in DNA sequencing technology are rapidly expanding our ability to undertake genomic studies at scale in large cohorts. In the future, such studies will provide a more complete picture of the genetic contribution to PAH and, potentially, a molecular classification of this disease. State of the art and research perspectives in genetics and genomics of pulmonary hypertension and insights into pathobiology http://ow.ly/dkkq30mgDo2",2019,"[{'authorId': '2247577748', 'name': 'N. W. Morrell'}, {'authorId': '2700712', 'name': 'M. Aldred'}, {'authorId': '2238416061', 'name': 'W. Chung'}, {'authorId': '2246457113', 'name': 'C. G. Elliott'}, {'authorId': '2250682945', 'name': 'William C Nichols'}, {'authorId': '6226306', 'name': 'F. Soubrier'}, {'authorId': '3959246', 'name': 'R. Trembath'}, {'authorId': '2250572940', 'name': 'James E. Loyd'}]","{'url': 'https://erj.ersjournals.com/content/erj/53/1/1801899.full.pdf', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6351337, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","since 2000 there have been major advances in our understanding of the genetic and genomics of pulmonary arterial hypertension (pah), although there remains much to discover. based on existing knowledge, around 25–30% of patients diagnosed with idiopathic pah have an underlying mendelian genetic cause for their condition and should be classified as heritable pah (hpah). here, we summarise the known genetic and genomic drivers of pah, the insights these provide into pathobiology, and the opportunities afforded for development of novel therapeutic approaches. in addition, factors determining the incomplete penetrance observed in hpah are discussed. the currently available approaches to genetic testing and counselling, and the impact of a genetic diagnosis on clinical management of the patient with pah, are presented. advances in dna sequencing technology are rapidly expanding our ability to undertake genomic studies at scale in large cohorts. in the future, such studies will provide a more complete picture of the genetic contribution to pah and, potentially, a molecular classification of this disease. state of the art and research perspectives in genetics and genomics of pulmonary hypertension and insights into pathobiology http://ow.ly/dkkq30mgdo2",https://erj.ersjournals.com/content/erj/53/1/1801899.full.pdf
51b64d9dd70ecf2e0f442a3e48c3dabe4461aa83,Targeted isolation and cultivation of uncultivated bacteria by reverse genomics,"Most microorganisms from all taxonomic levels are uncultured. Single-cell genomes and metagenomes continue to increase the known diversity of Bacteria and Archaea; however, while ’omics can be used to infer physiological or ecological roles for species in a community, most of these hypothetical roles remain unvalidated. Here, we report an approach to capture specific microorganisms from complex communities into pure cultures using genome-informed antibody engineering. We apply our reverse genomics approach to isolate and sequence single cells and to cultivate three different species-level lineages of human oral Saccharibacteria (TM7). Using our pure cultures, we show that all three Saccharibacteria species are epibionts of diverse Actinobacteria. We also isolate and cultivate human oral SR1 bacteria, which are members of a lineage of previously uncultured bacteria. Reverse-genomics-enabled cultivation of microorganisms can be applied to any species from any environment and has the potential to unlock the isolation, cultivation and characterization of species from as-yet-uncultured branches of the microbial tree of life. Microbial ‘dark matter’ is brought into culture using reverse genomics.",2019,"[{'authorId': '49108186', 'name': 'K. L. Cross'}, {'authorId': '50298679', 'name': 'James H. Campbell'}, {'authorId': '49847708', 'name': 'M. Balachandran'}, {'authorId': '32133553', 'name': 'A. Campbell'}, {'authorId': '101469288', 'name': 'C. Cooper'}, {'authorId': '31436224', 'name': 'A. Griffen'}, {'authorId': '1411121414', 'name': 'M. Heaton'}, {'authorId': '6480042', 'name': 'S. Joshi'}, {'authorId': '2807832', 'name': 'D. Klingeman'}, {'authorId': '3591546', 'name': 'E. Leys'}, {'authorId': '87816338', 'name': 'Zamin-K. Yang'}, {'authorId': '2888329', 'name': 'Jerry M. Parks'}, {'authorId': '6888384', 'name': 'M. Podar'}]","{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6858544', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6858544, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","most microorganisms from all taxonomic levels are uncultured. single-cell genomes and metagenomes continue to increase the known diversity of bacteria and archaea; however, while ’omics can be used to infer physiological or ecological roles for species in a community, most of these hypothetical roles remain unvalidated. here, we report an approach to capture specific microorganisms from complex communities into pure cultures using genome-informed antibody engineering. we apply our reverse genomics approach to isolate and sequence single cells and to cultivate three different species-level lineages of human oral saccharibacteria (tm7). using our pure cultures, we show that all three saccharibacteria species are epibionts of diverse actinobacteria. we also isolate and cultivate human oral sr1 bacteria, which are members of a lineage of previously uncultured bacteria. reverse-genomics-enabled cultivation of microorganisms can be applied to any species from any environment and has the potential to unlock the isolation, cultivation and characterization of species from as-yet-uncultured branches of the microbial tree of life. microbial ‘dark matter’ is brought into culture using reverse genomics.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6858544
288195b0e62ffd7c9709e4a6328989d62576d135,TP53 Variations in Human Cancers: New Lessons from the IARC TP53 Database and Genomics Data,"TP53 gene mutations are one of the most frequent somatic events in cancer. The IARC TP53 Database (http://p53.iarc.fr) is a popular resource that compiles occurrence and phenotype data on TP53 germline and somatic variations linked to human cancer. The deluge of data coming from cancer genomic studies generates new data on TP53 variations and attracts a growing number of database users for the interpretation of TP53 variants. Here, we present the current contents and functionalities of the IARC TP53 Database and perform a systematic analysis of TP53 somatic mutation data extracted from this database and from genomic data repositories. This analysis showed that IARC has more TP53 somatic mutation data than genomic repositories (29,000 vs. 4,000). However, the more complete screening achieved by genomic studies highlighted some overlooked facts about TP53 mutations, such as the presence of a significant number of mutations occurring outside the DNA‐binding domain in specific cancer types. We also provide an update on TP53 inherited variants including the ones that should be considered as neutral frequent variations. We thus provide an update of current knowledge on TP53 variations in human cancer as well as inform users on the efficient use of the IARC TP53 Database.",2016,"[{'authorId': '3392367', 'name': 'L. Bouaoun'}, {'authorId': '3362695', 'name': 'D. Sonkin'}, {'authorId': '3392206', 'name': 'M. Ardin'}, {'authorId': '144387638', 'name': 'M. Hollstein'}, {'authorId': '2406650', 'name': 'G. Byrnes'}, {'authorId': '3392418', 'name': 'J. Zavadil'}, {'authorId': '39069287', 'name': 'M. Olivier'}]","{'url': 'https://doi.org/10.1002/humu.23035', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/humu.23035?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/humu.23035, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","tp53 gene mutations are one of the most frequent somatic events in cancer. the iarc tp53 database (http://p53.iarc.fr) is a popular resource that compiles occurrence and phenotype data on tp53 germline and somatic variations linked to human cancer. the deluge of data coming from cancer genomic studies generates new data on tp53 variations and attracts a growing number of database users for the interpretation of tp53 variants. here, we present the current contents and functionalities of the iarc tp53 database and perform a systematic analysis of tp53 somatic mutation data extracted from this database and from genomic data repositories. this analysis showed that iarc has more tp53 somatic mutation data than genomic repositories (29,000 vs. 4,000). however, the more complete screening achieved by genomic studies highlighted some overlooked facts about tp53 mutations, such as the presence of a significant number of mutations occurring outside the dna‐binding domain in specific cancer types. we also provide an update on tp53 inherited variants including the ones that should be considered as neutral frequent variations. we thus provide an update of current knowledge on tp53 variations in human cancer as well as inform users on the efficient use of the iarc tp53 database.",https://doi.org/10.1002/humu.23035
6c20fecf959174309f8c9ddc1b21787513842af9,Saccharomyces Genome Database: the genomics resource of budding yeast,"The Saccharomyces Genome Database (SGD, http://www.yeastgenome.org) is the community resource for the budding yeast Saccharomyces cerevisiae. The SGD project provides the highest-quality manually curated information from peer-reviewed literature. The experimental results reported in the literature are extracted and integrated within a well-developed database. These data are combined with quality high-throughput results and provided through Locus Summary pages, a powerful query engine and rich genome browser. The acquisition, integration and retrieval of these data allow SGD to facilitate experimental design and analysis by providing an encyclopedia of the yeast genome, its chromosomal features, their functions and interactions. Public access to these data is provided to researchers and educators via web pages designed for optimal ease of use.",2011,"[{'authorId': '144042512', 'name': 'J. Cherry'}, {'authorId': '2176094', 'name': 'Eurie L. Hong'}, {'authorId': '3323244', 'name': 'C. Amundsen'}, {'authorId': '3215011', 'name': 'R. Balakrishnan'}, {'authorId': '3284230', 'name': 'G. Binkley'}, {'authorId': '34138468', 'name': 'Esther T. Chan'}, {'authorId': '2931623', 'name': 'K. Christie'}, {'authorId': '38859783', 'name': 'M. Costanzo'}, {'authorId': '3242590', 'name': 'S. Dwight'}, {'authorId': '144525380', 'name': 'S. Engel'}, {'authorId': '1984867', 'name': 'D. Fisk'}, {'authorId': '2900468', 'name': 'J. Hirschman'}, {'authorId': '2578936', 'name': 'B. Hitz'}, {'authorId': '2565389', 'name': 'K. Karra'}, {'authorId': '33526235', 'name': 'Cynthia J. Krieger'}, {'authorId': '2122727', 'name': 'S. Miyasato'}, {'authorId': '38455266', 'name': 'R. Nash'}, {'authorId': '2115952574', 'name': 'Julie Park'}, {'authorId': '2733892', 'name': 'M. Skrzypek'}, {'authorId': '2223361', 'name': 'Matt Simison'}, {'authorId': '2366373', 'name': 'S. Weng'}, {'authorId': '7160599', 'name': 'E. Wong'}]","{'url': 'https://academic.oup.com/nar/article-pdf/40/D1/D700/9475265/gkr1029.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3245034, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the saccharomyces genome database (sgd, http://www.yeastgenome.org) is the community resource for the budding yeast saccharomyces cerevisiae. the sgd project provides the highest-quality manually curated information from peer-reviewed literature. the experimental results reported in the literature are extracted and integrated within a well-developed database. these data are combined with quality high-throughput results and provided through locus summary pages, a powerful query engine and rich genome browser. the acquisition, integration and retrieval of these data allow sgd to facilitate experimental design and analysis by providing an encyclopedia of the yeast genome, its chromosomal features, their functions and interactions. public access to these data is provided to researchers and educators via web pages designed for optimal ease of use.",https://academic.oup.com/nar/article-pdf/40/D1/D700/9475265/gkr1029.pdf
a1ed4e5aaeedaab2af037fd940e51329bebdc88c,Conservation of biodiversity in the genomics era,"“Conservation genomics” encompasses the idea that genome-scale data will improve the capacity of resource managers to protect species. Although genetic approaches have long been used in conservation research, it has only recently become tractable to generate genome-wide data at a scale that is useful for conservation. In this Review, we discuss how genome-scale data can inform species delineation in the face of admixture, facilitate evolution through the identification of adaptive alleles, and enhance evolutionary rescue based on genomic patterns of inbreeding. As genomic approaches become more widely adopted in conservation, we expect that they will have a positive impact on management and policy decisions.",2018,"[{'authorId': '48009350', 'name': 'Megan A. Supple'}, {'authorId': '145762352', 'name': 'B. Shapiro'}]","{'url': 'https://genomebiology.biomedcentral.com/track/pdf/10.1186/s13059-018-1520-3', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6131752, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","“conservation genomics” encompasses the idea that genome-scale data will improve the capacity of resource managers to protect species. although genetic approaches have long been used in conservation research, it has only recently become tractable to generate genome-wide data at a scale that is useful for conservation. in this review, we discuss how genome-scale data can inform species delineation in the face of admixture, facilitate evolution through the identification of adaptive alleles, and enhance evolutionary rescue based on genomic patterns of inbreeding. as genomic approaches become more widely adopted in conservation, we expect that they will have a positive impact on management and policy decisions.",https://genomebiology.biomedcentral.com/track/pdf/10.1186/s13059-018-1520-3
ef5b94fe62791dd2d3609fdaf9864d7b1908ae6b,Defining cell types and states with single-cell genomics,"A revolution in cellular measurement technology is under way: For the first time, we have the ability to monitor global gene regulation in thousands of individual cells in a single experiment. Such experiments will allow us to discover new cell types and states and trace their developmental origins. They overcome fundamental limitations inherent in measurements of bulk cell population that have frustrated efforts to resolve cellular states. Single-cell genomics and proteomics enable not only precise characterization of cell state, but also provide a stunningly high-resolution view of transitions between states. These measurements may finally make explicit the metaphor that C.H. Waddington posed nearly 60 years ago to explain cellular plasticity: Cells are residents of a vast “landscape” of possible states, over which they travel during development and in disease. Single-cell technology helps not only locate cells on this landscape, but illuminates the molecular mechanisms that shape the landscape itself. However, single-cell genomics is a field in its infancy, with many experimental and computational advances needed to fully realize its full potential.",2015,"[{'authorId': '2244164', 'name': 'C. Trapnell'}]","{'url': 'http://genome.cshlp.org/content/25/10/1491.full.pdf', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4579334, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a revolution in cellular measurement technology is under way: for the first time, we have the ability to monitor global gene regulation in thousands of individual cells in a single experiment. such experiments will allow us to discover new cell types and states and trace their developmental origins. they overcome fundamental limitations inherent in measurements of bulk cell population that have frustrated efforts to resolve cellular states. single-cell genomics and proteomics enable not only precise characterization of cell state, but also provide a stunningly high-resolution view of transitions between states. these measurements may finally make explicit the metaphor that c.h. waddington posed nearly 60 years ago to explain cellular plasticity: cells are residents of a vast “landscape” of possible states, over which they travel during development and in disease. single-cell technology helps not only locate cells on this landscape, but illuminates the molecular mechanisms that shape the landscape itself. however, single-cell genomics is a field in its infancy, with many experimental and computational advances needed to fully realize its full potential.",http://genome.cshlp.org/content/25/10/1491.full.pdf
59552aac8fab4b7ebcdc1e8cd566ef4f064fccd7,Comparative genomics of the major parasitic worms,"Parasitic nematodes (roundworms) and platyhelminths (flatworms) cause debilitating chronic infections of humans and animals, decimate crop production and are a major impediment to socioeconomic development. Here we report a broad comparative study of 81 genomes of parasitic and non-parasitic worms. We have identified gene family births and hundreds of expanded gene families at key nodes in the phylogeny that are relevant to parasitism. Examples include gene families that modulate host immune responses, enable parasite migration though host tissues or allow the parasite to feed. We reveal extensive lineage-specific differences in core metabolism and protein families historically targeted for drug development. From an in silico screen, we have identified and prioritized new potential drug targets and compounds for testing. This comparative genomics resource provides a much-needed boost for the research community to understand and combat parasitic worms. Comparative study of 81 genomes of parasitic and non-parasitic worms identifies gene family births and expanded gene families at key nodes in the phylogeny that are relevant to parasitism and proteins historically targeted for drug development.",2017,"[{'authorId': '2253259931', 'name': 'International Helminth Genomes Consortium'}]","{'url': 'https://www.nature.com/articles/s41588-018-0262-1.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41588-018-0262-1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41588-018-0262-1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","parasitic nematodes (roundworms) and platyhelminths (flatworms) cause debilitating chronic infections of humans and animals, decimate crop production and are a major impediment to socioeconomic development. here we report a broad comparative study of 81 genomes of parasitic and non-parasitic worms. we have identified gene family births and hundreds of expanded gene families at key nodes in the phylogeny that are relevant to parasitism. examples include gene families that modulate host immune responses, enable parasite migration though host tissues or allow the parasite to feed. we reveal extensive lineage-specific differences in core metabolism and protein families historically targeted for drug development. from an in silico screen, we have identified and prioritized new potential drug targets and compounds for testing. this comparative genomics resource provides a much-needed boost for the research community to understand and combat parasitic worms. comparative study of 81 genomes of parasitic and non-parasitic worms identifies gene family births and expanded gene families at key nodes in the phylogeny that are relevant to parasitism and proteins historically targeted for drug development.",https://www.nature.com/articles/s41588-018-0262-1.pdf
8e010307ef2b7c9678aa8fe37f9a610429f02d13,Brain Imaging Genomics: Integrated Analysis and Machine Learning,"Brain imaging genomics is an emerging data science field, where integrated analysis of brain imaging and genomics data, often combined with other biomarker, clinical, and environmental data, is performed to gain new insights into the phenotypic, genetic, and molecular characteristics of the brain as well as their impact on normal and disordered brain function and behavior. It has enormous potential to contribute significantly to biomedical discoveries in brain science. Given the increasingly important role of statistical and machine learning in biomedicine and rapidly growing literature in brain imaging genomics, we provide an up-to-date and comprehensive review of statistical and machine learning methods for brain imaging genomics, as well as a practical discussion on method selection for various biomedical applications.",2020,"[{'authorId': '38862163', 'name': 'Li Shen'}, {'authorId': '2300186380', 'name': 'P. Thompson'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/5/8944310/08886705.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JPROC.2019.2947272?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JPROC.2019.2947272, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","brain imaging genomics is an emerging data science field, where integrated analysis of brain imaging and genomics data, often combined with other biomarker, clinical, and environmental data, is performed to gain new insights into the phenotypic, genetic, and molecular characteristics of the brain as well as their impact on normal and disordered brain function and behavior. it has enormous potential to contribute significantly to biomedical discoveries in brain science. given the increasingly important role of statistical and machine learning in biomedicine and rapidly growing literature in brain imaging genomics, we provide an up-to-date and comprehensive review of statistical and machine learning methods for brain imaging genomics, as well as a practical discussion on method selection for various biomedical applications.",https://ieeexplore.ieee.org/ielx7/5/8944310/08886705.pdf
573f49307528ef9b2bfe0f813eb6879a07953810,Pathogen Genomics in Public Health.,"Rapid advances in DNA sequencing technology (""next-generation sequencing"") have inspired optimism about the potential of human genomics for ""precision medicine."" Meanwhile, pathogen genomics is already delivering ""precision public health"" through more effective investigations of outbreaks of foodborne illnesses, better-targeted tuberculosis control, and more timely and granular influenza surveillance to inform the selection of vaccine strains. In this article, we describe how public health agencies have been adopting pathogen genomics to improve their effectiveness in almost all domains of infectious disease. This momentum is likely to continue, given the ongoing development in sequencing and sequencing-related technologies.",2019,"[{'authorId': '35104335', 'name': 'G. Armstrong'}, {'authorId': '4989727', 'name': 'D. MacCannell'}, {'authorId': '2109985604', 'name': 'Jill Taylor'}, {'authorId': '4005276', 'name': 'H. Carleton'}, {'authorId': '7626713', 'name': 'Elizabeth B. Neuhaus'}, {'authorId': '3195816', 'name': 'R. Bradbury'}, {'authorId': '4545981', 'name': 'J. Posey'}, {'authorId': '2810522', 'name': 'M. Gwinn'}]","{'url': 'https://researchonline.federation.edu.au/vital/access/services/Download/vital:17512/SOURCE1', 'status': 'BRONZE', 'license': 'CCBYND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1097/01.ogx.0000666232.13540.20?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1097/01.ogx.0000666232.13540.20, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","rapid advances in dna sequencing technology (""next-generation sequencing"") have inspired optimism about the potential of human genomics for ""precision medicine."" meanwhile, pathogen genomics is already delivering ""precision public health"" through more effective investigations of outbreaks of foodborne illnesses, better-targeted tuberculosis control, and more timely and granular influenza surveillance to inform the selection of vaccine strains. in this article, we describe how public health agencies have been adopting pathogen genomics to improve their effectiveness in almost all domains of infectious disease. this momentum is likely to continue, given the ongoing development in sequencing and sequencing-related technologies.",https://researchonline.federation.edu.au/vital/access/services/Download/vital:17512/SOURCE1
38eb73ec8ea218bf1e8dc0e0629339509251c08a,Population Genomics of Parallel Adaptation in Threespine Stickleback using Sequenced RAD Tags,"Next-generation sequencing technology provides novel opportunities for gathering genome-scale sequence data in natural populations, laying the empirical foundation for the evolving field of population genomics. Here we conducted a genome scan of nucleotide diversity and differentiation in natural populations of threespine stickleback (Gasterosteus aculeatus). We used Illumina-sequenced RAD tags to identify and type over 45,000 single nucleotide polymorphisms (SNPs) in each of 100 individuals from two oceanic and three freshwater populations. Overall estimates of genetic diversity and differentiation among populations confirm the biogeographic hypothesis that large panmictic oceanic populations have repeatedly given rise to phenotypically divergent freshwater populations. Genomic regions exhibiting signatures of both balancing and divergent selection were remarkably consistent across multiple, independently derived populations, indicating that replicate parallel phenotypic evolution in stickleback may be occurring through extensive, parallel genetic evolution at a genome-wide scale. Some of these genomic regions co-localize with previously identified QTL for stickleback phenotypic variation identified using laboratory mapping crosses. In addition, we have identified several novel regions showing parallel differentiation across independent populations. Annotation of these regions revealed numerous genes that are candidates for stickleback phenotypic evolution and will form the basis of future genetic analyses in this and other organisms. This study represents the first high-density SNP–based genome scan of genetic diversity and differentiation for populations of threespine stickleback in the wild. These data illustrate the complementary nature of laboratory crosses and population genomic scans by confirming the adaptive significance of previously identified genomic regions, elucidating the particular evolutionary and demographic history of such regions in natural populations, and identifying new genomic regions and candidate genes of evolutionary significance.",2010,"[{'authorId': '6680870', 'name': 'Paul A Hohenlohe'}, {'authorId': '3982817', 'name': 'S. Bassham'}, {'authorId': '3265715', 'name': 'Paul D. Etter'}, {'authorId': '8627011', 'name': 'Nicholas Stiffler'}, {'authorId': '2148774179', 'name': 'Eric A. Johnson'}, {'authorId': '6691811', 'name': 'W. Cresko'}]","{'url': 'https://journals.plos.org/plosgenetics/article/file?id=10.1371/journal.pgen.1000862&type=printable', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC2829049, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","next-generation sequencing technology provides novel opportunities for gathering genome-scale sequence data in natural populations, laying the empirical foundation for the evolving field of population genomics. here we conducted a genome scan of nucleotide diversity and differentiation in natural populations of threespine stickleback (gasterosteus aculeatus). we used illumina-sequenced rad tags to identify and type over 45,000 single nucleotide polymorphisms (snps) in each of 100 individuals from two oceanic and three freshwater populations. overall estimates of genetic diversity and differentiation among populations confirm the biogeographic hypothesis that large panmictic oceanic populations have repeatedly given rise to phenotypically divergent freshwater populations. genomic regions exhibiting signatures of both balancing and divergent selection were remarkably consistent across multiple, independently derived populations, indicating that replicate parallel phenotypic evolution in stickleback may be occurring through extensive, parallel genetic evolution at a genome-wide scale. some of these genomic regions co-localize with previously identified qtl for stickleback phenotypic variation identified using laboratory mapping crosses. in addition, we have identified several novel regions showing parallel differentiation across independent populations. annotation of these regions revealed numerous genes that are candidates for stickleback phenotypic evolution and will form the basis of future genetic analyses in this and other organisms. this study represents the first high-density snp–based genome scan of genetic diversity and differentiation for populations of threespine stickleback in the wild. these data illustrate the complementary nature of laboratory crosses and population genomic scans by confirming the adaptive significance of previously identified genomic regions, elucidating the particular evolutionary and demographic history of such regions in natural populations, and identifying new genomic regions and candidate genes of evolutionary significance.",https://journals.plos.org/plosgenetics/article/file?id=10.1371/journal.pgen.1000862&type=printable
3ebfecd33f2e3a4508ef28899e5ba42b9511dbea,Insect mitochondrial genomics: implications for evolution and phylogeny.,"The mitochondrial (mt) genome is, to date, the most extensively studied genomic system in insects, outnumbering nuclear genomes tenfold and representing all orders versus very few. Phylogenomic analysis methods have been tested extensively, identifying compositional bias and rate variation, both within and between lineages, as the principal issues confronting accurate analyses. Major studies at both inter- and intraordinal levels have contributed to our understanding of phylogenetic relationships within many groups. Genome rearrangements are an additional data type for defining relationships, with rearrangement synapomorphies identified across multiple orders and at many different taxonomic levels. Hymenoptera and Psocodea have greatly elevated rates of rearrangement offering both opportunities and pitfalls for identifying rearrangement synapomorphies in each group. Finally, insects are model systems for studying aberrant mt genomes, including truncated tRNAs and multichromosomal genomes. Greater integration of nuclear and mt genomic studies is necessary to further our understanding of insect genomic evolution.",2014,"[{'authorId': '47640576', 'name': 'S. Cameron'}]","{'url': 'https://www.annualreviews.org/doi/pdf/10.1146/annurev-ento-011613-162007', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1146/annurev-ento-011613-162007?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/annurev-ento-011613-162007, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the mitochondrial (mt) genome is, to date, the most extensively studied genomic system in insects, outnumbering nuclear genomes tenfold and representing all orders versus very few. phylogenomic analysis methods have been tested extensively, identifying compositional bias and rate variation, both within and between lineages, as the principal issues confronting accurate analyses. major studies at both inter- and intraordinal levels have contributed to our understanding of phylogenetic relationships within many groups. genome rearrangements are an additional data type for defining relationships, with rearrangement synapomorphies identified across multiple orders and at many different taxonomic levels. hymenoptera and psocodea have greatly elevated rates of rearrangement offering both opportunities and pitfalls for identifying rearrangement synapomorphies in each group. finally, insects are model systems for studying aberrant mt genomes, including truncated trnas and multichromosomal genomes. greater integration of nuclear and mt genomic studies is necessary to further our understanding of insect genomic evolution.",https://www.annualreviews.org/doi/pdf/10.1146/annurev-ento-011613-162007
15edd7bc18ec4690329155b43738781165120dac,Gateway-compatible vectors for plant functional genomics and proteomics.,"Gateway cloning technology facilitates high-throughput cloning of target sequences by making use of the bacteriophage lambda site-specific recombination system. Target sequences are first captured in a commercially available ""entry vector"" and are then recombined into various ""destination vectors"" for expression in different experimental organisms. Gateway technology has been embraced by a number of plant laboratories that have engineered destination vectors for promoter specificity analyses, protein localization studies, protein/protein interaction studies, constitutive or inducible protein expression studies, gene knockdown by RNA interference, or affinity purification experiments. We review the various types of Gateway destination vectors that are currently available to the plant research community and provide links and references to enable additional information to be obtained concerning these vectors. We also describe a set of ""pEarleyGate"" plasmid vectors for Agrobacterium-mediated plant transformation that translationally fuse FLAG, HA, cMyc, AcV5 or tandem affinity purification epitope tags onto target proteins, with or without an adjacent fluorescent protein. The oligopeptide epitope tags allow the affinity purification, immunolocalization or immunoprecipitation of recombinant proteins expressed in vivo. We demonstrate the utility of pEarleyGate destination vectors for the expression of epitope-tagged proteins that can be affinity captured or localized by immunofluorescence microscopy. Antibodies detecting the FLAG, HA, cMyc and AcV5 tags show relatively little cross-reaction with endogenous proteins in a variety of monocotyledonous and dicotyledonous plants, suggesting broad utility for the tags and vectors.",2006,"[{'authorId': '50430378', 'name': 'K. Earley'}, {'authorId': '37577435', 'name': 'J. Haag'}, {'authorId': '3499908', 'name': 'O. Pontes'}, {'authorId': '2102182244', 'name': 'Kristen Opper'}, {'authorId': '150320343', 'name': 'T. Juehne'}, {'authorId': '2093281386', 'name': 'Keming Song'}, {'authorId': '3326429', 'name': 'C. Pikaard'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-313X.2005.02617.x', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/J.1365-313X.2005.02617.X?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/J.1365-313X.2005.02617.X, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","gateway cloning technology facilitates high-throughput cloning of target sequences by making use of the bacteriophage lambda site-specific recombination system. target sequences are first captured in a commercially available ""entry vector"" and are then recombined into various ""destination vectors"" for expression in different experimental organisms. gateway technology has been embraced by a number of plant laboratories that have engineered destination vectors for promoter specificity analyses, protein localization studies, protein/protein interaction studies, constitutive or inducible protein expression studies, gene knockdown by rna interference, or affinity purification experiments. we review the various types of gateway destination vectors that are currently available to the plant research community and provide links and references to enable additional information to be obtained concerning these vectors. we also describe a set of ""pearleygate"" plasmid vectors for agrobacterium-mediated plant transformation that translationally fuse flag, ha, cmyc, acv5 or tandem affinity purification epitope tags onto target proteins, with or without an adjacent fluorescent protein. the oligopeptide epitope tags allow the affinity purification, immunolocalization or immunoprecipitation of recombinant proteins expressed in vivo. we demonstrate the utility of pearleygate destination vectors for the expression of epitope-tagged proteins that can be affinity captured or localized by immunofluorescence microscopy. antibodies detecting the flag, ha, cmyc and acv5 tags show relatively little cross-reaction with endogenous proteins in a variety of monocotyledonous and dicotyledonous plants, suggesting broad utility for the tags and vectors.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-313X.2005.02617.x
5ad9a4e6972b742a93fccc17e8ef995d3d8139d1,Ensembl comparative genomics resources,"Evolution provides the unifying framework with which to understand biology. The coherent investigation of genic and genomic data often requires comparative genomics analyses based on whole-genome alignments, sets of homologous genes and other relevant datasets in order to evaluate and answer evolutionary-related questions. However, the complexity and computational requirements of producing such data are substantial: this has led to only a small number of reference resources that are used for most comparative analyses. The Ensembl comparative genomics resources are one such reference set that facilitates comprehensive and reproducible analysis of chordate genome data. Ensembl computes pairwise and multiple whole-genome alignments from which large-scale synteny, per-base conservation scores and constrained elements are obtained. Gene alignments are used to define Ensembl Protein Families, GeneTrees and homologies for both protein-coding and non-coding RNA genes. These resources are updated frequently and have a consistent informatics infrastructure and data presentation across all supported species. Specialized web-based visualizations are also available including synteny displays, collapsible gene tree plots, a gene family locator and different alignment views. The Ensembl comparative genomics infrastructure is extensively reused for the analysis of non-vertebrate species by other projects including Ensembl Genomes and Gramene and much of the information here is relevant to these projects. The consistency of the annotation across species and the focus on vertebrates makes Ensembl an ideal system to perform and support vertebrate comparative genomic analyses. We use robust software and pipelines to produce reference comparative data and make it freely available. Database URL: http://www.ensembl.org.",2016,"[{'authorId': '145048374', 'name': 'Javier Herrero'}, {'authorId': '3284013', 'name': 'Matthieu Muffato'}, {'authorId': '145879529', 'name': 'Kathryn M Beal'}, {'authorId': '143719430', 'name': 'Stephen Fitzgerald'}, {'authorId': '144661319', 'name': 'Leo Gordon'}, {'authorId': '48682592', 'name': 'M. Pignatelli'}, {'authorId': '1803829', 'name': 'Albert J. Vilella'}, {'authorId': '144783711', 'name': 'S. Searle'}, {'authorId': '1877838405', 'name': 'R. Amode'}, {'authorId': '1752444', 'name': 'Simon Brent'}, {'authorId': '2496349', 'name': 'W. Spooner'}, {'authorId': '1773679', 'name': 'Eugene Kulesha'}, {'authorId': '27733692', 'name': 'Andrew D. Yates'}, {'authorId': '49974981', 'name': 'P. Flicek'}]","{'url': 'https://academic.oup.com/database/article-pdf/doi/10.1093/database/bav096/8222278/bav096.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4761110, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","evolution provides the unifying framework with which to understand biology. the coherent investigation of genic and genomic data often requires comparative genomics analyses based on whole-genome alignments, sets of homologous genes and other relevant datasets in order to evaluate and answer evolutionary-related questions. however, the complexity and computational requirements of producing such data are substantial: this has led to only a small number of reference resources that are used for most comparative analyses. the ensembl comparative genomics resources are one such reference set that facilitates comprehensive and reproducible analysis of chordate genome data. ensembl computes pairwise and multiple whole-genome alignments from which large-scale synteny, per-base conservation scores and constrained elements are obtained. gene alignments are used to define ensembl protein families, genetrees and homologies for both protein-coding and non-coding rna genes. these resources are updated frequently and have a consistent informatics infrastructure and data presentation across all supported species. specialized web-based visualizations are also available including synteny displays, collapsible gene tree plots, a gene family locator and different alignment views. the ensembl comparative genomics infrastructure is extensively reused for the analysis of non-vertebrate species by other projects including ensembl genomes and gramene and much of the information here is relevant to these projects. the consistency of the annotation across species and the focus on vertebrates makes ensembl an ideal system to perform and support vertebrate comparative genomic analyses. we use robust software and pipelines to produce reference comparative data and make it freely available. database url: http://www.ensembl.org.",https://academic.oup.com/database/article-pdf/doi/10.1093/database/bav096/8222278/bav096.pdf
6975f704d606658ce5f326b40d6a7c15fdfd89ef,Scaling computational genomics to millions of individuals with GPUs,"Current genomics methods are designed to handle tens to thousands of samples but will need to scale to millions to match the pace of data and hypothesis generation in biomedical science. Here, we show that high efficiency at low cost can be achieved by leveraging general-purpose libraries for computing using graphics processing units (GPUs), such as PyTorch and TensorFlow. We demonstrate > 200-fold decreases in runtime and ~ 5–10-fold reductions in cost relative to CPUs. We anticipate that the accessibility of these libraries will lead to a widespread adoption of GPUs in computational genomics.",2018,"[{'authorId': '1398127956', 'name': 'A. Taylor-Weiner'}, {'authorId': '48975912', 'name': 'F. Aguet'}, {'authorId': '4047392', 'name': 'N. Haradhvala'}, {'authorId': '5184754', 'name': 'Sager J. Gosai'}, {'authorId': '48361643', 'name': 'Shankara K. Anand'}, {'authorId': '46454427', 'name': 'Jaegil Kim'}, {'authorId': '4351471', 'name': 'K. Ardlie'}, {'authorId': '3459785', 'name': 'E. V. Van Allen'}, {'authorId': '2110594', 'name': 'G. Getz'}]","{'url': 'https://genomebiology.biomedcentral.com/track/pdf/10.1186/s13059-019-1836-7', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6823959, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","current genomics methods are designed to handle tens to thousands of samples but will need to scale to millions to match the pace of data and hypothesis generation in biomedical science. here, we show that high efficiency at low cost can be achieved by leveraging general-purpose libraries for computing using graphics processing units (gpus), such as pytorch and tensorflow. we demonstrate > 200-fold decreases in runtime and ~ 5–10-fold reductions in cost relative to cpus. we anticipate that the accessibility of these libraries will lead to a widespread adoption of gpus in computational genomics.",https://genomebiology.biomedcentral.com/track/pdf/10.1186/s13059-019-1836-7
18972d2f0e37f9470284b78efdd8bc93e3c662f4,CottonFGD: an integrated functional genomics database for cotton,"BackgroundCotton (Gossypium spp.) is the most important fiber and oil crop in the world. With the emergence of huge -omics data sets, it is essential to have an integrated functional genomics database that allows worldwide users to quickly and easily fetch and visualize genomic information. Currently available cotton-related databases have some weakness in integrating multiple kinds of -omics data from multiple Gossypium species. Therefore, it is necessary to establish an integrated functional genomics database for cotton.DescriptionWe developed CottonFGD (Cotton Functional Genomic Database, https://cottonfgd.org), an integrated database that includes genomic sequences, gene structural and functional annotations, genetic marker data, transcriptome data, and population genome resequencing data for all four of the sequenced Gossypium species. It consists of three interconnected modules: search, profile, and analysis. These modules make CottonFGD enable both single gene review and batch analysis with multiple kinds of -omics data and multiple species. CottonFGD also includes additional pages for data statistics, bulk data download, and a detailed user manual.ConclusionEquipped with specialized functional modules and modernized visualization tools, and populated with multiple kinds of -omics data, CottonFGD provides a quick and easy-to-use data analysis platform for cotton researchers worldwide.",2017,"[{'authorId': '1883724226', 'name': 'Tao Zhu'}, {'authorId': '2113437336', 'name': 'Chengzhen Liang'}, {'authorId': '39960933', 'name': 'Zhigang Meng'}, {'authorId': '50355988', 'name': 'Guoqing Sun'}, {'authorId': '16879157', 'name': 'Zhaoghong Meng'}, {'authorId': '145261763', 'name': 'Sandui Guo'}, {'authorId': '49775269', 'name': 'Rui Zhang'}]","{'url': 'https://bmcplantbiol.biomedcentral.com/track/pdf/10.1186/s12870-017-1039-x', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5465443, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","backgroundcotton (gossypium spp.) is the most important fiber and oil crop in the world. with the emergence of huge -omics data sets, it is essential to have an integrated functional genomics database that allows worldwide users to quickly and easily fetch and visualize genomic information. currently available cotton-related databases have some weakness in integrating multiple kinds of -omics data from multiple gossypium species. therefore, it is necessary to establish an integrated functional genomics database for cotton.descriptionwe developed cottonfgd (cotton functional genomic database, https://cottonfgd.org), an integrated database that includes genomic sequences, gene structural and functional annotations, genetic marker data, transcriptome data, and population genome resequencing data for all four of the sequenced gossypium species. it consists of three interconnected modules: search, profile, and analysis. these modules make cottonfgd enable both single gene review and batch analysis with multiple kinds of -omics data and multiple species. cottonfgd also includes additional pages for data statistics, bulk data download, and a detailed user manual.conclusionequipped with specialized functional modules and modernized visualization tools, and populated with multiple kinds of -omics data, cottonfgd provides a quick and easy-to-use data analysis platform for cotton researchers worldwide.",https://bmcplantbiol.biomedcentral.com/track/pdf/10.1186/s12870-017-1039-x
8a953891eb1acb35e36f4636ca63b90e0a07ad3c,Materials genomics methods for high-throughput construction of COFs and targeted synthesis,"Materials genomics represents a research mode for materials development, for which reliable methods for efficient materials construction are essential. Here we present a methodology for high-throughput construction of covalent organic frameworks (COFs) based on materials genomics strategy, in which a gene partition method of genetic structural units (GSUs) with reactive sites and quasi-reactive assembly algorithms (QReaxAA) for structure generation were proposed by mimicking the natural growth processes of COFs, leading to a library of 130 GSUs and a database of ~470,000 materials containing structures with 10 unreported topologies as well as the existing COFs. As a proof-of-concept example, two generated 3D-COFs with ffc topology and two 2D-COFs with existing topologies were successfully synthesized. This work not only presents useful genomics methods for developing COFs and largely extended the COF structures, but also will stimulate the switch of materials development mode from trial-and-error to theoretical prediction-experimental validation. The discovery of new covalent organic framework (COF) topologies is often led by trial-and-error experiments. Here, the authors present a methodology for high throughput construction of COFs based on a materials genomics strategy and demonstrate the synthesis of the generated 2D and 3D-COFs.",2018,"[{'authorId': '92920051', 'name': 'Youshi Lan'}, {'authorId': '12005652', 'name': 'Xianghao Han'}, {'authorId': '9838263', 'name': 'Minman Tong'}, {'authorId': '2388718', 'name': 'Hongliang Huang'}, {'authorId': '145600188', 'name': 'Qingyuan Yang'}, {'authorId': '5941005', 'name': 'Dahuan Liu'}, {'authorId': '144854849', 'name': 'Xin Zhao'}, {'authorId': '2296326', 'name': 'Chongli Zhong'}]","{'url': 'https://www.nature.com/articles/s41467-018-07720-x.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6288119, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","materials genomics represents a research mode for materials development, for which reliable methods for efficient materials construction are essential. here we present a methodology for high-throughput construction of covalent organic frameworks (cofs) based on materials genomics strategy, in which a gene partition method of genetic structural units (gsus) with reactive sites and quasi-reactive assembly algorithms (qreaxaa) for structure generation were proposed by mimicking the natural growth processes of cofs, leading to a library of 130 gsus and a database of ~470,000 materials containing structures with 10 unreported topologies as well as the existing cofs. as a proof-of-concept example, two generated 3d-cofs with ffc topology and two 2d-cofs with existing topologies were successfully synthesized. this work not only presents useful genomics methods for developing cofs and largely extended the cof structures, but also will stimulate the switch of materials development mode from trial-and-error to theoretical prediction-experimental validation. the discovery of new covalent organic framework (cof) topologies is often led by trial-and-error experiments. here, the authors present a methodology for high throughput construction of cofs based on a materials genomics strategy and demonstrate the synthesis of the generated 2d and 3d-cofs.",https://www.nature.com/articles/s41467-018-07720-x.pdf
bc86cc7b512c468df18cdc65dab3a582a975c34b,"Computational pan-genomics: status, promises and challenges","Many disciplines, from human genetics and oncology to plant breeding, microbiology and virology, commonly face the challenge of analyzing rapidly increasing numbers of genomes. In case of Homo sapiens, the number of sequenced genomes will approach hundreds of thousands in the next few years. Simply scaling up established bioinformatics pipelines will not be sufficient for leveraging the full potential of such rich genomic datasets. Instead, novel, qualitatively different computational methods and paradigms are needed. We will witness the rapid extension of computational pan-genomics, a new sub-area of research in computational biology. In this paper, we generalize existing definitions and understand a pan-genome as any collection of genomic sequences to be analyzed jointly or to be used as a reference. We examine already available approaches to construct and use pan-genomes, discuss the potential benefits of future technologies and methodologies, and review open challenges from the vantage point of the above-mentioned biological disciplines. As a prominent example for a computational paradigm shift, we particularly highlight the transition from the representation of reference genomes as strings to representations as graphs. We outline how this and other challenges from different application domains translate into common computational problems, point out relevant bioinformatics techniques and identify open problems in computer science. With this review, we aim to increase awareness that a joint approach to computational pan-genomics can help address many of the problems currently faced in various domains.",2016,"[{'authorId': '1814678779', 'name': 'The Icgctcga Pan-Cancer Analysis of Whole Genomes Consortium'}]","{'url': 'https://doi.org/10.1101/043430', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5862344, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","many disciplines, from human genetics and oncology to plant breeding, microbiology and virology, commonly face the challenge of analyzing rapidly increasing numbers of genomes. in case of homo sapiens, the number of sequenced genomes will approach hundreds of thousands in the next few years. simply scaling up established bioinformatics pipelines will not be sufficient for leveraging the full potential of such rich genomic datasets. instead, novel, qualitatively different computational methods and paradigms are needed. we will witness the rapid extension of computational pan-genomics, a new sub-area of research in computational biology. in this paper, we generalize existing definitions and understand a pan-genome as any collection of genomic sequences to be analyzed jointly or to be used as a reference. we examine already available approaches to construct and use pan-genomes, discuss the potential benefits of future technologies and methodologies, and review open challenges from the vantage point of the above-mentioned biological disciplines. as a prominent example for a computational paradigm shift, we particularly highlight the transition from the representation of reference genomes as strings to representations as graphs. we outline how this and other challenges from different application domains translate into common computational problems, point out relevant bioinformatics techniques and identify open problems in computer science. with this review, we aim to increase awareness that a joint approach to computational pan-genomics can help address many of the problems currently faced in various domains.",https://doi.org/10.1101/043430
6649ec6922a9ccad546220fe031d8f23aaa3bd8a,Ancient Genomics of Modern Humans: The First Decade.,"The first decade of ancient genomics has revolutionized the study of human prehistory and evolution. We review new insights based on prehistoric modern human genomes, including greatly increased resolution of the timing and structure of the out-of-Africa expansion, the diversification of present-day non-African populations, and the earliest expansions of those populations into Eurasia and America. Prehistoric genomes now document population transformations on every inhabited continent-in particular the effect of agricultural expansions in Africa, Europe, and Oceania-and record a history of natural selection that shapes present-day phenotypic diversity. Despite these advances, much remains unknown, in particular about the genomic histories of Asia (the most populous continent) and Africa (the continent that contains the most genetic diversity). Ancient genomes from these and other regions, integrated with a growing understanding of the genomic basis of human phenotypic diversity, will be in focus during the next decade of research in the field.",2018,"[{'authorId': '2466099', 'name': 'P. Skoglund'}, {'authorId': '48165784', 'name': 'I. Mathieson'}]","{'url': 'https://www.annualreviews.org/doi/pdf/10.1146/annurev-genom-083117-021749', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1146/annurev-genom-083117-021749?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/annurev-genom-083117-021749, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the first decade of ancient genomics has revolutionized the study of human prehistory and evolution. we review new insights based on prehistoric modern human genomes, including greatly increased resolution of the timing and structure of the out-of-africa expansion, the diversification of present-day non-african populations, and the earliest expansions of those populations into eurasia and america. prehistoric genomes now document population transformations on every inhabited continent-in particular the effect of agricultural expansions in africa, europe, and oceania-and record a history of natural selection that shapes present-day phenotypic diversity. despite these advances, much remains unknown, in particular about the genomic histories of asia (the most populous continent) and africa (the continent that contains the most genetic diversity). ancient genomes from these and other regions, integrated with a growing understanding of the genomic basis of human phenotypic diversity, will be in focus during the next decade of research in the field.",https://www.annualreviews.org/doi/pdf/10.1146/annurev-genom-083117-021749
b0550307a0c2c53557a681adab219448ac335dc0,Genomics and evolution of heritable bacterial symbionts.,"Insect heritable symbionts have proven to be ubiquitous, based on molecular screening of various insect lineages. Recently, molecular and experimental approaches have yielded an immensely richer understanding of their diverse biological roles, resulting in a burgeoning research literature. Increasingly, commonalities and intermediates are being discovered between categories of symbionts once considered distinct: obligate mutualists that provision nutrients, facultative mutualists that provide protection against enemies or stress, and symbionts such as Wolbachia that manipulate reproductive systems. Among the most far-reaching impacts of widespread heritable symbiosis is that it may promote speciation by increasing reproductive and ecological isolation of host populations, and it effectively provides a means for transfer of genetic information among host lineages. In addition, insect symbionts provide some of the extremes of cellular genomes, including the smallest and the fastest evolving, raising new questions about the limits of evolution of life.",2008,"[{'authorId': '2515416', 'name': 'N. Moran'}, {'authorId': '46595443', 'name': 'J. McCutcheon'}, {'authorId': '6477993', 'name': 'A. Nakabachi'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1146/annurev.genet.41.110306.130119?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/annurev.genet.41.110306.130119, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","insect heritable symbionts have proven to be ubiquitous, based on molecular screening of various insect lineages. recently, molecular and experimental approaches have yielded an immensely richer understanding of their diverse biological roles, resulting in a burgeoning research literature. increasingly, commonalities and intermediates are being discovered between categories of symbionts once considered distinct: obligate mutualists that provision nutrients, facultative mutualists that provide protection against enemies or stress, and symbionts such as wolbachia that manipulate reproductive systems. among the most far-reaching impacts of widespread heritable symbiosis is that it may promote speciation by increasing reproductive and ecological isolation of host populations, and it effectively provides a means for transfer of genetic information among host lineages. in addition, insect symbionts provide some of the extremes of cellular genomes, including the smallest and the fastest evolving, raising new questions about the limits of evolution of life.",
4e4eaf02f8e8206925e96d9346cb6ad5339ae226,Population genomics of domestic and wild yeasts,"Since the completion of the genome sequence of Saccharomyces cerevisiae in 1996 (refs 1, 2), there has been a large increase in complete genome sequences, accompanied by great advances in our understanding of genome evolution. Although little is known about the natural and life histories of yeasts in the wild, there are an increasing number of studies looking at ecological and geographic distributions, population structure and sexual versus asexual reproduction. Less well understood at the whole genome level are the evolutionary processes acting within populations and species that lead to adaptation to different environments, phenotypic differences and reproductive isolation. Here we present one- to fourfold or more coverage of the genome sequences of over seventy isolates of the baker’s yeast S. cerevisiae and its closest relative, Saccharomyces paradoxus. We examine variation in gene content, single nucleotide polymorphisms, nucleotide insertions and deletions, copy numbers and transposable elements. We find that phenotypic variation broadly correlates with global genome-wide phylogenetic relationships. S. paradoxus populations are well delineated along geographic boundaries, whereas the variation among worldwide S. cerevisiae isolates shows less differentiation and is comparable to a single S. paradoxus population. Rather than one or two domestication events leading to the extant baker’s yeasts, the population structure of S. cerevisiae consists of a few well-defined, geographically isolated lineages and many different mosaics of these lineages, supporting the idea that human influence provided the opportunity for cross-breeding and production of new combinations of pre-existing variations.",2008,"[{'authorId': '2694739', 'name': 'Gianni Liti'}, {'authorId': '2082581692', 'name': 'David M. Carter'}, {'authorId': '145497462', 'name': 'Alan M. Moses'}, {'authorId': '49398049', 'name': 'J. Warringer'}, {'authorId': '2827805', 'name': 'L. Parts'}, {'authorId': '2516796', 'name': 'S. James'}, {'authorId': '7729327', 'name': 'Robert P. Davey'}, {'authorId': '2731553', 'name': 'I. Roberts'}, {'authorId': '143854200', 'name': 'A. Burt'}, {'authorId': '4904969', 'name': 'Vassiliki Koufopanou'}, {'authorId': '13941522', 'name': 'Isheng. J. Tsai'}, {'authorId': '2606473', 'name': 'C. Bergman'}, {'authorId': '39559554', 'name': 'D. Bensasson'}, {'authorId': '1400817538', 'name': 'Michael J. T. O’Kelly'}, {'authorId': '4263781', 'name': 'A. van Oudenaarden'}, {'authorId': '3664856', 'name': 'David B. H. Barton'}, {'authorId': '6483990', 'name': 'E. Bailes'}, {'authorId': '2422462', 'name': 'Alex N. Nguyen Ba'}, {'authorId': '2111036373', 'name': 'Matthew C. Jones'}, {'authorId': '2875971', 'name': 'M. Quail'}, {'authorId': '4344302', 'name': 'I. Goodhead'}, {'authorId': '143817580', 'name': 'S. Sims'}, {'authorId': '2065074268', 'name': 'Frances Smith'}, {'authorId': '46530347', 'name': 'A. Blomberg'}, {'authorId': '144187514', 'name': 'R. Durbin'}, {'authorId': '35633102', 'name': 'E. Louis'}]","{'url': 'https://europepmc.org/articles/pmc2659681?pdf=render', 'status': 'GREEN', 'license': 'unspecified-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC2659681, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","since the completion of the genome sequence of saccharomyces cerevisiae in 1996 (refs 1, 2), there has been a large increase in complete genome sequences, accompanied by great advances in our understanding of genome evolution. although little is known about the natural and life histories of yeasts in the wild, there are an increasing number of studies looking at ecological and geographic distributions, population structure and sexual versus asexual reproduction. less well understood at the whole genome level are the evolutionary processes acting within populations and species that lead to adaptation to different environments, phenotypic differences and reproductive isolation. here we present one- to fourfold or more coverage of the genome sequences of over seventy isolates of the baker’s yeast s. cerevisiae and its closest relative, saccharomyces paradoxus. we examine variation in gene content, single nucleotide polymorphisms, nucleotide insertions and deletions, copy numbers and transposable elements. we find that phenotypic variation broadly correlates with global genome-wide phylogenetic relationships. s. paradoxus populations are well delineated along geographic boundaries, whereas the variation among worldwide s. cerevisiae isolates shows less differentiation and is comparable to a single s. paradoxus population. rather than one or two domestication events leading to the extant baker’s yeasts, the population structure of s. cerevisiae consists of a few well-defined, geographically isolated lineages and many different mosaics of these lineages, supporting the idea that human influence provided the opportunity for cross-breeding and production of new combinations of pre-existing variations.",https://europepmc.org/articles/pmc2659681?pdf=render
3a09814039dc1b8ed55a4c54f8425b18b26b7abd,NCBI GEO: archive for functional genomics data sets—10 years on,"A decade ago, the Gene Expression Omnibus (GEO) database was established at the National Center for Biotechnology Information (NCBI). The original objective of GEO was to serve as a public repository for high-throughput gene expression data generated mostly by microarray technology. However, the research community quickly applied microarrays to non-gene-expression studies, including examination of genome copy number variation and genome-wide profiling of DNA-binding proteins. Because the GEO database was designed with a flexible structure, it was possible to quickly adapt the repository to store these data types. More recently, as the microarray community switches to next-generation sequencing technologies, GEO has again adapted to host these data sets. Today, GEO stores over 20 000 microarray- and sequence-based functional genomics studies, and continues to handle the majority of direct high-throughput data submissions from the research community. Multiple mechanisms are provided to help users effectively search, browse, download and visualize the data at the level of individual genes or entire studies. This paper describes recent database enhancements, including new search and data representation tools, as well as a brief review of how the community uses GEO data. GEO is freely accessible at http://www.ncbi.nlm.nih.gov/geo/.",2010,"[{'authorId': '49588046', 'name': 'T. Barrett'}, {'authorId': '2518262', 'name': 'D. B. Troup'}, {'authorId': '2822927', 'name': 'S. E. Wilhite'}, {'authorId': '2069203893', 'name': 'Pierre Ledoux'}, {'authorId': '144913647', 'name': 'Carlos Evangelista'}, {'authorId': '32105076', 'name': 'Irene F. Kim'}, {'authorId': '2594000', 'name': 'Maxim Tomashevsky'}, {'authorId': '87433149', 'name': 'K. A. Marshall'}, {'authorId': '2427959', 'name': 'Katherine H. Phillippy'}, {'authorId': '40125323', 'name': 'Patti M. Sherman'}, {'authorId': '3159953', 'name': 'Rolf N. Muertter'}, {'authorId': '2451164', 'name': 'Michelle Holko'}, {'authorId': '2751923', 'name': 'Oluwabukunmi Ayanbule'}, {'authorId': '92899487', 'name': 'A. Yefanov'}, {'authorId': '47981624', 'name': 'Alexandra Soboleva'}]","{'url': 'https://academic.oup.com/nar/article-pdf/39/suppl_1/D1005/7633372/gkq1184.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC3013736, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a decade ago, the gene expression omnibus (geo) database was established at the national center for biotechnology information (ncbi). the original objective of geo was to serve as a public repository for high-throughput gene expression data generated mostly by microarray technology. however, the research community quickly applied microarrays to non-gene-expression studies, including examination of genome copy number variation and genome-wide profiling of dna-binding proteins. because the geo database was designed with a flexible structure, it was possible to quickly adapt the repository to store these data types. more recently, as the microarray community switches to next-generation sequencing technologies, geo has again adapted to host these data sets. today, geo stores over 20 000 microarray- and sequence-based functional genomics studies, and continues to handle the majority of direct high-throughput data submissions from the research community. multiple mechanisms are provided to help users effectively search, browse, download and visualize the data at the level of individual genes or entire studies. this paper describes recent database enhancements, including new search and data representation tools, as well as a brief review of how the community uses geo data. geo is freely accessible at http://www.ncbi.nlm.nih.gov/geo/.",https://academic.oup.com/nar/article-pdf/39/suppl_1/D1005/7633372/gkq1184.pdf
2f5a303052f6e9734daf9f916e8089efd4e3a4f1,Comparative genomics of BCG vaccines by whole-genome DNA microarray.,"Bacille Calmette-Guérin (BCG) vaccines are live attenuated strains of Mycobacterium bovis administered to prevent tuberculosis. To better understand the differences between M. tuberculosis, M. bovis, and the various BCG daughter strains, their genomic compositions were studied by performing comparative hybridization experiments on a DNA microarray. Regions deleted from BCG vaccines relative to the virulent M. tuberculosis H37Rv reference strain were confirmed by sequencing across the missing segment of the H37Rv genome. Eleven regions (encompassing 91 open reading frames) of H37Rv were found that were absent from one or more virulent strains of M. bovis. Five additional regions representing 38 open reading frames were present in M. bovis but absent from some or all BCG strains; this is evidence for the ongoing evolution of BCG strains since their original derivation. A precise understanding of the genetic differences between closely related Mycobacteria suggests rational approaches to the design of improved diagnostics and vaccines.",1999,"[{'authorId': '2061377', 'name': 'M. Behr'}, {'authorId': '2148457929', 'name': 'Michael Wilson'}, {'authorId': '39343498', 'name': 'W. Gill'}, {'authorId': '3218140', 'name': 'H. Salamon'}, {'authorId': '3108764', 'name': 'G. Schoolnik'}, {'authorId': '144206746', 'name': 'S. Rane'}, {'authorId': '2034446', 'name': 'P. Small'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1126/SCIENCE.284.5419.1520?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/SCIENCE.284.5419.1520, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","bacille calmette-guérin (bcg) vaccines are live attenuated strains of mycobacterium bovis administered to prevent tuberculosis. to better understand the differences between m. tuberculosis, m. bovis, and the various bcg daughter strains, their genomic compositions were studied by performing comparative hybridization experiments on a dna microarray. regions deleted from bcg vaccines relative to the virulent m. tuberculosis h37rv reference strain were confirmed by sequencing across the missing segment of the h37rv genome. eleven regions (encompassing 91 open reading frames) of h37rv were found that were absent from one or more virulent strains of m. bovis. five additional regions representing 38 open reading frames were present in m. bovis but absent from some or all bcg strains; this is evidence for the ongoing evolution of bcg strains since their original derivation. a precise understanding of the genetic differences between closely related mycobacteria suggests rational approaches to the design of improved diagnostics and vaccines.",
0156cb656b2b459de621448cdec94e49bd843482,"Aquaculture genomics, genetics and breeding in the United States: current status, challenges, and priorities for future research","Advancing the production efficiency and profitability of aquaculture is dependent upon the ability to utilize a diverse array of genetic resources. The ultimate goals of aquaculture genomics, genetics and breeding research are to enhance aquaculture production efficiency, sustainability, product quality, and profitability in support of the commercial sector and for the benefit of consumers. In order to achieve these goals, it is important to understand the genomic structure and organization of aquaculture species, and their genomic and phenomic variations, as well as the genetic basis of traits and their interrelationships. In addition, it is also important to understand the mechanisms of regulation and evolutionary conservation at the levels of genome, transcriptome, proteome, epigenome, and systems biology. With genomic information and information between the genomes and phenomes, technologies for marker/causal mutation-assisted selection, genome selection, and genome editing can be developed for applications in aquaculture. A set of genomic tools and resources must be made available including reference genome sequences and their annotations (including coding and non-coding regulatory elements), genome-wide polymorphic markers, efficient genotyping platforms, high-density and high-resolution linkage maps, and transcriptome resources including non-coding transcripts. Genomic and genetic control of important performance and production traits, such as disease resistance, feed conversion efficiency, growth rate, processing yield, behaviour, reproductive characteristics, and tolerance to environmental stressors like low dissolved oxygen, high or low water temperature and salinity, must be understood. QTL need to be identified, validated across strains, lines and populations, and their mechanisms of control understood. Causal gene(s) need to be identified. Genetic and epigenetic regulation of important aquaculture traits need to be determined, and technologies for marker-assisted selection, causal gene/mutation-assisted selection, genome selection, and genome editing using CRISPR and other technologies must be developed, demonstrated with applicability, and application to aquaculture industries. Major progress has been made in aquaculture genomics for dozens of fish and shellfish species including the development of genetic linkage maps, physical maps, microarrays, single nucleotide polymorphism (SNP) arrays, transcriptome databases and various stages of genome reference sequences. This paper provides a general review of the current status, challenges and future research needs of aquaculture genomics, genetics, and breeding, with a focus on major aquaculture species in the United States: catfish, rainbow trout, Atlantic salmon, tilapia, striped bass, oysters, and shrimp. While the overall research priorities and the practical goals are similar across various aquaculture species, the current status in each species should dictate the next priority areas within the species. This paper is an output of the USDA Workshop for Aquaculture Genomics, Genetics, and Breeding held in late March 2016 in Auburn, Alabama, with participants from all parts of the United States.",2017,"[{'authorId': '1522000161', 'name': 'H. Abdelrahman'}, {'authorId': '2137938609', 'name': 'M. Elhady'}, {'authorId': '90375584', 'name': 'A. Alcivar-Warren'}, {'authorId': '10668809', 'name': 'S. Allen'}, {'authorId': '1402072237', 'name': 'Rafet Al-Tobasei'}, {'authorId': '33860249', 'name': 'Lisui Bao'}, {'authorId': '39393439', 'name': 'B. Beck'}, {'authorId': '145116083', 'name': 'H. Blackburn'}, {'authorId': '40207586', 'name': 'B. Bosworth'}, {'authorId': '2112199196', 'name': 'John Buchanan'}, {'authorId': '39998872', 'name': 'J. Chappell'}, {'authorId': '34967078', 'name': 'W. Daniels'}, {'authorId': '50549210', 'name': 'Sheng Dong'}, {'authorId': '40024808', 'name': 'R. Dunham'}, {'authorId': '9522726', 'name': 'E. Durland'}, {'authorId': '9522729', 'name': 'Ahmed Elaswad'}, {'authorId': '1400466579', 'name': 'M. Gómez-Chiarri'}, {'authorId': '9511073', 'name': 'K. Gosh'}, {'authorId': '33874394', 'name': 'Ximing Guo'}, {'authorId': '4525923', 'name': 'P. Hackett'}, {'authorId': '2133394', 'name': 'T. Hanson'}, {'authorId': '6785952', 'name': 'D. Hedgecock'}, {'authorId': '1401012241', 'name': 'T. Howard'}, {'authorId': '97637730', 'name': 'Leigh Holland'}, {'authorId': '2113489748', 'name': 'Molly Jackson'}, {'authorId': '40313330', 'name': 'Yulin Jin'}, {'authorId': '1441264803', 'name': 'Karim Kahlil'}, {'authorId': '8231851', 'name': 'T. Kocher'}, {'authorId': '5730062', 'name': 'T. Leeds'}, {'authorId': '2120048768', 'name': 'Ning Li'}, {'authorId': '46513018', 'name': 'Lauren Lindsey'}, {'authorId': '2131144872', 'name': 'Shikai Liu'}, {'authorId': '151269401', 'name': 'Zhanjiang Liu'}, {'authorId': '2468448', 'name': 'K. Martin'}, {'authorId': '9498380', 'name': 'Romi Novriadi'}, {'authorId': '47996357', 'name': 'R. Odin'}, {'authorId': '49643815', 'name': 'Y. Palti'}, {'authorId': '2169884', 'name': 'E. Peatman'}, {'authorId': '3694315', 'name': 'Dina A. Proestou'}, {'authorId': '40152377', 'name': 'Guyu Qin'}, {'authorId': '3849324', 'name': 'B. Reading'}, {'authorId': '5725910', 'name': 'C. Rexroad'}, {'authorId': '145736299', 'name': 'S. Roberts'}, {'authorId': '144305784', 'name': 'M. Salem'}, {'authorId': '36013423', 'name': 'A. Severin'}, {'authorId': '4590649', 'name': 'Huitong Shi'}, {'authorId': '5582007', 'name': 'C. Shoemaker'}, {'authorId': '21127509', 'name': 'S. Stiles'}, {'authorId': '34325523', 'name': 'Suxu Tan'}, {'authorId': '1876943', 'name': 'K. Tang'}, {'authorId': '9516017', 'name': 'W. Thongda'}, {'authorId': '2416635', 'name': 'T. Tiersch'}, {'authorId': '3703684', 'name': 'J. Tomasso'}, {'authorId': '9512308', 'name': 'W. Prabowo'}, {'authorId': '5948010', 'name': 'R. Vallejo'}, {'authorId': '31541081', 'name': 'H. van der Steen'}, {'authorId': '49325471', 'name': 'Khoi Vo'}, {'authorId': '4394842', 'name': 'G. Waldbieser'}, {'authorId': '2113289221', 'name': 'Hanping Wang'}, {'authorId': '48630721', 'name': 'Xiaozhu Wang'}, {'authorId': '144731046', 'name': 'J. Xiang'}, {'authorId': '2108585309', 'name': 'Yujia Yang'}, {'authorId': '9499177', 'name': 'R. Yant'}, {'authorId': '35058752', 'name': 'Zihao Yuan'}, {'authorId': '5786867', 'name': 'Qifan Zeng'}, {'authorId': '145156491', 'name': 'Tao Zhou'}]","{'url': 'https://bmcgenomics.biomedcentral.com/track/pdf/10.1186/s12864-017-3557-1', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5319170, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","advancing the production efficiency and profitability of aquaculture is dependent upon the ability to utilize a diverse array of genetic resources. the ultimate goals of aquaculture genomics, genetics and breeding research are to enhance aquaculture production efficiency, sustainability, product quality, and profitability in support of the commercial sector and for the benefit of consumers. in order to achieve these goals, it is important to understand the genomic structure and organization of aquaculture species, and their genomic and phenomic variations, as well as the genetic basis of traits and their interrelationships. in addition, it is also important to understand the mechanisms of regulation and evolutionary conservation at the levels of genome, transcriptome, proteome, epigenome, and systems biology. with genomic information and information between the genomes and phenomes, technologies for marker/causal mutation-assisted selection, genome selection, and genome editing can be developed for applications in aquaculture. a set of genomic tools and resources must be made available including reference genome sequences and their annotations (including coding and non-coding regulatory elements), genome-wide polymorphic markers, efficient genotyping platforms, high-density and high-resolution linkage maps, and transcriptome resources including non-coding transcripts. genomic and genetic control of important performance and production traits, such as disease resistance, feed conversion efficiency, growth rate, processing yield, behaviour, reproductive characteristics, and tolerance to environmental stressors like low dissolved oxygen, high or low water temperature and salinity, must be understood. qtl need to be identified, validated across strains, lines and populations, and their mechanisms of control understood. causal gene(s) need to be identified. genetic and epigenetic regulation of important aquaculture traits need to be determined, and technologies for marker-assisted selection, causal gene/mutation-assisted selection, genome selection, and genome editing using crispr and other technologies must be developed, demonstrated with applicability, and application to aquaculture industries. major progress has been made in aquaculture genomics for dozens of fish and shellfish species including the development of genetic linkage maps, physical maps, microarrays, single nucleotide polymorphism (snp) arrays, transcriptome databases and various stages of genome reference sequences. this paper provides a general review of the current status, challenges and future research needs of aquaculture genomics, genetics, and breeding, with a focus on major aquaculture species in the united states: catfish, rainbow trout, atlantic salmon, tilapia, striped bass, oysters, and shrimp. while the overall research priorities and the practical goals are similar across various aquaculture species, the current status in each species should dictate the next priority areas within the species. this paper is an output of the usda workshop for aquaculture genomics, genetics, and breeding held in late march 2016 in auburn, alabama, with participants from all parts of the united states.",https://bmcgenomics.biomedcentral.com/track/pdf/10.1186/s12864-017-3557-1
c0a737a5f1bcc70c368991c9daec41056894337e,Climate Change 2021 – The Physical Science Basis,"The Working Group I contribution to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC) provides a comprehensive assessment of the physical science basis of climate change. It considers in situ and remote observations; paleoclimate information; understanding of climate drivers and physical, chemical, and biological processes and feedbacks; global and regional climate modelling; advances in methods of analyses; and insights from climate services. It assesses the current state of the climate; human influence on climate in all regions; future climate change including sea level rise; global warming effects including extremes; climate information for risk assessment and regional adaptation; limiting climate change by reaching net zero carbon dioxide emissions and reducing other greenhouse gas emissions; and benefits for air quality. The report serves policymakers, decision makers, stakeholders, and all interested parties with the latest policy-relevant information on climate change. Available as Open Access on Cambridge Core.",2023,"[{'authorId': '2191493435', 'name': 'Intergovernmental Panel on Climate Change'}]","{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/84D59430721AC15204CEAFA4F3902A42/stamped-9781009157889pre1_i-ii.pdf/frontmatter.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1017/9781009157896?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/9781009157896, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the working group i contribution to the sixth assessment report of the intergovernmental panel on climate change (ipcc) provides a comprehensive assessment of the physical science basis of climate change. it considers in situ and remote observations; paleoclimate information; understanding of climate drivers and physical, chemical, and biological processes and feedbacks; global and regional climate modelling; advances in methods of analyses; and insights from climate services. it assesses the current state of the climate; human influence on climate in all regions; future climate change including sea level rise; global warming effects including extremes; climate information for risk assessment and regional adaptation; limiting climate change by reaching net zero carbon dioxide emissions and reducing other greenhouse gas emissions; and benefits for air quality. the report serves policymakers, decision makers, stakeholders, and all interested parties with the latest policy-relevant information on climate change. available as open access on cambridge core.",https://www.cambridge.org/core/services/aop-cambridge-core/content/view/84D59430721AC15204CEAFA4F3902A42/stamped-9781009157889pre1_i-ii.pdf/frontmatter.pdf
2f609099c16f84861bb18bdedf784d13d9610cc1,"Climate Change 2022 – Impacts, Adaptation and Vulnerability","The Working Group II contribution to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC) provides a comprehensive assessment of the scientific literature relevant to climate change impacts, adaptation and vulnerability. The report recognizes the interactions of climate, ecosystems and biodiversity, and human societies, and integrates across the natural, ecological, social and economic sciences. It emphasizes how efforts in adaptation and in reducing greenhouse gas emissions can come together in a process called climate resilient development, which enables a liveable future for biodiversity and humankind. The IPCC is the leading body for assessing climate change science. IPCC reports are produced in comprehensive, objective and transparent ways, ensuring they reflect the full range of views in the scientific literature. Novel elements include focused topical assessments, and an atlas presenting observed climate change impacts and future risks from global to regional scales. Available as Open Access on Cambridge Core.",2023,"[{'authorId': '2233104413', 'name': 'Dr. Kirstin K. Holsman'}]","{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/ED03547F55DC52E331FE751F53C8709F/stamped-9781009325837pre1_i-ii.pdf/frontmatter.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1017/9781009325844?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/9781009325844, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the working group ii contribution to the sixth assessment report of the intergovernmental panel on climate change (ipcc) provides a comprehensive assessment of the scientific literature relevant to climate change impacts, adaptation and vulnerability. the report recognizes the interactions of climate, ecosystems and biodiversity, and human societies, and integrates across the natural, ecological, social and economic sciences. it emphasizes how efforts in adaptation and in reducing greenhouse gas emissions can come together in a process called climate resilient development, which enables a liveable future for biodiversity and humankind. the ipcc is the leading body for assessing climate change science. ipcc reports are produced in comprehensive, objective and transparent ways, ensuring they reflect the full range of views in the scientific literature. novel elements include focused topical assessments, and an atlas presenting observed climate change impacts and future risks from global to regional scales. available as open access on cambridge core.",https://www.cambridge.org/core/services/aop-cambridge-core/content/view/ED03547F55DC52E331FE751F53C8709F/stamped-9781009325837pre1_i-ii.pdf/frontmatter.pdf
d5ab152a21eff7560fae68710c082da76ac86f23,Climate Change 2014 - Synthesis Report,"The Synthesis Report (SYR) distils and integrates the findings of the three Working Group contributions to the Fifth Assessment Report (AR5) of the Intergovernmental Panel on Climate Change (IPCC), the most comprehensive assessment of climate change undertaken thus far by the IPCC: Climate Change 2013: The Physical Science Basis; Climate Change 2014: Impacts, Adaptation, and Vulnerability; and Climate Change 2014: Mitigation of Climate Change. The SYR also incorporates the findings of two Special Reports on Renewable Energy Sources and Climate Change Mitigation (2011) and on Managing the Risks of Extreme Events and Disasters to Advance Climate Change Adaptation (2011).",2015,"[{'authorId': '92605164', 'name': 'Jean-Pascal van Ypersele de Strihou'}]","{'url': 'https://www.ipcc.ch/site/assets/uploads/2018/02/SYR_AR5_FINAL_full.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.59327/ipcc/ar5-9789291691432?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.59327/ipcc/ar5-9789291691432, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the synthesis report (syr) distils and integrates the findings of the three working group contributions to the fifth assessment report (ar5) of the intergovernmental panel on climate change (ipcc), the most comprehensive assessment of climate change undertaken thus far by the ipcc: climate change 2013: the physical science basis; climate change 2014: impacts, adaptation, and vulnerability; and climate change 2014: mitigation of climate change. the syr also incorporates the findings of two special reports on renewable energy sources and climate change mitigation (2011) and on managing the risks of extreme events and disasters to advance climate change adaptation (2011).",https://www.ipcc.ch/site/assets/uploads/2018/02/SYR_AR5_FINAL_full.pdf
b050e7db1b7ca2095406ba0dcecd6472a758a517,Impacts of Climate Change,"Climate change is already affecting the environment and people around the world. We have seen changes in the air, in water, and in plants and animals. These impacts include things like warmer temperatures, sea-level rise, heavy rainfall and more intense storms. Hundreds of plants and animals on the land and in the ocean have been lost because of very hot temperatures. Climate change has also made it more difficult for many people to access food or water, and has caused some people to lose their ways of earning a living. Unfortunately, people who have contributed the least to climate change are experiencing the worst effects. This shows that the effects of climate change are not fair and that there are uneven impacts on different people and places. It is important for us to understand the impacts of climate change on the environment and people so that we can find ways to solve these problems.",2024,"[{'authorId': '2238260986', 'name': 'Nils Gilman'}, {'authorId': '2238261442', 'name': 'Doug Randall'}, {'authorId': '2238260226', 'name': 'Peter Schwartz'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1163/9789004322714_cclc_2015-0029-001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1163/9789004322714_cclc_2015-0029-001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","climate change is already affecting the environment and people around the world. we have seen changes in the air, in water, and in plants and animals. these impacts include things like warmer temperatures, sea-level rise, heavy rainfall and more intense storms. hundreds of plants and animals on the land and in the ocean have been lost because of very hot temperatures. climate change has also made it more difficult for many people to access food or water, and has caused some people to lose their ways of earning a living. unfortunately, people who have contributed the least to climate change are experiencing the worst effects. this shows that the effects of climate change are not fair and that there are uneven impacts on different people and places. it is important for us to understand the impacts of climate change on the environment and people so that we can find ways to solve these problems.",
774e8d544542686c58c1be0ab913a070246d815a,Climate change 2001 : the scientific basis,"Summary for policymakers Technical summary 1. The climate system - an overview 2. Observed climate variability and change 3. The carbon cycle and atmospheric CO2 4. Atmospheric chemistry and greenhouse gases 5. Aerosols, their direct and indirect effects 6. Radiative forcing of climate change 7. Physical climate processes and feedbacks 8. Model evaluation 9. Projections of future climate change 10. Regional climate simulation - evaluation and projections 11. Changes in sea level 12. Detection of climate change and attribution of causes 13. Climate scenario development 14. Advancing our understanding Glossary Index Appendix.",2001,"[{'authorId': '82502978', 'name': 'J. Houghton'}, {'authorId': '2107678351', 'name': 'Y. Ding'}, {'authorId': '3666782', 'name': 'D. Griggs'}, {'authorId': '49419886', 'name': 'M. Noguer'}, {'authorId': '49029935', 'name': 'P. Linden'}, {'authorId': '92693535', 'name': 'X. Dai'}, {'authorId': '145308568', 'name': 'K. Maskell'}, {'authorId': '2350695224', 'name': 'C. Johnson'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2307/20033020?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2307/20033020, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","summary for policymakers technical summary 1. the climate system - an overview 2. observed climate variability and change 3. the carbon cycle and atmospheric co2 4. atmospheric chemistry and greenhouse gases 5. aerosols, their direct and indirect effects 6. radiative forcing of climate change 7. physical climate processes and feedbacks 8. model evaluation 9. projections of future climate change 10. regional climate simulation - evaluation and projections 11. changes in sea level 12. detection of climate change and attribution of causes 13. climate scenario development 14. advancing our understanding glossary index appendix.",
66d10c9eceae45ea98a42e01181d2ab568004216,Climate change 2001,"Summary for policymakers Technical summary Part I. Setting the Stage for Impact, Adaptation, and Vulnerability Assessment: 1. Overview 2. Methods and tools 3. Development and application of scenarios in Climate Change Impact, Adaptation, and Vulnerability Assessment Part II. Sectors and Systems: Impacts, Adaptation, and Vulnerability: 4. Hydrology and water resources 5. Natural and managed ecosystems 6. Coastal zones and marine ecosystems 7. Energy, industry, and settlements 8. Financial services 9. Human health Part III. Regional Analyses: Impacts, Adaptation, and Vulnerability: 10. Africa 11. Asia 12. Australasia 13. Europe 14. Latin America 15. North America 16. Polar regions (Arctic and Antarctic) 17. Small island states Part IV. Global Issues and Synthesis: 18. Adaptation to climate change in the context of sustainable development and equity 19. Synthesis and integration of impacts, adaptation, and vulnerability Index.",2001,"[{'authorId': '2266686255', 'name': 'James J. McCarthi'}, {'authorId': '69360376', 'name': 'O. Canziani'}, {'authorId': '2266681866', 'name': 'N. Leary'}, {'authorId': '104605516', 'name': 'D. Dokken'}, {'authorId': '108415165', 'name': 'K. White'}]","{'url': 'https://escholarship.org/content/qt6x71f1xm/qt6x71f1xm.pdf?t=lvuf60', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5860/choice.39-3433?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5860/choice.39-3433, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","summary for policymakers technical summary part i. setting the stage for impact, adaptation, and vulnerability assessment: 1. overview 2. methods and tools 3. development and application of scenarios in climate change impact, adaptation, and vulnerability assessment part ii. sectors and systems: impacts, adaptation, and vulnerability: 4. hydrology and water resources 5. natural and managed ecosystems 6. coastal zones and marine ecosystems 7. energy, industry, and settlements 8. financial services 9. human health part iii. regional analyses: impacts, adaptation, and vulnerability: 10. africa 11. asia 12. australasia 13. europe 14. latin america 15. north america 16. polar regions (arctic and antarctic) 17. small island states part iv. global issues and synthesis: 18. adaptation to climate change in the context of sustainable development and equity 19. synthesis and integration of impacts, adaptation, and vulnerability index.",https://escholarship.org/content/qt6x71f1xm/qt6x71f1xm.pdf?t=lvuf60
9dc534fff352b413de81dfddfba9f4d0990f079c,Atmospheric Chemistry and Physics: From Air Pollution to Climate Change,"Expanded and updated with new findings and new features • New chapter on Global Climate providing a self-contained treatment of climate forcing, feedbacks, and climate sensitivity • New chapter on Atmospheric Organic Aerosols and new treatment of the statistical method of Positive Matrix Factorization • Updated treatments of physical meteorology, atmospheric nucleation, aerosol-cloud relationships, chemistry of biogenic hydrocarbons • Each topic developed from the fundamental science to the point of application to real-world problems • New problems at an introductory level to aid in classroom teaching",1998,"[{'authorId': '2530017', 'name': 'J. Seinfeld'}, {'authorId': '5103014', 'name': 'S. Pandis'}, {'authorId': '2379954', 'name': 'K. Noone'}]","{'url': 'https://pq-static-content.proquest.com/collateral/media2/documents/ebookcentral-dda.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1063/1.882420?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1063/1.882420, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","expanded and updated with new findings and new features • new chapter on global climate providing a self-contained treatment of climate forcing, feedbacks, and climate sensitivity • new chapter on atmospheric organic aerosols and new treatment of the statistical method of positive matrix factorization • updated treatments of physical meteorology, atmospheric nucleation, aerosol-cloud relationships, chemistry of biogenic hydrocarbons • each topic developed from the fundamental science to the point of application to real-world problems • new problems at an introductory level to aid in classroom teaching",https://pq-static-content.proquest.com/collateral/media2/documents/ebookcentral-dda.pdf
acea7ea50129a20cd2afcc6ab96e1dc40d4addc6,Climate change 2007 : the physical science basis : contribution of Working Group I to the Fourth Assessment Report of the Intergovernmental Panel on Climate Change,"Foreword Preface Summary for Policymakers Technical Summary 1. Historical Overview of Climate Changes Science 2. Changes in Atmospheric Constituents and Radiative Forcing 3. Observations: Atmosphic Surface and Climate Change 4. Observations: Changes in Snow, Ice and Frozen Ground 5. Observations: Ocean Climate Change and Sea Level 6. Palaeoclimate 7. Coupling Between Changes in the Climate System and Biogeochemistry 8. Climate Models and their Evaluation 9. Understanding and Attributing Climate Change 10. Global Climate Projections 11. Regional Climate Projections Annex I: Glossary Annex II: Contributors to the IPCC WGI Fourth Assessment Report Annex III: Reviewers of the IPCC WGI Fourth Assessment Report Annex IV: Acronyms Index.",2007,"[{'authorId': '5211480', 'name': 'S. Schiavon'}, {'authorId': '4763686', 'name': 'R. Zecchin'}]","{'url': 'https://digital.library.unt.edu/ark:/67531/metadc950214/m2/1/high_res_d/WG1AR5_SummaryVolume_FINAL.pdf', 'status': 'GREEN', 'license': 'public-domain', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1017/CBO9781107415324?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/CBO9781107415324, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","foreword preface summary for policymakers technical summary 1. historical overview of climate changes science 2. changes in atmospheric constituents and radiative forcing 3. observations: atmosphic surface and climate change 4. observations: changes in snow, ice and frozen ground 5. observations: ocean climate change and sea level 6. palaeoclimate 7. coupling between changes in the climate system and biogeochemistry 8. climate models and their evaluation 9. understanding and attributing climate change 10. global climate projections 11. regional climate projections annex i: glossary annex ii: contributors to the ipcc wgi fourth assessment report annex iii: reviewers of the ipcc wgi fourth assessment report annex iv: acronyms index.",https://digital.library.unt.edu/ark:/67531/metadc950214/m2/1/high_res_d/WG1AR5_SummaryVolume_FINAL.pdf
471141e357adde215ed13d2a7b4704059ad4cdc4,Ecological and Evolutionary Responses to Recent Climate Change,"Ecological changes in the phenology and distribution of plants and animals are occurring in all well-studied marine, freshwater, and terrestrial groups. These observed changes are heavily biased in the directions predicted from global warming and have been linked to local or regional climate change through correlations between climate and biological variation, field and laboratory experiments, and physiological research. Range-restricted species, particularly polar and mountaintop species, show severe range contractions and have been the first groups in which entire species have gone extinct due to recent climate change. Tropical coral reefs and amphibians have been most negatively affected. Predator-prey and plant-insect interactions have been disrupted when interacting species have responded differently to warming. Evolutionary adaptations to warmer conditions have occurred in the interiors of species’ ranges, and resource use and dispersal have evolved rapidly at expanding range margins. Observed genetic shifts modulate local effects of climate change, but there is little evidence that they will mitigate negative effects at the species level.",2006,"[{'authorId': '3729426', 'name': 'C. Parmesan'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1146/ANNUREV.ECOLSYS.37.091305.110100?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/ANNUREV.ECOLSYS.37.091305.110100, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ecological changes in the phenology and distribution of plants and animals are occurring in all well-studied marine, freshwater, and terrestrial groups. these observed changes are heavily biased in the directions predicted from global warming and have been linked to local or regional climate change through correlations between climate and biological variation, field and laboratory experiments, and physiological research. range-restricted species, particularly polar and mountaintop species, show severe range contractions and have been the first groups in which entire species have gone extinct due to recent climate change. tropical coral reefs and amphibians have been most negatively affected. predator-prey and plant-insect interactions have been disrupted when interacting species have responded differently to warming. evolutionary adaptations to warmer conditions have occurred in the interiors of species’ ranges, and resource use and dispersal have evolved rapidly at expanding range margins. observed genetic shifts modulate local effects of climate change, but there is little evidence that they will mitigate negative effects at the species level.",
039dee6843d163e09e6883494c299b8b99152464,The Economics of Climate Change,"�Greenhouse gas (GHG) emissions are exter nalities and represent the biggest market failure the world has seen. We all produce emissions, people around the world are already suffering from past emissions, and current emissions will have potentially catastrophic impacts in the future. Thus, these emissions are not ordinary, localized externalities. Risk on a global scale is at the core of the issue. These basic features of the problem must shape the economic analy sis we bring to bear; failure to do this will, and has, produced approaches to policy that are pro foundly misleading and indeed dangerous. The purpose of this lecture is to set out what I think is an appropriate way to examine the economics of climate change, given the unique scientific and economic challenges posed, and to suggest implications for emissions targets, policy instruments, and global action. The sub ject is complex and very wide-ranging. It is a subject of vital importance but one in which the economics is fairly young. A central challenge is to provide the economic tools necessary as",2007,"[{'authorId': '46250923', 'name': 'N. Stern'}]","{'url': 'https://repositorio.cepal.org//bitstream/11362/38452/1/FOCUSISsue3Jul-Sept2009.pdf', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1017/CBO9780511817434.039?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/CBO9780511817434.039, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","�greenhouse gas (ghg) emissions are exter nalities and represent the biggest market failure the world has seen. we all produce emissions, people around the world are already suffering from past emissions, and current emissions will have potentially catastrophic impacts in the future. thus, these emissions are not ordinary, localized externalities. risk on a global scale is at the core of the issue. these basic features of the problem must shape the economic analy sis we bring to bear; failure to do this will, and has, produced approaches to policy that are pro foundly misleading and indeed dangerous. the purpose of this lecture is to set out what i think is an appropriate way to examine the economics of climate change, given the unique scientific and economic challenges posed, and to suggest implications for emissions targets, policy instruments, and global action. the sub ject is complex and very wide-ranging. it is a subject of vital importance but one in which the economics is fairly young. a central challenge is to provide the economic tools necessary as",https://repositorio.cepal.org//bitstream/11362/38452/1/FOCUSISsue3Jul-Sept2009.pdf
16d468609c73fe5588c1bbd0418d57e1c2b760a9,"A review of the global climate change impacts, adaptation, and sustainable mitigation measures","Climate change is a long-lasting change in the weather arrays across tropics to polls. It is a global threat that has embarked on to put stress on various sectors. This study is aimed to conceptually engineer how climate variability is deteriorating the sustainability of diverse sectors worldwide. Specifically, the agricultural sector’s vulnerability is a globally concerning scenario, as sufficient production and food supplies are threatened due to irreversible weather fluctuations. In turn, it is challenging the global feeding patterns, particularly in countries with agriculture as an integral part of their economy and total productivity. Climate change has also put the integrity and survival of many species at stake due to shifts in optimum temperature ranges, thereby accelerating biodiversity loss by progressively changing the ecosystem structures. Climate variations increase the likelihood of particular food and waterborne and vector-borne diseases, and a recent example is a coronavirus pandemic. Climate change also accelerates the enigma of antimicrobial resistance, another threat to human health due to the increasing incidence of resistant pathogenic infections. Besides, the global tourism industry is devastated as climate change impacts unfavorable tourism spots. The methodology investigates hypothetical scenarios of climate variability and attempts to describe the quality of evidence to facilitate readers’ careful, critical engagement. Secondary data is used to identify sustainability issues such as environmental, social, and economic viability. To better understand the problem, gathered the information in this report from various media outlets, research agencies, policy papers, newspapers, and other sources. This review is a sectorial assessment of climate change mitigation and adaptation approaches worldwide in the aforementioned sectors and the associated economic costs. According to the findings, government involvement is necessary for the country’s long-term development through strict accountability of resources and regulations implemented in the past to generate cutting-edge climate policy. Therefore, mitigating the impacts of climate change must be of the utmost importance, and hence, this global threat requires global commitment to address its dreadful implications to ensure global sustenance.",2022,"[{'authorId': '151407410', 'name': 'Kashif Abbass'}, {'authorId': '2113690020', 'name': 'M. Qasim'}, {'authorId': '2115232167', 'name': 'Huaming Song'}, {'authorId': '5017564', 'name': 'Muntasir Murshed'}, {'authorId': '145929201', 'name': 'Haider Mahmood'}, {'authorId': '1992971287', 'name': 'Ijaz Younis'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11356-022-19718-6.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8978769, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","climate change is a long-lasting change in the weather arrays across tropics to polls. it is a global threat that has embarked on to put stress on various sectors. this study is aimed to conceptually engineer how climate variability is deteriorating the sustainability of diverse sectors worldwide. specifically, the agricultural sector’s vulnerability is a globally concerning scenario, as sufficient production and food supplies are threatened due to irreversible weather fluctuations. in turn, it is challenging the global feeding patterns, particularly in countries with agriculture as an integral part of their economy and total productivity. climate change has also put the integrity and survival of many species at stake due to shifts in optimum temperature ranges, thereby accelerating biodiversity loss by progressively changing the ecosystem structures. climate variations increase the likelihood of particular food and waterborne and vector-borne diseases, and a recent example is a coronavirus pandemic. climate change also accelerates the enigma of antimicrobial resistance, another threat to human health due to the increasing incidence of resistant pathogenic infections. besides, the global tourism industry is devastated as climate change impacts unfavorable tourism spots. the methodology investigates hypothetical scenarios of climate variability and attempts to describe the quality of evidence to facilitate readers’ careful, critical engagement. secondary data is used to identify sustainability issues such as environmental, social, and economic viability. to better understand the problem, gathered the information in this report from various media outlets, research agencies, policy papers, newspapers, and other sources. this review is a sectorial assessment of climate change mitigation and adaptation approaches worldwide in the aforementioned sectors and the associated economic costs. according to the findings, government involvement is necessary for the country’s long-term development through strict accountability of resources and regulations implemented in the past to generate cutting-edge climate policy. therefore, mitigating the impacts of climate change must be of the utmost importance, and hence, this global threat requires global commitment to address its dreadful implications to ensure global sustenance.",https://link.springer.com/content/pdf/10.1007/s11356-022-19718-6.pdf
56c3ef8da9cc7d9ea69316a7b330dbd33558380b,Climate Change and Land,"The Intergovernmental Panel on Climate Change (IPCC) is the leading international body for assessing the science related to climate change. It provides policymakers with regular assessments of the scientific basis of human-induced climate change, its impacts and future risks, and options for adaptation and mitigation. This IPCC Special Report on Climate Change and Land (SRCCL) is the most comprehensive and up-to-date scientific assessment of the multiple interactions between climate change and land, assessing climate change, desertification, land degradation, sustainable land management, food security, and greenhouse gas fluxes in terrestrial ecosystems. It assesses the options for governance and decision-making across multiple scales. It serves policymakers, decision makers, stakeholders, and all interested parties with unbiased, up-to-date, policy-relevant information. This title is also available as Open Access on Cambridge Core.",2022,"[{'authorId': '2254858161', 'name': 'V. Masson-Delmotte'}, {'authorId': '2244215520', 'name': 'Panmao Zhai'}, {'authorId': '144881762', 'name': 'H. Pörtner'}, {'authorId': '2259776823', 'name': 'D. Roberts'}, {'authorId': '2259803798', 'name': 'S. Connors'}, {'authorId': '101921392', 'name': 'R. V. Diemen'}, {'authorId': '2254899909', 'name': 'M. Ferrat'}, {'authorId': '2135253630', 'name': 'E. Haughey'}, {'authorId': '84315675', 'name': 'S. Neogi'}, {'authorId': '2259802617', 'name': 'M. Pathak'}, {'authorId': '2259801005', 'name': 'J. Petzold'}, {'authorId': '4268660', 'name': 'Purvi Vyas'}, {'authorId': '2259790377', 'name': 'E. Huntley'}, {'authorId': '2259790340', 'name': 'K. Kissick'}, {'authorId': '2259788718', 'name': 'M. Belkacemi'}, {'authorId': '2259781324', 'name': 'J. Malley'}]","{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/AAB03E2F17650B1FDEA514E3F605A685/9781009158015AR.pdf/Climate_Change_and_Land.pdf?event-type=FTLA', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1017/9781009157988?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/9781009157988, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the intergovernmental panel on climate change (ipcc) is the leading international body for assessing the science related to climate change. it provides policymakers with regular assessments of the scientific basis of human-induced climate change, its impacts and future risks, and options for adaptation and mitigation. this ipcc special report on climate change and land (srccl) is the most comprehensive and up-to-date scientific assessment of the multiple interactions between climate change and land, assessing climate change, desertification, land degradation, sustainable land management, food security, and greenhouse gas fluxes in terrestrial ecosystems. it assesses the options for governance and decision-making across multiple scales. it serves policymakers, decision makers, stakeholders, and all interested parties with unbiased, up-to-date, policy-relevant information. this title is also available as open access on cambridge core.",https://www.cambridge.org/core/services/aop-cambridge-core/content/view/AAB03E2F17650B1FDEA514E3F605A685/9781009158015AR.pdf/Climate_Change_and_Land.pdf?event-type=FTLA
0ad6bb5c3e3d41ec13f0c6b555ef43970c32afd5,Climate Endgame: Exploring catastrophic climate change scenarios,"Prudent risk management requires consideration of bad-to-worst-case scenarios. Yet, for climate change, such potential futures are poorly understood. Could anthropogenic climate change result in worldwide societal collapse or even eventual human extinction? At present, this is a dangerously underexplored topic. Yet there are ample reasons to suspect that climate change could result in a global catastrophe. Analyzing the mechanisms for these extreme consequences could help galvanize action, improve resilience, and inform policy, including emergency responses. We outline current knowledge about the likelihood of extreme climate change, discuss why understanding bad-to-worst cases is vital, articulate reasons for concern about catastrophic outcomes, define key terms, and put forward a research agenda. The proposed agenda covers four main questions: 1) What is the potential for climate change to drive mass extinction events? 2) What are the mechanisms that could result in human mass mortality and morbidity? 3) What are human societies' vulnerabilities to climate-triggered risk cascades, such as from conflict, political instability, and systemic financial risk? 4) How can these multiple strands of evidence—together with other global dangers—be usefully synthesized into an “integrated catastrophe assessment”? It is time for the scientific community to grapple with the challenge of better understanding catastrophic climate change.",2022,"[{'authorId': '152134059', 'name': 'Luke Kemp'}, {'authorId': '144910248', 'name': 'Chi Xu'}, {'authorId': '5816612', 'name': 'J. Depledge'}, {'authorId': '143932649', 'name': 'K. Ebi'}, {'authorId': '49894277', 'name': 'Goodwin Gibbins'}, {'authorId': '33357212', 'name': 'Timothy A. Kohler'}, {'authorId': '50393319', 'name': 'J. Rockström'}, {'authorId': '145644167', 'name': 'M. Scheffer'}, {'authorId': '92187834', 'name': 'H. Schellnhuber'}, {'authorId': '30346473', 'name': 'W. Steffen'}, {'authorId': '1789900', 'name': 'T. Lenton'}]","{'url': 'https://doi.org/10.1073/pnas.2108146119', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9407216, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","prudent risk management requires consideration of bad-to-worst-case scenarios. yet, for climate change, such potential futures are poorly understood. could anthropogenic climate change result in worldwide societal collapse or even eventual human extinction? at present, this is a dangerously underexplored topic. yet there are ample reasons to suspect that climate change could result in a global catastrophe. analyzing the mechanisms for these extreme consequences could help galvanize action, improve resilience, and inform policy, including emergency responses. we outline current knowledge about the likelihood of extreme climate change, discuss why understanding bad-to-worst cases is vital, articulate reasons for concern about catastrophic outcomes, define key terms, and put forward a research agenda. the proposed agenda covers four main questions: 1) what is the potential for climate change to drive mass extinction events? 2) what are the mechanisms that could result in human mass mortality and morbidity? 3) what are human societies' vulnerabilities to climate-triggered risk cascades, such as from conflict, political instability, and systemic financial risk? 4) how can these multiple strands of evidence—together with other global dangers—be usefully synthesized into an “integrated catastrophe assessment”? it is time for the scientific community to grapple with the challenge of better understanding catastrophic climate change.",https://doi.org/10.1073/pnas.2108146119
ca61dd83565d18924cf662a0dd1a7cc1f71fe249,Extreme weather impacts of climate change: an attribution perspective,"Extreme event attribution aims to elucidate the link between global climate change, extreme weather events, and the harms experienced on the ground by people, property, and nature. It therefore allows the disentangling of different drivers of extreme weather from human-induced climate change and hence provides valuable information to adapt to climate change and to assess loss and damage. However, providing such assessments systematically is currently out of reach. This is due to limitations in attribution science, including the capacity for studying different types of events, as well as the geographical heterogeneity of both climate and impact data availability. Here, we review current knowledge of the influences of climate change on five different extreme weather hazards (extreme temperatures, heavy rainfall, drought, wildfire, tropical cyclones), the impacts of recent extreme weather events of each type, and thus the degree to which various impacts are attributable to climate change. For instance, heat extremes have increased in likelihood and intensity worldwide due to climate change, with tens of thousands of deaths directly attributable. This is likely a significant underestimate due to the limited availability of impact information in lower- and middle-income countries. Meanwhile, tropical cyclone rainfall and storm surge height have increased for individual events and across all basins. In the North Atlantic basin, climate change amplified the rainfall of events that, combined, caused half a trillion USD in damages. At the same time, severe droughts in many parts of the world are not attributable to climate change. To advance our understanding of present-day extreme weather impacts due to climate change developments on several levels are required. These include improving the recording of extreme weather impacts around the world, improving the coverage of attribution studies across different events and regions, and using attribution studies to explore the contributions of both climate and non-climate drivers of impacts.",2022,"[{'authorId': '49948686', 'name': 'B. Clarke'}, {'authorId': '40055467', 'name': 'F. Otto'}, {'authorId': '2033275892', 'name': 'R. Stuart‐Smith'}, {'authorId': '46213224', 'name': 'L. Harrington'}]","{'url': 'https://doi.org/10.1088/2752-5295/ac6e7d', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1088/2752-5295/ac6e7d?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/2752-5295/ac6e7d, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","extreme event attribution aims to elucidate the link between global climate change, extreme weather events, and the harms experienced on the ground by people, property, and nature. it therefore allows the disentangling of different drivers of extreme weather from human-induced climate change and hence provides valuable information to adapt to climate change and to assess loss and damage. however, providing such assessments systematically is currently out of reach. this is due to limitations in attribution science, including the capacity for studying different types of events, as well as the geographical heterogeneity of both climate and impact data availability. here, we review current knowledge of the influences of climate change on five different extreme weather hazards (extreme temperatures, heavy rainfall, drought, wildfire, tropical cyclones), the impacts of recent extreme weather events of each type, and thus the degree to which various impacts are attributable to climate change. for instance, heat extremes have increased in likelihood and intensity worldwide due to climate change, with tens of thousands of deaths directly attributable. this is likely a significant underestimate due to the limited availability of impact information in lower- and middle-income countries. meanwhile, tropical cyclone rainfall and storm surge height have increased for individual events and across all basins. in the north atlantic basin, climate change amplified the rainfall of events that, combined, caused half a trillion usd in damages. at the same time, severe droughts in many parts of the world are not attributable to climate change. to advance our understanding of present-day extreme weather impacts due to climate change developments on several levels are required. these include improving the recording of extreme weather impacts around the world, improving the coverage of attribution studies across different events and regions, and using attribution studies to explore the contributions of both climate and non-climate drivers of impacts.",https://doi.org/10.1088/2752-5295/ac6e7d
04ee1ba392aa89ceafeb73221e1e46bce54d2d8a,"Climate change, coral bleaching and the future of the world's coral reefs","Sea temperatures in many tropical regions have increased by almost 1 degrees C over the past 100 years, and are currently increasing at similar to 1-2 degrees C per century. Coral bleaching occurs when the thermal tolerance of corals and their photosynthetic symbionts (zooxanthellae) is exceeded. Mass coral bleaching has occurred in association with episodes of elevated sea temperatures over the past 20 years and involves the loss of the zooxanthellae following chronic photoinhibition. Mass bleaching has resulted in significant losses of live coral in many parts of the world. This paper considers the biochemical, physiological and ecological perspectives of coral bleaching. It also uses the outputs of four runs from three models of global climate change which simulate changes in sea temperature and hence how the frequency and intensity of bleaching events will change over the next 100 years. The results suggest that the thermal tolerances of reef-building corals are likely to be exceeded every year within the next few decades. Events as severe as the 1998 event, the worst on record, are likely to become commonplace within 20 years. Most information suggests that the capacity for acclimation by corals has already been exceeded, and that adaptation will be too slow to avert a decline in the quality of the world's reefs. The rapidity of the changes that are predicted indicates a major problem for tropical marine ecosystems and suggests that unrestrained warming cannot occur without the loss and degradation of coral reefs on a global scale.",1999,"[{'authorId': '1398297041', 'name': 'O. Hoegh‐Guldberg'}]","{'url': 'https://doi.org/10.1071/mf99078', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1071/MF99078?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1071/MF99078, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","sea temperatures in many tropical regions have increased by almost 1 degrees c over the past 100 years, and are currently increasing at similar to 1-2 degrees c per century. coral bleaching occurs when the thermal tolerance of corals and their photosynthetic symbionts (zooxanthellae) is exceeded. mass coral bleaching has occurred in association with episodes of elevated sea temperatures over the past 20 years and involves the loss of the zooxanthellae following chronic photoinhibition. mass bleaching has resulted in significant losses of live coral in many parts of the world. this paper considers the biochemical, physiological and ecological perspectives of coral bleaching. it also uses the outputs of four runs from three models of global climate change which simulate changes in sea temperature and hence how the frequency and intensity of bleaching events will change over the next 100 years. the results suggest that the thermal tolerances of reef-building corals are likely to be exceeded every year within the next few decades. events as severe as the 1998 event, the worst on record, are likely to become commonplace within 20 years. most information suggests that the capacity for acclimation by corals has already been exceeded, and that adaptation will be too slow to avert a decline in the quality of the world's reefs. the rapidity of the changes that are predicted indicates a major problem for tropical marine ecosystems and suggests that unrestrained warming cannot occur without the loss and degradation of coral reefs on a global scale.",https://doi.org/10.1071/mf99078
d6b8d1ab59bbfecb101f0a0cbdd174c4580d319d,Predicting the impacts of climate change on the distribution of species: are bioclimate envelope models useful?,"Modelling strategies for predicting the potential impacts of climate change on the natural distribution of species have often focused on the characterization of a species’ bioclimate envelope. A number of recent critiques have questioned the validity of this approach by pointing to the many factors other than climate that play an important part in determining species distributions and the dynamics of distribution changes. Such factors include biotic interactions, evolutionary change and dispersal ability. This paper reviews and evaluates criticisms of bioclimate envelope models and discusses the implications of these criticisms for the different modelling strategies employed. It is proposed that, although the complexity of the natural system presents fundamental limits to predictive modelling, the bioclimate envelope approach can provide a useful first approximation as to the potentially dramatic impact of climate change on biodiversity. However, it is stressed that the spatial scale at which these models are applied is of fundamental importance, and that model results should not be interpreted without due consideration of the limitations involved. A hierarchical modelling framework is proposed through which some of these limitations can be addressed within a broader, scale-dependent",2003,"[{'authorId': '2238097700', 'name': 'Richard G. Pearson'}, {'authorId': '2250088097', 'name': 'Terence P. Dawson'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1046/J.1466-822X.2003.00042.X?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1046/J.1466-822X.2003.00042.X, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","modelling strategies for predicting the potential impacts of climate change on the natural distribution of species have often focused on the characterization of a species’ bioclimate envelope. a number of recent critiques have questioned the validity of this approach by pointing to the many factors other than climate that play an important part in determining species distributions and the dynamics of distribution changes. such factors include biotic interactions, evolutionary change and dispersal ability. this paper reviews and evaluates criticisms of bioclimate envelope models and discusses the implications of these criticisms for the different modelling strategies employed. it is proposed that, although the complexity of the natural system presents fundamental limits to predictive modelling, the bioclimate envelope approach can provide a useful first approximation as to the potentially dramatic impact of climate change on biodiversity. however, it is stressed that the spatial scale at which these models are applied is of fundamental importance, and that model results should not be interpreted without due consideration of the limitations involved. a hierarchical modelling framework is proposed through which some of these limitations can be addressed within a broader, scale-dependent",
138ca9d28b5b10e70a18dce89d5ced48376b6f0a,CLIMATE CHANGE AND WATER,"The warming temperatures and changing precipitation regimes associated with global climate change have effects on the quantity and quality of water in rivers, lakes, and aquifers. Indeed, it is likely that aquatic systems are among the most sensitive of all ecosystems to climate change, as water temperatures track air temperatures closely, the majority of aquatic species are cold blooded and easily affected by changes in temperature, and many ecological processes such as productivity, decomposition, and nutrient cycling in waterways are closely linked to temperature (Ormerod 2009). These waterways are essential for the functioning of all of the planet’s ecosystems, as well as for the maintenance of human life. They also provide essential habitat for more than125,000 species of freshwater animals, representing 9.5% of all known animal species on the planet, along with associated high levels of plant diversity (Strayer 2010). Despite this richness and vulnerability, aquatic systems are often not well protected by traditional protected areas, and receive less conservation attention than terrestrial systems. At the global scale, warming temperatures increase humidity and precipitation, and precipitation has increased about 2% in the last century (Huntington 2006). However, this figure disguises regional differences, as precipitation is expected to increase at high latitudes, and decrease at low and mid latitudes (Malmqvist 2002). Global precipitation trends will also be driven by changes in atmospheric circulation patterns, and on alterations of multiannual and decadal climate cycles such as the El Nino Southern Oscillation or the North Atlantic Oscillation (Wise 2010). However, the majority of effects on waterways and aquatic systems occur at regional and local scales. The main pathways for change are warming water temperatures, changes in snowpack and timing of runoff events, loss of ephemeral wetlands, and sea level rise causing flooding and salinization of coastal wetlands.",2019,"[{'authorId': '4128852', 'name': 'P. Gleick'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1525/9780520943933-008?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1525/9780520943933-008, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the warming temperatures and changing precipitation regimes associated with global climate change have effects on the quantity and quality of water in rivers, lakes, and aquifers. indeed, it is likely that aquatic systems are among the most sensitive of all ecosystems to climate change, as water temperatures track air temperatures closely, the majority of aquatic species are cold blooded and easily affected by changes in temperature, and many ecological processes such as productivity, decomposition, and nutrient cycling in waterways are closely linked to temperature (ormerod 2009). these waterways are essential for the functioning of all of the planet’s ecosystems, as well as for the maintenance of human life. they also provide essential habitat for more than125,000 species of freshwater animals, representing 9.5% of all known animal species on the planet, along with associated high levels of plant diversity (strayer 2010). despite this richness and vulnerability, aquatic systems are often not well protected by traditional protected areas, and receive less conservation attention than terrestrial systems. at the global scale, warming temperatures increase humidity and precipitation, and precipitation has increased about 2% in the last century (huntington 2006). however, this figure disguises regional differences, as precipitation is expected to increase at high latitudes, and decrease at low and mid latitudes (malmqvist 2002). global precipitation trends will also be driven by changes in atmospheric circulation patterns, and on alterations of multiannual and decadal climate cycles such as the el nino southern oscillation or the north atlantic oscillation (wise 2010). however, the majority of effects on waterways and aquatic systems occur at regional and local scales. the main pathways for change are warming water temperatures, changes in snowpack and timing of runoff events, loss of ephemeral wetlands, and sea level rise causing flooding and salinization of coastal wetlands.",
a6ec4a6bbce8b37bb0fca2b4d478f51f23f97f5d,The Economics of Climate Change,plant chloroplasts from with -,2018,"[{'authorId': '2262643554', 'name': 'John Quiggin'}]","{'url': 'https://repositorio.cepal.org//bitstream/11362/38452/1/FOCUSISsue3Jul-Sept2009.pdf', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1515/9783110535129-005?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1515/9783110535129-005, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",the economics of climate change,https://repositorio.cepal.org//bitstream/11362/38452/1/FOCUSISsue3Jul-Sept2009.pdf
93e2f546d5361bc288b07f6c547a7f88b5f4eedd,The Impact of Climate Change on Agricultural Insect Pests,"Simple Summary Climate change and extreme weather events have a major impact on crop production and agricultural pests. As generally adaptable organisms, insect pests respond differently to different causes of climate change. In this review, we address the effects of rising temperatures and atmospheric CO2 levels, as well as changing precipitation patterns, on agricultural insect pests. Since temperature is the most important environmental factor affecting insect population dynamics, it is expected that global climate warming could trigger an expansion of their geographic range, increased overwintering survival, increased number of generations, increased risk of invasive insect species and insect-transmitted plant diseases, as well as changes in their interaction with host plants and natural enemies. As climate change exacerbates the pest problem, there is a great need for future pest management strategies. These include monitoring climate and pest populations, modified integrated pest management strategies, and the use of modelling prediction tools which are presented here. Abstract Climate change and global warming are of great concern to agriculture worldwide and are among the most discussed issues in today’s society. Climate parameters such as increased temperatures, rising atmospheric CO2 levels, and changing precipitation patterns have significant impacts on agricultural production and on agricultural insect pests. Changes in climate can affect insect pests in several ways. They can result in an expansion of their geographic distribution, increased survival during overwintering, increased number of generations, altered synchrony between plants and pests, altered interspecific interaction, increased risk of invasion by migratory pests, increased incidence of insect-transmitted plant diseases, and reduced effectiveness of biological control, especially natural enemies. As a result, there is a serious risk of crop economic losses, as well as a challenge to human food security. As a major driver of pest population dynamics, climate change will require adaptive management strategies to deal with the changing status of pests. Several priorities can be identified for future research on the effects of climatic changes on agricultural insect pests. These include modified integrated pest management tactics, monitoring climate and pest populations, and the use of modelling prediction tools.",2021,"[{'authorId': '30706642', 'name': 'S. Skendžić'}, {'authorId': '5986891', 'name': 'M. Zovko'}, {'authorId': '88221024', 'name': 'I. Živković'}, {'authorId': '9323324', 'name': 'V. Lešić'}, {'authorId': '145029788', 'name': 'D. Lemić'}]","{'url': 'https://www.mdpi.com/2075-4450/12/5/440/pdf?version=1620822800', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8150874, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","simple summary climate change and extreme weather events have a major impact on crop production and agricultural pests. as generally adaptable organisms, insect pests respond differently to different causes of climate change. in this review, we address the effects of rising temperatures and atmospheric co2 levels, as well as changing precipitation patterns, on agricultural insect pests. since temperature is the most important environmental factor affecting insect population dynamics, it is expected that global climate warming could trigger an expansion of their geographic range, increased overwintering survival, increased number of generations, increased risk of invasive insect species and insect-transmitted plant diseases, as well as changes in their interaction with host plants and natural enemies. as climate change exacerbates the pest problem, there is a great need for future pest management strategies. these include monitoring climate and pest populations, modified integrated pest management strategies, and the use of modelling prediction tools which are presented here. abstract climate change and global warming are of great concern to agriculture worldwide and are among the most discussed issues in today’s society. climate parameters such as increased temperatures, rising atmospheric co2 levels, and changing precipitation patterns have significant impacts on agricultural production and on agricultural insect pests. changes in climate can affect insect pests in several ways. they can result in an expansion of their geographic distribution, increased survival during overwintering, increased number of generations, altered synchrony between plants and pests, altered interspecific interaction, increased risk of invasion by migratory pests, increased incidence of insect-transmitted plant diseases, and reduced effectiveness of biological control, especially natural enemies. as a result, there is a serious risk of crop economic losses, as well as a challenge to human food security. as a major driver of pest population dynamics, climate change will require adaptive management strategies to deal with the changing status of pests. several priorities can be identified for future research on the effects of climatic changes on agricultural insect pests. these include modified integrated pest management tactics, monitoring climate and pest populations, and the use of modelling prediction tools.",https://www.mdpi.com/2075-4450/12/5/440/pdf?version=1620822800
51ad2e9c038d69253b7438ea96f9d973684608ef,"Forest microclimates and climate change: Importance, drivers and future research agenda","Forest microclimates contrast strongly with the climate outside forests. To fully understand and better predict how forests' biodiversity and functions relate to climate and climate change, microclimates need to be integrated into ecological research. Despite the potentially broad impact of microclimates on the response of forest ecosystems to global change, our understanding of how microclimates within and below tree canopies modulate biotic responses to global change at the species, community and ecosystem level is still limited. Here, we review how spatial and temporal variation in forest microclimates result from an interplay of forest features, local water balance, topography and landscape composition. We first stress and exemplify the importance of considering forest microclimates to understand variation in biodiversity and ecosystem functions across forest landscapes. Next, we explain how macroclimate warming (of the free atmosphere) can affect microclimates, and vice versa, via interactions with land‐use changes across different biomes. Finally, we perform a priority ranking of future research avenues at the interface of microclimate ecology and global change biology, with a specific focus on three key themes: (1) disentangling the abiotic and biotic drivers and feedbacks of forest microclimates; (2) global and regional mapping and predictions of forest microclimates; and (3) the impacts of microclimate on forest biodiversity and ecosystem functioning in the face of climate change. The availability of microclimatic data will significantly increase in the coming decades, characterizing climate variability at unprecedented spatial and temporal scales relevant to biological processes in forests. This will revolutionize our understanding of the dynamics, drivers and implications of forest microclimates on biodiversity and ecological functions, and the impacts of global changes. In order to support the sustainable use of forests and to secure their biodiversity and ecosystem services for future generations, microclimates cannot be ignored.",2021,"[{'authorId': '7812461', 'name': 'P. De Frenne'}, {'authorId': '48154579', 'name': 'J. Lenoir'}, {'authorId': '3078861', 'name': 'M. Luoto'}, {'authorId': '5401801', 'name': 'Brett R. Scheffers'}, {'authorId': '40606333', 'name': 'Florian Zellweger'}, {'authorId': '3195646', 'name': 'J. Aalto'}, {'authorId': '2839226', 'name': 'M. Ashcroft'}, {'authorId': '35279656', 'name': 'D. M. Christiansen'}, {'authorId': '6014916', 'name': 'G. Decocq'}, {'authorId': '2054698744', 'name': 'K. De Pauw'}, {'authorId': '117746635', 'name': 'S. Govaert'}, {'authorId': '10806514', 'name': 'Caroline Greiser'}, {'authorId': '117625766', 'name': 'Eva Gril'}, {'authorId': '32053622', 'name': 'A. Hampe'}, {'authorId': '3727835', 'name': 'T. Jucker'}, {'authorId': '1646886301', 'name': 'D. Klinges'}, {'authorId': '113801561', 'name': 'Irena A. Koelemeijer'}, {'authorId': '6615558', 'name': 'J. Lembrechts'}, {'authorId': '2027633086', 'name': 'Ronan Marrec'}, {'authorId': '113021890', 'name': 'C. Meeussen'}, {'authorId': '3882413', 'name': 'J. Ogée'}, {'authorId': '11410096', 'name': 'V. Tyystjärvi'}, {'authorId': '6184210', 'name': 'P. Vangansbeke'}, {'authorId': '6720073', 'name': 'K. Hylander'}]","{'url': 'https://biblio.ugent.be/publication/8701223/file/8701227.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/gcb.15569?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/gcb.15569, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","forest microclimates contrast strongly with the climate outside forests. to fully understand and better predict how forests' biodiversity and functions relate to climate and climate change, microclimates need to be integrated into ecological research. despite the potentially broad impact of microclimates on the response of forest ecosystems to global change, our understanding of how microclimates within and below tree canopies modulate biotic responses to global change at the species, community and ecosystem level is still limited. here, we review how spatial and temporal variation in forest microclimates result from an interplay of forest features, local water balance, topography and landscape composition. we first stress and exemplify the importance of considering forest microclimates to understand variation in biodiversity and ecosystem functions across forest landscapes. next, we explain how macroclimate warming (of the free atmosphere) can affect microclimates, and vice versa, via interactions with land‐use changes across different biomes. finally, we perform a priority ranking of future research avenues at the interface of microclimate ecology and global change biology, with a specific focus on three key themes: (1) disentangling the abiotic and biotic drivers and feedbacks of forest microclimates; (2) global and regional mapping and predictions of forest microclimates; and (3) the impacts of microclimate on forest biodiversity and ecosystem functioning in the face of climate change. the availability of microclimatic data will significantly increase in the coming decades, characterizing climate variability at unprecedented spatial and temporal scales relevant to biological processes in forests. this will revolutionize our understanding of the dynamics, drivers and implications of forest microclimates on biodiversity and ecological functions, and the impacts of global changes. in order to support the sustainable use of forests and to secure their biodiversity and ecosystem services for future generations, microclimates cannot be ignored.",https://biblio.ugent.be/publication/8701223/file/8701227.pdf
c78b02f4ce2eb5125ae71845a77c64b7a5c48f76,Health effects of climate change: an overview of systematic reviews,"Objectives We aimed to develop a systematic synthesis of systematic reviews of health impacts of climate change, by synthesising studies’ characteristics, climate impacts, health outcomes and key findings. Design We conducted an overview of systematic reviews of health impacts of climate change. We registered our review in PROSPERO (CRD42019145972). No ethical approval was required since we used secondary data. Additional data are not available. Data sources On 22 June 2019, we searched Medline, Cumulative Index to Nursing and Allied Health Literature (CINAHL), Embase, Cochrane and Web of Science. Eligibility criteria We included systematic reviews that explored at least one health impact of climate change. Data extraction and synthesis We organised systematic reviews according to their key characteristics, including geographical regions, year of publication and authors’ affiliations. We mapped the climate effects and health outcomes being studied and synthesised major findings. We used a modified version of A MeaSurement Tool to Assess systematic Reviews-2 (AMSTAR-2) to assess the quality of studies. Results We included 94 systematic reviews. Most were published after 2015 and approximately one-fifth contained meta-analyses. Reviews synthesised evidence about five categories of climate impacts; the two most common were meteorological and extreme weather events. Reviews covered 10 health outcome categories; the 3 most common were (1) infectious diseases, (2) mortality and (3) respiratory, cardiovascular or neurological outcomes. Most reviews suggested a deleterious impact of climate change on multiple adverse health outcomes, although the majority also called for more research. Conclusions Most systematic reviews suggest that climate change is associated with worse human health. This study provides a comprehensive higher order summary of research on health impacts of climate change. Study limitations include possible missed relevant reviews, no meta-meta-analyses, and no assessment of overlap. Future research could explore the potential explanations between these associations to propose adaptation and mitigation strategies and could include broader sociopsychological health impacts of climate change.",2021,"[{'authorId': '7204898', 'name': 'Rhéa Rocque'}, {'authorId': '145741403', 'name': 'Caroline Beaudoin'}, {'authorId': '8318061', 'name': 'R. Ndjaboué'}, {'authorId': '2061019010', 'name': 'Laura Cameron'}, {'authorId': '2176408927', 'name': 'Louann Poirier-Bergeron'}, {'authorId': '2176408506', 'name': 'Rose-Alice Poulin-Rheault'}, {'authorId': '2960690', 'name': 'C. Fallon'}, {'authorId': '145087336', 'name': 'A. Tricco'}, {'authorId': '2906283', 'name': 'H. Witteman'}]","{'url': 'https://bmjopen.bmj.com/content/bmjopen/11/6/e046333.full.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8191619, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objectives we aimed to develop a systematic synthesis of systematic reviews of health impacts of climate change, by synthesising studies’ characteristics, climate impacts, health outcomes and key findings. design we conducted an overview of systematic reviews of health impacts of climate change. we registered our review in prospero (crd42019145972). no ethical approval was required since we used secondary data. additional data are not available. data sources on 22 june 2019, we searched medline, cumulative index to nursing and allied health literature (cinahl), embase, cochrane and web of science. eligibility criteria we included systematic reviews that explored at least one health impact of climate change. data extraction and synthesis we organised systematic reviews according to their key characteristics, including geographical regions, year of publication and authors’ affiliations. we mapped the climate effects and health outcomes being studied and synthesised major findings. we used a modified version of a measurement tool to assess systematic reviews-2 (amstar-2) to assess the quality of studies. results we included 94 systematic reviews. most were published after 2015 and approximately one-fifth contained meta-analyses. reviews synthesised evidence about five categories of climate impacts; the two most common were meteorological and extreme weather events. reviews covered 10 health outcome categories; the 3 most common were (1) infectious diseases, (2) mortality and (3) respiratory, cardiovascular or neurological outcomes. most reviews suggested a deleterious impact of climate change on multiple adverse health outcomes, although the majority also called for more research. conclusions most systematic reviews suggest that climate change is associated with worse human health. this study provides a comprehensive higher order summary of research on health impacts of climate change. study limitations include possible missed relevant reviews, no meta-meta-analyses, and no assessment of overlap. future research could explore the potential explanations between these associations to propose adaptation and mitigation strategies and could include broader sociopsychological health impacts of climate change.",https://bmjopen.bmj.com/content/bmjopen/11/6/e046333.full.pdf
93ed5ec1dc19723acf80fd060f9bca8d00dc1dd7,Understanding the value and limits of nature-based solutions to climate change and other global challenges,"There is growing awareness that ‘nature-based solutions' (NbS) can help to protect us from climate change impacts while slowing further warming, supporting biodiversity and securing ecosystem services. However, the potential of NbS to provide the intended benefits has not been rigorously assessed. There are concerns over their reliability and cost-effectiveness compared to engineered alternatives, and their resilience to climate change. Trade-offs can arise if climate mitigation policy encourages NbS with low biodiversity value, such as afforestation with non-native monocultures. This can result in maladaptation, especially in a rapidly changing world where biodiversity-based resilience and multi-functional landscapes are key. Here, we highlight the rise of NbS in climate policy—focusing on their potential for climate change adaptation as well as mitigation—and discuss barriers to their evidence-based implementation. We outline the major financial and governance challenges to implementing NbS at scale, highlighting avenues for further research. As climate policy turns increasingly towards greenhouse gas removal approaches such as afforestation, we stress the urgent need for natural and social scientists to engage with policy makers. They must ensure that NbS can achieve their potential to tackle both the climate and biodiversity crisis while also contributing to sustainable development. This will require systemic change in the way we conduct research and run our institutions. This article is part of the theme issue ‘Climate change and ecosystems: threats, opportunities and solutions’.",2020,"[{'authorId': '2521180', 'name': 'N. Seddon'}, {'authorId': '6116471', 'name': 'A. Chausson'}, {'authorId': '121360570', 'name': 'P. Berry'}, {'authorId': '35182759', 'name': 'C. Girardin'}, {'authorId': '2116708800', 'name': 'Alison C. Smith'}, {'authorId': '48360562', 'name': 'B. Turner'}]","{'url': 'https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2019.0120', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1098/rstb.2019.0120?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1098/rstb.2019.0120, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","there is growing awareness that ‘nature-based solutions' (nbs) can help to protect us from climate change impacts while slowing further warming, supporting biodiversity and securing ecosystem services. however, the potential of nbs to provide the intended benefits has not been rigorously assessed. there are concerns over their reliability and cost-effectiveness compared to engineered alternatives, and their resilience to climate change. trade-offs can arise if climate mitigation policy encourages nbs with low biodiversity value, such as afforestation with non-native monocultures. this can result in maladaptation, especially in a rapidly changing world where biodiversity-based resilience and multi-functional landscapes are key. here, we highlight the rise of nbs in climate policy—focusing on their potential for climate change adaptation as well as mitigation—and discuss barriers to their evidence-based implementation. we outline the major financial and governance challenges to implementing nbs at scale, highlighting avenues for further research. as climate policy turns increasingly towards greenhouse gas removal approaches such as afforestation, we stress the urgent need for natural and social scientists to engage with policy makers. they must ensure that nbs can achieve their potential to tackle both the climate and biodiversity crisis while also contributing to sustainable development. this will require systemic change in the way we conduct research and run our institutions. this article is part of the theme issue ‘climate change and ecosystems: threats, opportunities and solutions’.",https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2019.0120
2b96bb54e41fcbb5fbb9e7fff71cdb18d8b7c1a9,Plant phenology and global climate change: Current progresses and challenges,"Plant phenology, the annually recurring sequence of plant developmental stages, is important for plant functioning and ecosystem services and their biophysical and biogeochemical feedbacks to the climate system. Plant phenology depends on temperature, and the current rapid climate change has revived interest in understanding and modeling the responses of plant phenology to the warming trend and the consequences thereof for ecosystems. Here, we review recent progresses in plant phenology and its interactions with climate change. Focusing on the start (leaf unfolding) and end (leaf coloring) of plant growing seasons, we show that the recent rapid expansion in ground‐ and remote sensing‐ based phenology data acquisition has been highly beneficial and has supported major advances in plant phenology research. Studies using multiple data sources and methods generally agree on the trends of advanced leaf unfolding and delayed leaf coloring due to climate change, yet these trends appear to have decelerated or even reversed in recent years. Our understanding of the mechanisms underlying the plant phenology responses to climate warming is still limited. The interactions between multiple drivers complicate the modeling and prediction of plant phenology changes. Furthermore, changes in plant phenology have important implications for ecosystem carbon cycles and ecosystem feedbacks to climate, yet the quantification of such impacts remains challenging. We suggest that future studies should primarily focus on using new observation tools to improve the understanding of tropical plant phenology, on improving process‐based phenology modeling, and on the scaling of phenology from species to landscape‐level.",2019,"[{'authorId': '1751339', 'name': 'S. Piao'}, {'authorId': '51064962', 'name': 'Qiang Liu'}, {'authorId': '48162950', 'name': 'Anping Chen'}, {'authorId': '2368804', 'name': 'I. Janssens'}, {'authorId': '6403681', 'name': 'Yongshuo H. Fu'}, {'authorId': '7698364', 'name': 'Junhu Dai'}, {'authorId': '49480359', 'name': 'Lingli Liu'}, {'authorId': '93989417', 'name': 'Xu Lian'}, {'authorId': '35422182', 'name': 'M. Shen'}, {'authorId': '49897567', 'name': 'Xiaolin Zhu'}]","{'url': 'http://ira.lib.polyu.edu.hk/bitstream/10397/94083/1/Piao_Plant_Phenology_Climate.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/gcb.14619?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/gcb.14619, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","plant phenology, the annually recurring sequence of plant developmental stages, is important for plant functioning and ecosystem services and their biophysical and biogeochemical feedbacks to the climate system. plant phenology depends on temperature, and the current rapid climate change has revived interest in understanding and modeling the responses of plant phenology to the warming trend and the consequences thereof for ecosystems. here, we review recent progresses in plant phenology and its interactions with climate change. focusing on the start (leaf unfolding) and end (leaf coloring) of plant growing seasons, we show that the recent rapid expansion in ground‐ and remote sensing‐ based phenology data acquisition has been highly beneficial and has supported major advances in plant phenology research. studies using multiple data sources and methods generally agree on the trends of advanced leaf unfolding and delayed leaf coloring due to climate change, yet these trends appear to have decelerated or even reversed in recent years. our understanding of the mechanisms underlying the plant phenology responses to climate warming is still limited. the interactions between multiple drivers complicate the modeling and prediction of plant phenology changes. furthermore, changes in plant phenology have important implications for ecosystem carbon cycles and ecosystem feedbacks to climate, yet the quantification of such impacts remains challenging. we suggest that future studies should primarily focus on using new observation tools to improve the understanding of tropical plant phenology, on improving process‐based phenology modeling, and on the scaling of phenology from species to landscape‐level.",http://ira.lib.polyu.edu.hk/bitstream/10397/94083/1/Piao_Plant_Phenology_Climate.pdf
67b84c6e4998ccb50d2a05e23e16923f982bf408,Climate change impacts on cultural heritage: A literature review,"Climate change, as revealed by gradual changes in temperature, precipitation, atmospheric moisture, and wind intensity, as well as sea level rise and changes in the occurrence of extreme events, is already affecting cultural heritage sites. Accordingly, there is a rapidly increasing body of research reporting on the impacts of climatic stressors on cultural heritage and on the assessment of climate change impacts on cultural heritage assets. This review synthesizes the international literature on climate change impacts on tangible cultural heritage by developing hazard‐impact diagrams focusing on the impacts of gradual changes in climate on: (1) the cultural heritage exposed to the outside environment, (2) the interiors of historical buildings and their collections, and (3) a third diagram associated with climate change and the impacts due to sudden changes in the natural physical environment (e.g., storm surges, floods and landslides, wildfire) in addition to sea level rise, permafrost thawing, desertification and changes in the properties of the oceans. These diagrams, which depict the relationships between various stressors and their impacts on cultural heritage, will allow other researchers, stakeholders, and potentially decision makers to determine the potential impacts of climate change on a specific cultural heritage asset without a separate examination of the literature. This review thus provides the current state‐of‐the‐art on the impacts of climate change on the tangible, built heritage, that is, monuments, archeological sites, historical buildings, as well as their interiors and the collections they hold, highlights the limitations of previous research, and provides recommendations for further studies.",2021,"[{'authorId': '108012446', 'name': 'Elena Sesana'}, {'authorId': '46572321', 'name': 'A. Gagnon'}, {'authorId': '13499604', 'name': 'C. Ciantelli'}, {'authorId': '2840314', 'name': 'J. Cassar'}, {'authorId': '2113442991', 'name': 'John Hughes'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wcc.710', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/wcc.710?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/wcc.710, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","climate change, as revealed by gradual changes in temperature, precipitation, atmospheric moisture, and wind intensity, as well as sea level rise and changes in the occurrence of extreme events, is already affecting cultural heritage sites. accordingly, there is a rapidly increasing body of research reporting on the impacts of climatic stressors on cultural heritage and on the assessment of climate change impacts on cultural heritage assets. this review synthesizes the international literature on climate change impacts on tangible cultural heritage by developing hazard‐impact diagrams focusing on the impacts of gradual changes in climate on: (1) the cultural heritage exposed to the outside environment, (2) the interiors of historical buildings and their collections, and (3) a third diagram associated with climate change and the impacts due to sudden changes in the natural physical environment (e.g., storm surges, floods and landslides, wildfire) in addition to sea level rise, permafrost thawing, desertification and changes in the properties of the oceans. these diagrams, which depict the relationships between various stressors and their impacts on cultural heritage, will allow other researchers, stakeholders, and potentially decision makers to determine the potential impacts of climate change on a specific cultural heritage asset without a separate examination of the literature. this review thus provides the current state‐of‐the‐art on the impacts of climate change on the tangible, built heritage, that is, monuments, archeological sites, historical buildings, as well as their interiors and the collections they hold, highlights the limitations of previous research, and provides recommendations for further studies.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wcc.710
ed765e5404352fdc9365b397fcedbf85b89bf0ae,Impacts of climate change on the future of biodiversity.,"Many studies in recent years have investigated the effects of climate change on the future of biodiversity. In this review, we first examine the different possible effects of climate change that can operate at individual, population, species, community, ecosystem and biome scales, notably showing that species can respond to climate change challenges by shifting their climatic niche along three non-exclusive axes: time (e.g. phenology), space (e.g. range) and self (e.g. physiology). Then, we present the principal specificities and caveats of the most common approaches used to estimate future biodiversity at global and sub-continental scales and we synthesise their results. Finally, we highlight several challenges for future research both in theoretical and applied realms. Overall, our review shows that current estimates are very variable, depending on the method, taxonomic group, biodiversity loss metrics, spatial scales and time periods considered. Yet, the majority of models indicate alarming consequences for biodiversity, with the worst-case scenarios leading to extinction rates that would qualify as the sixth mass extinction in the history of the earth.",2012,"[{'authorId': '6782126', 'name': 'C. Bellard'}, {'authorId': '6672923', 'name': 'C. Bertelsmeier'}, {'authorId': '4856898', 'name': 'P. Leadley'}, {'authorId': '3210891', 'name': 'W. Thuiller'}, {'authorId': '5586838', 'name': 'F. Courchamp'}]","{'url': 'https://europepmc.org/articles/pmc3880584?pdf=render', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/j.1461-0248.2011.01736.x?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/j.1461-0248.2011.01736.x, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","many studies in recent years have investigated the effects of climate change on the future of biodiversity. in this review, we first examine the different possible effects of climate change that can operate at individual, population, species, community, ecosystem and biome scales, notably showing that species can respond to climate change challenges by shifting their climatic niche along three non-exclusive axes: time (e.g. phenology), space (e.g. range) and self (e.g. physiology). then, we present the principal specificities and caveats of the most common approaches used to estimate future biodiversity at global and sub-continental scales and we synthesise their results. finally, we highlight several challenges for future research both in theoretical and applied realms. overall, our review shows that current estimates are very variable, depending on the method, taxonomic group, biodiversity loss metrics, spatial scales and time periods considered. yet, the majority of models indicate alarming consequences for biodiversity, with the worst-case scenarios leading to extinction rates that would qualify as the sixth mass extinction in the history of the earth.",https://europepmc.org/articles/pmc3880584?pdf=render
beff0131c6dd5b9acd4e3c7f1996d144309f2e2e,Strategies for mitigation of climate change: a review,"Climate change is defined as the shift in climate patterns mainly caused by greenhouse gas emissions from natural systems and human activities. So far, anthropogenic activities have caused about 1.0 °C of global warming above the pre-industrial level and this is likely to reach 1.5 °C between 2030 and 2052 if the current emission rates persist. In 2018, the world encountered 315 cases of natural disasters which are mainly related to the climate. Approximately 68.5 million people were affected, and economic losses amounted to $131.7 billion, of which storms, floods, wildfires and droughts accounted for approximately 93%. Economic losses attributed to wildfires in 2018 alone are almost equal to the collective losses from wildfires incurred over the past decade, which is quite alarming. Furthermore, food, water, health, ecosystem, human habitat and infrastructure have been identified as the most vulnerable sectors under climate attack. In 2015, the Paris agreement was introduced with the main objective of limiting global temperature increase to 2 °C by 2100 and pursuing efforts to limit the increase to 1.5 °C. This article reviews the main strategies for climate change abatement, namely conventional mitigation, negative emissions and radiative forcing geoengineering. Conventional mitigation technologies focus on reducing fossil-based CO2 emissions. Negative emissions technologies are aiming to capture and sequester atmospheric carbon to reduce carbon dioxide levels. Finally, geoengineering techniques of radiative forcing alter the earth’s radiative energy budget to stabilize or reduce global temperatures. It is evident that conventional mitigation efforts alone are not sufficient to meet the targets stipulated by the Paris agreement; therefore, the utilization of alternative routes appears inevitable. While various technologies presented may still be at an early stage of development, biogenic-based sequestration techniques are to a certain extent mature and can be deployed immediately.",2020,"[{'authorId': '1842273253', 'name': 'Samer Fawzy'}, {'authorId': '32474777', 'name': 'A. Osman'}, {'authorId': '112900599', 'name': 'J. Doran'}, {'authorId': '145461361', 'name': 'D. Rooney'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s10311-020-01059-w.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10311-020-01059-w?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10311-020-01059-w, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","climate change is defined as the shift in climate patterns mainly caused by greenhouse gas emissions from natural systems and human activities. so far, anthropogenic activities have caused about 1.0 °c of global warming above the pre-industrial level and this is likely to reach 1.5 °c between 2030 and 2052 if the current emission rates persist. in 2018, the world encountered 315 cases of natural disasters which are mainly related to the climate. approximately 68.5 million people were affected, and economic losses amounted to $131.7 billion, of which storms, floods, wildfires and droughts accounted for approximately 93%. economic losses attributed to wildfires in 2018 alone are almost equal to the collective losses from wildfires incurred over the past decade, which is quite alarming. furthermore, food, water, health, ecosystem, human habitat and infrastructure have been identified as the most vulnerable sectors under climate attack. in 2015, the paris agreement was introduced with the main objective of limiting global temperature increase to 2 °c by 2100 and pursuing efforts to limit the increase to 1.5 °c. this article reviews the main strategies for climate change abatement, namely conventional mitigation, negative emissions and radiative forcing geoengineering. conventional mitigation technologies focus on reducing fossil-based co2 emissions. negative emissions technologies are aiming to capture and sequester atmospheric carbon to reduce carbon dioxide levels. finally, geoengineering techniques of radiative forcing alter the earth’s radiative energy budget to stabilize or reduce global temperatures. it is evident that conventional mitigation efforts alone are not sufficient to meet the targets stipulated by the paris agreement; therefore, the utilization of alternative routes appears inevitable. while various technologies presented may still be at an early stage of development, biogenic-based sequestration techniques are to a certain extent mature and can be deployed immediately.",https://link.springer.com/content/pdf/10.1007/s10311-020-01059-w.pdf
4a32f5d448a6254994bc575453f87fb36554cd26,The Impact of Climate Change on Mental Health: A Systematic Descriptive Review,"Background Climate change is one of the great challenges of our time. The consequences of climate change on exposed biological subjects, as well as on vulnerable societies, are a concern for the entire scientific community. Rising temperatures, heat waves, floods, tornadoes, hurricanes, droughts, fires, loss of forest, and glaciers, along with disappearance of rivers and desertification, can directly and indirectly cause human pathologies that are physical and mental. However, there is a clear lack in psychiatric studies on mental disorders linked to climate change. Methods Literature available on PubMed, EMBASE, and Cochrane library until end of June 2019 were reviewed. The total number of articles and association reports was 445. From these, 163 were selected. We looked for the association between classical psychiatric disorders such as anxiety schizophrenia, mood disorder and depression, suicide, aggressive behaviors, despair for the loss of usual landscape, and phenomena related to climate change and extreme weather. Review of literature was then divided into specific areas: the course of change in mental health, temperature, water, air pollution, drought, as well as the exposure of certain groups and critical psychological adaptations. Results Climate change has an impact on a large part of the population, in different geographical areas and with different types of threats to public health. However, the delay in studies on climate change and mental health consequences is an important aspect. Lack of literature is perhaps due to the complexity and novelty of this issue. It has been shown that climate change acts on mental health with different timing. The phenomenology of the effects of climate change differs greatly—some mental disorders are common and others more specific in relation to atypical climatic conditions. Moreover, climate change also affects different population groups who are directly exposed and more vulnerable in their geographical conditions, as well as a lack of access to resources, information, and protection. Perhaps it is also worth underlining that in some papers the connection between climatic events and mental disorders was described through the introduction of new terms, coined only recently: ecoanxiety, ecoguilt, ecopsychology, ecological grief, solastalgia, biospheric concern, etc. Conclusions The effects of climate change can be direct or indirect, short-term or long-term. Acute events can act through mechanisms similar to that of traumatic stress, leading to well-understood psychopathological patterns. In addition, the consequences of exposure to extreme or prolonged weather-related events can also be delayed, encompassing disorders such as posttraumatic stress, or even transmitted to later generations.",2020,"[{'authorId': '98856838', 'name': 'P. Cianconi'}, {'authorId': '15807465', 'name': ""S. Betro'""}, {'authorId': '4420034', 'name': 'L. Janiri'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyt.2020.00074/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7068211, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background climate change is one of the great challenges of our time. the consequences of climate change on exposed biological subjects, as well as on vulnerable societies, are a concern for the entire scientific community. rising temperatures, heat waves, floods, tornadoes, hurricanes, droughts, fires, loss of forest, and glaciers, along with disappearance of rivers and desertification, can directly and indirectly cause human pathologies that are physical and mental. however, there is a clear lack in psychiatric studies on mental disorders linked to climate change. methods literature available on pubmed, embase, and cochrane library until end of june 2019 were reviewed. the total number of articles and association reports was 445. from these, 163 were selected. we looked for the association between classical psychiatric disorders such as anxiety schizophrenia, mood disorder and depression, suicide, aggressive behaviors, despair for the loss of usual landscape, and phenomena related to climate change and extreme weather. review of literature was then divided into specific areas: the course of change in mental health, temperature, water, air pollution, drought, as well as the exposure of certain groups and critical psychological adaptations. results climate change has an impact on a large part of the population, in different geographical areas and with different types of threats to public health. however, the delay in studies on climate change and mental health consequences is an important aspect. lack of literature is perhaps due to the complexity and novelty of this issue. it has been shown that climate change acts on mental health with different timing. the phenomenology of the effects of climate change differs greatly—some mental disorders are common and others more specific in relation to atypical climatic conditions. moreover, climate change also affects different population groups who are directly exposed and more vulnerable in their geographical conditions, as well as a lack of access to resources, information, and protection. perhaps it is also worth underlining that in some papers the connection between climatic events and mental disorders was described through the introduction of new terms, coined only recently: ecoanxiety, ecoguilt, ecopsychology, ecological grief, solastalgia, biospheric concern, etc. conclusions the effects of climate change can be direct or indirect, short-term or long-term. acute events can act through mechanisms similar to that of traumatic stress, leading to well-understood psychopathological patterns. in addition, the consequences of exposure to extreme or prolonged weather-related events can also be delayed, encompassing disorders such as posttraumatic stress, or even transmitted to later generations.",https://www.frontiersin.org/articles/10.3389/fpsyt.2020.00074/pdf
cd76ca1e6c00b79bfc2777e6bcb99bcfee719acd,Firm-level Climate Change Exposure,"We introduce a method that identifies climate change exposure from earnings conference calls of 10,158 firms from 34 countries. The method adapts a machine learning keyword discovery algorithm and captures exposures related to opportunity, physical, and regulatory shocks associated with climate change. The exposure measures exhibit cross-sectional and time-series variations that align with reasonable priors, and these measures are better at capturing firm-level variation than are carbon intensities or ratings. The exposure measures capture economic factors that prior work has identified as important correlates of climate change exposure. In recent years, exposure to regulatory shocks negatively correlates with firm valuations.",2020,"[{'authorId': '66795750', 'name': 'Z. Sautner'}, {'authorId': '1677658320', 'name': 'Laurence van Lent'}, {'authorId': '52158685', 'name': 'G. Vilkov'}, {'authorId': '15176382', 'name': 'Ruishen Zhang'}]","{'url': 'https://www.econstor.eu/bitstream/10419/288045/1/JOFI_JOFI13219.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3642508?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3642508, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we introduce a method that identifies climate change exposure from earnings conference calls of 10,158 firms from 34 countries. the method adapts a machine learning keyword discovery algorithm and captures exposures related to opportunity, physical, and regulatory shocks associated with climate change. the exposure measures exhibit cross-sectional and time-series variations that align with reasonable priors, and these measures are better at capturing firm-level variation than are carbon intensities or ratings. the exposure measures capture economic factors that prior work has identified as important correlates of climate change exposure. in recent years, exposure to regulatory shocks negatively correlates with firm valuations.",https://www.econstor.eu/bitstream/10419/288045/1/JOFI_JOFI13219.pdf
d3f553581a465375f284e8cc74bee52fea1d54d8,Mapping the effectiveness of nature‐based solutions for climate change adaptation,"Nature‐based solutions (NbS) to climate change currently have considerable political traction. However, national intentions to deploy NbS have yet to be fully translated into evidence‐based targets and action on the ground. To enable NbS policy and practice to be better informed by science, we produced the first global systematic map of evidence on the effectiveness of nature‐based interventions for addressing the impacts of climate change and hydrometeorological hazards on people. Most of the interventions in natural or semi‐natural ecosystems were reported to have ameliorated adverse climate impacts. Conversely, interventions involving created ecosystems (e.g., afforestation) were associated with trade‐offs; such studies primarily reported reduced soil erosion or increased vegetation cover but lower water availability, although this evidence was geographically restricted. Overall, studies reported more synergies than trade‐offs between reduced climate impacts and broader ecological, social, and climate change mitigation outcomes. In addition, nature‐based interventions were most often shown to be as effective or more so than alternative interventions for addressing climate impacts. However, there were substantial gaps in the evidence base. Notably, there were few studies of the cost‐effectiveness of interventions compared to alternatives and few integrated assessments considering broader social and ecological outcomes. There was also a bias in evidence toward the Global North, despite communities in the Global South being generally more vulnerable to climate impacts. To build resilience to climate change worldwide, it is imperative that we protect and harness the benefits that nature can provide, which can only be done effectively if informed by a strengthened evidence base.",2020,"[{'authorId': '6116471', 'name': 'A. Chausson'}, {'authorId': '48360562', 'name': 'B. Turner'}, {'authorId': '1937834150', 'name': 'Dan Seddon'}, {'authorId': '1937833333', 'name': 'Nicole Chabaneix'}, {'authorId': '35182759', 'name': 'C. Girardin'}, {'authorId': '5461543', 'name': 'V. Kapos'}, {'authorId': '1937833322', 'name': 'Isabel Key'}, {'authorId': '12468577', 'name': 'D. Roe'}, {'authorId': '2116708800', 'name': 'Alison C. Smith'}, {'authorId': '113679861', 'name': 'Stephen Woroniecki'}, {'authorId': '2521180', 'name': 'N. Seddon'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/gcb.15310', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/gcb.15310?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/gcb.15310, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","nature‐based solutions (nbs) to climate change currently have considerable political traction. however, national intentions to deploy nbs have yet to be fully translated into evidence‐based targets and action on the ground. to enable nbs policy and practice to be better informed by science, we produced the first global systematic map of evidence on the effectiveness of nature‐based interventions for addressing the impacts of climate change and hydrometeorological hazards on people. most of the interventions in natural or semi‐natural ecosystems were reported to have ameliorated adverse climate impacts. conversely, interventions involving created ecosystems (e.g., afforestation) were associated with trade‐offs; such studies primarily reported reduced soil erosion or increased vegetation cover but lower water availability, although this evidence was geographically restricted. overall, studies reported more synergies than trade‐offs between reduced climate impacts and broader ecological, social, and climate change mitigation outcomes. in addition, nature‐based interventions were most often shown to be as effective or more so than alternative interventions for addressing climate impacts. however, there were substantial gaps in the evidence base. notably, there were few studies of the cost‐effectiveness of interventions compared to alternatives and few integrated assessments considering broader social and ecological outcomes. there was also a bias in evidence toward the global north, despite communities in the global south being generally more vulnerable to climate impacts. to build resilience to climate change worldwide, it is imperative that we protect and harness the benefits that nature can provide, which can only be done effectively if informed by a strengthened evidence base.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/gcb.15310
9fb9ea1a76e29b7f4b9b1611c4933be6a1d3feca,"Climate change and ecosystems: threats, opportunities and solutions","The rapid anthropogenic climate change that is being experienced in the early twenty-first century is intimately entwined with the health and functioning of the biosphere. Climate change is impacting ecosystems through changes in mean conditions and in climate variability, coupled with other associated changes such as increased ocean acidification and atmospheric carbon dioxide concentrations. It also interacts with other pressures on ecosystems, including degradation, defaunation and fragmentation. There is a need to understand the ecological dynamics of these climate impacts, to identify hotspots of vulnerability and resilience and to identify management interventions that may assist biosphere resilience to climate change. At the same time, ecosystems can also assist in the mitigation of, and adaptation to, climate change. The mechanisms, potential and limits of such nature-based solutions to climate change need to be explored and quantified. This paper introduces a thematic issue dedicated to the interaction between climate change and the biosphere. It explores novel perspectives on how ecosystems respond to climate change, how ecosystem resilience can be enhanced and how ecosystems can assist in addressing the challenge of a changing climate. It draws on a Royal Society-National Academy of Sciences Forum held in Washington DC in November 2018, where these themes and issues were discussed. We conclude by identifying some priorities for academic research and practical implementation, in order to maximize the potential for maintaining a diverse, resilient and well-functioning biosphere under the challenging conditions of the twenty-first century. This article is part of the theme issue ‘Climate change and ecosystems: threats, opportunities and solutions’.",2020,"[{'authorId': '48401102', 'name': 'Y. Malhi'}, {'authorId': '144735103', 'name': 'J. Franklin'}, {'authorId': '2521180', 'name': 'N. Seddon'}, {'authorId': '4028247', 'name': 'M. Solan'}, {'authorId': '40144448', 'name': 'M. Turner'}, {'authorId': '2525997', 'name': 'C. Field'}, {'authorId': '144873730', 'name': 'N. Knowlton'}]","{'url': 'https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2019.0104', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1098/rstb.2019.0104?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1098/rstb.2019.0104, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the rapid anthropogenic climate change that is being experienced in the early twenty-first century is intimately entwined with the health and functioning of the biosphere. climate change is impacting ecosystems through changes in mean conditions and in climate variability, coupled with other associated changes such as increased ocean acidification and atmospheric carbon dioxide concentrations. it also interacts with other pressures on ecosystems, including degradation, defaunation and fragmentation. there is a need to understand the ecological dynamics of these climate impacts, to identify hotspots of vulnerability and resilience and to identify management interventions that may assist biosphere resilience to climate change. at the same time, ecosystems can also assist in the mitigation of, and adaptation to, climate change. the mechanisms, potential and limits of such nature-based solutions to climate change need to be explored and quantified. this paper introduces a thematic issue dedicated to the interaction between climate change and the biosphere. it explores novel perspectives on how ecosystems respond to climate change, how ecosystem resilience can be enhanced and how ecosystems can assist in addressing the challenge of a changing climate. it draws on a royal society-national academy of sciences forum held in washington dc in november 2018, where these themes and issues were discussed. we conclude by identifying some priorities for academic research and practical implementation, in order to maximize the potential for maintaining a diverse, resilient and well-functioning biosphere under the challenging conditions of the twenty-first century. this article is part of the theme issue ‘climate change and ecosystems: threats, opportunities and solutions’.",https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2019.0104
ff8536b6af80b3e919baa4eb0dbf2d78d7074bf2,Achievements and needs for the climate change scenario framework,"Long-term global scenarios have underpinned research and assessment of global environmental change for four decades. Over the past ten years, the climate change research community has developed a scenario framework combining alternative futures of climate and society to facilitate integrated research and consistent assessment to inform policy. Here we assess how well this framework is working and what challenges it faces. We synthesize insights from scenario-based literature, community discussions and recent experience in assessments, concluding that the framework has been widely adopted across research communities and is largely meeting immediate needs. However, some mixed successes and a changing policy and research landscape present key challenges, and we recommend several new directions for the development and use of this framework. The SSP–RCP scenario framework has been an important component of physical, social and integrated climate change research for the past decade. This Perspective reviews the successes of the framework and the challenges it faces, and provides suggestions for improvement moving forward.",2020,"[{'authorId': '1400843812', 'name': 'B. O’Neill'}, {'authorId': '49045938', 'name': 'T. Carter'}, {'authorId': '143932649', 'name': 'K. Ebi'}, {'authorId': '2128846', 'name': 'P. Harrison'}, {'authorId': '1403750462', 'name': 'E. Kemp-Benedict'}, {'authorId': '39689738', 'name': 'K. Kok'}, {'authorId': '2304547', 'name': 'E. Kriegler'}, {'authorId': '2110592', 'name': 'B. Preston'}, {'authorId': '3491432', 'name': 'K. Riahi'}, {'authorId': '4730956', 'name': 'J. Sillmann'}, {'authorId': '137091543', 'name': 'Bas J. van Ruijven'}, {'authorId': '31589982', 'name': 'D. V. van Vuuren'}, {'authorId': '2072090918', 'name': 'David Carlisle'}, {'authorId': '77839636', 'name': 'C. Conde'}, {'authorId': '104102124', 'name': 'J. Fuglestvedt'}, {'authorId': '2028821431', 'name': 'Carole Green'}, {'authorId': '50031977', 'name': 'T. Hasegawa'}, {'authorId': '91874317', 'name': 'Julia Leininger'}, {'authorId': '2028823616', 'name': 'Seth Monteith'}, {'authorId': '1414003999', 'name': 'Ramón Pichs-Madruga'}]","{'url': 'https://www.nature.com/articles/s41558-020-00952-0.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7688299, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","long-term global scenarios have underpinned research and assessment of global environmental change for four decades. over the past ten years, the climate change research community has developed a scenario framework combining alternative futures of climate and society to facilitate integrated research and consistent assessment to inform policy. here we assess how well this framework is working and what challenges it faces. we synthesize insights from scenario-based literature, community discussions and recent experience in assessments, concluding that the framework has been widely adopted across research communities and is largely meeting immediate needs. however, some mixed successes and a changing policy and research landscape present key challenges, and we recommend several new directions for the development and use of this framework. the ssp–rcp scenario framework has been an important component of physical, social and integrated climate change research for the past decade. this perspective reviews the successes of the framework and the challenges it faces, and provides suggestions for improvement moving forward.",https://www.nature.com/articles/s41558-020-00952-0.pdf
6b276225026544ddbd517df5fe6de57b31795683,"A review of renewable energy sources, sustainability issues and climate change mitigation","Abstract The world is fast becoming a global village due to the increasing daily requirement of energy by all population across the world while the earth in its form cannot change. The need for energy and its related services to satisfy human social and economic development, welfare and health is increasing. Returning to renewables to help mitigate climate change is an excellent approach which needs to be sustainable in order to meet energy demand of future generations. The study reviewed the opportunities associated with renewable energy sources which includes: Energy Security, Energy Access, Social and Economic development, Climate Change Mitigation, and reduction of environmental and health impacts. Despite these opportunities, there are challenges that hinder the sustainability of renewable energy sources towards climate change mitigation. These challenges include Market failures, lack of information, access to raw materials for future renewable resource deployment, and our daily carbon footprint. The study suggested some measures and policy recommendations which when considered would help achieve the goal of renewable energy thus to reduce emissions, mitigate climate change and provide a clean environment as well as clean energy for all and future generations.",2016,"[{'authorId': '11570110', 'name': 'P. A. Owusu'}, {'authorId': '1403449788', 'name': 'Samuel Asumadu-Sarkodie'}]","{'url': 'https://doi.org/10.1080/23311916.2016.1167990', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/23311916.2016.1167990?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/23311916.2016.1167990, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the world is fast becoming a global village due to the increasing daily requirement of energy by all population across the world while the earth in its form cannot change. the need for energy and its related services to satisfy human social and economic development, welfare and health is increasing. returning to renewables to help mitigate climate change is an excellent approach which needs to be sustainable in order to meet energy demand of future generations. the study reviewed the opportunities associated with renewable energy sources which includes: energy security, energy access, social and economic development, climate change mitigation, and reduction of environmental and health impacts. despite these opportunities, there are challenges that hinder the sustainability of renewable energy sources towards climate change mitigation. these challenges include market failures, lack of information, access to raw materials for future renewable resource deployment, and our daily carbon footprint. the study suggested some measures and policy recommendations which when considered would help achieve the goal of renewable energy thus to reduce emissions, mitigate climate change and provide a clean environment as well as clean energy for all and future generations.",https://doi.org/10.1080/23311916.2016.1167990
02a385e4eebc1009e801d06dfc7293d8445beef2,Growing polarization around climate change on social media,"Climate change and political polarization are two of the twenty-first century’s critical socio-political issues. Here we investigate their intersection by studying the discussion around the United Nations Conference of the Parties on Climate Change (COP) using Twitter data from 2014 to 2021. First, we reveal a large increase in ideological polarization during COP26, following low polarization between COP20 and COP25. Second, we show that this increase is driven by growing right-wing activity, a fourfold increase since COP21 relative to pro-climate groups. Finally, we identify a broad range of ‘climate contrarian’ views during COP26, emphasizing the theme of political hypocrisy as a topic of cross-ideological appeal; contrarian views and accusations of hypocrisy have become key themes in the Twitter climate discussion since 2019. With future climate action reliant on negotiations at COP27 and beyond, our results highlight the importance of monitoring polarization and its impacts in the public climate discourse. Polarization and the resulting political deadlock have become key barriers to more ambitious climate action. Using Twitter data between Conferences of the Parties, this research identifies a trend of increasing polarization driven by growing right-wing activity alongside accusations of political hypocrisy.",2021,"[{'authorId': '80916191', 'name': 'M. Falkenberg'}, {'authorId': '30978073', 'name': 'Alessandro Galeazzi'}, {'authorId': '1400580680', 'name': 'M. Torricelli'}, {'authorId': '2174134588', 'name': 'N. Di Marco'}, {'authorId': '2024386537', 'name': 'F. Larosa'}, {'authorId': '2049085100', 'name': 'Madalina Sas'}, {'authorId': '2146695726', 'name': 'Amin Mekacher'}, {'authorId': '119591703', 'name': 'Warren Pearce'}, {'authorId': '40016674', 'name': 'Fabiana Zollo'}, {'authorId': '1728390', 'name': 'Walter Quattrociocchi'}, {'authorId': '2836702', 'name': 'Andrea Baronchelli'}]","{'url': 'https://www.nature.com/articles/s41558-022-01527-x.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2112.12137, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","climate change and political polarization are two of the twenty-first century’s critical socio-political issues. here we investigate their intersection by studying the discussion around the united nations conference of the parties on climate change (cop) using twitter data from 2014 to 2021. first, we reveal a large increase in ideological polarization during cop26, following low polarization between cop20 and cop25. second, we show that this increase is driven by growing right-wing activity, a fourfold increase since cop21 relative to pro-climate groups. finally, we identify a broad range of ‘climate contrarian’ views during cop26, emphasizing the theme of political hypocrisy as a topic of cross-ideological appeal; contrarian views and accusations of hypocrisy have become key themes in the twitter climate discussion since 2019. with future climate action reliant on negotiations at cop27 and beyond, our results highlight the importance of monitoring polarization and its impacts in the public climate discourse. polarization and the resulting political deadlock have become key barriers to more ambitious climate action. using twitter data between conferences of the parties, this research identifies a trend of increasing polarization driven by growing right-wing activity alongside accusations of political hypocrisy.",https://www.nature.com/articles/s41558-022-01527-x.pdf
947eed49886780415ff71c823430bbe679391b0f,THE WCRP CMIP3 Multimodel Dataset: A New Era in Climate Change Research,"A coordinated set of global coupled climate model [atmosphere–ocean general circulation model (AOGCM)] experiments for twentieth- and twenty-first-century climate, as well as several climate change commitment and other experiments, was run by 16 modeling groups from 11 countries with 23 models for assessment in the Intergovernmental Panel on Climate Change (IPCC) Fourth Assessment Report (AR4). Since the assessment was completed, output from another model has been added to the dataset, so the participation is now 17 groups from 12 countries with 24 models. This effort, as well as the subsequent analysis phase, was organized by the World Climate Research Programme (WCRP) Climate Variability and Predictability (CLIVAR) Working Group on Coupled Models (WGCM) Climate Simulation Panel, and constitutes the third phase of the Coupled Model Intercomparison Project (CMIP3). The dataset is called the WCRP CMIP3 multimodel dataset, and represents the largest and most comprehensive international global coupled climate model experiment and multimodel analysis effort ever attempted. As of March 2007, the Program for Climate Model Diagnostics and Intercomparison (PCMDI) has collected, archived, and served roughly 32 TB of model data. With oversight from the panel, the multimodel data were made openly available from PCMDI for analysis and academic applications. Over 171 TB of data had been downloaded among the more than 1000 registered users to date. Over 200 journal articles, based in part on the dataset, have been published so far. Though initially aimed at the IPCC AR4, this unique and valuable resource will continue to be maintained for at least the next several years. Never before has such an extensive set of climate model simulations been made available to the international climate science community for study. The ready access to the multimodel dataset opens up these types of model analyses to researchers, including students, who previously could not obtain state-of-the-art climate model output, and thus represents a new era in climate change research. As a direct consequence, these ongoing studies are increasing the body of knowledge regarding our understanding of how the climate system currently works, and how it may change in the future.",2007,"[{'authorId': '3221562', 'name': 'G. Meehl'}, {'authorId': '7786618', 'name': 'C. Covey'}, {'authorId': '4953183', 'name': 'T. Delworth'}, {'authorId': '145933242', 'name': 'M. Latif'}, {'authorId': '101910817', 'name': 'B. Mcavaney'}, {'authorId': '144964145', 'name': 'J. Mitchell'}, {'authorId': '3711975', 'name': 'R. Stouffer'}, {'authorId': '2490339', 'name': 'K. Taylor'}]","{'url': 'https://journals.ametsoc.org/downloadpdf/journals/bams/88/9/bams-88-9-1383.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1175/BAMS-88-9-1383?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1175/BAMS-88-9-1383, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a coordinated set of global coupled climate model [atmosphere–ocean general circulation model (aogcm)] experiments for twentieth- and twenty-first-century climate, as well as several climate change commitment and other experiments, was run by 16 modeling groups from 11 countries with 23 models for assessment in the intergovernmental panel on climate change (ipcc) fourth assessment report (ar4). since the assessment was completed, output from another model has been added to the dataset, so the participation is now 17 groups from 12 countries with 24 models. this effort, as well as the subsequent analysis phase, was organized by the world climate research programme (wcrp) climate variability and predictability (clivar) working group on coupled models (wgcm) climate simulation panel, and constitutes the third phase of the coupled model intercomparison project (cmip3). the dataset is called the wcrp cmip3 multimodel dataset, and represents the largest and most comprehensive international global coupled climate model experiment and multimodel analysis effort ever attempted. as of march 2007, the program for climate model diagnostics and intercomparison (pcmdi) has collected, archived, and served roughly 32 tb of model data. with oversight from the panel, the multimodel data were made openly available from pcmdi for analysis and academic applications. over 171 tb of data had been downloaded among the more than 1000 registered users to date. over 200 journal articles, based in part on the dataset, have been published so far. though initially aimed at the ipcc ar4, this unique and valuable resource will continue to be maintained for at least the next several years. never before has such an extensive set of climate model simulations been made available to the international climate science community for study. the ready access to the multimodel dataset opens up these types of model analyses to researchers, including students, who previously could not obtain state-of-the-art climate model output, and thus represents a new era in climate change research. as a direct consequence, these ongoing studies are increasing the body of knowledge regarding our understanding of how the climate system currently works, and how it may change in the future.",https://journals.ametsoc.org/downloadpdf/journals/bams/88/9/bams-88-9-1383.pdf
ca362cbf9e0b02a000720db28cddd3abc6b24bb2,Global water resources: vulnerability from climate change and population growth.,"The future adequacy of freshwater resources is difficult to assess, owing to a complex and rapidly changing geography of water supply and use. Numerical experiments combining climate model outputs, water budgets, and socioeconomic information along digitized river networks demonstrate that (i) a large proportion of the world's population is currently experiencing water stress and (ii) rising water demands greatly outweigh greenhouse warming in defining the state of global water systems to 2025. Consideration of direct human impacts on global water supply remains a poorly articulated but potentially important facet of the larger global change question.",2000,"[{'authorId': '4055812', 'name': 'C. Vörösmarty'}, {'authorId': '2057029243', 'name': 'P. Green'}, {'authorId': '107875760', 'name': 'J. Salisbury'}, {'authorId': '50397428', 'name': 'R. Lammers'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1126/SCIENCE.289.5477.284?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/SCIENCE.289.5477.284, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the future adequacy of freshwater resources is difficult to assess, owing to a complex and rapidly changing geography of water supply and use. numerical experiments combining climate model outputs, water budgets, and socioeconomic information along digitized river networks demonstrate that (i) a large proportion of the world's population is currently experiencing water stress and (ii) rising water demands greatly outweigh greenhouse warming in defining the state of global water systems to 2025. consideration of direct human impacts on global water supply remains a poorly articulated but potentially important facet of the larger global change question.",
344f12e4bb0047855dc23bdb70bb9a3a26371c4b,A systematic review of climate change education: giving children and young people a ‘voice’ and a ‘hand’ in redressing climate change,"ABSTRACT The reality of anthropogenic climate change has been established ‘beyond reasonable doubt’ by leading scientists worldwide. Applying a systematic literature review process, we analysed existing literature from 1993 to 2014 regarding climate change education for children and young people, with the aim of identifying key areas for further research. While a number of studies have indicated that young people’s understandings of climate change are generally limited, erroneous and highly influenced by mass media, other studies suggest that didactic approaches to climate change education have been largely ineffectual in affecting students’ attitudes and behaviour. The review identifies the need for participatory, interdisciplinary, creative, and affect-driven approaches to climate change education, which to date have been largely missing from the literature. In conclusion, we call for the development of new forms of climate change education that directly involve young people in responding to the scientific, social, ethical, and political complexities of climate change.",2020,"[{'authorId': '103910564', 'name': 'David Rousell'}, {'authorId': '1412785280', 'name': 'Amy Cutter-Mackenzie-Knowles'}]","{'url': 'https://e-space.mmu.ac.uk/623566/3/Final_Version_Lit_Reviewaccepted.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/14733285.2019.1614532?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/14733285.2019.1614532, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the reality of anthropogenic climate change has been established ‘beyond reasonable doubt’ by leading scientists worldwide. applying a systematic literature review process, we analysed existing literature from 1993 to 2014 regarding climate change education for children and young people, with the aim of identifying key areas for further research. while a number of studies have indicated that young people’s understandings of climate change are generally limited, erroneous and highly influenced by mass media, other studies suggest that didactic approaches to climate change education have been largely ineffectual in affecting students’ attitudes and behaviour. the review identifies the need for participatory, interdisciplinary, creative, and affect-driven approaches to climate change education, which to date have been largely missing from the literature. in conclusion, we call for the development of new forms of climate change education that directly involve young people in responding to the scientific, social, ethical, and political complexities of climate change.",https://e-space.mmu.ac.uk/623566/3/Final_Version_Lit_Reviewaccepted.pdf
403803176eb90515d06a06165677300296d75dd8,Climate change : the IPCC scientific assessment,Book review of the intergovernmental panel on climate change report on global warming and the greenhouse effect. Covers the scientific basis for knowledge of the future climate. Presents chemistry of greenhouse gases and mathematical modelling of the climate system. The book is primarily for government policy makers.,1990,"[{'authorId': '82502978', 'name': 'J. Houghton'}, {'authorId': '105008979', 'name': 'G. Jenkins'}, {'authorId': '103308755', 'name': 'J. J. Ephraums'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5860/choice.29-3325?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5860/choice.29-3325, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",climate change : the ipcc scientific assessment,
2500e5d38d94303ca22d4b7234d17dca111e84de,Insects and recent climate change,"Insects have diversified through more than 450 million y of Earth’s changeable climate, yet rapidly shifting patterns of temperature and precipitation now pose novel challenges as they combine with decades of other anthropogenic stressors including the conversion and degradation of land. Here, we consider how insects are responding to recent climate change while summarizing the literature on long-term monitoring of insect populations in the context of climatic fluctuations. Results to date suggest that climate change impacts on insects have the potential to be considerable, even when compared with changes in land use. The importance of climate is illustrated with a case study from the butterflies of Northern California, where we find that population declines have been severe in high-elevation areas removed from the most immediate effects of habitat loss. These results shed light on the complexity of montane-adapted insects responding to changing abiotic conditions. We also consider methodological issues that would improve syntheses of results across long-term insect datasets and highlight directions for future empirical work.",2020,"[{'authorId': '1396516107', 'name': 'C. A. Halsch'}, {'authorId': '32943792', 'name': 'A. Shapiro'}, {'authorId': '6617624', 'name': 'J. Fordyce'}, {'authorId': '3718778', 'name': 'C. Nice'}, {'authorId': '36154603', 'name': 'J. Thorne'}, {'authorId': '8053741', 'name': 'D. Waetjen'}, {'authorId': '5423525', 'name': 'M. Forister'}]","{'url': 'https://www.pnas.org/content/pnas/118/2/e2002543117.full.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1101/2020.03.09.984328?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1101/2020.03.09.984328, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","insects have diversified through more than 450 million y of earth’s changeable climate, yet rapidly shifting patterns of temperature and precipitation now pose novel challenges as they combine with decades of other anthropogenic stressors including the conversion and degradation of land. here, we consider how insects are responding to recent climate change while summarizing the literature on long-term monitoring of insect populations in the context of climatic fluctuations. results to date suggest that climate change impacts on insects have the potential to be considerable, even when compared with changes in land use. the importance of climate is illustrated with a case study from the butterflies of northern california, where we find that population declines have been severe in high-elevation areas removed from the most immediate effects of habitat loss. these results shed light on the complexity of montane-adapted insects responding to changing abiotic conditions. we also consider methodological issues that would improve syntheses of results across long-term insect datasets and highlight directions for future empirical work.",https://www.pnas.org/content/pnas/118/2/e2002543117.full.pdf
3d7393fa004487a46eed19543533f9faf094836d,The Community Earth System Model (CESM) large ensemble project: a community resource for studying climate change in the presence of internal climate variability,"AbstractWhile internal climate variability is known to affect climate projections, its influence is often underappreciated and confused with model error. Why? In general, modeling centers contribute a small number of realizations to international climate model assessments [e.g., phase 5 of the Coupled Model Intercomparison Project (CMIP5)]. As a result, model error and internal climate variability are difficult, and at times impossible, to disentangle. In response, the Community Earth System Model (CESM) community designed the CESM Large Ensemble (CESM-LE) with the explicit goal of enabling assessment of climate change in the presence of internal climate variability. All CESM-LE simulations use a single CMIP5 model (CESM with the Community Atmosphere Model, version 5). The core simulations replay the twenty to twenty-first century (1920–2100) 30 times under historical and representative concentration pathway 8.5 external forcing with small initial condition differences. Two companion 1000+-yr-long preindu...",2015,"[{'authorId': None, 'name': 'a.'}, {'authorId': '2171321973', 'name': 'Phillips'}, {'authorId': None, 'name': 'G.'}, {'authorId': '2168026341', 'name': 'Danabasoglu'}, {'authorId': None, 'name': 'P.'}, {'authorId': '2240610653', 'name': 'KushnEr'}, {'authorId': None, 'name': 'K.'}, {'authorId': '2240619634', 'name': 'linDsay'}, {'authorId': None, 'name': 'E.'}, {'authorId': '2240620692', 'name': 'Munoz'}, {'authorId': None, 'name': 'l.'}, {'authorId': '2240586205', 'name': 'Polvani'}]","{'url': 'https://journals.ametsoc.org/downloadpdf/journals/bams/96/8/bams-d-13-00255.1.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1175/BAMS-D-13-00255.1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1175/BAMS-D-13-00255.1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstractwhile internal climate variability is known to affect climate projections, its influence is often underappreciated and confused with model error. why? in general, modeling centers contribute a small number of realizations to international climate model assessments [e.g., phase 5 of the coupled model intercomparison project (cmip5)]. as a result, model error and internal climate variability are difficult, and at times impossible, to disentangle. in response, the community earth system model (cesm) community designed the cesm large ensemble (cesm-le) with the explicit goal of enabling assessment of climate change in the presence of internal climate variability. all cesm-le simulations use a single cmip5 model (cesm with the community atmosphere model, version 5). the core simulations replay the twenty to twenty-first century (1920–2100) 30 times under historical and representative concentration pathway 8.5 external forcing with small initial condition differences. two companion 1000+-yr-long preindu...",https://journals.ametsoc.org/downloadpdf/journals/bams/96/8/bams-d-13-00255.1.pdf
81ceb04803f4f4406ba7e9218e4a9f71fe8a3725,The Intergovernmental Panel on Climate Change (IPCC),"Recognizing the problem of a potential global climate change, the World Meteorological Organization ( WMO) and the United Nations Environment Programme ( UNEP) established the Intergovernmental Panel on Climate Change, IPCC, in 1988. The role of the IPCC is to assess the scientific, technical and socio-economic information relevant for the understanding of the risk of human-induced change. It does not carry out research nor does it monitor climate-related data or other relevant parameters. It bases its assessment mainly on peer-reviewed and published scientific and technical literature. The IPCC has three Working Groups and a Task Force: ♦ Working Group I assesses the scientific aspects of the climate system and climate change. ♦ Working Group II addresses the vulnerability of socio-economic and natural systems to climate change, the negative and positive consequences of climate change, and options for adapting to it. ♦ Working Group III assesses options for limiting greenhouse-gas emissions and otherwise mitigating climate change. ♦ The Task Force on National Greenhouse Gas Inventories is responsible for the IPCC National Greenhouse Gas Inventories Programme. The IPCC completed its First Assessment Report in 1990. The Report played an important role in the establishing of the Intergovernmental Negotiating Committee for a UN Framework Convention on Climate Change by the UN General Assembly. The Convention was adopted in Rio de Janeiro in 1992. The Second Assessment Report, Climate Change 1995, provided key input to the negotiations that led to the adoption of the Kyoto Protocol in 1997. The Third Assessment Report ( TAR) was adopted in September 2001. Some 2000 scientists representing a variety of disciplines the world over took part in this assessment, and the results were further reviewed both from the political and scientific aspect by representatives of the participating countries. This is the most all-embracing assessment of research that has ever been made. A Fourth Assessment Report is scheduled to be ready by 2007. The IPCC also prepares Special Reports and Technical Papers on topics where independent scientific information and advice is deemed necessary (see Publications, p.14). It also supports the climate convention through its work on methodologies for National Greenhouse Gas Inventories. The Intergovernmental Panel on Climate Change, IPCC",2015,"[{'authorId': '115290199', 'name': 'D. P. Stone'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1017/CBO9781316146705.014?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/CBO9781316146705.014, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recognizing the problem of a potential global climate change, the world meteorological organization ( wmo) and the united nations environment programme ( unep) established the intergovernmental panel on climate change, ipcc, in 1988. the role of the ipcc is to assess the scientific, technical and socio-economic information relevant for the understanding of the risk of human-induced change. it does not carry out research nor does it monitor climate-related data or other relevant parameters. it bases its assessment mainly on peer-reviewed and published scientific and technical literature. the ipcc has three working groups and a task force: ♦ working group i assesses the scientific aspects of the climate system and climate change. ♦ working group ii addresses the vulnerability of socio-economic and natural systems to climate change, the negative and positive consequences of climate change, and options for adapting to it. ♦ working group iii assesses options for limiting greenhouse-gas emissions and otherwise mitigating climate change. ♦ the task force on national greenhouse gas inventories is responsible for the ipcc national greenhouse gas inventories programme. the ipcc completed its first assessment report in 1990. the report played an important role in the establishing of the intergovernmental negotiating committee for a un framework convention on climate change by the un general assembly. the convention was adopted in rio de janeiro in 1992. the second assessment report, climate change 1995, provided key input to the negotiations that led to the adoption of the kyoto protocol in 1997. the third assessment report ( tar) was adopted in september 2001. some 2000 scientists representing a variety of disciplines the world over took part in this assessment, and the results were further reviewed both from the political and scientific aspect by representatives of the participating countries. this is the most all-embracing assessment of research that has ever been made. a fourth assessment report is scheduled to be ready by 2007. the ipcc also prepares special reports and technical papers on topics where independent scientific information and advice is deemed necessary (see publications, p.14). it also supports the climate convention through its work on methodologies for national greenhouse gas inventories. the intergovernmental panel on climate change, ipcc",
85f4d04076aefafe60a8ead0435b34bf7d8fbfdd,Online misinformation about climate change,"Policymakers, scholars, and practitioners have all called attention to the issue of misinformation in the climate change debate. But what is climate change misinformation, who is involved, how does it spread, why does it matter, and what can be done about it? Climate change misinformation is closely linked to climate change skepticism, denial, and contrarianism. A network of actors are involved in financing, producing, and amplifying misinformation. Once in the public domain, characteristics of online social networks, such as homophily, polarization, and echo chambers—characteristics also found in climate change debate—provide fertile ground for misinformation to spread. Underlying belief systems and social norms, as well as psychological heuristics such as confirmation bias, are further factors which contribute to the spread of misinformation. A variety of ways to understand and address misinformation, from a diversity of disciplines, are discussed. These include educational, technological, regulatory, and psychological‐based approaches. No single approach addresses all concerns about misinformation, and all have limitations, necessitating an interdisciplinary approach to tackle this multifaceted issue. Key research gaps include understanding the diffusion of climate change misinformation on social media, and examining whether misinformation extends to climate alarmism, as well as climate denial. This article explores the concepts of misinformation and disinformation and defines disinformation to be a subset of misinformation. A diversity of disciplinary and interdisciplinary literature is reviewed to fully interrogate the concept of misinformation—and within this, disinformation—particularly as it pertains to climate change.",2020,"[{'authorId': '2006380376', 'name': 'K. Treen'}, {'authorId': '144991676', 'name': 'Hywel T. P. Williams'}, {'authorId': '1404141296', 'name': ""S. O'Neill""}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wcc.665', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/wcc.665?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/wcc.665, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","policymakers, scholars, and practitioners have all called attention to the issue of misinformation in the climate change debate. but what is climate change misinformation, who is involved, how does it spread, why does it matter, and what can be done about it? climate change misinformation is closely linked to climate change skepticism, denial, and contrarianism. a network of actors are involved in financing, producing, and amplifying misinformation. once in the public domain, characteristics of online social networks, such as homophily, polarization, and echo chambers—characteristics also found in climate change debate—provide fertile ground for misinformation to spread. underlying belief systems and social norms, as well as psychological heuristics such as confirmation bias, are further factors which contribute to the spread of misinformation. a variety of ways to understand and address misinformation, from a diversity of disciplines, are discussed. these include educational, technological, regulatory, and psychological‐based approaches. no single approach addresses all concerns about misinformation, and all have limitations, necessitating an interdisciplinary approach to tackle this multifaceted issue. key research gaps include understanding the diffusion of climate change misinformation on social media, and examining whether misinformation extends to climate alarmism, as well as climate denial. this article explores the concepts of misinformation and disinformation and defines disinformation to be a subset of misinformation. a diversity of disciplinary and interdisciplinary literature is reviewed to fully interrogate the concept of misinformation—and within this, disinformation—particularly as it pertains to climate change.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wcc.665
66b9d15921b998e21d6b69f15bf39388f8e9f490,"Climate change vulnerability, water resources and social implications in North Africa","North Africa is considered a climate change hot spot. Existing studies either focus on the physical aspects of climate change or discuss the social ones. The present article aims to address this divide by assessing and comparing the climate change vulnerability of Algeria, Egypt, Libya, Morocco, and Tunisia and linking it to its social implications. The vulnerability assessment focuses on climate change exposure, water resources, sensitivity, and adaptive capacity. The results suggest that all countries are exposed to strong temperature increases and a high drought risk under climate change. Algeria is most vulnerable to climate change, mainly due to the country’s high sensitivity. Across North Africa, the combination of climate change and strong population growth is very likely to further aggravate the already scarce water situation. The so-called Arab Spring has shown that social unrest is partly caused by unmet basic needs of the population for food and water. Thus, climate change may become an indirect driver of social instability in North Africa. To mitigate the impact of climate change, it is important to reduce economic and livelihood dependence on rain-fed agriculture, strengthen sustainable land use practices, and increase the adaptive capacity. Further, increased regional cooperation and sub-national vulnerability assessments are needed.",2020,"[{'authorId': '37304890', 'name': 'J. Schilling'}, {'authorId': '66726429', 'name': 'E. Hertig'}, {'authorId': '11765071', 'name': 'Y. Tramblay'}, {'authorId': '3054680', 'name': 'J. Scheffran'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s10113-020-01597-7.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10113-020-01597-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10113-020-01597-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","north africa is considered a climate change hot spot. existing studies either focus on the physical aspects of climate change or discuss the social ones. the present article aims to address this divide by assessing and comparing the climate change vulnerability of algeria, egypt, libya, morocco, and tunisia and linking it to its social implications. the vulnerability assessment focuses on climate change exposure, water resources, sensitivity, and adaptive capacity. the results suggest that all countries are exposed to strong temperature increases and a high drought risk under climate change. algeria is most vulnerable to climate change, mainly due to the country’s high sensitivity. across north africa, the combination of climate change and strong population growth is very likely to further aggravate the already scarce water situation. the so-called arab spring has shown that social unrest is partly caused by unmet basic needs of the population for food and water. thus, climate change may become an indirect driver of social instability in north africa. to mitigate the impact of climate change, it is important to reduce economic and livelihood dependence on rain-fed agriculture, strengthen sustainable land use practices, and increase the adaptive capacity. further, increased regional cooperation and sub-national vulnerability assessments are needed.",https://link.springer.com/content/pdf/10.1007/s10113-020-01597-7.pdf
755644b5d2676783f736346b1c55b71c546115a0,Climate-change–driven accelerated sea-level rise detected in the altimeter era,"Significance Satellite altimetry has shown that global mean sea level has been rising at a rate of ∼3 ± 0.4 mm/y since 1993. Using the altimeter record coupled with careful consideration of interannual and decadal variability as well as potential instrument errors, we show that this rate is accelerating at 0.084 ± 0.025 mm/y2, which agrees well with climate model projections. If sea level continues to change at this rate and acceleration, sea-level rise by 2100 (∼65 cm) will be more than double the amount if the rate was constant at 3 mm/y. Using a 25-y time series of precision satellite altimeter data from TOPEX/Poseidon, Jason-1, Jason-2, and Jason-3, we estimate the climate-change–driven acceleration of global mean sea level over the last 25 y to be 0.084 ± 0.025 mm/y2. Coupled with the average climate-change–driven rate of sea level rise over these same 25 y of 2.9 mm/y, simple extrapolation of the quadratic implies global mean sea level could rise 65 ± 12 cm by 2100 compared with 2005, roughly in agreement with the Intergovernmental Panel on Climate Change (IPCC) 5th Assessment Report (AR5) model projections.",2018,"[{'authorId': '25428694', 'name': 'R. Nerem'}, {'authorId': '46435785', 'name': 'B. Beckley'}, {'authorId': '3718910', 'name': 'J. Fasullo'}, {'authorId': '2584020', 'name': 'B. Hamlington'}, {'authorId': '144019713', 'name': 'D. Masters'}, {'authorId': '38547012', 'name': 'G. Mitchum'}]","{'url': 'https://www.pnas.org/content/pnas/115/9/2022.full.pdf', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5834701, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","significance satellite altimetry has shown that global mean sea level has been rising at a rate of ∼3 ± 0.4 mm/y since 1993. using the altimeter record coupled with careful consideration of interannual and decadal variability as well as potential instrument errors, we show that this rate is accelerating at 0.084 ± 0.025 mm/y2, which agrees well with climate model projections. if sea level continues to change at this rate and acceleration, sea-level rise by 2100 (∼65 cm) will be more than double the amount if the rate was constant at 3 mm/y. using a 25-y time series of precision satellite altimeter data from topex/poseidon, jason-1, jason-2, and jason-3, we estimate the climate-change–driven acceleration of global mean sea level over the last 25 y to be 0.084 ± 0.025 mm/y2. coupled with the average climate-change–driven rate of sea level rise over these same 25 y of 2.9 mm/y, simple extrapolation of the quadratic implies global mean sea level could rise 65 ± 12 cm by 2100 compared with 2005, roughly in agreement with the intergovernmental panel on climate change (ipcc) 5th assessment report (ar5) model projections.",https://www.pnas.org/content/pnas/115/9/2022.full.pdf
2248987a623f11fd2269233a6084110d9dff68e7,Impact of Climate Change on Crops Adaptation and Strategies to Tackle Its Outcome: A Review,"Agriculture and climate change are internally correlated with each other in various aspects, as climate change is the main cause of biotic and abiotic stresses, which have adverse effects on the agriculture of a region. The land and its agriculture are being affected by climate changes in different ways, e.g., variations in annual rainfall, average temperature, heat waves, modifications in weeds, pests or microbes, global change of atmospheric CO2 or ozone level, and fluctuations in sea level. The threat of varying global climate has greatly driven the attention of scientists, as these variations are imparting negative impact on global crop production and compromising food security worldwide. According to some predicted reports, agriculture is considered the most endangered activity adversely affected by climate changes. To date, food security and ecosystem resilience are the most concerning subjects worldwide. Climate-smart agriculture is the only way to lower the negative impact of climate variations on crop adaptation, before it might affect global crop production drastically. In this review paper, we summarize the causes of climate change, stresses produced due to climate change, impacts on crops, modern breeding technologies, and biotechnological strategies to cope with climate change, in order to develop climate resilient crops. Revolutions in genetic engineering techniques can also aid in overcoming food security issues against extreme environmental conditions, by producing transgenic plants.",2019,"[{'authorId': '48860813', 'name': 'A. Raza'}, {'authorId': '20456575', 'name': 'A. Razzaq'}, {'authorId': '68977276', 'name': 'S. Mehmood'}, {'authorId': '4853629', 'name': 'Xiling Zou'}, {'authorId': '1890764', 'name': 'Xuekun Zhang'}, {'authorId': '51244235', 'name': 'Y. Lv'}, {'authorId': '47882724', 'name': 'Jinsong Xu'}]","{'url': 'https://www.mdpi.com/2223-7747/8/2/34/pdf?version=1548840989', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6409995, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","agriculture and climate change are internally correlated with each other in various aspects, as climate change is the main cause of biotic and abiotic stresses, which have adverse effects on the agriculture of a region. the land and its agriculture are being affected by climate changes in different ways, e.g., variations in annual rainfall, average temperature, heat waves, modifications in weeds, pests or microbes, global change of atmospheric co2 or ozone level, and fluctuations in sea level. the threat of varying global climate has greatly driven the attention of scientists, as these variations are imparting negative impact on global crop production and compromising food security worldwide. according to some predicted reports, agriculture is considered the most endangered activity adversely affected by climate changes. to date, food security and ecosystem resilience are the most concerning subjects worldwide. climate-smart agriculture is the only way to lower the negative impact of climate variations on crop adaptation, before it might affect global crop production drastically. in this review paper, we summarize the causes of climate change, stresses produced due to climate change, impacts on crops, modern breeding technologies, and biotechnological strategies to cope with climate change, in order to develop climate resilient crops. revolutions in genetic engineering techniques can also aid in overcoming food security issues against extreme environmental conditions, by producing transgenic plants.",https://www.mdpi.com/2223-7747/8/2/34/pdf?version=1548840989
6a8b56f8858e17f26f6eafc76b1f0c76c13b9cc6,Hedging Climate Change News,"
 We propose and implement a procedure to dynamically hedge climate change risk. We extract innovations from climate news series that we construct through textual analysis of newspapers. We then use a mimicking portfolio approach to build climate change hedge portfolios. We discipline the exercise by using third-party ESG scores of firms to model their climate risk exposures. We show that this approach yields parsimonious and industry-balanced portfolios that perform well in hedging innovations in climate news both in sample and out of sample. We discuss multiple directions for future research on financial approaches to managing climate risk.",2019,"[{'authorId': '35535410', 'name': 'R. Engle'}, {'authorId': '69847461', 'name': 'Stefano Giglio'}, {'authorId': '152467398', 'name': 'B. Kelly'}, {'authorId': '95743321', 'name': 'Heebum Lee'}, {'authorId': '51486091', 'name': 'J. Stroebel'}]","{'url': 'http://www.nber.org/papers/w25734.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3317570?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3317570, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",we propose and implement a procedure to dynamically hedge climate change risk. we extract innovations from climate news series that we construct through textual analysis of newspapers. we then use a mimicking portfolio approach to build climate change hedge portfolios. we discipline the exercise by using third-party esg scores of firms to model their climate risk exposures. we show that this approach yields parsimonious and industry-balanced portfolios that perform well in hedging innovations in climate news both in sample and out of sample. we discuss multiple directions for future research on financial approaches to managing climate risk.,http://www.nber.org/papers/w25734.pdf
458e9616f6d0c4ac264d15c7ae256728d5f5022c,The human imperative of stabilizing global climate change at 1.5°C,"The need to stabilize global climate Climate change will be the greatest threat to humanity and global ecosystems in the coming years, and there is a pressing need to understand and communicate the impacts of warming, across the perspectives of the natural and social sciences. Hoegh-Guldberg et al. review the climate change–impact literature, expanding on the recent report of the Intergovernmental Panel on Climate Change. They provide evidence of the impacts of warming at 1°, 1.5°, and 2°C—and higher—for the physical system, ecosystems, agriculture, and human livelihoods. The benefits of limiting climate change to no more than 1.5°C above preindustrial levels would outweigh the costs. Science, this issue p. eaaw6974 BACKGROUND The United Nations Framework Convention on Climate Change (UNFCCC) was established in 1992 to pursue the “stabilization of greenhouse gas concentrations at a level that would prevent dangerous anthropogenic interferences with the climate system.” Since 1992, five major climate change assessment cycles have been completed by the UN Intergovernmental Panel on Climate Change (IPCC). These reports identified rapidly growing climate-related impacts and risks, including more intense storms, collapsing ecosystems, and record heatwaves, among many others. Once thought to be tolerable, increases in global mean surface temperature (GMST) of 2.0°C or higher than the pre-industrial period look increasingly unmanageable and hence dangerous to natural and human systems. The Paris Climate Agreement is the most recent attempt to establish international cooperation over climate change. This agreement, ratified or acceded to by 185 countries, was designed to bring nations together voluntarily to take ambitious action on mitigating climate change, while also developing adaptation options and strategies as well as guaranteeing the means of implementation (e.g., climate finance). The Agreement is aimed at “holding the increase in the global average temperature to well below 2.0°C above pre-industrial levels and pursuing efforts to limit the temperature increase to 1.5°C above pre-industrial levels, recognizing that this would significantly reduce the risks and impacts of climate change.” Many unanswered questions regarding a 1.5°C target surround the feasibility, costs, and inherent risks to natural and human systems. Consequently, countries invited the IPCC to prepare a Special Report on “the impacts of global warming of 1.5°C above pre-industrial levels and related global greenhouse gas emission pathways, in the context of strengthening the global response to the threat of climate change, sustainable development, and efforts to eradicate poverty.” The Special Report was completed and approved by the 48th Session of the IPCC in October 2018. ADVANCES Multiple lines of evidence indicate that the next 0.5°C above today (which will take GMST from 1.0°C to 1.5°C above the pre-industrial period) will involve greater risks per unit temperature than those seen in the last 0.5°C increase. This principle of “accelerating risk” is also likely to drive proportionally and possibly exponentially higher risk levels in the transition from 1.5°C to 2.0°C above the pre-industrial period. We argue that this is a consequence of impacts accelerating as a function of distance from the optimal temperature for an organism or an ecosystem process. Coral reefs, for example, often appear healthy right up until the onset of mass coral bleaching and mortality, which can then destroy a reef within a few months. This also explains the observation of “tipping points” where the condition of a group of organisms or an ecosystem can appear “healthy” right up to the point of collapse, suggesting caution in extrapolating from measures of ecosystem condition to predict the future. Information of this nature needs to be combined with an appreciation of organisms’ distance from their optimal temperature. Finally, we explore elements of the costs and benefits associated with acting in response to climate change, and come to the preliminary conclusion that restraining average global temperature to 1.5°C above the pre-industrial period would be much less costly than the damage due to inaction on global climate change. OUTLOOK As an IPCC expert group, we were asked to assess the impact of recent climate change (1.0°C, 2017) and the likely impact over the next 0.5° to 1.0°C of additional global warming. At the beginning of this exercise, many of us were concerned that the task would be hindered by a lack of expert literature available for 1.5°C and 2.0°C warmer worlds. Although this was the case at the time of the Paris Agreement, it has not been our experience 4 years later. With an accelerating amount of peer-reviewed scientific literature since the IPCC Special Report Global Warming of 1.5°C, it is very clear that there is an even more compelling case for deepening commitment and actions for stabilizing GMST at 1.5°C above the pre-industrial period. Climate change and nonlinear responses. (A) Reef-building corals can bleach, losing (B) dinoflagellate symbionts (~10 mm across) and dying, thus exhibiting (C) a nonlinear response to impacts/risks from climate change. H (high) and VH (very high) are the confidence for transition from one impact/risk level to another: white, no climate change–related impacts; yellow, some detectable climate change impacts/risks; red, severe and widespread impacts/risks; purple, very high impacts/risks with significant irreversibility or persistence. CREDITS: [(A) AND (B)] O. HOEGH-GULDBERG; (C) THE IPCC SPECIAL REPORT GLOBAL WARMING OF 1.5°C, WITH PERMISSION FROM IPCC Increased concentrations of atmospheric greenhouse gases have led to a global mean surface temperature 1.0°C higher than during the pre-industrial period. We expand on the recent IPCC Special Report on global warming of 1.5°C and review the additional risks associated with higher levels of warming, each having major implications for multiple geographies, climates, and ecosystems. Limiting warming to 1.5°C rather than 2.0°C would be required to maintain substantial proportions of ecosystems and would have clear benefits for human health and economies. These conclusions are relevant for people everywhere, particularly in low- and middle-income countries, where the escalation of climate-related risks may prevent the achievement of the United Nations Sustainable Development Goals.",2019,"[{'authorId': '1398297041', 'name': 'O. Hoegh‐Guldberg'}, {'authorId': '2105792750', 'name': 'D. Jacob'}, {'authorId': '2107227373', 'name': 'M. Taylor'}, {'authorId': '113027629', 'name': 'T. G. Bolaños'}, {'authorId': '50368662', 'name': 'M. Bindi'}, {'authorId': '2006413561', 'name': 'Sally Brown'}, {'authorId': '2006413561', 'name': 'Sally Brown'}, {'authorId': '93091116', 'name': 'I. Camilloni'}, {'authorId': '50783946', 'name': 'A. Diedhiou'}, {'authorId': '97793239', 'name': 'R. Djalante'}, {'authorId': '143932649', 'name': 'K. Ebi'}, {'authorId': '152845973', 'name': 'F. Engelbrecht'}, {'authorId': '77380541', 'name': 'J. Guiot'}, {'authorId': '115201877', 'name': 'Y. Hijioka'}, {'authorId': '103480836', 'name': 'S. Mehrotra'}, {'authorId': '3102518', 'name': 'C. Hope'}, {'authorId': '144205788', 'name': 'A. Payne'}, {'authorId': '1460146170', 'name': 'Hans-Ove Pörtner'}, {'authorId': '5777136', 'name': 'S. Seneviratne'}, {'authorId': '47707870', 'name': 'Adelle Thomas'}, {'authorId': '144224137', 'name': 'R. Warren'}, {'authorId': '2107532376', 'name': 'G. Zhou'}]","{'url': 'https://science.sciencemag.org/content/sci/365/6459/eaaw6974.full.pdf', 'status': 'HYBRID', 'license': 'CCBYSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1126/science.aaw6974?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/science.aaw6974, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the need to stabilize global climate climate change will be the greatest threat to humanity and global ecosystems in the coming years, and there is a pressing need to understand and communicate the impacts of warming, across the perspectives of the natural and social sciences. hoegh-guldberg et al. review the climate change–impact literature, expanding on the recent report of the intergovernmental panel on climate change. they provide evidence of the impacts of warming at 1°, 1.5°, and 2°c—and higher—for the physical system, ecosystems, agriculture, and human livelihoods. the benefits of limiting climate change to no more than 1.5°c above preindustrial levels would outweigh the costs. science, this issue p. eaaw6974 background the united nations framework convention on climate change (unfccc) was established in 1992 to pursue the “stabilization of greenhouse gas concentrations at a level that would prevent dangerous anthropogenic interferences with the climate system.” since 1992, five major climate change assessment cycles have been completed by the un intergovernmental panel on climate change (ipcc). these reports identified rapidly growing climate-related impacts and risks, including more intense storms, collapsing ecosystems, and record heatwaves, among many others. once thought to be tolerable, increases in global mean surface temperature (gmst) of 2.0°c or higher than the pre-industrial period look increasingly unmanageable and hence dangerous to natural and human systems. the paris climate agreement is the most recent attempt to establish international cooperation over climate change. this agreement, ratified or acceded to by 185 countries, was designed to bring nations together voluntarily to take ambitious action on mitigating climate change, while also developing adaptation options and strategies as well as guaranteeing the means of implementation (e.g., climate finance). the agreement is aimed at “holding the increase in the global average temperature to well below 2.0°c above pre-industrial levels and pursuing efforts to limit the temperature increase to 1.5°c above pre-industrial levels, recognizing that this would significantly reduce the risks and impacts of climate change.” many unanswered questions regarding a 1.5°c target surround the feasibility, costs, and inherent risks to natural and human systems. consequently, countries invited the ipcc to prepare a special report on “the impacts of global warming of 1.5°c above pre-industrial levels and related global greenhouse gas emission pathways, in the context of strengthening the global response to the threat of climate change, sustainable development, and efforts to eradicate poverty.” the special report was completed and approved by the 48th session of the ipcc in october 2018. advances multiple lines of evidence indicate that the next 0.5°c above today (which will take gmst from 1.0°c to 1.5°c above the pre-industrial period) will involve greater risks per unit temperature than those seen in the last 0.5°c increase. this principle of “accelerating risk” is also likely to drive proportionally and possibly exponentially higher risk levels in the transition from 1.5°c to 2.0°c above the pre-industrial period. we argue that this is a consequence of impacts accelerating as a function of distance from the optimal temperature for an organism or an ecosystem process. coral reefs, for example, often appear healthy right up until the onset of mass coral bleaching and mortality, which can then destroy a reef within a few months. this also explains the observation of “tipping points” where the condition of a group of organisms or an ecosystem can appear “healthy” right up to the point of collapse, suggesting caution in extrapolating from measures of ecosystem condition to predict the future. information of this nature needs to be combined with an appreciation of organisms’ distance from their optimal temperature. finally, we explore elements of the costs and benefits associated with acting in response to climate change, and come to the preliminary conclusion that restraining average global temperature to 1.5°c above the pre-industrial period would be much less costly than the damage due to inaction on global climate change. outlook as an ipcc expert group, we were asked to assess the impact of recent climate change (1.0°c, 2017) and the likely impact over the next 0.5° to 1.0°c of additional global warming. at the beginning of this exercise, many of us were concerned that the task would be hindered by a lack of expert literature available for 1.5°c and 2.0°c warmer worlds. although this was the case at the time of the paris agreement, it has not been our experience 4 years later. with an accelerating amount of peer-reviewed scientific literature since the ipcc special report global warming of 1.5°c, it is very clear that there is an even more compelling case for deepening commitment and actions for stabilizing gmst at 1.5°c above the pre-industrial period. climate change and nonlinear responses. (a) reef-building corals can bleach, losing (b) dinoflagellate symbionts (~10 mm across) and dying, thus exhibiting (c) a nonlinear response to impacts/risks from climate change. h (high) and vh (very high) are the confidence for transition from one impact/risk level to another: white, no climate change–related impacts; yellow, some detectable climate change impacts/risks; red, severe and widespread impacts/risks; purple, very high impacts/risks with significant irreversibility or persistence. credits: [(a) and (b)] o. hoegh-guldberg; (c) the ipcc special report global warming of 1.5°c, with permission from ipcc increased concentrations of atmospheric greenhouse gases have led to a global mean surface temperature 1.0°c higher than during the pre-industrial period. we expand on the recent ipcc special report on global warming of 1.5°c and review the additional risks associated with higher levels of warming, each having major implications for multiple geographies, climates, and ecosystems. limiting warming to 1.5°c rather than 2.0°c would be required to maintain substantial proportions of ecosystems and would have clear benefits for human health and economies. these conclusions are relevant for people everywhere, particularly in low- and middle-income countries, where the escalation of climate-related risks may prevent the achievement of the united nations sustainable development goals.",https://science.sciencemag.org/content/sci/365/6459/eaaw6974.full.pdf
998039a4876edc440e0cabb0bc42239b0eb29644,Tackling Climate Change with Machine Learning,"Climate change is one of the greatest challenges facing humanity, and we, as machine learning (ML) experts, may wonder how we can help. Here we describe how ML can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ML, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the ML community to join the global effort against climate change.",2019,"[{'authorId': '2346588776', 'name': 'D. Rolnick'}, {'authorId': '49698491', 'name': 'P. Donti'}, {'authorId': '12736608', 'name': 'Lynn H. Kaack'}, {'authorId': '80536011', 'name': 'K. Kochanski'}, {'authorId': '8651990', 'name': 'Alexandre Lacoste'}, {'authorId': '46769963', 'name': 'K. Sankaran'}, {'authorId': '2068943123', 'name': 'A. Ross'}, {'authorId': '1417437895', 'name': 'Nikola Milojevic-Dupont'}, {'authorId': '3106683', 'name': 'Natasha Jaques'}, {'authorId': '1419467725', 'name': 'Anna Waldman-Brown'}, {'authorId': '2993731', 'name': 'A. Luccioni'}, {'authorId': '3422058', 'name': 'Tegan Maharaj'}, {'authorId': '74936246', 'name': 'Evan D. Sherwin'}, {'authorId': '103485736', 'name': 'S. Mukkavilli'}, {'authorId': '3282030', 'name': 'Konrad Paul Kording'}, {'authorId': '2064532325', 'name': 'Carla P. Gomes'}, {'authorId': '2067948334', 'name': 'Andrew Y. Ng'}, {'authorId': '48987704', 'name': 'D. Hassabis'}, {'authorId': '144189092', 'name': 'John C. Platt'}, {'authorId': '47628266', 'name': 'F. Creutzig'}, {'authorId': '1695997', 'name': 'J. Chayes'}, {'authorId': '1751762', 'name': 'Yoshua Bengio'}]","{'url': 'https://dl.acm.org/doi/pdf/10.1145/3485128', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1906.05433, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","climate change is one of the greatest challenges facing humanity, and we, as machine learning (ml) experts, may wonder how we can help. here we describe how ml can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. from smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ml, in collaboration with other fields. our recommendations encompass exciting research questions as well as promising business opportunities. we call on the ml community to join the global effort against climate change.",https://dl.acm.org/doi/pdf/10.1145/3485128
b7a660df1dabbf1073bcc55226a8ad0fda60a123,Climate change has likely already affected global food production,"Crop yields are projected to decrease under future climate conditions, and recent research suggests that yields have already been impacted. However, current impacts on a diversity of crops subnationally and implications for food security remains unclear. Here, we constructed linear regression relationships using weather and reported crop data to assess the potential impact of observed climate change on the yields of the top ten global crops–barley, cassava, maize, oil palm, rapeseed, rice, sorghum, soybean, sugarcane and wheat at ~20,000 political units. We find that the impact of global climate change on yields of different crops from climate trends ranged from -13.4% (oil palm) to 3.5% (soybean). Our results show that impacts are mostly negative in Europe, Southern Africa and Australia but generally positive in Latin America. Impacts in Asia and Northern and Central America are mixed. This has likely led to ~1% average reduction (-3.5 X 1013 kcal/year) in consumable food calories in these ten crops. In nearly half of food insecure countries, estimated caloric availability decreased. Our results suggest that climate change has already affected global food production.",2019,"[{'authorId': '15801785', 'name': 'D. Ray'}, {'authorId': '39577452', 'name': 'P. West'}, {'authorId': '80551826', 'name': 'Michael A. Clark'}, {'authorId': '2105153', 'name': 'J. Gerber'}, {'authorId': '12116038', 'name': 'A. Prishchepov'}, {'authorId': '32054866', 'name': 'Snigdha Chatterjee'}]","{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0217148&type=printable', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6544233, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","crop yields are projected to decrease under future climate conditions, and recent research suggests that yields have already been impacted. however, current impacts on a diversity of crops subnationally and implications for food security remains unclear. here, we constructed linear regression relationships using weather and reported crop data to assess the potential impact of observed climate change on the yields of the top ten global crops–barley, cassava, maize, oil palm, rapeseed, rice, sorghum, soybean, sugarcane and wheat at ~20,000 political units. we find that the impact of global climate change on yields of different crops from climate trends ranged from -13.4% (oil palm) to 3.5% (soybean). our results show that impacts are mostly negative in europe, southern africa and australia but generally positive in latin america. impacts in asia and northern and central america are mixed. this has likely led to ~1% average reduction (-3.5 x 1013 kcal/year) in consumable food calories in these ten crops. in nearly half of food insecure countries, estimated caloric availability decreased. our results suggest that climate change has already affected global food production.",https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0217148&type=printable
88b1b025a26148a50e799cb9bdb7903e13a839c7,Climate change and agriculture in South Asia: adaptation options in smallholder production systems,"Agriculture in South Asia is vulnerable to climate change. Therefore, adaptation measures are required to sustain agricultural productivity, to reduce vulnerability, and to enhance the resilience of the agricultural system to climate change. There are many adaptation practices in the production systems that have been proposed and tested for minimizing the effects of climate change. Some socioeconomic and political setup contributes to adaptation, while others may inhibit it. This paper presents a systematic review of the impacts of climate change on crop production and also the major options in the agricultural sector that are available for adaptation to climate change. One of the key conclusions is that agricultural practices that help climate change adaptation in agriculture are available, while the institutional setup to implement and disseminate those technical solutions is yet to be strengthened. Thus, it is important to examine how to bring the required institutional change, generate fund to invest on these changes, and design dynamic policies for long-term climate change adaptation in agriculture rather than a mere focus on agricultural technology. This is one of the areas where South Asian climate policies require reconsidering to avoid possible maladaptation in the long run.",2019,"[{'authorId': '37751480', 'name': 'J. Aryal'}, {'authorId': '6118957', 'name': 'T. Sapkota'}, {'authorId': '32258082', 'name': 'R. Khurana'}, {'authorId': '1403588495', 'name': 'A. Khatri-Chhetri'}, {'authorId': '9751565', 'name': 'D. Rahut'}, {'authorId': '5636084', 'name': 'M. L. Jat'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s10668-019-00414-4.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10668-019-00414-4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10668-019-00414-4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","agriculture in south asia is vulnerable to climate change. therefore, adaptation measures are required to sustain agricultural productivity, to reduce vulnerability, and to enhance the resilience of the agricultural system to climate change. there are many adaptation practices in the production systems that have been proposed and tested for minimizing the effects of climate change. some socioeconomic and political setup contributes to adaptation, while others may inhibit it. this paper presents a systematic review of the impacts of climate change on crop production and also the major options in the agricultural sector that are available for adaptation to climate change. one of the key conclusions is that agricultural practices that help climate change adaptation in agriculture are available, while the institutional setup to implement and disseminate those technical solutions is yet to be strengthened. thus, it is important to examine how to bring the required institutional change, generate fund to invest on these changes, and design dynamic policies for long-term climate change adaptation in agriculture rather than a mere focus on agricultural technology. this is one of the areas where south asian climate policies require reconsidering to avoid possible maladaptation in the long run.",https://link.springer.com/content/pdf/10.1007/s10668-019-00414-4.pdf
219bdfec8b349a2a709ba429c9d4a083d3f8057a,Urban Climates and Climate Change,"Cities are particularly vulnerable to extreme weather episodes, which are expected to increase with climate change. Cities also influence their own local climate, for example, through the relative ...",2020,"[{'authorId': '32184154', 'name': 'V. Masson'}, {'authorId': '6730422', 'name': 'A. Lemonsu'}, {'authorId': '47254489', 'name': 'J. Hidalgo'}, {'authorId': '38171333', 'name': 'J. Voogt'}]","{'url': 'https://www.annualreviews.org/doi/pdf/10.1146/annurev-environ-012320-083623', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1146/annurev-environ-012320-083623?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/annurev-environ-012320-083623, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",urban climates and climate change,https://www.annualreviews.org/doi/pdf/10.1146/annurev-environ-012320-083623
810bfe714e387596b802bcb6fb3d7deb3d4856a8,"Examining the interconnectedness of green finance: an analysis of dynamic spillover effects among green bonds, renewable energy, and carbon markets","There is growing importance of green finance as a means to finance sustainable projects and reduce carbon emissions. Green bonds have emerged as an important financing tool in this context, and there is a need to understand how they are interconnected with other components of the green finance ecosystem, such as renewable energy and carbon markets. This study investigates the interconnectivity of green finance by analyzing the dynamic spillover effects among green bonds, renewable energy stocks, and carbon markets. Using daily data spanning from January 2010 to December 2020, vector autoregressive models and time-varying parameter models are applied to examine the transmission channels of shocks among these assets. The results reveal significant dynamic spillover effects between green bonds and renewable energy stocks, as well as between carbon markets and renewable energy stocks. Additionally, the findings suggest a complementary relationship between green bonds and carbon markets. This study provides insights into the interdependence of different green financial instruments and their role in promoting sustainable development. The outcomes of the research can guide policymakers, investors, and other stakeholders in making informed decisions regarding green finance.",2023,"[{'authorId': '2145048455', 'name': 'Yafei Zhang'}, {'authorId': '2257111436', 'name': 'Muhammad Umair'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11356-023-27870-w.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10233175, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","there is growing importance of green finance as a means to finance sustainable projects and reduce carbon emissions. green bonds have emerged as an important financing tool in this context, and there is a need to understand how they are interconnected with other components of the green finance ecosystem, such as renewable energy and carbon markets. this study investigates the interconnectivity of green finance by analyzing the dynamic spillover effects among green bonds, renewable energy stocks, and carbon markets. using daily data spanning from january 2010 to december 2020, vector autoregressive models and time-varying parameter models are applied to examine the transmission channels of shocks among these assets. the results reveal significant dynamic spillover effects between green bonds and renewable energy stocks, as well as between carbon markets and renewable energy stocks. additionally, the findings suggest a complementary relationship between green bonds and carbon markets. this study provides insights into the interdependence of different green financial instruments and their role in promoting sustainable development. the outcomes of the research can guide policymakers, investors, and other stakeholders in making informed decisions regarding green finance.",https://link.springer.com/content/pdf/10.1007/s11356-023-27870-w.pdf
11886cb64f00e43a4de8bc98974a6c9244ac8381,A Global Assessment: Can Renewable Energy Replace Fossil Fuels by 2050?,"Our study evaluated the effectiveness of using eight pathways in combination for a complete to transition from fossil fuels to renewable energy by 2050. These pathways included renewable energy development; improving energy efficiency; increasing energy conservation; carbon taxes; more equitable balancing of human wellbeing and per capita energy use; cap and trade systems; carbon capture, utilization, and storage; and nuclear power development. We used the annual ‘British Petroleum statistical review of world energy 2021’ report as our primary database. Globally, fossil fuels, renewable (primarily hydro, wind and solar), nuclear energy accounted for 83%, 12.6%, and 6.3% of the total energy consumption in 2020. To achieve zero fossil fuel use by 2050, we found that renewable energy production will need to be increased by up to 6-fold or 8-fold if energy demand is held constant at, or increased 50% from, the 2020 energy demand level. Constraining 2050 world energy demand to a 25% increase over the 2020 level, improves the probability of achieving independence from fossil fuels. Improvements in energy efficiency need to accelerate beyond the current rate of ~1.5% per year. Aggressive application of energy conservation policies involving land use and taxation could potentially reduce world energy use by 10% or more by 2050. Our meta-analysis shows that the minimum level of per capita energy consumption that would allow 8 billion people to have a ‘Decent Living Standard’ is on average ~70 GJ per capita per year, which is 93% of the 2020 global average. Developed countries in temperate climates with high vehicle-dependency needed ~120 GJ per capita year−1, whereas equatorial countries with low vehicle-dependency needed 30 GJ per capita year−1. Our meta-analyses indicated replacement of fossil fuels with renewable energy by 2050 may be possible but will require aggressive application of all eight pathways, major lifestyle changes in developed countries, and close cooperation among all countries.",2022,"[{'authorId': '14419934', 'name': 'J. Holechek'}, {'authorId': '102622646', 'name': 'H. Geli'}, {'authorId': '88647481', 'name': 'M. Sawalhah'}, {'authorId': '144966541', 'name': 'Raul Valdez'}]","{'url': 'https://www.mdpi.com/2071-1050/14/8/4792/pdf?version=1650101696', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su14084792?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su14084792, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","our study evaluated the effectiveness of using eight pathways in combination for a complete to transition from fossil fuels to renewable energy by 2050. these pathways included renewable energy development; improving energy efficiency; increasing energy conservation; carbon taxes; more equitable balancing of human wellbeing and per capita energy use; cap and trade systems; carbon capture, utilization, and storage; and nuclear power development. we used the annual ‘british petroleum statistical review of world energy 2021’ report as our primary database. globally, fossil fuels, renewable (primarily hydro, wind and solar), nuclear energy accounted for 83%, 12.6%, and 6.3% of the total energy consumption in 2020. to achieve zero fossil fuel use by 2050, we found that renewable energy production will need to be increased by up to 6-fold or 8-fold if energy demand is held constant at, or increased 50% from, the 2020 energy demand level. constraining 2050 world energy demand to a 25% increase over the 2020 level, improves the probability of achieving independence from fossil fuels. improvements in energy efficiency need to accelerate beyond the current rate of ~1.5% per year. aggressive application of energy conservation policies involving land use and taxation could potentially reduce world energy use by 10% or more by 2050. our meta-analysis shows that the minimum level of per capita energy consumption that would allow 8 billion people to have a ‘decent living standard’ is on average ~70 gj per capita per year, which is 93% of the 2020 global average. developed countries in temperate climates with high vehicle-dependency needed ~120 gj per capita year−1, whereas equatorial countries with low vehicle-dependency needed 30 gj per capita year−1. our meta-analyses indicated replacement of fossil fuels with renewable energy by 2050 may be possible but will require aggressive application of all eight pathways, major lifestyle changes in developed countries, and close cooperation among all countries.",https://www.mdpi.com/2071-1050/14/8/4792/pdf?version=1650101696
b6e1184369c724068ac5af5395b1aaca5b1cad9d,"Mitigating Emissions in India: Accounting for the Role of Real Income, Renewable Energy Consumption and Investment in Energy","Accomplishing environmental sustainability has become a global initiative whilst addressing climate change and its effects. Thus, there is a necessity for innovation on part of economies as they seek energy for sustainable development. Thus, we explore the case of India a highly industrialized and heavy emitter of carbon emission. To this end, this study explores the effect of renewable energy, non-renewable, economic growth, and investment in the energy sector on CO2 emission in the Indian economy. Canonical Cointegration Regression (CCR), Fully Modified Least Squares (FMOLS) and Dynamic Least Squares (DOLS) were used to access the long-run elasticity of the variables as well as Granger Causality analysis to detect the direction of causality relationship among the highlighted variables. Empirical regression shows a negative relation between CO2 emission and renewable energy. Thus, suggesting that renewable energy serves as a panacea for sustainable development in the face of economic growth trajectory. However, there was a positive relationship between CO2 emission and both non-renewable and real GDP growth. On the Granger analysis, we observe a one-way causality among renewable energy consumption and CO2 emission, economic development, and energy investment. These outcomes have far-reaching policy direction of environmental sustainability target in Indian economy.",2022,"[{'authorId': '152545590', 'name': 'F. Bekun'}]","{'url': 'https://www.econjournals.com/index.php/ijeep/article/download/12652/6209', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.32479/ijeep.12652?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.32479/ijeep.12652, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","accomplishing environmental sustainability has become a global initiative whilst addressing climate change and its effects. thus, there is a necessity for innovation on part of economies as they seek energy for sustainable development. thus, we explore the case of india a highly industrialized and heavy emitter of carbon emission. to this end, this study explores the effect of renewable energy, non-renewable, economic growth, and investment in the energy sector on co2 emission in the indian economy. canonical cointegration regression (ccr), fully modified least squares (fmols) and dynamic least squares (dols) were used to access the long-run elasticity of the variables as well as granger causality analysis to detect the direction of causality relationship among the highlighted variables. empirical regression shows a negative relation between co2 emission and renewable energy. thus, suggesting that renewable energy serves as a panacea for sustainable development in the face of economic growth trajectory. however, there was a positive relationship between co2 emission and both non-renewable and real gdp growth. on the granger analysis, we observe a one-way causality among renewable energy consumption and co2 emission, economic development, and energy investment. these outcomes have far-reaching policy direction of environmental sustainability target in indian economy.",https://www.econjournals.com/index.php/ijeep/article/download/12652/6209
70949fc9d662a8e3deab106da8c06fca3ccfa0f6,On the History and Future of 100% Renewable Energy Systems Research,"Research on 100% renewable energy systems is a relatively recent phenomenon. It was initiated in the mid-1970s, catalyzed by skyrocketing oil prices. Since the mid-2000s, it has quickly evolved into a prominent research field encompassing an expansive and growing number of research groups and organizations across the world. The main conclusion of most of these studies is that 100% renewables is feasible worldwide at low cost. Advanced concepts and methods now enable the field to chart realistic as well as cost- or resource-optimized and efficient transition pathways to a future without the use of fossil fuels. Such proposed pathways in turn, have helped spur 100% renewable energy policy targets and actions, leading to more research. In most transition pathways, solar energy and wind power increasingly emerge as the central pillars of a sustainable energy system combined with energy efficiency measures. Cost-optimization modeling and greater resource availability tend to lead to higher solar photovoltaic shares, while emphasis on energy supply diversification tends to point to higher wind power contributions. Recent research has focused on the challenges and opportunities regarding grid congestion, energy storage, sector coupling, electrification of transport and industry implying power-to-X and hydrogen-to-X, and the inclusion of natural and technical carbon dioxide removal (CDR) approaches. The result is a holistic vision of the transition towards a net-negative greenhouse gas emissions economy that can limit global warming to 1.5°C with a clearly defined carbon budget in a sustainable and cost-effective manner based on 100% renewable energy-industry-CDR systems. Initially, the field encountered very strong skepticism. Therefore, this paper also includes a response to major critiques against 100% renewable energy systems, and also discusses the institutional inertia that hampers adoption by the International Energy Agency and the Intergovernmental Panel on Climate Change, as well as possible negative connections to community acceptance and energy justice. We conclude by discussing how this emergent research field can further progress to the benefit of society.",2022,"[{'authorId': '9376135', 'name': 'C. Breyer'}, {'authorId': '144408072', 'name': 'S. Khalili'}, {'authorId': '143702213', 'name': 'D. Bogdanov'}, {'authorId': '123799015', 'name': 'M. Ram'}, {'authorId': '79442346', 'name': 'A. S. Oyewo'}, {'authorId': '30637601', 'name': 'A. Aghahosseini'}, {'authorId': '20803211', 'name': 'Ashish Gulagi'}, {'authorId': '52089439', 'name': 'A. A. Solomon'}, {'authorId': '120192121', 'name': 'Dominik Keiner'}, {'authorId': '2165917585', 'name': 'Gabriel Lopez'}, {'authorId': '98768518', 'name': 'P. A. Ostergaard'}, {'authorId': '145384279', 'name': 'H. Lund'}, {'authorId': '74906146', 'name': 'B. Mathiesen'}, {'authorId': '2122915', 'name': 'M. Jacobson'}, {'authorId': '134490318', 'name': 'M. Victoria'}, {'authorId': '47852064', 'name': 'Sven Teske'}, {'authorId': '11278936', 'name': 'T. Pregger'}, {'authorId': '92609935', 'name': 'V. Fthenakis'}, {'authorId': '3288953', 'name': 'M. Raugei'}, {'authorId': '1861743', 'name': 'H. Holttinen'}, {'authorId': '6049741', 'name': 'U. Bardi'}, {'authorId': '51052289', 'name': 'Auke Hoekstra'}, {'authorId': '3291986', 'name': 'Benjamin Sovacool'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837910.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/access.2022.3193402?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/access.2022.3193402, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","research on 100% renewable energy systems is a relatively recent phenomenon. it was initiated in the mid-1970s, catalyzed by skyrocketing oil prices. since the mid-2000s, it has quickly evolved into a prominent research field encompassing an expansive and growing number of research groups and organizations across the world. the main conclusion of most of these studies is that 100% renewables is feasible worldwide at low cost. advanced concepts and methods now enable the field to chart realistic as well as cost- or resource-optimized and efficient transition pathways to a future without the use of fossil fuels. such proposed pathways in turn, have helped spur 100% renewable energy policy targets and actions, leading to more research. in most transition pathways, solar energy and wind power increasingly emerge as the central pillars of a sustainable energy system combined with energy efficiency measures. cost-optimization modeling and greater resource availability tend to lead to higher solar photovoltaic shares, while emphasis on energy supply diversification tends to point to higher wind power contributions. recent research has focused on the challenges and opportunities regarding grid congestion, energy storage, sector coupling, electrification of transport and industry implying power-to-x and hydrogen-to-x, and the inclusion of natural and technical carbon dioxide removal (cdr) approaches. the result is a holistic vision of the transition towards a net-negative greenhouse gas emissions economy that can limit global warming to 1.5°c with a clearly defined carbon budget in a sustainable and cost-effective manner based on 100% renewable energy-industry-cdr systems. initially, the field encountered very strong skepticism. therefore, this paper also includes a response to major critiques against 100% renewable energy systems, and also discusses the institutional inertia that hampers adoption by the international energy agency and the intergovernmental panel on climate change, as well as possible negative connections to community acceptance and energy justice. we conclude by discussing how this emergent research field can further progress to the benefit of society.",https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837910.pdf
887326b9cc9f764019045c2ac7477f44cbfa8461,"Cost, environmental impact, and resilience of renewable energy under a changing climate: a review","Energy derived from fossil fuels contributes significantly to global climate change, accounting for more than 75% of global greenhouse gas emissions and approximately 90% of all carbon dioxide emissions. Alternative energy from renewable sources must be utilized to decarbonize the energy sector. However, the adverse effects of climate change, such as increasing temperatures, extreme winds, rising sea levels, and decreased precipitation, may impact renewable energies. Here we review renewable energies with a focus on costs, the impact of climate on renewable energies, the impact of renewable energies on the environment, economy, and on decarbonization in different countries. We focus on solar, wind, biomass, hydropower, and geothermal energy. We observe that the price of solar photovoltaic energy has declined from $0.417 in 2010 to $0.048/kilowatt-hour in 2021. Similarly, prices have declined by 68% for onshore wind, 60% for offshore wind, 68% for concentrated solar power, and 14% for biomass energy. Wind energy and hydropower production could decrease by as much as 40% in some regions due to climate change, whereas solar energy appears the least impacted energy source. Climate change can also modify biomass productivity, growth, chemical composition, and soil microbial communities. Hydroelectric power plants are the most damaging to the environment; and solar photovoltaics must be carefully installed to reduce their impact. Wind turbines and biomass power plants have a minimal environmental impact; therefore, they should be implemented extensively. Renewable energy sources could decarbonize 90% of the electricity industry by 2050, drastically reducing carbon emissions, and contributing to climate change mitigation. By establishing the zero carbon emission decarbonization concept, the future of renewable energy is promising, with the potential to replace fossil fuel-derived energy and limit global temperature rise to 1.5 °C by 2050.",2022,"[{'authorId': '32474777', 'name': 'A. Osman'}, {'authorId': '2145130787', 'name': 'Lin Chen'}, {'authorId': '2150426754', 'name': 'Mingyu Yang'}, {'authorId': '2140482815', 'name': 'Goodluck Msigwa'}, {'authorId': '80967597', 'name': 'Mohamed Farghali'}, {'authorId': '1842273253', 'name': 'Samer Fawzy'}, {'authorId': '2126610635', 'name': 'David W. Rooney'}, {'authorId': '123276858', 'name': 'P. Yap'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s10311-022-01532-8.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10311-022-01532-8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10311-022-01532-8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","energy derived from fossil fuels contributes significantly to global climate change, accounting for more than 75% of global greenhouse gas emissions and approximately 90% of all carbon dioxide emissions. alternative energy from renewable sources must be utilized to decarbonize the energy sector. however, the adverse effects of climate change, such as increasing temperatures, extreme winds, rising sea levels, and decreased precipitation, may impact renewable energies. here we review renewable energies with a focus on costs, the impact of climate on renewable energies, the impact of renewable energies on the environment, economy, and on decarbonization in different countries. we focus on solar, wind, biomass, hydropower, and geothermal energy. we observe that the price of solar photovoltaic energy has declined from $0.417 in 2010 to $0.048/kilowatt-hour in 2021. similarly, prices have declined by 68% for onshore wind, 60% for offshore wind, 68% for concentrated solar power, and 14% for biomass energy. wind energy and hydropower production could decrease by as much as 40% in some regions due to climate change, whereas solar energy appears the least impacted energy source. climate change can also modify biomass productivity, growth, chemical composition, and soil microbial communities. hydroelectric power plants are the most damaging to the environment; and solar photovoltaics must be carefully installed to reduce their impact. wind turbines and biomass power plants have a minimal environmental impact; therefore, they should be implemented extensively. renewable energy sources could decarbonize 90% of the electricity industry by 2050, drastically reducing carbon emissions, and contributing to climate change mitigation. by establishing the zero carbon emission decarbonization concept, the future of renewable energy is promising, with the potential to replace fossil fuel-derived energy and limit global temperature rise to 1.5 °c by 2050.",https://link.springer.com/content/pdf/10.1007/s10311-022-01532-8.pdf
d1038fe8279310a1b80d23f462511ab89a5f7898,Role of green finance in improving energy efficiency and renewable energy development,"Deploying green energy is, directly and indirectly, related to energy- and environment-related sustainable development goals (SDGs). This study uses the stochastic impact by regression on the population, affluence, and technology (STIRPAT) model to examine the relationship between CO2 emissions, energy efficiency, green energy index (GEI), and green finance in the top ten economies that support green finance. The results show that green bonds are a suitable method to promote green energy projects and reduce CO2 emissions significantly. At the same time, there is no causal linkage between these variables in the short term. Therefore, to achieve sustainable economic growth for environmental issues, governments should implement supportive policies with a long-term approach to boost private participation in the investment of green energy projects. This policy may be applicable during and in the post the COVID-19 era when green projects have more difficulties accessing finance.",2022,"[{'authorId': '12978689', 'name': 'E. Rasoulinezhad'}, {'authorId': '1403753708', 'name': 'Farhad Taghizadeh‐Hesary'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s12053-022-10021-4.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9058054, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deploying green energy is, directly and indirectly, related to energy- and environment-related sustainable development goals (sdgs). this study uses the stochastic impact by regression on the population, affluence, and technology (stirpat) model to examine the relationship between co2 emissions, energy efficiency, green energy index (gei), and green finance in the top ten economies that support green finance. the results show that green bonds are a suitable method to promote green energy projects and reduce co2 emissions significantly. at the same time, there is no causal linkage between these variables in the short term. therefore, to achieve sustainable economic growth for environmental issues, governments should implement supportive policies with a long-term approach to boost private participation in the investment of green energy projects. this policy may be applicable during and in the post the covid-19 era when green projects have more difficulties accessing finance.",https://link.springer.com/content/pdf/10.1007/s12053-022-10021-4.pdf
9f3b3d2224a4fe6047b5a4d7bb84e07c9985f7ad,Does green finance mitigate the effects of climate variability: role of renewable energy investment and infrastructure,"Few researches have inspected the task of green finance in reducing CO2 emissions, while earlier studies have inspected the influence of economic development on carbon emissions. A green finance development index is built using four indicators to fill in this knowledge gap: green credit, green insurance, green securities, and green investing. Using data spanning the years 2005–2019, a panel quantile regression is applied to investigate the links between green finance, renewable energy, and CO2 emissions. Increases in renewable energy use and advances in the green finance development index have contributed to a reduction in CO2 emissions from BRICS countries. CO2 emissions on the other hand slowed the growth of renewable energy use, slowed the flow of investment to green projects, and ultimately hampered the development of green finance. There was also a clear policy-driven influence on renewable energy spending in the countries of the BRICS region. Green finance policies, on the other hand, have consistently failed to have a long-term impact. Therefore, rising the consumption of renewable energy and creating a carbon trading market are all part of this study’s recommendations for green finance policy improvement.",2022,"[{'authorId': '2278953845', 'name': 'Franley Mngumi'}, {'authorId': '2248537948', 'name': 'Shaorong Sun'}, {'authorId': '1404279867', 'name': 'F. Shair'}, {'authorId': '40315256', 'name': 'M. Waqas'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11356-022-19839-y.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8986026, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","few researches have inspected the task of green finance in reducing co2 emissions, while earlier studies have inspected the influence of economic development on carbon emissions. a green finance development index is built using four indicators to fill in this knowledge gap: green credit, green insurance, green securities, and green investing. using data spanning the years 2005–2019, a panel quantile regression is applied to investigate the links between green finance, renewable energy, and co2 emissions. increases in renewable energy use and advances in the green finance development index have contributed to a reduction in co2 emissions from brics countries. co2 emissions on the other hand slowed the growth of renewable energy use, slowed the flow of investment to green projects, and ultimately hampered the development of green finance. there was also a clear policy-driven influence on renewable energy spending in the countries of the brics region. green finance policies, on the other hand, have consistently failed to have a long-term impact. therefore, rising the consumption of renewable energy and creating a carbon trading market are all part of this study’s recommendations for green finance policy improvement.",https://link.springer.com/content/pdf/10.1007/s11356-022-19839-y.pdf
f218a893a0fc6b8683f58be6eaea31811b71daab,Renewable Energy Consumption and Economic Growth Nexus—A Systematic Literature Review,"An efficient use of energy is the pre-condition for economic development. But excessive use of fossil fuel harms the environment. As renewable energy emits no or low greenhouse gases, more countries are trying to increase the use of energies from renewable sources. At the same time, no matter developed or developing, nations have to maintain economic growth. By collecting SCI/SSCI indexed peer-reviewed journal articles, this article systematically reviews the consumption nexus of renewable energy and economic growth. A total of 46 articles have been reviewed following the PRISMA guidelines from 2010 to 2021. Our review research shows that renewable energy does not hinder economic growth for both developing and developed countries, whereas, there is little significance of consuming renewable energy (threshold level) on economic growth for developed countries.",2022,"[{'authorId': '71756883', 'name': 'M. Bhuiyan'}, {'authorId': '2108235072', 'name': 'Qiannan Zhang'}, {'authorId': '90981308', 'name': 'V. Khare'}, {'authorId': '153273488', 'name': 'A. Mikhaylov'}, {'authorId': '48575831', 'name': 'Gábor Pintér'}, {'authorId': '2145052813', 'name': 'Xiaowen Huang'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fenvs.2022.878394/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3389/fenvs.2022.878394?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3389/fenvs.2022.878394, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","an efficient use of energy is the pre-condition for economic development. but excessive use of fossil fuel harms the environment. as renewable energy emits no or low greenhouse gases, more countries are trying to increase the use of energies from renewable sources. at the same time, no matter developed or developing, nations have to maintain economic growth. by collecting sci/ssci indexed peer-reviewed journal articles, this article systematically reviews the consumption nexus of renewable energy and economic growth. a total of 46 articles have been reviewed following the prisma guidelines from 2010 to 2021. our review research shows that renewable energy does not hinder economic growth for both developing and developed countries, whereas, there is little significance of consuming renewable energy (threshold level) on economic growth for developed countries.",https://www.frontiersin.org/articles/10.3389/fenvs.2022.878394/pdf
df8e877ef5649f240b0acea24ea363f51888e8c8,The role of renewable energy consumption and financial development in environmental sustainability: implications for the Nordic Countries,"ABSTRACT The Nordic nations have yet to significantly contribute to achieving Sustainable Development Goals (SDG) 7 and 13. This predicament might be attributed to fundamental financialization concerns in these nations and renewable energy generation implementation issues. The Nordic nations are fighting to reduce CO2 emissions as a result of these two situations. Dealing with this problem may necessitate a policy shift, which represents the focus of this research. Utilizing data from 1980 to 2020, we analyze the heterogeneous impacts of financial development and renewable energy on CO2 emissions using advanced panel and time-series methodologies. The advantage of the wavelet tools (wavelet coherence, partial wavelet and multiple wavelet techniques) is that they help to capture policy initiatives at different frequencies, i.e., short, medium and long-term. Our empirical outcomes from the CS-ARDL show that both financial development and renewable energy decrease CO2 emissions in the short and long term. Furthermore, the outcomes of the wavelet coherence show negative co-movement between CO2 and renewable energy in each Nordic nation except for Iceland with renewable energy driving CO2 in all frequencies. Additionally, financial development enhances the ‘CO2 emissions-renewable energy consumption’ association, but in the short term, it has no stimulating effect. These findings lead to the recommendation of an SDG-oriented policy framework. While this policy agenda is designed to achieve SDGs 7 and 13, it may also be applied to other nations. The study recommends that the Nordic countries implement measures to boost renewable energy supply through enhanced renewable energy technologies. Abbreviations: ASEAN: Association of Southeast Asian Nations; BRICS: Brazil, Russia, India, China and South Africa; CO2 : Carbon Emissions; CS-ARDL: Cross Sectional Autoregressive Distributed Lag Model; FD: Financial Development; PMG-ARDL: Pool Mean Group Autoregressive Lag Model; VAR: Vector Autoregressive; VECM: Vector Error Corrected Model; MINT: Mexico, Indonesia, Nigeria and Turkey; REC: Renewable Energy; SDG: Sustainable Development Goal; SD: Sustainable Development",2022,"[{'authorId': '2125098239', 'name': 'Lichao Wu'}, {'authorId': '1742465570', 'name': 'T. Adebayo'}, {'authorId': '2057215943', 'name': 'Xiao-Guang Yue'}, {'authorId': '2079689127', 'name': 'A. Umut'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/13504509.2022.2115577?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/13504509.2022.2115577, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the nordic nations have yet to significantly contribute to achieving sustainable development goals (sdg) 7 and 13. this predicament might be attributed to fundamental financialization concerns in these nations and renewable energy generation implementation issues. the nordic nations are fighting to reduce co2 emissions as a result of these two situations. dealing with this problem may necessitate a policy shift, which represents the focus of this research. utilizing data from 1980 to 2020, we analyze the heterogeneous impacts of financial development and renewable energy on co2 emissions using advanced panel and time-series methodologies. the advantage of the wavelet tools (wavelet coherence, partial wavelet and multiple wavelet techniques) is that they help to capture policy initiatives at different frequencies, i.e., short, medium and long-term. our empirical outcomes from the cs-ardl show that both financial development and renewable energy decrease co2 emissions in the short and long term. furthermore, the outcomes of the wavelet coherence show negative co-movement between co2 and renewable energy in each nordic nation except for iceland with renewable energy driving co2 in all frequencies. additionally, financial development enhances the ‘co2 emissions-renewable energy consumption’ association, but in the short term, it has no stimulating effect. these findings lead to the recommendation of an sdg-oriented policy framework. while this policy agenda is designed to achieve sdgs 7 and 13, it may also be applied to other nations. the study recommends that the nordic countries implement measures to boost renewable energy supply through enhanced renewable energy technologies. abbreviations: asean: association of southeast asian nations; brics: brazil, russia, india, china and south africa; co2 : carbon emissions; cs-ardl: cross sectional autoregressive distributed lag model; fd: financial development; pmg-ardl: pool mean group autoregressive lag model; var: vector autoregressive; vecm: vector error corrected model; mint: mexico, indonesia, nigeria and turkey; rec: renewable energy; sdg: sustainable development goal; sd: sustainable development",
b4d643731251f7e8ff143ac853e66cd3e5acb8de,"How Do Renewable Energy, Economic Growth and Natural Resources Rent Affect Environmental Sustainability in a Globalized Economy? Evidence From Colombia Based on the Gradual Shift Causality Approach","Undoubtedly, fossil fuel energy consumption causes global warming. The question at the core is whether or not we want to quit energy consumption? The obvious answer to this question is “no.” Therefore, the necessity for innovation is curial to attain green energy and sustainable growth. This research specifically focused on Colombia, which represents the aforementioned threats to a large extent as the trajectory of economic expansion is characterized by significant CO2 emissions in Colombia. In this regard, we examine the association between globalization, renewable energy, natural resources rent, economic growth, and CO2 emissions from 1970 to 2017. The cointegration test confirmed a long association between the considered variables. This study employed the Fully Modified Ordinary Least Squares, Dynamic Ordinary Least Squares, and Autoregressive Distributed Lag estimators for the long-run analysis. The long-run empirical results uncovered growth-induced emissions in Colombia. The result illustrated that the path of development is unsustainable in Columbia. In contrast, globalization and renewable energy demonstrated a favorable contribution to environmental quality. The outcomes of the Gradual Shift Causality indicated that globalization, natural resource rent, and economic growth Granger cause CO2 emissions. The findings highlight the need to enact well-coordinated measures to reduce environmental deterioration in Colombia. Colombia must aggressively promote the development of renewable energy and also foster a better viable environment for renewable energy investment to mitigate environmental damage caused by economic growth.",2022,"[{'authorId': '2006682228', 'name': 'Abraham Ayobamiji Awosusi'}, {'authorId': '1576903027', 'name': 'M. N. Mata'}, {'authorId': '50124459', 'name': 'Zahoor Ahmed'}, {'authorId': '2151274931', 'name': 'Manuel Francisco Coelho'}, {'authorId': '2059287080', 'name': 'Mehmet Altuntaş'}, {'authorId': '48901275', 'name': 'J. Martins'}, {'authorId': '2087617450', 'name': 'Jéssica Nunes Martins'}, {'authorId': '1741410865', 'name': 'Stephen Taiwo Onifade'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fenrg.2021.739721/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3389/fenrg.2021.739721?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3389/fenrg.2021.739721, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","undoubtedly, fossil fuel energy consumption causes global warming. the question at the core is whether or not we want to quit energy consumption? the obvious answer to this question is “no.” therefore, the necessity for innovation is curial to attain green energy and sustainable growth. this research specifically focused on colombia, which represents the aforementioned threats to a large extent as the trajectory of economic expansion is characterized by significant co2 emissions in colombia. in this regard, we examine the association between globalization, renewable energy, natural resources rent, economic growth, and co2 emissions from 1970 to 2017. the cointegration test confirmed a long association between the considered variables. this study employed the fully modified ordinary least squares, dynamic ordinary least squares, and autoregressive distributed lag estimators for the long-run analysis. the long-run empirical results uncovered growth-induced emissions in colombia. the result illustrated that the path of development is unsustainable in columbia. in contrast, globalization and renewable energy demonstrated a favorable contribution to environmental quality. the outcomes of the gradual shift causality indicated that globalization, natural resource rent, and economic growth granger cause co2 emissions. the findings highlight the need to enact well-coordinated measures to reduce environmental deterioration in colombia. colombia must aggressively promote the development of renewable energy and also foster a better viable environment for renewable energy investment to mitigate environmental damage caused by economic growth.",https://www.frontiersin.org/articles/10.3389/fenrg.2021.739721/pdf
c2cfb942f6a7ee47e09a98c2e3663b3faed94a12,Does Renewable Energy Matter to Achieve Sustainable Development Goals? The Impact of Renewable Energy Strategies on Sustainable Economic Growth,"The influences of renewable and conventional energy consumption on ecological sustainability remain unclear because of the dynamic economic and innovative framework. This investigation gives a new perception by exploring the association between the production of various sources of renewable energies (e.g., hydroelectric, wind, solar PV, geothermal, and biomass power) and economic growth encapsulating capital, government spending, and trade openness. This research used a heterogeneous approach for panel data and second generational tools for econometrics, which allow for cross-sectional reliance and slope heterogeneity. This study has revealed the substantial reason to back up the feedback assumptions between renewable energy sources and economic growth, using the Dumitrescu and Hurlin analysis. In terms of policy, this empirical analysis suggests enacting impactful policies that encourage green power and economic reform in an attempt to lessen CO2 concentrations in the biosphere.",2022,"[{'authorId': None, 'name': 'Jie Chen'}, {'authorId': '145667758', 'name': 'F. Su'}, {'authorId': '2061365227', 'name': 'Vipin Jain'}, {'authorId': '34944439', 'name': 'Asma Salman'}, {'authorId': '74336418', 'name': 'M. Tabash'}, {'authorId': '71414475', 'name': 'A. Haddad'}, {'authorId': '151446069', 'name': 'Eman A. Zabalawi'}, {'authorId': '98875375', 'name': 'Al-Amin A. Abdalla'}, {'authorId': '143885956', 'name': 'M. Shabbir'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fenrg.2022.829252/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3389/fenrg.2022.829252?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3389/fenrg.2022.829252, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the influences of renewable and conventional energy consumption on ecological sustainability remain unclear because of the dynamic economic and innovative framework. this investigation gives a new perception by exploring the association between the production of various sources of renewable energies (e.g., hydroelectric, wind, solar pv, geothermal, and biomass power) and economic growth encapsulating capital, government spending, and trade openness. this research used a heterogeneous approach for panel data and second generational tools for econometrics, which allow for cross-sectional reliance and slope heterogeneity. this study has revealed the substantial reason to back up the feedback assumptions between renewable energy sources and economic growth, using the dumitrescu and hurlin analysis. in terms of policy, this empirical analysis suggests enacting impactful policies that encourage green power and economic reform in an attempt to lessen co2 concentrations in the biosphere.",https://www.frontiersin.org/articles/10.3389/fenrg.2022.829252/pdf
b549542079068e1593a9314654d9d8fdf02147d5,International Renewable Energy Agency,"Comments on the working paper can be sent to Mr. Hugo Lucas at hlucas@irena.org. Unless expressly stated otherwise, the findings, interpretations and conclusions expressed herein are those of the various IRENA staff members, contributors, consultants and advisers to the IRENA Secretariat who prepared the work and do not necessarily represent the views of the International Renewable Energy Agency or its Members. the designations employed and the presentation of materials herein do not imply the expression of any opinion whatsoever on the part of the Secretariat of the International Renewable Energy Agency concerning the legal status of any country, territory, city or area or of its authorities, or concerning the delimitation of its frontiers or boundaries. the term ""country"" as used in this material also refers, as appropriate, to territories or areas.",2021,"[{'authorId': '100734973', 'name': 'Hugo Lucas'}, {'authorId': '118474348', 'name': 'R. Ferroukhi'}]","{'url': 'https://biblio.ugent.be/publication/8714318/file/8714319', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.18356/9789210056755c212?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.18356/9789210056755c212, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","comments on the working paper can be sent to mr. hugo lucas at hlucas@irena.org. unless expressly stated otherwise, the findings, interpretations and conclusions expressed herein are those of the various irena staff members, contributors, consultants and advisers to the irena secretariat who prepared the work and do not necessarily represent the views of the international renewable energy agency or its members. the designations employed and the presentation of materials herein do not imply the expression of any opinion whatsoever on the part of the secretariat of the international renewable energy agency concerning the legal status of any country, territory, city or area or of its authorities, or concerning the delimitation of its frontiers or boundaries. the term ""country"" as used in this material also refers, as appropriate, to territories or areas.",https://biblio.ugent.be/publication/8714318/file/8714319
e0ba91aec2309f563d160c5a2ec3a7c53a8a2aa3,Renewable Energy and CO2 Emissions in Top Natural Resource Rents Depending Countries: The Role of Governance,This study analyzes the relationship between renewable energy and CO2 emissions in top natural resource depending countries over the period 2000–2015. An important contribution of this study is to assess the role of governance. The Ordinary Least Squares Fixed effects Generalized Least Squares methods and two-step GMM estimators are used for panel data. The empirical results show that renewable energy has significant negative impact on per capita CO2 emissions. The estimates show that 1 percentage point increase in renewable energy consumption leads to 1.25% decrease in CO2 emissions per capita. We also find that renewable energy consumption decreases CO2 emissions faster in countries with higher rule of law and voice and accountability. gross domestic product per capita has inverted U-shaped relationship with CO2 emissions.,2022,"[{'authorId': '122601943', 'name': 'Beata Szetela'}, {'authorId': '51331586', 'name': 'A. Majewska'}, {'authorId': '98561552', 'name': 'P. Jamróz'}, {'authorId': '2079987534', 'name': 'B. Djalilov'}, {'authorId': '13231814', 'name': 'Raufhon Salahodjaev'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fenrg.2022.872941/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3389/fenrg.2022.872941?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3389/fenrg.2022.872941, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",this study analyzes the relationship between renewable energy and co2 emissions in top natural resource depending countries over the period 2000–2015. an important contribution of this study is to assess the role of governance. the ordinary least squares fixed effects generalized least squares methods and two-step gmm estimators are used for panel data. the empirical results show that renewable energy has significant negative impact on per capita co2 emissions. the estimates show that 1 percentage point increase in renewable energy consumption leads to 1.25% decrease in co2 emissions per capita. we also find that renewable energy consumption decreases co2 emissions faster in countries with higher rule of law and voice and accountability. gross domestic product per capita has inverted u-shaped relationship with co2 emissions.,https://www.frontiersin.org/articles/10.3389/fenrg.2022.872941/pdf
beed2f53456f6482b615dd79dfcd041f14df32cb,Renewable Energy in the Sustainable Development of Electrical Power Sector: A Review,"The electrical power sector plays an important role in the economic growth and development of every country around the world. Total global demand for electric energy is growing both in developed and developing economies. The commitment to the decarbonization of economies, which would mean replacing fossil fuels with renewable energy sources (RES) as well as the electrification of transport and heating as a means to tackle global warming and dangerous climate change, would lead to a surge in electricity consumption worldwide. Hence, it appears reasonable that the electric power sector should embed the principles of sustainable development into its functioning and operation. In addition, events such as the recent European gas crisis that have emerged as a result of the massive deployment of renewables need to be studied and prevented. This review aims at assessing the role of the renewable energy in the sustainable development of the electrical power sector, focusing on the energy providers and consumers represented both by businesses and households that are gradually becoming prosumers on the market of electric energy. Furthermore, it also focuses on the impact of renewables on the utility side and their benefits for the grid. In addition, it identifies the major factors of the sustainable development of the electrical power sector.",2021,"[{'authorId': '10739486', 'name': 'W. Strielkowski'}, {'authorId': '119215290', 'name': 'Lubomír Civín'}, {'authorId': '2142828566', 'name': 'E. Tarkhanova'}, {'authorId': '3153464', 'name': 'M. Tvaronavičienė'}, {'authorId': '119077316', 'name': 'Yelena S. Petrenko'}]","{'url': 'https://www.mdpi.com/1996-1073/14/24/8240/pdf?version=1638931924', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/en14248240?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/en14248240, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the electrical power sector plays an important role in the economic growth and development of every country around the world. total global demand for electric energy is growing both in developed and developing economies. the commitment to the decarbonization of economies, which would mean replacing fossil fuels with renewable energy sources (res) as well as the electrification of transport and heating as a means to tackle global warming and dangerous climate change, would lead to a surge in electricity consumption worldwide. hence, it appears reasonable that the electric power sector should embed the principles of sustainable development into its functioning and operation. in addition, events such as the recent european gas crisis that have emerged as a result of the massive deployment of renewables need to be studied and prevented. this review aims at assessing the role of the renewable energy in the sustainable development of the electrical power sector, focusing on the energy providers and consumers represented both by businesses and households that are gradually becoming prosumers on the market of electric energy. furthermore, it also focuses on the impact of renewables on the utility side and their benefits for the grid. in addition, it identifies the major factors of the sustainable development of the electrical power sector.",https://www.mdpi.com/1996-1073/14/24/8240/pdf?version=1638931924
07c81a7fa1b3b9b4b7e4da947a5c5ddac1c934ec,A critical review of the integration of renewable energy sources with various technologies,"Wind power, solar power and water power are technologies that can be used as the main sources of renewable energy so that the target of decarbonisation in the energy sector can be achieved. However, when compared with conventional power plants, they have a significant difference. The share of renewable energy has made a difference and posed various challenges, especially in the power generation system. The reliability of the power system can achieve the decarbonization target but this objective often collides with several challenges and failures, such that they make achievement of the target very vulnerable, Even so, the challenges and technological solutions are still very rarely discussed in the literature. This study carried out specific investigations on various technological solutions and challenges, especially in the power system domain. The results of the review of the solution matrix and the interrelated technological challenges are the most important parts to be developed in the future. Developing a matrix with various renewable technology solutions can help solve RE challenges. The potential of the developed technological solutions is expected to be able to help and prioritize them especially cost-effective energy. In addition, technology solutions that are identified in groups can help reduce certain challenges. The categories developed in this study are used to assist in determining the specific needs and increasing transparency of the renewable energy integration process in the future.",2021,"[{'authorId': '101560269', 'name': 'Erdiwansyah'}, {'authorId': '123055781', 'name': 'Mahidin'}, {'authorId': '37410830', 'name': 'H. Husin'}, {'authorId': '48873482', 'name': 'Nasaruddin'}, {'authorId': '50294466', 'name': 'M. Zaki'}, {'authorId': '98208238', 'name': 'Muhibbuddin'}]","{'url': 'https://pcmp.springeropen.com/track/pdf/10.1186/s41601-021-00181-3', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1186/s41601-021-00181-3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/s41601-021-00181-3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","wind power, solar power and water power are technologies that can be used as the main sources of renewable energy so that the target of decarbonisation in the energy sector can be achieved. however, when compared with conventional power plants, they have a significant difference. the share of renewable energy has made a difference and posed various challenges, especially in the power generation system. the reliability of the power system can achieve the decarbonization target but this objective often collides with several challenges and failures, such that they make achievement of the target very vulnerable, even so, the challenges and technological solutions are still very rarely discussed in the literature. this study carried out specific investigations on various technological solutions and challenges, especially in the power system domain. the results of the review of the solution matrix and the interrelated technological challenges are the most important parts to be developed in the future. developing a matrix with various renewable technology solutions can help solve re challenges. the potential of the developed technological solutions is expected to be able to help and prioritize them especially cost-effective energy. in addition, technology solutions that are identified in groups can help reduce certain challenges. the categories developed in this study are used to assist in determining the specific needs and increasing transparency of the renewable energy integration process in the future.",https://pcmp.springeropen.com/track/pdf/10.1186/s41601-021-00181-3
bf1baccc465a6c6ffe75b7f9abd2bd49a008c115,Power-Electronic Systems for the Grid Integration of Renewable Energy Sources: A Survey,"The use of distributed energy resources is increasingly being pursued as a supplement and an alternative to large conventional central power stations. The specification of a power-electronic interface is subject to requirements related not only to the renewable energy source itself but also to its effects on the power-system operation, especially where the intermittent energy source constitutes a significant part of the total system capacity. In this paper, new trends in power electronics for the integration of wind and photovoltaic (PV) power generators are presented. A review of the appropriate storage-system technology used for the integration of intermittent renewable energy sources is also introduced. Discussions about common and future trends in renewable energy systems based on reliability and maturity of each technology are presented",2006,"[{'authorId': '145874144', 'name': 'J. Carrasco'}, {'authorId': '1756639', 'name': 'L. Franquelo'}, {'authorId': '2442938', 'name': 'J. Bialasiewicz'}, {'authorId': '145142685', 'name': 'E. Galván'}, {'authorId': '2240913553', 'name': 'Ramón Portillo'}, {'authorId': '2248348665', 'name': 'Guisado'}, {'authorId': '2248341665', 'name': 'Ma Ángeles'}, {'authorId': '2248348347', 'name': 'Martín Prats'}, {'authorId': '2248336099', 'name': 'Ignacio León'}, {'authorId': '1431231418', 'name': 'Narciso Moreno-Alfonso'}]","{'url': 'https://idus.us.es/bitstream/11441/42133/4/IEEETIE_Carrasco_Moreno_Alfonso%20et%20al_2006_%20power%20electronic_a%20survey.pdf', 'status': 'GREEN', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TIE.2006.878356?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TIE.2006.878356, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the use of distributed energy resources is increasingly being pursued as a supplement and an alternative to large conventional central power stations. the specification of a power-electronic interface is subject to requirements related not only to the renewable energy source itself but also to its effects on the power-system operation, especially where the intermittent energy source constitutes a significant part of the total system capacity. in this paper, new trends in power electronics for the integration of wind and photovoltaic (pv) power generators are presented. a review of the appropriate storage-system technology used for the integration of intermittent renewable energy sources is also introduced. discussions about common and future trends in renewable energy systems based on reliability and maturity of each technology are presented",https://idus.us.es/bitstream/11441/42133/4/IEEETIE_Carrasco_Moreno_Alfonso%20et%20al_2006_%20power%20electronic_a%20survey.pdf
922d6ff8b81eca1fd27e16119cddef040469c009,"The Impact of Economic Growth, Trade Openness and Technological Progress on Renewable Energy Use in Organization for Economic Co-Operation and Development Countries","This study investigates the short-term and long-term impacts of economic growth, trade openness and technological progress on renewable energy use in Organization for Economic Co-operation and Development (OECD) countries. Based on a panel data set of 25 OECD countries for 43 years, we used the autoregressive distributed lag (ARDL) approach and the related intermediate estimators, including pooled mean group (PMG), mean group (MG) and dynamic fixed effect (DFE) to achieve the objective. The estimated ARDL model has also been checked for robustness using the two substitute single equation estimators, these being the dynamic ordinary least squares (DOLS) and fully modified ordinary least squares (FMOLS). Empirical results reveal that economic growth, trade openness and technological progress significantly influence renewable energy use over the long-term in OECD countries. While the long-term nature of dynamics of the variables is found to be similar across 25 OECD countries, their short-term dynamics are found to be mixed in nature. This is attributed to varying levels of trade openness and technological progress in OECD countries. Since this is a pioneer study that investigates the issue, the findings are completely new and they make a significant contribution to renewable energy literature as well as relevant policy development.",2020,"[{'authorId': '2109950768', 'name': 'M. Alam'}, {'authorId': '11306633', 'name': 'W. Murad'}]","{'url': 'https://osf.io/wj45u/download', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.31235/osf.io/wj45u?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.31235/osf.io/wj45u, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study investigates the short-term and long-term impacts of economic growth, trade openness and technological progress on renewable energy use in organization for economic co-operation and development (oecd) countries. based on a panel data set of 25 oecd countries for 43 years, we used the autoregressive distributed lag (ardl) approach and the related intermediate estimators, including pooled mean group (pmg), mean group (mg) and dynamic fixed effect (dfe) to achieve the objective. the estimated ardl model has also been checked for robustness using the two substitute single equation estimators, these being the dynamic ordinary least squares (dols) and fully modified ordinary least squares (fmols). empirical results reveal that economic growth, trade openness and technological progress significantly influence renewable energy use over the long-term in oecd countries. while the long-term nature of dynamics of the variables is found to be similar across 25 oecd countries, their short-term dynamics are found to be mixed in nature. this is attributed to varying levels of trade openness and technological progress in oecd countries. since this is a pioneer study that investigates the issue, the findings are completely new and they make a significant contribution to renewable energy literature as well as relevant policy development.",https://osf.io/wj45u/download
dd311dfb26c68ea95ac1da1f63330d84b2f33a6b,"Renewable energy for sustainable development in India: current status, future prospects, challenges, employment, and investment opportunities","The primary objective for deploying renewable energy in India is to advance economic development, improve energy security, improve access to energy, and mitigate climate change. Sustainable development is possible by use of sustainable energy and by ensuring access to affordable, reliable, sustainable, and modern energy for citizens. Strong government support and the increasingly opportune economic situation have pushed India to be one of the top leaders in the world’s most attractive renewable energy markets. The government has designed policies, programs, and a liberal environment to attract foreign investments to ramp up the country in the renewable energy market at a rapid rate. It is anticipated that the renewable energy sector can create a large number of domestic jobs over the following years. This paper aims to present significant achievements, prospects, projections, generation of electricity, as well as challenges and investment and employment opportunities due to the development of renewable energy in India. In this review, we have identified the various obstacles faced by the renewable sector. The recommendations based on the review outcomes will provide useful information for policymakers, innovators, project developers, investors, industries, associated stakeholders and departments, researchers, and scientists.",2020,"[{'authorId': '1481052479', 'name': 'C. Kumar. J'}, {'authorId': '151123585', 'name': 'M. Majid'}]","{'url': 'https://energsustainsoc.biomedcentral.com/track/pdf/10.1186/s13705-019-0232-1', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1186/s13705-019-0232-1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/s13705-019-0232-1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the primary objective for deploying renewable energy in india is to advance economic development, improve energy security, improve access to energy, and mitigate climate change. sustainable development is possible by use of sustainable energy and by ensuring access to affordable, reliable, sustainable, and modern energy for citizens. strong government support and the increasingly opportune economic situation have pushed india to be one of the top leaders in the world’s most attractive renewable energy markets. the government has designed policies, programs, and a liberal environment to attract foreign investments to ramp up the country in the renewable energy market at a rapid rate. it is anticipated that the renewable energy sector can create a large number of domestic jobs over the following years. this paper aims to present significant achievements, prospects, projections, generation of electricity, as well as challenges and investment and employment opportunities due to the development of renewable energy in india. in this review, we have identified the various obstacles faced by the renewable sector. the recommendations based on the review outcomes will provide useful information for policymakers, innovators, project developers, investors, industries, associated stakeholders and departments, researchers, and scientists.",https://energsustainsoc.biomedcentral.com/track/pdf/10.1186/s13705-019-0232-1
79b4c2916aebc77fdf8cdba92c2e5a6985bd2418,"Measuring the impact of renewable energy, public health expenditure, logistics, and environmental performance on sustainable economic growth","The study aims to examine the potential relationship between public health expenditures, logistics performance indices, renewable energy, and ecological sustainability in Association of Southeast Asian Nations member countries. The study used secondary data, which downloaded from the World Bank website and tested for hypotheses using the structural equation modeling. The results show that the use of renewable energy in logistics operations will improve environmental and economic performance to reduce emissions, whereas environmental performance is negatively correlated with public health expenditures, indicating that greater environmental sustainability can improve human health and economic growth. The results also show that increased public health spending and poor environmental performance undermine economic growth in low efficiency and low labor productivity, thus reducing the speed of economic activity. On the other hand, the use of renewable energy in logistics cannot only improve the sustainability of the environment but also create a better national image and provide better export opportunities in environmentally friendly countries to promote sustainable economic growth. The outcomes of this study will",2020,"[{'authorId': '2166425628', 'name': 'S. Khan'}, {'authorId': '143893278', 'name': 'Yu Zhang'}, {'authorId': '2005706696', 'name': 'Anil Kumar'}, {'authorId': '145366462', 'name': 'E. Zavadskas'}, {'authorId': '16273690', 'name': 'D. Štreimikienė'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/sd.2034?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/sd.2034, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the study aims to examine the potential relationship between public health expenditures, logistics performance indices, renewable energy, and ecological sustainability in association of southeast asian nations member countries. the study used secondary data, which downloaded from the world bank website and tested for hypotheses using the structural equation modeling. the results show that the use of renewable energy in logistics operations will improve environmental and economic performance to reduce emissions, whereas environmental performance is negatively correlated with public health expenditures, indicating that greater environmental sustainability can improve human health and economic growth. the results also show that increased public health spending and poor environmental performance undermine economic growth in low efficiency and low labor productivity, thus reducing the speed of economic activity. on the other hand, the use of renewable energy in logistics cannot only improve the sustainability of the environment but also create a better national image and provide better export opportunities in environmentally friendly countries to promote sustainable economic growth. the outcomes of this study will",
9e104cc62a388c9add9606be12dcb46c21bf2f69,"An empirical analysis of the non-linear impacts of ICT-trade openness on renewable energy transition, energy efficiency, clean cooking fuel access and environmental sustainability in South Asia","Energy security and environmental sustainability have become an integral policy agenda worldwide whereby the global economic growth policies are being restructured to ensure the reliability of energy supply and safeguard environmental well-being as well. However, technological inefficiency is one of the major hindrances in attaining these over-arching goals. Hence, this paper probed into the non-linear impacts of ICT trade on the prospects of undergoing renewable energy transition, improving energy use efficiencies, enhancing access to cleaner cooking fuels, and mitigating carbon dioxide emissions across selected South Asian economies: Bangladesh, India, Pakistan, Sri Lanka, Nepal, and Maldives. The results from the econometric analyses reveal that ICT trade directly increases renewable energy consumption, enhances renewable energy shares, reduces intensity of energy use, facilitates adoption of cleaner cooking fuels, and reduces carbon-dioxide emissions. Moreover, ICT trade also indirectly mitigates carbon-dioxide emissions through boosting renewable energy consumption levels, improving energy efficiencies, and enhancing cleaner cooking fuel access. Hence, these results, in a nutshell, portray the significance of reducing the barriers to ICT trade with respect to ensuring energy security and environmental sustainability across South Asia. Therefore, it is ideal for the government to gradually lessen the trade barriers to boost the volumes of cross-border flows of green ICT commodities. Besides, it is also recommended to attract foreign direct investments for the potential development of the respective ICT sectors of the South Asian economies.",2020,"[{'authorId': '5017564', 'name': 'Muntasir Murshed'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11356-020-09497-3.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7302924, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","energy security and environmental sustainability have become an integral policy agenda worldwide whereby the global economic growth policies are being restructured to ensure the reliability of energy supply and safeguard environmental well-being as well. however, technological inefficiency is one of the major hindrances in attaining these over-arching goals. hence, this paper probed into the non-linear impacts of ict trade on the prospects of undergoing renewable energy transition, improving energy use efficiencies, enhancing access to cleaner cooking fuels, and mitigating carbon dioxide emissions across selected south asian economies: bangladesh, india, pakistan, sri lanka, nepal, and maldives. the results from the econometric analyses reveal that ict trade directly increases renewable energy consumption, enhances renewable energy shares, reduces intensity of energy use, facilitates adoption of cleaner cooking fuels, and reduces carbon-dioxide emissions. moreover, ict trade also indirectly mitigates carbon-dioxide emissions through boosting renewable energy consumption levels, improving energy efficiencies, and enhancing cleaner cooking fuel access. hence, these results, in a nutshell, portray the significance of reducing the barriers to ict trade with respect to ensuring energy security and environmental sustainability across south asia. therefore, it is ideal for the government to gradually lessen the trade barriers to boost the volumes of cross-border flows of green ict commodities. besides, it is also recommended to attract foreign direct investments for the potential development of the respective ict sectors of the south asian economies.",https://link.springer.com/content/pdf/10.1007/s11356-020-09497-3.pdf
d2814c2120e17c3cb670e9b66411d39eaafac221,"A Comprehensive Review on Renewable Energy Development, Challenges, and Policies of Leading Indian States With an International Perspective","Clean and environment-friendly energy harvesting are of prime interest today as it is one of the key enablers in achieving the Sustainable Development Goals (SDGs) as well as accelerates social progress and enhances living standards. India, the second-most populous nation with a population of 1.353 billion, is one of the largest consumers of fossil fuels in the world which is responsible for global warming. An ever-increasing population is projected until 2050, and consequently, the energy demand in the upcoming decades will be co-accelerated by the rapid industrial growth. The Ministry of New and Renewable Energy (MNRE) with the support of National Institution for Transforming India (NITI) Aayog is working to achieve the Indian Government’s target of attaining 175 GW through renewable energy resources. Many Indian states are currently increasing their renewable energy capacity in an objective to meet future energy demand. The review paper discusses in-depth about the three Indian states, namely Karnataka, Gujarat, Tamil Nadu, which pioneers the renewable energy production in India. The global energy scenario was discussed in detail with Indian contrast. Further, the barriers to the development of renewable energy generation and policies of the Indian government are discussed in detail to promote renewable energy generation throughout India as well as globally since the challenges are similar for other nations. This study analyzed various prospects of the country in renewable energy which has been done in a purpose to help the scholars, researchers, and policymakers of the nation, as it gives an insight into the present renewable energy scenario of the country.",2020,"[{'authorId': '134634893', 'name': 'R. Elavarasan'}, {'authorId': '3210830', 'name': 'G. Shafiullah'}, {'authorId': '9728462', 'name': 'Sanjeevikumar Padmanaban'}, {'authorId': '27666347', 'name': 'Nallapaneni Manoj Kumar'}, {'authorId': '1666173479', 'name': 'Annapurna Annam'}, {'authorId': '1666146694', 'name': 'Ajayragavan Manavalanagar Vetrichelvan'}, {'authorId': '1410699247', 'name': 'L. Mihet-Popa'}, {'authorId': '1402064664', 'name': 'J. Holm‐Nielsen'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09072152.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2020.2988011?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2020.2988011, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","clean and environment-friendly energy harvesting are of prime interest today as it is one of the key enablers in achieving the sustainable development goals (sdgs) as well as accelerates social progress and enhances living standards. india, the second-most populous nation with a population of 1.353 billion, is one of the largest consumers of fossil fuels in the world which is responsible for global warming. an ever-increasing population is projected until 2050, and consequently, the energy demand in the upcoming decades will be co-accelerated by the rapid industrial growth. the ministry of new and renewable energy (mnre) with the support of national institution for transforming india (niti) aayog is working to achieve the indian government’s target of attaining 175 gw through renewable energy resources. many indian states are currently increasing their renewable energy capacity in an objective to meet future energy demand. the review paper discusses in-depth about the three indian states, namely karnataka, gujarat, tamil nadu, which pioneers the renewable energy production in india. the global energy scenario was discussed in detail with indian contrast. further, the barriers to the development of renewable energy generation and policies of the indian government are discussed in detail to promote renewable energy generation throughout india as well as globally since the challenges are similar for other nations. this study analyzed various prospects of the country in renewable energy which has been done in a purpose to help the scholars, researchers, and policymakers of the nation, as it gives an insight into the present renewable energy scenario of the country.",https://ieeexplore.ieee.org/ielx7/6287639/8948470/09072152.pdf
7cbe09fd50f2e8cf4741888aa4c911b06b661daf,"How renewable energy consumption lower global CO
 2
 emissions? Evidence from countries with different income levels","Significant difference in the emission–renewables nexus across countries with different income levels is frequently ignored in previous studies. To empirically investigate whether the effect of renewable energy consumption on carbon dioxide (CO2) emissions differs across countries with different income levels, the emission–growth–renewables nexus for a global panel of 120 countries and four income‐based subpanels over the period 1995–2015 is examined. Fully considering the potential cross‐sectional dependence and slope heterogeneity, a series of econometric techniques allowing for cross‐sectional dependence and slope heterogeneity is utilised. Cross‐sectional dependence and slope heterogeneity are confirmed for the global panel as well as for all four subpanels. Only for the global panel, high‐income subpanel and upper‐middle‐income subpanel is the environmental Kuznets curve (EKC) hypothesis valid. Renewable energy consumption has a negative effect on CO2 emissions, but its effect is not significant; the mitigation effect may be obscured by higher economic growth and increasing non‐renewable energy consumption. The global panel and four subpanels provide mixed directionality of causality among the variables, suggesting that for various income‐based subpanels, significant differences exist in the effect of renewable energy consumption on CO2 emissions, especially highlighting in various direct and indirect influencing paths between renewable energy consumption and CO2 emissions.",2020,"[{'authorId': '46228633', 'name': 'Kangyin Dong'}, {'authorId': '49988755', 'name': 'Xiucheng Dong'}, {'authorId': '48208952', 'name': 'Qingzhe Jiang'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/twec.12898?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/twec.12898, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","significant difference in the emission–renewables nexus across countries with different income levels is frequently ignored in previous studies. to empirically investigate whether the effect of renewable energy consumption on carbon dioxide (co2) emissions differs across countries with different income levels, the emission–growth–renewables nexus for a global panel of 120 countries and four income‐based subpanels over the period 1995–2015 is examined. fully considering the potential cross‐sectional dependence and slope heterogeneity, a series of econometric techniques allowing for cross‐sectional dependence and slope heterogeneity is utilised. cross‐sectional dependence and slope heterogeneity are confirmed for the global panel as well as for all four subpanels. only for the global panel, high‐income subpanel and upper‐middle‐income subpanel is the environmental kuznets curve (ekc) hypothesis valid. renewable energy consumption has a negative effect on co2 emissions, but its effect is not significant; the mitigation effect may be obscured by higher economic growth and increasing non‐renewable energy consumption. the global panel and four subpanels provide mixed directionality of causality among the variables, suggesting that for various income‐based subpanels, significant differences exist in the effect of renewable energy consumption on co2 emissions, especially highlighting in various direct and indirect influencing paths between renewable energy consumption and co2 emissions.",
f6e1181a4f3e23a52e795847c0cfd67dfd60cdc5,Alkaline Water Electrolysis Powered by Renewable Energy: A Review,"Alkaline water electrolysis is a key technology for large-scale hydrogen production powered by renewable energy. As conventional electrolyzers are designed for operation at fixed process conditions, the implementation of fluctuating and highly intermittent renewable energy is challenging. This contribution shows the recent state of system descriptions for alkaline water electrolysis and renewable energies, such as solar and wind power. Each component of a hydrogen energy system needs to be optimized to increase the operation time and system efficiency. Only in this way can hydrogen produced by electrolysis processes be competitive with the conventional path based on fossil energy sources. Conventional alkaline water electrolyzers show a limited part-load range due to an increased gas impurity at low power availability. As explosive mixtures of hydrogen and oxygen must be prevented, a safety shutdown is performed when reaching specific gas contamination. Furthermore, the cell voltage should be optimized to maintain a high efficiency. While photovoltaic panels can be directly coupled to alkaline water electrolyzers, wind turbines require suitable converters with additional losses. By combining alkaline water electrolysis with hydrogen storage tanks and fuel cells, power grid stabilization can be performed. As a consequence, the conventional spinning reserve can be reduced, which additionally lowers the carbon dioxide emissions.",2020,"[{'authorId': '1580503740', 'name': 'J. Brauns'}, {'authorId': '47154710', 'name': 'T. Turek'}]","{'url': 'https://www.mdpi.com/2227-9717/8/2/248/pdf?version=1582684442', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/pr8020248?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/pr8020248, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","alkaline water electrolysis is a key technology for large-scale hydrogen production powered by renewable energy. as conventional electrolyzers are designed for operation at fixed process conditions, the implementation of fluctuating and highly intermittent renewable energy is challenging. this contribution shows the recent state of system descriptions for alkaline water electrolysis and renewable energies, such as solar and wind power. each component of a hydrogen energy system needs to be optimized to increase the operation time and system efficiency. only in this way can hydrogen produced by electrolysis processes be competitive with the conventional path based on fossil energy sources. conventional alkaline water electrolyzers show a limited part-load range due to an increased gas impurity at low power availability. as explosive mixtures of hydrogen and oxygen must be prevented, a safety shutdown is performed when reaching specific gas contamination. furthermore, the cell voltage should be optimized to maintain a high efficiency. while photovoltaic panels can be directly coupled to alkaline water electrolyzers, wind turbines require suitable converters with additional losses. by combining alkaline water electrolysis with hydrogen storage tanks and fuel cells, power grid stabilization can be performed. as a consequence, the conventional spinning reserve can be reduced, which additionally lowers the carbon dioxide emissions.",https://www.mdpi.com/2227-9717/8/2/248/pdf?version=1582684442
95e35289c5832f91549e66806e4d16696aeb9bfc,Assessment of the Public Acceptance and Utilization of Renewable Energy in Pakistan,"Abstract The acceptance of renewable energy technologies is a complicated and multifaceted process influenced by a broad range of factors. Therefore, this study aims to examine the factors influencing consumer intention to utilize renewable energy (RE). Moreover, the current research highlights the factors that encourage or discourage consumers from utilizing RE by expanding the structural context of the Theory of Planned Behavior (TPB) by integrating three new considerations (the perception of self-effectiveness, beliefs about the benefits of RE, and perception about neighbor participation). The data used for analysis were collected from 351 households in four large cities, including Rawalpindi, Lahore, Gujranwala, and Faisalabad, in Pakistan. We utilized the Structural Equation Modeling (SEM) approach to check the relationship between constructs and latent variables. The results reveal that the driving factors, i.e., the perception of self-effectiveness, awareness, and perception about neighbor participation have significant and positive effects on consumer intention to utilize RE. However, consumer beliefs related to the cost of RE utilization have a negative effect on their intention to utilize RE. More interestingly, it was observed that beliefs about the benefits of RE and environmental concern have insignificant effects. The outcomes of this study can assist policy makers, experts and consumers in understanding renewable energy consumption and gaining awareness about environmental problems while simultaneously improving environmental sustainability practices.",2021,"[{'authorId': '103188435', 'name': 'M. Irfan'}, {'authorId': '143833191', 'name': 'Y. Hao'}, {'authorId': '1491791260', 'name': 'M. Ikram'}, {'authorId': '2004582860', 'name': 'Haitao Wu'}, {'authorId': '8075006', 'name': 'R. Akram'}, {'authorId': '2132084113', 'name': 'Abdul Rauf'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3811627?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3811627, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the acceptance of renewable energy technologies is a complicated and multifaceted process influenced by a broad range of factors. therefore, this study aims to examine the factors influencing consumer intention to utilize renewable energy (re). moreover, the current research highlights the factors that encourage or discourage consumers from utilizing re by expanding the structural context of the theory of planned behavior (tpb) by integrating three new considerations (the perception of self-effectiveness, beliefs about the benefits of re, and perception about neighbor participation). the data used for analysis were collected from 351 households in four large cities, including rawalpindi, lahore, gujranwala, and faisalabad, in pakistan. we utilized the structural equation modeling (sem) approach to check the relationship between constructs and latent variables. the results reveal that the driving factors, i.e., the perception of self-effectiveness, awareness, and perception about neighbor participation have significant and positive effects on consumer intention to utilize re. however, consumer beliefs related to the cost of re utilization have a negative effect on their intention to utilize re. more interestingly, it was observed that beliefs about the benefits of re and environmental concern have insignificant effects. the outcomes of this study can assist policy makers, experts and consumers in understanding renewable energy consumption and gaining awareness about environmental problems while simultaneously improving environmental sustainability practices.",
47e1e88ac536b6b7d4aa16009b3a350a2225bb6c,The impact of financial development and geopolitical risk on renewable energy consumption: evidence from emerging markets,"In the past three decades, the significance of large industrialized emerging economies has been highlighted. In terms of economic productivity and CO2 emissions, these markets play an important role in the global environment. Hence, to achieve global environmental needs, transition to renewable energy sources is essential. However, financial constraints along with geopolitical risks could act as possible barriers to the required transition. Thereby, in this paper, we aim to assess the impact of financial development and geopolitical risk on renewable energy consumption in emerging markets from 1996 to 2015. A two-step system GMM is tested, revealing a positive significant effect of financial development on transition to renewable energy. Moreover, contrary to the expected negative effect of geopolitical risk, our results reveal significant positive effect of geopolitical risk on renewable energy consumption. We highlight that the effects of both financial development and geopolitical risk are more pronounced in the long run. Finally, imperative policy implications are highlighted.",2021,"[{'authorId': '120771620', 'name': 'Naif Alsagr'}, {'authorId': '2047151339', 'name': 'S. V. van Hemmen'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11356-021-12447-2.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7817766, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the past three decades, the significance of large industrialized emerging economies has been highlighted. in terms of economic productivity and co2 emissions, these markets play an important role in the global environment. hence, to achieve global environmental needs, transition to renewable energy sources is essential. however, financial constraints along with geopolitical risks could act as possible barriers to the required transition. thereby, in this paper, we aim to assess the impact of financial development and geopolitical risk on renewable energy consumption in emerging markets from 1996 to 2015. a two-step system gmm is tested, revealing a positive significant effect of financial development on transition to renewable energy. moreover, contrary to the expected negative effect of geopolitical risk, our results reveal significant positive effect of geopolitical risk on renewable energy consumption. we highlight that the effects of both financial development and geopolitical risk are more pronounced in the long run. finally, imperative policy implications are highlighted.",https://link.springer.com/content/pdf/10.1007/s11356-021-12447-2.pdf
aea100d17dfeef8bb204984481d322ec382c9fcc,Role of Export Diversification and Renewable Energy on the Load Capacity Factor in Indonesia: A Fourier Quantile Causality Approach,"Sustainable development and reducing environmental pressure are major issues that concern developed as well as developing countries. Although researchers widely use carbon dioxide emissions and ecological footprint within the scope of environmental degradation, a more comprehensive ecological indicator is needed to assess environmental sustainability. In this context, the load capacity factor enables a comprehensive environmental sustainability assessment through the simultaneous analysis of biocapacity and ecological footprint. However, there are few studies analyzing the determinants of load capacity factor and this study aims to fill this gap for Indonesia. Using the recently developed Fourier quantile causality test, this study investigates the impact of income, export diversification, non-renewable and renewable energy consumption on the load capacity factor for Indonesia during 1965Q1–2014Q4. The results show unidirectional causality from non-renewable energy consumption to the load capacity factor at all quantiles, while income, export diversification, and renewable energy are the causes of environmental quality at middle and higher quantiles (within 0.5, 0.7, and 0.9). Most importantly, renewable energy and export diversification increase the load capacity factor and thus support environmental quality. In contrast, an increase in income and consumption of non-renewable energy reduces the load capacity factor. These results highlight the importance of renewable energy and export diversification for the sustainable development of Indonesia.",2021,"[{'authorId': '9347680', 'name': 'Zeeshan Fareed'}, {'authorId': '2004289621', 'name': 'Sultan Salem'}, {'authorId': '1742465570', 'name': 'T. Adebayo'}, {'authorId': '32110592', 'name': 'U. Pata'}, {'authorId': '38646221', 'name': 'F. Shahzad'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fenvs.2021.770152/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3389/fenvs.2021.770152?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3389/fenvs.2021.770152, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","sustainable development and reducing environmental pressure are major issues that concern developed as well as developing countries. although researchers widely use carbon dioxide emissions and ecological footprint within the scope of environmental degradation, a more comprehensive ecological indicator is needed to assess environmental sustainability. in this context, the load capacity factor enables a comprehensive environmental sustainability assessment through the simultaneous analysis of biocapacity and ecological footprint. however, there are few studies analyzing the determinants of load capacity factor and this study aims to fill this gap for indonesia. using the recently developed fourier quantile causality test, this study investigates the impact of income, export diversification, non-renewable and renewable energy consumption on the load capacity factor for indonesia during 1965q1–2014q4. the results show unidirectional causality from non-renewable energy consumption to the load capacity factor at all quantiles, while income, export diversification, and renewable energy are the causes of environmental quality at middle and higher quantiles (within 0.5, 0.7, and 0.9). most importantly, renewable energy and export diversification increase the load capacity factor and thus support environmental quality. in contrast, an increase in income and consumption of non-renewable energy reduces the load capacity factor. these results highlight the importance of renewable energy and export diversification for the sustainable development of indonesia.",https://www.frontiersin.org/articles/10.3389/fenvs.2021.770152/pdf
097b7296cfa19f212782d947a6c3ec3c76cacdf0,A Critical Review of Sustainable Energy Policies for the Promotion of Renewable Energy Sources,"Meeting the rising energy demand and limiting its environmental impact are the two intertwined issues faced in the 21st century. Governments in different countries have been engaged in developing regulations and related policies to encourage environment friendly renewable energy generation along with conservation strategies and technological innovations. It is important to develop sustainable energy policies and provide relevant and suitable policy recommendations for end-users. This study presents a review on sustainable energy policy for promotion of renewable energy by introducing the development history of energy policy in five countries, i.e., the United States, Germany, the United Kingdom, Denmark and China. A survey of the articles aimed at promoting the development of sustainable energy policies and their modelling is carried out. It is observed that energy-efficiency standard is one of the most popular strategy for building energy saving, which is dynamic and renewed based on the current available technologies. Feed-in-tariff has been widely applied to encourage the application of renewable energy, which is demonstrated successfully in different countries. Building energy performance certification schemes should be enhanced in terms of reliable database system and information transparency to pave the way for future net-zero energy building and smart cities.",2020,"[{'authorId': '48518090', 'name': 'Yuehong Lu'}, {'authorId': '30115568', 'name': 'Z. Khan'}, {'authorId': '1409901879', 'name': 'Manuel S. Alvarez‐Alvarado'}, {'authorId': '2145955554', 'name': 'Yang Zhang'}, {'authorId': '40629197', 'name': 'Zhijia Huang'}, {'authorId': '2143706101', 'name': 'M. Imran'}]","{'url': 'https://www.mdpi.com/2071-1050/12/12/5078/pdf?version=1592906762', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su12125078?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su12125078, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","meeting the rising energy demand and limiting its environmental impact are the two intertwined issues faced in the 21st century. governments in different countries have been engaged in developing regulations and related policies to encourage environment friendly renewable energy generation along with conservation strategies and technological innovations. it is important to develop sustainable energy policies and provide relevant and suitable policy recommendations for end-users. this study presents a review on sustainable energy policy for promotion of renewable energy by introducing the development history of energy policy in five countries, i.e., the united states, germany, the united kingdom, denmark and china. a survey of the articles aimed at promoting the development of sustainable energy policies and their modelling is carried out. it is observed that energy-efficiency standard is one of the most popular strategy for building energy saving, which is dynamic and renewed based on the current available technologies. feed-in-tariff has been widely applied to encourage the application of renewable energy, which is demonstrated successfully in different countries. building energy performance certification schemes should be enhanced in terms of reliable database system and information transparency to pave the way for future net-zero energy building and smart cities.",https://www.mdpi.com/2071-1050/12/12/5078/pdf?version=1592906762
681729b5d358aefb7453139b4d22c00a1624ae21,Investigating the role of environmental taxes and regulations for renewable energy consumption: evidence from developed economies,"Abstract The current study aims to explore the role of environmental taxes and regulations for the renewable energy consumption, focusing on reporting policy suggestions to overcome climate change issues and achieve environmental sustainability. The main objective of this paper is to examine the relation between renewable energy, environmental taxes, environmental technologies, and environmental regulations in 29 OECD countries during 1996–2018. More precisely, we inspect the impact of the environmental regulations and environmental technologies on the renewable energy consumption. The authors employ CIPS and CADF unit root tests, panel Westerlund co-integration test, FMOLS, and Quantile regression methods for the econometric analysis. The econometric analysis suggests that the environmental regulations impede the renewable energy consumption in OECD economies. The study suggests that environmental policy initiatives should focus on implementing environmental strategies to inspire cohesiveness between environmental regulations and the development of environmental technologies in order to promote the renewables industry in the developed countries.",2021,"[{'authorId': '48415295', 'name': 'M. F. Bashir'}, {'authorId': '48223769', 'name': 'Ben-jiang Ma'}, {'authorId': '145198877', 'name': 'M. Bashir'}, {'authorId': '37270470', 'name': 'M. Radulescu'}, {'authorId': '8654822', 'name': 'Umer Shahzad'}]","{'url': 'https://doi.org/10.1080/1331677x.2021.1962383', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/1331677X.2021.1962383?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/1331677X.2021.1962383, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the current study aims to explore the role of environmental taxes and regulations for the renewable energy consumption, focusing on reporting policy suggestions to overcome climate change issues and achieve environmental sustainability. the main objective of this paper is to examine the relation between renewable energy, environmental taxes, environmental technologies, and environmental regulations in 29 oecd countries during 1996–2018. more precisely, we inspect the impact of the environmental regulations and environmental technologies on the renewable energy consumption. the authors employ cips and cadf unit root tests, panel westerlund co-integration test, fmols, and quantile regression methods for the econometric analysis. the econometric analysis suggests that the environmental regulations impede the renewable energy consumption in oecd economies. the study suggests that environmental policy initiatives should focus on implementing environmental strategies to inspire cohesiveness between environmental regulations and the development of environmental technologies in order to promote the renewables industry in the developed countries.",https://doi.org/10.1080/1331677x.2021.1962383
06ea016ce74c778dd8b466ff49eb5c163ee73c48,ADVANTAGES AND DISADVANTAGES OF RENEWABLE ENERGY SOURCES UTILIZATION,"Renewable energy sources are still not the predominant energy resource in the energy sector, although in certain developed countries they participate in a significant share in electricity generation. It is estimated that world energy consumption from renewable energy sources exceeds 20% at the present and continues to grow. Renewable energy sources appear as an additional source of energy in the conventional electro-industry. The main reason for the increasing investment and exploitation of renewables is certainly environment preservation and environmental aspect of sustainability. This study seeks to expand the existing literature and contribute to a comprehensive understanding of the characteristics of renewable energy sources as a whole. Therefore, the purpose of this paper is to determine the advantages and disadvantages of renewable energy sources utilization in general, without considering the individual type of renewables, such as wind or solar energy. Thereby, the paper presents numerous advantages of using renewable energy in the electricity generation, such as environment preservation in terms of reduced greenhouse gas emissions or improvement of innovations and technical/technological development. There are also presented certain disadvantages of renewables in the production of electricity, such as dependence on weather conditions or low energy efficiency and low ability to produce electricity.",2021,"[{'authorId': '107921958', 'name': 'D. Maradin'}]","{'url': 'https://econjournals.com/index.php/ijeep/article/download/11027/5802', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.32479/IJEEP.11027?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.32479/IJEEP.11027, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","renewable energy sources are still not the predominant energy resource in the energy sector, although in certain developed countries they participate in a significant share in electricity generation. it is estimated that world energy consumption from renewable energy sources exceeds 20% at the present and continues to grow. renewable energy sources appear as an additional source of energy in the conventional electro-industry. the main reason for the increasing investment and exploitation of renewables is certainly environment preservation and environmental aspect of sustainability. this study seeks to expand the existing literature and contribute to a comprehensive understanding of the characteristics of renewable energy sources as a whole. therefore, the purpose of this paper is to determine the advantages and disadvantages of renewable energy sources utilization in general, without considering the individual type of renewables, such as wind or solar energy. thereby, the paper presents numerous advantages of using renewable energy in the electricity generation, such as environment preservation in terms of reduced greenhouse gas emissions or improvement of innovations and technical/technological development. there are also presented certain disadvantages of renewables in the production of electricity, such as dependence on weather conditions or low energy efficiency and low ability to produce electricity.",https://econjournals.com/index.php/ijeep/article/download/11027/5802
3d11d05dca3e9504b544dcd35b6c4bbe0d72e5b1,"Inequality, Finance and Renewable Energy Consumption in Sub-Saharan Africa","The study investigates linkages between financial development, income inequality and renewable energy consumption from 39 countries in Sub-Saharan Africa. The empirical evidence is based on data for the period 2004-2014, Generalized Method of Moments (GMM) and Quantile Regressions (QR). The GMM results show that financial development unconditionally promotes renewable energy consumption while income inequality counteracts the underlying positive effect. The QR results reveal that the GMM findings only withstand empirical validity in bottom quantiles of the renewable energy consumption distribution. In order to increase room for policy implications for the promotion of renewable energy consumption, critical masses of income inequality that should not be exceeded are computed for bottom quantiles of the renewable energy consumption distribution while income inequality thresholds that should be exceeded are computed for top quantiles of the renewable energy consumption distribution. The study reconciles two strands of the literature. Theoretical, practical and policy implications are discussed.",2020,"[{'authorId': '5102164', 'name': 'S. Asongu'}, {'authorId': '2059461', 'name': 'N. Odhiambo'}]","{'url': 'http://publications.resanet.org/RePEc/abh/abh-wpaper/Inequality-Finance-and-Renewable-Energy-Consumption-in-Sub-Saharan-Africa.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3729336?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3729336, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the study investigates linkages between financial development, income inequality and renewable energy consumption from 39 countries in sub-saharan africa. the empirical evidence is based on data for the period 2004-2014, generalized method of moments (gmm) and quantile regressions (qr). the gmm results show that financial development unconditionally promotes renewable energy consumption while income inequality counteracts the underlying positive effect. the qr results reveal that the gmm findings only withstand empirical validity in bottom quantiles of the renewable energy consumption distribution. in order to increase room for policy implications for the promotion of renewable energy consumption, critical masses of income inequality that should not be exceeded are computed for bottom quantiles of the renewable energy consumption distribution while income inequality thresholds that should be exceeded are computed for top quantiles of the renewable energy consumption distribution. the study reconciles two strands of the literature. theoretical, practical and policy implications are discussed.",http://publications.resanet.org/RePEc/abh/abh-wpaper/Inequality-Finance-and-Renewable-Energy-Consumption-in-Sub-Saharan-Africa.pdf
9d0f14a87ac6a56638f84711fb6ca8ebea2fbc30,The dynamics of green supply chain management within the framework of renewable energy,"This study provides an overview of green supply chain management (GSCM) in the context of renewable energy sources. Thus, it establishes a green management standard with GSCM that companies can adopt. The environmental, economic, and social components determine the concept of GSCM. However, the development and commercialization of renewable energy and sustainable manufacturing practices play a fundamental role in shaping the traditional supply chain management (SCM) and business models. GSCM means that firms and organizations must balance economic and environmental performance to stay competitive, and conform with regulatory and community pressures. This has forced enterprises to design and implement strategies such as eco‐efficiency, greener production, and cleaner environmental practices, for green management practices, which aim at reducing the environmental impacts of their operations. This study further highlights insights needed to significantly improve performance and overcome barriers to the development of renewable energy green supply chain management (REGSCM). It also presents useful techniques by outlining better control chain costs to make renewable energy more affordable and efficient, and a new conceptual model that is mainly grounded within the network of distributed energy systems in the context of GSCM. This concept allows renewable energy producers to sell their surplus electricity based on a peer‐to‐peer (P2P) network or sell directly via the general market. Specifically, this model brings to bear the linkages to the creation of value by firms.",2021,"[{'authorId': '32124500', 'name': 'S. Gawusu'}, {'authorId': '49469323', 'name': 'Xiaobing Zhang'}, {'authorId': '2134330729', 'name': 'Seidu Abdulai Jamatutu'}, {'authorId': '2011716726', 'name': 'A. Ahmed'}, {'authorId': '90689331', 'name': 'A. A. Amadu'}, {'authorId': '2123920794', 'name': 'Elvis Djam Miensah'}]","{'url': 'https://doi.org/10.1002/er.7278', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/er.7278?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/er.7278, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study provides an overview of green supply chain management (gscm) in the context of renewable energy sources. thus, it establishes a green management standard with gscm that companies can adopt. the environmental, economic, and social components determine the concept of gscm. however, the development and commercialization of renewable energy and sustainable manufacturing practices play a fundamental role in shaping the traditional supply chain management (scm) and business models. gscm means that firms and organizations must balance economic and environmental performance to stay competitive, and conform with regulatory and community pressures. this has forced enterprises to design and implement strategies such as eco‐efficiency, greener production, and cleaner environmental practices, for green management practices, which aim at reducing the environmental impacts of their operations. this study further highlights insights needed to significantly improve performance and overcome barriers to the development of renewable energy green supply chain management (regscm). it also presents useful techniques by outlining better control chain costs to make renewable energy more affordable and efficient, and a new conceptual model that is mainly grounded within the network of distributed energy systems in the context of gscm. this concept allows renewable energy producers to sell their surplus electricity based on a peer‐to‐peer (p2p) network or sell directly via the general market. specifically, this model brings to bear the linkages to the creation of value by firms.",https://doi.org/10.1002/er.7278
ad8781d54db7ad36e0ccdeddaf28faa713685565,Impact of Energy Storage on Renewable Energy Utilization: A Geometric Description,"The high penetration of volatile renewable energy challenges power system operation. Energy storage units (ESUs) can shift the demand over time and compensate real-time discrepancy between generation and demand, and thus improve system operation flexibility and reduce renewable energy curtailment. This paper proposes two parametric optimization models to quantify how the power (MW) and energy (MWh) capacity of ESU would impact renewable energy utilization from two aspects: renewable energy curtailment and system flexibility for uncertainty mitigation. The two indicators are characterized as multivariate functions in the capacity parameters of ESUs. A severity ranking algorithm is suggested to pick up critical scenarios of fluctuation patterns from the uncertainty set; consequently, the proposed models come down to multi-parametric mixed-integer linear programs (mp-MILPs) which can be solved by a decomposition algorithm. The proposed method provides analytical expressions of the two indicators as functions in MW and MWh capacity. Such a characterization delivers abundant sensitivity information on the impact of ESU capacity parameters, and provides a powerful tool for visualization and useful reference for storage sizing. Case studies verify the effectiveness of the proposed method and demonstrate how to use the geometric information.",2021,"[{'authorId': '1934675547', 'name': 'Zhongjie Guo'}, {'authorId': '2049474785', 'name': 'Wei Wei'}, {'authorId': '2429690', 'name': 'Laijun Chen'}, {'authorId': '144402926', 'name': 'Z. Dong'}, {'authorId': '145158560', 'name': 'S. Mei'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TSTE.2020.3023498?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TSTE.2020.3023498, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the high penetration of volatile renewable energy challenges power system operation. energy storage units (esus) can shift the demand over time and compensate real-time discrepancy between generation and demand, and thus improve system operation flexibility and reduce renewable energy curtailment. this paper proposes two parametric optimization models to quantify how the power (mw) and energy (mwh) capacity of esu would impact renewable energy utilization from two aspects: renewable energy curtailment and system flexibility for uncertainty mitigation. the two indicators are characterized as multivariate functions in the capacity parameters of esus. a severity ranking algorithm is suggested to pick up critical scenarios of fluctuation patterns from the uncertainty set; consequently, the proposed models come down to multi-parametric mixed-integer linear programs (mp-milps) which can be solved by a decomposition algorithm. the proposed method provides analytical expressions of the two indicators as functions in mw and mwh capacity. such a characterization delivers abundant sensitivity information on the impact of esu capacity parameters, and provides a powerful tool for visualization and useful reference for storage sizing. case studies verify the effectiveness of the proposed method and demonstrate how to use the geometric information.",
91990159a2941a1c5cc896f13e31209b681af0ae,A Review on Energy and Renewable Energy Policies in Iran,"Iran, endowed with abundant renewable and non-renewable energy resources, particularly non-renewable resources, faces challenges such as air pollution, climate change and energy security. As a leading exporter and consumer of fossil fuels, it is also attempting to use renewable energy as part of its energy mix toward energy security and sustainability. Due to its favorable geographic characteristics, Iran has diverse and accessible renewable sources, which provide appropriate substitutes to reduce dependence on fossil fuels. Therefore, this study aims to examine trends in energy demand, policies and development of renewable energies and the causal relationship between renewable and non-renewable energies and economic growth using two methodologies. This study first reviews the current state of energy and energy policies and then employs Granger causality analysis to test the relationships between the variables considered. Results showed that renewable energy technologies currently do not have a significant and adequate role in the energy supply of Iran. To encourage the use of renewable energy, especially in electricity production, fuel diversification policies and development program goals were introduced in the late 2000s and early 2010s. Diversifying energy resources is a key pillar of Iran’s new plan. In addition to solar and hydropower, biomass from the municipal waste from large cities and other agricultural products, including fruits, can be used to generate energy and renewable sources. While present policies indicate the incorporation of sustainable energy sources, further efforts are needed to offset the use of fossil fuels. Moreover, the study predicts that with the production capacity of agricultural products in 2018, approximately 4.8 billion liters of bioethanol can be obtained from crop residues and about 526 thousand tons of biodiesel from oilseeds annually. Granger’s causality analysis also shows that there is a unidirectional causal relationship between economic growth to renewable and non-renewable energy use. Labor force and gross fixed capital formation cause renewable energy consumption, and nonrenewable energy consumption causes renewable energy consumption.",2021,"[{'authorId': '2455642', 'name': 'S. Solaymani'}]","{'url': 'https://www.mdpi.com/2071-1050/13/13/7328/pdf?version=1625046400', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su13137328?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su13137328, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","iran, endowed with abundant renewable and non-renewable energy resources, particularly non-renewable resources, faces challenges such as air pollution, climate change and energy security. as a leading exporter and consumer of fossil fuels, it is also attempting to use renewable energy as part of its energy mix toward energy security and sustainability. due to its favorable geographic characteristics, iran has diverse and accessible renewable sources, which provide appropriate substitutes to reduce dependence on fossil fuels. therefore, this study aims to examine trends in energy demand, policies and development of renewable energies and the causal relationship between renewable and non-renewable energies and economic growth using two methodologies. this study first reviews the current state of energy and energy policies and then employs granger causality analysis to test the relationships between the variables considered. results showed that renewable energy technologies currently do not have a significant and adequate role in the energy supply of iran. to encourage the use of renewable energy, especially in electricity production, fuel diversification policies and development program goals were introduced in the late 2000s and early 2010s. diversifying energy resources is a key pillar of iran’s new plan. in addition to solar and hydropower, biomass from the municipal waste from large cities and other agricultural products, including fruits, can be used to generate energy and renewable sources. while present policies indicate the incorporation of sustainable energy sources, further efforts are needed to offset the use of fossil fuels. moreover, the study predicts that with the production capacity of agricultural products in 2018, approximately 4.8 billion liters of bioethanol can be obtained from crop residues and about 526 thousand tons of biodiesel from oilseeds annually. granger’s causality analysis also shows that there is a unidirectional causal relationship between economic growth to renewable and non-renewable energy use. labor force and gross fixed capital formation cause renewable energy consumption, and nonrenewable energy consumption causes renewable energy consumption.",https://www.mdpi.com/2071-1050/13/13/7328/pdf?version=1625046400
67a2345899a372e9d0f7d428461a1c24568c4054,Ethiopia renewable energy potentials and current state,"Ethiopia is endowed with abundant renewable energy resources, which can meet the ambitions of nationwide electrification. However, in spite of all its available potentials the country energy sector is still in its infancy stage. The majority of Ethiopia population lives in the rural area without access to modern energy and relied solely on traditional biomass energy sources. Nowadays Ethiopia has one of the lowest electricity consumption per capita in Africa. Recognizing that energy access and security are a crucial factor to economic growth; Ethiopia needs to cope with key challenges related to energy security and diversification of energy supply. This paper provides a comprehensive and extensive review of renewable energy potentials in Ethiopia. Further, current state of renewable energy resources is described and existing energy policies are articulated. Various policies, that could possibly promote energy technology use in a rural Ethiopia, are proposed. Finally, this paper helps the researchers as well as the government officials to find the better renewable energy technology to meet rural community energy demand; by raising awareness of the country energy potentials and current state of renewable energy, along with proposing pragmatic recommendations.",2021,"[{'authorId': '2041889596', 'name': 'A. D. Hailu'}, {'authorId': '2150241290', 'name': 'Desta Kalbessa Kumsa'}]","{'url': 'https://doi.org/10.3934/energy.2021001', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3934/energy.2021001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3934/energy.2021001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ethiopia is endowed with abundant renewable energy resources, which can meet the ambitions of nationwide electrification. however, in spite of all its available potentials the country energy sector is still in its infancy stage. the majority of ethiopia population lives in the rural area without access to modern energy and relied solely on traditional biomass energy sources. nowadays ethiopia has one of the lowest electricity consumption per capita in africa. recognizing that energy access and security are a crucial factor to economic growth; ethiopia needs to cope with key challenges related to energy security and diversification of energy supply. this paper provides a comprehensive and extensive review of renewable energy potentials in ethiopia. further, current state of renewable energy resources is described and existing energy policies are articulated. various policies, that could possibly promote energy technology use in a rural ethiopia, are proposed. finally, this paper helps the researchers as well as the government officials to find the better renewable energy technology to meet rural community energy demand; by raising awareness of the country energy potentials and current state of renewable energy, along with proposing pragmatic recommendations.",https://doi.org/10.3934/energy.2021001
32a267534ffd57b6b5fe39d32dbe553daf987748,Does Board Gender Diversity Affect Renewable Energy Consumption?,"Abstract This paper examines the effect of board gender diversity on renewable energy consumption. Using a panel of 11,677 firm-year observations from the USA for 2008–2016, we find a positive relationship between board gender diversity and renewable energy consumption. Moreover, boards require two or more women for women to have a significant impact on renewable energy consumption, consistent with the critical mass theory. Further, we document that the positive impact of female directors on renewable energy consumption stems from female independent rather than female executive directors. Finally, we find a positive effect of the interaction between renewable energy consumption and board gender diversity on firm financial performance. Our findings are robust to different identification strategies and estimation techniques.",2020,"[{'authorId': '1380375502', 'name': 'Muhammad Atif'}, {'authorId': '1515624412', 'name': 'Mohammed Hossain'}, {'authorId': '49885190', 'name': 'M. Alam'}, {'authorId': '46223055', 'name': 'M. Goergen'}]","{'url': 'https://doi.org/10.1016/j.jcorpfin.2020.101665', 'status': 'CLOSED', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3428921?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3428921, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract this paper examines the effect of board gender diversity on renewable energy consumption. using a panel of 11,677 firm-year observations from the usa for 2008–2016, we find a positive relationship between board gender diversity and renewable energy consumption. moreover, boards require two or more women for women to have a significant impact on renewable energy consumption, consistent with the critical mass theory. further, we document that the positive impact of female directors on renewable energy consumption stems from female independent rather than female executive directors. finally, we find a positive effect of the interaction between renewable energy consumption and board gender diversity on firm financial performance. our findings are robust to different identification strategies and estimation techniques.",https://doi.org/10.1016/j.jcorpfin.2020.101665
cec2d6f8b3d22e4d90d23e64f3c9f0cf51efdc7d,"Evaluating the role of renewable energy, economic growth and agriculture on CO2 emission in E7 countries","ABSTRACT This study examines the dynamic links between per capita CO2 emission, economic growth, agricultural value added, renewable and non-renewable energy consumption and investigates the existence of Environmental Kuznets Curve (EKC) hypothesis for a panel of E7 countries spanning the period 1990–2014. The estimates indicate that there is a positive relationship between CO2 emissions and real GDP, non-renewable energy consumption and agricultural value added in the long run, whereas a negative relationship is represented between CO2 emissions and square of real GDP and renewable energy consumption. The results of long-run estimates support the inverted U-shape EKC in these selected countries. Regarding the Granger causality analysis, bi-directional Granger causality exists between non-renewable energy consumption and CO2 emissions in the long run. In regards policy implications and recommendations, E7 countries should keep on increasing the share of renewable energy for the sake of growth purposes in the agricultural sector, thereby reducing fossil energy consumption for environmental improvements.",2020,"[{'authorId': '100854021', 'name': 'Berna Aydoğan'}, {'authorId': '122160236', 'name': 'G. Vardar'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/14786451.2019.1686380?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/14786451.2019.1686380, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract this study examines the dynamic links between per capita co2 emission, economic growth, agricultural value added, renewable and non-renewable energy consumption and investigates the existence of environmental kuznets curve (ekc) hypothesis for a panel of e7 countries spanning the period 1990–2014. the estimates indicate that there is a positive relationship between co2 emissions and real gdp, non-renewable energy consumption and agricultural value added in the long run, whereas a negative relationship is represented between co2 emissions and square of real gdp and renewable energy consumption. the results of long-run estimates support the inverted u-shape ekc in these selected countries. regarding the granger causality analysis, bi-directional granger causality exists between non-renewable energy consumption and co2 emissions in the long run. in regards policy implications and recommendations, e7 countries should keep on increasing the share of renewable energy for the sake of growth purposes in the agricultural sector, thereby reducing fossil energy consumption for environmental improvements.",
c01e6d0801e92441004f29836b07704c66eabb54,Renewable energy: a bibliometric analysis,"The aims of this paper are to identify existing research on renewable energy; identify the most influential publications, authors, organizations to understand the research areas. The paper is centered on the bibliometric analysis based on the Web of Science database for the key phrase’ renewable energy’ in the article title until 2020. We analyzed the publications about renewable energy by years, by research areas, by geography, by research organizations and research sponsors, by journals, by citations of journals, authors, publications, co-occurrence by keywords. Analysis of the most cited publications and authors, analysis of cooccurrence by keywords was performed using VOSviewer. We performed hierarchical cluster analysis, and clusters were selected using VOSviewer. We found 17805 scientific publications on renewable energy published in scientific journals (51.7% of publications were published during 2016-2020). The most popular research areas are energy fuels, engineering, science technology, environmental sciences, ecology, and business economics. The majority of papers was published by the scientists from the United States, China, and India. In addition, we identified six main research clusters. They are related to an optimizer, renewable energy, biomass, co2 emissions, model, desalination. Conclusions: This analysis confirmed the author’s hypothesis about the definition of new scientific horizons of renewable energy research. Our results can help scientists interested in renewable energy looking for research funding and research project risks based on renewable energy.",2021,"[{'authorId': '2079428069', 'name': 'A. Rosokhata'}, {'authorId': '2100943971', 'name': 'M. Minchenko'}, {'authorId': '39610404', 'name': 'L. Khomenko'}, {'authorId': '91339923', 'name': 'O. Chygryn'}]","{'url': 'https://www.e3s-conferences.org/articles/e3sconf/pdf/2021/26/e3sconf_tresp2021_03002.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1051/E3SCONF/202125003002?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1051/E3SCONF/202125003002, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the aims of this paper are to identify existing research on renewable energy; identify the most influential publications, authors, organizations to understand the research areas. the paper is centered on the bibliometric analysis based on the web of science database for the key phrase’ renewable energy’ in the article title until 2020. we analyzed the publications about renewable energy by years, by research areas, by geography, by research organizations and research sponsors, by journals, by citations of journals, authors, publications, co-occurrence by keywords. analysis of the most cited publications and authors, analysis of cooccurrence by keywords was performed using vosviewer. we performed hierarchical cluster analysis, and clusters were selected using vosviewer. we found 17805 scientific publications on renewable energy published in scientific journals (51.7% of publications were published during 2016-2020). the most popular research areas are energy fuels, engineering, science technology, environmental sciences, ecology, and business economics. the majority of papers was published by the scientists from the united states, china, and india. in addition, we identified six main research clusters. they are related to an optimizer, renewable energy, biomass, co2 emissions, model, desalination. conclusions: this analysis confirmed the author’s hypothesis about the definition of new scientific horizons of renewable energy research. our results can help scientists interested in renewable energy looking for research funding and research project risks based on renewable energy.",https://www.e3s-conferences.org/articles/e3sconf/pdf/2021/26/e3sconf_tresp2021_03002.pdf
c2b1a15eab194c346b21ddbd6319172238702f1b,Review on the development scenario of renewable energy in different country,"To solve the environmental problems the choice of Renewable energy has become an important. The development in this field can improve energy efficiency and reduce greenhouse effect. this paper summarizes the renewable energy development situation, of the different country. The development trend of emerging renewable energy have been analyzed. In order to confirm that the development of renewable energy sources, it is necessary to modified energy market and also necessary to maintain the rationality of policy formulation. Proper education system and awareness on renewable energy helps the energy market in case of development. From this study it is found that a considerable experiment is going on renewable energy. This paper has established an idea about different renewable energy application, their development in different countries in the field of application and their solution.",2021,"[{'authorId': '2005881791', 'name': 'Subhodeep Paul'}, {'authorId': '74037673', 'name': 'Tathagata Dey'}, {'authorId': '1773448', 'name': 'P. Saha'}, {'authorId': '2143933554', 'name': 'Snehasish Dey'}, {'authorId': '2067136752', 'name': 'Ruma Sen'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/iemre52042.2021.9386748?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/iemre52042.2021.9386748, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","to solve the environmental problems the choice of renewable energy has become an important. the development in this field can improve energy efficiency and reduce greenhouse effect. this paper summarizes the renewable energy development situation, of the different country. the development trend of emerging renewable energy have been analyzed. in order to confirm that the development of renewable energy sources, it is necessary to modified energy market and also necessary to maintain the rationality of policy formulation. proper education system and awareness on renewable energy helps the energy market in case of development. from this study it is found that a considerable experiment is going on renewable energy. this paper has established an idea about different renewable energy application, their development in different countries in the field of application and their solution.",
88c57396a332db526340a600bf8a9928e3b1ef17,Renewable energy production will exacerbate mining threats to biodiversity,"Renewable energy production is necessary to halt climate change and reverse associated biodiversity losses. However, generating the required technologies and infrastructure will drive an increase in the production of many metals, creating new mining threats for biodiversity. Here, we map mining areas and assess their spatial coincidence with biodiversity conservation sites and priorities. Mining potentially influences 50 million km2 of Earth’s land surface, with 8% coinciding with Protected Areas, 7% with Key Biodiversity Areas, and 16% with Remaining Wilderness. Most mining areas (82%) target materials needed for renewable energy production, and areas that overlap with Protected Areas and Remaining Wilderness contain a greater density of mines (our indicator of threat severity) compared to the overlapping mining areas that target other materials. Mining threats to biodiversity will increase as more mines target materials for renewable energy production and, without strategic planning, these new threats to biodiversity may surpass those averted by climate change mitigation. Renewable energy production is necessary to mitigate climate change, however, generating the required technologies and infrastructure will demand huge production increases of many metals. Here, the authors map mining areas and assess spatial coincidence with biodiversity conservation sites, and show that new mining threats to biodiversity may surpass those averted by climate change mitigation.",2020,"[{'authorId': '4283129', 'name': 'Laura J. Sonter'}, {'authorId': '51989452', 'name': 'M. Dade'}, {'authorId': '2172620932', 'name': 'J. Watson'}, {'authorId': '2106839730', 'name': 'R. Valenta'}]","{'url': 'https://www.nature.com/articles/s41467-020-17928-5.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7463236, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","renewable energy production is necessary to halt climate change and reverse associated biodiversity losses. however, generating the required technologies and infrastructure will drive an increase in the production of many metals, creating new mining threats for biodiversity. here, we map mining areas and assess their spatial coincidence with biodiversity conservation sites and priorities. mining potentially influences 50 million km2 of earth’s land surface, with 8% coinciding with protected areas, 7% with key biodiversity areas, and 16% with remaining wilderness. most mining areas (82%) target materials needed for renewable energy production, and areas that overlap with protected areas and remaining wilderness contain a greater density of mines (our indicator of threat severity) compared to the overlapping mining areas that target other materials. mining threats to biodiversity will increase as more mines target materials for renewable energy production and, without strategic planning, these new threats to biodiversity may surpass those averted by climate change mitigation. renewable energy production is necessary to mitigate climate change, however, generating the required technologies and infrastructure will demand huge production increases of many metals. here, the authors map mining areas and assess spatial coincidence with biodiversity conservation sites, and show that new mining threats to biodiversity may surpass those averted by climate change mitigation.",https://www.nature.com/articles/s41467-020-17928-5.pdf
75a2e1dab04140f96215398f4ce3362086ef8cbb,"Reviewing Usage, Potentials, and Limitations of Renewable Energy Sources","The world’s ever-increasing population, combined with economic and technological growth and a new, modern way of life, has led to high energy demand and consumption. Fossil fuels have been the main energy source for many years, but their use has many negative impacts on the environment. This has made the transition to renewable energy sources necessary in order to address climate change and meet the 1.5 °C goal. This paper is a review of the different types of renewables, their potentials and limitations, and their connection to climate change, economic growth, and human health. It also examines consumers’ willingness to pay for renewables in different countries, based on the existing literature. IEA (International Energy Agency) data are analyzed, concerning renewables’ current use, the evolution of their usage, and forecasts about their future usage. Finally, policies and strategies are recommended in order to address climate change and fully integrate renewables as a sustainable energy source.",2020,"[{'authorId': '66751645', 'name': 'G. Halkos'}, {'authorId': '2006570260', 'name': 'Eleni-Christina Gkampoura'}]","{'url': 'https://www.mdpi.com/1996-1073/13/11/2906/pdf?version=1592019243', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/en13112906?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/en13112906, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the world’s ever-increasing population, combined with economic and technological growth and a new, modern way of life, has led to high energy demand and consumption. fossil fuels have been the main energy source for many years, but their use has many negative impacts on the environment. this has made the transition to renewable energy sources necessary in order to address climate change and meet the 1.5 °c goal. this paper is a review of the different types of renewables, their potentials and limitations, and their connection to climate change, economic growth, and human health. it also examines consumers’ willingness to pay for renewables in different countries, based on the existing literature. iea (international energy agency) data are analyzed, concerning renewables’ current use, the evolution of their usage, and forecasts about their future usage. finally, policies and strategies are recommended in order to address climate change and fully integrate renewables as a sustainable energy source.",https://www.mdpi.com/1996-1073/13/11/2906/pdf?version=1592019243
7979160cda79b584014d83872e5479ea86b6d35b,A Review of Energy Storage Technologies’ Application Potentials in Renewable Energy Sources Grid Integration,"Renewable energy sources (RESs) such as wind and solar are frequently hit by fluctuations due to, for example, insufficient wind or sunshine. Energy storage technologies (ESTs) mitigate the problem by storing excess energy generated and then making it accessible on demand. While there are various EST studies, the literature remains isolated and dated. The comparison of the characteristics of ESTs and their potential applications is also short. This paper fills this gap. Using selected criteria, it identifies key ESTs and provides an updated review of the literature on ESTs and their application potential to the renewable energy sector. The critical review shows a high potential application for Li-ion batteries and most fit to mitigate the fluctuation of RESs in utility grid integration sector. However, for Li-ion batteries to be fully adopted in the RESs utility grid integration, their cost needs to be reduced.",2020,"[{'authorId': '2022230342', 'name': 'Henok Ayele Behabtu'}, {'authorId': '31009483', 'name': 'M. Messagie'}, {'authorId': '4255385', 'name': 'T. Coosemans'}, {'authorId': '2462348', 'name': 'M. Berecibar'}, {'authorId': '3377415', 'name': 'Kinde Anlay Fante'}, {'authorId': '50282759', 'name': 'A. Kebede'}, {'authorId': '1909680', 'name': 'J. Mierlo'}]","{'url': 'https://www.mdpi.com/2071-1050/12/24/10511/pdf?version=1608105275', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su122410511?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su122410511, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","renewable energy sources (ress) such as wind and solar are frequently hit by fluctuations due to, for example, insufficient wind or sunshine. energy storage technologies (ests) mitigate the problem by storing excess energy generated and then making it accessible on demand. while there are various est studies, the literature remains isolated and dated. the comparison of the characteristics of ests and their potential applications is also short. this paper fills this gap. using selected criteria, it identifies key ests and provides an updated review of the literature on ests and their application potential to the renewable energy sector. the critical review shows a high potential application for li-ion batteries and most fit to mitigate the fluctuation of ress in utility grid integration sector. however, for li-ion batteries to be fully adopted in the ress utility grid integration, their cost needs to be reduced.",https://www.mdpi.com/2071-1050/12/24/10511/pdf?version=1608105275
b8651a5e032d30318de1841531b6b9b65a9cc454,High-Level Penetration of Renewable Energy Sources Into Grid Utility: Challenges and Solutions,"The utilization of renewable energy sources (RESs) has become significant throughout the world, especially over the last two decades. Although high-level RESs penetration reduces negative environmental impact compared to conventional fossil fuel-based energy generation, control issues become more complex as the system inertia is significantly decreased due to the absence of conventional synchronous generators. Some other technical issues, high uncertainties, low fault ride through capability, high fault current, low generation reserve, and low power quality, arise due to RESs integration. Renewable energy like solar and wind are highly uncertain due to the intermittent nature of wind and sunlight. Cutting edge technologies including different control strategies, optimization techniques, energy storage devices, and fault current limiters are employed to handle those issues. This paper summarizes several challenges in the integration process of high-level RESs to the existing grid. The respective solutions to each challenge are presented and discussed. A comprehensive list of challenges and solutions, for both wind and solar energy integration cases, are well documented. Finally, the future recommendations are provided to solve the several problems of renewable energy integration which could be key research areas for the industry personnel and researchers.",2020,"[{'authorId': '1738344', 'name': 'Md. Shafiul Alam'}, {'authorId': '2326970193', 'name': 'Fahad Alismail'}, {'authorId': '37571678', 'name': 'A. Salem'}, {'authorId': '145486763', 'name': 'M. A. Abido'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09224611.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2006.04638, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the utilization of renewable energy sources (ress) has become significant throughout the world, especially over the last two decades. although high-level ress penetration reduces negative environmental impact compared to conventional fossil fuel-based energy generation, control issues become more complex as the system inertia is significantly decreased due to the absence of conventional synchronous generators. some other technical issues, high uncertainties, low fault ride through capability, high fault current, low generation reserve, and low power quality, arise due to ress integration. renewable energy like solar and wind are highly uncertain due to the intermittent nature of wind and sunlight. cutting edge technologies including different control strategies, optimization techniques, energy storage devices, and fault current limiters are employed to handle those issues. this paper summarizes several challenges in the integration process of high-level ress to the existing grid. the respective solutions to each challenge are presented and discussed. a comprehensive list of challenges and solutions, for both wind and solar energy integration cases, are well documented. finally, the future recommendations are provided to solve the several problems of renewable energy integration which could be key research areas for the industry personnel and researchers.",https://ieeexplore.ieee.org/ielx7/6287639/8948470/09224611.pdf
d102e230efc2b279665a603d7be55ceff5318c4b,Oil price shocks and renewable energy transition: Empirical evidence from net oil-importing South Asian economies,"This paper makes a novel attempt to model the nonlinear association between renewable energy consumption and crude oil prices concerning four net oil-importing South Asian economies: Bangladesh, India, Pakistan and Sri Lanka. Using annual data from 1990 to 2018, the long-run elasticity estimates confirm the nonlinear nexus and suggest that although rising crude oil prices do not facilitate renewable energy consumption initially, upon reaching a threshold level of crude oil price, further hikes in the oil prices are likely to elevate the renewable energy consumption figures. The estimated real oil price threshold, in this regard, is predicted to be around 135 US dollars per barrel, which is way above the prevailing oil price level. Identical nonlinearity is also confirmed in the context of the oil prices and renewable energy share in total final energy consumption volumes. Moreover, the nexus between renewable electricity share in aggregate electricity outputs and crude oil prices is also seen to exhibit nonlinearity. However, rising crude oil prices were not found to enhance the renewable electricity shares. Besides, the causality results implicated that movements in crude oil prices influenced the renewable energy transition process across the concerned South Asian economies. Thus, these results, in a nutshell, impose critically important policy implications for attainment of energy security and environmental sustainability in South Asia, particularly via curbing the traditional imported crude oil-dependencies of these nations.",2020,"[{'authorId': '5017564', 'name': 'Muntasir Murshed'}, {'authorId': '1708177907', 'name': 'Muntaha Masud Tanha'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s40974-020-00168-0.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7240004, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper makes a novel attempt to model the nonlinear association between renewable energy consumption and crude oil prices concerning four net oil-importing south asian economies: bangladesh, india, pakistan and sri lanka. using annual data from 1990 to 2018, the long-run elasticity estimates confirm the nonlinear nexus and suggest that although rising crude oil prices do not facilitate renewable energy consumption initially, upon reaching a threshold level of crude oil price, further hikes in the oil prices are likely to elevate the renewable energy consumption figures. the estimated real oil price threshold, in this regard, is predicted to be around 135 us dollars per barrel, which is way above the prevailing oil price level. identical nonlinearity is also confirmed in the context of the oil prices and renewable energy share in total final energy consumption volumes. moreover, the nexus between renewable electricity share in aggregate electricity outputs and crude oil prices is also seen to exhibit nonlinearity. however, rising crude oil prices were not found to enhance the renewable electricity shares. besides, the causality results implicated that movements in crude oil prices influenced the renewable energy transition process across the concerned south asian economies. thus, these results, in a nutshell, impose critically important policy implications for attainment of energy security and environmental sustainability in south asia, particularly via curbing the traditional imported crude oil-dependencies of these nations.",https://link.springer.com/content/pdf/10.1007/s40974-020-00168-0.pdf
133a4145059573a3a883a9fa2f55cbbfd98c2a8d,Implementing a Just Renewable Energy Transition: Policy Advice for Transposing the New European Rules for Renewable Energy Communities,"Abstract The recast of the Renewable Energy Directive (RED II) provides an enabling framework for “Renewable Energy Communities” (RECs) that is being transposed into law by the 27 European Union Member States by June 2021. RECs are majority owned by local members or shareholders who are authorized to share energy within the community, offering the potential to unlock private investment and financing for renewable energy sources and provide social benefits. However, successful implementation and a just energy transition requires the coupling of technological solutions with more open decision making, based on sound analysis, knowledge of engineering, spatial planning, and social science. We argue that financing and ownership models that address renewable energy complementarity, spatial organization of resource potential, demographics, pushback from incumbents, and inclusion of traditionally marginalized groups, are common issues across all Member States that are crucial for the transposition of RED II and a just energy transition. This paper highlights the benefits and challenges of widespread development of RECs, and using examples from the pending transposition process provides policy advice for effective implementation of the RED II with respect to RECs.",2020,"[{'authorId': '98414677', 'name': 'C. Hoicka'}, {'authorId': '116368828', 'name': 'J. Lowitzsch'}, {'authorId': '36725014', 'name': 'M. Brisbois'}, {'authorId': '40632033', 'name': 'Ankit Kumar'}, {'authorId': '2353525457', 'name': 'Luis Ramirez Camargo'}]","{'url': 'https://figshare.com/articles/journal_contribution/Implementing_a_just_renewable_energy_transition_policy_advice_for_transposing_the_new_European_rules_for_Renewable_Energy_Communities/23482775/1/files/41191694.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3729512?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3729512, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the recast of the renewable energy directive (red ii) provides an enabling framework for “renewable energy communities” (recs) that is being transposed into law by the 27 european union member states by june 2021. recs are majority owned by local members or shareholders who are authorized to share energy within the community, offering the potential to unlock private investment and financing for renewable energy sources and provide social benefits. however, successful implementation and a just energy transition requires the coupling of technological solutions with more open decision making, based on sound analysis, knowledge of engineering, spatial planning, and social science. we argue that financing and ownership models that address renewable energy complementarity, spatial organization of resource potential, demographics, pushback from incumbents, and inclusion of traditionally marginalized groups, are common issues across all member states that are crucial for the transposition of red ii and a just energy transition. this paper highlights the benefits and challenges of widespread development of recs, and using examples from the pending transposition process provides policy advice for effective implementation of the red ii with respect to recs.",https://figshare.com/articles/journal_contribution/Implementing_a_just_renewable_energy_transition_policy_advice_for_transposing_the_new_European_rules_for_Renewable_Energy_Communities/23482775/1/files/41191694.pdf
0eb85eb760df3d9b865875423d1bafdbddb010f4,Stand-Alone Microgrid with 100% Renewable Energy: A Case Study with Hybrid Solar PV-Battery-Hydrogen,"A 100% renewable energy-based stand-alone microgrid system can be developed by robust energy storage systems to stabilize the variable and intermittent renewable energy resources. Hydrogen as an energy carrier and energy storage medium has gained enormous interest globally in recent years. Its use in stand-alone or off-grid microgrids for both the urban and rural communities has commenced recently in some locations. Therefore, this research evaluates the techno-economic feasibility of renewable energy-based systems using hydrogen as energy storage for a stand-alone/off-grid microgrid. Three case scenarios in a microgrid environment were identified and investigated in order to select an optimum solution for a remote community by considering the energy balance and techno-economic optimization. The “HOMER Pro” energy modelling and simulating software was used to compare the energy balance, economics and environmental impact amongst the proposed scenarios. The simulation results showed that the hydrogen-battery hybrid energy storage system is the most cost-effective scenario, though all developed scenarios are technically possible and economically comparable in the long run, while each has different merits and challenges. It has been shown that the proposed hybrid energy systems have significant potentialities in electrifying remote communities with low energy generation costs, as well as a contribution to the reduction of their carbon footprint and to ameliorating the energy crisis to achieve a sustainable future.",2020,"[{'authorId': '115162866', 'name': 'Furat Dawood'}, {'authorId': '3210830', 'name': 'G. Shafiullah'}, {'authorId': '144123090', 'name': 'M. Anda'}]","{'url': 'https://www.mdpi.com/2071-1050/12/5/2047/pdf?version=1583505485', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su12052047?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su12052047, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a 100% renewable energy-based stand-alone microgrid system can be developed by robust energy storage systems to stabilize the variable and intermittent renewable energy resources. hydrogen as an energy carrier and energy storage medium has gained enormous interest globally in recent years. its use in stand-alone or off-grid microgrids for both the urban and rural communities has commenced recently in some locations. therefore, this research evaluates the techno-economic feasibility of renewable energy-based systems using hydrogen as energy storage for a stand-alone/off-grid microgrid. three case scenarios in a microgrid environment were identified and investigated in order to select an optimum solution for a remote community by considering the energy balance and techno-economic optimization. the “homer pro” energy modelling and simulating software was used to compare the energy balance, economics and environmental impact amongst the proposed scenarios. the simulation results showed that the hydrogen-battery hybrid energy storage system is the most cost-effective scenario, though all developed scenarios are technically possible and economically comparable in the long run, while each has different merits and challenges. it has been shown that the proposed hybrid energy systems have significant potentialities in electrifying remote communities with low energy generation costs, as well as a contribution to the reduction of their carbon footprint and to ameliorating the energy crisis to achieve a sustainable future.",https://www.mdpi.com/2071-1050/12/5/2047/pdf?version=1583505485
5aa7cedaae5cb21f035ae92def0e97b4063d2f44,Effects of Covid-19 outbreak on environment and renewable energy sector,"Many articles have been written in the medical field related to the Covid-19 outbreak that has surrounded the World and killed many people. However, its environmental and energy impacts have not been sufficiently studied. Some sources argue that Covid-19 outbreak reduces pollution environmentally, while others say that environmentally significant damages await us. On the other hand, it is wondered how the global flexible renewable energy sector will react to Covid-19 outbreak. In this study, the effects of Covid-19 outbreak in terms of the environment and renewable energy sector in the literature were examined in detail and the findings obtained were discussed. The main aim of this study is to shed light on the future studies of environmental and renewable energy researchers.",2020,"[{'authorId': '93596309', 'name': 'H. Eroglu'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s10668-020-00837-4.pdf', 'status': 'HYBRID', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7321016, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","many articles have been written in the medical field related to the covid-19 outbreak that has surrounded the world and killed many people. however, its environmental and energy impacts have not been sufficiently studied. some sources argue that covid-19 outbreak reduces pollution environmentally, while others say that environmentally significant damages await us. on the other hand, it is wondered how the global flexible renewable energy sector will react to covid-19 outbreak. in this study, the effects of covid-19 outbreak in terms of the environment and renewable energy sector in the literature were examined in detail and the findings obtained were discussed. the main aim of this study is to shed light on the future studies of environmental and renewable energy researchers.",https://link.springer.com/content/pdf/10.1007/s10668-020-00837-4.pdf
1241f889302de7d9d6e9969f4ace5f0777b5b836,"Towards Sustainable Energy: A Systematic Review of Renewable Energy Sources, Technologies, and Public Opinions","The use of renewable energy resources, such as solar, wind, and biomass will not diminish their availability. Sunlight being a constant source of energy is used to meet the ever-increasing energy need. This review discusses the world’s energy needs, renewable energy technologies for domestic use, and highlights public opinions on renewable energy. A systematic review of the literature was conducted from 2009 to 2018. During this process, more than 300 articles were classified and 42 papers were filtered for critical review. The literature analysis showed that despite serious efforts at all levels to reduce reliance on fossil fuels by promoting renewable energy as its alternative, fossil fuels continue to contribute 73.5% to the worldwide electricity production in 2017. Conversely, renewable sources contributed only 26.5%. Furthermore, this study highlights that the lack of public awareness is a major barrier to the acceptance of renewable energy technologies. The results of this study show that worldwide energy crises can be managed by integrating renewable energy sources in the power generation. Moreover, in order to facilitate the development of renewable energy technologies, this systematic review has highlighted the importance of public opinion and performed a real-time analysis of public tweets. This example of tweet analysis is a relatively novel initiative in a review study that will seek to direct the attention of future researchers and policymakers toward public opinion and recommend the implications to both academia and industries.",2019,"[{'authorId': '34890777', 'name': 'Atika Qazi'}, {'authorId': '2065253348', 'name': 'Fayaz Hussain'}, {'authorId': '144563708', 'name': 'N. Rahim'}, {'authorId': '2806070', 'name': 'Glenn Hardaker'}, {'authorId': '2820987', 'name': 'D. Alghazzawi'}, {'authorId': '144251852', 'name': 'K. Shaban'}, {'authorId': '31838752', 'name': 'Khalid Haruna'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08721134.pdf', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2019.2906402?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2019.2906402, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the use of renewable energy resources, such as solar, wind, and biomass will not diminish their availability. sunlight being a constant source of energy is used to meet the ever-increasing energy need. this review discusses the world’s energy needs, renewable energy technologies for domestic use, and highlights public opinions on renewable energy. a systematic review of the literature was conducted from 2009 to 2018. during this process, more than 300 articles were classified and 42 papers were filtered for critical review. the literature analysis showed that despite serious efforts at all levels to reduce reliance on fossil fuels by promoting renewable energy as its alternative, fossil fuels continue to contribute 73.5% to the worldwide electricity production in 2017. conversely, renewable sources contributed only 26.5%. furthermore, this study highlights that the lack of public awareness is a major barrier to the acceptance of renewable energy technologies. the results of this study show that worldwide energy crises can be managed by integrating renewable energy sources in the power generation. moreover, in order to facilitate the development of renewable energy technologies, this systematic review has highlighted the importance of public opinion and performed a real-time analysis of public tweets. this example of tweet analysis is a relatively novel initiative in a review study that will seek to direct the attention of future researchers and policymakers toward public opinion and recommend the implications to both academia and industries.",https://ieeexplore.ieee.org/ielx7/6287639/8600701/08721134.pdf
4300b4fe10e001075888b0ddf60a3234d4fc4764,"Limitations, challenges, and solution approaches in grid‐connected renewable energy systems","In the modern world, only conventional energy resources cannot fulfil the growing energy demand. Electricity is a fundamental building block of a technological revolution. Today, most of the electricity demand is met by the burning of fossil fuels but at the cost of adverse environmental impact. In order to bridge the gap between electricity demand and supply, nonconventional and eco‐friendly means of energy generation are considered. Renewable energy systems (RESs) offer an adequate solution to mitigate the challenges originated due to greenhouse gasses (GHG). However, they have an unpredictable power generation with specific site requirements. Grid integration of RESs may lead to new challenges related to power quality, reliability, power system stability, harmonics, subsynchronous oscillations (SSOs), power quality, and reactive power compensation. The integration with energy storage systems (ESSs) can reduce these complexities that arise due to the intermittent nature of RESs. In this paper, a comprehensive review of renewable energy sources has been presented. Application of ESSs in RESs and their development phase has been discussed. Role of ESSs in increasing lifetime, efficiency, and energy density of power system having RESs has been reviewed. Moreover, different techniques to solve the critical issues like low efficiency, harmonics, and inertia reduction in photovoltaic (PV) systems have been presented. Unlike most of the available review papers, this article also investigates the impact of FACTS technology in RESs‐based power system using multitype flexible AC transmission system (FACTS) controllers. Three simulation models have been developed in MATLAB/Simulink. The results show that FACTS devices help to maintain the stability of RESs integrated power system. This review paper is believed to be of potential benefit for researchers from both the industry and academia to develop better understanding of challenges and solution techniques for REs‐based power systems and future research dimensions in this area.",2020,"[{'authorId': '2260738303', 'name': 'Muhammad Abdul Basit'}, {'authorId': '50843013', 'name': 'Saad Dilshad'}, {'authorId': '2220106', 'name': 'R. Badar'}, {'authorId': '1741188492', 'name': 'S. Rehman'}]","{'url': 'https://doi.org/10.1002/er.5033', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/er.5033?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/er.5033, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the modern world, only conventional energy resources cannot fulfil the growing energy demand. electricity is a fundamental building block of a technological revolution. today, most of the electricity demand is met by the burning of fossil fuels but at the cost of adverse environmental impact. in order to bridge the gap between electricity demand and supply, nonconventional and eco‐friendly means of energy generation are considered. renewable energy systems (ress) offer an adequate solution to mitigate the challenges originated due to greenhouse gasses (ghg). however, they have an unpredictable power generation with specific site requirements. grid integration of ress may lead to new challenges related to power quality, reliability, power system stability, harmonics, subsynchronous oscillations (ssos), power quality, and reactive power compensation. the integration with energy storage systems (esss) can reduce these complexities that arise due to the intermittent nature of ress. in this paper, a comprehensive review of renewable energy sources has been presented. application of esss in ress and their development phase has been discussed. role of esss in increasing lifetime, efficiency, and energy density of power system having ress has been reviewed. moreover, different techniques to solve the critical issues like low efficiency, harmonics, and inertia reduction in photovoltaic (pv) systems have been presented. unlike most of the available review papers, this article also investigates the impact of facts technology in ress‐based power system using multitype flexible ac transmission system (facts) controllers. three simulation models have been developed in matlab/simulink. the results show that facts devices help to maintain the stability of ress integrated power system. this review paper is believed to be of potential benefit for researchers from both the industry and academia to develop better understanding of challenges and solution techniques for res‐based power systems and future research dimensions in this area.",https://doi.org/10.1002/er.5033
4cedae2154fed84cebc37b57cd76797e7ad3d997,Multi-Criteria Decision-Making (MCDM) for the Assessment of Renewable Energy Technologies in a Household: A Review,"Different power generation technologies have different advantages and disadvantages. However, if compared to traditional energy sources, renewable energy sources provide a possibility to solve the climate change and economic decarbonization issues that are so relevant today. Therefore, the analysis and evaluation of renewable energy technologies has been receiving increasing attention in the politics of different countries and the scientific literature. The household sector consumes almost one third of all energy produced, thus studies on the evaluation of renewable energy production technologies in households are very important. This article reviews the scientific literature that have used multiple-criteria decision-making (MCDM) methods as a key tool to evaluate renewable energy technologies in households. The findings of the conducted research are categorized according to the objectives pursued and the criteria on which the evaluation was based are discussed. The article also provides an overview and in-depth analysis of MCDM methods and distinguishes the main advantages and disadvantages of using them to evaluate technologies in households.",2020,"[{'authorId': '1659147254', 'name': 'Indre Siksnelyte-Butkiene'}, {'authorId': '145366462', 'name': 'E. Zavadskas'}, {'authorId': '16273690', 'name': 'D. Štreimikienė'}]","{'url': 'https://www.mdpi.com/1996-1073/13/5/1164/pdf?version=1583325189', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/en13051164?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/en13051164, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","different power generation technologies have different advantages and disadvantages. however, if compared to traditional energy sources, renewable energy sources provide a possibility to solve the climate change and economic decarbonization issues that are so relevant today. therefore, the analysis and evaluation of renewable energy technologies has been receiving increasing attention in the politics of different countries and the scientific literature. the household sector consumes almost one third of all energy produced, thus studies on the evaluation of renewable energy production technologies in households are very important. this article reviews the scientific literature that have used multiple-criteria decision-making (mcdm) methods as a key tool to evaluate renewable energy technologies in households. the findings of the conducted research are categorized according to the objectives pursued and the criteria on which the evaluation was based are discussed. the article also provides an overview and in-depth analysis of mcdm methods and distinguishes the main advantages and disadvantages of using them to evaluate technologies in households.",https://www.mdpi.com/1996-1073/13/5/1164/pdf?version=1583325189
998fae507eae9d430ea5bd20156dd6b0ff6c87e1,Sustainable Energy Transition for Renewable and Low Carbon Grid Electricity Generation and Supply,"The greatest sustainability challenge facing humanity today is the greenhouse gas emissions and the global climate change with fossil fuels led by coal, natural gas and oil contributing 61.3% of global electricity generation in the year 2020. The cumulative effect of the Stockholm, Rio, and Johannesburg conferences identified sustainable energy development (SED) as a very important factor in the sustainable global development. This study reviews energy transition strategies and proposes a roadmap for sustainable energy transition for sustainable electricity generation and supply in line with commitments of the Paris Agreement aimed at reducing greenhouse gas emissions and limiting the rise in global average temperature to 1.5°C above the preindustrial level. The sustainable transition strategies typically consist of three major technological changes namely, energy savings on the demand side, generation efficiency at production level and fossil fuel substitution by various renewable energy sources and low carbon nuclear. For the transition remain technically and economically feasible and beneficial, policy initiatives are necessary to steer the global electricity transition towards a sustainable energy and electricity system. Large-scale renewable energy adoption should include measures to improve efficiency of existing nonrenewable sources which still have an important cost reduction and stabilization role. A resilient grid with advanced energy storage for storage and absorption of variable renewables should also be part of the transition strategies. From this study, it was noted that whereas sustainable development has social, economic, and environmental pillars, energy sustainability is best analysed by five-dimensional approach consisting of environmental, economic, social, technical, and institutional/political sustainability to determine resource sustainability. The energy transition requires new technology for maximum use of the abundant but intermittent renewable sources a sustainable mix with limited nonrenewable sources optimized to minimize cost and environmental impact but maintained quality, stability, and flexibility of an electricity supply system. Technologies needed for the transition are those that use conventional mitigation, negative emissions technologies which capture and sequester carbon emissions and finally technologies which alter the global atmospheric radiative energy budget to stabilize and reduce global average temperature. A sustainable electricity system needs facilitating technology, policy, strategies and infrastructure like smart grids, and models with an appropriate mix of both renewable and low carbon energy sources.",2022,"[{'authorId': '1395710434', 'name': 'M. Kabeyi'}, {'authorId': '144833102', 'name': 'O. Olanrewaju'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fenrg.2021.743114/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3389/fenrg.2021.743114?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3389/fenrg.2021.743114, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the greatest sustainability challenge facing humanity today is the greenhouse gas emissions and the global climate change with fossil fuels led by coal, natural gas and oil contributing 61.3% of global electricity generation in the year 2020. the cumulative effect of the stockholm, rio, and johannesburg conferences identified sustainable energy development (sed) as a very important factor in the sustainable global development. this study reviews energy transition strategies and proposes a roadmap for sustainable energy transition for sustainable electricity generation and supply in line with commitments of the paris agreement aimed at reducing greenhouse gas emissions and limiting the rise in global average temperature to 1.5°c above the preindustrial level. the sustainable transition strategies typically consist of three major technological changes namely, energy savings on the demand side, generation efficiency at production level and fossil fuel substitution by various renewable energy sources and low carbon nuclear. for the transition remain technically and economically feasible and beneficial, policy initiatives are necessary to steer the global electricity transition towards a sustainable energy and electricity system. large-scale renewable energy adoption should include measures to improve efficiency of existing nonrenewable sources which still have an important cost reduction and stabilization role. a resilient grid with advanced energy storage for storage and absorption of variable renewables should also be part of the transition strategies. from this study, it was noted that whereas sustainable development has social, economic, and environmental pillars, energy sustainability is best analysed by five-dimensional approach consisting of environmental, economic, social, technical, and institutional/political sustainability to determine resource sustainability. the energy transition requires new technology for maximum use of the abundant but intermittent renewable sources a sustainable mix with limited nonrenewable sources optimized to minimize cost and environmental impact but maintained quality, stability, and flexibility of an electricity supply system. technologies needed for the transition are those that use conventional mitigation, negative emissions technologies which capture and sequester carbon emissions and finally technologies which alter the global atmospheric radiative energy budget to stabilize and reduce global average temperature. a sustainable electricity system needs facilitating technology, policy, strategies and infrastructure like smart grids, and models with an appropriate mix of both renewable and low carbon energy sources.",https://www.frontiersin.org/articles/10.3389/fenrg.2021.743114/pdf
76099d21f2a96678316ccce9240e42a433e543a2,Predictive analytics on artificial intelligence in supply chain optimization,"AI-powered predictive analytics is among the most important ways of optimizing supply chains. This paper on AI-powered predictive analytics will address improving the competitiveness and effectiveness of supply chain operations. Nevertheless, current methods are not always scalable or adaptable to complex supply networks and changing market environments. Therefore, this paper posits that Supply Chain Optimization using Artificial Intelligence (SCO-AI) systems can help with these concerns. SCO-AI employs real-time data analysis and advanced machine learning algorithms which results to reduced response time, enhanced logistics route optimization, improved demand planning as well as real-time inventory control. Thus, the idea herein suggested fits smoothly into existing supply chain frameworks for data-driven decisions that make companies remain agile in ever-changing market dynamics. SCO-AI implementation has seen significant improvements in inventory turnover rate, rates of on-time delivery as well as overall supply chain costs. In this period of high business turbulence, such kind of research builds up the robustness of a given supply chain while at the same time minimizing operational risks by means of simulations and case studies",2024,"[{'authorId': '2309620066', 'name': 'Anber Abraheem Shlash Mohammad'}, {'authorId': '1404610848', 'name': 'I. Khanfar'}, {'authorId': '2249311683', 'name': 'Badrea Al Oraini'}, {'authorId': '1832534357', 'name': 'A. Vasudevan'}, {'authorId': '2318046281', 'name': 'Ibrahim Mohammad Suleiman'}, {'authorId': '2310918477', 'name': 'Zhou Fei'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.56294/dm2024395?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.56294/dm2024395, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ai-powered predictive analytics is among the most important ways of optimizing supply chains. this paper on ai-powered predictive analytics will address improving the competitiveness and effectiveness of supply chain operations. nevertheless, current methods are not always scalable or adaptable to complex supply networks and changing market environments. therefore, this paper posits that supply chain optimization using artificial intelligence (sco-ai) systems can help with these concerns. sco-ai employs real-time data analysis and advanced machine learning algorithms which results to reduced response time, enhanced logistics route optimization, improved demand planning as well as real-time inventory control. thus, the idea herein suggested fits smoothly into existing supply chain frameworks for data-driven decisions that make companies remain agile in ever-changing market dynamics. sco-ai implementation has seen significant improvements in inventory turnover rate, rates of on-time delivery as well as overall supply chain costs. in this period of high business turbulence, such kind of research builds up the robustness of a given supply chain while at the same time minimizing operational risks by means of simulations and case studies",
3a9dbf1921a56b7c3ca454d491f5dfdad76307b5,Leveraging artificial intelligence for enhanced supply chain optimization,"This study provides a comprehensive review of the integration of Artificial Intelligence (AI) into Supply Chain Management (SCM), focusing on its impact on operational efficiency, strategic innovation, and sustainability. Employing a systematic literature review and content analysis methodology, the research synthesizes findings from peer-reviewed articles and conference papers published between 2013 and 2023. The study identifies key advancements in AI technologies, such as machine learning, natural language processing, and robotics, and their applications across various supply chain processes including demand forecasting, inventory management, and logistics optimization. Key findings reveal that AI significantly enhances supply chain efficiency by improving decision-making, reducing costs, and optimizing resource allocation. However, challenges such as data privacy concerns, ethical considerations, and the need for skilled personnel emerge as critical factors influencing AI adoption in SCM. The future outlook for AI-enhanced supply chains is promising, with potential for further innovation and resilience, albeit contingent upon addressing existing challenges. The study concludes with strategic recommendations for practitioners and policymakers, emphasizing the importance of fostering a culture of innovation, developing digital competencies, and creating supportive regulatory frameworks for AI integration. Directions for future research include exploring the long-term impacts of AI on supply chain sustainability, ethical implications of autonomous systems, and the interplay between AI and emerging technologies. This research contributes to the academic discourse on AI in SCM, offering insights for enhancing supply chain operations in the digital age.",2024,"[{'authorId': '2238684025', 'name': 'Nsisong Louis'}, {'authorId': '2238677289', 'name': 'Eyo-Udo'}]","{'url': 'https://oarjpublication.com/journals/oarjms/sites/default/files/OARJMS-2023-0044.pdf', 'status': 'HYBRID', 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.53022/oarjms.2024.7.2.0044?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.53022/oarjms.2024.7.2.0044, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study provides a comprehensive review of the integration of artificial intelligence (ai) into supply chain management (scm), focusing on its impact on operational efficiency, strategic innovation, and sustainability. employing a systematic literature review and content analysis methodology, the research synthesizes findings from peer-reviewed articles and conference papers published between 2013 and 2023. the study identifies key advancements in ai technologies, such as machine learning, natural language processing, and robotics, and their applications across various supply chain processes including demand forecasting, inventory management, and logistics optimization. key findings reveal that ai significantly enhances supply chain efficiency by improving decision-making, reducing costs, and optimizing resource allocation. however, challenges such as data privacy concerns, ethical considerations, and the need for skilled personnel emerge as critical factors influencing ai adoption in scm. the future outlook for ai-enhanced supply chains is promising, with potential for further innovation and resilience, albeit contingent upon addressing existing challenges. the study concludes with strategic recommendations for practitioners and policymakers, emphasizing the importance of fostering a culture of innovation, developing digital competencies, and creating supportive regulatory frameworks for ai integration. directions for future research include exploring the long-term impacts of ai on supply chain sustainability, ethical implications of autonomous systems, and the interplay between ai and emerging technologies. this research contributes to the academic discourse on ai in scm, offering insights for enhancing supply chain operations in the digital age.",https://oarjpublication.com/journals/oarjms/sites/default/files/OARJMS-2023-0044.pdf
42258b105bdad2bc0a9358c5c4a89534a8395a24,Theoretical approaches to AI in supply chain optimization: Pathways to efficiency and resilience,"The integration of Artificial Intelligence (AI) into supply chain management has emerged as a pivotal avenue for enhancing efficiency and resilience in contemporary business operations. This paper explores various theoretical approaches to AI within the context of supply chain optimization, delineating pathways to achieve heightened performance and adaptability. Commencing with a historical overview, the paper delves into the evolution of AI techniques in supply chain management, elucidating how these methodologies have transformed the landscape of logistics and operations. Fundamental to this exploration is the discussion on mathematical modeling and algorithmic frameworks that underpin supply chain optimization, providing the theoretical foundation for subsequent AI applications. A key focus of the paper lies in the application of machine learning techniques for demand forecasting and inventory management, which leverage data-driven insights to optimize resource allocation and mitigate risks associated with supply-demand fluctuations. Additionally, network theory and graph algorithms play a crucial role in optimizing the structure and dynamics of supply chain networks, enabling efficient transportation, distribution, and inventory routing. Strategic decision-making in supply chains is addressed through the lens of game theory, which offers theoretical frameworks to model interactions among multiple stakeholders and optimize outcomes in competitive environments. Moreover, swarm intelligence and multi-agent systems provide innovative solutions for coordination and collaboration within complex supply chain ecosystems. Evolutionary algorithms and artificial neural networks are discussed as powerful tools for supply chain design, predictive analytics, and risk management, offering capabilities for optimizing decision-making processes across various operational domains. Furthermore, reinforcement learning techniques empower dynamic decision-making in real-time operational settings, fostering adaptive and resilient supply chain management practices. By integrating multiple AI techniques, hybrid approaches offer synergistic solutions that capitalize on the strengths of diverse methodologies to address multifaceted challenges in supply chain optimization. Through a synthesis of theoretical insights and practical case studies, this paper provides valuable insights into the current state and future directions of AI-driven supply chain optimization.",2024,"[{'authorId': '2294779450', 'name': 'Gerald Adeyemi Abaku'}, {'authorId': '2294779394', 'name': 'Emmanuel Adeyemi Abaku'}, {'authorId': '2294779392', 'name': 'Tolulope Esther Edunjobi'}, {'authorId': '2294781054', 'name': 'Agnes Clare Odimarha'}]","{'url': 'https://sciresjournals.com/ijstra/sites/default/files/IJSTRA-2024-0033.pdf', 'status': 'HYBRID', 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.53771/ijstra.2024.6.1.0033?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.53771/ijstra.2024.6.1.0033, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the integration of artificial intelligence (ai) into supply chain management has emerged as a pivotal avenue for enhancing efficiency and resilience in contemporary business operations. this paper explores various theoretical approaches to ai within the context of supply chain optimization, delineating pathways to achieve heightened performance and adaptability. commencing with a historical overview, the paper delves into the evolution of ai techniques in supply chain management, elucidating how these methodologies have transformed the landscape of logistics and operations. fundamental to this exploration is the discussion on mathematical modeling and algorithmic frameworks that underpin supply chain optimization, providing the theoretical foundation for subsequent ai applications. a key focus of the paper lies in the application of machine learning techniques for demand forecasting and inventory management, which leverage data-driven insights to optimize resource allocation and mitigate risks associated with supply-demand fluctuations. additionally, network theory and graph algorithms play a crucial role in optimizing the structure and dynamics of supply chain networks, enabling efficient transportation, distribution, and inventory routing. strategic decision-making in supply chains is addressed through the lens of game theory, which offers theoretical frameworks to model interactions among multiple stakeholders and optimize outcomes in competitive environments. moreover, swarm intelligence and multi-agent systems provide innovative solutions for coordination and collaboration within complex supply chain ecosystems. evolutionary algorithms and artificial neural networks are discussed as powerful tools for supply chain design, predictive analytics, and risk management, offering capabilities for optimizing decision-making processes across various operational domains. furthermore, reinforcement learning techniques empower dynamic decision-making in real-time operational settings, fostering adaptive and resilient supply chain management practices. by integrating multiple ai techniques, hybrid approaches offer synergistic solutions that capitalize on the strengths of diverse methodologies to address multifaceted challenges in supply chain optimization. through a synthesis of theoretical insights and practical case studies, this paper provides valuable insights into the current state and future directions of ai-driven supply chain optimization.",https://sciresjournals.com/ijstra/sites/default/files/IJSTRA-2024-0033.pdf
8915fcdd448f3a0d68726cae2f17cc75604c3289,LEVERAGING ARTIFICIAL INTELLIGENCE FOR ENHANCED SUPPLY CHAIN OPTIMIZATION: A COMPREHENSIVE REVIEW OF CURRENT PRACTICES AND FUTURE POTENTIALS,"The integration of artificial intelligence (AI) technologies into supply chain management has emerged as a crucial avenue for enhancing efficiency, agility, and responsiveness in modern business operations. This comprehensive review synthesizes current practices and future potentials of leveraging AI for supply chain optimization. Beginning with an overview of traditional supply chain management challenges, the review elucidates how AI solutions address these complexities by enabling predictive analytics, real-time visibility, and intelligent decision-making. The review delves into the diverse applications of AI across different stages of the supply chain, including demand forecasting, inventory management, logistics optimization, and supplier relationship management. Examples of AI-driven technologies such as machine learning, natural language processing, and robotic process automation are analyzed for their role in revolutionizing supply chain operations. Furthermore, the review highlights the transformative impact of AI on supply chain resilience, emphasizing its ability to mitigate disruptions, adapt to dynamic market conditions, and optimize resource allocation. The review also addresses critical considerations such as data privacy, ethical implications, and organizational readiness for AI adoption within supply chain contexts.  Lastly, the review discusses future research directions and potential advancements in AI-enabled supply chain management, envisioning intelligent autonomous supply chains characterized by self-learning systems, collaborative ecosystems, and enhanced sustainability practices. In conclusion, this review underscores the pivotal role of AI in driving continuous innovation and competitive advantage within supply chain networks, while also emphasizing the importance of strategic planning and responsible implementation to harness its full potential. 
Keywords:   AI, Supply Chain, Optimization, Practices, Review.",2024,"[{'authorId': '2291823634', 'name': 'Olorunyomi Stephen Joel'}, {'authorId': '2292062429', 'name': 'Adedoyin Tolulope Oyewole'}, {'authorId': '2284274266', 'name': 'Olusegun Gbenga Odunaiya'}, {'authorId': '2284275205', 'name': 'Oluwatobi Timothy Soyombo'}]","{'url': 'https://fepbl.com/index.php/ijmer/article/download/882/1096', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.51594/ijmer.v6i3.882?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.51594/ijmer.v6i3.882, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the integration of artificial intelligence (ai) technologies into supply chain management has emerged as a crucial avenue for enhancing efficiency, agility, and responsiveness in modern business operations. this comprehensive review synthesizes current practices and future potentials of leveraging ai for supply chain optimization. beginning with an overview of traditional supply chain management challenges, the review elucidates how ai solutions address these complexities by enabling predictive analytics, real-time visibility, and intelligent decision-making. the review delves into the diverse applications of ai across different stages of the supply chain, including demand forecasting, inventory management, logistics optimization, and supplier relationship management. examples of ai-driven technologies such as machine learning, natural language processing, and robotic process automation are analyzed for their role in revolutionizing supply chain operations. furthermore, the review highlights the transformative impact of ai on supply chain resilience, emphasizing its ability to mitigate disruptions, adapt to dynamic market conditions, and optimize resource allocation. the review also addresses critical considerations such as data privacy, ethical implications, and organizational readiness for ai adoption within supply chain contexts. lastly, the review discusses future research directions and potential advancements in ai-enabled supply chain management, envisioning intelligent autonomous supply chains characterized by self-learning systems, collaborative ecosystems, and enhanced sustainability practices. in conclusion, this review underscores the pivotal role of ai in driving continuous innovation and competitive advantage within supply chain networks, while also emphasizing the importance of strategic planning and responsible implementation to harness its full potential. keywords: ai, supply chain, optimization, practices, review.",https://fepbl.com/index.php/ijmer/article/download/882/1096
38a15a132b8ab6dbbb854197262ca8fdd70414ea,ECONOMIC THEORY AND PRACTICAL IMPACTS OF DIGITAL TRANSFORMATION IN SUPPLY CHAIN OPTIMIZATION," Digital transformation has emerged as a critical driver of innovation and efficiency in supply chain management, reshaping traditional economic paradigms and yielding profound practical implications. This paper delves into the economic theory underpinning digital transformation in supply chain optimization and explores its practical impacts on businesses and industries. In terms of economic theory, we examine the evolution from traditional supply chain models to digitally-enabled ecosystems. The integration of digital technologies such as big data analytics, artificial intelligence, and blockchain revolutionizes supply chain dynamics, enhancing efficiency, reducing costs, and mitigating risks. Drawing on game theory applications, we elucidate strategic interactions among supply chain stakeholders and the implications of digital transformation on their decision-making processes. Turning to practical impacts, we investigate how digital transformation enables enhanced visibility, real-time tracking, and predictive analytics, fostering agility and responsiveness in supply chain operations. Automation and AI-driven insights empower decision-makers to optimize resource allocation and mitigate disruptions effectively. Through case studies, we illustrate the tangible benefits and strategic advantages accrued by organizations embracing digital transformation. 
However, this transformation is not devoid of challenges. Cybersecurity threats, data privacy concerns, and the integration complexities of legacy systems pose significant hurdles. Addressing these challenges necessitates a holistic approach encompassing technological innovation, regulatory frameworks, and workforce development. Looking ahead, future trends such as blockchain integration, IoT applications, and sustainability initiatives promise further advancements in supply chain optimization. This paper underscores the imperative for ongoing research and adaptation to harness the full potential of digital transformation in reshaping the future of supply chain management. 
Keywords: Economic Theory, Practical Impacts, Digital Transformation, Supply Chain Optimization.",2024,"[{'authorId': '2298543874', 'name': 'Henry Ejiga Adama'}, {'authorId': '2298539015', 'name': 'Oladapo Adeboye Popoola'}, {'authorId': '2298541958', 'name': 'Chukwuekem David Okeke'}, {'authorId': '2298538854', 'name': 'Abiodun Emmanuel Akinoso'}]","{'url': 'https://fepbl.com/index.php/ijae/article/download/1072/1296', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.51594/ijae.v6i4.1072?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.51594/ijae.v6i4.1072, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","digital transformation has emerged as a critical driver of innovation and efficiency in supply chain management, reshaping traditional economic paradigms and yielding profound practical implications. this paper delves into the economic theory underpinning digital transformation in supply chain optimization and explores its practical impacts on businesses and industries. in terms of economic theory, we examine the evolution from traditional supply chain models to digitally-enabled ecosystems. the integration of digital technologies such as big data analytics, artificial intelligence, and blockchain revolutionizes supply chain dynamics, enhancing efficiency, reducing costs, and mitigating risks. drawing on game theory applications, we elucidate strategic interactions among supply chain stakeholders and the implications of digital transformation on their decision-making processes. turning to practical impacts, we investigate how digital transformation enables enhanced visibility, real-time tracking, and predictive analytics, fostering agility and responsiveness in supply chain operations. automation and ai-driven insights empower decision-makers to optimize resource allocation and mitigate disruptions effectively. through case studies, we illustrate the tangible benefits and strategic advantages accrued by organizations embracing digital transformation. however, this transformation is not devoid of challenges. cybersecurity threats, data privacy concerns, and the integration complexities of legacy systems pose significant hurdles. addressing these challenges necessitates a holistic approach encompassing technological innovation, regulatory frameworks, and workforce development. looking ahead, future trends such as blockchain integration, iot applications, and sustainability initiatives promise further advancements in supply chain optimization. this paper underscores the imperative for ongoing research and adaptation to harness the full potential of digital transformation in reshaping the future of supply chain management. keywords: economic theory, practical impacts, digital transformation, supply chain optimization.",https://fepbl.com/index.php/ijae/article/download/1072/1296
15577b9d82156ed646dfa949b4cf8b72317efd32,WOA: Wombat Optimization Algorithm for Solving Supply Chain Optimization Problems,"Supply Chain (SC) Optimization is a key activity in today’s industry with the goal of increasing operational efficiency, reducing costs, and improving customer satisfaction. Traditional optimization methods often struggle to effectively use resources while handling complex and dynamic Supply chain networks. This paper introduces a novel biomimetic metaheuristic algorithm called the Wombat Optimization Algorithm (WOA) for supply chain optimization. This algorithm replicates the natural behaviors observed in wombats living in the wild, particularly focusing on their foraging tactics and evasive maneuvers towards predators. The theory of WOA is described and then mathematically modeled in two phases: (i) exploration based on the simulation of wombat movements during foraging and trying to find food and (ii) exploitation based on simulating wombat movements when diving towards nearby tunnels to defend against its predators. The effectiveness of WOA in addressing optimization challenges is assessed by handling the CEC 2017 test suite across various problem dimensions, including 10, 30, 50, and 100. The findings of the optimization indicate that WOA demonstrates a strong ability to effectively manage exploration and exploitation, and maintains a balance between them throughout the search phase to deliver optimal solutions for optimization problems. A total of twelve well-known metaheuristic algorithms are called upon to test their performance against WOA in the optimization process. The outcomes of the simulations reveal that WOA outperforms the other algorithms, achieving superior results across most benchmark functions and securing the top ranking as the most efficient optimizer. Using a Wilcoxon rank sum test statistical analysis, it has been proven that WOA outperforms other algorithms significantly. WOA is put to the test with twenty-two constrained optimization problems from the CEC 2011 test suite and four engineering design problems to showcase its ability to solve real-world optimization problems. The results of the simulations demonstrate that WOA excels in real-world applications by delivering superior solutions and outperforming its competitors.",2024,"[{'authorId': '83493903', 'name': 'Zoubida Benmamoun'}, {'authorId': '2294633345', 'name': 'Khaoula Khlie'}, {'authorId': '2261526390', 'name': 'Mohammad Dehghani'}, {'authorId': '2294633337', 'name': 'Youness Gherabi'}]","{'url': 'https://www.mdpi.com/2227-7390/12/7/1059/pdf?version=1711967470', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/math12071059?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/math12071059, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","supply chain (sc) optimization is a key activity in today’s industry with the goal of increasing operational efficiency, reducing costs, and improving customer satisfaction. traditional optimization methods often struggle to effectively use resources while handling complex and dynamic supply chain networks. this paper introduces a novel biomimetic metaheuristic algorithm called the wombat optimization algorithm (woa) for supply chain optimization. this algorithm replicates the natural behaviors observed in wombats living in the wild, particularly focusing on their foraging tactics and evasive maneuvers towards predators. the theory of woa is described and then mathematically modeled in two phases: (i) exploration based on the simulation of wombat movements during foraging and trying to find food and (ii) exploitation based on simulating wombat movements when diving towards nearby tunnels to defend against its predators. the effectiveness of woa in addressing optimization challenges is assessed by handling the cec 2017 test suite across various problem dimensions, including 10, 30, 50, and 100. the findings of the optimization indicate that woa demonstrates a strong ability to effectively manage exploration and exploitation, and maintains a balance between them throughout the search phase to deliver optimal solutions for optimization problems. a total of twelve well-known metaheuristic algorithms are called upon to test their performance against woa in the optimization process. the outcomes of the simulations reveal that woa outperforms the other algorithms, achieving superior results across most benchmark functions and securing the top ranking as the most efficient optimizer. using a wilcoxon rank sum test statistical analysis, it has been proven that woa outperforms other algorithms significantly. woa is put to the test with twenty-two constrained optimization problems from the cec 2011 test suite and four engineering design problems to showcase its ability to solve real-world optimization problems. the results of the simulations demonstrate that woa excels in real-world applications by delivering superior solutions and outperforming its competitors.",https://www.mdpi.com/2227-7390/12/7/1059/pdf?version=1711967470
e7822000f3c6f79e34de310c014f391e5af2174b,Data-driven digital marketing and battery supply chain optimization in the battery-powered aircraft industry through case studies of Rolls-Royce’s ACCEL and Airbus's E-Fan X Projects,"This paper investigates the interplay between data-driven digital marketing strategies and battery supply chain optimization in the battery-powered aircraft industry, with a focus on Rolls-Royce's ACCEL and Airbus's E-Fan X projects. As the electric aircraft market emerges, these companies face the dual challenge of promoting technological advancements to a skeptical audience while navigating complex supply chain requirements. The study explores how data analytics and targeted content marketing are employed to enhance stakeholder engagement, build consumer trust, and communicate the benefits of electric aviation. By leveraging digital platforms, Rolls-Royce and Airbus effectively highlight key aspects such as battery performance, sustainability, and the safety of electric propulsion, addressing both technical and consumer concerns. Concurrently, the research delves into the intricacies of battery supply chain optimization, examining the processes involved in sourcing high-energy-density batteries, ensuring quality control, and adhering to regulatory standards. Advanced supply chain management techniques, including predictive analytics and real-time monitoring, are analyzed for their role in streamlining procurement and manufacturing processes. The integration of these strategies within digital marketing campaigns demonstrates how each company positions itself as a leader in the industry, emphasizing technological innovation and reliability. This study aims to provide a comprehensive understanding of how digital marketing and supply chain optimization are not only critical for promoting the adoption of electric aircraft but also for overcoming market skepticism and ensuring operational efficiency. By presenting case studies of two pioneering projects, ACCEL and E-Fan X, the research highlights best practices and strategic approaches that can guide other companies in the industry. The findings underscore the importance of a synergistic approach where digital marketing is informed by supply chain realities, creating a transparent and trustworthy narrative for consumers and stakeholders. Ultimately, this paper contributes to the discourse on how emerging technologies in aviation can be successfully marketed and operationalized, offering insights into the effective use of digital marketing and supply chain management in the rapidly evolving electric aircraft sector.",2024,"[{'authorId': '2314818947', 'name': 'Joy Onma Enyejo'}, {'authorId': '2326234208', 'name': 'Idayat Ninilola'}, {'authorId': '2326237037', 'name': 'Ololade Babalola'}, {'authorId': '2326237235', 'name': 'Fadekemi Rukayat'}, {'authorId': '2326237140', 'name': 'Adedoyin Owolabi'}, {'authorId': '2326174605', 'name': 'Adenike Folashade Adeyemi'}, {'authorId': '2326233813', 'name': 'George Osam-Nunoo'}, {'authorId': '2326236102', 'name': 'Angelina Okewu Ogwuche'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.56781/ijsrr.2024.5.2.0045?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.56781/ijsrr.2024.5.2.0045, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper investigates the interplay between data-driven digital marketing strategies and battery supply chain optimization in the battery-powered aircraft industry, with a focus on rolls-royce's accel and airbus's e-fan x projects. as the electric aircraft market emerges, these companies face the dual challenge of promoting technological advancements to a skeptical audience while navigating complex supply chain requirements. the study explores how data analytics and targeted content marketing are employed to enhance stakeholder engagement, build consumer trust, and communicate the benefits of electric aviation. by leveraging digital platforms, rolls-royce and airbus effectively highlight key aspects such as battery performance, sustainability, and the safety of electric propulsion, addressing both technical and consumer concerns. concurrently, the research delves into the intricacies of battery supply chain optimization, examining the processes involved in sourcing high-energy-density batteries, ensuring quality control, and adhering to regulatory standards. advanced supply chain management techniques, including predictive analytics and real-time monitoring, are analyzed for their role in streamlining procurement and manufacturing processes. the integration of these strategies within digital marketing campaigns demonstrates how each company positions itself as a leader in the industry, emphasizing technological innovation and reliability. this study aims to provide a comprehensive understanding of how digital marketing and supply chain optimization are not only critical for promoting the adoption of electric aircraft but also for overcoming market skepticism and ensuring operational efficiency. by presenting case studies of two pioneering projects, accel and e-fan x, the research highlights best practices and strategic approaches that can guide other companies in the industry. the findings underscore the importance of a synergistic approach where digital marketing is informed by supply chain realities, creating a transparent and trustworthy narrative for consumers and stakeholders. ultimately, this paper contributes to the discourse on how emerging technologies in aviation can be successfully marketed and operationalized, offering insights into the effective use of digital marketing and supply chain management in the rapidly evolving electric aircraft sector.",
2884658cb1e7f408869d410b84c97a63e2c0d049,Advanced supply chain optimization for emerging market healthcare systems,"The complexities of pharmaceutical supply chains in emerging markets present significant challenges that directly impact healthcare outcomes, particularly in underserved regions. This research focuses on the optimization of supply chain systems for the healthcare sector, with an emphasis on enhancing pharmaceutical delivery. By leveraging data analytics and innovative procurement strategies, the study seeks to improve efficiency, reduce operational costs, and ensure the timely distribution of essential medications. Drawing on practical experiences at eMedic Technologies Africa, the research highlights the need for advanced models that integrate real-time data to optimize inventory management, forecast demand, and address bottlenecks in last-mile delivery. The study proposes a multi-faceted approach to addressing common challenges in emerging market supply chains, including unreliable infrastructure, fluctuating demand, and limited access to technology. By utilizing predictive analytics, the proposed models aim to improve accuracy in demand planning, reducing stockouts and overstock situations. Additionally, innovative procurement strategies, such as centralized procurement and strategic partnerships with local suppliers, are explored as key methods for enhancing cost-effectiveness and streamlining supply chain operations. A critical component of the research is the focus on last-mile delivery, which remains a significant hurdle in rural and underserved areas. The study advocates for the use of digital platforms and mobile technologies to enhance delivery tracking and coordination, ensuring that essential medications reach their destination efficiently. Furthermore, it emphasizes the importance of fostering collaboration between governments, non-governmental organizations, and private sector stakeholders to build resilient supply chain systems capable of adapting to local conditions. By providing actionable insights and scalable models for supply chain optimization, this research aims to contribute to improved healthcare delivery in emerging markets. The proposed strategies not only reduce costs and improve efficiency but also ensure a reliable and consistent supply of medications, ultimately leading to better health outcomes in regions most in need. 
Keywords: Supply Chain Optimization, Data-Driven Procurement, Last-Mile Delivery, Healthcare Efficiency, Emerging Markets",2024,"[{'authorId': '2325177468', 'name': 'Precious Azino Usuemerai'}, {'authorId': '2325180095', 'name': 'Olumide Emmanuel Ibikunle'}, {'authorId': '2325177211', 'name': 'Luqman Adewale Abass'}, {'authorId': '2322780130', 'name': 'Victor Alemede'}, {'authorId': '2325177638', 'name': 'Ejike Innocent Nwankwo'}, {'authorId': '2325184241', 'name': 'Akachukwu Obianuju Mbata'}]","{'url': 'https://www.fepbl.com/index.php/ijmer/article/download/1637/1883', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.51594/ijmer.v6i10.1637?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.51594/ijmer.v6i10.1637, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the complexities of pharmaceutical supply chains in emerging markets present significant challenges that directly impact healthcare outcomes, particularly in underserved regions. this research focuses on the optimization of supply chain systems for the healthcare sector, with an emphasis on enhancing pharmaceutical delivery. by leveraging data analytics and innovative procurement strategies, the study seeks to improve efficiency, reduce operational costs, and ensure the timely distribution of essential medications. drawing on practical experiences at emedic technologies africa, the research highlights the need for advanced models that integrate real-time data to optimize inventory management, forecast demand, and address bottlenecks in last-mile delivery. the study proposes a multi-faceted approach to addressing common challenges in emerging market supply chains, including unreliable infrastructure, fluctuating demand, and limited access to technology. by utilizing predictive analytics, the proposed models aim to improve accuracy in demand planning, reducing stockouts and overstock situations. additionally, innovative procurement strategies, such as centralized procurement and strategic partnerships with local suppliers, are explored as key methods for enhancing cost-effectiveness and streamlining supply chain operations. a critical component of the research is the focus on last-mile delivery, which remains a significant hurdle in rural and underserved areas. the study advocates for the use of digital platforms and mobile technologies to enhance delivery tracking and coordination, ensuring that essential medications reach their destination efficiently. furthermore, it emphasizes the importance of fostering collaboration between governments, non-governmental organizations, and private sector stakeholders to build resilient supply chain systems capable of adapting to local conditions. by providing actionable insights and scalable models for supply chain optimization, this research aims to contribute to improved healthcare delivery in emerging markets. the proposed strategies not only reduce costs and improve efficiency but also ensure a reliable and consistent supply of medications, ultimately leading to better health outcomes in regions most in need. keywords: supply chain optimization, data-driven procurement, last-mile delivery, healthcare efficiency, emerging markets",https://www.fepbl.com/index.php/ijmer/article/download/1637/1883
b4197cf09b7c8d78a1880d6d442022e4a67a1169,AI in supply chain optimization: A comparative review of USA and African Trends,"The integration of Artificial Intelligence (AI) in supply chain management has emerged as a critical driver of efficiency and competitiveness in global markets. This paper provides a comparative review of AI trends in supply chain optimization between the United States and African regions, shedding light on the unique challenges and opportunities faced by each. In the United States, AI adoption in supply chain optimization has been robust, with a focus on predictive analytics, machine learning, and advanced automation technologies. American companies leverage AI to enhance demand forecasting, optimize inventory management, and streamline logistics processes. The integration of AI-driven solutions has allowed U.S. businesses to achieve higher accuracy in demand predictions, reduce lead times, and minimize operational costs. Furthermore, the use of AI algorithms in route optimization has significantly improved delivery efficiency, leading to enhanced customer satisfaction. Contrastingly, African countries are experiencing a more gradual but steadily increasing adoption of AI in supply chain optimization. Limited access to advanced technology infrastructure, coupled with resource constraints, has posed challenges for African businesses. However, innovative approaches are being explored, such as the use of mobile technologies and cloud-based solutions to overcome infrastructure limitations. AI applications in African supply chains focus on improving visibility, minimizing waste, and ensuring timely delivery. The continent's diverse supply chain landscape, encompassing agriculture, mining, and manufacturing, presents a unique set of challenges that AI aims to address. Both the United States and African nations recognize the potential of AI to transform supply chain management. While the U.S. is at the forefront of AI implementation, Africa is forging ahead with tailored solutions that align with its specific context. Collaboration and knowledge exchange between these regions could pave the way for a globalized approach to AI in supply chain optimization. This review underscores the importance of understanding regional nuances in adopting AI technologies, fostering collaboration for mutual benefit, and advancing the global evolution of AI-driven supply chain management.",2024,"[{'authorId': '2254384745', 'name': 'Andrew Ifesinachi Daraojimba'}, {'authorId': '2179000681', 'name': 'Akoh Atadoga'}, {'authorId': '2290099374', 'name': 'Ogugua Chimezie Obi'}, {'authorId': '2288309139', 'name': 'Femi Osasona'}, {'authorId': '2282791174', 'name': 'Shedrack Onwusinkwue'}, {'authorId': '2290201278', 'name': 'Samuel Onimisi Dawodu'}]","{'url': 'https://ijsra.net/sites/default/files/IJSRA-2024-0156.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.30574/ijsra.2024.11.1.0156?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.30574/ijsra.2024.11.1.0156, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the integration of artificial intelligence (ai) in supply chain management has emerged as a critical driver of efficiency and competitiveness in global markets. this paper provides a comparative review of ai trends in supply chain optimization between the united states and african regions, shedding light on the unique challenges and opportunities faced by each. in the united states, ai adoption in supply chain optimization has been robust, with a focus on predictive analytics, machine learning, and advanced automation technologies. american companies leverage ai to enhance demand forecasting, optimize inventory management, and streamline logistics processes. the integration of ai-driven solutions has allowed u.s. businesses to achieve higher accuracy in demand predictions, reduce lead times, and minimize operational costs. furthermore, the use of ai algorithms in route optimization has significantly improved delivery efficiency, leading to enhanced customer satisfaction. contrastingly, african countries are experiencing a more gradual but steadily increasing adoption of ai in supply chain optimization. limited access to advanced technology infrastructure, coupled with resource constraints, has posed challenges for african businesses. however, innovative approaches are being explored, such as the use of mobile technologies and cloud-based solutions to overcome infrastructure limitations. ai applications in african supply chains focus on improving visibility, minimizing waste, and ensuring timely delivery. the continent's diverse supply chain landscape, encompassing agriculture, mining, and manufacturing, presents a unique set of challenges that ai aims to address. both the united states and african nations recognize the potential of ai to transform supply chain management. while the u.s. is at the forefront of ai implementation, africa is forging ahead with tailored solutions that align with its specific context. collaboration and knowledge exchange between these regions could pave the way for a globalized approach to ai in supply chain optimization. this review underscores the importance of understanding regional nuances in adopting ai technologies, fostering collaboration for mutual benefit, and advancing the global evolution of ai-driven supply chain management.",https://ijsra.net/sites/default/files/IJSRA-2024-0156.pdf
bbe2f0a73e8bac09457ea17d3b6276dc97f170df,Large Language Models for Supply Chain Optimization,"Supply chain operations traditionally involve a variety of complex decision making problems. Over the last few decades, supply chains greatly benefited from advances in computation, which allowed the transition from manual processing to automation and cost-effective optimization. Nonetheless, business operators still need to spend substantial efforts in explaining and interpreting the optimization outcomes to stakeholders. Motivated by the recent advances in Large Language Models (LLMs), we study how this disruptive technology can help bridge the gap between supply chain automation and human comprehension and trust thereof. We design OptiGuide -- a framework that accepts as input queries in plain text, and outputs insights about the underlying optimization outcomes. Our framework does not forgo the state-of-the-art combinatorial optimization technology, but rather leverages it to quantitatively answer what-if scenarios (e.g., how would the cost change if we used supplier B instead of supplier A for a given demand?). Importantly, our design does not require sending proprietary data over to LLMs, which can be a privacy concern in some circumstances. We demonstrate the effectiveness of our framework on a real server placement scenario within Microsoft's cloud supply chain. Along the way, we develop a general evaluation benchmark, which can be used to evaluate the accuracy of the LLM output in other scenarios.",2023,"[{'authorId': '3369602', 'name': 'Beibin Li'}, {'authorId': '1453737193', 'name': 'Konstantina Mellou'}, {'authorId': '2000450964', 'name': 'Bo-qing Zhang'}, {'authorId': '2740008', 'name': 'Jeevan Pathuri'}, {'authorId': '1684547', 'name': 'Ishai Menache'}]","{'url': 'https://arxiv.org/pdf/2307.03875', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2307.03875, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","supply chain operations traditionally involve a variety of complex decision making problems. over the last few decades, supply chains greatly benefited from advances in computation, which allowed the transition from manual processing to automation and cost-effective optimization. nonetheless, business operators still need to spend substantial efforts in explaining and interpreting the optimization outcomes to stakeholders. motivated by the recent advances in large language models (llms), we study how this disruptive technology can help bridge the gap between supply chain automation and human comprehension and trust thereof. we design optiguide -- a framework that accepts as input queries in plain text, and outputs insights about the underlying optimization outcomes. our framework does not forgo the state-of-the-art combinatorial optimization technology, but rather leverages it to quantitatively answer what-if scenarios (e.g., how would the cost change if we used supplier b instead of supplier a for a given demand?). importantly, our design does not require sending proprietary data over to llms, which can be a privacy concern in some circumstances. we demonstrate the effectiveness of our framework on a real server placement scenario within microsoft's cloud supply chain. along the way, we develop a general evaluation benchmark, which can be used to evaluate the accuracy of the llm output in other scenarios.",https://arxiv.org/pdf/2307.03875
532fbeecd8100eef887ec509c711517258deb122,Supply Chain Optimization Considering Sustainability Aspects,"Supply chain optimization concerns the improvement of the performance and efficiency of the manufacturing and distribution supply chain by making the best use of resources. In the context of supply chain optimization, scheduling has always been a challenging task for experts, especially when considering a distributed manufacturing system (DMS). The present study aims to tackle the supply chain scheduling problem in a DMS while considering two essential sustainability aspects, namely environmental and economic. The economic aspect is addressed by optimizing the total delivery time of order, transportation cost, and production cost while optimizing environmental pollution and the quality of products contribute to the environmental aspect. To cope with the problem, it is mathematically formulated as a mixed-integer linear programming (MILP) model. Due to the complexity of the problem, an improved genetic algorithm (GA) named GA-TOPKOR is proposed. The algorithm is a combination of GA and TOPKOR, which is one of the multi-criteria decision-making techniques. To assess the efficiency of GA-TOPKOR, it is applied to a real-life case study and a set of test problems. The solutions obtained by the algorithm are compared against the traditional GA and the optimum solutions obtained from the MILP model. The results of comparisons collectively show the efficiency of the GA-TOPKOR. Analysis of results also revealed that using the TOPKOR technique in the selection operator of GA significantly improves its performance.",2021,"[{'authorId': '25855885', 'name': 'M. Beheshtinia'}, {'authorId': '2136320436', 'name': 'Parisa Feizollahy'}, {'authorId': '51498424', 'name': 'Masood Fathi'}]","{'url': 'https://www.mdpi.com/2071-1050/13/21/11873/pdf?version=1635331620', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su132111873?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su132111873, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","supply chain optimization concerns the improvement of the performance and efficiency of the manufacturing and distribution supply chain by making the best use of resources. in the context of supply chain optimization, scheduling has always been a challenging task for experts, especially when considering a distributed manufacturing system (dms). the present study aims to tackle the supply chain scheduling problem in a dms while considering two essential sustainability aspects, namely environmental and economic. the economic aspect is addressed by optimizing the total delivery time of order, transportation cost, and production cost while optimizing environmental pollution and the quality of products contribute to the environmental aspect. to cope with the problem, it is mathematically formulated as a mixed-integer linear programming (milp) model. due to the complexity of the problem, an improved genetic algorithm (ga) named ga-topkor is proposed. the algorithm is a combination of ga and topkor, which is one of the multi-criteria decision-making techniques. to assess the efficiency of ga-topkor, it is applied to a real-life case study and a set of test problems. the solutions obtained by the algorithm are compared against the traditional ga and the optimum solutions obtained from the milp model. the results of comparisons collectively show the efficiency of the ga-topkor. analysis of results also revealed that using the topkor technique in the selection operator of ga significantly improves its performance.",https://www.mdpi.com/2071-1050/13/21/11873/pdf?version=1635331620
ac1bbd78e7e48ed71dcd1bafc4784405a302a46a,Enhancing Supply Chain Agility and Sustainability through Machine Learning: Optimization Techniques for Logistics and Inventory Management,"As global supply chains face increasing complexity, the demand for agile and sustainable management strategies has become more critical. This study employs advanced machine learning (ML) techniques to transform logistics and inventory management, moving beyond the constraints of traditional analytical methods. Utilizing historical data from a multinational retail corporation, including sales, inventory levels, order fulfillment rates, and operational costs, we have applied a range of ML algorithms such as regression, classification, clustering, and time series analysis. These models were developed to tackle key operational challenges, enhancing decision-making by improving demand forecasting accuracy by 15%, optimizing stock levels by reducing overstock and stockouts by 10%, and predicting order fulfillment timelines with 95% accuracy. Additionally, our approach enabled the identification of at-risk shipments and the segmentation of customers based on their delivery preferences, facilitating personalized service offerings. A comprehensive evaluation of these models showed significant improvements in predictive accuracy, efficiency in lead time by 12%, silhouette coefficients for clustering at 0.75, and a reduction in replenishment errors by 8%, highlighting the transformative potential of ML in making supply chain operations more responsive and data driven.",2024,"[{'authorId': '2311264624', 'name': 'Vikram Pasupuleti'}, {'authorId': '2311259930', 'name': 'Bharadwaj Thuraka'}, {'authorId': '2302105820', 'name': 'Chandra Shikhi Kodete'}, {'authorId': '2179121206', 'name': 'Saiteja Malisetty'}]","{'url': 'https://www.mdpi.com/2305-6290/8/3/73/pdf?version=1723514568', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/logistics8030073?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/logistics8030073, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","as global supply chains face increasing complexity, the demand for agile and sustainable management strategies has become more critical. this study employs advanced machine learning (ml) techniques to transform logistics and inventory management, moving beyond the constraints of traditional analytical methods. utilizing historical data from a multinational retail corporation, including sales, inventory levels, order fulfillment rates, and operational costs, we have applied a range of ml algorithms such as regression, classification, clustering, and time series analysis. these models were developed to tackle key operational challenges, enhancing decision-making by improving demand forecasting accuracy by 15%, optimizing stock levels by reducing overstock and stockouts by 10%, and predicting order fulfillment timelines with 95% accuracy. additionally, our approach enabled the identification of at-risk shipments and the segmentation of customers based on their delivery preferences, facilitating personalized service offerings. a comprehensive evaluation of these models showed significant improvements in predictive accuracy, efficiency in lead time by 12%, silhouette coefficients for clustering at 0.75, and a reduction in replenishment errors by 8%, highlighting the transformative potential of ml in making supply chain operations more responsive and data driven.",https://www.mdpi.com/2305-6290/8/3/73/pdf?version=1723514568
33038b6197f7bf5d0c0664fa6064ab4da875479a,Selected Multiple Criteria Supply Chain Optimization Problems,"Supply chain is an important aspect for all the companies and can affect many aspects of companies. Especially the disruption in supply chain is causing huge impacts and consequences that are difficult to deal with. This chapter presents a review of selected multiple criteria problems used in supply chain optimization. Research analyzed the multiple criteria decision-making methods to tackle the problem of supplier evaluation and selection. It also focuses on the problem of supply chain when a disruption happens and presents strategies to deal with the issue of disruptions in supply chain and how to mitigate the impact of disruptions. Prevention, response, protection, and recovery strategies are explained. Practical part is focused in the risk-averse models to minimize expected worst-case scenario by single sourcing. Computational experiments for practical examples have been solved using CPLEX solver.",2020,"[{'authorId': '1997580', 'name': 'Bartosz Sawik'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/s0276-897620200000020003?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/s0276-897620200000020003, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","supply chain is an important aspect for all the companies and can affect many aspects of companies. especially the disruption in supply chain is causing huge impacts and consequences that are difficult to deal with. this chapter presents a review of selected multiple criteria problems used in supply chain optimization. research analyzed the multiple criteria decision-making methods to tackle the problem of supplier evaluation and selection. it also focuses on the problem of supply chain when a disruption happens and presents strategies to deal with the issue of disruptions in supply chain and how to mitigate the impact of disruptions. prevention, response, protection, and recovery strategies are explained. practical part is focused in the risk-averse models to minimize expected worst-case scenario by single sourcing. computational experiments for practical examples have been solved using cplex solver.",
93693c2edf90e9d844d134bdf5addd05b335e3b1,Enhancing manufacturing productivity: A review of AI-Driven supply chain management optimization and ERP systems integration,"This abstract delves into the realm of manufacturing productivity enhancement through the review of AI-driven supply chain management (SCM) optimization and Enterprise Resource Planning (ERP) systems integration. As industries strive for operational excellence, the convergence of artificial intelligence (AI) and supply chain management emerges as a transformative force in driving efficiency, agility, and competitiveness. Through a comprehensive analysis, this abstract examines the synergistic relationship between AI-driven SCM optimization and the integration of ERP systems, elucidating their collective impact on manufacturing productivity. AI-driven SCM optimization encompasses a spectrum of technologies and methodologies, including predictive analytics, machine learning, and autonomous decision-making systems, aimed at optimizing various facets of the supply chain, from demand forecasting and inventory management to production planning and logistics optimization. By harnessing the power of AI, manufacturers can enhance forecasting accuracy, reduce lead times, optimize inventory levels, and mitigate supply chain disruptions, thereby improving overall productivity and customer satisfaction. Integration of ERP systems plays a complementary role in manufacturing productivity enhancement by providing a centralized platform for data management, process automation, and cross-functional collaboration. Through seamless integration with AI-driven SCM optimization tools, ERP systems enable real-time data exchange, actionable insights, and end-to-end visibility across the supply chain, facilitating informed decision-making and agile response to dynamic market conditions. Drawing insights from case studies and industry examples, this abstract highlights best practices, challenges, and emerging trends in AI-driven SCM optimization and ERP systems integration. Strategies for successful implementation, including organizational readiness assessment, change management, and stakeholder engagement, are discussed to guide manufacturers in unlocking the full potential of these transformative technologies. In conclusion, the convergence of AI-driven SCM optimization and ERP systems integration offers a compelling pathway for enhancing manufacturing productivity, driving operational excellence, and sustaining competitive advantage in the digital era.. 
Keywords:  Artificial Intelligence, Supply Chain Management, Enterprise Resource Planning, Manufacturing Productivity, AI Integration, Predictive Analytics.",2024,"[{'authorId': '2301160605', 'name': 'Olubunmi Adeolu Adenekan'}, {'authorId': '2301161451', 'name': 'Nko Okina Solomon'}, {'authorId': '2301160734', 'name': 'Peter Simpa'}, {'authorId': '2301160575', 'name': 'Scholar Chinenye Obasi'}]","{'url': 'https://fepbl.com/index.php/ijmer/article/download/1126/1355', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.51594/ijmer.v6i5.1126?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.51594/ijmer.v6i5.1126, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this abstract delves into the realm of manufacturing productivity enhancement through the review of ai-driven supply chain management (scm) optimization and enterprise resource planning (erp) systems integration. as industries strive for operational excellence, the convergence of artificial intelligence (ai) and supply chain management emerges as a transformative force in driving efficiency, agility, and competitiveness. through a comprehensive analysis, this abstract examines the synergistic relationship between ai-driven scm optimization and the integration of erp systems, elucidating their collective impact on manufacturing productivity. ai-driven scm optimization encompasses a spectrum of technologies and methodologies, including predictive analytics, machine learning, and autonomous decision-making systems, aimed at optimizing various facets of the supply chain, from demand forecasting and inventory management to production planning and logistics optimization. by harnessing the power of ai, manufacturers can enhance forecasting accuracy, reduce lead times, optimize inventory levels, and mitigate supply chain disruptions, thereby improving overall productivity and customer satisfaction. integration of erp systems plays a complementary role in manufacturing productivity enhancement by providing a centralized platform for data management, process automation, and cross-functional collaboration. through seamless integration with ai-driven scm optimization tools, erp systems enable real-time data exchange, actionable insights, and end-to-end visibility across the supply chain, facilitating informed decision-making and agile response to dynamic market conditions. drawing insights from case studies and industry examples, this abstract highlights best practices, challenges, and emerging trends in ai-driven scm optimization and erp systems integration. strategies for successful implementation, including organizational readiness assessment, change management, and stakeholder engagement, are discussed to guide manufacturers in unlocking the full potential of these transformative technologies. in conclusion, the convergence of ai-driven scm optimization and erp systems integration offers a compelling pathway for enhancing manufacturing productivity, driving operational excellence, and sustaining competitive advantage in the digital era.. keywords: artificial intelligence, supply chain management, enterprise resource planning, manufacturing productivity, ai integration, predictive analytics.",https://fepbl.com/index.php/ijmer/article/download/1126/1355
244ffd71727905b25c54b62d29711916ac7b16e6,Blockchain-Based Zero-Trust Supply Chain Security Integrated with Deep Reinforcement Learning for Inventory Optimization,"Modern supply chain systems face significant challenges, including lack of transparency, inefficient inventory management, and vulnerability to disruptions and security threats. Traditional optimization methods often struggle to adapt to the complex and dynamic nature of these systems. This paper presents a novel blockchain-based zero-trust supply chain security framework integrated with deep reinforcement learning (SAC-rainbow) to address these challenges. The SAC-rainbow framework leverages the Soft Actor–Critic (SAC) algorithm with prioritized experience replay for inventory optimization and a blockchain-based zero-trust mechanism for secure supply chain management. The SAC-rainbow algorithm learns adaptive policies under demand uncertainty, while the blockchain architecture ensures secure, transparent, and traceable record-keeping and automated execution of supply chain transactions. An experiment using real-world supply chain data demonstrated the superior performance of the proposed framework in terms of reward maximization, inventory stability, and security metrics. The SAC-rainbow framework offers a promising solution for addressing the challenges of modern supply chains by leveraging blockchain, deep reinforcement learning, and zero-trust security principles. This research paves the way for developing secure, transparent, and efficient supply chain management systems in the face of growing complexity and security risks.",2024,"[{'authorId': '2289608648', 'name': 'Zhe Ma'}, {'authorId': '2277747465', 'name': 'Xuhesheng Chen'}, {'authorId': '2302161799', 'name': 'Tiejiang Sun'}, {'authorId': '2244240468', 'name': 'Xukang Wang'}, {'authorId': '2244273907', 'name': 'Y. Wu'}, {'authorId': '2262196225', 'name': 'Mengjie Zhou'}]","{'url': 'https://www.mdpi.com/1999-5903/16/5/163/pdf?version=1715604144', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/fi16050163?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/fi16050163, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","modern supply chain systems face significant challenges, including lack of transparency, inefficient inventory management, and vulnerability to disruptions and security threats. traditional optimization methods often struggle to adapt to the complex and dynamic nature of these systems. this paper presents a novel blockchain-based zero-trust supply chain security framework integrated with deep reinforcement learning (sac-rainbow) to address these challenges. the sac-rainbow framework leverages the soft actor–critic (sac) algorithm with prioritized experience replay for inventory optimization and a blockchain-based zero-trust mechanism for secure supply chain management. the sac-rainbow algorithm learns adaptive policies under demand uncertainty, while the blockchain architecture ensures secure, transparent, and traceable record-keeping and automated execution of supply chain transactions. an experiment using real-world supply chain data demonstrated the superior performance of the proposed framework in terms of reward maximization, inventory stability, and security metrics. the sac-rainbow framework offers a promising solution for addressing the challenges of modern supply chains by leveraging blockchain, deep reinforcement learning, and zero-trust security principles. this research paves the way for developing secure, transparent, and efficient supply chain management systems in the face of growing complexity and security risks.",https://www.mdpi.com/1999-5903/16/5/163/pdf?version=1715604144
b41ca398e5ac1dae918b3dfb6ac0efa815a3303f,Deep Reinforcement Learning Approach for Capacitated Supply Chain optimization under Demand Uncertainty,"With the global trade competition becoming further intensified, Supply Chain Management (SCM) technology has become critical to maintain competitive advantages for enterprises. However, the economic integration and increased market uncertainty have brought great challenges to SCM. In this paper, two Deep Reinforcement Learning (DRL) based methods are proposed to solve multi-period capacitated supply chain optimization problem under demand uncertainty. The capacity constraints are satisfied from both modelling perspective and DRL algorithm perspective. Both continuous action space and discrete action space are considered. The performance of the methods is analyzed through the simulation of three different cases. Compared to the baseline of (r, Q) policy, the proposed methods show promising results for the supply chain optimization problem.",2019,"[{'authorId': '152245396', 'name': 'Zedong Peng'}, {'authorId': '39939149', 'name': 'Yi Zhang'}, {'authorId': '2185851018', 'name': 'Yiping Feng'}, {'authorId': '1500391713', 'name': 'T. Zhang'}, {'authorId': '145067434', 'name': 'Zhengguang Wu'}, {'authorId': '143885022', 'name': 'H. Su'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/CAC48633.2019.8997498?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CAC48633.2019.8997498, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with the global trade competition becoming further intensified, supply chain management (scm) technology has become critical to maintain competitive advantages for enterprises. however, the economic integration and increased market uncertainty have brought great challenges to scm. in this paper, two deep reinforcement learning (drl) based methods are proposed to solve multi-period capacitated supply chain optimization problem under demand uncertainty. the capacity constraints are satisfied from both modelling perspective and drl algorithm perspective. both continuous action space and discrete action space are considered. the performance of the methods is analyzed through the simulation of three different cases. compared to the baseline of (r, q) policy, the proposed methods show promising results for the supply chain optimization problem.",
dfc7c0db8cd60bcb4a22e9ee6ea2f704a3822d99,Exploring the Benefits of Modular Renewable-Powered Ammonia Production: A Supply Chain Optimization Study,"Small-scale renewable-powered ammonia production is more sustainable than the current fossil fuel- and energy-intensive method. The development of lower capital cost absorbent-enhanced ammonia synthesis as well as the concept of modular chemical processes may improve the economic feasibility of such a paradigm. This possibility is investigated through an ammonia supply chain optimization study wherein modular, wind-powered ammonia production based on this new technology can be added to the existing infrastructure. The benefit of modularity is captured via a mass production exponent which reduces per-module capital cost as more are constructed. Case studies for Minnesota and Iowa show first adoption of 8760 t/y modules at conventional ammonia prices of $610/t and $574/t, respectively, which are considerably lower than those required for incorporation of scaled-down Haber–Bosch. For mass production exponents of 0.9 and less, modular production results in lower supply chain cost and more renewable incorporat...",2018,"[{'authorId': '90239825', 'name': 'M. Palys'}, {'authorId': '14216374', 'name': 'A. Allman'}, {'authorId': '1972885', 'name': 'P. Daoutidis'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1021/ACS.IECR.8B04189?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/ACS.IECR.8B04189, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","small-scale renewable-powered ammonia production is more sustainable than the current fossil fuel- and energy-intensive method. the development of lower capital cost absorbent-enhanced ammonia synthesis as well as the concept of modular chemical processes may improve the economic feasibility of such a paradigm. this possibility is investigated through an ammonia supply chain optimization study wherein modular, wind-powered ammonia production based on this new technology can be added to the existing infrastructure. the benefit of modularity is captured via a mass production exponent which reduces per-module capital cost as more are constructed. case studies for minnesota and iowa show first adoption of 8760 t/y modules at conventional ammonia prices of $610/t and $574/t, respectively, which are considerably lower than those required for incorporation of scaled-down haber–bosch. for mass production exponents of 0.9 and less, modular production results in lower supply chain cost and more renewable incorporat...",
dcc7c284791a3fd75c8d10361a62a08833b228ec,A framework for ammonia supply chain optimization incorporating conventional and renewable generation,"Ammonia is an essential nutrient for global food production brought to farmers by a well-established supply chain. This article introduces a supply chain optimization framework which incorporates new renewable ammonia plants into the conventional ammonia supply chain. Both economic and environmental objectives are considered. The framework is then applied to two separate case studies analyzing the supply chains of Minnesota and Iowa, respectively. The base case results present an expected trade-off between cost, which favors purchasing ammonia from conventional plants, and emissions, which favor building distributed renewable ammonia plants. Further analysis of this trade-off shows that a carbon tax above $25/t will reduce emissions in the optimal supply chain through building large renewable plants. The importance of scale is emphasized through a Monte Carlo sensitivity analysis, as the largest scale renewable plants are selected most often in the optimal supply chain. © 2017 American Institute of Chemical Engineers AIChE J, 63: 4390–4402, 2017",2017,"[{'authorId': '14216374', 'name': 'A. Allman'}, {'authorId': '1972885', 'name': 'P. Daoutidis'}, {'authorId': '37939261', 'name': 'D. Tiffany'}, {'authorId': '40585893', 'name': 'S. Kelley'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/AIC.15838?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/AIC.15838, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ammonia is an essential nutrient for global food production brought to farmers by a well-established supply chain. this article introduces a supply chain optimization framework which incorporates new renewable ammonia plants into the conventional ammonia supply chain. both economic and environmental objectives are considered. the framework is then applied to two separate case studies analyzing the supply chains of minnesota and iowa, respectively. the base case results present an expected trade-off between cost, which favors purchasing ammonia from conventional plants, and emissions, which favor building distributed renewable ammonia plants. further analysis of this trade-off shows that a carbon tax above $25/t will reduce emissions in the optimal supply chain through building large renewable plants. the importance of scale is emphasized through a monte carlo sensitivity analysis, as the largest scale renewable plants are selected most often in the optimal supply chain. © 2017 american institute of chemical engineers aiche j, 63: 4390–4402, 2017",
4fcc252186787901f110e15ec35783752dc97591,The New Generation of Operations Research Methods in Supply Chain Optimization: A Review,"The possibilities of applying Operations Research (O.R.) techniques in the design of real-world systems are vast. The optimization and design of the supply chain network (SCN) is one of the relevant topics that has directed the attention of many scholars. Sound decisions in this regard, including the proper selection of the facility’s location, transportation modes and routes and inventory management policies, can noticeably improve the systems performance. Over 380 articles published between 2005 and 2016 in the ISI/Web of Science database have applied advanced O.R. techniques in SCN optimization studies. This paper offers a systematic review of these published contributions by focusing on two categories of O.R. approaches most recently applied for the design of SC systems: integrated mathematical modeling and simulation-optimization (S-O) frameworks. A taxonomy analysis of the mentioned approaches is presented based on the supply chain elements. A bibliometric analysis is also conducted to provide technical insights into the possible gaps in the field. Moreover, the relevant studies on SC sustainability are highlighted. The research results are supportive of the S-O frameworks as either an alternative approach or an effective solution method for the integrated problems. The research outcomes can provide researchers in the field with useful details of the integrated problems and S-O frameworks as the most recent O.R. methodologies in the field of SC optimization.",2016,"[{'authorId': '66593585', 'name': 'Pourya Pourhejazy'}, {'authorId': '50466428', 'name': 'O. Kwon'}]","{'url': 'https://www.mdpi.com/2071-1050/8/10/1033/pdf?version=1476686912', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/SU8101033?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/SU8101033, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the possibilities of applying operations research (o.r.) techniques in the design of real-world systems are vast. the optimization and design of the supply chain network (scn) is one of the relevant topics that has directed the attention of many scholars. sound decisions in this regard, including the proper selection of the facility’s location, transportation modes and routes and inventory management policies, can noticeably improve the systems performance. over 380 articles published between 2005 and 2016 in the isi/web of science database have applied advanced o.r. techniques in scn optimization studies. this paper offers a systematic review of these published contributions by focusing on two categories of o.r. approaches most recently applied for the design of sc systems: integrated mathematical modeling and simulation-optimization (s-o) frameworks. a taxonomy analysis of the mentioned approaches is presented based on the supply chain elements. a bibliometric analysis is also conducted to provide technical insights into the possible gaps in the field. moreover, the relevant studies on sc sustainability are highlighted. the research results are supportive of the s-o frameworks as either an alternative approach or an effective solution method for the integrated problems. the research outcomes can provide researchers in the field with useful details of the integrated problems and s-o frameworks as the most recent o.r. methodologies in the field of sc optimization.",https://www.mdpi.com/2071-1050/8/10/1033/pdf?version=1476686912
3ff3b1df8f4c2f8b1e5b287dc62e6fe71986f883,Supply Chain Disruption versus Optimization: A Review on Artificial Intelligence and Blockchain,"In response to significant disruption, supply chain optimization became sensitive to increasing consumer expectations, unexpected demand fluctuation, and inventory costs. Proactive movement, understanding, and empowerment have fostered the beneficial results of supply chain optimization, cooperation, and operational resilience. These pioneering activities are critical to achieving a paradigm shift in the supply chain, even agility in response to changing demand. However, sophisticated analytics such as artificial intelligence (AI) and blockchain are supposed to overcome these challenges to make smarter decisions on a daily basis. Due to these facts, this study aimed to model AI’s and blockchain’s role in supply chain optimization by conducting a systematic literature review based on the idealized framework of Rejeb et al., (2022) and the SALSA mechanism. In addition, this paradigm-shifting approach will provide fairer views and options for managing forecasting, planning, monitoring, and reporting across the entire supply chain. The emphasis remains on real-time accuracy, easy access, and optimization of operational indicators such as sales, visibility, and end-to-end supply chain operations at all times and from any location. It will be an eye-opening experience to enable stakeholders and partners to communicate information collaboratively, consistently, and efficiently.",2023,"[{'authorId': '70538324', 'name': 'M. Kashem'}, {'authorId': '104666236', 'name': 'M. Shamsuddoha'}, {'authorId': '97294474', 'name': 'Tasnuba Nasir'}, {'authorId': '2196379734', 'name': 'Asma Akter Chowdhury'}]","{'url': 'https://www.mdpi.com/2673-9585/3/1/7/pdf?version=1676974009', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/knowledge3010007?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/knowledge3010007, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in response to significant disruption, supply chain optimization became sensitive to increasing consumer expectations, unexpected demand fluctuation, and inventory costs. proactive movement, understanding, and empowerment have fostered the beneficial results of supply chain optimization, cooperation, and operational resilience. these pioneering activities are critical to achieving a paradigm shift in the supply chain, even agility in response to changing demand. however, sophisticated analytics such as artificial intelligence (ai) and blockchain are supposed to overcome these challenges to make smarter decisions on a daily basis. due to these facts, this study aimed to model ai’s and blockchain’s role in supply chain optimization by conducting a systematic literature review based on the idealized framework of rejeb et al., (2022) and the salsa mechanism. in addition, this paradigm-shifting approach will provide fairer views and options for managing forecasting, planning, monitoring, and reporting across the entire supply chain. the emphasis remains on real-time accuracy, easy access, and optimization of operational indicators such as sales, visibility, and end-to-end supply chain operations at all times and from any location. it will be an eye-opening experience to enable stakeholders and partners to communicate information collaboratively, consistently, and efficiently.",https://www.mdpi.com/2673-9585/3/1/7/pdf?version=1676974009
48f73beea48fbf03c8c216339b56c0de288d0bde,Uncertainty Analysis and Optimization Modeling with Application to Supply Chain Management: A Systematic Review,"In recent years, there have been frequent cases of impact on the stable development of supply chain economy caused by uncertain events such as COVID-19 and extreme weather events. The creation, management, and impact coping techniques of the supply chain economy now face wholly novel requirements as a result of the escalating level of global uncertainty. Although a significant literature applies uncertainty analysis and optimization modeling (UAO) to study supply chain management (SCM) under uncertainty, there is a lack of systematic literature review and research classification. Therefore, in this paper, 121 articles published in 44 international academic journals between 2015 and 2022 are extracted from the Web of Science database and reviewed using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). Bibliometric analysis and CiteSpace software are used to identify current developments in the field and to summarize research characteristics and hot topics. The selected published articles are classified and analyzed by author name, year of publication, application area, country, research purposes, modeling methods, research gaps and contributions, research results, and journals to comprehensively review and evaluate the SCM in the application of UAO. We find that UAO is widely used in SCM under uncertainty, especially in the field of decision-making, where it is common practice to abstractly model the decision problem to obtain scientific decision results. This study hopes to provide an important and valuable reference for future research on SCM under uncertainty. Future research could combine uncertainty theory with supply chain management segments (e.g., emergency management, resilience management, and security management), behavioral factors, big data technologies, artificial intelligence, etc.",2023,"[{'authorId': '2118537010', 'name': 'Lin Chen'}, {'authorId': '2061034539', 'name': 'Ting Dong'}, {'authorId': '2179532315', 'name': 'Jin Peng'}, {'authorId': '50057290', 'name': 'D. Ralescu'}]","{'url': 'https://www.mdpi.com/2227-7390/11/11/2530/pdf?version=1685536415', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/math11112530?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/math11112530, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in recent years, there have been frequent cases of impact on the stable development of supply chain economy caused by uncertain events such as covid-19 and extreme weather events. the creation, management, and impact coping techniques of the supply chain economy now face wholly novel requirements as a result of the escalating level of global uncertainty. although a significant literature applies uncertainty analysis and optimization modeling (uao) to study supply chain management (scm) under uncertainty, there is a lack of systematic literature review and research classification. therefore, in this paper, 121 articles published in 44 international academic journals between 2015 and 2022 are extracted from the web of science database and reviewed using the preferred reporting items for systematic reviews and meta-analyses (prisma). bibliometric analysis and citespace software are used to identify current developments in the field and to summarize research characteristics and hot topics. the selected published articles are classified and analyzed by author name, year of publication, application area, country, research purposes, modeling methods, research gaps and contributions, research results, and journals to comprehensively review and evaluate the scm in the application of uao. we find that uao is widely used in scm under uncertainty, especially in the field of decision-making, where it is common practice to abstractly model the decision problem to obtain scientific decision results. this study hopes to provide an important and valuable reference for future research on scm under uncertainty. future research could combine uncertainty theory with supply chain management segments (e.g., emergency management, resilience management, and security management), behavioral factors, big data technologies, artificial intelligence, etc.",https://www.mdpi.com/2227-7390/11/11/2530/pdf?version=1685536415
93b2014dbaa801117a5514ce3af1f29cbd9c7791,METHODOLOGY AND ALGORITHM FOR ASPHALT SUPPLY CHAIN OPTIMIZATION,"In this paper authors suggest and test evolutionary algorithm of multiple criteria solver (MCS) for asphalt supply chain optimization. On the basis of the defined imperfection of the basic mathematical model authors made an algorithm and conducted simulations of transportation problems cases generated from the given realistic input intervals in order to determine the constraints and possibilities for improvement of the original model of the transportation problem of large amounts of asphalt mixture. Results have shown that the suggested model verifies and eliminates the lack of the original model. As well, it is shown in which scenarios of transportation problem and to which extent the suggested methodology contributes to the total transportation costs savings and insurance of the program’s optimality.",2016,"[{'authorId': '71816462', 'name': 'M. Galić'}, {'authorId': '72330878', 'name': 'I. Zavrski'}, {'authorId': '1412367678', 'name': 'Zlata Dolaček-Alduk'}]","{'url': 'https://doi.org/10.17559/tv-20150623140015', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.17559/TV-20150623140015?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.17559/TV-20150623140015, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this paper authors suggest and test evolutionary algorithm of multiple criteria solver (mcs) for asphalt supply chain optimization. on the basis of the defined imperfection of the basic mathematical model authors made an algorithm and conducted simulations of transportation problems cases generated from the given realistic input intervals in order to determine the constraints and possibilities for improvement of the original model of the transportation problem of large amounts of asphalt mixture. results have shown that the suggested model verifies and eliminates the lack of the original model. as well, it is shown in which scenarios of transportation problem and to which extent the suggested methodology contributes to the total transportation costs savings and insurance of the program’s optimality.",https://doi.org/10.17559/tv-20150623140015
33e7356dd3308650dde08c5356ddb9a33b3e76b0,Electric vehicle battery chemistry affects supply chain disruption vulnerabilities,"We examine the relationship between electric vehicle battery chemistry and supply chain disruption vulnerability for four critical minerals: lithium, cobalt, nickel, and manganese. We compare the nickel manganese cobalt (NMC) and lithium iron phosphate (LFP) cathode chemistries by (1) mapping the supply chains for these four materials, (2) calculating a vulnerability index for each cathode chemistry for various focal countries and (3) using network flow optimization to bound uncertainties. World supply is currently vulnerable to disruptions in China for both chemistries: 80% [71% to 100%] of NMC cathodes and 92% [90% to 93%] of LFP cathodes include minerals that pass through China. NMC has additional risks due to concentrations of nickel, cobalt, and manganese in other countries. The combined vulnerability of multiple supply chain stages is substantially larger than at individual steps alone. Our results suggest that reducing risk requires addressing vulnerabilities across the entire battery supply chain.",2024,"[{'authorId': '2290389327', 'name': 'Anthony L. Cheng'}, {'authorId': '2290387989', 'name': 'Erica R. H. Fuchs'}, {'authorId': '4648077', 'name': 'V. Karplus'}, {'authorId': '2284047083', 'name': 'Jeremy J. Michalek'}]","{'url': 'https://www.nature.com/articles/s41467-024-46418-1.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10923860, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we examine the relationship between electric vehicle battery chemistry and supply chain disruption vulnerability for four critical minerals: lithium, cobalt, nickel, and manganese. we compare the nickel manganese cobalt (nmc) and lithium iron phosphate (lfp) cathode chemistries by (1) mapping the supply chains for these four materials, (2) calculating a vulnerability index for each cathode chemistry for various focal countries and (3) using network flow optimization to bound uncertainties. world supply is currently vulnerable to disruptions in china for both chemistries: 80% [71% to 100%] of nmc cathodes and 92% [90% to 93%] of lfp cathodes include minerals that pass through china. nmc has additional risks due to concentrations of nickel, cobalt, and manganese in other countries. the combined vulnerability of multiple supply chain stages is substantially larger than at individual steps alone. our results suggest that reducing risk requires addressing vulnerabilities across the entire battery supply chain.",https://www.nature.com/articles/s41467-024-46418-1.pdf
3a70fd0cfb0fc943c0bbb51c9b64f49caf5364d4,Hybrid Fuzzy and Data-Driven Robust Optimization for Resilience and Sustainable Health Care Supply Chain with Vendor-Managed Inventory Approach,"One of the problems that government managers deal with are medical inventory management in COVID-19 conditions. Based on this situation, the best strategy for managing and reducing inventory costs can be Vendor-Managed Inventory (VMI) policy in the recent decade. Therefore, a hybrid fuzzy and data-driven robust optimization for Resilience and Sustainable Health Care Supply Chain (RSHCSC) with VMI approach is appropriate for improving the inventory management system and tackling uncertainty and disruption in this situation. Three RSHCSC models are suggested using hybrid fuzzy and data-driven robust optimization with a stochastic programming approach. The first model is average and mean absolute function, the second model is Conditional Value at Risk (CVaR), the third model is Minimax model, and the final model is the traditional inventory model. Each of the proposed models has advantages and disadvantages that depend on the conservative level of decision-maker. Sensitivity analysis is done on essential parameters like fuzzy cut, confidence level, robust and resilience coefficient, and size models. The results show that increasing fuzzy cut, confidence level, robustification coefficient, resiliency coefficient, and CVaR confidence level amount of costs grows. The Minimax function is suitable for conservative decision-makers.",2022,"[{'authorId': '1813738473', 'name': 'Reza Lotfi'}, {'authorId': '1581794713', 'name': 'Bahareh Kargar'}, {'authorId': '1409205424', 'name': 'M. Rajabzadeh'}, {'authorId': '2152016915', 'name': 'Fatemeh Hesabi'}, {'authorId': '3205065', 'name': 'Eren Özceylan'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s40815-021-01209-4.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8805141, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","one of the problems that government managers deal with are medical inventory management in covid-19 conditions. based on this situation, the best strategy for managing and reducing inventory costs can be vendor-managed inventory (vmi) policy in the recent decade. therefore, a hybrid fuzzy and data-driven robust optimization for resilience and sustainable health care supply chain (rshcsc) with vmi approach is appropriate for improving the inventory management system and tackling uncertainty and disruption in this situation. three rshcsc models are suggested using hybrid fuzzy and data-driven robust optimization with a stochastic programming approach. the first model is average and mean absolute function, the second model is conditional value at risk (cvar), the third model is minimax model, and the final model is the traditional inventory model. each of the proposed models has advantages and disadvantages that depend on the conservative level of decision-maker. sensitivity analysis is done on essential parameters like fuzzy cut, confidence level, robust and resilience coefficient, and size models. the results show that increasing fuzzy cut, confidence level, robustification coefficient, resiliency coefficient, and cvar confidence level amount of costs grows. the minimax function is suitable for conservative decision-makers.",https://link.springer.com/content/pdf/10.1007/s40815-021-01209-4.pdf
1a3da4fea27b6b171eca46f82c9d8be65f93ad52,Fair profit allocation in supply chain optimization with transfer price and revenue sharing: MINLP model and algorithm for cellulosic biofuel supply chains,"A mixed-integer nonlinear programming (MINLP) formulation to simultaneously optimize operational decisions as well as profit allocation mechanisms in supply chain optimization, namely material transfer prices and revenue share policies among the supply chain participants is proposed. The case of cellulosic bioethanol supply chains is specifically considered and the game-theory Nash bargaining solution approach is employed to achieve fair allocation of profit among the collection facilities, biorefineries, and distribution centers. The structural advantages of certain supply chain participants can be taken into account by specifying different values of the negotiation-power indicators in the generalized Nash-type objective function. A solution strategy based on a logarithm transformation and a branch-and-refine algorithm for efficient global optimization of the resulting nonconvex MINLP problem is proposed. To demonstrate the application of the proposed framework, an illustrative example and a state-wide county-level case study on the optimization of a potential cellulosic bioethanol supply chain in Illinois are presented. © 2014 American Institute of Chemical Engineers AIChE J, 60: 3211–3229, 2014",2014,"[{'authorId': '36289039', 'name': 'D. Yue'}, {'authorId': '2647121', 'name': 'F. You'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/AIC.14511?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/AIC.14511, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a mixed-integer nonlinear programming (minlp) formulation to simultaneously optimize operational decisions as well as profit allocation mechanisms in supply chain optimization, namely material transfer prices and revenue share policies among the supply chain participants is proposed. the case of cellulosic bioethanol supply chains is specifically considered and the game-theory nash bargaining solution approach is employed to achieve fair allocation of profit among the collection facilities, biorefineries, and distribution centers. the structural advantages of certain supply chain participants can be taken into account by specifying different values of the negotiation-power indicators in the generalized nash-type objective function. a solution strategy based on a logarithm transformation and a branch-and-refine algorithm for efficient global optimization of the resulting nonconvex minlp problem is proposed. to demonstrate the application of the proposed framework, an illustrative example and a state-wide county-level case study on the optimization of a potential cellulosic bioethanol supply chain in illinois are presented. © 2014 american institute of chemical engineers aiche j, 60: 3211–3229, 2014",
94468b5931b2102f87ae7c04a3310ac93f3e9422,A hybrid optimization method to design a sustainable resilient supply chain in a perishable food industry,"To integrate the location, inventory, and routing (LIR) problems arising in designing a resilient sustainable perishable food supply network (RSPFSN), a bi-objective optimization model is developed. To improve the resiliency and sustainability of the RSPFSN, a dynamic pricing strategy is used to cope with the disrupting events, along with minimizing the total cost and CO_2 emission of the whole network. One of the important features of the proposed model is taking into account the effects of route disruptions and traffic conditions on the deterioration of products. To solve the mixed-integer nonlinear bi-objective optimization model, a novel hybrid method is developed using the Heuristic Multi-Choice Goal Programming and Utility Function Genetics Algorithm (HMCGP-UFGA). To improve resiliency, the dynamic pricing strategy, considering the traffic condition, can lead to around a 20% improvement in both cost and CO_2 emission, based on the results of our case study in a dairy supply chain. Besides, the results of sensitivity analysis display the high flexibility of the proposed approach for various problems.",2022,"[{'authorId': '2182148069', 'name': 'Mahyar Abbasian'}, {'authorId': '2512769', 'name': 'Z. Sazvar'}, {'authorId': '2107055622', 'name': 'Mohammadhossein Mohammadisiahroudi'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s11356-022-22115-8.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9392506, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","to integrate the location, inventory, and routing (lir) problems arising in designing a resilient sustainable perishable food supply network (rspfsn), a bi-objective optimization model is developed. to improve the resiliency and sustainability of the rspfsn, a dynamic pricing strategy is used to cope with the disrupting events, along with minimizing the total cost and co_2 emission of the whole network. one of the important features of the proposed model is taking into account the effects of route disruptions and traffic conditions on the deterioration of products. to solve the mixed-integer nonlinear bi-objective optimization model, a novel hybrid method is developed using the heuristic multi-choice goal programming and utility function genetics algorithm (hmcgp-ufga). to improve resiliency, the dynamic pricing strategy, considering the traffic condition, can lead to around a 20% improvement in both cost and co_2 emission, based on the results of our case study in a dairy supply chain. besides, the results of sensitivity analysis display the high flexibility of the proposed approach for various problems.",https://link.springer.com/content/pdf/10.1007/s11356-022-22115-8.pdf
946e324d21898cdd6b7f1d3bbc1f38b9c0096c7c,An optimization model for fresh-food electronic commerce supply chain with carbon emissions and food waste,"ABSTRACT This study contributes to the fresh food supply chain system due to the lack of carbon emissions and food waste reduction that the prior studies neglected. This study examines a fresh-food supply chain system with multiple farmers, a single processor, multi-distributor, customers, and multiple periods. This paper presents a mixed-integer linear programming to optimize total purchasing, inspection, food waste, packing, cold storage, transportation, and carbon emission costs by optimizing product inventories and deliveries. The model is also validated to provide insights into relevant industries. The results show that the total distribution cost from distributor to customers, the total purchasing cost, and total packaging cost are 38.68%; 25.87%; and 16.84%, respectively. In addition, sensitivity analyzes show that the total costs and emissions are significantly affected by the variance in temperature control, carbon punishing cost, and vehicle types. Furthermore, this research can guide the decision-makers by considering the influence of these parameters. Graphical abstract",2022,"[{'authorId': '101429688', 'name': 'I. D. Wangsa'}, {'authorId': '2025833', 'name': 'I. Vanany'}, {'authorId': '3222482', 'name': 'N. Siswanto'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/21681015.2022.2099473?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/21681015.2022.2099473, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract this study contributes to the fresh food supply chain system due to the lack of carbon emissions and food waste reduction that the prior studies neglected. this study examines a fresh-food supply chain system with multiple farmers, a single processor, multi-distributor, customers, and multiple periods. this paper presents a mixed-integer linear programming to optimize total purchasing, inspection, food waste, packing, cold storage, transportation, and carbon emission costs by optimizing product inventories and deliveries. the model is also validated to provide insights into relevant industries. the results show that the total distribution cost from distributor to customers, the total purchasing cost, and total packaging cost are 38.68%; 25.87%; and 16.84%, respectively. in addition, sensitivity analyzes show that the total costs and emissions are significantly affected by the variance in temperature control, carbon punishing cost, and vehicle types. furthermore, this research can guide the decision-makers by considering the influence of these parameters. graphical abstract",
a295ce37181c490c4d43710e68633ac9f3fbc436,A Review of Relief Supply Chain Optimization,"With a steep increase of the global disaster relief efforts around the world, the relief supply chain and humanitarian logistics play an important role to address this issue. A broad overview of operations research ranges from a principle or conceptual framework to analytical methodology and case study applied in this field. In this paper, we provide an overview of this challenging research area with emphasis on the corresponding optimization problems. The scope of this study begins with classification by the stage of the disaster lifecycle system. The characteristics of each optimization problem for the disaster supply chain are considered in detail as well as the logistics features. We found that the papers related to disaster relief can be grouped in three aspects in terms of logistics attributes: facility location, distribution model, and inventory model. Furthermore, the literature also analyzes objectives and solution algorithms proposed in each optimization model in order to discover insights, research gaps and findings. Finally, we offer future research directions based on our findings from the investigation of literature review.",2014,"[{'authorId': '3301281', 'name': 'W. Manopiniwes'}, {'authorId': '70245609', 'name': 'T. Irohara'}]","{'url': 'http://society.kisti.re.kr/sv/SV_svpsbs03V.do?method=download&cn1=JAKO201411560023616', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.7232/IEMS.2014.13.1.001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.7232/IEMS.2014.13.1.001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with a steep increase of the global disaster relief efforts around the world, the relief supply chain and humanitarian logistics play an important role to address this issue. a broad overview of operations research ranges from a principle or conceptual framework to analytical methodology and case study applied in this field. in this paper, we provide an overview of this challenging research area with emphasis on the corresponding optimization problems. the scope of this study begins with classification by the stage of the disaster lifecycle system. the characteristics of each optimization problem for the disaster supply chain are considered in detail as well as the logistics features. we found that the papers related to disaster relief can be grouped in three aspects in terms of logistics attributes: facility location, distribution model, and inventory model. furthermore, the literature also analyzes objectives and solution algorithms proposed in each optimization model in order to discover insights, research gaps and findings. finally, we offer future research directions based on our findings from the investigation of literature review.",http://society.kisti.re.kr/sv/SV_svpsbs03V.do?method=download&cn1=JAKO201411560023616
1279a08827a1937422186b4a759553b84817d7aa,Energy supply chain optimization of hybrid feedstock processes: a review.,"The economic, environmental, and social performances of energy systems depend on their geographical locations and the surrounding market infrastructure for feedstocks and energy products. Strategic decisions to locate energy conversion facilities must take all upstream and downstream operations into account, prompting the development of supply chain modeling and optimization methods. This article reviews the contributions of energy supply chain studies that include heat, power, and liquid fuels production. Studies are categorized based on specific features of the mathematical model, highlighting those that address energy supply chain models with and without considerations of multiperiod decisions. Studies that incorporate uncertainties are discussed, and opportunities for future research developments are outlined.",2014,"[{'authorId': '39094920', 'name': 'J. Elia'}, {'authorId': '1696826', 'name': 'C. Floudas'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1146/annurev-chembioeng-060713-040425?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/annurev-chembioeng-060713-040425, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the economic, environmental, and social performances of energy systems depend on their geographical locations and the surrounding market infrastructure for feedstocks and energy products. strategic decisions to locate energy conversion facilities must take all upstream and downstream operations into account, prompting the development of supply chain modeling and optimization methods. this article reviews the contributions of energy supply chain studies that include heat, power, and liquid fuels production. studies are categorized based on specific features of the mathematical model, highlighting those that address energy supply chain models with and without considerations of multiperiod decisions. studies that incorporate uncertainties are discussed, and opportunities for future research developments are outlined.",
7f7de97203f40cf820a51f82de8486e9328e33d0,"Nationwide, Regional, and Statewide Energy Supply Chain Optimization for Natural Gas to Liquid Transportation Fuel (GTL) Systems","An optimization-based supply chain framework is proposed for the nationwide, regional, and statewide analyses of natural gas to liquids (GTL) systems for the United States. With optimized GTL refineries of differing capacities (i.e., 1, 5, 10, 50, and 200 thousand barrels per day) and fuel product ratios (i.e., unrestricted, maximization of diesel, maximization of kerosene, and commensurate with the United States demand), the optimal nationwide, regional, and statewide supply chains are obtained by solving a large-scale mixed-integer linear optimization (MILP) model that minimizes the total cost of fuel production. The mathematical formulation includes the locations of natural gas in the United States discretized by county, the delivery locations of fuel products, the transportation costs of every input and output of the refinery, the material balances of each GTL refinery, water resources, electricity requirements/production of the supply chain, and the CO2 sequestration capacities in the United States. ...",2014,"[{'authorId': '39094920', 'name': 'J. Elia'}, {'authorId': '2382412', 'name': 'Richard C. Baliban'}, {'authorId': '1696826', 'name': 'C. Floudas'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1021/IE401378R?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/IE401378R, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","an optimization-based supply chain framework is proposed for the nationwide, regional, and statewide analyses of natural gas to liquids (gtl) systems for the united states. with optimized gtl refineries of differing capacities (i.e., 1, 5, 10, 50, and 200 thousand barrels per day) and fuel product ratios (i.e., unrestricted, maximization of diesel, maximization of kerosene, and commensurate with the united states demand), the optimal nationwide, regional, and statewide supply chains are obtained by solving a large-scale mixed-integer linear optimization (milp) model that minimizes the total cost of fuel production. the mathematical formulation includes the locations of natural gas in the united states discretized by county, the delivery locations of fuel products, the transportation costs of every input and output of the refinery, the material balances of each gtl refinery, water resources, electricity requirements/production of the supply chain, and the co2 sequestration capacities in the united states. ...",
0183a5914dcf16b81f617b4902234577428c53ab,Fuzzy mathematical programming approaches for reverse supply chain optimization with disassembly line balancing problem,"Today, the requirement of reverse supply chain RSC optimization takes more attention due to environmental and competitive factors. However, increasing attention and existing uncertainty in RSC also increases the difficulties for decisions of production/distribution planning. Therefore, considering strategic and tactical decisions together under fuzziness is being essential. This paper presents a fuzzy programming approach to the integration of RSC optimization strategic level and disassembly line balancing DLB tactical level problems. The aim of this study is to apply fuzzy modeling to optimize a RSC that involves customers, collection/disassembly centers and plants while balancing the disassembly lines in disassembly centers, simultaneously. Two types of fuzzy mathematical programming models with different aggregation operators are used. Finally, accuracy and applicability of the model is illustrated and a comparison of fuzzy approaches is done via a hypothetical example.",2014,"[{'authorId': '3205065', 'name': 'Eren Özceylan'}, {'authorId': '2626951', 'name': 'T. Paksoy'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3233/IFS-130875?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3233/IFS-130875, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","today, the requirement of reverse supply chain rsc optimization takes more attention due to environmental and competitive factors. however, increasing attention and existing uncertainty in rsc also increases the difficulties for decisions of production/distribution planning. therefore, considering strategic and tactical decisions together under fuzziness is being essential. this paper presents a fuzzy programming approach to the integration of rsc optimization strategic level and disassembly line balancing dlb tactical level problems. the aim of this study is to apply fuzzy modeling to optimize a rsc that involves customers, collection/disassembly centers and plants while balancing the disassembly lines in disassembly centers, simultaneously. two types of fuzzy mathematical programming models with different aggregation operators are used. finally, accuracy and applicability of the model is illustrated and a comparison of fuzzy approaches is done via a hypothetical example.",
4a00a7e578054996430fe88ed26fbfe1bd85fb19,Optimization Approaches for Multiple Conflicting Objectives in Sustainable Green Supply Chain Management,"Over the years, the global supply chain has evolved into a more extensive interconnected complex network with multiple suppliers, manufacturers, and customers. Since environmental issues have become a burning question in recent years, the focus has shifted to attaining sustainability in supply chain management. The green supply chain or sustainable network is a concept to reduce environmental impacts in the life cycle of a product. However, green supply chain management is often challenged with additional operating costs and difficulty monitoring the implications within the complex network system. Additionally, many stakeholders are unaware of the importance of sustainability analysis, which eventually complicates adopting green cultures in actual applications. Since green supply chain management deals with multiple aspects, such as cost and carbon emission, the multiobjective optimization method is widely used to evaluate supply chain performance. This paper intensively reviews the state-of-the-art literature on applying multiobjective optimization techniques in green supply chain management. The study highlights aspects of green supply chain structures, model formulation techniques considering multiple objectives simultaneously, and solution methods for multiobjective optimization problems. Finally, a conclusion is drawn with the scope of the potential research opportunities for integrating economic and environmental considerations in sustainable supply chain management practice.",2022,"[{'authorId': '2187606700', 'name': 'L. N. Asha'}, {'authorId': '48839212', 'name': 'Arup Dey'}, {'authorId': '24287459', 'name': 'Nita Yodo'}, {'authorId': '66576098', 'name': 'Lucy G. Aragon'}]","{'url': 'https://www.mdpi.com/2071-1050/14/19/12790/pdf?version=1665476710', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su141912790?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su141912790, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","over the years, the global supply chain has evolved into a more extensive interconnected complex network with multiple suppliers, manufacturers, and customers. since environmental issues have become a burning question in recent years, the focus has shifted to attaining sustainability in supply chain management. the green supply chain or sustainable network is a concept to reduce environmental impacts in the life cycle of a product. however, green supply chain management is often challenged with additional operating costs and difficulty monitoring the implications within the complex network system. additionally, many stakeholders are unaware of the importance of sustainability analysis, which eventually complicates adopting green cultures in actual applications. since green supply chain management deals with multiple aspects, such as cost and carbon emission, the multiobjective optimization method is widely used to evaluate supply chain performance. this paper intensively reviews the state-of-the-art literature on applying multiobjective optimization techniques in green supply chain management. the study highlights aspects of green supply chain structures, model formulation techniques considering multiple objectives simultaneously, and solution methods for multiobjective optimization problems. finally, a conclusion is drawn with the scope of the potential research opportunities for integrating economic and environmental considerations in sustainable supply chain management practice.",https://www.mdpi.com/2071-1050/14/19/12790/pdf?version=1665476710
dbf9421d70055e750dc6554161a3ea691a4d5037,Optimization Of The Trust Propagation On Supply Chain Network Based On Blockchain Plus,"The decentralization of blockchain technology greatly improves the trust relationship in the supply chain network. In view of the lack of trust, uncertainty, and asymmetry in the supply chain network, this paper integrates the blockchain technology to build a network dynamics model of trust representation, calculation, and propagation, and explores how the blockchain influences the supply chain network. The result indicates that the network scale increased by 115.89%, the network connectivity increased by 60.31%, and the average shortest path decreased by 4.95%, after the blockchain trust framework had been deployed in the agricultural supply chain. Meanwhile, the network topology performance such as degree distribution and average clustering coefficient were optimized to varying degrees. Taking agricultural supply chain as an example, the practical significance of topological change was explained. Overall, the blockchain trust mechanism improves the topology of the supply chain network by affecting the trust relationship between nodes.",2022,"[{'authorId': '2119322767', 'name': 'Ling Chen'}, {'authorId': '96679021', 'name': 'Shan Su'}]","{'url': 'https://library.acadlore.com/JIMD/2022/1/1/JIMD_01.01_03.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.56578/jimd010103?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.56578/jimd010103, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the decentralization of blockchain technology greatly improves the trust relationship in the supply chain network. in view of the lack of trust, uncertainty, and asymmetry in the supply chain network, this paper integrates the blockchain technology to build a network dynamics model of trust representation, calculation, and propagation, and explores how the blockchain influences the supply chain network. the result indicates that the network scale increased by 115.89%, the network connectivity increased by 60.31%, and the average shortest path decreased by 4.95%, after the blockchain trust framework had been deployed in the agricultural supply chain. meanwhile, the network topology performance such as degree distribution and average clustering coefficient were optimized to varying degrees. taking agricultural supply chain as an example, the practical significance of topological change was explained. overall, the blockchain trust mechanism improves the topology of the supply chain network by affecting the trust relationship between nodes.",https://library.acadlore.com/JIMD/2022/1/1/JIMD_01.01_03.pdf
e3258d47aefa511af753baaaeef53e3a3176b84a,Optimization of Meat and Poultry Farm Inventory Stock Using Data Analytics for Green Supply Chain Network,"The traditional meat and poultry farms use a fixed quantity of supply, which creates an imbalance between demand and supply. Due to this imbalance, a huge amount is spent on balancing the requirements. There is an inequality among demand and supply since typical meat and poultry farms use a fixed amount of supply. A lot of money is spent trying to balance the requirements because of this mismatch. In addition, when connecting and building the meat and poultry farm system, the procedure ignores the impact on the environment. The owner’s primary goals are to retain massive profits and raise reliability. The classical method neglects the effect on the environment while linking and designing the meat and poultry farm system. The main aim of the owner is to increase the quality and maintain the maximum profit. This paper deals with the meat and poultry farms in two folds. In the first step, the IoT based system is implemented for the traceability and demand-supply monitoring. The second steps include optimization of the supply network to reduce the carbon emission from the transportation. Both steps take data analytics as an input to process the final result for the farm to run and optimize. Effective inventory optimization algorithms have been shown to be able to evaluate a significant portion of previous sales data and anticipate inventory future demand by taking seasonality and lead times into account. Revenue, productivity, and customer satisfaction are just a few of the business variables that these strategies may affect. Finally, the comparison is done with the traditional farm and supply chain on the points of demand-supply balance, cost, carbon emission, and wastage. It is found that the farms using data analytics to optimize the overall system perform better and with 37% more efficient than the traditional systems.",2022,"[{'authorId': '93741825', 'name': 'Rajnish Kler'}, {'authorId': '84599560', 'name': 'Roshan Gangurde'}, {'authorId': '120895078', 'name': 'Samariddin Elmirzaev'}, {'authorId': '145437540', 'name': 'Md. Shamim Hossain'}, {'authorId': '2179791171', 'name': 'Nhut T. M. Vo'}, {'authorId': '2140156110', 'name': 'Tien V. T. Nguyen'}, {'authorId': '2219814169', 'name': 'P. N. Kumar'}]","{'url': 'https://downloads.hindawi.com/journals/ddns/2022/8970549.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1155/2022/8970549?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1155/2022/8970549, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the traditional meat and poultry farms use a fixed quantity of supply, which creates an imbalance between demand and supply. due to this imbalance, a huge amount is spent on balancing the requirements. there is an inequality among demand and supply since typical meat and poultry farms use a fixed amount of supply. a lot of money is spent trying to balance the requirements because of this mismatch. in addition, when connecting and building the meat and poultry farm system, the procedure ignores the impact on the environment. the owner’s primary goals are to retain massive profits and raise reliability. the classical method neglects the effect on the environment while linking and designing the meat and poultry farm system. the main aim of the owner is to increase the quality and maintain the maximum profit. this paper deals with the meat and poultry farms in two folds. in the first step, the iot based system is implemented for the traceability and demand-supply monitoring. the second steps include optimization of the supply network to reduce the carbon emission from the transportation. both steps take data analytics as an input to process the final result for the farm to run and optimize. effective inventory optimization algorithms have been shown to be able to evaluate a significant portion of previous sales data and anticipate inventory future demand by taking seasonality and lead times into account. revenue, productivity, and customer satisfaction are just a few of the business variables that these strategies may affect. finally, the comparison is done with the traditional farm and supply chain on the points of demand-supply balance, cost, carbon emission, and wastage. it is found that the farms using data analytics to optimize the overall system perform better and with 37% more efficient than the traditional systems.",https://downloads.hindawi.com/journals/ddns/2022/8970549.pdf
7e9955a5a62ec6b5141d4e2fade566546cb43435,Product Selection and Supply Chain Optimization for Fast Pyrolysis and Biorefinery System,"This study determines the optimal plant sizes, locations, and product distributions for an integrated fast pyrolysis biorefinery supply chain using a mixed-integer nonlinear programming (MINLP) model. Hydrogen, liquid fuels, commodity chemicals, and lignin are considered as the potential biorefinery products. The proposed approach is illustrated through a case study of Minnesota, where forest residue is selected as the biomass feedstock. The decisions about biomass supply (roadside chipped forest residue and raw forest residue), facility selection, and product distribution are explored in this case study. The total converted bio-oil is 1.1 million metric tons per year and the total cost is $330 million for the base case. Impacts of marketing prices on product selections are investigated. Compared to upgrading of phase separated bio-oil, whole bio-oil upgrading is preferable in terms of economics. Hydrogen and liquid fuel prices have greater influence on the annualized profit than the commodity chemical price.",2014,"[{'authorId': '2136627027', 'name': 'Yanan Zhang'}, {'authorId': '49708826', 'name': 'M. Wright'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1021/IE503487D?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/IE503487D, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study determines the optimal plant sizes, locations, and product distributions for an integrated fast pyrolysis biorefinery supply chain using a mixed-integer nonlinear programming (minlp) model. hydrogen, liquid fuels, commodity chemicals, and lignin are considered as the potential biorefinery products. the proposed approach is illustrated through a case study of minnesota, where forest residue is selected as the biomass feedstock. the decisions about biomass supply (roadside chipped forest residue and raw forest residue), facility selection, and product distribution are explored in this case study. the total converted bio-oil is 1.1 million metric tons per year and the total cost is $330 million for the base case. impacts of marketing prices on product selections are investigated. compared to upgrading of phase separated bio-oil, whole bio-oil upgrading is preferable in terms of economics. hydrogen and liquid fuel prices have greater influence on the annualized profit than the commodity chemical price.",
fa4478d665f7bc3da51e5accbf76f27519546e88,A robust optimization model for sustainable and resilient closed-loop supply chain network design considering conditional value at risk,"One of the challenges facing supply chain designers is designing a sustainable and resilient supply chain network. The present study considers a closed-loop supply chain by taking into account sustainability, resilience, robustness, and risk aversion for the first time. The study suggests a two-stage mixed-integer linear programming model for the problem. Further, the robust counterpart model is used to handle uncertainties. Furthermore, conditional value at risk criterion in the model is considered in order to create real-life conditions. The sustainability goals addressed in the present study include minimizing the costs, \begin{document}$ \text{CO}_2 $\end{document} emission, and energy, along with maximizing employment. In addition, effective environmental and social life-cycle evaluations are provided to assess the associated effects of the model on society, environment, and energy consumption. The model aims to answer the questions regarding the establishment of facilities and amount of transported goods between facilities. The model is implemented in a car assembler company in Iran. Based on the results, several managerial insights are offered to the decision-makers. Due to the complexity of the problem, a constraint relaxation is applied to produce quality upper and lower bounds in medium and large-scale models. Moreover, the LP-Metric method is used to merge the objectives to attain an optimal solution. The results revealed that the robust counterpart provides a better estimation of the total cost, pollution, energy consumption, and employment level compared to the basic model.",2021,"[{'authorId': '1813738473', 'name': 'Reza Lotfi'}, {'authorId': '1714619', 'name': 'Y. Z. Mehrjerdi'}, {'authorId': '2910123', 'name': 'M. Pishvaee'}, {'authorId': '67225861', 'name': 'A. Sadeghieh'}, {'authorId': '48476415', 'name': 'G. Weber'}]","{'url': 'https://doi.org/10.3934/naco.2020023', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3934/naco.2020023?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3934/naco.2020023, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","one of the challenges facing supply chain designers is designing a sustainable and resilient supply chain network. the present study considers a closed-loop supply chain by taking into account sustainability, resilience, robustness, and risk aversion for the first time. the study suggests a two-stage mixed-integer linear programming model for the problem. further, the robust counterpart model is used to handle uncertainties. furthermore, conditional value at risk criterion in the model is considered in order to create real-life conditions. the sustainability goals addressed in the present study include minimizing the costs, \begin{document}$ \text{co}_2 $\end{document} emission, and energy, along with maximizing employment. in addition, effective environmental and social life-cycle evaluations are provided to assess the associated effects of the model on society, environment, and energy consumption. the model aims to answer the questions regarding the establishment of facilities and amount of transported goods between facilities. the model is implemented in a car assembler company in iran. based on the results, several managerial insights are offered to the decision-makers. due to the complexity of the problem, a constraint relaxation is applied to produce quality upper and lower bounds in medium and large-scale models. moreover, the lp-metric method is used to merge the objectives to attain an optimal solution. the results revealed that the robust counterpart provides a better estimation of the total cost, pollution, energy consumption, and employment level compared to the basic model.",https://doi.org/10.3934/naco.2020023
8ce75dcb07053ecd1fad8eae44291e3da21c7879,Optimization of Inventory Management to Prevent Drug Shortages in the Hospital Supply Chain,"Drug shortage is always a critical issue of inventory management in healthcare systems since it potentially invokes several negative impacts. In supply chain management, optimization goes hand-in-hand with inventory control to address several issues of the supply, management, and use of drugs. However, it is difficult to determine a shortage situation in a hospital due to multiple unpredictable reasons, such as manufacturing problems, supply and demand issues, and raw material problems. To avoid the shortage problem in a hospital, efficient inventory management is required to operate the system in a sustainable way and maximize the profit of the organization in the Hospital Supply Chain (HSC). In this work, we study a drug refilling optimization problem, a general model for drug inventory management in a hospital. We then investigate a Deep Reinforcement Learning (DRL) model to address this problem under an online solution that can automatically make a drug refilling decision in order to prevent a drug shortage. We further present a numerical result to verify the performance of the proposed algorithm, which outperforms the baselines (e.g., over-provisioning, ski-rental, and max-min) in terms of the refilling cost and the shortage rate.",2021,"[{'authorId': '2052705632', 'name': 'Tarek Abu Zwaida'}, {'authorId': '1949053', 'name': 'Chuan Pham'}, {'authorId': '6761380', 'name': 'Yvan Beauregard'}]","{'url': 'https://www.mdpi.com/2076-3417/11/6/2726/pdf?version=1616061757', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/APP11062726?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/APP11062726, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","drug shortage is always a critical issue of inventory management in healthcare systems since it potentially invokes several negative impacts. in supply chain management, optimization goes hand-in-hand with inventory control to address several issues of the supply, management, and use of drugs. however, it is difficult to determine a shortage situation in a hospital due to multiple unpredictable reasons, such as manufacturing problems, supply and demand issues, and raw material problems. to avoid the shortage problem in a hospital, efficient inventory management is required to operate the system in a sustainable way and maximize the profit of the organization in the hospital supply chain (hsc). in this work, we study a drug refilling optimization problem, a general model for drug inventory management in a hospital. we then investigate a deep reinforcement learning (drl) model to address this problem under an online solution that can automatically make a drug refilling decision in order to prevent a drug shortage. we further present a numerical result to verify the performance of the proposed algorithm, which outperforms the baselines (e.g., over-provisioning, ski-rental, and max-min) in terms of the refilling cost and the shortage rate.",https://www.mdpi.com/2076-3417/11/6/2726/pdf?version=1616061757
2d977bccf523d603d25d235b58dd43bb9be85158,"Robust optimization of risk-aware, resilient and sustainable closed-loop supply chain network design with Lagrange relaxation and fix-and-optimize","ABSTRACT This study explores a Robust, Risk-aware, Resilient, and Sustainable Closed-Loop Supply Chain Network Design (3RSCLSCND) to tackle demand fluctuation like COVID-19 pandemic. A two-stage robust stochastic multiobjective programming model serves to express the proposed problems in formulae. The objective functions include minimising costs, CO2 emissions, energy consumption, and maximising employment by applying Conditional Value at Risk (CVaR) to achieve reliability through risk reduction. The Entropic Value at Risk (EVaR) and Minimax method are used to compare with the proposed model. We utilise the Lp-Metric method to solve the multiobjective problem. Since this model is complex, the Lagrange relaxation and Fix-and-Optimise algorithm are applied to find lower and upper bounds in large-scale, respectively. The results confirm the superior power of the model offered in estimating costs, energy consumption, environmental pollution, and employment level. This model and algorithms are applicable for other CLSC problems.",2021,"[{'authorId': '1813738473', 'name': 'Reza Lotfi'}, {'authorId': '2146919531', 'name': 'Zohre Sheikhi'}, {'authorId': '2141304875', 'name': 'Mohsen Amra'}, {'authorId': '2075755562', 'name': 'Mehdi Alibakhshi'}, {'authorId': '48476415', 'name': 'G. Weber'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/13675567.2021.2017418?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/13675567.2021.2017418, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract this study explores a robust, risk-aware, resilient, and sustainable closed-loop supply chain network design (3rsclscnd) to tackle demand fluctuation like covid-19 pandemic. a two-stage robust stochastic multiobjective programming model serves to express the proposed problems in formulae. the objective functions include minimising costs, co2 emissions, energy consumption, and maximising employment by applying conditional value at risk (cvar) to achieve reliability through risk reduction. the entropic value at risk (evar) and minimax method are used to compare with the proposed model. we utilise the lp-metric method to solve the multiobjective problem. since this model is complex, the lagrange relaxation and fix-and-optimise algorithm are applied to find lower and upper bounds in large-scale, respectively. the results confirm the superior power of the model offered in estimating costs, energy consumption, environmental pollution, and employment level. this model and algorithms are applicable for other clsc problems.",
dbbaa9ee6071b66080fefa9c40286afe66506e0b,"Multi-objective optimization for multi-echelon, multi-product, stochastic sustainable closed-loop supply chain","ABSTRACT The closed-loop supply chain (CLSC) is the supply chain that includes various recovery plans for used products to be reused in the industry. Most of the previous stochastic CLSC studies considered the effect of uncertain parameter changes on the economic aspect only, while the other sustainability aspects were neglected. The purpose of this study is to develop a realistic mathematical model that represents and analyzes the impact of uncertainty in demand and recovery rate of products on the economic, environmental, and social sustainability aspects in the CLSC. The objective functions were optimized using the constrained optimization by linear approximation (COBYLA) algorithm along with preference-based Pareto optimal solution set algorithm at multiple computations to optimize various objectives simultaneously and efficiently. The results show a significant correlation between demand uncertainty, rate of return uncertainty, and the sustainability objectives in the CLSC using optimal inventory management settings.",2021,"[{'authorId': '2027027650', 'name': 'O. Elfarouk'}, {'authorId': '1707348', 'name': 'K. Wong'}, {'authorId': '46687918', 'name': 'W. Wong'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/21681015.2021.1963338?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/21681015.2021.1963338, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the closed-loop supply chain (clsc) is the supply chain that includes various recovery plans for used products to be reused in the industry. most of the previous stochastic clsc studies considered the effect of uncertain parameter changes on the economic aspect only, while the other sustainability aspects were neglected. the purpose of this study is to develop a realistic mathematical model that represents and analyzes the impact of uncertainty in demand and recovery rate of products on the economic, environmental, and social sustainability aspects in the clsc. the objective functions were optimized using the constrained optimization by linear approximation (cobyla) algorithm along with preference-based pareto optimal solution set algorithm at multiple computations to optimize various objectives simultaneously and efficiently. the results show a significant correlation between demand uncertainty, rate of return uncertainty, and the sustainability objectives in the clsc using optimal inventory management settings.",
d65390cfba5e28541c7e4aafc3579dba037bde66,A robust-heuristic optimization approach to a green supply chain design with consideration of assorted vehicle types and carbon policies under uncertainty,"Adoption of carbon regulation mechanisms facilitates an evolution toward green and sustainable supply chains followed by an increased complexity. Through the development and usage of a multi-choice goal programming model solved by an improved algorithm, this article investigates sustainability strategies for carbon regulations mechanisms. We first propose a sustainable logistics model that considers assorted vehicle types and gas emissions involved with product transportation. We then construct a bi-objective model that minimizes total cost as the first objective function and follows environmental considerations in the second one. With our novel robust-heuristic optimization approach, we seek to support the decision-makers in comparison and selection of carbon emission policies in supply chains in complex settings with assorted vehicle types, demand and economic uncertainty. We deploy our model in a case-study to evaluate and analyse two carbon reduction policies, i.e., carbon-tax and cap-and-trade policies. The results demonstrate that our robust-heuristic methodology can efficiently deal with demand and economic uncertainty, especially in large-scale problems. Our findings suggest that governmental incentives for a cap-and-trade policy would be more effective for supply chains in lowering pollution by investing in cleaner technologies and adopting greener practices.",2021,"[{'authorId': '103968662', 'name': 'Zahra Homayouni'}, {'authorId': '2910123', 'name': 'M. Pishvaee'}, {'authorId': '83890974', 'name': 'Hamed Jahani'}, {'authorId': '1743246', 'name': 'D. Ivanov'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s10479-021-03985-6.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10479-021-03985-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10479-021-03985-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","adoption of carbon regulation mechanisms facilitates an evolution toward green and sustainable supply chains followed by an increased complexity. through the development and usage of a multi-choice goal programming model solved by an improved algorithm, this article investigates sustainability strategies for carbon regulations mechanisms. we first propose a sustainable logistics model that considers assorted vehicle types and gas emissions involved with product transportation. we then construct a bi-objective model that minimizes total cost as the first objective function and follows environmental considerations in the second one. with our novel robust-heuristic optimization approach, we seek to support the decision-makers in comparison and selection of carbon emission policies in supply chains in complex settings with assorted vehicle types, demand and economic uncertainty. we deploy our model in a case-study to evaluate and analyse two carbon reduction policies, i.e., carbon-tax and cap-and-trade policies. the results demonstrate that our robust-heuristic methodology can efficiently deal with demand and economic uncertainty, especially in large-scale problems. our findings suggest that governmental incentives for a cap-and-trade policy would be more effective for supply chains in lowering pollution by investing in cleaner technologies and adopting greener practices.",https://link.springer.com/content/pdf/10.1007/s10479-021-03985-6.pdf
8d4a188e8776991d0909ccc10bb260d7ffa4a1f2,Cooperative Coevolutionary Bare-Bones Particle Swarm Optimization With Function Independent Decomposition for Large-Scale Supply Chain Network Design With Uncertainties,"Supply chain network design (SCND) is a complicated constrained optimization problem that plays a significant role in the business management. This article extends the SCND model to a large-scale SCND with uncertainties (LUSCND), which is more practical but also more challenging. However, it is difficult for traditional approaches to obtain the feasible solutions in the large-scale search space within the limited time. This article proposes a cooperative coevolutionary bare-bones particle swarm optimization (CCBBPSO) with function independent decomposition (FID), called CCBBPSO-FID, for a multiperiod three-echelon LUSCND problem. For the large-scale issue, binary encoding of the original model is converted to integer encoding for dimensionality reduction, and a novel FID is designed to efficiently decompose the problem. For obtaining the feasible solutions, two repair methods are designed to repair the infeasible solutions that appear frequently in the LUSCND problem. A step translation method is proposed to deal with the variables out of bounds, and a labeled reposition operator with adaptive probabilities is designed to repair the infeasible solutions that violate the constraints. Experiments are conducted on 405 instances with three different scales. The results show that CCBBPSO-FID has an evident superiority over contestant algorithms.",2020,"[{'authorId': '2149174820', 'name': 'Xin Zhang'}, {'authorId': '2196699', 'name': 'Ke-Jing Du'}, {'authorId': '1680620', 'name': 'Zhi-hui Zhan'}, {'authorId': '1687386', 'name': 'S. Kwong'}, {'authorId': '143651316', 'name': 'T. Gu'}, {'authorId': '18997752', 'name': 'Jun Zhang'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6221036/9204774/08845753.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TCYB.2019.2937565?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TCYB.2019.2937565, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","supply chain network design (scnd) is a complicated constrained optimization problem that plays a significant role in the business management. this article extends the scnd model to a large-scale scnd with uncertainties (luscnd), which is more practical but also more challenging. however, it is difficult for traditional approaches to obtain the feasible solutions in the large-scale search space within the limited time. this article proposes a cooperative coevolutionary bare-bones particle swarm optimization (ccbbpso) with function independent decomposition (fid), called ccbbpso-fid, for a multiperiod three-echelon luscnd problem. for the large-scale issue, binary encoding of the original model is converted to integer encoding for dimensionality reduction, and a novel fid is designed to efficiently decompose the problem. for obtaining the feasible solutions, two repair methods are designed to repair the infeasible solutions that appear frequently in the luscnd problem. a step translation method is proposed to deal with the variables out of bounds, and a labeled reposition operator with adaptive probabilities is designed to repair the infeasible solutions that violate the constraints. experiments are conducted on 405 instances with three different scales. the results show that ccbbpso-fid has an evident superiority over contestant algorithms.",https://ieeexplore.ieee.org/ielx7/6221036/9204774/08845753.pdf
7724b3d4ea817ee3d03cc445688c92cce1edcd7f,Multi-Objective Optimization for Sustainable Supply Chain and Logistics: A Review,"There are several methods available for modeling sustainable supply chain and logistics (SSCL) issues. Multi-objective optimization (MOO) has been a widely used method in SSCL modeling (SSCLM), nonetheless selecting a suitable optimization technique and solution method is still of interest as model performance is highly dependent on decision-making variables of the model development process. This study provides insights from the analysis of 95 scholarly articles to identify research gaps in the MOO for SSCLM and to assist decision-makers in selecting suitable MOO techniques and solution methods. The results of the analysis indicate that economic and environmental aspects of sustainability are the main context of SSCLM, where the social aspect is still limited. More SSCLMs for sourcing, distribution, and transportation phases of the supply chain are required. Additionally, more sophisticated techniques and solution methods, including hybrid metaheuristics approaches, are needed in SSCLM.",2021,"[{'authorId': '120030488', 'name': 'C. Jayarathna'}, {'authorId': '2753760', 'name': 'Duzgun Agdas'}, {'authorId': '2558722', 'name': 'L. Dawes'}, {'authorId': '3266895', 'name': 'Tan Yigitcanlar'}]","{'url': 'https://www.mdpi.com/2071-1050/13/24/13617/pdf?version=1639057818', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su132413617?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su132413617, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","there are several methods available for modeling sustainable supply chain and logistics (sscl) issues. multi-objective optimization (moo) has been a widely used method in sscl modeling (ssclm), nonetheless selecting a suitable optimization technique and solution method is still of interest as model performance is highly dependent on decision-making variables of the model development process. this study provides insights from the analysis of 95 scholarly articles to identify research gaps in the moo for ssclm and to assist decision-makers in selecting suitable moo techniques and solution methods. the results of the analysis indicate that economic and environmental aspects of sustainability are the main context of ssclm, where the social aspect is still limited. more ssclms for sourcing, distribution, and transportation phases of the supply chain are required. additionally, more sophisticated techniques and solution methods, including hybrid metaheuristics approaches, are needed in ssclm.",https://www.mdpi.com/2071-1050/13/24/13617/pdf?version=1639057818
4933216d2ead5ceb29356f5ef59babbc1ad1eaa1,"Green warehousing, logistics optimization, social values and ethics and economic performance: the role of supply chain sustainability","This study primarily explores the influence of green warehousing, logistics optimization and social values and ethics on supply chain sustainability and economic performance. The study further examines the mediating role of supply chain sustainability between economic performance and green warehousing, logistics optimization and social values and ethics.,The study employs a quantitative research approach where survey data are collected from 200 managers of manufacturing companies in Ghana. The dataset is analyzed using partial least square structural equation modeling software (PLS-SEM) SmartPLS 3.,The results show that green warehousing and logistics optimization negatively influence economic performance but improves economic performance through supply chain sustainability. It is further discovered that social values and ethics have a positive influence on supply chain sustainability and economic performance.,This paper proposes and tests a theoretical model that explores the relationships between green warehousing, supply chain sustainability, economic performance, logistics optimization and social values and ethics through the resource dependency theory (RDT) in the manufacturing firms in Ghana.",2020,"[{'authorId': '1580719447', 'name': 'Yaw Agyabeng‐Mensah'}, {'authorId': '1580716180', 'name': 'Esther Ahenkorah'}, {'authorId': '1580704574', 'name': 'Ebenezer Afum'}, {'authorId': '2005360440', 'name': 'Essel Dacosta'}, {'authorId': '2069521951', 'name': 'Zhongxing Tian'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/ijlm-10-2019-0275?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/ijlm-10-2019-0275, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study primarily explores the influence of green warehousing, logistics optimization and social values and ethics on supply chain sustainability and economic performance. the study further examines the mediating role of supply chain sustainability between economic performance and green warehousing, logistics optimization and social values and ethics.,the study employs a quantitative research approach where survey data are collected from 200 managers of manufacturing companies in ghana. the dataset is analyzed using partial least square structural equation modeling software (pls-sem) smartpls 3.,the results show that green warehousing and logistics optimization negatively influence economic performance but improves economic performance through supply chain sustainability. it is further discovered that social values and ethics have a positive influence on supply chain sustainability and economic performance.,this paper proposes and tests a theoretical model that explores the relationships between green warehousing, supply chain sustainability, economic performance, logistics optimization and social values and ethics through the resource dependency theory (rdt) in the manufacturing firms in ghana.",
834c3845504a0037b861e118556fdfc58a984de6,Decision Optimization of Low-Carbon Dual-Channel Supply Chain of Auto Parts Based on Smart City Architecture,"Affected by the Internet, computer, information technology, etc., building a smart city has become a key task of socialist construction work. The smart city has always regarded green and low-carbon development as one of the goals, and the carbon emissions of the auto parts industry cannot be ignored, so we should carry out energy conservation and emission reduction. With the rapid development of the domestic auto parts industry, the number of car ownership has increased dramatically, producing more and more CO2 and waste. Facing the pressure of resources, energy, and environment, the effective and circular operation of the auto parts supply chain under the low-carbon transformation is not only a great challenge, but also a development opportunity. Under the background of carbon emission, this paper establishes a decision-making optimization model of the low-carbon supply chain of auto parts based on carbon emission responsibility sharing and resource sharing. This paper analyzes the optimal decision-making behavior and interaction of suppliers, producers, physical retailers, online retailers, demand markets, and recyclers in the auto parts industry, constructs the economic and environmental objective functions of low-carbon supply chain management, applies variational inequality to analyze the optimal conditions of the whole low-carbon supply chain system, and finally carries out simulation calculation. The research shows that the upstream and downstream auto parts enterprises based on low-carbon competition and cooperation can effectively manage the carbon footprint of the whole supply chain through the sharing of responsibilities and resources among enterprises, so as to reduce the overall carbon emissions of the supply chain system.",2020,"[{'authorId': '2145976511', 'name': 'Zheng Liu'}, {'authorId': '2087121009', 'name': 'Bin Hu'}, {'authorId': '1738352287', 'name': 'Bangtong Huang'}, {'authorId': '1577501399', 'name': 'Lingling Lang'}, {'authorId': '1576097906', 'name': 'Hangxin Guo'}, {'authorId': '2110150565', 'name': 'Yuanjun Zhao'}]","{'url': 'https://downloads.hindawi.com/journals/complexity/2020/2145951.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1155/2020/2145951?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1155/2020/2145951, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","affected by the internet, computer, information technology, etc., building a smart city has become a key task of socialist construction work. the smart city has always regarded green and low-carbon development as one of the goals, and the carbon emissions of the auto parts industry cannot be ignored, so we should carry out energy conservation and emission reduction. with the rapid development of the domestic auto parts industry, the number of car ownership has increased dramatically, producing more and more co2 and waste. facing the pressure of resources, energy, and environment, the effective and circular operation of the auto parts supply chain under the low-carbon transformation is not only a great challenge, but also a development opportunity. under the background of carbon emission, this paper establishes a decision-making optimization model of the low-carbon supply chain of auto parts based on carbon emission responsibility sharing and resource sharing. this paper analyzes the optimal decision-making behavior and interaction of suppliers, producers, physical retailers, online retailers, demand markets, and recyclers in the auto parts industry, constructs the economic and environmental objective functions of low-carbon supply chain management, applies variational inequality to analyze the optimal conditions of the whole low-carbon supply chain system, and finally carries out simulation calculation. the research shows that the upstream and downstream auto parts enterprises based on low-carbon competition and cooperation can effectively manage the carbon footprint of the whole supply chain through the sharing of responsibilities and resources among enterprises, so as to reduce the overall carbon emissions of the supply chain system.",https://downloads.hindawi.com/journals/complexity/2020/2145951.pdf
de3f205750c735cbde380be2da42a7b7c2cf986a,"A robust optimization approach for multi-objective, multi-product, multi-period, closed-loop green supply chain network designs under uncertainty and discount","ABSTRACT One of the basic requirements of the companies to survive in real-world competitive environments is to make their supply chains as efficient as possible. Due to recent governmental regulations, environmental issues, and the development of the concept of social responsibility, the closed-loop supply chain management has been focused by many researchers. A closed-loop supply chain includes both forward and reverse supply chain networks with the purpose of combining environmental considerations with the traditional supply chain network designs through the collection of used products and activities related to their reuse. In this paper, a bi-objective, multi-period, multi-product, closed-loop supply chain network is designed under environmental considerations, discounts, and uncertainties. The deterministic model of the chain is first solved by three multi-objective decision-making methods. Then, based on real-world uncertainties involved in some of the parameters, a robust optimization model is proposed and solved using decision-making methods. At the end, the best deterministic and robust models are selected based on the displaced ideal solution.",2020,"[{'authorId': '1862063706', 'name': 'Javid Ghahremani nahr'}, {'authorId': '3015727', 'name': 'S. Pasandideh'}, {'authorId': '1821150', 'name': 'S. T. A. Niaki'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/21681015.2017.1421591?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/21681015.2017.1421591, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract one of the basic requirements of the companies to survive in real-world competitive environments is to make their supply chains as efficient as possible. due to recent governmental regulations, environmental issues, and the development of the concept of social responsibility, the closed-loop supply chain management has been focused by many researchers. a closed-loop supply chain includes both forward and reverse supply chain networks with the purpose of combining environmental considerations with the traditional supply chain network designs through the collection of used products and activities related to their reuse. in this paper, a bi-objective, multi-period, multi-product, closed-loop supply chain network is designed under environmental considerations, discounts, and uncertainties. the deterministic model of the chain is first solved by three multi-objective decision-making methods. then, based on real-world uncertainties involved in some of the parameters, a robust optimization model is proposed and solved using decision-making methods. at the end, the best deterministic and robust models are selected based on the displaced ideal solution.",
ef4bc8a33a14278340da4fd5186b1d4ddbbb54e6,Robust Scenario Formulations for Strategic Supply Chain Optimization under Uncertainty,"Strategic supply chain optimization (SCO) problems are often modeled as two-stage optimization problems, in which the first-stage variables represent decisions on the development of the supply chain and the second-stage variables represent decisions on the operations of the supply chain. When uncertainty is explicitly considered, the problem becomes an intractable infinite-dimensional optimization problem, which is usually solved approximately using a scenario or a robust approach. This article proposes a novel synergy of the scenario and robust approaches for strategic SCO under uncertainty. Two formulations are developed, namely, naive robust scenario formulation and affinely adjustable robust scenario formulation. It is shown that both formulations can be reformulated into tractable deterministic optimization problems if the uncertainty is bounded by the infinity norm and the uncertain equality constraints can be reformulated into deterministic constraints without any assumption about the uncertainty r...",2013,"[{'authorId': '2053760004', 'name': 'Kyle McLean'}, {'authorId': '2144438886', 'name': 'Xiang Li'}]","{'url': 'http://qspace.library.queensu.ca/bitstreams/7f379bdb-310d-4219-983e-ce0cfeb0a79c/download', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1021/IE303114R?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/IE303114R, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","strategic supply chain optimization (sco) problems are often modeled as two-stage optimization problems, in which the first-stage variables represent decisions on the development of the supply chain and the second-stage variables represent decisions on the operations of the supply chain. when uncertainty is explicitly considered, the problem becomes an intractable infinite-dimensional optimization problem, which is usually solved approximately using a scenario or a robust approach. this article proposes a novel synergy of the scenario and robust approaches for strategic sco under uncertainty. two formulations are developed, namely, naive robust scenario formulation and affinely adjustable robust scenario formulation. it is shown that both formulations can be reformulated into tractable deterministic optimization problems if the uncertainty is bounded by the infinity norm and the uncertain equality constraints can be reformulated into deterministic constraints without any assumption about the uncertainty r...",http://qspace.library.queensu.ca/bitstreams/7f379bdb-310d-4219-983e-ce0cfeb0a79c/download
006fc92694bc1cc48b780f2961d016cb29f3d27d,"Hardwood Biomass to Gasoline, Diesel, and Jet Fuel: 2. Supply Chain Optimization Framework for a Network of Thermochemical Refineries","Biomass-based energy processes pose logistical challenges because of the dispersed nature of biomass resources. A nationwide supply chain optimization framework is applied to a biomass-to-liquid (BTL) system that uses hardwood biomass resources in the United States to produce gasoline, diesel, and jet fuel. Using optimized BTL refineries of differing capacities (i.e., 0.8, 1, 2.5, and 10 thousand barrels per day) and fuel product ratios (i.e., commensurate with the United States demand, maximization of diesel, and maximization of jet fuel), the supply chain case studies that correspond to the three product ratios are addressed via a large-scale mixed-integer linear programming (MILP) optimization model. The mathematical formulation includes the locations of hardwood biomass in the United States, the delivery locations of fuel products, the transportation costs of every input and output of the refinery, the material balances of each BTL refinery, water resources, and electricity requirement of the supply c...",2013,"[{'authorId': '39094920', 'name': 'J. Elia'}, {'authorId': '2382412', 'name': 'Richard C. Baliban'}, {'authorId': '1696826', 'name': 'C. Floudas'}, {'authorId': '92997996', 'name': 'B. Gurau'}, {'authorId': '2101606965', 'name': 'Michael B. Weingarten'}, {'authorId': '152850875', 'name': 'Stephen D. Klotz'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1021/EF400430X?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/EF400430X, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","biomass-based energy processes pose logistical challenges because of the dispersed nature of biomass resources. a nationwide supply chain optimization framework is applied to a biomass-to-liquid (btl) system that uses hardwood biomass resources in the united states to produce gasoline, diesel, and jet fuel. using optimized btl refineries of differing capacities (i.e., 0.8, 1, 2.5, and 10 thousand barrels per day) and fuel product ratios (i.e., commensurate with the united states demand, maximization of diesel, and maximization of jet fuel), the supply chain case studies that correspond to the three product ratios are addressed via a large-scale mixed-integer linear programming (milp) optimization model. the mathematical formulation includes the locations of hardwood biomass in the united states, the delivery locations of fuel products, the transportation costs of every input and output of the refinery, the material balances of each btl refinery, water resources, and electricity requirement of the supply c...",
d6cfb8dfb349cf093a20b58e68b29e9262cc8212,"Internet of Things (IoT) in Supply Chain Management: Challenges, Opportunities, and Best Practices","The advent of the Internet of Things (IoT) has ushered in a transformative era in supply chain management, revolutionizing the way organizations monitor, analyze, and optimize their operations. This comprehensive survey paper explores the multifaceted landscape of IoT applications in supply chain management, shedding light on the challenges, opportunities, and best practices that define this technological paradigm shift. The paper delves into the fundamental principles of IoT, elucidating how sensor-laden devices, real-time data streams, and advanced analytics empower organizations with unprecedented visibility and control across their supply chains. It systematically examines IoT applications in key supply chain domains, including inventory management, asset tracking, cold chain monitoring, predictive maintenance, route optimization, and waste reduction. Each application is scrutinized for its role in enhancing efficiency, reducing costs, ensuring product quality, and advancing sustainability. Furthermore, this paper addresses the challenges inherent in implementing IoT within supply chains, such as data security, interoperability, scalability, and regulatory compliance. It underscores the importance of change management and workforce development in harnessing the full potential of IoT and presents a roadmap for best practices to overcome these obstacles. The paper culminates in a forward-looking exploration of future trends and innovations in the IoT-driven supply chain landscape. By offering a comprehensive overview of IoT's role in supply chain management, this paper equips practitioners, researchers, and decision-makers with a holistic understanding of the transformative power of IoT, empowering them to navigate the complexities, seize opportunities, and implement best practices that will define the future of supply chain management.",2023,"[{'authorId': '2742687', 'name': 'Karam M. Sallam'}, {'authorId': '2256955429', 'name': 'Mona Mohamed'}, {'authorId': '2256846893', 'name': 'Ali Wagdy Mohamed'}]","{'url': 'https://smijournal.org/index.php/smij/article/download/10/14', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.61185/smij.2023.22103?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.61185/smij.2023.22103, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the advent of the internet of things (iot) has ushered in a transformative era in supply chain management, revolutionizing the way organizations monitor, analyze, and optimize their operations. this comprehensive survey paper explores the multifaceted landscape of iot applications in supply chain management, shedding light on the challenges, opportunities, and best practices that define this technological paradigm shift. the paper delves into the fundamental principles of iot, elucidating how sensor-laden devices, real-time data streams, and advanced analytics empower organizations with unprecedented visibility and control across their supply chains. it systematically examines iot applications in key supply chain domains, including inventory management, asset tracking, cold chain monitoring, predictive maintenance, route optimization, and waste reduction. each application is scrutinized for its role in enhancing efficiency, reducing costs, ensuring product quality, and advancing sustainability. furthermore, this paper addresses the challenges inherent in implementing iot within supply chains, such as data security, interoperability, scalability, and regulatory compliance. it underscores the importance of change management and workforce development in harnessing the full potential of iot and presents a roadmap for best practices to overcome these obstacles. the paper culminates in a forward-looking exploration of future trends and innovations in the iot-driven supply chain landscape. by offering a comprehensive overview of iot's role in supply chain management, this paper equips practitioners, researchers, and decision-makers with a holistic understanding of the transformative power of iot, empowering them to navigate the complexities, seize opportunities, and implement best practices that will define the future of supply chain management.",https://smijournal.org/index.php/smij/article/download/10/14
adea442dfe0b46a48f50336ce506cdd9a3b0b959,Optimization Models for Harvest and Production Planning in Agri-Food Supply Chain: A Systematic Review,"This paper provides a comprehensive review of the research done on optimization models that focus on harvest and production planning for food crops. Optimization models have been used extensively in providing insights to decision-makers on issues related to harvest and production planning in agri-food supply chains. First, we conduct an extensive literature review on previous survey articles to distinguish our research from others. Based on the previous reviews, a new classification scheme is developed to classify articles systematically. Harvest and production planning problems in agri-food supply chains are analyzed through three sections: problem scope, model characteristics, and modeling approach. Neglected problem topics and several promising research directions are presented to stimulate research interest on agri-food supply chains specifically planning of harvest and production.",2021,"[{'authorId': '2132795380', 'name': 'Tuğçe Taşkıner'}, {'authorId': '1742588', 'name': 'B. Bilgen'}]","{'url': 'https://www.mdpi.com/2305-6290/5/3/52/pdf?version=1628504652', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/logistics5030052?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/logistics5030052, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper provides a comprehensive review of the research done on optimization models that focus on harvest and production planning for food crops. optimization models have been used extensively in providing insights to decision-makers on issues related to harvest and production planning in agri-food supply chains. first, we conduct an extensive literature review on previous survey articles to distinguish our research from others. based on the previous reviews, a new classification scheme is developed to classify articles systematically. harvest and production planning problems in agri-food supply chains are analyzed through three sections: problem scope, model characteristics, and modeling approach. neglected problem topics and several promising research directions are presented to stimulate research interest on agri-food supply chains specifically planning of harvest and production.",https://www.mdpi.com/2305-6290/5/3/52/pdf?version=1628504652
f0f7017ed8171823618f2cb292513be7f8ef35e5,Biorefinery location and technology selection through supply chain optimization,"This paper proposes a mixed integer linear program for determining economical biomass processing facility locations and capacities, and applies it to assess the biofuel supply chain of the Midwestern United States and the feasibility of meeting governmental biofuel mandates in 2015. Existing corn ethanol facilities and new candidate facility sites are considered for biofuel production by utilizing eight types of biomass. The spatial distribution and farmgate cost of biomass is accessed from a recently updated U.S. Department of Energy database. Seven biomass processing technologies that are expected to be commercialized in the near-term are available for construction at each candidate facility site. A detailed cash flow analysis that includes capital depreciation and taxation is embedded into the model formulation to give insights into the minimum biofuel selling price for each facility site. Equilibrium market cost for the Renewable Fuel Standard biofuel classifications (renewable fuel, advanced biofuel,...",2013,"[{'authorId': '145864777', 'name': 'W. Marvin'}, {'authorId': '40188350', 'name': 'L. Schmidt'}, {'authorId': '1972885', 'name': 'P. Daoutidis'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1021/IE3010463?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/IE3010463, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper proposes a mixed integer linear program for determining economical biomass processing facility locations and capacities, and applies it to assess the biofuel supply chain of the midwestern united states and the feasibility of meeting governmental biofuel mandates in 2015. existing corn ethanol facilities and new candidate facility sites are considered for biofuel production by utilizing eight types of biomass. the spatial distribution and farmgate cost of biomass is accessed from a recently updated u.s. department of energy database. seven biomass processing technologies that are expected to be commercialized in the near-term are available for construction at each candidate facility site. a detailed cash flow analysis that includes capital depreciation and taxation is embedded into the model formulation to give insights into the minimum biofuel selling price for each facility site. equilibrium market cost for the renewable fuel standard biofuel classifications (renewable fuel, advanced biofuel,...",
10834861b8455fff1fd6e4d217f1231d2cbf8330,GDP Economic Forecasting Model Based on Improved RBF Neural Network,"Among the existing GDP forecasting methods, time series forecasting and regression model forecasting are the two most commonly used forecasting methods. However, traditional macroeconomic forecasting models are unable to accurately achieve optimal forecasts of highly complex nonlinear dynamic macroeconomic systems due to the influence of multiple confounding factors. In order to solve the above problems, a GDP economic forecasting model based on an improved RBF neural network is proposed. First, the main traditional GDP forecasting methods are analyzed. Then, RBF neural networks are used to solve the problem that traditional forecasting technology methods cannot handle multi-factor complex nonlinearities well. Second, to further improve the convergence speed and accuracy of the RBF neural network learning algorithm, the Shuffled Frog Leaping Algorithm with global search capability and high practicality is fused into the RBF network training. Finally, the improved RBF neural network is used to build a GDP economic forecasting model. The performance of the Shuffled Frog Leaping Algorithm and the improved RBF neural network was tested using the approximation of Hermit polynomials and the Iris classification problem as simulation examples. The experimental results show that the improved RBF neural network-based GDP economic forecasting model achieves more accurate forecasting accuracy than other forecasting methods.",2022,"[{'authorId': '2119040683', 'name': 'Ying Yu'}]","{'url': 'https://downloads.hindawi.com/journals/mpe/2022/7630268.pdf', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1155/2022/7630268?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1155/2022/7630268, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","among the existing gdp forecasting methods, time series forecasting and regression model forecasting are the two most commonly used forecasting methods. however, traditional macroeconomic forecasting models are unable to accurately achieve optimal forecasts of highly complex nonlinear dynamic macroeconomic systems due to the influence of multiple confounding factors. in order to solve the above problems, a gdp economic forecasting model based on an improved rbf neural network is proposed. first, the main traditional gdp forecasting methods are analyzed. then, rbf neural networks are used to solve the problem that traditional forecasting technology methods cannot handle multi-factor complex nonlinearities well. second, to further improve the convergence speed and accuracy of the rbf neural network learning algorithm, the shuffled frog leaping algorithm with global search capability and high practicality is fused into the rbf network training. finally, the improved rbf neural network is used to build a gdp economic forecasting model. the performance of the shuffled frog leaping algorithm and the improved rbf neural network was tested using the approximation of hermit polynomials and the iris classification problem as simulation examples. the experimental results show that the improved rbf neural network-based gdp economic forecasting model achieves more accurate forecasting accuracy than other forecasting methods.",https://downloads.hindawi.com/journals/mpe/2022/7630268.pdf
dfae8be8c2a4caa8dda6338cba7ab5d852ee98d7,An Economic Forecasting Method Based on the LightGBM-Optimized LSTM and Time-Series Model,"Stock price prediction is very important in financial decision-making, and it is also the most difficult part of economic forecasting. The factors affecting stock prices are complex and changeable, and stock price fluctuations have a certain degree of randomness. If we can accurately predict stock prices, regulatory authorities can conduct reasonable supervision of the stock market and provide investors with valuable investment decision-making information. As we know, the LSTM (Long Short-Term Memory) algorithm is mainly used in large-scale data mining competitions, but it has not yet been used to predict the stock market. Therefore, this article uses this algorithm to predict the closing price of stocks. As an emerging research field, LSTM is superior to traditional time-series models and machine learning models and is suitable for stock market analysis and forecasting. However, the general LSTM model has some shortcomings, so this paper designs a LightGBM-optimized LSTM to realize short-term stock price forecasting. In order to verify its effectiveness compared with other deep network models such as RNN (Recurrent Neural Network) and GRU (Gated Recurrent Unit), the LightGBM-LSTM, RNN, and GRU are respectively used to predict the Shanghai and Shenzhen 300 indexes. Experimental results show that the LightGBM-LSTM has the highest prediction accuracy and the best ability to track stock index price trends, and its effect is better than the GRU and RNN algorithms.",2021,"[{'authorId': '2152218179', 'name': 'Jiehua Lv'}, {'authorId': '2144447559', 'name': 'Chao Wang'}, {'authorId': '1491074474', 'name': 'W. Gao'}, {'authorId': '2130761633', 'name': 'Qiumin Zhao'}]","{'url': 'https://downloads.hindawi.com/journals/cin/2021/8128879.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8492266, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","stock price prediction is very important in financial decision-making, and it is also the most difficult part of economic forecasting. the factors affecting stock prices are complex and changeable, and stock price fluctuations have a certain degree of randomness. if we can accurately predict stock prices, regulatory authorities can conduct reasonable supervision of the stock market and provide investors with valuable investment decision-making information. as we know, the lstm (long short-term memory) algorithm is mainly used in large-scale data mining competitions, but it has not yet been used to predict the stock market. therefore, this article uses this algorithm to predict the closing price of stocks. as an emerging research field, lstm is superior to traditional time-series models and machine learning models and is suitable for stock market analysis and forecasting. however, the general lstm model has some shortcomings, so this paper designs a lightgbm-optimized lstm to realize short-term stock price forecasting. in order to verify its effectiveness compared with other deep network models such as rnn (recurrent neural network) and gru (gated recurrent unit), the lightgbm-lstm, rnn, and gru are respectively used to predict the shanghai and shenzhen 300 indexes. experimental results show that the lightgbm-lstm has the highest prediction accuracy and the best ability to track stock index price trends, and its effect is better than the gru and rnn algorithms.",https://downloads.hindawi.com/journals/cin/2021/8128879.pdf
8f057bbe8f6152ad7df1fafbde81ee7406010cfa,Economic Forecasting with an Agent-Based Model,"We develop the first agent-based model (ABM) that can compete with benchmark VAR and DSGE models in out-of-sample forecasting of macro variables. Our ABM for a small open economy uses micro and macro data from national and sector accounts, input-output tables, government statistics, census and business demography data. The model incorporates all economic activities as classified by the European System of Accounts as heterogeneous agents. The detailed structure of the ABM allows for a breakdown into sector level forecasts. Potential applications of the model include stress-testing and predicting the effects of changes in monetary, fiscal, or other macroeconomic policies.",2020,"[{'authorId': '19269881', 'name': 'S. Poledna'}, {'authorId': '72300188', 'name': 'M. Miess'}, {'authorId': '77090294', 'name': 'C. Hommes'}, {'authorId': '1995547', 'name': 'K. Rabitsch'}]","{'url': 'https://pure.iiasa.ac.at/id/eprint/18339/1/1-s2.0-S0014292122001891-main%20%281%29.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3484768?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3484768, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we develop the first agent-based model (abm) that can compete with benchmark var and dsge models in out-of-sample forecasting of macro variables. our abm for a small open economy uses micro and macro data from national and sector accounts, input-output tables, government statistics, census and business demography data. the model incorporates all economic activities as classified by the european system of accounts as heterogeneous agents. the detailed structure of the abm allows for a breakdown into sector level forecasts. potential applications of the model include stress-testing and predicting the effects of changes in monetary, fiscal, or other macroeconomic policies.",https://pure.iiasa.ac.at/id/eprint/18339/1/1-s2.0-S0014292122001891-main%20%281%29.pdf
1276066091d55ee8ca60c9d0a448dbfe64a1ef09,Conceptualization of Machine Learning in Economic Forecasting,"Economic forecasting is a very important aspect that policymakers in the financial and corporate organization rely on because helps them to determine future events that might infringe some hardship on the economy and the citizens at large. However, the principal statistical pointers that are available to the public domain provide numerous reservations and doubts for their economics estimates as it is later released with frequent issues to major revisions and also it shows a great lag in decision making for an incoming event. To this effect, the expansion of the latest forecasting patterns was important to address the gaps. Hence, this paper examines the conceptualization of Machine learning in economic forecasting. To achieve this, the Italian economy was used as the dataset, and machine learning controlled tools were used as the method of analysis. The result obtained from this study shows that machine learning is a better model to use in economic forecasting for quick and reliable data to avert future events.",2021,"[{'authorId': '2121711312', 'name': 'Harish Paruchuri'}]","{'url': 'https://abc.us.org/ojs/index.php/abr/article/download/532/1032', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.18034/ABR.V11I2.532?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.18034/ABR.V11I2.532, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","economic forecasting is a very important aspect that policymakers in the financial and corporate organization rely on because helps them to determine future events that might infringe some hardship on the economy and the citizens at large. however, the principal statistical pointers that are available to the public domain provide numerous reservations and doubts for their economics estimates as it is later released with frequent issues to major revisions and also it shows a great lag in decision making for an incoming event. to this effect, the expansion of the latest forecasting patterns was important to address the gaps. hence, this paper examines the conceptualization of machine learning in economic forecasting. to achieve this, the italian economy was used as the dataset, and machine learning controlled tools were used as the method of analysis. the result obtained from this study shows that machine learning is a better model to use in economic forecasting for quick and reliable data to avert future events.",https://abc.us.org/ojs/index.php/abr/article/download/532/1032
ea4b6253cd6f0cd13a6dde24376e66970372be78,Making Text Count: Economic Forecasting Using Newspaper Text,"We consider the best way to extract timely signals from newspaper text and use them to forecast macroeconomic variables using three popular UK newspapers that collectively represent UK newspaper readership in terms of political perspective and editorial style. We find that newspaper text can improve economic forecasts both in absolute and marginal terms. We introduce a powerful new method of incorporating text information in forecasts that combines counts of terms with supervised machine learning techniques. This method improves forecasts of macroeconomic variables including GDP, inflation, and unemployment, including relative to existing text-based methods. Forecast improvements occur when it matters most, during stressed periods.",2020,"[{'authorId': '6151373', 'name': 'E. Kalamara'}, {'authorId': '2329404', 'name': 'A. Turrell'}, {'authorId': '3199103', 'name': 'C. Redl'}, {'authorId': '2725420', 'name': 'G. Kapetanios'}, {'authorId': '38685463', 'name': 'S. Kapadia'}]","{'url': 'https://www.bankofengland.co.uk/-/media/boe/files/working-paper/2020/making-text-count-economic-forecasting-using-newspaper-text.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3610770?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3610770, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we consider the best way to extract timely signals from newspaper text and use them to forecast macroeconomic variables using three popular uk newspapers that collectively represent uk newspaper readership in terms of political perspective and editorial style. we find that newspaper text can improve economic forecasts both in absolute and marginal terms. we introduce a powerful new method of incorporating text information in forecasts that combines counts of terms with supervised machine learning techniques. this method improves forecasts of macroeconomic variables including gdp, inflation, and unemployment, including relative to existing text-based methods. forecast improvements occur when it matters most, during stressed periods.",https://www.bankofengland.co.uk/-/media/boe/files/working-paper/2020/making-text-count-economic-forecasting-using-newspaper-text.pdf
1866ebbf6bd2fabb88a27ea0969b0b650a462d66,A Monte Carlo localization method based on differential evolution optimization applied into economic forecasting in mobile wireless sensor networks,"The localization of sensor node is an essential problem for many economic forecasting applications in wireless sensor networks. Considering that the mobile sensors change their locations frequently over time, Monte Carlo localization algorithm utilizes the moving characteristics of nodes and employs the probability distribution function (PDF) in the previous time slot to estimate the current location by using a weighted particle filter. However, it also has the problem of insufficient number of valid samples, which further affects the node’s localization accuracy. In this paper, differential evolution method is introduced into the Monte Carlo localization algorithm. The sample weight is taken as the objective function, and differential evolution algorithm is implemented in sample stage. Finally, the node position is estimated by making the sample close to the actual location of the node instead of being filtered out. The simulation results demonstrate that the proposed algorithm provides a better position estimation with less localization error.",2018,"[{'authorId': '23797191', 'name': 'M. Qin'}, {'authorId': '2636125', 'name': 'Rongbo Zhu'}]","{'url': 'https://jwcn-eurasipjournals.springeropen.com/track/pdf/10.1186/s13638-018-1037-1', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1186/S13638-018-1037-1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/S13638-018-1037-1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the localization of sensor node is an essential problem for many economic forecasting applications in wireless sensor networks. considering that the mobile sensors change their locations frequently over time, monte carlo localization algorithm utilizes the moving characteristics of nodes and employs the probability distribution function (pdf) in the previous time slot to estimate the current location by using a weighted particle filter. however, it also has the problem of insufficient number of valid samples, which further affects the node’s localization accuracy. in this paper, differential evolution method is introduced into the monte carlo localization algorithm. the sample weight is taken as the objective function, and differential evolution algorithm is implemented in sample stage. finally, the node position is estimated by making the sample close to the actual location of the node instead of being filtered out. the simulation results demonstrate that the proposed algorithm provides a better position estimation with less localization error.",https://jwcn-eurasipjournals.springeropen.com/track/pdf/10.1186/s13638-018-1037-1
33ed3d9a505131daf631ca5fa1307e3aafdd3343,Learning skillful medium-range global weather forecasting,"Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy but does not directly use historical weather data to improve the underlying model. Here, we introduce GraphCast, a machine learning–based method trained directly from reanalysis data. It predicts hundreds of weather variables for the next 10 days at 0.25° resolution globally in under 1 minute. GraphCast significantly outperforms the most accurate operational deterministic systems on 90% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclone tracking, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting and helps realize the promise of machine learning for modeling complex dynamical systems. Editor’s summary The numerical models used to predict weather are large, complex, and computationally demanding and do not learn from past weather patterns. Lam et al. introduced a machine learning–based method that has been trained directly from reanalysis data of past atmospheric conditions. In this way, the authors were able to quickly predict hundreds of weather variables globally up to 10 days in advance and at high resolution. Their predictions were more accurate than those of traditional weather models in 90% of tested cases and displayed better severe event prediction for tropical cyclones, atmospheric rivers, and extreme temperatures. —H. Jesse Smith Machine learning leads to better, faster, and cheaper weather forecasting.",2023,"[{'authorId': '2266459752', 'name': 'Remi Lam'}, {'authorId': '2266397148', 'name': 'Alvaro Sanchez-Gonzalez'}, {'authorId': '2266396481', 'name': 'Matthew Willson'}, {'authorId': '5721359', 'name': 'Peter Wirnsberger'}, {'authorId': '2065413220', 'name': 'Meire Fortunato'}, {'authorId': '2266458515', 'name': 'Ferran Alet'}, {'authorId': '2938043', 'name': 'Suman V. Ravuri'}, {'authorId': '23988602', 'name': 'T. Ewalds'}, {'authorId': '1397576010', 'name': 'Z. Eaton-Rosen'}, {'authorId': '2267195372', 'name': 'Weihua Hu'}, {'authorId': '2198276136', 'name': 'Alexander Merose'}, {'authorId': '2257229905', 'name': 'Stephan Hoyer'}, {'authorId': '2198276080', 'name': 'George Holland'}, {'authorId': '1689108', 'name': 'O. Vinyals'}, {'authorId': '2114860628', 'name': 'Jacklynn Stott'}, {'authorId': '1863250', 'name': 'A. Pritzel'}, {'authorId': '1701708450', 'name': 'Shakir Mohamed'}, {'authorId': '2265542669', 'name': 'Peter W. Battaglia'}]","{'url': 'https://www.science.org/doi/pdf/10.1126/science.adi2336?download=true', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1126/science.adi2336?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/science.adi2336, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","global medium-range weather forecasting is critical to decision-making across many social and economic domains. traditional numerical weather prediction uses increased compute resources to improve forecast accuracy but does not directly use historical weather data to improve the underlying model. here, we introduce graphcast, a machine learning–based method trained directly from reanalysis data. it predicts hundreds of weather variables for the next 10 days at 0.25° resolution globally in under 1 minute. graphcast significantly outperforms the most accurate operational deterministic systems on 90% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclone tracking, atmospheric rivers, and extreme temperatures. graphcast is a key advance in accurate and efficient weather forecasting and helps realize the promise of machine learning for modeling complex dynamical systems. editor’s summary the numerical models used to predict weather are large, complex, and computationally demanding and do not learn from past weather patterns. lam et al. introduced a machine learning–based method that has been trained directly from reanalysis data of past atmospheric conditions. in this way, the authors were able to quickly predict hundreds of weather variables globally up to 10 days in advance and at high resolution. their predictions were more accurate than those of traditional weather models in 90% of tested cases and displayed better severe event prediction for tropical cyclones, atmospheric rivers, and extreme temperatures. —h. jesse smith machine learning leads to better, faster, and cheaper weather forecasting.",https://www.science.org/doi/pdf/10.1126/science.adi2336?download=true
a09aeca884ce5fbac30824c653d4789110658ed5,Non-equidistant “Basic Form”-focused Grey Verhulst Models (NBFGVMs) for ill-structured socio-economic forecasting problems,"Multiple uncertainties complicate socio-economic forecasting problems, especially when relying on ill-conditioned limited data. Such problems are best addressed by grey prediction models such as Grey Verhulst Model (GVM). This paper resolves the incompatibility between GVM’s estimation and prediction by taking its basic form equation as the basis of both. The resultant “Basic Form”-focused GVM (BFGVM) is also further developed to create Direct Non-equidistant BFGVM (DNBFGVM) and, in turn, DNBFGVM with Recursive simulation (DNBFGVMR). Experimental analyses comprise 19 socio-economic time series with an emphasis on Iranian population, a low-frequency non-equidistant time series with remarkable strategic importance. Promisingly, the proposed DNBFGVM and DNBFGVMR provide accurate in-sample and out-of-sample socio-economic forecasts, show highly significant improvements over the best traditional GVM, and offer cost-effective intelligent support of decision-making. Final results suggest future trends of studied socio-economic time series. Specifically, they reveal Iranian population to grow even slower than anticipated, demanding an urgent consideration of policy-makers.",2017,"[{'authorId': '1423387632', 'name': 'Mohammad Hashem-Nazari'}, {'authorId': '2772244', 'name': 'A. Esfahanipour'}, {'authorId': '121119201', 'name': 'S. F. Ghomi'}]","{'url': 'https://journals.vgtu.lt/index.php/JBEM/article/download/1228/966', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3846/16111699.2017.1337045?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3846/16111699.2017.1337045, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","multiple uncertainties complicate socio-economic forecasting problems, especially when relying on ill-conditioned limited data. such problems are best addressed by grey prediction models such as grey verhulst model (gvm). this paper resolves the incompatibility between gvm’s estimation and prediction by taking its basic form equation as the basis of both. the resultant “basic form”-focused gvm (bfgvm) is also further developed to create direct non-equidistant bfgvm (dnbfgvm) and, in turn, dnbfgvm with recursive simulation (dnbfgvmr). experimental analyses comprise 19 socio-economic time series with an emphasis on iranian population, a low-frequency non-equidistant time series with remarkable strategic importance. promisingly, the proposed dnbfgvm and dnbfgvmr provide accurate in-sample and out-of-sample socio-economic forecasts, show highly significant improvements over the best traditional gvm, and offer cost-effective intelligent support of decision-making. final results suggest future trends of studied socio-economic time series. specifically, they reveal iranian population to grow even slower than anticipated, demanding an urgent consideration of policy-makers.",https://journals.vgtu.lt/index.php/JBEM/article/download/1228/966
1950c05ee977afbdc2fc59f7229bf8fa75375d70,Economic Forecasting in Theory and Practice: An Interview with David F. Hendry,"David Hendry has made major contributions to many areas of economic forecasting. He has developed a taxonomy of forecast errors and a theory of unpredictability that have yielded valuable insights into the nature of forecasting. He has also provided new perspectives on many existing forecast techniques, including mean square forecast errors, add factors, leading indicators, pooling of forecasts, and multi-step estimation. In addition, David has developed new forecast tools, such as forecast encompassing; and he has improved existing ones, such as nowcasting and robustification to breaks. This interview for the International Journal of Forecasting explores David Hendry’s research on forecasting.",2016,"[{'authorId': '66180174', 'name': 'Neil R. Ericsson'}]","{'url': 'http://www.gwu.edu/~forcpgm/2016-012.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.17016/IFDP.2016.1184?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.17016/IFDP.2016.1184, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","david hendry has made major contributions to many areas of economic forecasting. he has developed a taxonomy of forecast errors and a theory of unpredictability that have yielded valuable insights into the nature of forecasting. he has also provided new perspectives on many existing forecast techniques, including mean square forecast errors, add factors, leading indicators, pooling of forecasts, and multi-step estimation. in addition, david has developed new forecast tools, such as forecast encompassing; and he has improved existing ones, such as nowcasting and robustification to breaks. this interview for the international journal of forecasting explores david hendry’s research on forecasting.",http://www.gwu.edu/~forcpgm/2016-012.pdf
9712e670200fbc081c1115a5789086a59b0edd50,Forecasting the impact of the first wave of the COVID-19 pandemic on hospital demand and deaths for the USA and European Economic Area countries,"Summary Background: Hospitals need to plan for the surge in demand in each state or region in the United States and the European Economic Area (EEA) due to the COVID-19 pandemic. Planners need forecasts of the most likely trajectory in the coming weeks and will want to plan for the higher values in the range of those forecasts. To date, forecasts of what is most likely to occur in the weeks ahead are not available for states in the USA or for all countries in the EEA. Methods: This study used data on confirmed COVID-19 deaths by day from local and national government websites and WHO. Data on hospital capacity and utilisation and observed COVID-19 utilisation data from select locations were obtained from publicly available sources and direct contributions of data from select local governments. We develop a mixed effects non-linear regression framework to estimate the trajectory of the cumulative and daily death rate as a function of the implementation of social distancing measures, supported by additional evidence from mobile phone data. An extended mixture model was used in data rich settings to capture asymmetric daily death patterns. Health service needs were forecast using a micro-simulation model that estimates hospital admissions, ICU admissions, length of stay, and ventilator need using available data on clinical practices in COVID-19 patients. We assume that those jurisdictions that have not implemented school closures, non-essential business closures, and stay at home orders will do so within twenty-one days. Findings: Compared to licensed capacity and average annual occupancy rates, excess demand in the USA from COVID-19 at the estimated peak of the epidemic (the end of the second week of April) is predicted to be 9,079 (95% UI 253-61,937) total beds and 9,356 (3,526-29,714) ICU beds. At the peak of the epidemic, ventilator use is predicted to be 16,545 (8,083-41,991). The corresponding numbers for EEA countries are 120,080 (119,183-121,107), 32,291 (32,157-32,425) and 28,973 (28,868-29,085) at a peak of April 6. The date of peak daily deaths varies from March 30 through May 12 by state in the USA and March 27 through May 4 by country in the EEA. We estimate that through the end of July, there will be 60,308 (34,063-140,381) deaths from COVID-19 in the USA and 143,088 (101,131-253,163) deaths in the EEA. Deaths from COVID-19 are estimated to drop below 0.3 per million between May 4 and June 29 by state in the USA and between May 4 and July 13 by country in the EEA. Timing of the peak need for hospital resource requirements varies considerably across states in the USA and across regions of Europe. Interpretation: In addition to a large number of deaths from COVID-19, the epidemic will place a load on health system resources well beyond the current capacity of hospitals in the USA and EEA to manage, especially for ICU care and ventilator use. These estimates can help inform the development and implementation of strategies to mitigate this gap, including reducing non-COVID-19 demand for services and temporarily increasing system capacity. The estimated excess demand on hospital systems is predicated on the enactment of social distancing measures within three weeks in all locations that have not done so already and maintenance of these measures throughout the epidemic, emphasising the importance of implementing, enforcing, and maintaining these measures to mitigate hospital system overload and prevent deaths.",2020,"[{'authorId': '117629891', 'name': 'C. Murray'}]","{'url': 'https://doi.org/10.1101/2020.04.21.20074732', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1101/2020.04.21.20074732?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1101/2020.04.21.20074732, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","summary background: hospitals need to plan for the surge in demand in each state or region in the united states and the european economic area (eea) due to the covid-19 pandemic. planners need forecasts of the most likely trajectory in the coming weeks and will want to plan for the higher values in the range of those forecasts. to date, forecasts of what is most likely to occur in the weeks ahead are not available for states in the usa or for all countries in the eea. methods: this study used data on confirmed covid-19 deaths by day from local and national government websites and who. data on hospital capacity and utilisation and observed covid-19 utilisation data from select locations were obtained from publicly available sources and direct contributions of data from select local governments. we develop a mixed effects non-linear regression framework to estimate the trajectory of the cumulative and daily death rate as a function of the implementation of social distancing measures, supported by additional evidence from mobile phone data. an extended mixture model was used in data rich settings to capture asymmetric daily death patterns. health service needs were forecast using a micro-simulation model that estimates hospital admissions, icu admissions, length of stay, and ventilator need using available data on clinical practices in covid-19 patients. we assume that those jurisdictions that have not implemented school closures, non-essential business closures, and stay at home orders will do so within twenty-one days. findings: compared to licensed capacity and average annual occupancy rates, excess demand in the usa from covid-19 at the estimated peak of the epidemic (the end of the second week of april) is predicted to be 9,079 (95% ui 253-61,937) total beds and 9,356 (3,526-29,714) icu beds. at the peak of the epidemic, ventilator use is predicted to be 16,545 (8,083-41,991). the corresponding numbers for eea countries are 120,080 (119,183-121,107), 32,291 (32,157-32,425) and 28,973 (28,868-29,085) at a peak of april 6. the date of peak daily deaths varies from march 30 through may 12 by state in the usa and march 27 through may 4 by country in the eea. we estimate that through the end of july, there will be 60,308 (34,063-140,381) deaths from covid-19 in the usa and 143,088 (101,131-253,163) deaths in the eea. deaths from covid-19 are estimated to drop below 0.3 per million between may 4 and june 29 by state in the usa and between may 4 and july 13 by country in the eea. timing of the peak need for hospital resource requirements varies considerably across states in the usa and across regions of europe. interpretation: in addition to a large number of deaths from covid-19, the epidemic will place a load on health system resources well beyond the current capacity of hospitals in the usa and eea to manage, especially for icu care and ventilator use. these estimates can help inform the development and implementation of strategies to mitigate this gap, including reducing non-covid-19 demand for services and temporarily increasing system capacity. the estimated excess demand on hospital systems is predicated on the enactment of social distancing measures within three weeks in all locations that have not done so already and maintenance of these measures throughout the epidemic, emphasising the importance of implementing, enforcing, and maintaining these measures to mitigate hospital system overload and prevent deaths.",https://doi.org/10.1101/2020.04.21.20074732
c895672cf206f54de507d90848563ef5dd33a629,Forecasting with Economic News,"Abstract The goal of this article is to evaluate the informational content of sentiment extracted from news articles about the state of the economy. We propose a fine-grained aspect-based sentiment analysis that has two main characteristics: (a) we consider only the text in the article that is semantically dependent on a term of interest (aspect-based) and, (b) assign a sentiment score to each word based on a dictionary that we develop for applications in economics and finance (fine-grained). Our dataset includes six large U.S. newspapers, for a total of over 6.6 million articles and 4.2 billion words. Our findings suggest that several measures of economic sentiment track closely business cycle fluctuations and that they are relevant predictors for four major macroeconomic variables. We find that there are significant improvements in forecasting when sentiment is considered along with macroeconomic factors. In addition, we also find that sentiment matters to explains the tails of the probability distribution across several macroeconomic variables.",2020,"[{'authorId': '89076793', 'name': 'L. Barbaglia'}, {'authorId': '1748453', 'name': 'S. Consoli'}, {'authorId': '2373691', 'name': 'S. Manzan'}]","{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/07350015.2022.2060988?needAccess=true', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2203.15686, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the goal of this article is to evaluate the informational content of sentiment extracted from news articles about the state of the economy. we propose a fine-grained aspect-based sentiment analysis that has two main characteristics: (a) we consider only the text in the article that is semantically dependent on a term of interest (aspect-based) and, (b) assign a sentiment score to each word based on a dictionary that we develop for applications in economics and finance (fine-grained). our dataset includes six large u.s. newspapers, for a total of over 6.6 million articles and 4.2 billion words. our findings suggest that several measures of economic sentiment track closely business cycle fluctuations and that they are relevant predictors for four major macroeconomic variables. we find that there are significant improvements in forecasting when sentiment is considered along with macroeconomic factors. in addition, we also find that sentiment matters to explains the tails of the probability distribution across several macroeconomic variables.",https://www.tandfonline.com/doi/pdf/10.1080/07350015.2022.2060988?needAccess=true
44523c6003d7bd7218e6dbe7c0820fb53fb357b0,A Task-Based Day-Ahead Load Forecasting Model for Stochastic Economic Dispatch,"Load forecasting is one of the most important and studied topics in modern power systems. Most of the existing research on day-ahead load forecasting try to build a good model to improve the forecasting accuracy. The forecasted load is then used as the input to generation scheduling with the ultimate goal of minimizing the cost of generation schedules. However, existing day-ahead load forecasting models do not consider this ultimate goal at the training/forecasting stage. This paper proposes a task-based day-ahead load forecasting model labeled as LfEdNet that combines two individual layers in one model, including a load forecasting layer based on deep neural network (Lf layer) and a day-ahead stochastic economic dispatch (SED) layer (Ed layer). The training of LfEdNet aims to minimize the cost of the day-ahead SED in the Ed layer by updating the parameters of the Lf layer. Sequential quadratic programming (SQP) is used to solve the day-ahead SED in the Ed layer. The test results demonstrate that the forecasted results produced by LfEdNet can lead to lower cost of day-ahead SED at the expense of slight reduction in forecasting accuracy.",2020,"[{'authorId': '2111759595', 'name': 'Jiayu Han'}, {'authorId': '2110133350', 'name': 'Lei Yan'}, {'authorId': '152985888', 'name': 'Zuyi Li'}]","{'url': 'https://doi.org/10.1109/tpwrs.2021.3072904', 'status': 'BRONZE', 'license': 'publisher-specific-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2008.07025, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","load forecasting is one of the most important and studied topics in modern power systems. most of the existing research on day-ahead load forecasting try to build a good model to improve the forecasting accuracy. the forecasted load is then used as the input to generation scheduling with the ultimate goal of minimizing the cost of generation schedules. however, existing day-ahead load forecasting models do not consider this ultimate goal at the training/forecasting stage. this paper proposes a task-based day-ahead load forecasting model labeled as lfednet that combines two individual layers in one model, including a load forecasting layer based on deep neural network (lf layer) and a day-ahead stochastic economic dispatch (sed) layer (ed layer). the training of lfednet aims to minimize the cost of the day-ahead sed in the ed layer by updating the parameters of the lf layer. sequential quadratic programming (sqp) is used to solve the day-ahead sed in the ed layer. the test results demonstrate that the forecasted results produced by lfednet can lead to lower cost of day-ahead sed at the expense of slight reduction in forecasting accuracy.",https://doi.org/10.1109/tpwrs.2021.3072904
f53538995762051c14712f2651bbedb3249cec69,Regional Economic Forecasting: State-of-the-Art Methodology and Future Challenges,"Over the last decade, the topic of regional economic forecasting has become increasingly prevalent in academic literature. The most striking problem in this context is data availability at a regional level. However, considerable methodological improvements have been made to address this problem. This paper summarizes a multitude of articles from academic journals and describes state-of-the-art techniques in regional economic forecasting. After identifying current practices, the article closes with a roadmap for possible future research activities.",2014,"[{'authorId': '145742636', 'name': 'R. Lehmann'}, {'authorId': '2524952', 'name': 'K. Wohlrabe'}]","{'url': 'https://www.unioviedo.es/reunido/index.php/EBL/article/download/10416/10122', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.17811/ebl.3.4.2014.218-231?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.17811/ebl.3.4.2014.218-231, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","over the last decade, the topic of regional economic forecasting has become increasingly prevalent in academic literature. the most striking problem in this context is data availability at a regional level. however, considerable methodological improvements have been made to address this problem. this paper summarizes a multitude of articles from academic journals and describes state-of-the-art techniques in regional economic forecasting. after identifying current practices, the article closes with a roadmap for possible future research activities.",https://www.unioviedo.es/reunido/index.php/EBL/article/download/10416/10122
7dff3280beed4cef96265350074498bf142c41e7,GraphCast: Learning skillful medium-range global weather forecasting,"Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy, but cannot directly use historical weather data to improve the underlying model. We introduce a machine learning-based method called""GraphCast"", which can be trained directly from reanalysis data. It predicts hundreds of weather variables, over 10 days at 0.25 degree resolution globally, in under one minute. We show that GraphCast significantly outperforms the most accurate operational deterministic systems on 90% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclones, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting, and helps realize the promise of machine learning for modeling complex dynamical systems.",2022,"[{'authorId': '2390625', 'name': 'Rémi R. Lam'}, {'authorId': '1398105826', 'name': 'Alvaro Sanchez-Gonzalez'}, {'authorId': '39561601', 'name': 'M. Willson'}, {'authorId': '5721359', 'name': 'Peter Wirnsberger'}, {'authorId': '39067762', 'name': 'Meire Fortunato'}, {'authorId': '1863250', 'name': 'A. Pritzel'}, {'authorId': '2938043', 'name': 'Suman V. Ravuri'}, {'authorId': '23988602', 'name': 'T. Ewalds'}, {'authorId': '27587911', 'name': 'Ferran Alet'}, {'authorId': '1397576010', 'name': 'Z. Eaton-Rosen'}, {'authorId': '48594758', 'name': 'Weihua Hu'}, {'authorId': '2198276136', 'name': 'Alexander Merose'}, {'authorId': '7018631', 'name': 'Stephan Hoyer'}, {'authorId': '2198276080', 'name': 'George Holland'}, {'authorId': '2114860628', 'name': 'Jacklynn Stott'}, {'authorId': '1689108', 'name': 'O. Vinyals'}, {'authorId': '14594344', 'name': 'S. Mohamed'}, {'authorId': '2019153', 'name': 'P. Battaglia'}]","{'url': 'https://arxiv.org/pdf/2212.12794', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2212.12794, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","global medium-range weather forecasting is critical to decision-making across many social and economic domains. traditional numerical weather prediction uses increased compute resources to improve forecast accuracy, but cannot directly use historical weather data to improve the underlying model. we introduce a machine learning-based method called""graphcast"", which can be trained directly from reanalysis data. it predicts hundreds of weather variables, over 10 days at 0.25 degree resolution globally, in under one minute. we show that graphcast significantly outperforms the most accurate operational deterministic systems on 90% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclones, atmospheric rivers, and extreme temperatures. graphcast is a key advance in accurate and efficient weather forecasting, and helps realize the promise of machine learning for modeling complex dynamical systems.",https://arxiv.org/pdf/2212.12794
74acfbf241ee27710892d6a92d1d62f66326ce12,Day-Ahead vs. Intraday—Forecasting the Price Spread to Maximize Economic Benefits,"Recently, a dynamic development of intermittent renewable energy sources (RES) has been observed. In order to allow for the adoption of trading contracts for unplanned events and changing weather conditions, the day-ahead markets have been complemented by intraday markets; in some countries, such as Poland, balancing markets are used for this purpose. This research focuses on a small RES generator, which has no market power and sells electricity through a larger trading company. The generator needs to decide, in advance, how much electricity is sold in the day-ahead market. The optimal decision of the generator on where to sell the production depends on the relation between prices in different markets. Unfortunately, when making the decision, the generator is not sure which market will offer a higher price. This article investigates the possible gains from utilizing forecasts of the price spread between the intraday/balancing and day-ahead markets in the decision process. It shows that the sign of the price spread can be successfully predicted with econometric models, such as ARX and probit. Moreover, our research demonstrates that the statistical measures of forecast accuracy, such as the percentage of correct sign classifications, do not necessarily coincide with economic benefits.",2019,"[{'authorId': '2995125', 'name': 'K. Maciejowska'}, {'authorId': '101519094', 'name': 'W. Nitka'}, {'authorId': '2355402', 'name': 'Tomasz Weron'}]","{'url': 'https://www.mdpi.com/1996-1073/12/4/631/pdf?version=1550294761', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/EN12040631?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/EN12040631, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recently, a dynamic development of intermittent renewable energy sources (res) has been observed. in order to allow for the adoption of trading contracts for unplanned events and changing weather conditions, the day-ahead markets have been complemented by intraday markets; in some countries, such as poland, balancing markets are used for this purpose. this research focuses on a small res generator, which has no market power and sells electricity through a larger trading company. the generator needs to decide, in advance, how much electricity is sold in the day-ahead market. the optimal decision of the generator on where to sell the production depends on the relation between prices in different markets. unfortunately, when making the decision, the generator is not sure which market will offer a higher price. this article investigates the possible gains from utilizing forecasts of the price spread between the intraday/balancing and day-ahead markets in the decision process. it shows that the sign of the price spread can be successfully predicted with econometric models, such as arx and probit. moreover, our research demonstrates that the statistical measures of forecast accuracy, such as the percentage of correct sign classifications, do not necessarily coincide with economic benefits.",https://www.mdpi.com/1996-1073/12/4/631/pdf?version=1550294761
f87008037da0e0c7f8791f4abecde1dc68b3889c,Modeling and Forecasting Commodity Market Volatility with Long-term Economic and Financial Variables,"This paper investigates the time-varying volatility patterns of some major commodities as well as the potential factors that drive their long-term volatility component. For this purpose, we make use of a recently proposed GARCH-MIDAS approach which typically allows us to examine the role of economic and financial variables of different frequencies. Using commodity futures for crude oil (WTI and Brent), gold, silver and platinum, our results show the necessity of disentangling the short- and long-term components in modeling and forecasting commodity volatility. They also indicate that the long-term volatility of most commodity futures is significantly driven by the level of the general real economic activity as well as the changes in consumer sentiment, industrial production, and economic policy uncertainty. However, the forecasting results are not alike across commodity futures as no single model fits all commodities.",2018,"[{'authorId': '3490978', 'name': 'Duc Khuong Nguyen'}, {'authorId': '46204117', 'name': 'T. Walther'}]","{'url': 'https://mpra.ub.uni-muenchen.de/90348/9/MPRA_paper_90348.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3294967?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3294967, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper investigates the time-varying volatility patterns of some major commodities as well as the potential factors that drive their long-term volatility component. for this purpose, we make use of a recently proposed garch-midas approach which typically allows us to examine the role of economic and financial variables of different frequencies. using commodity futures for crude oil (wti and brent), gold, silver and platinum, our results show the necessity of disentangling the short- and long-term components in modeling and forecasting commodity volatility. they also indicate that the long-term volatility of most commodity futures is significantly driven by the level of the general real economic activity as well as the changes in consumer sentiment, industrial production, and economic policy uncertainty. however, the forecasting results are not alike across commodity futures as no single model fits all commodities.",https://mpra.ub.uni-muenchen.de/90348/9/MPRA_paper_90348.pdf
01802c2d301bc032e4085f202a17f85c10657bd0,The role of economic uncertainty in forecasting exchange rate returns and realized volatility: Evidence from quantile predictive regressions,"In this paper, we investigate whether the news-based measure of economic policy uncertainty (EPU), can be used to forecast exchange rate returns and volatility using a quantile regression approach, which accounts for persistence and endogeneity, using data from thirteen different countries. Our main findings suggest that: (i) EPU is useful for forecasting exchange rate returns and volatility, (ii) forecasting ability-quantile order relationships exhibit U-shape, possibly asymmetric form around the median and (iii) asymmetries are more pronounced in the case of forecasting volatility.",2018,"[{'authorId': '8308907', 'name': 'Christina Christou'}, {'authorId': '47495923', 'name': 'Rangan Gupta'}, {'authorId': '10774017', 'name': 'C. Hassapis'}, {'authorId': '2293118', 'name': 'Tahir Suleman'}]","{'url': 'https://repository.up.ac.za/bitstream/2263/67340/1/Christou_Role_2018.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/FOR.2539?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/FOR.2539, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this paper, we investigate whether the news-based measure of economic policy uncertainty (epu), can be used to forecast exchange rate returns and volatility using a quantile regression approach, which accounts for persistence and endogeneity, using data from thirteen different countries. our main findings suggest that: (i) epu is useful for forecasting exchange rate returns and volatility, (ii) forecasting ability-quantile order relationships exhibit u-shape, possibly asymmetric form around the median and (iii) asymmetries are more pronounced in the case of forecasting volatility.",https://repository.up.ac.za/bitstream/2263/67340/1/Christou_Role_2018.pdf
d109dbe7a89b71d3568d0641dc3d8eedb0a009cc,Forecasting and Nowcasting Emerging Market GDP Growth Rates: The Role of Latent Global Economic Policy Uncertainty and Macroeconomic Data Surprise Factors,"In this paper, we assess the predictive content of latent economic policy uncertainty and data surprises factors for forecasting and nowcasting GDP using factor-type econometric models. Our analysis focuses on five emerging market economies, including Brazil, Indonesia, Mexico, South Africa, and Turkey; and we carry out a forecasting horse-race in which predictions from various different models are compared. These models may (or may not) contain latent uncertainty and surprise factors constructed using both local and global economic datasets. The set of models that we examine in our experiments includes both simple benchmark linear econometric models as well as dynamic factor models (DFMs) that are estimated using a variety of frequentist and Bayesian data shrinkage methods based on the least absolute shrinkage operator (LASSO). We find that the inclusion of our new uncertainty and surprise factors leads to superior predictions of GDP growth, particularly when these latent factors are constructed using Bayesian variants of the LASSO. Overall, our findings point to the importance of spillover effects from global uncertainty and data surprises, when predicting GDP growth in emerging market economies.",2018,"[{'authorId': '103042502', 'name': 'Oğuzhan Çepni'}, {'authorId': '152396325', 'name': 'I. Guney'}, {'authorId': '7693286', 'name': 'Norman R. Swanson'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/for.2602', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3298924?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3298924, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in this paper, we assess the predictive content of latent economic policy uncertainty and data surprises factors for forecasting and nowcasting gdp using factor-type econometric models. our analysis focuses on five emerging market economies, including brazil, indonesia, mexico, south africa, and turkey; and we carry out a forecasting horse-race in which predictions from various different models are compared. these models may (or may not) contain latent uncertainty and surprise factors constructed using both local and global economic datasets. the set of models that we examine in our experiments includes both simple benchmark linear econometric models as well as dynamic factor models (dfms) that are estimated using a variety of frequentist and bayesian data shrinkage methods based on the least absolute shrinkage operator (lasso). we find that the inclusion of our new uncertainty and surprise factors leads to superior predictions of gdp growth, particularly when these latent factors are constructed using bayesian variants of the lasso. overall, our findings point to the importance of spillover effects from global uncertainty and data surprises, when predicting gdp growth in emerging market economies.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/for.2602
97ecc1fc65922315522bfbceddbfefa175121b6d,Questioning the News About Economic Growth: Sparse Forecasting Using Thousands of News-Based Sentiment Values,"The modern calculation of textual sentiment involves a myriad of choices as to the actual calibration. We introduce a general sentiment engineering framework that optimizes the design for forecasting purposes. It includes the use of the elastic net for sparse data-driven selection and the weighting of thousands of sentiment values. These values are obtained by pooling the textual sentiment values across publication venues, article topics, sentiment construction methods, and time. We apply the framework to the investigation of the value added by textual analysis-based sentiment indices for forecasting economic growth in the US. We find that the additional use of optimized news-based sentiment values yields significant accuracy gains for forecasting the nine-month and annual growth rates of the US industrial production, compared to the use of high-dimensional forecasting techniques based on only economic and financial indicators.",2017,"[{'authorId': '2181735', 'name': 'David Ardia'}, {'authorId': '51924175', 'name': 'Keven Bluteau'}, {'authorId': '2324655', 'name': 'Kris Boudt'}]","{'url': 'https://doi.org/10.1016/j.ijforecast.2018.10.010', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.2976084?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.2976084, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the modern calculation of textual sentiment involves a myriad of choices as to the actual calibration. we introduce a general sentiment engineering framework that optimizes the design for forecasting purposes. it includes the use of the elastic net for sparse data-driven selection and the weighting of thousands of sentiment values. these values are obtained by pooling the textual sentiment values across publication venues, article topics, sentiment construction methods, and time. we apply the framework to the investigation of the value added by textual analysis-based sentiment indices for forecasting economic growth in the us. we find that the additional use of optimized news-based sentiment values yields significant accuracy gains for forecasting the nine-month and annual growth rates of the us industrial production, compared to the use of high-dimensional forecasting techniques based on only economic and financial indicators.",https://doi.org/10.1016/j.ijforecast.2018.10.010
3735d09059e208d908f432a31dbbe61e980dcc65,BiLSTM Multitask Learning-Based Combined Load Forecasting Considering the Loads Coupling Relationship for Multienergy System,"Accurate load forecasting is the key to economic dispatch and efficient operation of Multi-Energy System (MES). This paper proposes a combined load forecasting method for MES based on Bi-directional Long Short-Term Memory (BiLSTM) multi-task learning. Firstly, this paper investigates the multi-energy interaction mechanism and multi-loads characteristics and analyzes the correlation of multi-loads in different seasons. Then, a combined load forecasting method is proposed, which focuses on making full use of the coupling relationship among multiple loads. In the forecasting model, the different loads are selected combinedly as the input features according to the Maximum Information Coefficient (MIC). The multi-task learning is adopted to construct the cooling, heating and electric combined load forecasting model based on the BiLSTM algorithm, which can effectively share the coupling information among the loads. Finally, case studies verify the effectiveness and superiority of the proposed method in both learning speed and forecasting accuracy.",2022,"[{'authorId': '2118270611', 'name': 'Yixiu Guo'}, {'authorId': '2154404160', 'name': 'Yong Li'}, {'authorId': '31893688', 'name': 'Xuebo Qiao'}, {'authorId': '2109338123', 'name': 'Zhenyu Zhang'}, {'authorId': '119796933', 'name': 'Wang-Jun Zhou'}, {'authorId': '2164970125', 'name': 'Yujie Mei'}, {'authorId': '2817530', 'name': 'Jinjie Lin'}, {'authorId': '2009826976', 'name': 'Yicheng Zhou'}, {'authorId': '47362170', 'name': 'Y. Nakanishi'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TSG.2022.3173964?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TSG.2022.3173964, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","accurate load forecasting is the key to economic dispatch and efficient operation of multi-energy system (mes). this paper proposes a combined load forecasting method for mes based on bi-directional long short-term memory (bilstm) multi-task learning. firstly, this paper investigates the multi-energy interaction mechanism and multi-loads characteristics and analyzes the correlation of multi-loads in different seasons. then, a combined load forecasting method is proposed, which focuses on making full use of the coupling relationship among multiple loads. in the forecasting model, the different loads are selected combinedly as the input features according to the maximum information coefficient (mic). the multi-task learning is adopted to construct the cooling, heating and electric combined load forecasting model based on the bilstm algorithm, which can effectively share the coupling information among the loads. finally, case studies verify the effectiveness and superiority of the proposed method in both learning speed and forecasting accuracy.",
922421cc3e102294125e8d54bb24381536d35c0c,Forecasting errors by the Troika in the economic adjustment programme for Portugal,"This article presents an evaluation of the economic adjustment programme negotiated between the Portuguese government and the Troika (European Commission, ECB and IMF) in May 2011, using an assessment that is different from the usual studies. Instead of a comparison between the actual results and the proposed targets, an evaluation of the quality of the programme forecast is made, showing that errors could have been avoided if the productive (input–output) structure of the economy and also the unemployment rate/external deficit trade-off had been taken into account. The main conclusion of this assessment is that a large underestimation of the unemployment rate was made, amounting to about four percentage points, which illustrates the technical flaw of this adjustment programme and the huge economic and social costs it unnecessarily caused. The methodology used can easily be replicated for assessing other similar programmes, such those applied in Greece, Ireland and Cyprus.",2016,"[{'authorId': '1845742', 'name': 'J. F. Amaral'}, {'authorId': '40236087', 'name': 'J. Lopes'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/CJE/BEW046?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/CJE/BEW046, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this article presents an evaluation of the economic adjustment programme negotiated between the portuguese government and the troika (european commission, ecb and imf) in may 2011, using an assessment that is different from the usual studies. instead of a comparison between the actual results and the proposed targets, an evaluation of the quality of the programme forecast is made, showing that errors could have been avoided if the productive (input–output) structure of the economy and also the unemployment rate/external deficit trade-off had been taken into account. the main conclusion of this assessment is that a large underestimation of the unemployment rate was made, amounting to about four percentage points, which illustrates the technical flaw of this adjustment programme and the huge economic and social costs it unnecessarily caused. the methodology used can easily be replicated for assessing other similar programmes, such those applied in greece, ireland and cyprus.",
f48b033e5d9f2b514036497b16231a2ce427d17c,Using Internet Data to Account for Special Events in Economic Forecasting,"Information about special events can improve economic forecasts substantially. However, due to the lack of timely quantitative data about these events, it has been difficult for professional forecasters to utilise such information in their forecasts. This paper investigates whether Internet search data can improve economic predictions in times of special events. An analysis of “cash for clunkers” programs in four selected countries exemplifies that including search query data into statistical forecasting models improves the forecasting performance in almost all cases. However, the challenge to identify irregular events and to find the appropriate time series from Google Insights for search remains.",2012,"[{'authorId': '40557822', 'name': 'Torsten Schmidt'}, {'authorId': '2104857813', 'name': 'Simeon Vosen'}]","{'url': 'https://www.econstor.eu/bitstream/10419/67127/1/731034538.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.2200402?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.2200402, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","information about special events can improve economic forecasts substantially. however, due to the lack of timely quantitative data about these events, it has been difficult for professional forecasters to utilise such information in their forecasts. this paper investigates whether internet search data can improve economic predictions in times of special events. an analysis of “cash for clunkers” programs in four selected countries exemplifies that including search query data into statistical forecasting models improves the forecasting performance in almost all cases. however, the challenge to identify irregular events and to find the appropriate time series from google insights for search remains.",https://www.econstor.eu/bitstream/10419/67127/1/731034538.pdf
088488af28a93fac590827e538a1ebc0cea26e6f,MetNet: A Neural Weather Model for Precipitation Forecasting,"Weather forecasting is a long standing scientific challenge with direct social and economic impact. The task is suitable for deep neural networks due to vast amounts of continuously collected data and a rich spatial and temporal structure that presents long range dependencies. We introduce MetNet, a neural network that forecasts precipitation up to 8 hours into the future at the high spatial resolution of 1 km$^2$ and at the temporal resolution of 2 minutes with a latency in the order of seconds. MetNet takes as input radar and satellite data and forecast lead time and produces a probabilistic precipitation map. The architecture uses axial self-attention to aggregate the global context from a large input patch corresponding to a million square kilometers. We evaluate the performance of MetNet at various precipitation thresholds and find that MetNet outperforms Numerical Weather Prediction at forecasts of up to 7 to 8 hours on the scale of the continental United States.",2020,"[{'authorId': '1402816540', 'name': 'C. Sønderby'}, {'authorId': '2311318', 'name': 'L. Espeholt'}, {'authorId': '151488492', 'name': 'J. Heek'}, {'authorId': '3226635', 'name': 'Mostafa Dehghani'}, {'authorId': '35679876', 'name': 'Avital Oliver'}, {'authorId': '2887364', 'name': 'Tim Salimans'}, {'authorId': '3443290', 'name': 'Shreya Agrawal'}, {'authorId': '25642955', 'name': 'Jason Hickey'}, {'authorId': '2583391', 'name': 'Nal Kalchbrenner'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2003.12140, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","weather forecasting is a long standing scientific challenge with direct social and economic impact. the task is suitable for deep neural networks due to vast amounts of continuously collected data and a rich spatial and temporal structure that presents long range dependencies. we introduce metnet, a neural network that forecasts precipitation up to 8 hours into the future at the high spatial resolution of 1 km$^2$ and at the temporal resolution of 2 minutes with a latency in the order of seconds. metnet takes as input radar and satellite data and forecast lead time and produces a probabilistic precipitation map. the architecture uses axial self-attention to aggregate the global context from a large input patch corresponding to a million square kilometers. we evaluate the performance of metnet at various precipitation thresholds and find that metnet outperforms numerical weather prediction at forecasts of up to 7 to 8 hours on the scale of the continental united states.",
39955327c44d2e00f08a584b1fdd78ab54958548,The Oxford handbook of economic forecasting,"This Handbook provides up-to-date coverage of both new developments and well-established fields in the sphere of economic forecasting. The chapters are written by world experts in their respective fields, and provide authoritative yet accessible accounts of the key concepts, subject matter and techniques in a number of diverse but related areas. It covers the ways in which the availability of ever more plentiful data and computational power have been used in forecasting, either in terms of the frequency of observations, the number of variables, or the use of multiple data vintages. Greater data availability has been coupled with developments in statistical theory and economic theory to allow more elaborate and complicated models to be entertained; the volume provides explanations and critiques of these developments. These include factor models, DSGE models, restricted vector autoregressions, and non-linear models, as well as models for handling data observed at mixed frequencies, high-frequency data, multiple data vintages, and methods for forecasting when there are structural breaks, and how breaks might be forecast. Also covered are areas which are less commonly associated with economic forecasting, such as climate change, health economics, long-horizon growth forecasting, and political elections. Econometric forecasting has important contributions to make in these areas, as well as their developments informing the mainstream. In the early 21st century, climate change and the forecasting of health expenditures and population are topics of pressing importance. Available in OSO: http://www.oxfordhandbooks.com/oso/public/content/oho_economics/9780195398649/toc.html",2011,"[{'authorId': '2249064', 'name': 'Michael P. Clements'}, {'authorId': '2566726', 'name': 'D. Hendry'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/OXFORDHB/9780195398649.001.0001?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/OXFORDHB/9780195398649.001.0001, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this handbook provides up-to-date coverage of both new developments and well-established fields in the sphere of economic forecasting. the chapters are written by world experts in their respective fields, and provide authoritative yet accessible accounts of the key concepts, subject matter and techniques in a number of diverse but related areas. it covers the ways in which the availability of ever more plentiful data and computational power have been used in forecasting, either in terms of the frequency of observations, the number of variables, or the use of multiple data vintages. greater data availability has been coupled with developments in statistical theory and economic theory to allow more elaborate and complicated models to be entertained; the volume provides explanations and critiques of these developments. these include factor models, dsge models, restricted vector autoregressions, and non-linear models, as well as models for handling data observed at mixed frequencies, high-frequency data, multiple data vintages, and methods for forecasting when there are structural breaks, and how breaks might be forecast. also covered are areas which are less commonly associated with economic forecasting, such as climate change, health economics, long-horizon growth forecasting, and political elections. econometric forecasting has important contributions to make in these areas, as well as their developments informing the mainstream. in the early 21st century, climate change and the forecasting of health expenditures and population are topics of pressing importance. available in oso: http://www.oxfordhandbooks.com/oso/public/content/oho_economics/9780195398649/toc.html",
6d4ae82ea08f09f2fd07769486ebbfd8c0732caa,Electricity load forecasting: a systematic review,"The economic growth of every nation is highly related to its electricity infrastructure, network, and availability since electricity has become the central part of everyday life in this modern world. Hence, the global demand for electricity for residential and commercial purposes has seen an incredible increase. On the other side, electricity prices keep fluctuating over the past years and not mentioning the inadequacy in electricity generation to meet global demand. As a solution to this, numerous studies aimed at estimating future electrical energy demand for residential and commercial purposes to enable electricity generators, distributors, and suppliers to plan effectively ahead and promote energy conservation among the users. Notwithstanding, load forecasting is one of the major problems facing the power industry since the inception of electric power. The current study tried to undertake a systematic and critical review of about seventy-seven (77) relevant previous works reported in academic journals over nine years (2010–2020) in electricity demand forecasting. Specifically, attention was given to the following themes: (i) The forecasting algorithms used and their fitting ability in this field, (ii) the theories and factors affecting electricity consumption and the origin of research work, (iii) the relevant accuracy and error metrics applied in electricity load forecasting, and (iv) the forecasting period. The results revealed that 90% out of the top nine models used in electricity forecasting was artificial intelligence based, with artificial neural network (ANN) representing 28%. In this scope, ANN models were primarily used for short-term electricity forecasting where electrical energy consumption patterns are complicated. Concerning the accuracy metrics used, it was observed that root-mean-square error (RMSE) (38%) was the most used error metric among electricity forecasters, followed by mean absolute percentage error MAPE (35%). The study further revealed that 50% of electricity demand forecasting was based on weather and economic parameters, 8.33% on household lifestyle, 38.33% on historical energy consumption, and 3.33% on stock indices. Finally, we recap the challenges and opportunities for further research in electricity load forecasting locally and globally.",2020,"[{'authorId': '66913822', 'name': 'Isaac Kofi Nti'}, {'authorId': '1940002343', 'name': 'Moses Teimeh'}, {'authorId': '1403694006', 'name': 'O. Nyarko-Boateng'}, {'authorId': '51966799', 'name': 'Adebayo Felix Adekoya'}]","{'url': 'https://jesit.springeropen.com/track/pdf/10.1186/s43067-020-00021-8', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1186/s43067-020-00021-8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/s43067-020-00021-8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the economic growth of every nation is highly related to its electricity infrastructure, network, and availability since electricity has become the central part of everyday life in this modern world. hence, the global demand for electricity for residential and commercial purposes has seen an incredible increase. on the other side, electricity prices keep fluctuating over the past years and not mentioning the inadequacy in electricity generation to meet global demand. as a solution to this, numerous studies aimed at estimating future electrical energy demand for residential and commercial purposes to enable electricity generators, distributors, and suppliers to plan effectively ahead and promote energy conservation among the users. notwithstanding, load forecasting is one of the major problems facing the power industry since the inception of electric power. the current study tried to undertake a systematic and critical review of about seventy-seven (77) relevant previous works reported in academic journals over nine years (2010–2020) in electricity demand forecasting. specifically, attention was given to the following themes: (i) the forecasting algorithms used and their fitting ability in this field, (ii) the theories and factors affecting electricity consumption and the origin of research work, (iii) the relevant accuracy and error metrics applied in electricity load forecasting, and (iv) the forecasting period. the results revealed that 90% out of the top nine models used in electricity forecasting was artificial intelligence based, with artificial neural network (ann) representing 28%. in this scope, ann models were primarily used for short-term electricity forecasting where electrical energy consumption patterns are complicated. concerning the accuracy metrics used, it was observed that root-mean-square error (rmse) (38%) was the most used error metric among electricity forecasters, followed by mean absolute percentage error mape (35%). the study further revealed that 50% of electricity demand forecasting was based on weather and economic parameters, 8.33% on household lifestyle, 38.33% on historical energy consumption, and 3.33% on stock indices. finally, we recap the challenges and opportunities for further research in electricity load forecasting locally and globally.",https://jesit.springeropen.com/track/pdf/10.1186/s43067-020-00021-8
8f26dc7dc984bad91816c461580a7f9c8efd4054,Improving the Role of Judgment in Economic Forecasting,This article first explores the variety of ways in which judgment plays a role in economic forecasting before outlining the potential problems associated with these applications of judgment. It then discusses the effectiveness of methods that have been designed to improve judgment in other areas of forecasting and assesses the extent to which these methods can be usefully employed by economic forecasters.,2011,"[{'authorId': '143788060', 'name': 'P. Goodwin'}, {'authorId': '74572763', 'name': 'D. Önkal'}, {'authorId': '144880702', 'name': 'Michael Lawrence'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/OXFORDHB/9780195398649.013.0007?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/OXFORDHB/9780195398649.013.0007, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",this article first explores the variety of ways in which judgment plays a role in economic forecasting before outlining the potential problems associated with these applications of judgment. it then discusses the effectiveness of methods that have been designed to improve judgment in other areas of forecasting and assesses the extent to which these methods can be usefully employed by economic forecasters.,
9cfaa1e2c74161c345142cd1d321a07ec5904ae3,Internet Search Behavior as an Economic Forecasting Tool: The Case of Inflation Expectations,"This paper proposes a measure of real-time inflation expectations based on metadata, i.e., data about data, constructed from internet search queries performed on the search engine Google. The forecasting performance of the Google Inflation Search Index (GISI) is assessed relative to 37 other indicators of inflation expectations – 36 survey measures and the TIPS spread. For decades, the academic literature has focused on three measures of inflation expectations: the Livingston Survey, Survey of Professional Forecasters, and the Michigan Survey. While useful in developing models of forecasting inflation, these low frequency measures appear anachronistic in the modern era of higher frequency and real-time data. I demonstrate that higher frequency measures tend to outperform lower frequency measures in tests of accuracy, predictive power, and rationality. Furthermore, Granger Causality tests indicate that the GISI metadata indicator anticipates the inflation rate by 12 months, and out-of-sample forecasts show that the GISI has the lowest forecast error of all the inflation expectations indicators tested.",2011,"[{'authorId': '41189375', 'name': 'Giselle C. Guzman'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3233/JEM-2011-0342?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3233/JEM-2011-0342, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper proposes a measure of real-time inflation expectations based on metadata, i.e., data about data, constructed from internet search queries performed on the search engine google. the forecasting performance of the google inflation search index (gisi) is assessed relative to 37 other indicators of inflation expectations – 36 survey measures and the tips spread. for decades, the academic literature has focused on three measures of inflation expectations: the livingston survey, survey of professional forecasters, and the michigan survey. while useful in developing models of forecasting inflation, these low frequency measures appear anachronistic in the modern era of higher frequency and real-time data. i demonstrate that higher frequency measures tend to outperform lower frequency measures in tests of accuracy, predictive power, and rationality. furthermore, granger causality tests indicate that the gisi metadata indicator anticipates the inflation rate by 12 months, and out-of-sample forecasts show that the gisi has the lowest forecast error of all the inflation expectations indicators tested.",
6925eb23e3972b25267378c3eb5d40528967026a,How Useful is the Carry-Over Effect for Short-Term Economic Forecasting?,"The carry-over effect is the advance contribution of the old year to growth in the new year. Among practitioners the informative content of the carry-over effect for short-term forecasting is undisputed and is used routinely in economic forecasting. In this paper, the carry-over effect is analysed 'statistically' and it is shown how it reduces the uncertainty of short-term economic forecasts. This is followed by an empirical analysis of the carry-over effect using simple forecast models as well as Bundesbank and Consensus projections.",2010,"[{'authorId': '2996404', 'name': 'Karl-Heinz Tödter'}]","{'url': 'https://www.econstor.eu/bitstream/10419/41622/1/639461220.pdf', 'status': 'GREEN', 'license': 'mit', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.2785385?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.2785385, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the carry-over effect is the advance contribution of the old year to growth in the new year. among practitioners the informative content of the carry-over effect for short-term forecasting is undisputed and is used routinely in economic forecasting. in this paper, the carry-over effect is analysed 'statistically' and it is shown how it reduces the uncertainty of short-term economic forecasts. this is followed by an empirical analysis of the carry-over effect using simple forecast models as well as bundesbank and consensus projections.",https://www.econstor.eu/bitstream/10419/41622/1/639461220.pdf
c98cbbc71f72aa2d16f646d257df00fbffd51b90,Comparing Prophet and Deep Learning to ARIMA in Forecasting Wholesale Food Prices,"Setting sale prices correctly is of great importance for firms, and the study and forecast of prices time series is therefore a relevant topic not only from a data science perspective but also from an economic and applicative one. In this paper, we examine different techniques to forecast sale prices applied by an Italian food wholesaler, as a step towards the automation of pricing tasks usually taken care by human workforce. We consider ARIMA models and compare them to Prophet, a scalable forecasting tool by Facebook based on a generalized additive model, and to deep learning models exploiting Long Short-Term Memory (LSTM) and Convolutional Neural Networks (CNNs). ARIMA models are frequently used in econometric analyses, providing a good benchmark for the problem under study. Our results indicate that ARIMA models and LSTM neural networks perform similarly for the forecasting task under consideration, while the combination of CNNs and LSTMs attains the best overall accuracy, but requires more time to be tuned. On the contrary, Prophet is quick and easy to use, but considerably less accurate.",2021,"[{'authorId': '103266542', 'name': 'L. Menculini'}, {'authorId': '145957521', 'name': 'A. Marini'}, {'authorId': '2034256092', 'name': 'Massimiliano Proietti'}, {'authorId': '94882911', 'name': 'A. Garinei'}, {'authorId': '2121252802', 'name': 'Alessio Bozza'}, {'authorId': '2121263180', 'name': 'Cecilia Moretti'}, {'authorId': '144844819', 'name': 'M. Marconi'}]","{'url': 'https://www.mdpi.com/2571-9394/3/3/40/pdf?version=1631798007', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2107.12770, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","setting sale prices correctly is of great importance for firms, and the study and forecast of prices time series is therefore a relevant topic not only from a data science perspective but also from an economic and applicative one. in this paper, we examine different techniques to forecast sale prices applied by an italian food wholesaler, as a step towards the automation of pricing tasks usually taken care by human workforce. we consider arima models and compare them to prophet, a scalable forecasting tool by facebook based on a generalized additive model, and to deep learning models exploiting long short-term memory (lstm) and convolutional neural networks (cnns). arima models are frequently used in econometric analyses, providing a good benchmark for the problem under study. our results indicate that arima models and lstm neural networks perform similarly for the forecasting task under consideration, while the combination of cnns and lstms attains the best overall accuracy, but requires more time to be tuned. on the contrary, prophet is quick and easy to use, but considerably less accurate.",https://www.mdpi.com/2571-9394/3/3/40/pdf?version=1631798007
32a8ffa80c1a314f80b3e7a95313a268eb7ad1a5,Operational Day-Ahead Solar Power Forecasting for Aggregated PV Systems with a Varying Spatial Distribution,"Accurate forecasts of the power production of distributed photovoltaic (PV) systems are essential to support grid operation and enable a high PV penetration rate in the electricity grid. In this study, we analyse the performance of 12 different models that forecast the day-ahead power production in agreement with market conditions. These models include regression, support vector regression, ensemble learning, deep learning and physical based techniques. In addition, we examine the effect of aggregating multiple PV systems with a varying inter-system distance on the forecast model performance. The models are evaluated both on their technical and economic performance. From a technical perspective, the results show a positive effect from both an increasing inter-system distance and a larger sized PV fleet on the model performance. A similar effect was absent with regard to the economic performance. Furthermore, the ensemble and deep learning models are found to be preferred over the alternatives from a technical point of view. The economic assessment indicates the superiority of the physical based model, followed by the deep learning models. Due to its consistent good performance, a long short-term memory model is the best forecast model.",2021,"[{'authorId': '1491626976', 'name': 'Lennard R. Visser'}, {'authorId': '1887317', 'name': 'T. Alskaif'}, {'authorId': '2326361712', 'name': 'Wilfried van Sark'}]","{'url': 'https://dspace.library.uu.nl/bitstream/handle/1874/413445/1_s2.0_S0960148121015688_main.pdf?sequence=1&isAllowed=y', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3897783?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3897783, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","accurate forecasts of the power production of distributed photovoltaic (pv) systems are essential to support grid operation and enable a high pv penetration rate in the electricity grid. in this study, we analyse the performance of 12 different models that forecast the day-ahead power production in agreement with market conditions. these models include regression, support vector regression, ensemble learning, deep learning and physical based techniques. in addition, we examine the effect of aggregating multiple pv systems with a varying inter-system distance on the forecast model performance. the models are evaluated both on their technical and economic performance. from a technical perspective, the results show a positive effect from both an increasing inter-system distance and a larger sized pv fleet on the model performance. a similar effect was absent with regard to the economic performance. furthermore, the ensemble and deep learning models are found to be preferred over the alternatives from a technical point of view. the economic assessment indicates the superiority of the physical based model, followed by the deep learning models. due to its consistent good performance, a long short-term memory model is the best forecast model.",https://dspace.library.uu.nl/bitstream/handle/1874/413445/1_s2.0_S0960148121015688_main.pdf?sequence=1&isAllowed=y
e3c897df9bbdc2fd32f99e5d9fa2ffadff0820e8,Deep Learning for Load Forecasting: Sequence to Sequence Recurrent Neural Networks With Attention,"The biggest contributor to global warming is energy production and use. Moreover, a push for electrical vehicle and other economic developments are expected to further increase energy use. To combat these challenges, electrical load forecasting is essential as it supports energy production planning and scheduling, assists with budgeting, and helps identify saving opportunities. Machine learning approaches commonly used for energy forecasting such as feedforward neural networks and support vector regression encounter challenges with capturing time dependencies. Consequently, this paper proposes Sequence to Sequence Recurrent Neural Network (S2S RNN) with Attention for electrical load forecasting. The S2S architecture from language translation is adapted for load forecasting and a corresponding sample generation approach is designed. RNN enables capturing time dependencies present in the load data and S2S model further improves time modeling by combining two RNNs: encoder and decoder. The attention mechanism alleviates the burden of connecting encoder and decoder. The experiments evaluated attention mechanisms with different RNN cells (vanilla, LSTM, and GRU) and with varied time horizons. Results show that S2S with Bahdanau attention outperforms other models. Accuracy decreases as forecasting horizon increases; however, longer input sequences do not always increase accuracy.",2020,"[{'authorId': '1380993111', 'name': 'Ljubisa Sehovac'}, {'authorId': '2222599', 'name': 'Katarina Grolinger'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09006868.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2020.2975738?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2020.2975738, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the biggest contributor to global warming is energy production and use. moreover, a push for electrical vehicle and other economic developments are expected to further increase energy use. to combat these challenges, electrical load forecasting is essential as it supports energy production planning and scheduling, assists with budgeting, and helps identify saving opportunities. machine learning approaches commonly used for energy forecasting such as feedforward neural networks and support vector regression encounter challenges with capturing time dependencies. consequently, this paper proposes sequence to sequence recurrent neural network (s2s rnn) with attention for electrical load forecasting. the s2s architecture from language translation is adapted for load forecasting and a corresponding sample generation approach is designed. rnn enables capturing time dependencies present in the load data and s2s model further improves time modeling by combining two rnns: encoder and decoder. the attention mechanism alleviates the burden of connecting encoder and decoder. the experiments evaluated attention mechanisms with different rnn cells (vanilla, lstm, and gru) and with varied time horizons. results show that s2s with bahdanau attention outperforms other models. accuracy decreases as forecasting horizon increases; however, longer input sequences do not always increase accuracy.",https://ieeexplore.ieee.org/ielx7/6287639/8948470/09006868.pdf
5bf5b6e6326dbf6e159aca454088547ee076d26b,Economic Forecasting,"These lecture notes codify extensive recent research on economic forecasting. When a forecasting model coincides with the mechanism generating the data (DGP) in an unchanging world, the theory of economic forecasting is well developed. Forecasts are the conditional expectation, are unbiased, and no other predictor has a smaller mean-square forecast error matrix. Cointegration does not markedly alter that conclusion. Much less is known about forecasting in a non-stationary and evolving world, especially when the model and DGP differ. The main challenges facing a theory of economic forecasting, however, are to explain the recurrent episodes of systematic mis-forecasting observed historically, and to develop methods which avoid repeating such mistakes in future. To construct an empirically-relevant theory, we allow the model to be mis-specified for a DGP which alters unexpectedly at unknown times. We are able to deduce: what types of changes in economic behaviour are most deleterious for the main types of economic forecasting models; what can be done to improve the performance of such models in the face of structural breaks; and what factors and mistakes do not seem to cause forecast failure. First, the framework and basic concepts are explained. Most measures of forecast accuracy lack invariance to isomorphic representations of models: invariant measures would help avoid artefacts, but even if forecast accuracy remains ambiguous, forecast failure does not. The model class explored is a vector autoregression (VAR) in integrated-cointegrated variables – a vector equilibriumcorrection model (VEqCM) – subject to structural breaks. VARs in levels and differences are special cases; open models are not considered. The role of causal information in economic forecasting is studied, because non-causal variables may outperform when the model and DGP differ, and the latter suffers structural breaks. This difference from a constant-parameter world helps explain the practical procedures of macro-econometric forecasters. A taxonomy of forecast errors is delineated for mis-specified, data-based models, facing structural change in the forecast period, from a mis-measured forecast origin. Deterministic factors, especially shifts in equilibrium means, are the main culprit of systematic forecast failure, while other factors influence excess variability. The theory is applied to forecasting in the face of structural breaks, focusing on the differential robustness of differenced VARs and VEqCMs. The distinction between equilibrium correction (the embodiment of cointegration) and error correction (a mechanism for keeping a model on track) is stressed. The roles of parsimony and collinearity in forecasting highlight the importance of including important, and excluding irrelevant, but changing, variables. Unanticipated deterministic breaks are crucial, as Monte Carlo experiments illustrate. Differencing and intercept corrections can robustify forecasts against such shifts. Empirical examples illustrate the power of the resulting theory. ∗The research for these lecture notes, prepared for the Norwegian Doctoral Program, has been generously financed by the United Kingdom Economic and Social Research Council through the funding of The Econometrics of Economic Policy , R00023344,The Econometrics of Macroeconomic Forecasting , L11625107, andForecasting and Policy in the Evolving Macro-economy , L138251009, as well as by the Leverhulme Trust. I am grateful to both bodies for their continuing support. They are based on joint research with Michael P. Clements of Warwick University.",2010,"[{'authorId': '2262302103', 'name': 'David F. Hendry'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5860/choice.43-4136?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5860/choice.43-4136, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","these lecture notes codify extensive recent research on economic forecasting. when a forecasting model coincides with the mechanism generating the data (dgp) in an unchanging world, the theory of economic forecasting is well developed. forecasts are the conditional expectation, are unbiased, and no other predictor has a smaller mean-square forecast error matrix. cointegration does not markedly alter that conclusion. much less is known about forecasting in a non-stationary and evolving world, especially when the model and dgp differ. the main challenges facing a theory of economic forecasting, however, are to explain the recurrent episodes of systematic mis-forecasting observed historically, and to develop methods which avoid repeating such mistakes in future. to construct an empirically-relevant theory, we allow the model to be mis-specified for a dgp which alters unexpectedly at unknown times. we are able to deduce: what types of changes in economic behaviour are most deleterious for the main types of economic forecasting models; what can be done to improve the performance of such models in the face of structural breaks; and what factors and mistakes do not seem to cause forecast failure. first, the framework and basic concepts are explained. most measures of forecast accuracy lack invariance to isomorphic representations of models: invariant measures would help avoid artefacts, but even if forecast accuracy remains ambiguous, forecast failure does not. the model class explored is a vector autoregression (var) in integrated-cointegrated variables – a vector equilibriumcorrection model (veqcm) – subject to structural breaks. vars in levels and differences are special cases; open models are not considered. the role of causal information in economic forecasting is studied, because non-causal variables may outperform when the model and dgp differ, and the latter suffers structural breaks. this difference from a constant-parameter world helps explain the practical procedures of macro-econometric forecasters. a taxonomy of forecast errors is delineated for mis-specified, data-based models, facing structural change in the forecast period, from a mis-measured forecast origin. deterministic factors, especially shifts in equilibrium means, are the main culprit of systematic forecast failure, while other factors influence excess variability. the theory is applied to forecasting in the face of structural breaks, focusing on the differential robustness of differenced vars and veqcms. the distinction between equilibrium correction (the embodiment of cointegration) and error correction (a mechanism for keeping a model on track) is stressed. the roles of parsimony and collinearity in forecasting highlight the importance of including important, and excluding irrelevant, but changing, variables. unanticipated deterministic breaks are crucial, as monte carlo experiments illustrate. differencing and intercept corrections can robustify forecasts against such shifts. empirical examples illustrate the power of the resulting theory. ∗the research for these lecture notes, prepared for the norwegian doctoral program, has been generously financed by the united kingdom economic and social research council through the funding of the econometrics of economic policy , r00023344,the econometrics of macroeconomic forecasting , l11625107, andforecasting and policy in the evolving macro-economy , l138251009, as well as by the leverhulme trust. i am grateful to both bodies for their continuing support. they are based on joint research with michael p. clements of warwick university.",
373d75b78b2474ee2d677e3c5dd9162f1e8498aa,Current advances and approaches in wind speed and wind power forecasting for improved renewable energy integration: A review,"Wind power is playing a pivotal part in global energy growth as it is clean and pollution‐free. To maximize profits, economic scheduling, dispatching, and planning the unit commitment, there is a great demand for wind forecasting techniques. This drives the researchers and electric utility planners in the direction of more advanced approaches to forecast over broader time horizons. Key prediction techniques use physical, statistical approaches, artificial intelligence techniques, and hybrid methods. An extensive review of the current forecasting techniques, as well as their performance evaluation, is here presented. The techniques used for improving the prediction accuracy, methods to overcome major forecasting problems, evolving trends, and further advanced applications in future research are explored.",2020,"[{'authorId': '69961452', 'name': 'M. Santhosh'}, {'authorId': '30977287', 'name': 'C. Venkaiah'}, {'authorId': '123311293', 'name': 'D. V. Vinod Kumar'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/eng2.12178', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/eng2.12178?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/eng2.12178, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","wind power is playing a pivotal part in global energy growth as it is clean and pollution‐free. to maximize profits, economic scheduling, dispatching, and planning the unit commitment, there is a great demand for wind forecasting techniques. this drives the researchers and electric utility planners in the direction of more advanced approaches to forecast over broader time horizons. key prediction techniques use physical, statistical approaches, artificial intelligence techniques, and hybrid methods. an extensive review of the current forecasting techniques, as well as their performance evaluation, is here presented. the techniques used for improving the prediction accuracy, methods to overcome major forecasting problems, evolving trends, and further advanced applications in future research are explored.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/eng2.12178
a4e6dc9ea4cb54efa78653de7a23603e82e3e98c,Economic Forecasting,"Forecasts guide decisions in all areas of economics and finance and their value can only be understood in relation to, and in the context of, such decisions. We discuss the central role of the loss function in helping determine the forecaster's objectives and use this to present a unified framework for both the construction and evaluation of forecasts. Challenges arise from the explosion in the sheer volume of predictor variables under consideration and the forecaster's ability to entertain an endless array of functional forms and time-varying specifications, none of which may coincide with the 'true' model. Methods for comparing the forecasting performance of pairs of models or evaluating the ability of the best of many models to beat a benchmark specification are also reviewed.",2007,"[{'authorId': '91235891', 'name': 'G. Elliott'}, {'authorId': '2248625889', 'name': 'Allan Timmermann'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1257/jel.46.1.3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1257/jel.46.1.3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","forecasts guide decisions in all areas of economics and finance and their value can only be understood in relation to, and in the context of, such decisions. we discuss the central role of the loss function in helping determine the forecaster's objectives and use this to present a unified framework for both the construction and evaluation of forecasts. challenges arise from the explosion in the sheer volume of predictor variables under consideration and the forecaster's ability to entertain an endless array of functional forms and time-varying specifications, none of which may coincide with the 'true' model. methods for comparing the forecasting performance of pairs of models or evaluating the ability of the best of many models to beat a benchmark specification are also reviewed.",
11a598bf1f178ab8cd8f027c05241a333b330e0b,Forecasting Principles from Experience with Forecasting Competitions,"Economic forecasting is difficult, largely because of the many sources of nonstationarity influencing observational time series. Forecasting competitions aim to improve the practice of economic forecasting by providing very large data sets on which the efficacy of forecasting methods can be evaluated. We consider the general principles that seem to be the foundation for successful forecasting, and show how these are relevant for methods that did well in the M4 competition. We establish some general properties of the M4 data set, which we use to improve the basic benchmark methods, as well as the Card method that we created for our submission to that competition. A data generation process is proposed that captures the salient features of the annual data in M4.",2021,"[{'authorId': '5008433', 'name': 'Jennifer L. Castle'}, {'authorId': '2318305', 'name': 'J. Doornik'}, {'authorId': '2566726', 'name': 'D. Hendry'}]","{'url': 'https://www.mdpi.com/2571-9394/3/1/10/pdf?version=1615970839', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/FORECAST3010010?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/FORECAST3010010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","economic forecasting is difficult, largely because of the many sources of nonstationarity influencing observational time series. forecasting competitions aim to improve the practice of economic forecasting by providing very large data sets on which the efficacy of forecasting methods can be evaluated. we consider the general principles that seem to be the foundation for successful forecasting, and show how these are relevant for methods that did well in the m4 competition. we establish some general properties of the m4 data set, which we use to improve the basic benchmark methods, as well as the card method that we created for our submission to that competition. a data generation process is proposed that captures the salient features of the annual data in m4.",https://www.mdpi.com/2571-9394/3/1/10/pdf?version=1615970839
1c2d054a579bb0763985f6705362b6d3b2c4301f,An Overview of Economic Forecasting,1 What is a forecast? 2 What can be forecast? 3 How confident can we be in forecasts? 4 How is forecasting done generally? 5 How is forecasting done by economists? 6 How can one measure the success or failure of forecasts? 7 How does one analyze the properties of forecasting methods? 8 What special data features matter most? 9 What are the main problems? 10 Do these problems have potential solutions? 11 What is the future of economic forecasting?,2007,"[{'authorId': '2249064', 'name': 'Michael P. Clements'}, {'authorId': '2566726', 'name': 'D. Hendry'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/9780470996430.CH1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/9780470996430.CH1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",1 what is a forecast? 2 what can be forecast? 3 how confident can we be in forecasts? 4 how is forecasting done generally? 5 how is forecasting done by economists? 6 how can one measure the success or failure of forecasts? 7 how does one analyze the properties of forecasting methods? 8 what special data features matter most? 9 what are the main problems? 10 do these problems have potential solutions? 11 what is the future of economic forecasting?,
22fc28191934f3593804e381dea630ea03b59847,A companion to economic forecasting,"List of Contributors. Preface. Acknowledgments. 1. An Overview of Economic Forecasting: Michael P. Clements and David H. Hendry. 2. Predictable Uncertainty in Economic Forecasting: Neil R. Ericsson. 3. Density Forecasting: A Survey: Anthony S. Tay and Kenneth F. Wallis. 4. Statistical Approaches to Modelling and Forecasting Time Series: Diego J. Pedregal and Peter C. Young. 5. Forecasting with Structural Time--Series Models: Tommaso Proietti. 6. Judgemental Forecasting: Dilek A-nkal--Atay, Mary E. Thomson and Andrew C. Pollock. 7. Forecasting for Policy: Adrian R. Pagan and John Robertson. 8. Forecasting Cointegrated VARMA Processes: Helmut Lutkepohl. 9. Multi--Step Forecasting: Raj Bhansali. 10. The Rationality and Efficiency of Individuals' Forecasts: Herman O. Stekler. 11. Decision--Theoretic Methods for Forecast Evaluation: M. Hashem Pesaran and Spyros Skouros. 12. Forecast Combination and Encompassing: Paul Newbold and David I. Harvey. 13. Testing Forecast Accuracy: Roberto S. Mariano. 14. Inference About Predictive Ability: Michael W. McCracken and Kenneth D. West. 15. Forecasting Competitions: Their Role in Improving Forecasting Practice and Research: Robert Fildes and Keith Ord. 16. Empirical Comparisons of Inflation Modelsa Forecast Accuracy: A yvind Eitrheim, Tore Anders Husebo, and Ragnar Nymoen. 17. The Forecasting Performance of the OECD Composite Leading Indicators for France, Germany, Italy, and the UK: Gonzalo Camba--Mendez, George Kapetanios, Martin R. Weale and Richard J. Smith. 18. Unit Root Versus Deterministic Representations of Seasonality for Forecasting: Denise R. Osborn. 19. Forecasting with Periodic Autoregressive Time Series Models: Philip Hans Franses and Richard Paap. 20. Non--Linear Models and Forecasting: Ruey S. Tsay. 21. Forecasting with Smooth Transition Autoregressive Models: Stefan Lundbergh and Timo Terasvirta. 22. Forecasting Financial Variables: Terence C. Mills. 23. Explaining Forecast Failure in Macroeconomics: Michael P. Clements and David F. Hendry. Author Index. Subject Index",2004,"[{'authorId': '2249064', 'name': 'Michael P. Clements'}, {'authorId': '2566726', 'name': 'D. Hendry'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/B.9781405126236.2004.X?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/B.9781405126236.2004.X, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","list of contributors. preface. acknowledgments. 1. an overview of economic forecasting: michael p. clements and david h. hendry. 2. predictable uncertainty in economic forecasting: neil r. ericsson. 3. density forecasting: a survey: anthony s. tay and kenneth f. wallis. 4. statistical approaches to modelling and forecasting time series: diego j. pedregal and peter c. young. 5. forecasting with structural time--series models: tommaso proietti. 6. judgemental forecasting: dilek a-nkal--atay, mary e. thomson and andrew c. pollock. 7. forecasting for policy: adrian r. pagan and john robertson. 8. forecasting cointegrated varma processes: helmut lutkepohl. 9. multi--step forecasting: raj bhansali. 10. the rationality and efficiency of individuals' forecasts: herman o. stekler. 11. decision--theoretic methods for forecast evaluation: m. hashem pesaran and spyros skouros. 12. forecast combination and encompassing: paul newbold and david i. harvey. 13. testing forecast accuracy: roberto s. mariano. 14. inference about predictive ability: michael w. mccracken and kenneth d. west. 15. forecasting competitions: their role in improving forecasting practice and research: robert fildes and keith ord. 16. empirical comparisons of inflation modelsa forecast accuracy: a yvind eitrheim, tore anders husebo, and ragnar nymoen. 17. the forecasting performance of the oecd composite leading indicators for france, germany, italy, and the uk: gonzalo camba--mendez, george kapetanios, martin r. weale and richard j. smith. 18. unit root versus deterministic representations of seasonality for forecasting: denise r. osborn. 19. forecasting with periodic autoregressive time series models: philip hans franses and richard paap. 20. non--linear models and forecasting: ruey s. tsay. 21. forecasting with smooth transition autoregressive models: stefan lundbergh and timo terasvirta. 22. forecasting financial variables: terence c. mills. 23. explaining forecast failure in macroeconomics: michael p. clements and david f. hendry. author index. subject index",
5d02362fa70a5b437ae3527ea3e96ca83f11af25,Electric Vehicle Charging Load Forecasting: A Comparative Study of Deep Learning Approaches,"Load forecasting is one of the major challenges of power system operation and is crucial to the effective scheduling for economic dispatch at multiple time scales. Numerous load forecasting methods have been proposed for household and commercial demand, as well as for loads at various nodes in a power grid. However, compared with conventional loads, the uncoordinated charging of the large penetration of plug-in electric vehicles is different in terms of periodicity and fluctuation, which renders current load forecasting techniques ineffective. Deep learning methods, empowered by unprecedented learning ability from extensive data, provide novel approaches for solving challenging forecasting tasks. This research proposes a comparative study of deep learning approaches to forecast the super-short-term stochastic charging load of plug-in electric vehicles. Several popular and novel deep-learning based methods have been utilized in establishing the forecasting models using minute-level real-world data of a plug-in electric vehicle charging station to compare the forecasting performance. Numerical results of twelve cases on various time steps show that deep learning methods obtain high accuracy in super-short-term plug-in electric load forecasting. Among the various deep learning approaches, the long-short-term memory method performs the best by reducing over 30% forecasting error compared with the conventional artificial neural network model.",2019,"[{'authorId': '151504220', 'name': 'Juncheng Zhu'}, {'authorId': '1899227', 'name': 'Zhile Yang'}, {'authorId': '2519336', 'name': 'M. Mourshed'}, {'authorId': '49813885', 'name': 'Yuanjun Guo'}, {'authorId': '143959713', 'name': 'Yimin Zhou'}, {'authorId': '144664598', 'name': 'Yan Chang'}, {'authorId': '3164695', 'name': 'Yanjie Wei'}, {'authorId': '2113511259', 'name': 'Shengzhong Feng'}]","{'url': 'https://www.mdpi.com/1996-1073/12/14/2692/pdf?version=1563007560', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/EN12142692?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/EN12142692, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","load forecasting is one of the major challenges of power system operation and is crucial to the effective scheduling for economic dispatch at multiple time scales. numerous load forecasting methods have been proposed for household and commercial demand, as well as for loads at various nodes in a power grid. however, compared with conventional loads, the uncoordinated charging of the large penetration of plug-in electric vehicles is different in terms of periodicity and fluctuation, which renders current load forecasting techniques ineffective. deep learning methods, empowered by unprecedented learning ability from extensive data, provide novel approaches for solving challenging forecasting tasks. this research proposes a comparative study of deep learning approaches to forecast the super-short-term stochastic charging load of plug-in electric vehicles. several popular and novel deep-learning based methods have been utilized in establishing the forecasting models using minute-level real-world data of a plug-in electric vehicle charging station to compare the forecasting performance. numerical results of twelve cases on various time steps show that deep learning methods obtain high accuracy in super-short-term plug-in electric load forecasting. among the various deep learning approaches, the long-short-term memory method performs the best by reducing over 30% forecasting error compared with the conventional artificial neural network model.",https://www.mdpi.com/1996-1073/12/14/2692/pdf?version=1563007560
db99c9efba6272ce2b45b844656766b89f449c0f,Uncertainty and disagreement in economic forecasting,"Using the probabilistic responses from the Survey of Professional Forecasters, we study the evolution of uncertainty and disagreement associated with inflation forecasts in the United States since 1968. We compare and contrast alternative measures summarizing the distributions of mean forecasts and forecast uncertainty across individuals at an approximate one-year-ahead horizon. In light of the heterogeneity in individual uncertainty reflected in the survey responses, we provide quarterly estimates for both average uncertainty and disagreement regarding uncertainty. We propose direct estimation of parametric distributions characterizing the uncertainty across individuals in a manner that mitigates errors associated with rounding and approximation of responses when individual uncertainty is small. Our results indicate that higher average expected inflation is associated with both higher average inflation uncertainty and greater disagreement about the inflation outlook. Disagreement about the mean forecast, however, may be a weak proxy for forecast uncertainty. We also examine the relationship of these measures with the term premia embedded in the term-structure of interest rates.",2008,"[{'authorId': '1400700521', 'name': 'Stefania D’Amico'}, {'authorId': '2079264890', 'name': 'Athanasios Orphanides'}]","{'url': 'https://doi.org/10.17016/feds.2008.56', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.17016/FEDS.2008.56?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.17016/FEDS.2008.56, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","using the probabilistic responses from the survey of professional forecasters, we study the evolution of uncertainty and disagreement associated with inflation forecasts in the united states since 1968. we compare and contrast alternative measures summarizing the distributions of mean forecasts and forecast uncertainty across individuals at an approximate one-year-ahead horizon. in light of the heterogeneity in individual uncertainty reflected in the survey responses, we provide quarterly estimates for both average uncertainty and disagreement regarding uncertainty. we propose direct estimation of parametric distributions characterizing the uncertainty across individuals in a manner that mitigates errors associated with rounding and approximation of responses when individual uncertainty is small. our results indicate that higher average expected inflation is associated with both higher average inflation uncertainty and greater disagreement about the inflation outlook. disagreement about the mean forecast, however, may be a weak proxy for forecast uncertainty. we also examine the relationship of these measures with the term premia embedded in the term-structure of interest rates.",https://doi.org/10.17016/feds.2008.56
2d923d5530f509e468b839dd02481735656e1524,Macro-economic Forecasting and Modelling,"Confidence in macro-economic forecasting has periodically been punctured by episodes of economic turbulence and concomitant predictive failure. The poor performance in predicting the consumer boom in the late I98os, and the depth and duration of the recession in the I99os, can be viewed as merely the latest examples in a catalogue of failures, with noteworthy antecedents including the under-prediction of post-war consumption, and the I974-5 and I979-81 recessions.' Periods of economic turbulence may be informative in highlighting model inadequacy, but they also being into question the usefulness of economic forecasting.2 Should we be surprised that such failures have occurred? Econometric theory comprises a body of tools and techniques for analysing the properties of prospective methods under hypothetical states of nature. In the forecasting context, the methods are forecasting models and procedures, and the states of nature relate to the properties of the variables to be forecast. For an econometric theory of forecasting to be useful in terms of delivering relevant conclusions about empirical forecasting, those states must adequately capture thfie appropriate aspects of the real world to be forecast. However, the traditional, text-book theory of economic forecasting fails to allow for a number of vital features of the economy. In particular, analyses of forecasting have usually been based on assumptions that implicitly rule out structural change, or regime shifts, in the economy, namely: [I] a constant, time-invariant, data generating process (DGP); [2] a stationary (non-integrated) DGP; [3] a unique model of the economy which coincides with the DGP. Under these assumptions (particularly [i] and [3]), forecasts calculated as the conditional expectation given the model are optimal in the sense that they are unbiased and efficient - any other forecast will have a larger forecast error variance. By definition, if the model is the DGP, then the expected future value of the variable, given all information available at the present time, is the conditional expectation with respect to the model. In general, forecasts are not * Financial support from the UK Economic and Social Research Council under grant Rooo233447 is gratefully acknowledged by both authors. Neil Ericsson provided many helpful comments on an earlier draft. 1 Spanos (i989) considers the contemporary predictive failure of aggregate consumption functions over 1945-51, arguing that model mis-specification played a role. Wallis (i989) discusses the forecasting record of the major UK model-based forecasting teams for the I974-5 and I979-8i recessions.",1995,"[{'authorId': '2249064', 'name': 'Michael P. Clements'}, {'authorId': '2566726', 'name': 'D. Hendry'}]","{'url': 'https://ora.ox.ac.uk/objects/uuid:d149cd5e-b6eb-408b-94b6-fa5d1d945388/files/m99818ff5831d6247bb63d0cce0a99b69', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2307/2235166?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2307/2235166, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","confidence in macro-economic forecasting has periodically been punctured by episodes of economic turbulence and concomitant predictive failure. the poor performance in predicting the consumer boom in the late i98os, and the depth and duration of the recession in the i99os, can be viewed as merely the latest examples in a catalogue of failures, with noteworthy antecedents including the under-prediction of post-war consumption, and the i974-5 and i979-81 recessions.' periods of economic turbulence may be informative in highlighting model inadequacy, but they also being into question the usefulness of economic forecasting.2 should we be surprised that such failures have occurred? econometric theory comprises a body of tools and techniques for analysing the properties of prospective methods under hypothetical states of nature. in the forecasting context, the methods are forecasting models and procedures, and the states of nature relate to the properties of the variables to be forecast. for an econometric theory of forecasting to be useful in terms of delivering relevant conclusions about empirical forecasting, those states must adequately capture thfie appropriate aspects of the real world to be forecast. however, the traditional, text-book theory of economic forecasting fails to allow for a number of vital features of the economy. in particular, analyses of forecasting have usually been based on assumptions that implicitly rule out structural change, or regime shifts, in the economy, namely: [i] a constant, time-invariant, data generating process (dgp); [2] a stationary (non-integrated) dgp; [3] a unique model of the economy which coincides with the dgp. under these assumptions (particularly [i] and [3]), forecasts calculated as the conditional expectation given the model are optimal in the sense that they are unbiased and efficient - any other forecast will have a larger forecast error variance. by definition, if the model is the dgp, then the expected future value of the variable, given all information available at the present time, is the conditional expectation with respect to the model. in general, forecasts are not * financial support from the uk economic and social research council under grant rooo233447 is gratefully acknowledged by both authors. neil ericsson provided many helpful comments on an earlier draft. 1 spanos (i989) considers the contemporary predictive failure of aggregate consumption functions over 1945-51, arguing that model mis-specification played a role. wallis (i989) discusses the forecasting record of the major uk model-based forecasting teams for the i974-5 and i979-8i recessions.",https://ora.ox.ac.uk/objects/uuid:d149cd5e-b6eb-408b-94b6-fa5d1d945388/files/m99818ff5831d6247bb63d0cce0a99b69
1cf7c532655c17479806cf760813858425245202,A Statistical Approach to Economic Forecasting,"A recently developed statistical model, called Bayesian vector autoregression, has proven to be a useful tool for economic forecasting. Such a model today forecasts a strong resurgence of growth in the second half of 1985 and in 1986.",1986,"[{'authorId': '73776269', 'name': 'Robert B. Litterman'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/07350015.1986.10509485?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/07350015.1986.10509485, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",a statistical approach to economic forecasting,
3a34d63eb4d237cb7c72ac77985d6ef7e069ada6,Public mobility data enables COVID-19 forecasting and management at local and global scales,"Policymakers everywhere are working to determine the set of restrictions that will effectively contain the spread of COVID-19 without excessively stifling economic activity. We show that publicly available data on human mobility—collected by Google, Facebook, and other providers—can be used to evaluate the effectiveness of non-pharmaceutical interventions (NPIs) and forecast the spread of COVID-19. This approach uses simple and transparent statistical models to estimate the effect of NPIs on mobility, and basic machine learning methods to generate 10-day forecasts of COVID-19 cases. An advantage of the approach is that it involves minimal assumptions about disease dynamics, and requires only publicly-available data. We evaluate this approach using local and regional data from China, France, Italy, South Korea, and the United States, as well as national data from 80 countries around the world. We find that NPIs are associated with significant reductions in human mobility, and that changes in mobility can be used to forecast COVID-19 infections.",2020,"[{'authorId': '88182802', 'name': 'C. Ilin'}, {'authorId': '1412446068', 'name': 'Sébastien Annan-Phan'}, {'authorId': '19293146', 'name': 'Xiao Hui Tai'}, {'authorId': '2061340', 'name': 'Shikhar Mehra'}, {'authorId': '6354941', 'name': 'S. Hsiang'}, {'authorId': '2314259', 'name': 'J. Blumenstock'}]","{'url': 'https://doi.org/10.1038/s41598-021-92892-8', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8241991, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","policymakers everywhere are working to determine the set of restrictions that will effectively contain the spread of covid-19 without excessively stifling economic activity. we show that publicly available data on human mobility—collected by google, facebook, and other providers—can be used to evaluate the effectiveness of non-pharmaceutical interventions (npis) and forecast the spread of covid-19. this approach uses simple and transparent statistical models to estimate the effect of npis on mobility, and basic machine learning methods to generate 10-day forecasts of covid-19 cases. an advantage of the approach is that it involves minimal assumptions about disease dynamics, and requires only publicly-available data. we evaluate this approach using local and regional data from china, france, italy, south korea, and the united states, as well as national data from 80 countries around the world. we find that npis are associated with significant reductions in human mobility, and that changes in mobility can be used to forecast covid-19 infections.",https://doi.org/10.1038/s41598-021-92892-8
9bec8c19a030c45d474826c8ebb5ecd9c7d3e55d,Economic Theory and Forecasting: Lessons from the Literature,"Does economic theory help in forecasting key macroeconomic variables? This article aims to provide some insight into the question by drawing lessons from the literature. The definition of ""economic theory"" includes a broad range of examples, such as accounting identities, disaggregation and spatial restrictions when forecasting aggregate variables, cointegration and forecasting with Dynamic Stochastic General Equilibrium (DSGE) models. We group the lessons into three themes. The first discusses the importance of using the correct econometric tools when answering the question. The second presents examples of theory-based forecasting that have not proven useful, such as theory-driven variable selection and some popular DSGE models. The third set of lessons discusses types of theoretical restrictions that have shown some usefulness in forecasting, such as accounting identities, disaggregation and spatial restrictions, and cointegrating relationships. We conclude by suggesting that economic theory might help in overcoming the widespread instability that affects the forecasting performance of econometric models by guiding the search for stable relationships that could be usefully exploited for forecasting.",2014,"[{'authorId': '2243099', 'name': 'R. Giacomini'}]","{'url': 'https://academic.oup.com/ectj/article-pdf/18/2/C22/27682423/ectj0c22.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/ectj.12038?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/ectj.12038, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","does economic theory help in forecasting key macroeconomic variables? this article aims to provide some insight into the question by drawing lessons from the literature. the definition of ""economic theory"" includes a broad range of examples, such as accounting identities, disaggregation and spatial restrictions when forecasting aggregate variables, cointegration and forecasting with dynamic stochastic general equilibrium (dsge) models. we group the lessons into three themes. the first discusses the importance of using the correct econometric tools when answering the question. the second presents examples of theory-based forecasting that have not proven useful, such as theory-driven variable selection and some popular dsge models. the third set of lessons discusses types of theoretical restrictions that have shown some usefulness in forecasting, such as accounting identities, disaggregation and spatial restrictions, and cointegrating relationships. we conclude by suggesting that economic theory might help in overcoming the widespread instability that affects the forecasting performance of econometric models by guiding the search for stable relationships that could be usefully exploited for forecasting.",https://academic.oup.com/ectj/article-pdf/18/2/C22/27682423/ectj0c22.pdf
4d44fa8f1fb00fe343b66326b22b423351244e4c,Detection of regime switches between stationary and nonstationary processes and economic forecasting,"It often occurs that no model may be exactly right, and that different portions of the data may favour different models. The purpose of this paper is to propose a new procedure for the detection of regime switches between stationary and nonstationary processes in economic time series and to show its usefulness in economic forecasting. In the proposed procedure, time series observations are divided into several segments, and a stationary or nonstationary autoregressive model is fitted to each segment. The goodness of fit of the global model composed of these local models is evaluated using the corresponding information criterion, and the division which minimizes the information criterion defines the best model. Simulation and forecasting results show the efficacy and limitations of the proposed procedure. Copyright © 2005 John Wiley & Sons, Ltd.",2005,"[{'authorId': '1880151', 'name': 'Kosei Fukuda'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/FOR.941?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/FOR.941, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","it often occurs that no model may be exactly right, and that different portions of the data may favour different models. the purpose of this paper is to propose a new procedure for the detection of regime switches between stationary and nonstationary processes in economic time series and to show its usefulness in economic forecasting. in the proposed procedure, time series observations are divided into several segments, and a stationary or nonstationary autoregressive model is fitted to each segment. the goodness of fit of the global model composed of these local models is evaluated using the corresponding information criterion, and the division which minimizes the information criterion defines the best model. simulation and forecasting results show the efficacy and limitations of the proposed procedure. copyright © 2005 john wiley & sons, ltd.",
e5a617f559c8037b91fe9e812ed07cff2ba327f9,Policy analysis applications of remi economic forecasting and simulation models,"This article surveys the ways that regional economic forecasting and policy analysis models have been used to provide information as an input for policy decision making in the public and private sectors. The major areas are as follows: forecasting and planning; economic development; transportation; energy and natural resources; taxation, budget, and welfare; United States policies; and environmental policies. The survey indicates that, while analysis and research may be required to prepare for a model simulation, the predicted economic effects of a policy can be very important information as an input for a wide range of policy decisions.",1995,"[{'authorId': '67068787', 'name': 'G. Treyz'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/01900699508524997?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/01900699508524997, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this article surveys the ways that regional economic forecasting and policy analysis models have been used to provide information as an input for policy decision making in the public and private sectors. the major areas are as follows: forecasting and planning; economic development; transportation; energy and natural resources; taxation, budget, and welfare; united states policies; and environmental policies. the survey indicates that, while analysis and research may be required to prepare for a model simulation, the predicted economic effects of a policy can be very important information as an input for a wide range of policy decisions.",
87d357a39aeab2bafa59a29f8ca54ea01b3db4b7,Time Series Models for Business and Economic Forecasting,"With a new author team contributing decades of practical experience, this fully updated and thoroughly classroom-tested second edition textbook prepares students and practitioners to create effective forecasting models and master the techniques of time series analysis. Taking a practical and example-driven approach, this textbook summarises the most critical decisions, techniques and steps involved in creating forecasting models for business and economics. Students are led through the process with an entirely new set of carefully developed theoretical and practical exercises. Chapters examine the key features of economic time series, univariate time series analysis, trends, seasonality, aberrant observations, conditional heteroskedasticity and ARCH models, non-linearity and multivariate time series, making this a complete practical guide. Downloadable datasets are available online.",1998,"[{'authorId': '2388922', 'name': 'P. Franses'}, {'authorId': '143889230', 'name': 'D. Dijk'}, {'authorId': '70291672', 'name': 'A. Opschoor'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2307/2669428?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2307/2669428, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with a new author team contributing decades of practical experience, this fully updated and thoroughly classroom-tested second edition textbook prepares students and practitioners to create effective forecasting models and master the techniques of time series analysis. taking a practical and example-driven approach, this textbook summarises the most critical decisions, techniques and steps involved in creating forecasting models for business and economics. students are led through the process with an entirely new set of carefully developed theoretical and practical exercises. chapters examine the key features of economic time series, univariate time series analysis, trends, seasonality, aberrant observations, conditional heteroskedasticity and arch models, non-linearity and multivariate time series, making this a complete practical guide. downloadable datasets are available online.",
3a4efe398098609954b8b28750abc69b9cd32ee1,A Review of Electricity Demand Forecasting in Low and Middle Income Countries: The Demand Determinants and Horizons,"With the globally increasing electricity demand, its related uncertainties are on the rise as well. Therefore, a deeper insight of load forecasting techniques for projecting future electricity demands becomes imperative for business entities and policy makers. The electricity demand is governed by a set of different variables or “electricity demand determinants”. These demand determinants depend on forecasting horizons (long term, medium term, and short term), the load aggregation level, climate, and socio-economic activities. In this paper, a review of different electricity demand forecasting methodologies is provided in the context of a group of low and middle income countries. The article presents a comprehensive literature review by tabulating the different demand determinants used in different countries and forecasting the trends and techniques used in these countries. A comparative review of these forecasting methodologies over different time horizons reveals that the time series modeling approach has been extensively used while forecasting for long and medium terms. For short term forecasts, artificial intelligence-based techniques remain prevalent in the literature. Furthermore, a comparative analysis of the demand determinants in these countries indicates a frequent use of determinants like the population, GDP, weather, and load data over different time horizons. Following the analysis, potential research gaps are identified, and recommendations are provided, accordingly.",2020,"[{'authorId': '48024786', 'name': 'A. A. Mir'}, {'authorId': '31086283', 'name': 'Mohammed A. Alghassab'}, {'authorId': '100566903', 'name': 'Kafait Ullah'}, {'authorId': '30115568', 'name': 'Z. Khan'}, {'authorId': '48518090', 'name': 'Yuehong Lu'}, {'authorId': '2143706101', 'name': 'M. Imran'}]","{'url': 'https://www.mdpi.com/2071-1050/12/15/5931/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su12155931?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su12155931, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with the globally increasing electricity demand, its related uncertainties are on the rise as well. therefore, a deeper insight of load forecasting techniques for projecting future electricity demands becomes imperative for business entities and policy makers. the electricity demand is governed by a set of different variables or “electricity demand determinants”. these demand determinants depend on forecasting horizons (long term, medium term, and short term), the load aggregation level, climate, and socio-economic activities. in this paper, a review of different electricity demand forecasting methodologies is provided in the context of a group of low and middle income countries. the article presents a comprehensive literature review by tabulating the different demand determinants used in different countries and forecasting the trends and techniques used in these countries. a comparative review of these forecasting methodologies over different time horizons reveals that the time series modeling approach has been extensively used while forecasting for long and medium terms. for short term forecasts, artificial intelligence-based techniques remain prevalent in the literature. furthermore, a comparative analysis of the demand determinants in these countries indicates a frequent use of determinants like the population, gdp, weather, and load data over different time horizons. following the analysis, potential research gaps are identified, and recommendations are provided, accordingly.",https://www.mdpi.com/2071-1050/12/15/5931/pdf
85739bf7569da110b1b1ac2a71f7154402d88cf3,The Record and Improvability of Economic Forecasting,"Have macroeconomic forecasts grown more or less accurate over time? This paper assembles, examines, and interprets evidence bearing on this question. Contrary to some critics, there are no indications that U.S. forecasts have grown systematically worse, that is, less accurate, more biased, or both. Neither do any definite trends in a positive direction emerge from comparisons of annual and quarterly multiperiod forecasts and time-series projections for the principal aggregative variables. The argument is developed and to some extent documented that major failures of forecasting are related to the incidence of slowdowns and contractions in general economic activity. Not only the forecasts of real GNP growth and unemployment but also those of nominal GNP growth and inflation often go seriously wrong when such setbacks occur. Forecasters tend to rely heavily on the persistence of trends in spending, output, and the price level. More attention to data and techniques that are sensitive to business cycle movements and turning points could help improve their record.",1986,"[{'authorId': '70636774', 'name': 'V. Zarnowitz'}]","{'url': 'https://doi.org/10.3386/w2099', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3386/W2099?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3386/W2099, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","have macroeconomic forecasts grown more or less accurate over time? this paper assembles, examines, and interprets evidence bearing on this question. contrary to some critics, there are no indications that u.s. forecasts have grown systematically worse, that is, less accurate, more biased, or both. neither do any definite trends in a positive direction emerge from comparisons of annual and quarterly multiperiod forecasts and time-series projections for the principal aggregative variables. the argument is developed and to some extent documented that major failures of forecasting are related to the incidence of slowdowns and contractions in general economic activity. not only the forecasts of real gnp growth and unemployment but also those of nominal gnp growth and inflation often go seriously wrong when such setbacks occur. forecasters tend to rely heavily on the persistence of trends in spending, output, and the price level. more attention to data and techniques that are sensitive to business cycle movements and turning points could help improve their record.",https://doi.org/10.3386/w2099
8a5f9fad46b0df92aaab35e056ccbe45b05faa13,Economic forecasting at high-frequency intervals,"Forecasting on the basis of the daily flow of monthly or more frequent statistical reports on the economy can enhance the predictive accuracy of quarterly structural models. The high degree of serial correlation in economic data can be used advantageously in quarterly forecasting for a horizon as long as 6 months—perhaps somewhat longer. The model used for high-frequency (weekly) forecasting of the US economy has a national accounting structure and tries to follow the choice of indicators that are used in preparing early estimates of national income and product accounts (NIPA). Estimates are separately generated for the income side and the product side of NIPA. At the level of GDP and closely related aggregates a third prediction is also generated from estimates of the principal components of major monthly indicators. A simple average of three estimates of GDP, together with detail on NIPA components and scores of monthly indicators has been produced every weekend, summarizing the business week's flow of information. This procedure is followed not only for producing a steady stream of high-frequency forecasts but also for providing adjustment factors that can be used for model recalibration, without judgemental input. The tracking of the US economy is illustrated for the period starting before the invasion of Kuwait until the end of the Gulf War.",1993,"[{'authorId': '2317407', 'name': 'L. Klein'}, {'authorId': '2118687562', 'name': 'J. Y. Park'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/FOR.3980120310?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/FOR.3980120310, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","forecasting on the basis of the daily flow of monthly or more frequent statistical reports on the economy can enhance the predictive accuracy of quarterly structural models. the high degree of serial correlation in economic data can be used advantageously in quarterly forecasting for a horizon as long as 6 months—perhaps somewhat longer. the model used for high-frequency (weekly) forecasting of the us economy has a national accounting structure and tries to follow the choice of indicators that are used in preparing early estimates of national income and product accounts (nipa). estimates are separately generated for the income side and the product side of nipa. at the level of gdp and closely related aggregates a third prediction is also generated from estimates of the principal components of major monthly indicators. a simple average of three estimates of gdp, together with detail on nipa components and scores of monthly indicators has been produced every weekend, summarizing the business week's flow of information. this procedure is followed not only for producing a steady stream of high-frequency forecasts but also for providing adjustment factors that can be used for model recalibration, without judgemental input. the tracking of the us economy is illustrated for the period starting before the invasion of kuwait until the end of the gulf war.",
c6f13d3b5037fddf162d874730e27ced16d1863d,A Novel Framework of Reservoir Computing for Deterministic and Probabilistic Wind Power Forecasting,"The path towards wind power forecasting has yielded huge socio–economic benefits at a global scale. However, most of the previous studies tend to emphasize the improvement of deterministic forecasting, usually losing sight of the significance of probabilistic forecasting. In this paper, a novel forecasting system that can perform deterministic and probabilistic forecasting of wind power simultaneously, composed by the modules of feature selection, forecasting, system optimization, and system evaluation is presented to further supplement the existing studies in this field. Concretely, a hybrid feature selection strategy is proposed in the feature selection module to determine optimal system input; superior to traditional gradient descent algorithm, a dynamic reservoir theory-based recurrent neural network is developed in the forecasting module; an enhanced multi-objective optimization algorithm with the objectives of accuracy and stability is proposed in the system optimization module to provide an optimal scenario for system parameters; the effectiveness and feasibility of the proposed system is then validated in the evaluation module. Moreover, the comprehensive performance analysis of the proposed system is investigated in depth. Finally, the experimental results demonstrate that the proposed system has a significant advantage over the benchmarks considered, further verifying its tremendous potential to be used in a practical wind power system.",2020,"[{'authorId': '2048952723', 'name': 'Jianzhou Wang'}, {'authorId': '1499172715', 'name': 'Tong Niu'}, {'authorId': '49408281', 'name': 'H. Lu'}, {'authorId': '2144037305', 'name': 'Wendong Yang'}, {'authorId': '47413775', 'name': 'Pei Du'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TSTE.2019.2890875?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TSTE.2019.2890875, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the path towards wind power forecasting has yielded huge socio–economic benefits at a global scale. however, most of the previous studies tend to emphasize the improvement of deterministic forecasting, usually losing sight of the significance of probabilistic forecasting. in this paper, a novel forecasting system that can perform deterministic and probabilistic forecasting of wind power simultaneously, composed by the modules of feature selection, forecasting, system optimization, and system evaluation is presented to further supplement the existing studies in this field. concretely, a hybrid feature selection strategy is proposed in the feature selection module to determine optimal system input; superior to traditional gradient descent algorithm, a dynamic reservoir theory-based recurrent neural network is developed in the forecasting module; an enhanced multi-objective optimization algorithm with the objectives of accuracy and stability is proposed in the system optimization module to provide an optimal scenario for system parameters; the effectiveness and feasibility of the proposed system is then validated in the evaluation module. moreover, the comprehensive performance analysis of the proposed system is investigated in depth. finally, the experimental results demonstrate that the proposed system has a significant advantage over the benchmarks considered, further verifying its tremendous potential to be used in a practical wind power system.",
d5285cfc2a88b206e4bdcda308950d5f258e54d1,Erratum to “Acquisition of sexual orientation and gender identity data among NCI Community Oncology Research Program practice groups”,"This erratum corrects the following: Cathcart‐Rake EJ, Zemla T, Jatoi A, et al. Acquisition of sexual orientation and gender identity data among NCI Community Oncology Research Program practice groups. Cancer. 2019;125(8):1313‐1318. doi:10.1002/cncr.31925 “Gender identity” and “sexual orientation” were reversed throughout the article. The correct reporting is that 10% of the NCI Community Oncology Research Program practices reported routine collection of sexual orientation information and 24% reported collection of gender identity information. All other results in the article should reflect this corrected reversal. The authors regret this error.",2023,[],"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cncr.34912', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/cncr.34912?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/cncr.34912, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this erratum corrects the following: cathcart‐rake ej, zemla t, jatoi a, et al. acquisition of sexual orientation and gender identity data among nci community oncology research program practice groups. cancer. 2019;125(8):1313‐1318. doi:10.1002/cncr.31925 “gender identity” and “sexual orientation” were reversed throughout the article. the correct reporting is that 10% of the nci community oncology research program practices reported routine collection of sexual orientation information and 24% reported collection of gender identity information. all other results in the article should reflect this corrected reversal. the authors regret this error.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cncr.34912
b9e3d85a96f82118f9613d3b5b4285de9a95ee48,Graph Neural Networks in Cancer and Oncology Research: Emerging and Future Trends,"Simple Summary Graph Neural Networks are emerging as a powerful tool for structured data analysis, and predictive modeling in massive multimodal datasets. In this review, we survey recent applications of graph neural networks in the setting of cancer and oncology research. We identify currently predominant research areas, and compare graph neural networks with non-graph deep learning methods as well as probabilistic graphical models. We conclude by highlighting emerging trends and pressing challenges, such as developing independent and comprehensive benchmarking frameworks. This review is aimed at cancer and oncology researchers, clinicians and physician-scientists who are interested in applying graph-centered secondary data analysis methods to structured multimodal data. Abstract Next-generation cancer and oncology research needs to take full advantage of the multimodal structured, or graph, information, with the graph data types ranging from molecular structures to spatially resolved imaging and digital pathology, biological networks, and knowledge graphs. Graph Neural Networks (GNNs) efficiently combine the graph structure representations with the high predictive performance of deep learning, especially on large multimodal datasets. In this review article, we survey the landscape of recent (2020–present) GNN applications in the context of cancer and oncology research, and delineate six currently predominant research areas. We then identify the most promising directions for future research. We compare GNNs with graphical models and “non-structured” deep learning, and devise guidelines for cancer and oncology researchers or physician-scientists, asking the question of whether they should adopt the GNN methodology in their research pipelines.",2023,"[{'authorId': '7795980', 'name': 'Grigoriy Gogoshin'}, {'authorId': '2258705441', 'name': 'Andrei S. Rodin'}]","{'url': 'https://doi.org/10.3390/cancers15245858', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10742144, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","simple summary graph neural networks are emerging as a powerful tool for structured data analysis, and predictive modeling in massive multimodal datasets. in this review, we survey recent applications of graph neural networks in the setting of cancer and oncology research. we identify currently predominant research areas, and compare graph neural networks with non-graph deep learning methods as well as probabilistic graphical models. we conclude by highlighting emerging trends and pressing challenges, such as developing independent and comprehensive benchmarking frameworks. this review is aimed at cancer and oncology researchers, clinicians and physician-scientists who are interested in applying graph-centered secondary data analysis methods to structured multimodal data. abstract next-generation cancer and oncology research needs to take full advantage of the multimodal structured, or graph, information, with the graph data types ranging from molecular structures to spatially resolved imaging and digital pathology, biological networks, and knowledge graphs. graph neural networks (gnns) efficiently combine the graph structure representations with the high predictive performance of deep learning, especially on large multimodal datasets. in this review article, we survey the landscape of recent (2020–present) gnn applications in the context of cancer and oncology research, and delineate six currently predominant research areas. we then identify the most promising directions for future research. we compare gnns with graphical models and “non-structured” deep learning, and devise guidelines for cancer and oncology researchers or physician-scientists, asking the question of whether they should adopt the gnn methodology in their research pipelines.",https://doi.org/10.3390/cancers15245858
57e8fe4367e82b46d7d52fc9b172ee7c08982bb5,Three-dimensional in vitro culture models in oncology research,"Cancer is a multifactorial disease that is responsible for 10 million deaths per year. The intra- and inter-heterogeneity of malignant tumors make it difficult to develop single targeted approaches. Similarly, their diversity requires various models to investigate the mechanisms involved in cancer initiation, progression, drug resistance and recurrence. Of the in vitro cell-based models, monolayer adherent (also known as 2D culture) cell cultures have been used for the longest time. However, it appears that they are often less appropriate than the three-dimensional (3D) cell culture approach for mimicking the biological behavior of tumor cells, in particular the mechanisms leading to therapeutic escape and drug resistance. Multicellular tumor spheroids are widely used to study cancers in 3D, and can be generated by a multiplicity of techniques, such as liquid-based and scaffold-based 3D cultures, microfluidics and bioprinting. Organoids are more complex 3D models than multicellular tumor spheroids because they are generated from stem cells isolated from patients and are considered as powerful tools to reproduce the disease development in vitro. The present review provides an overview of the various 3D culture models that have been set up to study cancer development and drug response. The advantages of 3D models compared to 2D cell cultures, the limitations, and the fields of application of these models and their techniques of production are also discussed.",2022,"[{'authorId': '2120354806', 'name': 'Camille Jubelin'}, {'authorId': '1438395464', 'name': 'J. Muñoz-García'}, {'authorId': '1822283', 'name': 'L. Griscom'}, {'authorId': '3665217', 'name': 'D. Cochonneau'}, {'authorId': '2180575761', 'name': 'Emilie Ollivier'}, {'authorId': '3514516', 'name': 'M. Heymann'}, {'authorId': '2116333', 'name': 'F. Vallette'}, {'authorId': '5677404', 'name': 'L. Oliver'}, {'authorId': '2172906', 'name': 'D. Heymann'}]","{'url': 'https://cellandbioscience.biomedcentral.com/counter/pdf/10.1186/s13578-022-00887-3', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9465969, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cancer is a multifactorial disease that is responsible for 10 million deaths per year. the intra- and inter-heterogeneity of malignant tumors make it difficult to develop single targeted approaches. similarly, their diversity requires various models to investigate the mechanisms involved in cancer initiation, progression, drug resistance and recurrence. of the in vitro cell-based models, monolayer adherent (also known as 2d culture) cell cultures have been used for the longest time. however, it appears that they are often less appropriate than the three-dimensional (3d) cell culture approach for mimicking the biological behavior of tumor cells, in particular the mechanisms leading to therapeutic escape and drug resistance. multicellular tumor spheroids are widely used to study cancers in 3d, and can be generated by a multiplicity of techniques, such as liquid-based and scaffold-based 3d cultures, microfluidics and bioprinting. organoids are more complex 3d models than multicellular tumor spheroids because they are generated from stem cells isolated from patients and are considered as powerful tools to reproduce the disease development in vitro. the present review provides an overview of the various 3d culture models that have been set up to study cancer development and drug response. the advantages of 3d models compared to 2d cell cultures, the limitations, and the fields of application of these models and their techniques of production are also discussed.",https://cellandbioscience.biomedcentral.com/counter/pdf/10.1186/s13578-022-00887-3
3209adfe5736f848e3682c4b26fb9bf409115680,Exercise as cancer treatment: A clinical oncology framework for exercise oncology research,"Exercise has been proposed as a possible cancer treatment; however, there are an infinite number of clinical oncology settings involving diverse cancer types and treatment protocols in which exercise could be tested as a cancer treatment. The primary purpose of this paper is to propose a conceptual framework to organize and guide research on exercise as a cancer treatment across distinct clinical oncology settings. A secondary purpose is to provide an overview of existing exercise research using the proposed framework. The Exercise as Cancer Treatment (EXACT) framework proposes nine distinct clinical oncology scenarios based on tumor/disease status and treatment status at the time of the proposed exercise treatment. In terms of tumor/disease status, the primary tumor has either been surgically removed (primary goal to treat micrometastases), not surgically removed (primary goal to treat the primary tumor), or metastatic disease is present (primary goal to treat metastatic disease). In terms of treatment status, the extant disease has either not been treated yet (treatment naïve), is currently being treated (active treatment), or has previously been treated. These two key clinical oncology variables—tumor/disease status and treatment status—result in nine distinct clinical oncology scenarios in which exercise could be tested as a new cancer treatment: (a) treatment naïve micrometastases, (b) actively treated micrometastases, (c) previously treated micrometastases, (d) treatment naïve primary tumors, (e) actively treated primary tumors, (f) previously treated primary tumors, (g) treatment naïve metastatic disease, (h) actively treated metastatic disease, and (i) previously treated metastatic disease. To date, most preclinical animal studies have examined the effects of exercise on treatment naïve and actively treated primary tumors. Conversely, most observational human studies have examined the associations between exercise and cancer recurrence/survival in patients actively treated or previously treated for micrometastases. Few clinical trials have been conducted in any of these scenarios. For exercise to be integrated into clinical oncology practice as a cancer treatment, it will need to demonstrate benefit in a specific clinical setting. The EXACT framework provides a simple taxonomy for systematically evaluating exercise as a potential cancer treatment across a diverse range of cancer types and treatment protocols.",2022,"[{'authorId': '4555100', 'name': 'K. Courneya'}, {'authorId': '34871220', 'name': 'C. Booth'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fonc.2022.957135/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9480835, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","exercise has been proposed as a possible cancer treatment; however, there are an infinite number of clinical oncology settings involving diverse cancer types and treatment protocols in which exercise could be tested as a cancer treatment. the primary purpose of this paper is to propose a conceptual framework to organize and guide research on exercise as a cancer treatment across distinct clinical oncology settings. a secondary purpose is to provide an overview of existing exercise research using the proposed framework. the exercise as cancer treatment (exact) framework proposes nine distinct clinical oncology scenarios based on tumor/disease status and treatment status at the time of the proposed exercise treatment. in terms of tumor/disease status, the primary tumor has either been surgically removed (primary goal to treat micrometastases), not surgically removed (primary goal to treat the primary tumor), or metastatic disease is present (primary goal to treat metastatic disease). in terms of treatment status, the extant disease has either not been treated yet (treatment naïve), is currently being treated (active treatment), or has previously been treated. these two key clinical oncology variables—tumor/disease status and treatment status—result in nine distinct clinical oncology scenarios in which exercise could be tested as a new cancer treatment: (a) treatment naïve micrometastases, (b) actively treated micrometastases, (c) previously treated micrometastases, (d) treatment naïve primary tumors, (e) actively treated primary tumors, (f) previously treated primary tumors, (g) treatment naïve metastatic disease, (h) actively treated metastatic disease, and (i) previously treated metastatic disease. to date, most preclinical animal studies have examined the effects of exercise on treatment naïve and actively treated primary tumors. conversely, most observational human studies have examined the associations between exercise and cancer recurrence/survival in patients actively treated or previously treated for micrometastases. few clinical trials have been conducted in any of these scenarios. for exercise to be integrated into clinical oncology practice as a cancer treatment, it will need to demonstrate benefit in a specific clinical setting. the exact framework provides a simple taxonomy for systematically evaluating exercise as a potential cancer treatment across a diverse range of cancer types and treatment protocols.",https://www.frontiersin.org/articles/10.3389/fonc.2022.957135/pdf
c1d0e885129fe7a707e2fce41e65fa2ea4860e76,Advances in Hydrogel-Based Microfluidic Blood–Brain-Barrier Models in Oncology Research,"The intrinsic architecture and complexity of the brain restricts the capacity of therapeutic molecules to reach their potential targets, thereby limiting therapeutic possibilities concerning neurological ailments and brain malignancy. As conventional models fail to recapitulate the complexity of the brain, progress in the field of microfluidics has facilitated the development of advanced in vitro platforms that could imitate the in vivo microenvironments and pathological features of the blood–brain barrier (BBB). It is highly desirous that developed in vitro BBB-on-chip models serve as a platform to investigate cancer metastasis of the brain along with the possibility of efficiently screening chemotherapeutic agents against brain malignancies. In order to improve the proficiency of BBB-on-chip models, hydrogels have been widely explored due to their unique physical and chemical properties, which mimic the three-dimensional (3D) micro architecture of tissues. Hydrogel-based BBB-on-chip models serves as a stage which is conducive for cell growth and allows the exchange of gases and nutrients and the removal of metabolic wastes between cells and the cell/extra cellular matrix (ECM) interface. Here, we present recent advancements in BBB-on-chip models targeting brain malignancies and examine the utility of hydrogel-based BBB models that could further strengthen the future application of microfluidic devices in oncology research.",2022,"[{'authorId': '47573839', 'name': 'Ankur Sood'}, {'authorId': '2153105913', 'name': 'Anuj Kumar'}, {'authorId': '28070620', 'name': 'A. Dev'}, {'authorId': '2110651217', 'name': 'V. Gupta'}, {'authorId': '4260520', 'name': 'S. Han'}]","{'url': 'https://www.mdpi.com/1999-4923/14/5/993/pdf?version=1652084646', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9144371, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the intrinsic architecture and complexity of the brain restricts the capacity of therapeutic molecules to reach their potential targets, thereby limiting therapeutic possibilities concerning neurological ailments and brain malignancy. as conventional models fail to recapitulate the complexity of the brain, progress in the field of microfluidics has facilitated the development of advanced in vitro platforms that could imitate the in vivo microenvironments and pathological features of the blood–brain barrier (bbb). it is highly desirous that developed in vitro bbb-on-chip models serve as a platform to investigate cancer metastasis of the brain along with the possibility of efficiently screening chemotherapeutic agents against brain malignancies. in order to improve the proficiency of bbb-on-chip models, hydrogels have been widely explored due to their unique physical and chemical properties, which mimic the three-dimensional (3d) micro architecture of tissues. hydrogel-based bbb-on-chip models serves as a stage which is conducive for cell growth and allows the exchange of gases and nutrients and the removal of metabolic wastes between cells and the cell/extra cellular matrix (ecm) interface. here, we present recent advancements in bbb-on-chip models targeting brain malignancies and examine the utility of hydrogel-based bbb models that could further strengthen the future application of microfluidic devices in oncology research.",https://www.mdpi.com/1999-4923/14/5/993/pdf?version=1652084646
f43d626df920b64fbded8f6fe7e286030b694df3,Model-assisted cohort selection with bias analysis for generating large-scale cohorts from the EHR for oncology research,"Objective Electronic health records (EHRs) are a promising source of data for health outcomes research in oncology. A challenge in using EHR data is that selecting cohorts of patients often requires information in unstructured parts of the record. Machine learning has been used to address this, but even high-performing algorithms may select patients in a non-random manner and bias the resulting cohort. To improve the efficiency of cohort selection while measuring potential bias, we introduce a technique called Model-Assisted Cohort Selection (MACS) with Bias Analysis and apply it to the selection of metastatic breast cancer (mBC) patients. Materials and Methods We trained a model on 17,263 patients using term-frequency inverse-document-frequency (TF-IDF) and logistic regression. We used a test set of 17,292 patients to measure algorithm performance and perform Bias Analysis. We compared the cohort generated by MACS to the cohort that would have been generated without MACS as reference standard, first by comparing distributions of an extensive set of clinical and demographic variables and then by comparing the results of two analyses addressing existing example research questions. Results Our algorithm had an area under the curve (AUC) of 0.976, a sensitivity of 96.0%, and an abstraction efficiency gain of 77.9%. During Bias Analysis, we found no large differences in baseline characteristics and no differences in the example analyses. Conclusion MACS with bias analysis can significantly improve the efficiency of cohort selection on EHR data while instilling confidence that outcomes research performed on the resulting cohort will not be biased.",2020,"[{'authorId': '2071026187', 'name': 'B. Birnbaum'}, {'authorId': '48987583', 'name': 'N. Nussbaum'}, {'authorId': '1403676056', 'name': 'Kathi Seidl-Rathkopf'}, {'authorId': '2056898702', 'name': 'Monica Agrawal'}, {'authorId': '147460336', 'name': 'M. Estévez'}, {'authorId': '32180105', 'name': 'Evan Estola'}, {'authorId': '69047712', 'name': 'J. Haimson'}, {'authorId': '2218868148', 'name': 'Lucy He'}, {'authorId': '2060502459', 'name': 'Peter Larson'}, {'authorId': '153479296', 'name': 'P. Richardson'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2001.09765, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objective electronic health records (ehrs) are a promising source of data for health outcomes research in oncology. a challenge in using ehr data is that selecting cohorts of patients often requires information in unstructured parts of the record. machine learning has been used to address this, but even high-performing algorithms may select patients in a non-random manner and bias the resulting cohort. to improve the efficiency of cohort selection while measuring potential bias, we introduce a technique called model-assisted cohort selection (macs) with bias analysis and apply it to the selection of metastatic breast cancer (mbc) patients. materials and methods we trained a model on 17,263 patients using term-frequency inverse-document-frequency (tf-idf) and logistic regression. we used a test set of 17,292 patients to measure algorithm performance and perform bias analysis. we compared the cohort generated by macs to the cohort that would have been generated without macs as reference standard, first by comparing distributions of an extensive set of clinical and demographic variables and then by comparing the results of two analyses addressing existing example research questions. results our algorithm had an area under the curve (auc) of 0.976, a sensitivity of 96.0%, and an abstraction efficiency gain of 77.9%. during bias analysis, we found no large differences in baseline characteristics and no differences in the example analyses. conclusion macs with bias analysis can significantly improve the efficiency of cohort selection on ehr data while instilling confidence that outcomes research performed on the resulting cohort will not be biased.",
a90309dcfe6ce20e2fd47100da1002c829f1e703,A call to action: Antiracist patient engagement in adolescent and young adult oncology research and advocacy.,"Amidst the concurrent global crises of coronavirus disease 2019 (COVID-19), uprisings against Anti-Black racism and police brutality, as well as anti-Asian racism and violence, the field of medicine found itself simultaneously called upon to respond as essential workers in the public health devastation of COVID-19, and as representatives of healthcare institutions wrought with the impacts of systemic racism. Clinicians, researchers, and advocates in adolescent and young adult (AYA) oncology, must come together in authentic activism to begin the work of creating structural change to advance antiracist approaches to patient engagement in AYA oncology research and advocacy. Critical review of existing practices is needed to ensure that ethical and effective research methods are employed when engaging with racial and ethnic minority AYA patients with cancer, who may be particularly vulnerable and exploited in the current context.",2021,"[{'authorId': '29503424', 'name': 'Christabel K. Cheung'}, {'authorId': '1875875670', 'name': 'Reginald Tucker-Seeley'}, {'authorId': '1381158384', 'name': 'S. Davies'}, {'authorId': '2119568171', 'name': 'Megan L Gilman'}, {'authorId': '32884615', 'name': 'K. Miller'}, {'authorId': '151012406', 'name': 'G. Lopes'}, {'authorId': '26847590', 'name': 'Gail Betz'}, {'authorId': '1994895069', 'name': 'Thuli Katerere-Virima'}, {'authorId': '1994888083', 'name': 'Laura E Helbling'}, {'authorId': '146310017', 'name': 'Bria N Thomas'}, {'authorId': '2117278866', 'name': 'Mark A. Lewis'}]","{'url': 'https://doi.org/10.2217/fon-2020-1213', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2217/fon-2020-1213?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2217/fon-2020-1213, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","amidst the concurrent global crises of coronavirus disease 2019 (covid-19), uprisings against anti-black racism and police brutality, as well as anti-asian racism and violence, the field of medicine found itself simultaneously called upon to respond as essential workers in the public health devastation of covid-19, and as representatives of healthcare institutions wrought with the impacts of systemic racism. clinicians, researchers, and advocates in adolescent and young adult (aya) oncology, must come together in authentic activism to begin the work of creating structural change to advance antiracist approaches to patient engagement in aya oncology research and advocacy. critical review of existing practices is needed to ensure that ethical and effective research methods are employed when engaging with racial and ethnic minority aya patients with cancer, who may be particularly vulnerable and exploited in the current context.",https://doi.org/10.2217/fon-2020-1213
51fe2589f2a57be871e87af02d195b2fa1beecac,Current Landscape of Nutrition Within Prehabilitation Oncology Research: A Scoping Review,"Background: Prehabilitation aims to improve functional capacity prior to cancer treatment to achieve better psychosocial and clinical outcomes. Prehabilitation interventions vary considerably in design and delivery. In order to identify gaps in knowledge and facilitate the design of future studies, we undertook a scoping review of prehabilitation studies to map the range of work on prehabilitation being carried out in any cancer type and with a particular focus on diet or nutrition interventions. Objectives: Firstly, to describe the type of prehabilitation programs currently being conducted. Secondly, to describe the extent to which prehabilitation studies involved aspects of nutrition, including assessment, interventions, implementation, and outcomes. Eligibility Criteria: Any study of quantitative or qualitative design that employed a formal prehabilitation program before cancer treatment (“prehabilitation” listed in keywords, title, or abstract). Sources of Evidence: Search was conducted in July 2020 using MEDLINE, PubMed, EMBASE, EMCARE, CINAHL, and AMED. Charting Methods: Quantitative data were reported as frequencies. Qualitative nutrition data were charted using a framework analysis that reflects the Nutrition Care Process Model: assessment, intervention, and monitoring/evaluation of the nutrition intervention. Results: Five hundred fifty unique articles were identified: 110 studies met inclusion criteria of a formal prehabilitation study in oncology. prehabilitation studies were mostly cohort studies (41%) or randomized-controlled trials (38%) of multimodal (49%), or exercise-only (44%) interventions that were applied before surgery (94%). Nutrition assessment was inconsistently applied across these studies, and often conducted without validated tools (46%). Of the 110 studies, 37 (34%) included a nutrition treatment component. Half of these studies provided the goal for the nutrition component of their prehabilitation program; of these goals, less than half referenced accepted nutrition guidelines in surgery or oncology. Nutrition interventions largely consisted of counseling with dietary supplementation. The nutrition intervention was indiscernible in 24% of studies. Two-thirds of studies did not monitor the nutrition intervention nor evaluate nutrition outcomes. Conclusion: Prehabilitation literature lacks standardized and validated nutritional assessment, is frequently conducted without evidence-based nutrition interventions, and is typically implemented without monitoring the nutrition intervention or evaluating the intervention's contribution to outcomes. We suggest that the development of a core outcome set could improve the quality of the studies, enable pooling of evidence, and address some of the research gaps identified.",2021,"[{'authorId': '50515849', 'name': 'C. Gillis'}, {'authorId': '2069454426', 'name': 'S. Davies'}, {'authorId': '153790970', 'name': 'F. Carli'}, {'authorId': '4907785', 'name': 'P. Wischmeyer'}, {'authorId': '5700827', 'name': 'S. Wootton'}, {'authorId': '144672679', 'name': 'A. Jackson'}, {'authorId': '46487110', 'name': 'B. Riedel'}, {'authorId': '2173171', 'name': 'L. Marino'}, {'authorId': '4757084', 'name': 'D. Levett'}, {'authorId': '152239688', 'name': 'M. West'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fnut.2021.644723/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8062858, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background: prehabilitation aims to improve functional capacity prior to cancer treatment to achieve better psychosocial and clinical outcomes. prehabilitation interventions vary considerably in design and delivery. in order to identify gaps in knowledge and facilitate the design of future studies, we undertook a scoping review of prehabilitation studies to map the range of work on prehabilitation being carried out in any cancer type and with a particular focus on diet or nutrition interventions. objectives: firstly, to describe the type of prehabilitation programs currently being conducted. secondly, to describe the extent to which prehabilitation studies involved aspects of nutrition, including assessment, interventions, implementation, and outcomes. eligibility criteria: any study of quantitative or qualitative design that employed a formal prehabilitation program before cancer treatment (“prehabilitation” listed in keywords, title, or abstract). sources of evidence: search was conducted in july 2020 using medline, pubmed, embase, emcare, cinahl, and amed. charting methods: quantitative data were reported as frequencies. qualitative nutrition data were charted using a framework analysis that reflects the nutrition care process model: assessment, intervention, and monitoring/evaluation of the nutrition intervention. results: five hundred fifty unique articles were identified: 110 studies met inclusion criteria of a formal prehabilitation study in oncology. prehabilitation studies were mostly cohort studies (41%) or randomized-controlled trials (38%) of multimodal (49%), or exercise-only (44%) interventions that were applied before surgery (94%). nutrition assessment was inconsistently applied across these studies, and often conducted without validated tools (46%). of the 110 studies, 37 (34%) included a nutrition treatment component. half of these studies provided the goal for the nutrition component of their prehabilitation program; of these goals, less than half referenced accepted nutrition guidelines in surgery or oncology. nutrition interventions largely consisted of counseling with dietary supplementation. the nutrition intervention was indiscernible in 24% of studies. two-thirds of studies did not monitor the nutrition intervention nor evaluate nutrition outcomes. conclusion: prehabilitation literature lacks standardized and validated nutritional assessment, is frequently conducted without evidence-based nutrition interventions, and is typically implemented without monitoring the nutrition intervention or evaluating the intervention's contribution to outcomes. we suggest that the development of a core outcome set could improve the quality of the studies, enable pooling of evidence, and address some of the research gaps identified.",https://www.frontiersin.org/articles/10.3389/fnut.2021.644723/pdf
ffbd6557b51d1c929bfd880ea365c78857b3fd4b,Advancing the Field of Pediatric Exercise Oncology: Research and Innovation Needs,"The field of pediatric exercise oncology explores the relationships between physical activity (PA), including exercise, and a range of outcomes among children and adolescents affected by cancer. Although PA is safe and beneficial for this population, several important gaps in knowledge and practice remain. In this article, we describe research and innovation needs that were developed with a team of international experts and relevant literature, a series of online surveys, and an in-person meeting. Addressing these needs will contribute valuable knowledge and practice outputs to advance this field, ultimately enabling a greater number of children and adolescents affected by cancer to realize the benefits of moving more.",2021,"[{'authorId': '48850393', 'name': 'Amanda Wurz'}, {'authorId': '152472690', 'name': 'E. McLaughlin'}, {'authorId': '6332766', 'name': 'Carolina Chamorro Viña'}, {'authorId': '46528104', 'name': 'Sarah L. Grimshaw'}, {'authorId': '10402177', 'name': 'Lotta Hamari'}, {'authorId': '9035854', 'name': 'M. Götte'}, {'authorId': '4758916', 'name': 'S. Kesting'}, {'authorId': '2052876245', 'name': 'Francesca Rossi'}, {'authorId': '5543249', 'name': 'P. van der Torre'}, {'authorId': '144164345', 'name': 'G. Guilcher'}, {'authorId': '2047591765', 'name': 'K. McIntyre'}, {'authorId': '1400654166', 'name': 'S. Culos-Reed'}]","{'url': 'https://www.mdpi.com/1718-7729/28/1/61/pdf?version=1611328150', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7924382, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the field of pediatric exercise oncology explores the relationships between physical activity (pa), including exercise, and a range of outcomes among children and adolescents affected by cancer. although pa is safe and beneficial for this population, several important gaps in knowledge and practice remain. in this article, we describe research and innovation needs that were developed with a team of international experts and relevant literature, a series of online surveys, and an in-person meeting. addressing these needs will contribute valuable knowledge and practice outputs to advance this field, ultimately enabling a greater number of children and adolescents affected by cancer to realize the benefits of moving more.",https://www.mdpi.com/1718-7729/28/1/61/pdf?version=1611328150
776fbcd21d27e414feec1e4a6a0a625cf4b0c17c,Current Practices for Screening and Addressing Financial Hardship within the NCI Community Oncology Research Program,"Background: Cancer-related financial hardship is associated with poor care outcomes and reduced quality of life for patients and families. Scalable intervention development to address financial hardship requires knowledge of current screening practices and services within community cancer care. Methods: The NCI Community Oncology Research Program (NCORP) 2017 Landscape Assessment survey assessed financial screening and financial navigation practices within U.S. community oncology practices. Logistic models evaluated associations between financial hardship screening and availability of a cancer-specific financial navigator and practice group characteristics (e.g., safety-net designation, critical access hospital, proportion of racial and ethnic minority patients served). Results: Of 221 participating NCORP practice groups, 72% reported a financial screening process and 50% had a cancer-specific financial navigator. Practice groups with more than 10% of new patients with cancer enrolled in Medicaid (adjOR = 2.81, P = 0.02) and with less than 30% racial/ethnic minority cancer patient composition (adjOR = 3.91, P < 0.01) were more likely to screen for financial concerns. Practice groups with less than 30% racial/ethnic minority cancer patient composition (adjOR = 2.37, P < 0.01) were more likely to have a dedicated financial navigator or counselor for patients with cancer. Conclusions: Most NCORP practice groups screen for financial concerns and half have a cancer-specific financial navigator. Practices serving more racial or ethnic minority patients are less likely to screen and have a designated financial navigator. Impact: The effectiveness of financial screening and navigation for mitigating financial hardship could be tested within NCORP, along with specific interventions to address cancer care inequities. See related commentary by Yabroff et al., p. 593",2020,"[{'authorId': '1416288412', 'name': 'Laurie E. McLouth'}, {'authorId': '50304098', 'name': 'C. Nightingale'}, {'authorId': '2034674', 'name': 'E. Dressler'}, {'authorId': '4073954', 'name': 'A. Snavely'}, {'authorId': '3099520', 'name': 'M. Hudson'}, {'authorId': '2981439', 'name': 'J. Unger'}, {'authorId': '4878654', 'name': 'A. Kazak'}, {'authorId': '2667815', 'name': 'S. Lee'}, {'authorId': '8761765', 'name': 'J. Edward'}, {'authorId': '143789504', 'name': 'R. Carlos'}, {'authorId': '6299201', 'name': 'C. Kamen'}, {'authorId': '2287047', 'name': 'H. Neuman'}, {'authorId': '5107787', 'name': 'K. Weaver'}]","{'url': 'https://aacrjournals.org/cebp/article-pdf/30/4/669/3100360/669.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1158/1055-9965.EPI-20-1157?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1158/1055-9965.EPI-20-1157, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background: cancer-related financial hardship is associated with poor care outcomes and reduced quality of life for patients and families. scalable intervention development to address financial hardship requires knowledge of current screening practices and services within community cancer care. methods: the nci community oncology research program (ncorp) 2017 landscape assessment survey assessed financial screening and financial navigation practices within u.s. community oncology practices. logistic models evaluated associations between financial hardship screening and availability of a cancer-specific financial navigator and practice group characteristics (e.g., safety-net designation, critical access hospital, proportion of racial and ethnic minority patients served). results: of 221 participating ncorp practice groups, 72% reported a financial screening process and 50% had a cancer-specific financial navigator. practice groups with more than 10% of new patients with cancer enrolled in medicaid (adjor = 2.81, p = 0.02) and with less than 30% racial/ethnic minority cancer patient composition (adjor = 3.91, p < 0.01) were more likely to screen for financial concerns. practice groups with less than 30% racial/ethnic minority cancer patient composition (adjor = 2.37, p < 0.01) were more likely to have a dedicated financial navigator or counselor for patients with cancer. conclusions: most ncorp practice groups screen for financial concerns and half have a cancer-specific financial navigator. practices serving more racial or ethnic minority patients are less likely to screen and have a designated financial navigator. impact: the effectiveness of financial screening and navigation for mitigating financial hardship could be tested within ncorp, along with specific interventions to address cancer care inequities. see related commentary by yabroff et al., p. 593",https://aacrjournals.org/cebp/article-pdf/30/4/669/3100360/669.pdf
192e048050d84d83d12a114292469b1e1bab6dd3,Global Oncology Research and Training Collaborations Led by the National Cancer Institute (NCI)–Designated Cancer Centers: Results From the 2018 NCI/ASCO Global Oncology Survey of NCI-Designated Cancer Centers,"The National Cancer Institute (NCI)–Designated Cancer Centers (NDCCs) are active in global oncology research and training, leading collaborations that contribute to the evidence to support global cancer control. To better understand global oncology activities led by NDCCs, the National Cancer Institute Center for Global Health (NCI-CGH) collaborated with ASCO to conduct the 2018 NCI/ASCO Global Oncology Survey of NDCCs. The 70 NDCCs received a two-part survey that focused on global oncology programs at NDCCs and non–National Institutes of Health (NIH)–funded global oncology projects with an international collaborator led by the NDCCs. Sixty-five NDCCs responded to the survey, and 57 reported non–NIH-funded global oncology projects. Data were cleaned, coded, and analyzed by NCI-CGH staff. Thirty NDCCs (43%) report having a global oncology program, and 538 non–NIH-funded global oncology projects were reported. Of the NDCCs with global oncology programs, 17 report that trainees complete rotations outside the United States, and the same number enroll trainees from low- and middle-income countries (LMICs). In addition, 147 (28%) of the non–NIH-funded projects focused on capacity building or training, the second highest category after research. Of the 30 top project collaborator countries, 17 were LMICs. Compared with the NCI-funded international grant portfolio, non–NIH-funded global oncology projects were more likely to focus on prevention (12% NCI-funded v 20% non–NIH-funded); early detection, diagnosis, and prognosis (23% v 30%); and cancer control, survivorship, and outcomes research (13% v 22%). This survey shows that there is a substantial amount of global oncology research and training supported by NDCCs, and much of this is happening in LMICs. Results of the 2018 Global Oncology Survey can be used to foster opportunities for NDCCs to work collaboratively on activities and to share their findings with relevant stakeholders in their LMIC collaborator countries.",2019,"[{'authorId': '46739733', 'name': 'K. Duncan'}, {'authorId': '12345738', 'name': 'R. Abudu'}, {'authorId': '144831069', 'name': 'M. Cira'}, {'authorId': '120137511', 'name': 'D. Pyle'}]","{'url': 'https://doi.org/10.1200/jgo.19.11000', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1200/jgo.19.11000?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1200/jgo.19.11000, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the national cancer institute (nci)–designated cancer centers (ndccs) are active in global oncology research and training, leading collaborations that contribute to the evidence to support global cancer control. to better understand global oncology activities led by ndccs, the national cancer institute center for global health (nci-cgh) collaborated with asco to conduct the 2018 nci/asco global oncology survey of ndccs. the 70 ndccs received a two-part survey that focused on global oncology programs at ndccs and non–national institutes of health (nih)–funded global oncology projects with an international collaborator led by the ndccs. sixty-five ndccs responded to the survey, and 57 reported non–nih-funded global oncology projects. data were cleaned, coded, and analyzed by nci-cgh staff. thirty ndccs (43%) report having a global oncology program, and 538 non–nih-funded global oncology projects were reported. of the ndccs with global oncology programs, 17 report that trainees complete rotations outside the united states, and the same number enroll trainees from low- and middle-income countries (lmics). in addition, 147 (28%) of the non–nih-funded projects focused on capacity building or training, the second highest category after research. of the 30 top project collaborator countries, 17 were lmics. compared with the nci-funded international grant portfolio, non–nih-funded global oncology projects were more likely to focus on prevention (12% nci-funded v 20% non–nih-funded); early detection, diagnosis, and prognosis (23% v 30%); and cancer control, survivorship, and outcomes research (13% v 22%). this survey shows that there is a substantial amount of global oncology research and training supported by ndccs, and much of this is happening in lmics. results of the 2018 global oncology survey can be used to foster opportunities for ndccs to work collaboratively on activities and to share their findings with relevant stakeholders in their lmic collaborator countries.",https://doi.org/10.1200/jgo.19.11000
d68a9ed7b40ccacc92c075d9b652ed85b0ee14e1,CRI iAtlas: an interactive portal for immuno-oncology research,"The Cancer Research Institute (CRI) iAtlas is an interactive web platform for data exploration and discovery in the context of tumors and their interactions with the immune microenvironment. iAtlas allows researchers to study immune response characterizations and patterns for individual tumor types, tumor subtypes, and immune subtypes. iAtlas supports computation and visualization of correlations and statistics among features related to the tumor microenvironment, cell composition, immune expression signatures, tumor mutation burden, cancer driver mutations, adaptive cell clonality, patient survival, expression of key immunomodulators, and tumor infiltrating lymphocyte (TIL) spatial maps. iAtlas was launched to accompany the release of the TCGA PanCancer Atlas and has since been expanded to include new capabilities such as (1) user-defined loading of sample cohorts, (2) a tool for classifying expression data into immune subtypes, and (3) integration of TIL mapping from digital pathology images. We expect that the CRI iAtlas will accelerate discovery and improve patient outcomes by providing researchers access to standardized immunogenomics data to better understand the tumor immune microenvironment and its impact on patient responses to immunotherapy.",2020,"[{'authorId': '46672888', 'name': 'James A. Eddy'}, {'authorId': '1815330', 'name': 'V. Thorsson'}, {'authorId': '37381234', 'name': 'Andrew Lamb'}, {'authorId': '32188492', 'name': 'David L. Gibbs'}, {'authorId': '2005492738', 'name': 'Carolina Heimann'}, {'authorId': '153174801', 'name': 'Jia Xin Yu'}, {'authorId': '35514206', 'name': 'Verena Chung'}, {'authorId': '7346417', 'name': 'Yooree Chae'}, {'authorId': '2064842470', 'name': 'Kristen Dang'}, {'authorId': '3515232', 'name': 'B. Vincent'}, {'authorId': '1758585', 'name': 'I. Shmulevich'}, {'authorId': '1684985', 'name': 'J. Guinney'}]","{'url': 'https://f1000research.com/articles/9-1028/v1/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7658727, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the cancer research institute (cri) iatlas is an interactive web platform for data exploration and discovery in the context of tumors and their interactions with the immune microenvironment. iatlas allows researchers to study immune response characterizations and patterns for individual tumor types, tumor subtypes, and immune subtypes. iatlas supports computation and visualization of correlations and statistics among features related to the tumor microenvironment, cell composition, immune expression signatures, tumor mutation burden, cancer driver mutations, adaptive cell clonality, patient survival, expression of key immunomodulators, and tumor infiltrating lymphocyte (til) spatial maps. iatlas was launched to accompany the release of the tcga pancancer atlas and has since been expanded to include new capabilities such as (1) user-defined loading of sample cohorts, (2) a tool for classifying expression data into immune subtypes, and (3) integration of til mapping from digital pathology images. we expect that the cri iatlas will accelerate discovery and improve patient outcomes by providing researchers access to standardized immunogenomics data to better understand the tumor immune microenvironment and its impact on patient responses to immunotherapy.",https://f1000research.com/articles/9-1028/v1/pdf
8343b790c11a5aee807affa10ec26bbeef7eb84c,Bibliometric Analysis of the Results of Cardio-Oncology Research,"Objective To analyze the development of cardio-oncology, summarize the research achievements, and provide proposals for its future research. Methods The web of science database was used to search for “cardio-oncology” and “oncocardiology” related articles from the beginning of the database (1970) to April 5, 2019. Excel 2016 and Cytoscape were used to analyze the trend of cardio-oncology research. Results A total of 356 articles were obtained. The number of articles has grown rapidly in recent years. Cardiac injury caused by tumor therapy was a research hotspot (n = 107). Researchers paid more attention to the prevention and treatment of cardiotoxicity (n = 54). Experimental researches were a small part of all studies (n = 72), mainly focusing on the study of cancer drugs' cardiac injury, test indicators of cardiotoxicity, and preventive drugs. The United States (n = 156.25), Italy (n = 48.5), and Canada (n = 23.5) published the most articles, making a great contribution to the development of cardio-oncology. Conclusions Cardio-oncology has been developing rapidly and receiving a large amount of research efforts in recent years. Most articles on cardio-oncology were published by the authors from the United States (44%) and Italy (17%), while other countries need to pay more attention to cardio-oncology. As an independent discipline, cardio-oncology is certainly in need of significant progress, but it has formed a basic framework, which has obtained many leading theories and meaningful achievements in diagnostic criteria, diagnostic methods, prevention and treatment, mechanism research, and influencing factor. Cardiac injury of tumor drugs has always been a research hotspot in this discipline, and there is still a lot of research space. The research about detection methods of cardiotoxicity and preventive drugs is gradually increasing. Basic research lags behind, and many mechanisms are still unclear.",2020,"[{'authorId': '2052426835', 'name': 'K. Wei'}, {'authorId': '4522158', 'name': 'Jiangquan Liao'}, {'authorId': '150140615', 'name': 'Jiangmeng Chang'}, {'authorId': '1740126718', 'name': 'Xiaoqiong Zhang'}, {'authorId': '2356368948', 'name': 'Ming Chen'}, {'authorId': '8491166', 'name': 'Jinhang Du'}]","{'url': 'https://europepmc.org/articles/pmc7244983?pdf=render', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7244983, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objective to analyze the development of cardio-oncology, summarize the research achievements, and provide proposals for its future research. methods the web of science database was used to search for “cardio-oncology” and “oncocardiology” related articles from the beginning of the database (1970) to april 5, 2019. excel 2016 and cytoscape were used to analyze the trend of cardio-oncology research. results a total of 356 articles were obtained. the number of articles has grown rapidly in recent years. cardiac injury caused by tumor therapy was a research hotspot (n = 107). researchers paid more attention to the prevention and treatment of cardiotoxicity (n = 54). experimental researches were a small part of all studies (n = 72), mainly focusing on the study of cancer drugs' cardiac injury, test indicators of cardiotoxicity, and preventive drugs. the united states (n = 156.25), italy (n = 48.5), and canada (n = 23.5) published the most articles, making a great contribution to the development of cardio-oncology. conclusions cardio-oncology has been developing rapidly and receiving a large amount of research efforts in recent years. most articles on cardio-oncology were published by the authors from the united states (44%) and italy (17%), while other countries need to pay more attention to cardio-oncology. as an independent discipline, cardio-oncology is certainly in need of significant progress, but it has formed a basic framework, which has obtained many leading theories and meaningful achievements in diagnostic criteria, diagnostic methods, prevention and treatment, mechanism research, and influencing factor. cardiac injury of tumor drugs has always been a research hotspot in this discipline, and there is still a lot of research space. the research about detection methods of cardiotoxicity and preventive drugs is gradually increasing. basic research lags behind, and many mechanisms are still unclear.",https://europepmc.org/articles/pmc7244983?pdf=render
e939171fcefb6dc79c79f5ce71944ac1573d7ea1,The European Organization for Research and Treatment of Cancer QLQ-C30: a quality-of-life instrument for use in international clinical trials in oncology.,"BACKGROUND
In 1986, the European Organization for Research and Treatment of Cancer (EORTC) initiated a research program to develop an integrated, modular approach for evaluating the quality of life of patients participating in international clinical trials.


PURPOSE
We report here the results of an international field study of the practicality, reliability, and validity of the EORTC QLQ-C30, the current core questionnaire. The QLQ-C30 incorporates nine multi-item scales: five functional scales (physical, role, cognitive, emotional, and social); three symptom scales (fatigue, pain, and nausea and vomiting); and a global health and quality-of-life scale. Several single-item symptom measures are also included.


METHODS
The questionnaire was administered before treatment and once during treatment to 305 patients with nonresectable lung cancer from centers in 13 countries. Clinical variables assessed included disease stage, weight loss, performance status, and treatment toxicity.


RESULTS
The average time required to complete the questionnaire was approximately 11 minutes, and most patients required no assistance. The data supported the hypothesized scale structure of the questionnaire with the exception of role functioning (work and household activities), which was also the only multi-item scale that failed to meet the minimal standards for reliability (Cronbach's alpha coefficient > or = .70) either before or during treatment. Validity was shown by three findings. First, while all interscale correlations were statistically significant, the correlation was moderate, indicating that the scales were assessing distinct components of the quality-of-life construct. Second, most of the functional and symptom measures discriminated clearly between patients differing in clinical status as defined by the Eastern Cooperative Oncology Group performance status scale, weight loss, and treatment toxicity. Third, there were statistically significant changes, in the expected direction, in physical and role functioning, global quality of life, fatigue, and nausea and vomiting, for patients whose performance status had improved or worsened during treatment. The reliability and validity of the questionnaire were highly consistent across the three language-cultural groups studied: patients from English-speaking countries, Northern Europe, and Southern Europe.


CONCLUSIONS
These results support the EORTC QLQ-C30 as a reliable and valid measure of the quality of life of cancer patients in multicultural clinical research settings. Work is ongoing to examine the performance of the questionnaire among more heterogenous patient samples and in phase II and phase III clinical trials.",1993,"[{'authorId': '5258166', 'name': 'N. Aaronson'}, {'authorId': '5280872', 'name': 'S. Ahmedzai'}, {'authorId': '46558066', 'name': 'B. Bergman'}, {'authorId': '5659749', 'name': 'M. Bullinger'}, {'authorId': '32012198', 'name': 'A. Cull'}, {'authorId': '5210821', 'name': 'N. Duez'}, {'authorId': '8490574', 'name': 'A. Filiberti'}, {'authorId': '4772584', 'name': 'H. Flechtner'}, {'authorId': '5862801', 'name': 'S. Fleishman'}, {'authorId': '2434251', 'name': 'J. Haes'}, {'authorId': '2373918', 'name': 'S. Kaasa'}, {'authorId': '5830544', 'name': 'M. Klee'}, {'authorId': '4004887', 'name': 'D. Osoba'}, {'authorId': '5343352', 'name': 'D. Razavi'}, {'authorId': '2225021515', 'name': 'Peter B. C. Rofe'}, {'authorId': '6852082', 'name': 'S. Schraub'}, {'authorId': '4293137', 'name': 'K. Sneeuw'}, {'authorId': '47982304', 'name': 'M. Sullivan'}, {'authorId': '2104270046', 'name': 'F. Takeda'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/JNCI/85.5.365?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/JNCI/85.5.365, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background in 1986, the european organization for research and treatment of cancer (eortc) initiated a research program to develop an integrated, modular approach for evaluating the quality of life of patients participating in international clinical trials. purpose we report here the results of an international field study of the practicality, reliability, and validity of the eortc qlq-c30, the current core questionnaire. the qlq-c30 incorporates nine multi-item scales: five functional scales (physical, role, cognitive, emotional, and social); three symptom scales (fatigue, pain, and nausea and vomiting); and a global health and quality-of-life scale. several single-item symptom measures are also included. methods the questionnaire was administered before treatment and once during treatment to 305 patients with nonresectable lung cancer from centers in 13 countries. clinical variables assessed included disease stage, weight loss, performance status, and treatment toxicity. results the average time required to complete the questionnaire was approximately 11 minutes, and most patients required no assistance. the data supported the hypothesized scale structure of the questionnaire with the exception of role functioning (work and household activities), which was also the only multi-item scale that failed to meet the minimal standards for reliability (cronbach's alpha coefficient > or = .70) either before or during treatment. validity was shown by three findings. first, while all interscale correlations were statistically significant, the correlation was moderate, indicating that the scales were assessing distinct components of the quality-of-life construct. second, most of the functional and symptom measures discriminated clearly between patients differing in clinical status as defined by the eastern cooperative oncology group performance status scale, weight loss, and treatment toxicity. third, there were statistically significant changes, in the expected direction, in physical and role functioning, global quality of life, fatigue, and nausea and vomiting, for patients whose performance status had improved or worsened during treatment. the reliability and validity of the questionnaire were highly consistent across the three language-cultural groups studied: patients from english-speaking countries, northern europe, and southern europe. conclusions these results support the eortc qlq-c30 as a reliable and valid measure of the quality of life of cancer patients in multicultural clinical research settings. work is ongoing to examine the performance of the questionnaire among more heterogenous patient samples and in phase ii and phase iii clinical trials.",
e90c6ad9b9b95e28bc75b988f7622915a603c949,Strengths and limitations of large databases in lung cancer radiation oncology research.,"There has been a substantial rise in the utilization of large databases in radiation oncology research. The advantages of these datasets include a large sample size and inclusion of a diverse population of patients in a real-world setting. Such observational studies hold promise in enhancing our understanding of questions for which evidence is conflicting or absent in lung cancer radiotherapy. However, it is critical that investigators understand the strengths and limitations of large databases in order to avoid the common pitfalls that beset observational analyses. This review begins by outlining the data variables available in major registries that are used most often in observational analyses. This is followed by a discussion of the type of radiotherapy-related questions that can be addressed using such datasets, accompanied by examples from the lung cancer literature. Finally, we describe some limitations of observational research and techniques to mitigate bias and confounding. We hope that clinicians and researchers find this review helpful for designing new research studies and interpreting published analyses in the literature.",2019,"[{'authorId': '8024706', 'name': 'V. Jairam'}, {'authorId': '2651942', 'name': 'Henry S. Park'}]","{'url': 'https://tlcr.amegroups.com/article/viewFile/29070/21190', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.21037/TLCR.2019.05.06?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.21037/TLCR.2019.05.06, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","there has been a substantial rise in the utilization of large databases in radiation oncology research. the advantages of these datasets include a large sample size and inclusion of a diverse population of patients in a real-world setting. such observational studies hold promise in enhancing our understanding of questions for which evidence is conflicting or absent in lung cancer radiotherapy. however, it is critical that investigators understand the strengths and limitations of large databases in order to avoid the common pitfalls that beset observational analyses. this review begins by outlining the data variables available in major registries that are used most often in observational analyses. this is followed by a discussion of the type of radiotherapy-related questions that can be addressed using such datasets, accompanied by examples from the lung cancer literature. finally, we describe some limitations of observational research and techniques to mitigate bias and confounding. we hope that clinicians and researchers find this review helpful for designing new research studies and interpreting published analyses in the literature.",https://tlcr.amegroups.com/article/viewFile/29070/21190
f15238e280652664c421670e692427c743bf193f,Evolution of Cancer Care Delivery Research in the NCI Community Oncology Research Program.,"Research seeking to improve patient engagement with decision-making, use of evidence-based guidelines, and coordination of multi-specialty care has made important contributions to the decades-long effort to improve cancer care. The National Cancer Institute (NCI) expanded support for these efforts by including cancer care delivery research in the 2014 formation of the NCI Community Oncology Research Program (NCORP). Cancer care delivery research is a multi-disciplinary effort to generate evidence-based practice change that improves clinical outcomes and patient well-being. NCORP scientists and community-based clinicians and organizations rapidly embraced the addition of this type of research into the network, resulting in a robust portfolio of observational studies and intervention studies within the first five years of funding. This commentary describes the initial steps in conducting this type of research in a network previously focused on cancer prevention, control, and treatment studies; characterizes the protocols developed to date; and outlines future directions for cancer care delivery research in the second round of NCORP funding.",2019,"[{'authorId': '74667191', 'name': 'A. Geiger'}, {'authorId': '1393996289', 'name': ""A. O'Mara""}, {'authorId': '1416264228', 'name': 'W. McCaskill-Stevens'}, {'authorId': '3809419', 'name': 'Brenda A Adjei'}, {'authorId': '1470822729', 'name': 'Priyanga Tuovenin'}, {'authorId': '32680168', 'name': 'K. Castro'}]","{'url': 'https://academic.oup.com/jnci/article-pdf/112/6/557/33399503/djz234.pdf', 'status': 'HYBRID', 'license': 'public-domain', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/jnci/djz234?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/jnci/djz234, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","research seeking to improve patient engagement with decision-making, use of evidence-based guidelines, and coordination of multi-specialty care has made important contributions to the decades-long effort to improve cancer care. the national cancer institute (nci) expanded support for these efforts by including cancer care delivery research in the 2014 formation of the nci community oncology research program (ncorp). cancer care delivery research is a multi-disciplinary effort to generate evidence-based practice change that improves clinical outcomes and patient well-being. ncorp scientists and community-based clinicians and organizations rapidly embraced the addition of this type of research into the network, resulting in a robust portfolio of observational studies and intervention studies within the first five years of funding. this commentary describes the initial steps in conducting this type of research in a network previously focused on cancer prevention, control, and treatment studies; characterizes the protocols developed to date; and outlines future directions for cancer care delivery research in the second round of ncorp funding.",https://academic.oup.com/jnci/article-pdf/112/6/557/33399503/djz234.pdf
87beab871e336c329a4ba9d207df982246b7f747,"Of Mice, Dogs, Pigs, and Men: Choosing the Appropriate Model for Immuno-Oncology Research.","The immune system plays dual roles in response to cancer. The host immune system protects against tumor formation via immunosurveillance; however, recognition of the tumor by immune cells also induces sculpting mechanisms leading to a Darwinian selection of tumor cell variants with reduced immunogenicity. Cancer immunoediting is the concept used to describe the complex interplay between tumor cells and the immune system. This concept, commonly referred to as the three E's, is encompassed by 3 distinct phases of elimination, equilibrium, and escape. Despite impressive results in the clinic, cancer immunotherapy still has room for improvement as many patients remain unresponsive to therapy. Moreover, many of the preclinical results obtained in the widely used mouse models of cancer are lost in translation to human patients.To improve the success rate of immuno-oncology research and preclinical testing of immune-based anticancer therapies, using alternative animal models more closely related to humans is a promising approach. Here, we describe 2 of the major alternative model systems: canine (spontaneous) and porcine (experimental) cancer models. Although dogs display a high rate of spontaneous tumor formation, an increased number of genetically modified porcine models exist. We suggest that the optimal immuno-oncology model may depend on the stage of cancer immunoediting in question. In particular, the spontaneous canine tumor models provide a unique platform for evaluating therapies aimed at the escape phase of cancer, while genetically engineered swine allow for elucidation of tumor-immune cell interactions especially during the phases of elimination and equilibrium.",2018,"[{'authorId': '5688045', 'name': 'Nana H Overgaard'}, {'authorId': '4079371', 'name': 'T. Fan'}, {'authorId': '5788773', 'name': 'K. Schachtschneider'}, {'authorId': '6309656', 'name': 'D. Principe'}, {'authorId': '2312244', 'name': 'L. Schook'}, {'authorId': '4966871', 'name': 'G. Jungersen'}]","{'url': 'https://academic.oup.com/ilarjournal/advance-article-pdf/doi/10.1093/ilar/ily014/26681016/ily014.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/ilar/ily014?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/ilar/ily014, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the immune system plays dual roles in response to cancer. the host immune system protects against tumor formation via immunosurveillance; however, recognition of the tumor by immune cells also induces sculpting mechanisms leading to a darwinian selection of tumor cell variants with reduced immunogenicity. cancer immunoediting is the concept used to describe the complex interplay between tumor cells and the immune system. this concept, commonly referred to as the three e's, is encompassed by 3 distinct phases of elimination, equilibrium, and escape. despite impressive results in the clinic, cancer immunotherapy still has room for improvement as many patients remain unresponsive to therapy. moreover, many of the preclinical results obtained in the widely used mouse models of cancer are lost in translation to human patients.to improve the success rate of immuno-oncology research and preclinical testing of immune-based anticancer therapies, using alternative animal models more closely related to humans is a promising approach. here, we describe 2 of the major alternative model systems: canine (spontaneous) and porcine (experimental) cancer models. although dogs display a high rate of spontaneous tumor formation, an increased number of genetically modified porcine models exist. we suggest that the optimal immuno-oncology model may depend on the stage of cancer immunoediting in question. in particular, the spontaneous canine tumor models provide a unique platform for evaluating therapies aimed at the escape phase of cancer, while genetically engineered swine allow for elucidation of tumor-immune cell interactions especially during the phases of elimination and equilibrium.",https://academic.oup.com/ilarjournal/advance-article-pdf/doi/10.1093/ilar/ily014/26681016/ily014.pdf
ec1ea563af560a33fc382465856cf7e198404647,Ethical Framework for Including Research Biopsies in Oncology Clinical Trials: American Society of Clinical Oncology Research Statement.,"In contrast to clinical biopsies, where tissue is collected to inform patient care, research biopsies are performed for scientific purposes to potentially enhance understanding of the biologic bases of cancer and drug action, thereby improving diagnosis and treatment, but they may offer no direct benefit to participants and have known risks. The widespread use of research biopsies that do not have the potential to directly benefit participants has come under scrutiny, with critics raising ethical concerns related to the adequacy of participant protections, informed consent, and participant understanding of the risks and benefits, as well as the scientific impact of research biopsies on drug development and treatment. This manuscript presents the American Society of Clinical Oncology's (ASCO's) ethical framework for incorporation of research biopsies in trials. The framework provides guidance on the circumstances to include optional and mandatory biopsies, as well as provides recommendations to stakeholders on necessary steps for improving the conduct of research biopsies overall.",2019,"[{'authorId': '145000982', 'name': 'Laura A. Levit'}, {'authorId': '3982661', 'name': 'J. Peppercorn'}, {'authorId': '2718810', 'name': 'A. Tam'}, {'authorId': '13696553', 'name': 'Jonathan M Marron'}, {'authorId': '40568538', 'name': 'Debra J. H. Mathews'}, {'authorId': '78534218', 'name': 'Kathryn Levit'}, {'authorId': '37442806', 'name': 'N. Roach'}, {'authorId': '3505532', 'name': 'M. Ratain'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1200/JCO.19.01479?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1200/JCO.19.01479, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in contrast to clinical biopsies, where tissue is collected to inform patient care, research biopsies are performed for scientific purposes to potentially enhance understanding of the biologic bases of cancer and drug action, thereby improving diagnosis and treatment, but they may offer no direct benefit to participants and have known risks. the widespread use of research biopsies that do not have the potential to directly benefit participants has come under scrutiny, with critics raising ethical concerns related to the adequacy of participant protections, informed consent, and participant understanding of the risks and benefits, as well as the scientific impact of research biopsies on drug development and treatment. this manuscript presents the american society of clinical oncology's (asco's) ethical framework for incorporation of research biopsies in trials. the framework provides guidance on the circumstances to include optional and mandatory biopsies, as well as provides recommendations to stakeholders on necessary steps for improving the conduct of research biopsies overall.",
2907b56bc4953219fc0e6a478d3a62ba5e53db86,"Production Trends, Collaboration, and Main Topics of the Integrative and Complementary Oncology Research Area: A Bibliometric Analysis","Background: The prevalence of cancer has increased over time worldwide. Nevertheless, the number of deaths has been reduced during the past 2 decades. Thus, one-third of the cancer patients are users of complementary and alternative therapies, looking for other types of interventions. The main aim of the present study is to understand the current status of the research in integrative and complementary oncology. Three different aspects were analyzed: production trends, country collaboration, and leading research topics. Methods: The dataset was obtained from the documents indexed under the Integrative and Complementary Medicine category of the Web of Science database from 1976 to 2017. VOSviewer and SciMAT software were employed to perform the bibliometric analysis. Results: The Journal of Ethnopharmacology, China Medical University and the People’s Republic of China are the leading producers in the field. Regarding the collaboration, the United States and China present a close connection. The scientific community is focused on the following topics: apoptosis, breast cancer, oxidative stress, chemotherapy, and nuclear factor-Kappa-B (NF-Kappa-B). Conclusions: The present article shows potentially important information that allows understanding of the past, present, and future of research in integrative and complementary oncology. It is a useful evidence-based framework on which to base future research actions and academic directions.",2019,"[{'authorId': '1403473779', 'name': 'J. A. Moral-Munoz'}, {'authorId': '1401050034', 'name': 'Lidia Carballo-Costa'}, {'authorId': '1397996912', 'name': 'E. Herrera-Viedma'}, {'authorId': '143823752', 'name': 'M. Cobo'}]","{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/1534735419846401', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6501486, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background: the prevalence of cancer has increased over time worldwide. nevertheless, the number of deaths has been reduced during the past 2 decades. thus, one-third of the cancer patients are users of complementary and alternative therapies, looking for other types of interventions. the main aim of the present study is to understand the current status of the research in integrative and complementary oncology. three different aspects were analyzed: production trends, country collaboration, and leading research topics. methods: the dataset was obtained from the documents indexed under the integrative and complementary medicine category of the web of science database from 1976 to 2017. vosviewer and scimat software were employed to perform the bibliometric analysis. results: the journal of ethnopharmacology, china medical university and the people’s republic of china are the leading producers in the field. regarding the collaboration, the united states and china present a close connection. the scientific community is focused on the following topics: apoptosis, breast cancer, oxidative stress, chemotherapy, and nuclear factor-kappa-b (nf-kappa-b). conclusions: the present article shows potentially important information that allows understanding of the past, present, and future of research in integrative and complementary oncology. it is a useful evidence-based framework on which to base future research actions and academic directions.",https://journals.sagepub.com/doi/pdf/10.1177/1534735419846401
5f4ca611b05bbdb94c0db38059bc9d6ab34f21c7,"Predictive Analytics in Spine Oncology Research: First Steps, Limitations, and Future Directions","The potential of big data analytics to improve the quality of care for patients with spine tumors is significant. At this moment, the application of big data analytics to oncology and spine surgery is at a nascent stage. As such, efforts are underway to advance data-driven oncologic care, improve patient outcomes, and guide clinical decision making. This is both relevant and critical in the practice of spine oncology as clinical decision making is often made in isolation looking at select variables deemed relevant by the physician. With rapidly evolving therapeutics in surgery, radiation, interventional radiology, and oncology, there is a need to better develop decision-making algorithms utilizing the vast data available for each patient. The challenges and limitations inherent to big data analyses are presented with an eye towards future directions.",2019,"[{'authorId': '1478821972', 'name': 'E. Massaad'}, {'authorId': '134510399', 'name': 'N. Fatima'}, {'authorId': '1395995298', 'name': 'Muhamed Hadzipasic'}, {'authorId': '1401309851', 'name': 'C. Alvarez-Breckenridge'}, {'authorId': '144611771', 'name': 'G. Shankar'}, {'authorId': '145123630', 'name': 'John H. Shin'}]","{'url': 'https://www.e-neurospine.org/upload/pdf/ns-16-4-669.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6944986, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the potential of big data analytics to improve the quality of care for patients with spine tumors is significant. at this moment, the application of big data analytics to oncology and spine surgery is at a nascent stage. as such, efforts are underway to advance data-driven oncologic care, improve patient outcomes, and guide clinical decision making. this is both relevant and critical in the practice of spine oncology as clinical decision making is often made in isolation looking at select variables deemed relevant by the physician. with rapidly evolving therapeutics in surgery, radiation, interventional radiology, and oncology, there is a need to better develop decision-making algorithms utilizing the vast data available for each patient. the challenges and limitations inherent to big data analyses are presented with an eye towards future directions.",https://www.e-neurospine.org/upload/pdf/ns-16-4-669.pdf
9ac53d16590641b2454200d08b13f0f432e02b31,Landscape of Global Oncology Research and Training at National Cancer Institute–Designated Cancer Centers: Results of the 2018 to 2019 Global Oncology Survey,"PURPOSE The National Cancer Institute (NCI)–Designated Cancer Centers (NDCCs) are active in global oncology research and training, leading collaborations to support global cancer control. To better understand global oncology activities led by NDCCs, the NCI Center for Global Health collaborated with ASCO to conduct the 2018/2019 NCI/ASCO Global Oncology Survey of NDCCs. METHODS Seventy NDCCs received a two-part survey that focused on global oncology programs at NDCCs and non–National Institutes of Health (NIH)-funded global oncology projects with an international collaborator led by the NDCCs. Sixty-seven NDCCs responded to the survey. Data were coded and analyzed by NCI-Center for Global Health staff. RESULTS Thirty-three NDCCs (47%) reported having a global oncology program, and 61 (87%) reported a collective total of 613 non–NIH-funded global oncology projects. Of the NDCCs with global oncology programs, 17 reported that trainees completed rotations outside the United States and the same number enrolled trainees from low- and middle-income countries (LMIC). Primary focus areas of non–NIH-funded projects were research (469 [76.5%]) and capacity building or training (197 [32.1%]). Projects included collaborators from 110 countries; 68 of these were LMIC. CONCLUSION This survey shows that there is a substantial amount of global oncology research and training conducted by NDCCs and that much of this is happening in LMIC. Trends in these data reflect those in recent literature: The field of global oncology is growing, advancing scientific knowledge, contributing to building research and training capacity in LMIC, and becoming a recognized career path. Results of the 2018 Global Oncology Survey can be used to foster opportunities for NDCCs to work collaboratively on activities and to share their findings with relevant stakeholders in their LMIC collaborator countries.",2019,"[{'authorId': '12345738', 'name': 'R. Abudu'}, {'authorId': '144831069', 'name': 'M. Cira'}, {'authorId': '120137511', 'name': 'D. Pyle'}, {'authorId': '46739733', 'name': 'K. Duncan'}]","{'url': 'https://doi.org/10.1200/jgo.19.00308', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6882505, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose the national cancer institute (nci)–designated cancer centers (ndccs) are active in global oncology research and training, leading collaborations to support global cancer control. to better understand global oncology activities led by ndccs, the nci center for global health collaborated with asco to conduct the 2018/2019 nci/asco global oncology survey of ndccs. methods seventy ndccs received a two-part survey that focused on global oncology programs at ndccs and non–national institutes of health (nih)-funded global oncology projects with an international collaborator led by the ndccs. sixty-seven ndccs responded to the survey. data were coded and analyzed by nci-center for global health staff. results thirty-three ndccs (47%) reported having a global oncology program, and 61 (87%) reported a collective total of 613 non–nih-funded global oncology projects. of the ndccs with global oncology programs, 17 reported that trainees completed rotations outside the united states and the same number enrolled trainees from low- and middle-income countries (lmic). primary focus areas of non–nih-funded projects were research (469 [76.5%]) and capacity building or training (197 [32.1%]). projects included collaborators from 110 countries; 68 of these were lmic. conclusion this survey shows that there is a substantial amount of global oncology research and training conducted by ndccs and that much of this is happening in lmic. trends in these data reflect those in recent literature: the field of global oncology is growing, advancing scientific knowledge, contributing to building research and training capacity in lmic, and becoming a recognized career path. results of the 2018 global oncology survey can be used to foster opportunities for ndccs to work collaboratively on activities and to share their findings with relevant stakeholders in their lmic collaborator countries.",https://doi.org/10.1200/jgo.19.00308
fc55179600db54e82216293add99f753cb4897f4,Multidisciplinary Approach to Novel Therapies in Cardio-Oncology Research (MANTICORE 101-Breast): A Randomized Trial for the Prevention of Trastuzumab-Associated Cardiotoxicity.,"Purpose The primary toxicity of trastuzumab therapy for human epidermal growth factor receptor 2-overexpressing (HER2-positive) breast cancer is dose-independent cardiac dysfunction. Angiotensin-converting enzyme inhibitors and β-blockers are recommended first-line agents for heart failure. We hypothesized that angiotensin-converting enzyme inhibitors and β-blockers could prevent trastuzumab-related cardiotoxicity. Patients and Methods In this double-blinded, placebo-controlled trial, patients with HER2-positive early breast cancer were randomly assigned to receive treatment with perindopril, bisoprolol, or placebo (1:1:1) for the duration of trastuzumab adjuvant therapy. Patients underwent cardiac magnetic resonance imaging at baseline and post-cycle 17 for the determination of left ventricular volumes and left ventricular ejection fraction (LVEF). Cardiotoxicity was evaluated as the change in indexed left ventricular end diastolic volume and LVEF. Results Thirty-three patients received perindopril, 31 received bisoprolol, and 30 received placebo. Baseline demographic, cancer, and cardiovascular profiles were similar between groups. Study drugs were well tolerated with no serious adverse events. After 17 cycles of trastuzumab, indexed left ventricular end diastolic volume increased in patients treated with perindopril (+7 ± 14 mL/m2), bisoprolol (+8 mL ± 9 mL/m2), and placebo (+4 ± 11 mL/m2; P = .36). In secondary analyses, trastuzumab-mediated decline in LVEF was attenuated in bisoprolol-treated patients (-1 ± 5%) relative to the perindopril (-3 ± 4%) and placebo (-5 ± 5%) groups ( P = .001). Perindopril and bisoprolol use were independent predictors of maintained LVEF on multivariable analysis. Conclusion Perindopril and bisoprolol were well tolerated in patients with HER2-positive early breast cancer who received trastuzumab and protected against cancer therapy-related declines in LVEF; however, trastuzumab-mediated left ventricular remodeling-the primary outcome-was not prevented by these pharmacotherapies.",2017,"[{'authorId': '4098669', 'name': 'E. Pituskin'}, {'authorId': '2800712', 'name': 'J. Mackey'}, {'authorId': '144067499', 'name': 'S. Koshman'}, {'authorId': '6802434', 'name': 'D. Jassal'}, {'authorId': '144410668', 'name': 'M. Pitz'}, {'authorId': '6613407', 'name': 'M. Haykowsky'}, {'authorId': '4120875', 'name': 'J. Pagano'}, {'authorId': '37128163', 'name': 'Kelvin Chow'}, {'authorId': '22824706', 'name': 'Richard B. Thompson'}, {'authorId': '143985041', 'name': 'L. Vos'}, {'authorId': '2084845', 'name': 'Sunita Ghosh'}, {'authorId': '5049862', 'name': 'G. Oudit'}, {'authorId': '4177222', 'name': 'J. Ezekowitz'}, {'authorId': '32177373', 'name': 'D. Paterson'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1200/JCO.2016.68.7830?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1200/JCO.2016.68.7830, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose the primary toxicity of trastuzumab therapy for human epidermal growth factor receptor 2-overexpressing (her2-positive) breast cancer is dose-independent cardiac dysfunction. angiotensin-converting enzyme inhibitors and β-blockers are recommended first-line agents for heart failure. we hypothesized that angiotensin-converting enzyme inhibitors and β-blockers could prevent trastuzumab-related cardiotoxicity. patients and methods in this double-blinded, placebo-controlled trial, patients with her2-positive early breast cancer were randomly assigned to receive treatment with perindopril, bisoprolol, or placebo (1:1:1) for the duration of trastuzumab adjuvant therapy. patients underwent cardiac magnetic resonance imaging at baseline and post-cycle 17 for the determination of left ventricular volumes and left ventricular ejection fraction (lvef). cardiotoxicity was evaluated as the change in indexed left ventricular end diastolic volume and lvef. results thirty-three patients received perindopril, 31 received bisoprolol, and 30 received placebo. baseline demographic, cancer, and cardiovascular profiles were similar between groups. study drugs were well tolerated with no serious adverse events. after 17 cycles of trastuzumab, indexed left ventricular end diastolic volume increased in patients treated with perindopril (+7 ± 14 ml/m2), bisoprolol (+8 ml ± 9 ml/m2), and placebo (+4 ± 11 ml/m2; p = .36). in secondary analyses, trastuzumab-mediated decline in lvef was attenuated in bisoprolol-treated patients (-1 ± 5%) relative to the perindopril (-3 ± 4%) and placebo (-5 ± 5%) groups ( p = .001). perindopril and bisoprolol use were independent predictors of maintained lvef on multivariable analysis. conclusion perindopril and bisoprolol were well tolerated in patients with her2-positive early breast cancer who received trastuzumab and protected against cancer therapy-related declines in lvef; however, trastuzumab-mediated left ventricular remodeling-the primary outcome-was not prevented by these pharmacotherapies.",
9e8cd816ebadd7c4353693a9c9cf5fbe2d773ed3,Reporting guidelines for oncology research: helping to maximise the impact of your research,"Many reports of health research omit important information needed to assess their methodological robustness and clinical relevance. Without clear and complete reporting, it is not possible to identify flaws or biases, reproduce successful interventions, or use the findings in systematic reviews or meta-analyses. The EQUATOR Network (http://www.equator-network.org/) promotes responsible reporting and the use of reporting guidelines to improve the accuracy, completeness, and transparency of health research. EQUATOR supports researchers by providing online resources and training. EQUATOR Oncology, a project funded by Cancer Research UK, aims to support cancer researchers reporting their research through the provision of online resources. In this article, our objective is to highlight reporting issues related to oncology research publications and to introduce reporting guidelines that are designed to aid high-quality reporting. We describe generic reporting guidelines for the main study types, and explain how these guidelines should and should not be used. We also describe 37 oncology-specific reporting guidelines, covering different clinical areas (e.g., haematology or urology) and sections of the report (e.g., methods or study characteristics); most of these are little-used. We also provide some background information on EQUATOR Oncology, which focuses on addressing the reporting needs of the oncology research community.",2018,"[{'authorId': '3646177', 'name': 'A. Maccarthy'}, {'authorId': '4855240', 'name': 'S. Kirtley'}, {'authorId': '35410083', 'name': 'J. D. de Beyer'}, {'authorId': '144117798', 'name': 'D. Altman'}, {'authorId': '5777708', 'name': 'I. Simera'}]","{'url': 'https://www.nature.com/articles/bjc2017407.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5846057, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","many reports of health research omit important information needed to assess their methodological robustness and clinical relevance. without clear and complete reporting, it is not possible to identify flaws or biases, reproduce successful interventions, or use the findings in systematic reviews or meta-analyses. the equator network (http://www.equator-network.org/) promotes responsible reporting and the use of reporting guidelines to improve the accuracy, completeness, and transparency of health research. equator supports researchers by providing online resources and training. equator oncology, a project funded by cancer research uk, aims to support cancer researchers reporting their research through the provision of online resources. in this article, our objective is to highlight reporting issues related to oncology research publications and to introduce reporting guidelines that are designed to aid high-quality reporting. we describe generic reporting guidelines for the main study types, and explain how these guidelines should and should not be used. we also describe 37 oncology-specific reporting guidelines, covering different clinical areas (e.g., haematology or urology) and sections of the report (e.g., methods or study characteristics); most of these are little-used. we also provide some background information on equator oncology, which focuses on addressing the reporting needs of the oncology research community.",https://www.nature.com/articles/bjc2017407.pdf
682f304b28a9e62b3789bb129186e717ec65e8dd,Recent advances in precision oncology research,"Precision oncology has evolved into focusing on matching the most accurate and effective treatments based not only on the genetic profile of the patient and his/her cancer, but also on other unique characteristics that distinguish one patient from another. Each patient has a unique genome, proteome, epigenome, microbiome, lifestyle, diet, and other characteristics that all interact to influence oncogenesis, disease progression, effective treatment options, drug tolerance, remission, and relapse. Cancer comprises several hundred heterogeneous diseases, meaning that differences exist not only between cancer cells from various patients, but also between cancer cells within a single patient. Cancer is constantly developing characteristics to evade death and this is why no single drug has been effective in “curing” cancer. Precision oncology now involves using a combination of the unique characteristics of each patient to direct immunotherapy and targeted therapies.1 Many advances in research over the past year reflect these ideologies of precision oncology. Here we describe a few recent policy and research advances in the field of precision oncology. 
 
Most recently, the focus has shifted from treating cancer based on type and histology to treating the specific cancer mutation. FDA policies have paved the way for the adoption of “big data” genetic profiling techniques to guide patient therapies, such as those described by the NCI-MATCH (Molecular Analysis for Therapy Choice) or the NCI-MPACT (Molecular Profiling-based Assignment of Cancer Therapy) initiatives. In June 2017, the FDA granted regular approvals for using a combination of dabrafenib (i.e., a BRAF inhibitor) and trametinib (i.e., a MEK inhibitor) to treat patients if they had metastatic non-small cell lung cancer (NSCLC) with the BRAF V600E mutation. This regimen was first approved by the FDA in 2014 to treat melanomas in patients with BRAF mutations, and in 2017, researchers reported that the combination of dabrafenib and trametinib could also help patients with later stage melanoma by lowering the risk for recurrence after surgery.2 The hope is that the genetic profile of tumors can match patients with the BRAF V600E mutation treatment regimens including this combination or another BRAF inhibitor. Broader applicability remains to be seen but seems promising. However, results of next-generation sequencing have shown that most patients do not have “actionable” mutations like the BRAF V600E. In other words, we do not yet have a drug that can target every specific mutation identified. Also cancers can have more than one “driver” mutation. However, combination therapies seem to hold promise in overcoming these issues. 
 
A major challenge in drug development has been the minimum 10-year time frame traditionally required to move a drug from Phase I through Phase II and III trials and eventually into FDA approval for use in the clinic. This time frame is no longer acceptable, and the FDA has developed the “Breakthrough Therapy Designation” (BTTD) and accelerated approval of protocols to speed up the process. The BTTD was first approved in 2012, and this strategy refers to a drug that can be used alone or in combination to treat a life threatening condition or disease. The drug must have preliminary clinical evidence indicating that its use could demonstrate substantial improvement over existing therapies on one or more clinically relevant endpoints. Drugs that are designated as breakthrough therapy are granted expedited review and development. Even though a therapeutic receives breakthrough designation, the drug must still be further assessed in additional trials to confirm its clinical benefit. If the additional trial confirms the initial result, then the FDA will grant regular approval. The FDA-accelerated approval program is one of four evidence-based strategies used to speed-up the evaluation of therapeutics to treat life-threatening diseases such as cancer. The accelerated approval is built around the assessment of the effect of a therapeutic drug at an earlier stage than usual by using a surrogate endpoint (i.e., a marker believed to predict clinical benefit, such as tumor shrinkage that is associated with longer overall survival or improved quality of life). 
 
In spite of these challenges, 2017 was a remarkable year in the field of precision oncology and therapeutic advances. Notably, the European Society for Medical Oncology (ESMO) published a Precision Medicine Glossary in the Annals of Oncology.3 This publication is extremely important for establishing standardized communication regarding precision medicine between oncologists, researchers, and patients.",2018,"[{'authorId': '2087568', 'name': 'A. Bode'}, {'authorId': '52169987', 'name': 'Z. Dong'}]","{'url': 'https://www.nature.com/articles/s41698-018-0055-0.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5988666, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","precision oncology has evolved into focusing on matching the most accurate and effective treatments based not only on the genetic profile of the patient and his/her cancer, but also on other unique characteristics that distinguish one patient from another. each patient has a unique genome, proteome, epigenome, microbiome, lifestyle, diet, and other characteristics that all interact to influence oncogenesis, disease progression, effective treatment options, drug tolerance, remission, and relapse. cancer comprises several hundred heterogeneous diseases, meaning that differences exist not only between cancer cells from various patients, but also between cancer cells within a single patient. cancer is constantly developing characteristics to evade death and this is why no single drug has been effective in “curing” cancer. precision oncology now involves using a combination of the unique characteristics of each patient to direct immunotherapy and targeted therapies.1 many advances in research over the past year reflect these ideologies of precision oncology. here we describe a few recent policy and research advances in the field of precision oncology. most recently, the focus has shifted from treating cancer based on type and histology to treating the specific cancer mutation. fda policies have paved the way for the adoption of “big data” genetic profiling techniques to guide patient therapies, such as those described by the nci-match (molecular analysis for therapy choice) or the nci-mpact (molecular profiling-based assignment of cancer therapy) initiatives. in june 2017, the fda granted regular approvals for using a combination of dabrafenib (i.e., a braf inhibitor) and trametinib (i.e., a mek inhibitor) to treat patients if they had metastatic non-small cell lung cancer (nsclc) with the braf v600e mutation. this regimen was first approved by the fda in 2014 to treat melanomas in patients with braf mutations, and in 2017, researchers reported that the combination of dabrafenib and trametinib could also help patients with later stage melanoma by lowering the risk for recurrence after surgery.2 the hope is that the genetic profile of tumors can match patients with the braf v600e mutation treatment regimens including this combination or another braf inhibitor. broader applicability remains to be seen but seems promising. however, results of next-generation sequencing have shown that most patients do not have “actionable” mutations like the braf v600e. in other words, we do not yet have a drug that can target every specific mutation identified. also cancers can have more than one “driver” mutation. however, combination therapies seem to hold promise in overcoming these issues. a major challenge in drug development has been the minimum 10-year time frame traditionally required to move a drug from phase i through phase ii and iii trials and eventually into fda approval for use in the clinic. this time frame is no longer acceptable, and the fda has developed the “breakthrough therapy designation” (bttd) and accelerated approval of protocols to speed up the process. the bttd was first approved in 2012, and this strategy refers to a drug that can be used alone or in combination to treat a life threatening condition or disease. the drug must have preliminary clinical evidence indicating that its use could demonstrate substantial improvement over existing therapies on one or more clinically relevant endpoints. drugs that are designated as breakthrough therapy are granted expedited review and development. even though a therapeutic receives breakthrough designation, the drug must still be further assessed in additional trials to confirm its clinical benefit. if the additional trial confirms the initial result, then the fda will grant regular approval. the fda-accelerated approval program is one of four evidence-based strategies used to speed-up the evaluation of therapeutics to treat life-threatening diseases such as cancer. the accelerated approval is built around the assessment of the effect of a therapeutic drug at an earlier stage than usual by using a surrogate endpoint (i.e., a marker believed to predict clinical benefit, such as tumor shrinkage that is associated with longer overall survival or improved quality of life). in spite of these challenges, 2017 was a remarkable year in the field of precision oncology and therapeutic advances. notably, the european society for medical oncology (esmo) published a precision medicine glossary in the annals of oncology.3 this publication is extremely important for establishing standardized communication regarding precision medicine between oncologists, researchers, and patients.",https://www.nature.com/articles/s41698-018-0055-0.pdf
157896602a8b1e213e59d905c681094819be5e34,Genetically engineered mouse models in oncology research and cancer medicine,"Genetically engineered mouse models (GEMMs) have contributed significantly to the field of cancer research. In contrast to cancer cell inoculation models, GEMMs develop de novo tumors in a natural immune‐proficient microenvironment. Tumors arising in advanced GEMMs closely mimic the histopathological and molecular features of their human counterparts, display genetic heterogeneity, and are able to spontaneously progress toward metastatic disease. As such, GEMMs are generally superior to cancer cell inoculation models, which show no or limited heterogeneity and are often metastatic from the start. Given that GEMMs capture both tumor cell‐intrinsic and cell‐extrinsic factors that drive de novo tumor initiation and progression toward metastatic disease, these models are indispensable for preclinical research. GEMMs have successfully been used to validate candidate cancer genes and drug targets, assess therapy efficacy, dissect the impact of the tumor microenvironment, and evaluate mechanisms of drug resistance. In vivo validation of candidate cancer genes and therapeutic targets is further accelerated by recent advances in genetic engineering that enable fast‐track generation and fine‐tuning of GEMMs to more closely resemble human patients. In addition, aligning preclinical tumor intervention studies in advanced GEMMs with clinical studies in patients is expected to accelerate the development of novel therapeutic strategies and their translation into the clinic.",2016,"[{'authorId': '51007075', 'name': 'K. Kersten'}, {'authorId': '6492947', 'name': 'K. D. de Visser'}, {'authorId': '4932709', 'name': 'M. V. van Miltenburg'}, {'authorId': '145787310', 'name': 'J. Jonkers'}]","{'url': 'https://doi.org/10.15252/emmm.201606857', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5286388, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","genetically engineered mouse models (gemms) have contributed significantly to the field of cancer research. in contrast to cancer cell inoculation models, gemms develop de novo tumors in a natural immune‐proficient microenvironment. tumors arising in advanced gemms closely mimic the histopathological and molecular features of their human counterparts, display genetic heterogeneity, and are able to spontaneously progress toward metastatic disease. as such, gemms are generally superior to cancer cell inoculation models, which show no or limited heterogeneity and are often metastatic from the start. given that gemms capture both tumor cell‐intrinsic and cell‐extrinsic factors that drive de novo tumor initiation and progression toward metastatic disease, these models are indispensable for preclinical research. gemms have successfully been used to validate candidate cancer genes and drug targets, assess therapy efficacy, dissect the impact of the tumor microenvironment, and evaluate mechanisms of drug resistance. in vivo validation of candidate cancer genes and therapeutic targets is further accelerated by recent advances in genetic engineering that enable fast‐track generation and fine‐tuning of gemms to more closely resemble human patients. in addition, aligning preclinical tumor intervention studies in advanced gemms with clinical studies in patients is expected to accelerate the development of novel therapeutic strategies and their translation into the clinic.",https://doi.org/10.15252/emmm.201606857
c368c5aa3ec3ebd2124882ac6dc8c364a51d315d,Proposed Criteria for Systematic Evaluation of Qualitative Oncology Research.,"Oncology has made significant advances in standardizing how clinical research is conducted and reported. The advancement of such research that improves oncology practice requires an expansion of not only our research questions but also the research methods we deploy to address them. In particular, there is increasing recognition of the value of qualitative research methods to develop more comprehensive understandings of phenomena of interest and to describe and explain underlying motivations and potential causes of specific outcomes. However, qualitative researchers in oncology have lacked guidance to produce and evaluate methodologically rigorous qualitative publications. In this review, we highlight characteristics of high-quality, methodologically rigorous reports of qualitative research, provide criteria for readers and reviewers to appraise such publications critically, and proffer guidance for preparing publications for submission to Journal of Oncology Practice. Namely, the quality of qualitative research in oncology practice is best assessed according to key domains that include fitness of purpose, theoretical framework, methodological rigor, ethical concerns, analytic comprehensives, and the dissemination/application of findings. In particular, determinations of rigor in qualitative research in oncology practice should consider definitions of the appropriateness of qualitative methods for the research objectives against the setting of current literature, use of an appropriate theoretical framework, inclusion of a rigorous and innovative measurement plan, application of appropriate analytic techniques, and clear explanation and dissemination of the research findings.",2019,"[{'authorId': '7957392', 'name': 'S. Hannum'}, {'authorId': '2804067', 'name': 'S. Dy'}, {'authorId': '2157443997', 'name': 'K. Smith'}, {'authorId': '1967668', 'name': 'A. Kamal'}]","{'url': 'https://ascopubs.org/doi/pdfdirect/10.1200/JOP.19.00125', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1200/JOP.19.00125?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1200/JOP.19.00125, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","oncology has made significant advances in standardizing how clinical research is conducted and reported. the advancement of such research that improves oncology practice requires an expansion of not only our research questions but also the research methods we deploy to address them. in particular, there is increasing recognition of the value of qualitative research methods to develop more comprehensive understandings of phenomena of interest and to describe and explain underlying motivations and potential causes of specific outcomes. however, qualitative researchers in oncology have lacked guidance to produce and evaluate methodologically rigorous qualitative publications. in this review, we highlight characteristics of high-quality, methodologically rigorous reports of qualitative research, provide criteria for readers and reviewers to appraise such publications critically, and proffer guidance for preparing publications for submission to journal of oncology practice. namely, the quality of qualitative research in oncology practice is best assessed according to key domains that include fitness of purpose, theoretical framework, methodological rigor, ethical concerns, analytic comprehensives, and the dissemination/application of findings. in particular, determinations of rigor in qualitative research in oncology practice should consider definitions of the appropriateness of qualitative methods for the research objectives against the setting of current literature, use of an appropriate theoretical framework, inclusion of a rigorous and innovative measurement plan, application of appropriate analytic techniques, and clear explanation and dissemination of the research findings.",https://ascopubs.org/doi/pdfdirect/10.1200/JOP.19.00125
49ba6a0c95b2bdbfddaab9f687b8bd1ebc5b1a00,Three-dimensional bio-printing: A new frontier in oncology research,"Current research in oncology deploys methods that rely principally on two-dimensional (2D) mono-cell cultures and animal models. Although these methodologies have led to significant advancement in the development of novel experimental therapeutic agents with promising anticancer activity in the laboratory, clinicians still struggle to manage cancer in the clinical setting. The disappointing translational success is attributable mainly to poor representation and recreation of the cancer microenvironment present in human neoplasia. Three-dimensional (3D) bio-printed models could help to simulate this micro-environment, with recent bio-printing of live human cells demonstrating that effective in vitro replication is achievable. This literature review outlines up-to-date advancements and developments in the use of 3D bio-printed models currently being used in oncology research. These innovative advancements in 3D bio-printing open up a new frontier for oncology research and could herald an era of progressive clinical cancer therapeutics.",2017,"[{'authorId': '6356906', 'name': 'N. Charbe'}, {'authorId': '5989963', 'name': 'P. McCarron'}, {'authorId': '5569296', 'name': 'M. Tambuwala'}]","{'url': 'https://doi.org/10.5306/wjco.v8.i1.21', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5309712, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","current research in oncology deploys methods that rely principally on two-dimensional (2d) mono-cell cultures and animal models. although these methodologies have led to significant advancement in the development of novel experimental therapeutic agents with promising anticancer activity in the laboratory, clinicians still struggle to manage cancer in the clinical setting. the disappointing translational success is attributable mainly to poor representation and recreation of the cancer microenvironment present in human neoplasia. three-dimensional (3d) bio-printed models could help to simulate this micro-environment, with recent bio-printing of live human cells demonstrating that effective in vitro replication is achievable. this literature review outlines up-to-date advancements and developments in the use of 3d bio-printed models currently being used in oncology research. these innovative advancements in 3d bio-printing open up a new frontier for oncology research and could herald an era of progressive clinical cancer therapeutics.",https://doi.org/10.5306/wjco.v8.i1.21
1f83005b69b9a8869be14cfa17da88f5a49ad5e4,Recruitment problems in psychosocial oncology research,"• A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website. • The final author version and the galley proof are versions of the publication after peer review. • The final published version features the final layout of the paper including the volume, issue and page numbers. Link to publication",2018,"[{'authorId': '5108098', 'name': 'J. van Lankveld'}, {'authorId': '4250558', 'name': 'J. Fleer'}, {'authorId': '6191280', 'name': 'M. Schroevers'}, {'authorId': '6841423', 'name': 'R. Sanderman'}, {'authorId': '4007478', 'name': 'B. D. Den Oudsten'}, {'authorId': '145696693', 'name': 'J. Dekker'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/pon.4792', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6175209, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","• a submitted manuscript is the version of the article upon submission and before peer-review. there can be important differences between the submitted version and the official published version of record. people interested in the research are advised to contact the author for the final version of the publication, or visit the doi to the publisher's website. • the final author version and the galley proof are versions of the publication after peer review. • the final published version features the final layout of the paper including the volume, issue and page numbers. link to publication",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/pon.4792
96159eea50588975893787d2f13e21e38ed4615a,"Artificial intelligence in neuro-oncology: advances and challenges in brain tumor diagnosis, prognosis, and precision treatment","This review delves into the most recent advancements in applying artificial intelligence (AI) within neuro-oncology, specifically emphasizing work on gliomas, a class of brain tumors that represent a significant global health issue. AI has brought transformative innovations to brain tumor management, utilizing imaging, histopathological, and genomic tools for efficient detection, categorization, outcome prediction, and treatment planning. Assessing its influence across all facets of malignant brain tumor management- diagnosis, prognosis, and therapy- AI models outperform human evaluations in terms of accuracy and specificity. Their ability to discern molecular aspects from imaging may reduce reliance on invasive diagnostics and may accelerate the time to molecular diagnoses. The review covers AI techniques, from classical machine learning to deep learning, highlighting current applications and challenges. Promising directions for future research include multimodal data integration, generative AI, large medical language models, precise tumor delineation and characterization, and addressing racial and gender disparities. Adaptive personalized treatment strategies are also emphasized for optimizing clinical outcomes. Ethical, legal, and social implications are discussed, advocating for transparency and fairness in AI integration for neuro-oncology and providing a holistic understanding of its transformative impact on patient care.",2024,"[{'authorId': '1753640', 'name': 'S. Khalighi'}, {'authorId': '2294147866', 'name': 'Kartik Reddy'}, {'authorId': '2238147556', 'name': 'Abhishek Midya'}, {'authorId': '2293045889', 'name': 'K. Pandav'}, {'authorId': '1705442', 'name': 'A. Madabhushi'}, {'authorId': '6865020', 'name': 'M. Abedalthagafi'}]","{'url': 'https://www.nature.com/articles/s41698-024-00575-0.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10980741, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this review delves into the most recent advancements in applying artificial intelligence (ai) within neuro-oncology, specifically emphasizing work on gliomas, a class of brain tumors that represent a significant global health issue. ai has brought transformative innovations to brain tumor management, utilizing imaging, histopathological, and genomic tools for efficient detection, categorization, outcome prediction, and treatment planning. assessing its influence across all facets of malignant brain tumor management- diagnosis, prognosis, and therapy- ai models outperform human evaluations in terms of accuracy and specificity. their ability to discern molecular aspects from imaging may reduce reliance on invasive diagnostics and may accelerate the time to molecular diagnoses. the review covers ai techniques, from classical machine learning to deep learning, highlighting current applications and challenges. promising directions for future research include multimodal data integration, generative ai, large medical language models, precise tumor delineation and characterization, and addressing racial and gender disparities. adaptive personalized treatment strategies are also emphasized for optimizing clinical outcomes. ethical, legal, and social implications are discussed, advocating for transparency and fairness in ai integration for neuro-oncology and providing a holistic understanding of its transformative impact on patient care.",https://www.nature.com/articles/s41698-024-00575-0.pdf
e7613319070c7f6bcf60194c5101549464949ad4,Untapped Potential of Observational Research to Inform Clinical Decision Making: American Society of Clinical Oncology Research Statement.,"ASCO believes that high-quality observational studies can advance evidence-based practice for cancer care and are complementary to randomized controlled trials (RCTs). Observational studies can generate hypotheses by evaluating novel exposures or biomarkers and by revealing patterns of care and relationships that might not otherwise be discovered. Researchers can then test these hypotheses in RCTs. Observational studies can also answer or inform questions that either have not been or cannot be answered by RCTs. In addition, observational studies can be used for postmarketing surveillance of new cancer treatments, particularly in vulnerable populations. The incorporation of observational research as part of clinical decision making is consistent with the position of many leading institutions. ASCO identified five overarching recommendations to enhance the role of observational research in clinical decision making: (1) improve the quality of electronic health data available for research, (2) improve interoperability and the exchange of electronic health information, (3) ensure the use of rigorous observational research methodologies, (4) promote transparent reporting of observational research studies, and (5) protect patient privacy.",2017,"[{'authorId': '2373236', 'name': 'K. Visvanathan'}, {'authorId': '145000982', 'name': 'Laura A. Levit'}, {'authorId': '52606215', 'name': 'D. Raghavan'}, {'authorId': '5691447', 'name': 'C. Hudis'}, {'authorId': '40467184', 'name': 'S. Wong'}, {'authorId': '2555114', 'name': 'A. Dueck'}, {'authorId': '4190951', 'name': 'G. Lyman'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1200/JCO.2017.72.6414?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1200/JCO.2017.72.6414, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","asco believes that high-quality observational studies can advance evidence-based practice for cancer care and are complementary to randomized controlled trials (rcts). observational studies can generate hypotheses by evaluating novel exposures or biomarkers and by revealing patterns of care and relationships that might not otherwise be discovered. researchers can then test these hypotheses in rcts. observational studies can also answer or inform questions that either have not been or cannot be answered by rcts. in addition, observational studies can be used for postmarketing surveillance of new cancer treatments, particularly in vulnerable populations. the incorporation of observational research as part of clinical decision making is consistent with the position of many leading institutions. asco identified five overarching recommendations to enhance the role of observational research in clinical decision making: (1) improve the quality of electronic health data available for research, (2) improve interoperability and the exchange of electronic health information, (3) ensure the use of rigorous observational research methodologies, (4) promote transparent reporting of observational research studies, and (5) protect patient privacy.",
58d8ba80975609f0e10b06d7160b562776870873,Oncology Research Program.,"doi: 10.6004/jnccn.2018.0010 Highlights of the NCCN Oncology Research Program The NCCN Oncology Research Program (ORP) strives to improve the quality of life for patients and reduce cancer-related deaths by advancing cancer therapies through research. Since the program’s establishment in 1999, the NCCN ORP has brought millions of dollars in research grants to investigators at NCCN Member Institutions. Research grants are provided to NCCN through collaborations with pharmaceutical and biotechnology companies; these grants are in turn used to support scientifically meritorious cancer research efforts. NCCN ORP studies typically explore new avenues of clinical investigation and seek answers to important cancer-related questions. All studies are approved and funded through a scientific peer-review process and are overseen by the ORP. An NCCN study funded through the grant mechanism is highlighted below.",2018,"[{'authorId': '2265277787', 'name': 'James Harding'}]","{'url': 'https://doi.org/10.6004/jnccn.2018.0064', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.6004/jnccn.2018.0064?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.6004/jnccn.2018.0064, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","doi: 10.6004/jnccn.2018.0010 highlights of the nccn oncology research program the nccn oncology research program (orp) strives to improve the quality of life for patients and reduce cancer-related deaths by advancing cancer therapies through research. since the program’s establishment in 1999, the nccn orp has brought millions of dollars in research grants to investigators at nccn member institutions. research grants are provided to nccn through collaborations with pharmaceutical and biotechnology companies; these grants are in turn used to support scientifically meritorious cancer research efforts. nccn orp studies typically explore new avenues of clinical investigation and seek answers to important cancer-related questions. all studies are approved and funded through a scientific peer-review process and are overseen by the orp. an nccn study funded through the grant mechanism is highlighted below.",https://doi.org/10.6004/jnccn.2018.0064
c9f8f13782c43e75440358d05763288233f6d925,IOBR: Multi-Omics Immuno-Oncology Biological Research to Decode Tumor Microenvironment and Signatures,"Motivation Recent advance in next generation sequencing has triggered the rapid accumulation of publicly available multi-omics datasets. The application of integrated omics to exploring robust signatures for clinical translation is increasingly highlighted, attributed to the clinical success of immune checkpoint blockade in diverse malignancies. However, effective tools to comprehensively interpret multi-omics data is still warranted to provide increased granularity into intrinsic mechanism of oncogenesis and immunotherapeutic sensitivity. Results We developed a computational tool for effective Immuno-Oncology Biological Research (IOBR), providing comprehensive investigation of estimation of reported or user-built signatures, TME deconvolution and signature construction base on multi-omics data. Notably, IOBR offers batch analyses of these signatures and their correlations with clinical phenotypes, lncRNA profiling, genomic characteristics and signatures generated from single-cell RNA sequencing data in different cancer settings. Additionally, IOBR also integrates multiple existing microenvironmental deconvolution methodologies and signature construction tools for convenient comparison and selection. Collectively, IOBR is a user-friendly tool, to leverage multi-omics data to facilitate immuno-oncology exploration and unveiling of tumor-immune interactions and accelerating precision immunotherapy.",2020,"[{'authorId': '32339851', 'name': 'D. Zeng'}, {'authorId': '1406087982', 'name': 'Zilan Ye'}, {'authorId': '7329377', 'name': 'Guangchuang Yu'}, {'authorId': '2110437938', 'name': 'Jiani Wu'}, {'authorId': '1491199562', 'name': 'Yi Xiong'}, {'authorId': '1490948350', 'name': 'R. Zhou'}, {'authorId': '2057145815', 'name': 'Wenjun Qiu'}, {'authorId': '46363241', 'name': 'N. Huang'}, {'authorId': '2110966597', 'name': 'Li Sun'}, {'authorId': '4339763', 'name': 'J. Bin'}, {'authorId': '144054641', 'name': 'Y. Liao'}, {'authorId': '143931959', 'name': 'Min Shi'}, {'authorId': '48739986', 'name': 'W. Liao'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fimmu.2021.687975/pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8283787, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","motivation recent advance in next generation sequencing has triggered the rapid accumulation of publicly available multi-omics datasets. the application of integrated omics to exploring robust signatures for clinical translation is increasingly highlighted, attributed to the clinical success of immune checkpoint blockade in diverse malignancies. however, effective tools to comprehensively interpret multi-omics data is still warranted to provide increased granularity into intrinsic mechanism of oncogenesis and immunotherapeutic sensitivity. results we developed a computational tool for effective immuno-oncology biological research (iobr), providing comprehensive investigation of estimation of reported or user-built signatures, tme deconvolution and signature construction base on multi-omics data. notably, iobr offers batch analyses of these signatures and their correlations with clinical phenotypes, lncrna profiling, genomic characteristics and signatures generated from single-cell rna sequencing data in different cancer settings. additionally, iobr also integrates multiple existing microenvironmental deconvolution methodologies and signature construction tools for convenient comparison and selection. collectively, iobr is a user-friendly tool, to leverage multi-omics data to facilitate immuno-oncology exploration and unveiling of tumor-immune interactions and accelerating precision immunotherapy.",https://www.frontiersin.org/articles/10.3389/fimmu.2021.687975/pdf
dec91a82902055bf2789eeb723d75feeae784373,The use of the Godin-Shephard Leisure-Time Physical Activity Questionnaire in oncology research: a systematic review,"BackgroundThe Godin-Shephard Leisure-Time Physical Activity Questionnaire (GSLTPAQ) is one of the most often used questionnaires in oncology research, yet modifications to the scale are done with little evidence of psychometric testing. This study aimed to (i) document the frequency of use of the questionnaire for ranking (i.e., level of activity) and classification (i.e., active versus insufficiently active) purposes, (ii) summarize how the GSLTPAQ is used in terms of item content and scoring, and (iii) evaluate the extent to which validity evidence supports the use of the scale among cancer survivors.MethodsA systematic review was conducted with evidence drawn from English-written articles published between January 1st 1985 (year the GSLTPAQ was published) and December 31, 2014. A search of six databases, a scan of reference list of included articles, and a cited reference search identified articles that reported using the GSLTPAQ among cancer survivors.ResultsA total of 212 articles were retrieved. The GSLTPAQ was used for classifying cancer survivors into active and insufficiently active categories in 51 % of the articles. Moreover, a modified version of the questionnaire was used in 81 % of the research studies. Three studies reported validity evidence based on the relationship between the scores on the GSLTPAQ (i.e., leisure score index, LSI) and accelerometer or pedometer-derived activity data. Validity evidence supporting the use of the GSLTPAQ for assessing changes in LSI was computed from six randomized trials.ConclusionsThe use of the GSLTPAQ for classification purpose in oncology research is common. Standardization in the use and interpretation of the GSLTPAQ in oncology research is warranted. Although limited, there is support for using the original form of the GSLTPAQ and interpreting the LSI for ranking cancer survivors from the lowest to highest levels of leisure-time physical activity.",2015,"[{'authorId': '5818964', 'name': 'Steve Amireault'}, {'authorId': '1865615', 'name': 'G. Godin'}, {'authorId': '40589429', 'name': 'J. Lacombe'}, {'authorId': '5070415', 'name': 'C. Sabiston'}]","{'url': 'https://bmcmedresmethodol.biomedcentral.com/counter/pdf/10.1186/s12874-015-0045-7', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4542103, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","backgroundthe godin-shephard leisure-time physical activity questionnaire (gsltpaq) is one of the most often used questionnaires in oncology research, yet modifications to the scale are done with little evidence of psychometric testing. this study aimed to (i) document the frequency of use of the questionnaire for ranking (i.e., level of activity) and classification (i.e., active versus insufficiently active) purposes, (ii) summarize how the gsltpaq is used in terms of item content and scoring, and (iii) evaluate the extent to which validity evidence supports the use of the scale among cancer survivors.methodsa systematic review was conducted with evidence drawn from english-written articles published between january 1st 1985 (year the gsltpaq was published) and december 31, 2014. a search of six databases, a scan of reference list of included articles, and a cited reference search identified articles that reported using the gsltpaq among cancer survivors.resultsa total of 212 articles were retrieved. the gsltpaq was used for classifying cancer survivors into active and insufficiently active categories in 51 % of the articles. moreover, a modified version of the questionnaire was used in 81 % of the research studies. three studies reported validity evidence based on the relationship between the scores on the gsltpaq (i.e., leisure score index, lsi) and accelerometer or pedometer-derived activity data. validity evidence supporting the use of the gsltpaq for assessing changes in lsi was computed from six randomized trials.conclusionsthe use of the gsltpaq for classification purpose in oncology research is common. standardization in the use and interpretation of the gsltpaq in oncology research is warranted. although limited, there is support for using the original form of the gsltpaq and interpreting the lsi for ranking cancer survivors from the lowest to highest levels of leisure-time physical activity.",https://bmcmedresmethodol.biomedcentral.com/counter/pdf/10.1186/s12874-015-0045-7
ced76b3c08956e8da5898d814de8bf724df2c324,Metabolomics in cancer research and emerging applications in clinical oncology,"Cancer has myriad effects on metabolism that include both rewiring of intracellular metabolism to enable cancer cells to proliferate inappropriately and adapt to the tumor microenvironment, and changes in normal tissue metabolism. With the recognition that fluorodeoxyglucose‐positron emission tomography imaging is an important tool for the management of many cancers, other metabolites in biological samples have been in the spotlight for cancer diagnosis, monitoring, and therapy. Metabolomics is the global analysis of small molecule metabolites that like other ‐omics technologies can provide critical information about the cancer state that are otherwise not apparent. Here, the authors review how cancer and cancer therapies interact with metabolism at the cellular and systemic levels. An overview of metabolomics is provided with a focus on currently available technologies and how they have been applied in the clinical and translational research setting. The authors also discuss how metabolomics could be further leveraged in the future to improve the management of patients with cancer.",2021,"[{'authorId': '49718538', 'name': 'D. R. Schmidt'}, {'authorId': '40378816', 'name': 'R. Patel'}, {'authorId': '3256796', 'name': 'D. Kirsch'}, {'authorId': '15465440', 'name': 'C. Lewis'}, {'authorId': '3804233', 'name': 'M. V. Vander Heiden'}, {'authorId': '2268976', 'name': 'J. Locasale'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.3322/caac.21670', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3322/caac.21670?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3322/caac.21670, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cancer has myriad effects on metabolism that include both rewiring of intracellular metabolism to enable cancer cells to proliferate inappropriately and adapt to the tumor microenvironment, and changes in normal tissue metabolism. with the recognition that fluorodeoxyglucose‐positron emission tomography imaging is an important tool for the management of many cancers, other metabolites in biological samples have been in the spotlight for cancer diagnosis, monitoring, and therapy. metabolomics is the global analysis of small molecule metabolites that like other ‐omics technologies can provide critical information about the cancer state that are otherwise not apparent. here, the authors review how cancer and cancer therapies interact with metabolism at the cellular and systemic levels. an overview of metabolomics is provided with a focus on currently available technologies and how they have been applied in the clinical and translational research setting. the authors also discuss how metabolomics could be further leveraged in the future to improve the management of patients with cancer.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.3322/caac.21670
a71a12293875e3829716ce72214171747933375c,A framework for prescription in exercise-oncology research†,"The field of exercise‐oncology has increased dramatically over the past two decades, with close to 100 published studies investigating the efficacy of structured exercise training interventions in patients with cancer. Of interest, despite considerable differences in study population and primary study end point, the vast majority of studies have tested the efficacy of an exercise prescription that adhered to traditional guidelines consisting of either supervised or home‐based endurance (aerobic) training or endurance training combined with resistance training, prescribed at a moderate intensity (50–75% of a predetermined physiological parameter, typically age‐predicted heart rate maximum or reserve), for two to three sessions per week, for 10 to 60 min per exercise session, for 12 to 15 weeks. The use of generic exercise prescriptions may, however, be masking the full therapeutic potential of exercise treatment in the oncology setting. Against this background, this opinion paper provides an overview of the fundamental tenets of human exercise physiology known as the principles of training, with specific application of these principles in the design and conduct of clinical trials in exercise‐oncology research. We contend that the application of these guidelines will ensure continued progress in the field while optimizing the safety and efficacy of exercise treatment following a cancer diagnosis.",2015,"[{'authorId': '6456557', 'name': 'J. Sasso'}, {'authorId': '6455798', 'name': 'N. Eves'}, {'authorId': '49180352', 'name': 'J. Christensen'}, {'authorId': '6617453', 'name': 'G. Koelwyn'}, {'authorId': '144133143', 'name': 'Jessica M. Scott'}, {'authorId': '48681288', 'name': 'L. Jones'}]","{'url': 'https://europepmc.org/articles/pmc4458077?pdf=render', 'status': 'GREEN', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4458077, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the field of exercise‐oncology has increased dramatically over the past two decades, with close to 100 published studies investigating the efficacy of structured exercise training interventions in patients with cancer. of interest, despite considerable differences in study population and primary study end point, the vast majority of studies have tested the efficacy of an exercise prescription that adhered to traditional guidelines consisting of either supervised or home‐based endurance (aerobic) training or endurance training combined with resistance training, prescribed at a moderate intensity (50–75% of a predetermined physiological parameter, typically age‐predicted heart rate maximum or reserve), for two to three sessions per week, for 10 to 60 min per exercise session, for 12 to 15 weeks. the use of generic exercise prescriptions may, however, be masking the full therapeutic potential of exercise treatment in the oncology setting. against this background, this opinion paper provides an overview of the fundamental tenets of human exercise physiology known as the principles of training, with specific application of these principles in the design and conduct of clinical trials in exercise‐oncology research. we contend that the application of these guidelines will ensure continued progress in the field while optimizing the safety and efficacy of exercise treatment following a cancer diagnosis.",https://europepmc.org/articles/pmc4458077?pdf=render
9cde7e9d88183d6463c30213c1d2b2f8a4b773d4,Life after diagnosis and treatment of cancer in adulthood: contributions from psychosocial oncology research.,"The number of individuals living with a history of cancer is estimated at 13.7 million in the United States and is expected to rise with the aging of the population. With expanding attention to the psychosocial and physical consequences of surviving illness, psychological science and evidence-based practice are making important contributions to addressing the pressing needs of cancer survivors. Research is demonstrating that adults diagnosed with cancer evidence generally positive psychosocial adjustment over time; however, a subset is at risk for compromised psychological and physical health stemming from long-term or late effects of cancer and its treatment. In this article, we characterize survivorship after medical treatment completion during the periods of reentry, early survivorship, and long-term survivorship. We describe the major psychosocial and physical sequelae facing adults during those periods, highlight promising posttreatment psychosocial and behavioral interventions, and offer recommendations for future research and evidence-based practice.",2015,"[{'authorId': '3185826', 'name': 'A. Stanton'}, {'authorId': '1810154', 'name': 'J. Rowland'}, {'authorId': '3223756', 'name': 'P. Ganz'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1037/a0037875?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1037/a0037875, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the number of individuals living with a history of cancer is estimated at 13.7 million in the united states and is expected to rise with the aging of the population. with expanding attention to the psychosocial and physical consequences of surviving illness, psychological science and evidence-based practice are making important contributions to addressing the pressing needs of cancer survivors. research is demonstrating that adults diagnosed with cancer evidence generally positive psychosocial adjustment over time; however, a subset is at risk for compromised psychological and physical health stemming from long-term or late effects of cancer and its treatment. in this article, we characterize survivorship after medical treatment completion during the periods of reentry, early survivorship, and long-term survivorship. we describe the major psychosocial and physical sequelae facing adults during those periods, highlight promising posttreatment psychosocial and behavioral interventions, and offer recommendations for future research and evidence-based practice.",
d5f536198e7b8a34f5e6ad79cea769a4e7bad08c,Increasing Racial and Ethnic Diversity in Cancer Clinical Trials: An American Society of Clinical Oncology and Association of Community Cancer Centers Joint Research Statement.,"A concerted commitment across research stakeholders is necessary to increase equity, diversity, and inclusion (EDI) and address barriers to cancer clinical trial recruitment and participation. Racial and ethnic diversity among trial participants is key to understanding intrinsic and extrinsic factors that may affect patient response to cancer treatments. This ASCO and Association of Community Cancer Centers (ACCC) Research Statement presents specific recommendations and strategies for the research community to improve EDI in cancer clinical trials. There are six overarching recommendations: (1) clinical trials are an integral component of high-quality cancer care, and every person with cancer should have the opportunity to participate; (2) trial sponsors and investigators should design and implement trials with a focus on reducing barriers and enhancing EDI, and work with sites to conduct trials in ways that increase participation of under-represented populations; (3) trial sponsors, researchers, and sites should form long-standing partnerships with patients, patient advocacy groups, and community leaders and groups; (4) anyone designing or conducting trials should complete recurring education, training, and evaluation to demonstrate and maintain cross-cultural competencies, mitigation of bias, effective communication, and a commitment to achieving EDI; (5) research stakeholders should invest in programs and policies that increase EDI in trials and in the research workforce; and (6) research stakeholders should collect and publish aggregate data on racial and ethnic diversity of trial participants when reporting results of trials, programs, and interventions to increase EDI. The recommendations are intended to serve as a guide for the research community to improve participation rates among people from racial and ethnic minority populations historically under-represented in cancer clinical trials. ASCO and ACCC will work at all levels to advance the recommendations in this publication.",2022,"[{'authorId': '87726304', 'name': 'R. Oyer'}, {'authorId': '49158512', 'name': 'P. Hurley'}, {'authorId': '50634399', 'name': 'L. Boehmer'}, {'authorId': '10191468', 'name': 'S. Bruinooge'}, {'authorId': '78534218', 'name': 'Kathryn Levit'}, {'authorId': '14641147', 'name': 'Nadine J. Barrett'}, {'authorId': '2075282317', 'name': 'A. Benson'}, {'authorId': '2165787713', 'name': 'Lea Ann Bernick'}, {'authorId': '67140990', 'name': 'Leslie Byatt'}, {'authorId': '49029121', 'name': 'M. Charlot'}, {'authorId': '33668573', 'name': 'J. Crews'}, {'authorId': '2165788136', 'name': 'Kyle DeLeon'}, {'authorId': '2238193678', 'name': 'Lola Fashoyin-Aje'}, {'authorId': '1387456725', 'name': 'E. Garrett-Mayer'}, {'authorId': '6538145', 'name': 'J. Gralow'}, {'authorId': '27411533', 'name': 'Sybil R. Green'}, {'authorId': '144673564', 'name': 'Carmen E. Guerra'}, {'authorId': '66938565', 'name': 'Leila Hamroun'}, {'authorId': '40461121', 'name': 'Claudia Hardy'}, {'authorId': '6289897', 'name': 'Bridgette H. Hempstead'}, {'authorId': '13383393', 'name': 'Sanford E. Jeames'}, {'authorId': '16583666', 'name': 'M. Mann'}, {'authorId': '11904703', 'name': 'K. Matin'}, {'authorId': '1416264228', 'name': 'W. McCaskill-Stevens'}, {'authorId': '39778822', 'name': 'Janette K. Merrill'}, {'authorId': '2253371186', 'name': 'Grzegorz S. Nowakowski'}, {'authorId': '145132605', 'name': 'Manali I. Patel'}, {'authorId': '32934151', 'name': 'A. Pressman'}, {'authorId': '144128971', 'name': 'A. Ramirez'}, {'authorId': '2053794475', 'name': 'J. Segura'}, {'authorId': '1431273196', 'name': 'Barbara Segarra-Vasquez'}, {'authorId': '2165786183', 'name': 'Jen Hanley Williams'}, {'authorId': '2111788154', 'name': 'James E Williams'}, {'authorId': '10041535', 'name': 'K. Winkfield'}, {'authorId': '4305933', 'name': 'E. Yang'}, {'authorId': '13325659', 'name': 'V. Zwicker'}, {'authorId': '38555696', 'name': 'Lori J Pierce'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1200/JCO.22.00754?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1200/JCO.22.00754, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a concerted commitment across research stakeholders is necessary to increase equity, diversity, and inclusion (edi) and address barriers to cancer clinical trial recruitment and participation. racial and ethnic diversity among trial participants is key to understanding intrinsic and extrinsic factors that may affect patient response to cancer treatments. this asco and association of community cancer centers (accc) research statement presents specific recommendations and strategies for the research community to improve edi in cancer clinical trials. there are six overarching recommendations: (1) clinical trials are an integral component of high-quality cancer care, and every person with cancer should have the opportunity to participate; (2) trial sponsors and investigators should design and implement trials with a focus on reducing barriers and enhancing edi, and work with sites to conduct trials in ways that increase participation of under-represented populations; (3) trial sponsors, researchers, and sites should form long-standing partnerships with patients, patient advocacy groups, and community leaders and groups; (4) anyone designing or conducting trials should complete recurring education, training, and evaluation to demonstrate and maintain cross-cultural competencies, mitigation of bias, effective communication, and a commitment to achieving edi; (5) research stakeholders should invest in programs and policies that increase edi in trials and in the research workforce; and (6) research stakeholders should collect and publish aggregate data on racial and ethnic diversity of trial participants when reporting results of trials, programs, and interventions to increase edi. the recommendations are intended to serve as a guide for the research community to improve participation rates among people from racial and ethnic minority populations historically under-represented in cancer clinical trials. asco and accc will work at all levels to advance the recommendations in this publication.",
cfef4ce41f94175b86b7efbcf737081a5291be04,Global oncology research,"The material presented in this book is at the cutting-edge of global oncology and provides highly illuminating examples, addresses frequently asked questions, and provides information and a reference for future work in global oncology care, research, education, and outreach.",2017,"[{'authorId': '2056638930', 'name': 'Paul Nguyen'}, {'authorId': '46803064', 'name': 'W. Ngwa'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1088/978-0-7503-1359-9CH3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/978-0-7503-1359-9CH3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",global oncology research,
5c1b5a134aca6ee329ecc2d6dae103b00b8dddf4,The integration of psychology in pediatric oncology research and practice: collaboration to improve care and outcomes for children and families.,"Childhood cancers are life-threatening diseases that are universally distressing and potentially traumatic for children and their families at diagnosis, during treatment, and beyond. Dramatic improvements in survival have occurred as a result of increasingly aggressive multimodal therapies delivered in the context of clinical research trials. Nonetheless, cancers remain a leading cause of death in children, and their treatments have short- and long-term impacts on health and well-being. For over 35 years, pediatric psychologists have partnered with pediatric oncology teams to make many contributions to our understanding of the impact of cancer and its treatment on children and families and have played prominent roles in providing an understanding of treatment-related late effects and in improving quality of life. After discussing the incidence of cancer in children, its causes, and the treatment approaches to it in pediatric oncology, we present seven key contributions of psychologists to collaborative and integrated care in pediatric cancer: managing procedural pain, nausea, and other symptoms; understanding and reducing neuropsychological effects; treating children in the context of their families and other systems (social ecology); applying a developmental perspective; identifying competence and vulnerability; integrating psychological knowledge into decision making and other clinical care issues; and facilitating the transition to palliative care and bereavement. We conclude with a discussion of the current status of integrating knowledge from psychological research into practice in pediatric cancer.",2015,"[{'authorId': '4878654', 'name': 'A. Kazak'}, {'authorId': '152193976', 'name': 'R. Noll'}]","{'url': 'http://apa.org/pubs/journals/releases/amp-a0035695.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1037/a0035695?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1037/a0035695, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","childhood cancers are life-threatening diseases that are universally distressing and potentially traumatic for children and their families at diagnosis, during treatment, and beyond. dramatic improvements in survival have occurred as a result of increasingly aggressive multimodal therapies delivered in the context of clinical research trials. nonetheless, cancers remain a leading cause of death in children, and their treatments have short- and long-term impacts on health and well-being. for over 35 years, pediatric psychologists have partnered with pediatric oncology teams to make many contributions to our understanding of the impact of cancer and its treatment on children and families and have played prominent roles in providing an understanding of treatment-related late effects and in improving quality of life. after discussing the incidence of cancer in children, its causes, and the treatment approaches to it in pediatric oncology, we present seven key contributions of psychologists to collaborative and integrated care in pediatric cancer: managing procedural pain, nausea, and other symptoms; understanding and reducing neuropsychological effects; treating children in the context of their families and other systems (social ecology); applying a developmental perspective; identifying competence and vulnerability; integrating psychological knowledge into decision making and other clinical care issues; and facilitating the transition to palliative care and bereavement. we conclude with a discussion of the current status of integrating knowledge from psychological research into practice in pediatric cancer.",http://apa.org/pubs/journals/releases/amp-a0035695.pdf
7c2281bd688da87e22494c569bdbf11a483a6011,NCCN Oncology Research Program's Investigator Steering Committee and NCCN Best Practices Committee Molecular Profiling Surveys.,"BACKGROUND
With advances such as next-generation sequencing (NGS) increasing understanding of the basis of cancer and its response to treatment, NCCN believes it is important to understand how molecular profiling/diagnostic testing is being performed and used at NCCN Member Institutions and their community affiliates.


METHODS
The NCCN Oncology Research Program's Investigator Steering Committee and the NCCN Best Practices Committee gathered baseline information on the use of cancer-related molecular testing at NCCN Member Institutions and community members of the NCCN Affiliate Research Consortium through 2 separate surveys distributed in December 2013 and September 2014, respectively.


RESULTS
A total of 24 NCCN Member Institutions and 8 affiliate sites provided quantitative and qualitative data. In the context of these surveys, ""molecular profiling/diagnostics"" was defined as a panel of at least 10 genes examined as a diagnostic DNA test in a Clinical Laboratory Improvement Amendments (CLIA)-certified laboratory.


CONCLUSIONS
Results indicated that molecular profiling/diagnostics are used at 100% of survey respondents' institutions to make patient care decisions. However, challenges relating to reimbursement, lack of data regarding actionable targets and targeted therapies, and access to drugs on or off clinical trials were cited as barriers to integration of molecular profiling into patient care. Frameworks for using molecular diagnostic results based on levels of evidence, alongside continued research into the predictive value of biomarkers and targeted therapies, are recommended to advance understanding of the role of genomic biomarkers. Greater evidence and consensus regarding the clinical and cost-effectiveness of molecular profiling may lead to broader insurance coverage and increased integration into patient care.",2015,"[{'authorId': '49319257', 'name': 'R. Kurzrock'}, {'authorId': '3083917', 'name': 'A. Colevas'}, {'authorId': '4049451', 'name': 'A. Olszanski'}, {'authorId': '5948976', 'name': 'W. Akerley'}, {'authorId': '2057460', 'name': 'C. Arteaga'}, {'authorId': '145670152', 'name': 'W. Carson'}, {'authorId': '2237132706', 'name': 'Jeffrey W. Clark'}, {'authorId': '145322783', 'name': 'J. Dipersio'}, {'authorId': '5259683', 'name': 'D. Ettinger'}, {'authorId': '2234849566', 'name': 'Robert J. Morgan'}, {'authorId': '2196763325', 'name': 'L. Schwartzberg'}, {'authorId': '5157020', 'name': 'A. Venook'}, {'authorId': '6084038', 'name': 'C. Gocke'}, {'authorId': '2073524142', 'name': 'Jonathan Tait'}, {'authorId': '40235455', 'name': 'F. M. Stewart'}]","{'url': 'https://jnccn.org/downloadpdf/journals/jnccn/13/11/article-p1337.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.6004/JNCCN.2015.0163?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.6004/JNCCN.2015.0163, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background with advances such as next-generation sequencing (ngs) increasing understanding of the basis of cancer and its response to treatment, nccn believes it is important to understand how molecular profiling/diagnostic testing is being performed and used at nccn member institutions and their community affiliates. methods the nccn oncology research program's investigator steering committee and the nccn best practices committee gathered baseline information on the use of cancer-related molecular testing at nccn member institutions and community members of the nccn affiliate research consortium through 2 separate surveys distributed in december 2013 and september 2014, respectively. results a total of 24 nccn member institutions and 8 affiliate sites provided quantitative and qualitative data. in the context of these surveys, ""molecular profiling/diagnostics"" was defined as a panel of at least 10 genes examined as a diagnostic dna test in a clinical laboratory improvement amendments (clia)-certified laboratory. conclusions results indicated that molecular profiling/diagnostics are used at 100% of survey respondents' institutions to make patient care decisions. however, challenges relating to reimbursement, lack of data regarding actionable targets and targeted therapies, and access to drugs on or off clinical trials were cited as barriers to integration of molecular profiling into patient care. frameworks for using molecular diagnostic results based on levels of evidence, alongside continued research into the predictive value of biomarkers and targeted therapies, are recommended to advance understanding of the role of genomic biomarkers. greater evidence and consensus regarding the clinical and cost-effectiveness of molecular profiling may lead to broader insurance coverage and increased integration into patient care.",https://jnccn.org/downloadpdf/journals/jnccn/13/11/article-p1337.pdf
7e9cd89173fa68a5bd8cc5cb7aa68df172f603a2,Large language models and multimodal foundation models for precision oncology,"The technological progress in artificial intelligence (AI) has massively accelerated since 2022, with far-reaching implications for oncology and cancer research. Large language models (LLMs) now perform at human-level competency in text processing. Notably, both text and image processing networks are increasingly based on transformer neural networks. This convergence enables the development of multimodal AI models that take diverse types of data as an input simultaneously, marking a qualitative shift from specialized niche models which were prevalent in the 2010s. This editorial summarizes these developments, which are expected to impact precision oncology in the coming years.",2024,"[{'authorId': '2283302899', 'name': 'Daniel Truhn'}, {'authorId': '2034082291', 'name': 'Jan-Niklas Eckardt'}, {'authorId': '2258620804', 'name': 'Dyke Ferber'}, {'authorId': '2262022936', 'name': 'J. N. Kather'}]","{'url': 'https://www.nature.com/articles/s41698-024-00573-2.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10959931, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the technological progress in artificial intelligence (ai) has massively accelerated since 2022, with far-reaching implications for oncology and cancer research. large language models (llms) now perform at human-level competency in text processing. notably, both text and image processing networks are increasingly based on transformer neural networks. this convergence enables the development of multimodal ai models that take diverse types of data as an input simultaneously, marking a qualitative shift from specialized niche models which were prevalent in the 2010s. this editorial summarizes these developments, which are expected to impact precision oncology in the coming years.",https://www.nature.com/articles/s41698-024-00573-2.pdf
476f9375ad9d64ee67047cf68369a04a81aaa29c,"Enhancing Adolescent and Young Adult Oncology Research Within the National Clinical Trials Network: Rationale, Progress, and Emerging Strategies.","Adolescent and Young Adult Oncology (AYAO, including patients 15-39 years of age) is an emerging discipline in the field of cancer treatment and research. Poorer survival outcomes for this population and characteristic age-related challenges in care have called attention to the need for increased AYAO research. This chapter outlines pressing questions and reviews recent progress in AYAO research within the current organizational structure of the federal clinical trials enterprise, emphasizing how the United States National Cancer Institute's National Clinical Trials Network (NCTN) has created novel opportunities for collaborative AYAO research among the pediatric and adult NCTN groups. Potential strategies for expanding AYAO research, both within the NCTN and with other partners in the federal and advocacy domains are identified.",2015,"[{'authorId': '12450770', 'name': 'A. Weiss'}, {'authorId': '2209898', 'name': 'Craig R. Nichols'}, {'authorId': '4538441', 'name': 'D. Freyer'}]","{'url': 'https://europepmc.org/articles/pmc4604069?pdf=render', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1053/j.seminoncol.2015.07.012?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1053/j.seminoncol.2015.07.012, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","adolescent and young adult oncology (ayao, including patients 15-39 years of age) is an emerging discipline in the field of cancer treatment and research. poorer survival outcomes for this population and characteristic age-related challenges in care have called attention to the need for increased ayao research. this chapter outlines pressing questions and reviews recent progress in ayao research within the current organizational structure of the federal clinical trials enterprise, emphasizing how the united states national cancer institute's national clinical trials network (nctn) has created novel opportunities for collaborative ayao research among the pediatric and adult nctn groups. potential strategies for expanding ayao research, both within the nctn and with other partners in the federal and advocacy domains are identified.",https://europepmc.org/articles/pmc4604069?pdf=render
bb70e7a020b2e9461041a7f991e09bbc50de49c4,The impact of industry on oncology research and practice.,"Public scrutiny has increased over potential conflicts of interest among oncology researchers and providers. Given the increased prevalence and complexity of industry relationships, oncologists are increasingly faced with ethical challenges when navigating their financial relationships with industry. Oncologists are continually dealing with changing conflict of interest policies within academic centers and professional societies. With the recent passage of The Sunshine Act, oncologists are beginning to understand the repercussions of this new law. The consequences of the increasing use of direct-to-consumer advertising on patients with cancer are also unclear. Finally, industry's perspective on the evolution of these relationships is not clearly understood. This manuscript discusses issues related to industry's influence on oncology practice and research.",2015,"[{'authorId': '2563160', 'name': 'B. Moy'}, {'authorId': '2805842', 'name': 'R. Jagsi'}, {'authorId': '1402409684', 'name': 'Richard B. Gaynor'}, {'authorId': '3505532', 'name': 'M. Ratain'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.14694/EdBook_AM.2015.35.130?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.14694/EdBook_AM.2015.35.130, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","public scrutiny has increased over potential conflicts of interest among oncology researchers and providers. given the increased prevalence and complexity of industry relationships, oncologists are increasingly faced with ethical challenges when navigating their financial relationships with industry. oncologists are continually dealing with changing conflict of interest policies within academic centers and professional societies. with the recent passage of the sunshine act, oncologists are beginning to understand the repercussions of this new law. the consequences of the increasing use of direct-to-consumer advertising on patients with cancer are also unclear. finally, industry's perspective on the evolution of these relationships is not clearly understood. this manuscript discusses issues related to industry's influence on oncology practice and research.",
4243b2b11aa88bdcf1b40a863c8769dba65508ce,An overview and a roadmap for artificial intelligence in hematology and oncology,"Artificial intelligence (AI) is influencing our society on many levels and has broad implications for the future practice of hematology and oncology. However, for many medical professionals and researchers, it often remains unclear what AI can and cannot do, and what are promising areas for a sensible application of AI in hematology and oncology. Finally, the limits and perils of using AI in oncology are not obvious to many healthcare professionals. In this article, we provide an expert-based consensus statement by the joint Working Group on “Artificial Intelligence in Hematology and Oncology” by the German Society of Hematology and Oncology (DGHO), the German Association for Medical Informatics, Biometry and Epidemiology (GMDS), and the Special Interest Group Digital Health of the German Informatics Society (GI). We provide a conceptual framework for AI in hematology and oncology. First, we propose a technological definition, which we deliberately set in a narrow frame to mainly include the technical developments of the last ten years. Second, we present a taxonomy of clinically relevant AI systems, structured according to the type of clinical data they are used to analyze. Third, we show an overview of potential applications, including clinical, research, and educational environments with a focus on hematology and oncology. Thus, this article provides a point of reference for hematologists and oncologists, and at the same time sets forth a framework for the further development and clinical deployment of AI in hematology and oncology in the future.",2023,"[{'authorId': '2096234557', 'name': 'Wiebke Rösler'}, {'authorId': '9742089', 'name': 'M. Altenbuchinger'}, {'authorId': '1924789', 'name': 'B. Baessler'}, {'authorId': '4472076', 'name': 'T. Beissbarth'}, {'authorId': '89307364', 'name': 'G. Beutel'}, {'authorId': '2070626955', 'name': 'R. Bock'}, {'authorId': '5546605', 'name': 'N. von Bubnoff'}, {'authorId': '2034082291', 'name': 'Jan-Niklas Eckardt'}, {'authorId': '6234552', 'name': 'S. Foersch'}, {'authorId': '150952567', 'name': 'C. Loeffler'}, {'authorId': '118354462', 'name': 'J. Middeke'}, {'authorId': '2116235852', 'name': 'Martha Mueller'}, {'authorId': '47061835', 'name': 'T. Oellerich'}, {'authorId': '2351563199', 'name': 'Benjamin Risse'}, {'authorId': '4547549', 'name': 'A. Scherag'}, {'authorId': '6896549', 'name': 'C. Schliemann'}, {'authorId': '144362901', 'name': 'M. Scholz'}, {'authorId': '48692032', 'name': 'R. Spang'}, {'authorId': '120127798', 'name': 'C. Thielscher'}, {'authorId': '2085964264', 'name': 'I. Tsoukakis'}, {'authorId': '3955759', 'name': 'Jakob Nikolas Kather'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s00432-023-04667-5.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10374829, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","artificial intelligence (ai) is influencing our society on many levels and has broad implications for the future practice of hematology and oncology. however, for many medical professionals and researchers, it often remains unclear what ai can and cannot do, and what are promising areas for a sensible application of ai in hematology and oncology. finally, the limits and perils of using ai in oncology are not obvious to many healthcare professionals. in this article, we provide an expert-based consensus statement by the joint working group on “artificial intelligence in hematology and oncology” by the german society of hematology and oncology (dgho), the german association for medical informatics, biometry and epidemiology (gmds), and the special interest group digital health of the german informatics society (gi). we provide a conceptual framework for ai in hematology and oncology. first, we propose a technological definition, which we deliberately set in a narrow frame to mainly include the technical developments of the last ten years. second, we present a taxonomy of clinically relevant ai systems, structured according to the type of clinical data they are used to analyze. third, we show an overview of potential applications, including clinical, research, and educational environments with a focus on hematology and oncology. thus, this article provides a point of reference for hematologists and oncologists, and at the same time sets forth a framework for the further development and clinical deployment of ai in hematology and oncology in the future.",https://link.springer.com/content/pdf/10.1007/s00432-023-04667-5.pdf
dab84448bc89199c090f144e7814e8e7db837333,American Society of Clinical Oncology Road to Recovery Report: Learning From the COVID-19 Experience to Improve Clinical Research and Cancer Care.,"This report presents the American Society of Clinical Oncology’s (ASCO’s) evaluation of the adaptations in care delivery, research operations, and regulatory oversight made in response to the coronavirus pandemic and presents recommendations for moving forward as the pandemic recedes. ASCO organized its recommendations for clinical research around five goals to ensure lessons learned from the COVID-19 experience are used to craft a more equitable, accessible, and efficient clinical research system that protects patient safety, ensures scientific integrity, and maintains data quality. The specific goals are: (1) ensure that clinical research is accessible, affordable, and equitable; (2) design more pragmatic and efficient clinical trials; (3) minimize administrative and regulatory burdens on research sites; (4) recruit, retain, and support a well-trained clinical research workforce; and (5) promote appropriate oversight and review of clinical trial conduct and results. Similarly, ASCO also organized its recommendations regarding cancer care delivery around five goals: (1) promote and protect equitable access to high-quality cancer care; (2) support safe delivery of high-quality cancer care; (3) advance policies to ensure oncology providers have sufficient resources to provide high-quality patient care; (4) recognize and address threats to clinician, provider, and patient well-being; and (5) improve patient access to high-quality cancer care via telemedicine. ASCO will work at all levels to advance the recommendations made in this report.",2020,"[{'authorId': '6898541', 'name': 'N. Pennell'}, {'authorId': '11596003', 'name': 'Melissa S. Dillmon'}, {'authorId': '145000982', 'name': 'Laura A. Levit'}, {'authorId': '1679418051', 'name': 'E. Moushey'}, {'authorId': '143776096', 'name': 'A. Alva'}, {'authorId': '48327140', 'name': 'S. Blau'}, {'authorId': '6093379', 'name': 'T. Cannon'}, {'authorId': '11914423', 'name': 'N. Dickson'}, {'authorId': '1907024', 'name': 'M. Diehn'}, {'authorId': '2961596', 'name': 'M. Gonen'}, {'authorId': '2115576446', 'name': 'M. M. González'}, {'authorId': '15710316', 'name': 'J. Hensold'}, {'authorId': '3584513', 'name': 'L. Hinyard'}, {'authorId': '4689173', 'name': 'T. King'}, {'authorId': '84531778', 'name': 'S. Lindsey'}, {'authorId': '2977930', 'name': 'A. Magnuson'}, {'authorId': '13696553', 'name': 'Jonathan M Marron'}, {'authorId': '3422709', 'name': 'B. McAneny'}, {'authorId': '32443861', 'name': 'T. McDonnell'}, {'authorId': '10768733', 'name': 'K. Mileham'}, {'authorId': '47344336', 'name': 'Shelley Fuld Nasso'}, {'authorId': '2253371191', 'name': 'Grzegorz S. Nowakowski'}, {'authorId': '14446905', 'name': 'K. Oettel'}, {'authorId': '145132605', 'name': 'Manali I. Patel'}, {'authorId': '2431614', 'name': 'D. Patt'}, {'authorId': '46467553', 'name': 'J. Perlmutter'}, {'authorId': '40498155', 'name': 'T. Pickard'}, {'authorId': '2064855499', 'name': 'Gladys Rodriguez'}, {'authorId': '40241514', 'name': 'A. Rosenberg'}, {'authorId': '2034068885', 'name': 'Barry Russo'}, {'authorId': '16044346', 'name': 'Connie M Szczepanek'}, {'authorId': '2110281458', 'name': 'Cardinale B. Smith'}, {'authorId': '31153798', 'name': 'Piyush Srivastava'}, {'authorId': '11242955', 'name': 'E. Teplinsky'}, {'authorId': '39689607', 'name': 'R. Thota'}, {'authorId': '5754424', 'name': 'T. Traina'}, {'authorId': '2959060', 'name': 'R. Zon'}, {'authorId': '1640755396', 'name': 'Brian R Bourbeau'}, {'authorId': '10191468', 'name': 'S. Bruinooge'}, {'authorId': '2034046048', 'name': 'Shelagh E. Foster'}, {'authorId': '4497806', 'name': 'S. Grubbs'}, {'authorId': '1752724219', 'name': 'Karen Hagerty'}, {'authorId': '49158512', 'name': 'P. Hurley'}, {'authorId': '37980743', 'name': 'D. Kamin'}, {'authorId': '51312377', 'name': 'Jonathan Phillips'}, {'authorId': '26430896', 'name': 'Caroline Schenkel'}, {'authorId': '6682486', 'name': 'R. Schilsky'}, {'authorId': '2749158', 'name': 'H. Burris'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1200/jco.20.02953?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1200/jco.20.02953, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this report presents the american society of clinical oncology’s (asco’s) evaluation of the adaptations in care delivery, research operations, and regulatory oversight made in response to the coronavirus pandemic and presents recommendations for moving forward as the pandemic recedes. asco organized its recommendations for clinical research around five goals to ensure lessons learned from the covid-19 experience are used to craft a more equitable, accessible, and efficient clinical research system that protects patient safety, ensures scientific integrity, and maintains data quality. the specific goals are: (1) ensure that clinical research is accessible, affordable, and equitable; (2) design more pragmatic and efficient clinical trials; (3) minimize administrative and regulatory burdens on research sites; (4) recruit, retain, and support a well-trained clinical research workforce; and (5) promote appropriate oversight and review of clinical trial conduct and results. similarly, asco also organized its recommendations regarding cancer care delivery around five goals: (1) promote and protect equitable access to high-quality cancer care; (2) support safe delivery of high-quality cancer care; (3) advance policies to ensure oncology providers have sufficient resources to provide high-quality patient care; (4) recognize and address threats to clinician, provider, and patient well-being; and (5) improve patient access to high-quality cancer care via telemedicine. asco will work at all levels to advance the recommendations made in this report.",
2ec243b65691cfcb51de1466252c1f4de4b113c9,Glioblastoma in Adults: A Society for Neuro-Oncology (SNO) and European Society of Neuro-Oncology (EANO) Consensus Review on Current Management and Future Directions.,"Glioblastomas are the most common form of malignant primary brain tumor and an important cause of morbidity and mortality. In recent years there have been important advances in understanding the molecular pathogenesis and biology of these tumors, but this has not translated into significantly improved outcomes for patients. In this consensus review from the Society For Neuro-Oncology (SNO) and the European Association of Neuro-Oncology (EANO), the current management of isocitrate dehydrogenase-wildtype (IDHwt) glioblastomas will be discussed. In addition, novel therapies such as targeted molecular therapies, agents targeting DNA damage response and metabolism, immunotherapies and viral therapies will be reviewed, as well as the current challenges and future directions for research.",2020,"[{'authorId': '145426034', 'name': 'P. Wen'}, {'authorId': '145115639', 'name': 'M. Weller'}, {'authorId': '32917015', 'name': 'E. Lee'}, {'authorId': '2055186819', 'name': 'B. Alexander'}, {'authorId': '1390166347', 'name': 'J. Barnholtz-Sloan'}, {'authorId': '50763299', 'name': 'F. Barthel'}, {'authorId': '3354539', 'name': 'T. Batchelor'}, {'authorId': '2378747', 'name': 'R. Bindra'}, {'authorId': '18014955', 'name': 'Susan M. Chang'}, {'authorId': '144004820', 'name': 'E. Chiocca'}, {'authorId': '2718826', 'name': 'T. Cloughesy'}, {'authorId': '39032588', 'name': 'J. Degroot'}, {'authorId': '8010906', 'name': 'E. Galanis'}, {'authorId': '144390029', 'name': 'M. Gilbert'}, {'authorId': '4255014', 'name': 'M. Hegi'}, {'authorId': '3886144', 'name': 'C. Horbinski'}, {'authorId': '145111845', 'name': 'Raymond Y Huang'}, {'authorId': '7184791', 'name': 'A. Lassman'}, {'authorId': '52332900', 'name': 'É. Le Rhun'}, {'authorId': '143967209', 'name': 'M. Lim'}, {'authorId': '1765418', 'name': 'M. Mehta'}, {'authorId': '2569035', 'name': 'I. Mellinghoff'}, {'authorId': '3910480', 'name': 'G. Minniti'}, {'authorId': '40638746', 'name': 'D. Nathanson'}, {'authorId': '4173380', 'name': 'M. Plattén'}, {'authorId': '144646703', 'name': 'M. Preusser'}, {'authorId': '145382700', 'name': 'P. Roth'}, {'authorId': '144596968', 'name': 'M. Sanson'}, {'authorId': '145609574', 'name': 'D. Schiff'}, {'authorId': '49930229', 'name': 'S. Short'}, {'authorId': '145021367', 'name': 'M. Taphoorn'}, {'authorId': '4927727', 'name': 'J. Tonn'}, {'authorId': '47682625', 'name': 'J. Tsang'}, {'authorId': '144672002', 'name': 'R. Verhaak'}, {'authorId': '133681468', 'name': 'A. von Deimling'}, {'authorId': '2707080', 'name': 'W. Wick'}, {'authorId': '98462145', 'name': 'G. Zadeh'}, {'authorId': '2648068', 'name': 'D. Reardon'}, {'authorId': '50138848', 'name': 'K. Aldape'}, {'authorId': '7244239', 'name': 'M. J. van den Bent'}]","{'url': 'https://academic.oup.com/neuro-oncology/article-pdf/22/8/1073/33657355/noaa106.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/neuonc/noaa106?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/neuonc/noaa106, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","glioblastomas are the most common form of malignant primary brain tumor and an important cause of morbidity and mortality. in recent years there have been important advances in understanding the molecular pathogenesis and biology of these tumors, but this has not translated into significantly improved outcomes for patients. in this consensus review from the society for neuro-oncology (sno) and the european association of neuro-oncology (eano), the current management of isocitrate dehydrogenase-wildtype (idhwt) glioblastomas will be discussed. in addition, novel therapies such as targeted molecular therapies, agents targeting dna damage response and metabolism, immunotherapies and viral therapies will be reviewed, as well as the current challenges and future directions for research.",https://academic.oup.com/neuro-oncology/article-pdf/22/8/1073/33657355/noaa106.pdf
abf95ee95a683884134168bad5e222f7086d51cd,Integrative oncology: Addressing the global challenges of cancer prevention and treatment,"The increase in cancer incidence and mortality is challenging current cancer care delivery globally, disproportionally affecting low‐ and middle‐income countries (LMICs) when it comes to receiving evidence‐based cancer prevention, treatment, and palliative and survivorship care. Patients in LMICs often rely on traditional, complementary, and integrative medicine (TCIM) that is more familiar, less costly, and widely available. However, spheres of influence and tensions between conventional medicine and TCIM can further disrupt efforts in evidence‐based cancer care. Integrative oncology provides a framework to research and integrate safe, effective TCIM alongside conventional cancer treatment and can help bridge health care gaps in delivering evidence‐informed, patient‐centered care. This growing field uses lifestyle modifications, mind and body therapies (eg, acupuncture, massage, meditation, and yoga), and natural products to improve symptom management and quality of life among patients with cancer. On the basis of this review of the global challenges of cancer control and the current status of integrative oncology, the authors recommend: 1) educating and integrating TCIM providers into the cancer control workforce to promote risk reduction and culturally salient healthy life styles; 2) developing and testing TCIM interventions to address cancer symptoms or treatment‐related adverse effects (eg, pain, insomnia, fatigue); and 3) disseminating and implementing evidence‐based TCIM interventions as part of comprehensive palliative and survivorship care so patients from all cultures can live with or beyond cancer with respect, dignity, and vitality. With conventional medicine and TCIM united under a cohesive framework, integrative oncology may provide citizens of the world with access to safe, effective, evidence‐informed, and culturally sensitive cancer care.",2021,"[{'authorId': '145173340', 'name': 'J. Mao'}, {'authorId': '34375866', 'name': 'Geetha Krishnan Gopalakrishna Pillai'}, {'authorId': '2056054314', 'name': 'Carlos José Coelho de Andrade'}, {'authorId': '6435766', 'name': 'J. Ligibel'}, {'authorId': '3979573', 'name': 'P. Basu'}, {'authorId': '143868835', 'name': 'L. Cohen'}, {'authorId': '152212774', 'name': 'I. Khan'}, {'authorId': '6586890', 'name': 'K. Mustian'}, {'authorId': '1994724958', 'name': 'Rammanohar Puthiyedath'}, {'authorId': '87812940', 'name': 'K. Dhiman'}, {'authorId': '119900880', 'name': 'Li-Ying Lao'}, {'authorId': '12480257', 'name': 'Ricardo Ghelman'}, {'authorId': '66207820', 'name': 'P. Cáceres Guido'}, {'authorId': '143829458', 'name': 'G. Lopez'}, {'authorId': '1398597810', 'name': 'D. Gallego-Perez'}, {'authorId': '51094559', 'name': 'L. A. Salicrup'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3322/caac.21706?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3322/caac.21706, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the increase in cancer incidence and mortality is challenging current cancer care delivery globally, disproportionally affecting low‐ and middle‐income countries (lmics) when it comes to receiving evidence‐based cancer prevention, treatment, and palliative and survivorship care. patients in lmics often rely on traditional, complementary, and integrative medicine (tcim) that is more familiar, less costly, and widely available. however, spheres of influence and tensions between conventional medicine and tcim can further disrupt efforts in evidence‐based cancer care. integrative oncology provides a framework to research and integrate safe, effective tcim alongside conventional cancer treatment and can help bridge health care gaps in delivering evidence‐informed, patient‐centered care. this growing field uses lifestyle modifications, mind and body therapies (eg, acupuncture, massage, meditation, and yoga), and natural products to improve symptom management and quality of life among patients with cancer. on the basis of this review of the global challenges of cancer control and the current status of integrative oncology, the authors recommend: 1) educating and integrating tcim providers into the cancer control workforce to promote risk reduction and culturally salient healthy life styles; 2) developing and testing tcim interventions to address cancer symptoms or treatment‐related adverse effects (eg, pain, insomnia, fatigue); and 3) disseminating and implementing evidence‐based tcim interventions as part of comprehensive palliative and survivorship care so patients from all cultures can live with or beyond cancer with respect, dignity, and vitality. with conventional medicine and tcim united under a cohesive framework, integrative oncology may provide citizens of the world with access to safe, effective, evidence‐informed, and culturally sensitive cancer care.",
5f4e07bfa10edabdd16c614493dd28222472247f,Human Epidermal Growth Factor Receptor 2 Testing in Breast Cancer: American Society of Clinical Oncology/College of American Pathologists Clinical Practice Guideline Focused Update.,"Purpose To update key recommendations of the American Society of Clinical Oncology/College of American Pathologists human epidermal growth factor receptor 2 (HER2) testing in breast cancer guideline. Methods Based on the signals approach, an Expert Panel reviewed published literature and research survey results on the observed frequency of less common in situ hybridization (ISH) patterns to update the recommendations. Recommendations Two recommendations addressed via correspondence in 2015 are included. First, immunohistochemistry (IHC) 2+ is defined as invasive breast cancer with weak to moderate complete membrane staining observed in > 10% of tumor cells. Second, if the initial HER2 test result in a core needle biopsy specimen of a primary breast cancer is negative, a new HER2 test may (not ""must"") be ordered on the excision specimen based on specific clinical criteria. The HER2 testing algorithm for breast cancer is updated to address the recommended work-up for less common clinical scenarios (approximately 5% of cases) observed when using a dual-probe ISH assay. These scenarios are described as ISH group 2 ( HER2/chromosome enumeration probe 17 [CEP17] ratio ≥ 2.0; average HER2 copy number < 4.0 signals per cell), ISH group 3 ( HER2/CEP17 ratio < 2.0; average HER2 copy number ≥ 6.0 signals per cell), and ISH group 4 ( HER2/CEP17 ratio < 2.0; average HER2 copy number ≥ 4.0 and < 6.0 signals per cell). The diagnostic approach includes more rigorous interpretation criteria for ISH and requires concomitant IHC review for dual-probe ISH groups 2 to 4 to arrive at the most accurate HER2 status designation (positive or negative) based on combined interpretation of the ISH and IHC assays. The Expert Panel recommends that laboratories using single-probe ISH assays include concomitant IHC review as part of the interpretation of all single-probe ISH assay results. Find additional information at www.asco.org/breast-cancer-guidelines .",2018,"[{'authorId': '3274634', 'name': 'A. Wolff'}, {'authorId': '2271719085', 'name': 'M. Elizabeth'}, {'authorId': '2271277592', 'name': 'H. Hammond'}, {'authorId': '2870017', 'name': 'K. Allison'}, {'authorId': '40868347', 'name': 'Brittany E. Harvey'}, {'authorId': '3851436', 'name': 'P. Mangu'}, {'authorId': '143993580', 'name': 'J. Bartlett'}, {'authorId': '145534922', 'name': 'M. Bilous'}, {'authorId': '29807269', 'name': 'I. Ellis'}, {'authorId': '3794490', 'name': 'P. Fitzgibbons'}, {'authorId': '145784688', 'name': 'W. Hanna'}, {'authorId': '145207452', 'name': 'R. Jenkins'}, {'authorId': '2759793', 'name': 'M. Press'}, {'authorId': '3016802', 'name': 'P. Spears'}, {'authorId': '4468376', 'name': 'G. Vance'}, {'authorId': '49710557', 'name': 'G. Viale'}, {'authorId': '2933371', 'name': 'L. McShane'}, {'authorId': '112927420', 'name': 'M. Dowsett'}]","{'url': 'https://scholarworks.indianapolis.iu.edu/bitstreams/f8889404-392e-4ce8-be3d-c0c1a7ab3bd9/download', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1200/JCO.2018.77.8738?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1200/JCO.2018.77.8738, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purpose to update key recommendations of the american society of clinical oncology/college of american pathologists human epidermal growth factor receptor 2 (her2) testing in breast cancer guideline. methods based on the signals approach, an expert panel reviewed published literature and research survey results on the observed frequency of less common in situ hybridization (ish) patterns to update the recommendations. recommendations two recommendations addressed via correspondence in 2015 are included. first, immunohistochemistry (ihc) 2+ is defined as invasive breast cancer with weak to moderate complete membrane staining observed in > 10% of tumor cells. second, if the initial her2 test result in a core needle biopsy specimen of a primary breast cancer is negative, a new her2 test may (not ""must"") be ordered on the excision specimen based on specific clinical criteria. the her2 testing algorithm for breast cancer is updated to address the recommended work-up for less common clinical scenarios (approximately 5% of cases) observed when using a dual-probe ish assay. these scenarios are described as ish group 2 ( her2/chromosome enumeration probe 17 [cep17] ratio ≥ 2.0; average her2 copy number < 4.0 signals per cell), ish group 3 ( her2/cep17 ratio < 2.0; average her2 copy number ≥ 6.0 signals per cell), and ish group 4 ( her2/cep17 ratio < 2.0; average her2 copy number ≥ 4.0 and < 6.0 signals per cell). the diagnostic approach includes more rigorous interpretation criteria for ish and requires concomitant ihc review for dual-probe ish groups 2 to 4 to arrive at the most accurate her2 status designation (positive or negative) based on combined interpretation of the ish and ihc assays. the expert panel recommends that laboratories using single-probe ish assays include concomitant ihc review as part of the interpretation of all single-probe ish assay results. find additional information at www.asco.org/breast-cancer-guidelines .",https://scholarworks.indianapolis.iu.edu/bitstreams/f8889404-392e-4ce8-be3d-c0c1a7ab3bd9/download
fa15d5cfe64d344c671560a58c964f1f243e38fa,"Isocitrate dehydrogenase (IDH) mutant gliomas: A Society for Neuro-Oncology (SNO) consensus review on diagnosis, management, and future directions.","Isocitrate dehydrogenase (IDH) mutant gliomas are the most common adult, malignant primary brain tumors diagnosed in patients younger than 50, constituting an important cause of morbidity and mortality. In recent years, there has been significant progress in understanding the molecular pathogenesis and biology of these tumors, sparking multiple efforts to improve their diagnosis and treatment. In this consensus review from the Society for Neuro-Oncology (SNO), the current diagnosis and management of IDH-mutant gliomas will be discussed. In addition, novel therapies, such as targeted molecular therapies and immunotherapies, will be reviewed. Current challenges and future directions for research will be discussed.",2022,"[{'authorId': '152617678', 'name': 'Julie J. Miller'}, {'authorId': '4930824', 'name': 'L. G. Gonzalez Castro'}, {'authorId': '5011431', 'name': 'S. McBrayer'}, {'authorId': '2055513111', 'name': 'M. Weller'}, {'authorId': '6438765', 'name': 'T. Cloughesy'}, {'authorId': '5523018', 'name': 'J. Portnow'}, {'authorId': '3230849', 'name': 'O. Andronesi'}, {'authorId': '1390166347', 'name': 'J. Barnholtz-Sloan'}, {'authorId': '2074778346', 'name': 'B. Baumert'}, {'authorId': '82318840', 'name': 'M. Berger'}, {'authorId': '6559881', 'name': 'W. Bi'}, {'authorId': '2378747', 'name': 'R. Bindra'}, {'authorId': '31526375', 'name': 'D. Cahill'}, {'authorId': '18014955', 'name': 'Susan M. Chang'}, {'authorId': '2552233', 'name': 'J. Costello'}, {'authorId': '3886144', 'name': 'C. Horbinski'}, {'authorId': '145111845', 'name': 'Raymond Y Huang'}, {'authorId': '145207452', 'name': 'R. Jenkins'}, {'authorId': '5627829', 'name': 'K. Ligon'}, {'authorId': '2569035', 'name': 'I. Mellinghoff'}, {'authorId': '144897374', 'name': 'L. Nabors'}, {'authorId': '4173380', 'name': 'M. Plattén'}, {'authorId': '2648068', 'name': 'D. Reardon'}, {'authorId': '152601768', 'name': 'D. Shi'}, {'authorId': '145609574', 'name': 'D. Schiff'}, {'authorId': '2130453645', 'name': 'W. Wick'}, {'authorId': '2152208728', 'name': 'Hai Yan'}, {'authorId': '133681468', 'name': 'A. von Deimling'}, {'authorId': '7244239', 'name': 'M. J. van den Bent'}, {'authorId': '3938100', 'name': 'W. Kaelin'}, {'authorId': '145426034', 'name': 'P. Wen'}]","{'url': 'https://academic.oup.com/neuro-oncology/article-pdf/25/1/4/48496899/noac207.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/neuonc/noac207?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/neuonc/noac207, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","isocitrate dehydrogenase (idh) mutant gliomas are the most common adult, malignant primary brain tumors diagnosed in patients younger than 50, constituting an important cause of morbidity and mortality. in recent years, there has been significant progress in understanding the molecular pathogenesis and biology of these tumors, sparking multiple efforts to improve their diagnosis and treatment. in this consensus review from the society for neuro-oncology (sno), the current diagnosis and management of idh-mutant gliomas will be discussed. in addition, novel therapies, such as targeted molecular therapies and immunotherapies, will be reviewed. current challenges and future directions for research will be discussed.",https://academic.oup.com/neuro-oncology/article-pdf/25/1/4/48496899/noac207.pdf
6b2ca0c16962ba8082be560c4dec8f4e66eb5d15,Yoga for symptom management in oncology: A review of the evidence base and future directions for research,"Because yoga is increasingly recognized as a complementary approach to cancer symptom management, patients/survivors and providers need to understand its potential benefits and limitations both during and after treatment. The authors reviewed randomized controlled trials (RCTs) of yoga conducted at these points in the cancer continuum (N = 29; n = 13 during treatment, n = 12 post‐treatment, and n = 4 with mixed samples). Findings both during and after treatment demonstrated the efficacy of yoga to improve overall quality of life (QOL), with improvement in subdomains of QOL varying across studies. Fatigue was the most commonly measured outcome, and most RCTs conducted during or after cancer treatment reported improvements in fatigue. Results also suggested that yoga can improve stress/distress during treatment and post‐treatment disturbances in sleep and cognition. Several RCTs provided evidence that yoga may improve biomarkers of stress, inflammation, and immune function. Outcomes with limited or mixed findings (eg, anxiety, depression, pain, cancer‐specific symptoms, such as lymphedema) and positive psychological outcomes (such as benefit‐finding and life satisfaction) warrant further study. Important future directions for yoga research in oncology include: enrolling participants with cancer types other than breast, standardizing self‐report assessments, increasing the use of active control groups and objective measures, and addressing the heterogeneity of yoga interventions, which vary in type, key components (movement, meditation, breathing), dose, and delivery mode.",2019,"[{'authorId': '4527555', 'name': 'S. Danhauer'}, {'authorId': '13114484', 'name': 'E. Addington'}, {'authorId': '143868835', 'name': 'L. Cohen'}, {'authorId': '4457231', 'name': 'S. Sohl'}, {'authorId': '6233781', 'name': 'M. Van Puymbroeck'}, {'authorId': '40911591', 'name': 'Natalia K. Albinati'}, {'authorId': '1400654166', 'name': 'S. Culos-Reed'}]","{'url': 'https://acsjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cncr.31979', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/cncr.31979?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/cncr.31979, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","because yoga is increasingly recognized as a complementary approach to cancer symptom management, patients/survivors and providers need to understand its potential benefits and limitations both during and after treatment. the authors reviewed randomized controlled trials (rcts) of yoga conducted at these points in the cancer continuum (n = 29; n = 13 during treatment, n = 12 post‐treatment, and n = 4 with mixed samples). findings both during and after treatment demonstrated the efficacy of yoga to improve overall quality of life (qol), with improvement in subdomains of qol varying across studies. fatigue was the most commonly measured outcome, and most rcts conducted during or after cancer treatment reported improvements in fatigue. results also suggested that yoga can improve stress/distress during treatment and post‐treatment disturbances in sleep and cognition. several rcts provided evidence that yoga may improve biomarkers of stress, inflammation, and immune function. outcomes with limited or mixed findings (eg, anxiety, depression, pain, cancer‐specific symptoms, such as lymphedema) and positive psychological outcomes (such as benefit‐finding and life satisfaction) warrant further study. important future directions for yoga research in oncology include: enrolling participants with cancer types other than breast, standardizing self‐report assessments, increasing the use of active control groups and objective measures, and addressing the heterogeneity of yoga interventions, which vary in type, key components (movement, meditation, breathing), dose, and delivery mode.",https://acsjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cncr.31979
e1d63b0d1559dd3a9ca43e286f4e487dad49cdee,Sarcopenia and Cardiovascular Diseases,"Sarcopenia is the loss of muscle strength, mass, and function, which is often exacerbated by chronic comorbidities including cardiovascular diseases, chronic kidney disease, and cancer. Sarcopenia is associated with faster progression of cardiovascular diseases and higher risk of mortality, falls, and reduced quality of life, particularly among older adults. Although the pathophysiologic mechanisms are complex, the broad underlying cause of sarcopenia includes an imbalance between anabolic and catabolic muscle homeostasis with or without neuronal degeneration. The intrinsic molecular mechanisms of aging, chronic illness, malnutrition, and immobility are associated with the development of sarcopenia. Screening and testing for sarcopenia may be particularly important among those with chronic disease states. Early recognition of sarcopenia is important because it can provide an opportunity for interventions to reverse or delay the progression of muscle disorder, which may ultimately impact cardiovascular outcomes. Relying on body mass index is not useful for screening because many patients will have sarcopenic obesity, a particularly important phenotype among older cardiac patients. In this review, we aimed to: (1) provide a definition of sarcopenia within the context of muscle wasting disorders; (2) summarize the associations between sarcopenia and different cardiovascular diseases; (3) highlight an approach for a diagnostic evaluation; (4) discuss management strategies for sarcopenia; and (5) outline key gaps in knowledge with implications for the future of the field.",2023,"[{'authorId': '2249539919', 'name': 'Abdulla A. Damluji'}, {'authorId': '2151743738', 'name': 'Maha Alfaraidhy'}, {'authorId': '52004164', 'name': 'Noora Alhajri'}, {'authorId': '80233159', 'name': 'N. Rohant'}, {'authorId': '2217179225', 'name': 'Manish Kumar'}, {'authorId': '2115016122', 'name': 'Christina Al Malouf'}, {'authorId': '6827796', 'name': 'Samira Bahrainy'}, {'authorId': '2138732828', 'name': 'Min Ji Kwak'}, {'authorId': '2094972800', 'name': 'Wayne B. Batchelor'}, {'authorId': '35048921', 'name': 'D. Forman'}, {'authorId': '2782091', 'name': 'M. Rich'}, {'authorId': '2066516948', 'name': 'James R M Kirkpatrick'}, {'authorId': '2183016774', 'name': 'Ashok Krishnaswami'}, {'authorId': '3064864', 'name': 'K. Alexander'}, {'authorId': '4348216', 'name': 'G. Gerstenblith'}, {'authorId': '2287910481', 'name': 'Peggy M. Cawthon'}, {'authorId': '2306252', 'name': 'C. Defilippi'}, {'authorId': '50845754', 'name': 'P. Goyal'}]","{'url': 'https://www.ahajournals.org/doi/pdf/10.1161/CIRCULATIONAHA.123.064071', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10180053, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","sarcopenia is the loss of muscle strength, mass, and function, which is often exacerbated by chronic comorbidities including cardiovascular diseases, chronic kidney disease, and cancer. sarcopenia is associated with faster progression of cardiovascular diseases and higher risk of mortality, falls, and reduced quality of life, particularly among older adults. although the pathophysiologic mechanisms are complex, the broad underlying cause of sarcopenia includes an imbalance between anabolic and catabolic muscle homeostasis with or without neuronal degeneration. the intrinsic molecular mechanisms of aging, chronic illness, malnutrition, and immobility are associated with the development of sarcopenia. screening and testing for sarcopenia may be particularly important among those with chronic disease states. early recognition of sarcopenia is important because it can provide an opportunity for interventions to reverse or delay the progression of muscle disorder, which may ultimately impact cardiovascular outcomes. relying on body mass index is not useful for screening because many patients will have sarcopenic obesity, a particularly important phenotype among older cardiac patients. in this review, we aimed to: (1) provide a definition of sarcopenia within the context of muscle wasting disorders; (2) summarize the associations between sarcopenia and different cardiovascular diseases; (3) highlight an approach for a diagnostic evaluation; (4) discuss management strategies for sarcopenia; and (5) outline key gaps in knowledge with implications for the future of the field.",https://www.ahajournals.org/doi/pdf/10.1161/CIRCULATIONAHA.123.064071
921ca2901a01693b57693779e07ae1c858d7048b,The role of lactate in cardiovascular diseases,"Cardiovascular diseases pose a major threat worldwide. Common cardiovascular diseases include acute myocardial infarction (AMI), heart failure, atrial fibrillation (AF) and atherosclerosis. Glycolysis process often has changed during these cardiovascular diseases. Lactate, the end-product of glycolysis, has been overlooked in the past but has gradually been identified to play major biological functions in recent years. Similarly, the role of lactate in cardiovascular disease is gradually being recognized. Targeting lactate production, regulating lactate transport, and modulating circulating lactate levels may serve as potential strategies for the treatment of cardiovascular diseases in the future. The purpose of this review is to integrate relevant clinical and basic research on the role of lactate in the pathophysiological process of cardiovascular disease in recent years to clarify the important role of lactate in cardiovascular disease and to guide further studies exploring the role of lactate in cardiovascular and other diseases. Video Abstract",2023,"[{'authorId': '2264652251', 'name': 'Jun Ouyang'}, {'authorId': '2264393913', 'name': 'Hui Wang'}, {'authorId': '50535361', 'name': 'Jiangnan Huang'}]","{'url': 'https://biosignaling.biomedcentral.com/counter/pdf/10.1186/s12964-023-01350-7', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10623854, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases pose a major threat worldwide. common cardiovascular diseases include acute myocardial infarction (ami), heart failure, atrial fibrillation (af) and atherosclerosis. glycolysis process often has changed during these cardiovascular diseases. lactate, the end-product of glycolysis, has been overlooked in the past but has gradually been identified to play major biological functions in recent years. similarly, the role of lactate in cardiovascular disease is gradually being recognized. targeting lactate production, regulating lactate transport, and modulating circulating lactate levels may serve as potential strategies for the treatment of cardiovascular diseases in the future. the purpose of this review is to integrate relevant clinical and basic research on the role of lactate in the pathophysiological process of cardiovascular disease in recent years to clarify the important role of lactate in cardiovascular disease and to guide further studies exploring the role of lactate in cardiovascular and other diseases. video abstract",https://biosignaling.biomedcentral.com/counter/pdf/10.1186/s12964-023-01350-7
569debf9aa348a6dde135d50045ab7333b544fa8,Triglyceride-glucose index as a marker in cardiovascular diseases: landscape and limitations,"The triglyceride-glucose (TyG) index has been identified as a reliable alternative biomarker of insulin resistance (IR). Recently, a considerable number of studies have provided robust statistical evidence suggesting that the TyG index is associated with the development and prognosis of cardiovascular disease (CVD). Nevertheless, the application of the TyG index as a marker of CVD has not systemically been evaluated, and even less information exists regarding the underlying mechanisms associated with CVD. To this end, in this review, we summarize the history of the use of the TyG index as a surrogate marker for IR. We aimed to highlight the application value of the TyG index for a variety of CVD types and to explore the potential limitations of using this index as a predictor for cardiovascular events to improve its application value for CVD and provide more extensive and precise supporting evidence.",2022,"[{'authorId': '2162110632', 'name': 'Lichan Tao'}, {'authorId': '2294020706', 'name': 'Jia-ni Xu'}, {'authorId': '121576261', 'name': 'Tingting Wang'}, {'authorId': '46294256', 'name': 'Fei Hua'}, {'authorId': '1701502', 'name': 'Jian Li'}]","{'url': 'https://cardiab.biomedcentral.com/track/pdf/10.1186/s12933-022-01511-x', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9078015, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the triglyceride-glucose (tyg) index has been identified as a reliable alternative biomarker of insulin resistance (ir). recently, a considerable number of studies have provided robust statistical evidence suggesting that the tyg index is associated with the development and prognosis of cardiovascular disease (cvd). nevertheless, the application of the tyg index as a marker of cvd has not systemically been evaluated, and even less information exists regarding the underlying mechanisms associated with cvd. to this end, in this review, we summarize the history of the use of the tyg index as a surrogate marker for ir. we aimed to highlight the application value of the tyg index for a variety of cvd types and to explore the potential limitations of using this index as a predictor for cardiovascular events to improve its application value for cvd and provide more extensive and precise supporting evidence.",https://cardiab.biomedcentral.com/track/pdf/10.1186/s12933-022-01511-x
c319e665839ec3676520e7fe3f521fd25b7d1021,"Obesity Phenotypes, Diabetes, and Cardiovascular Diseases.","This review addresses the interplay between obesity, type 2 diabetes mellitus, and cardiovascular diseases. It is proposed that obesity, generally defined by an excess of body fat causing prejudice to health, can no longer be evaluated solely by the body mass index (expressed in kg/m2) because it represents a heterogeneous entity. For instance, several cardiometabolic imaging studies have shown that some individuals who have a normal weight or who are overweight are at high risk if they have an excess of visceral adipose tissue-a condition often accompanied by accumulation of fat in normally lean tissues (ectopic fat deposition in liver, heart, skeletal muscle, etc). On the other hand, individuals who are overweight or obese can nevertheless be at much lower risk than expected when faced with excess energy intake if they have the ability to expand their subcutaneous adipose tissue mass, particularly in the gluteal-femoral area. Hence, excessive amounts of visceral adipose tissue and of ectopic fat largely define the cardiovascular disease risk of overweight and moderate obesity. There is also a rapidly expanding subgroup of patients characterized by a high accumulation of body fat (severe obesity). Severe obesity is characterized by specific additional cardiovascular health issues that should receive attention. Because of the difficulties of normalizing body fat content in patients with severe obesity, more aggressive treatments have been studied in this subgroup of individuals such as obesity surgery, also referred to as metabolic surgery. On the basis of the above, we propose that we should refer to obesities rather than obesity.",2020,"[{'authorId': '35015552', 'name': 'M. Piché'}, {'authorId': '2960424', 'name': 'A. Tchernof'}, {'authorId': '144853843', 'name': 'J. Despres'}]","{'url': 'https://www.ahajournals.org/doi/pdf/10.1161/CIRCRESAHA.120.316101', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1161/CIRCRESAHA.120.316101?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1161/CIRCRESAHA.120.316101, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this review addresses the interplay between obesity, type 2 diabetes mellitus, and cardiovascular diseases. it is proposed that obesity, generally defined by an excess of body fat causing prejudice to health, can no longer be evaluated solely by the body mass index (expressed in kg/m2) because it represents a heterogeneous entity. for instance, several cardiometabolic imaging studies have shown that some individuals who have a normal weight or who are overweight are at high risk if they have an excess of visceral adipose tissue-a condition often accompanied by accumulation of fat in normally lean tissues (ectopic fat deposition in liver, heart, skeletal muscle, etc). on the other hand, individuals who are overweight or obese can nevertheless be at much lower risk than expected when faced with excess energy intake if they have the ability to expand their subcutaneous adipose tissue mass, particularly in the gluteal-femoral area. hence, excessive amounts of visceral adipose tissue and of ectopic fat largely define the cardiovascular disease risk of overweight and moderate obesity. there is also a rapidly expanding subgroup of patients characterized by a high accumulation of body fat (severe obesity). severe obesity is characterized by specific additional cardiovascular health issues that should receive attention. because of the difficulties of normalizing body fat content in patients with severe obesity, more aggressive treatments have been studied in this subgroup of individuals such as obesity surgery, also referred to as metabolic surgery. on the basis of the above, we propose that we should refer to obesities rather than obesity.",https://www.ahajournals.org/doi/pdf/10.1161/CIRCRESAHA.120.316101
7546e7bc275a6fbd6d065fed34f177faa09fc864,"Ferroptosis: a cell death connecting oxidative stress, inflammation and cardiovascular diseases","Ferroptosis, a recently identified and iron-dependent cell death, differs from other cell death such as apoptosis, necroptosis, pyroptosis, and autophagy-dependent cell death. This form of cell death does not exhibit typical morphological and biochemical characteristics, including cell shrinkage, mitochondrial fragmentation, nuclear condensation. The dysfunction of lipid peroxide clearance, the presence of redox-active iron as well as oxidation of polyunsaturated fatty acid (PUFA)-containing phospholipids are three essential features of ferroptosis. Iron metabolism and lipid peroxidation signaling are increasingly recognized as central mediators of ferroptosis. Ferroptosis plays an important role in the regulation of oxidative stress and inflammatory responses. Accumulating evidence suggests that ferroptosis is implicated in a variety of cardiovascular diseases such as atherosclerosis, stroke, ischemia-reperfusion injury, and heart failure, indicating that targeting ferroptosis will present a novel therapeutic approach against cardiovascular diseases. Here, we provide an overview of the features, process, function, and mechanisms of ferroptosis, and its increasingly connected relevance to oxidative stress, inflammation, and cardiovascular diseases.",2021,"[{'authorId': '48623606', 'name': 'Yi Yu'}, {'authorId': '2115359780', 'name': 'Yuan Yan'}, {'authorId': '1919756', 'name': 'F. Niu'}, {'authorId': '2125068117', 'name': 'Yajun Wang'}, {'authorId': '2145448504', 'name': 'Xueyi Chen'}, {'authorId': '2120902129', 'name': 'Guodong Su'}, {'authorId': '47909573', 'name': 'Yuru Liu'}, {'authorId': '2135962859', 'name': 'Xiling Zhao'}, {'authorId': '2151171316', 'name': 'Lu Qian'}, {'authorId': '2157787163', 'name': 'Ping Liu'}, {'authorId': '8096487', 'name': 'Yuyan Xiong'}]","{'url': 'https://www.nature.com/articles/s41420-021-00579-w.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8313570, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ferroptosis, a recently identified and iron-dependent cell death, differs from other cell death such as apoptosis, necroptosis, pyroptosis, and autophagy-dependent cell death. this form of cell death does not exhibit typical morphological and biochemical characteristics, including cell shrinkage, mitochondrial fragmentation, nuclear condensation. the dysfunction of lipid peroxide clearance, the presence of redox-active iron as well as oxidation of polyunsaturated fatty acid (pufa)-containing phospholipids are three essential features of ferroptosis. iron metabolism and lipid peroxidation signaling are increasingly recognized as central mediators of ferroptosis. ferroptosis plays an important role in the regulation of oxidative stress and inflammatory responses. accumulating evidence suggests that ferroptosis is implicated in a variety of cardiovascular diseases such as atherosclerosis, stroke, ischemia-reperfusion injury, and heart failure, indicating that targeting ferroptosis will present a novel therapeutic approach against cardiovascular diseases. here, we provide an overview of the features, process, function, and mechanisms of ferroptosis, and its increasingly connected relevance to oxidative stress, inflammation, and cardiovascular diseases.",https://www.nature.com/articles/s41420-021-00579-w.pdf
c6d159a4380a99e2921a9f7c19ea63ce80e53ee9,Periodontitis and cardiovascular diseases: Consensus report,"Abstract Background In Europe cardiovascular disease (CVD) is responsible for 3.9 million deaths (45% of deaths), being ischaemic heart disease, stroke, hypertension (leading to heart failure) the major cause of these CVD related deaths. Periodontitis is also a chronic non‐communicable disease (NCD) with a high prevalence, being severe periodontitis, affecting 11.2% of the world's population, the sixth most common human disease. Material and Methods There is now a significant body of evidence to support independent associations between severe periodontitis and several NCDs, in particular CVD. In 2012 a joint workshop was held between the European Federation of Periodontology (EFP) and the American Academy of Periodontology to review the literature relating periodontitis and systemic diseases, including CVD. In the last five years important new scientific information has emerged providing important emerging evidence to support these associations Results and Conclusions The present review reports the proceedings of the workshop jointly organised by the EFP and the World Heart Federation (WHF), which has updated the existing epidemiological evidence for significant associations between periodontitis and CVD, the mechanistic links and the impact of periodontal therapy on cardiovascular and surrogate outcomes. This review has also focused on the potential risk and complications of periodontal therapy in patients on anti thrombotic therapy and has made recommendations for dentists, physicians and for patients visiting both the dental and medical practices.",2020,"[{'authorId': '144569589', 'name': 'M. Sanz'}, {'authorId': '2243453910', 'name': 'Álvaro Marco del Castillo'}, {'authorId': '145489505', 'name': 'S. Jepsen'}, {'authorId': '1390166364', 'name': 'J. González-Juanatey'}, {'authorId': '1398163758', 'name': 'F. D’Aiuto'}, {'authorId': '74272896', 'name': 'P. Bouchard'}, {'authorId': '34877296', 'name': 'I. Chapple'}, {'authorId': '145728531', 'name': 'T. Dietrich'}, {'authorId': '5562217', 'name': 'I. Gotsman'}, {'authorId': '4054717', 'name': 'F. Graziani'}, {'authorId': '33498727', 'name': 'D. Herrera'}, {'authorId': '1915362', 'name': 'B. Loos'}, {'authorId': '144040414', 'name': 'P. Madianos'}, {'authorId': '143688096', 'name': 'J. Michel'}, {'authorId': '2662985', 'name': 'P. Perel'}, {'authorId': '4247050', 'name': 'B. Pieske'}, {'authorId': '2717456', 'name': 'L. Shapira'}, {'authorId': '4446980', 'name': 'M. Shechter'}, {'authorId': '4191265', 'name': 'M. Tonetti'}, {'authorId': '3638529', 'name': 'C. Vlachopoulos'}, {'authorId': '49462157', 'name': 'G. Wimmer'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/jcpe.13189', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7027895, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract background in europe cardiovascular disease (cvd) is responsible for 3.9 million deaths (45% of deaths), being ischaemic heart disease, stroke, hypertension (leading to heart failure) the major cause of these cvd related deaths. periodontitis is also a chronic non‐communicable disease (ncd) with a high prevalence, being severe periodontitis, affecting 11.2% of the world's population, the sixth most common human disease. material and methods there is now a significant body of evidence to support independent associations between severe periodontitis and several ncds, in particular cvd. in 2012 a joint workshop was held between the european federation of periodontology (efp) and the american academy of periodontology to review the literature relating periodontitis and systemic diseases, including cvd. in the last five years important new scientific information has emerged providing important emerging evidence to support these associations results and conclusions the present review reports the proceedings of the workshop jointly organised by the efp and the world heart federation (whf), which has updated the existing epidemiological evidence for significant associations between periodontitis and cvd, the mechanistic links and the impact of periodontal therapy on cardiovascular and surrogate outcomes. this review has also focused on the potential risk and complications of periodontal therapy in patients on anti thrombotic therapy and has made recommendations for dentists, physicians and for patients visiting both the dental and medical practices.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/jcpe.13189
0b452af1c6e1ad5cda3a62c915a75dd2f81e69e4,Microglia-Mediated Neuroinflammation: A Potential Target for the Treatment of Cardiovascular Diseases,"Abstract Microglia are tissue-resident macrophages of the central nervous system (CNS). In the CNS, microglia play an important role in the monitoring and intervention of synaptic and neuron-level activities. Interventions targeting microglia have been shown to improve the prognosis of various neurological diseases. Recently, studies have observed the activation of microglia in different cardiovascular diseases. In addition, different approaches that regulate the activity of microglia have been shown to modulate the incidence and progression of cardiovascular diseases. The change in autonomic nervous system activity after neuroinflammation may be a potential intermediate link between microglia and cardiovascular diseases. Here, in this review, we will discuss recent updates on the regulatory role of microglia in hypertension, myocardial infarction and ischemia/reperfusion injury. We propose that microglia serve as neuroimmune modulators and potential targets for cardiovascular diseases.",2022,"[{'authorId': '5635528', 'name': 'Menglong Wang'}, {'authorId': '2075363102', 'name': 'Wei Pan'}, {'authorId': '50125598', 'name': 'Yao Xu'}, {'authorId': '1519052221', 'name': 'Jishou Zhang'}, {'authorId': '145121531', 'name': 'J. Wan'}, {'authorId': '2157786238', 'name': 'Hong Jiang'}]","{'url': 'https://www.dovepress.com/getfile.php?fileID=81030', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9148574, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract microglia are tissue-resident macrophages of the central nervous system (cns). in the cns, microglia play an important role in the monitoring and intervention of synaptic and neuron-level activities. interventions targeting microglia have been shown to improve the prognosis of various neurological diseases. recently, studies have observed the activation of microglia in different cardiovascular diseases. in addition, different approaches that regulate the activity of microglia have been shown to modulate the incidence and progression of cardiovascular diseases. the change in autonomic nervous system activity after neuroinflammation may be a potential intermediate link between microglia and cardiovascular diseases. here, in this review, we will discuss recent updates on the regulatory role of microglia in hypertension, myocardial infarction and ischemia/reperfusion injury. we propose that microglia serve as neuroimmune modulators and potential targets for cardiovascular diseases.",https://www.dovepress.com/getfile.php?fileID=81030
6e1ecb995d211071606eaa9d21650a8d007d8613,China cardiovascular diseases report 2018: an updated summary,"Rapid socioeconomic progress has greatly affected the lifestyle in China. Consequently, owing to lifestyle changes, urbanization, and accelerated population aging, the risk of cardiovascular diseases (CVD) has increased. The incidence of CVD has been increasing continuously and this upward trend is projected to continue in the next decade. The growing burden of CVD has become a major public health issue. Accordingly, since 2005, the National Center for Cardiovascular Diseases of China has directed experts in cardiology, neurology, nephrology, diabetes, epidemiology, community healthcare, health economics, biostatistics, and other related fields to prepare the annual Report on Cardiovascular Diseases in China. This report aims to provide a timely review of the growing epidemic of CVD in the country as well as to assess the progress made in its prevention and control. We present herein an updated summary of the Report on Cardiovascular Diseases in China 2018 that includes trends in CVD, the morbidity and mortality of CVD, risk factor assessment, health resources for CVD, and a profile of medical expenditure.",2020,"[{'authorId': '2109642943', 'name': 'Li-Yuan Ma'}, {'authorId': '2109820972', 'name': 'Wei-wei Chen'}, {'authorId': '145816531', 'name': 'R. Gao'}, {'authorId': '2109292057', 'name': 'Li-sheng Liu'}, {'authorId': '4267324', 'name': 'Man-lu Zhu'}, {'authorId': '2108096758', 'name': 'Yong-jun Wang'}, {'authorId': '2117988620', 'name': 'Zhaoying Wu'}, {'authorId': '1897190', 'name': 'Haiyang Li'}, {'authorId': '153210550', 'name': 'D. Gu'}, {'authorId': '47796030', 'name': 'Yuejin Yang'}, {'authorId': '143732445', 'name': 'Zhe Zheng'}, {'authorId': '47291117', 'name': 'Sheng-Shou Hu'}]","{'url': '', 'status': None, 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7008101, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","rapid socioeconomic progress has greatly affected the lifestyle in china. consequently, owing to lifestyle changes, urbanization, and accelerated population aging, the risk of cardiovascular diseases (cvd) has increased. the incidence of cvd has been increasing continuously and this upward trend is projected to continue in the next decade. the growing burden of cvd has become a major public health issue. accordingly, since 2005, the national center for cardiovascular diseases of china has directed experts in cardiology, neurology, nephrology, diabetes, epidemiology, community healthcare, health economics, biostatistics, and other related fields to prepare the annual report on cardiovascular diseases in china. this report aims to provide a timely review of the growing epidemic of cvd in the country as well as to assess the progress made in its prevention and control. we present herein an updated summary of the report on cardiovascular diseases in china 2018 that includes trends in cvd, the morbidity and mortality of cvd, risk factor assessment, health resources for cvd, and a profile of medical expenditure.",
257d4e49b7b006c76ae94c62815f6726fb020f37,Report on Cardiovascular Health and Diseases in China 2023: An Updated Summary.,"Since 1990, China has made considerable progress in resolving the problem of ""treatment difficulty"" of cardiovascular diseases (CVD). The prevalent unhealthy lifestyle among Chinese residents has exposed a massive proportion of the population to CVD risk factors, and this situation is further worsened due to the accelerated aging population in China. CVD remains one of the greatest threats to the health of Chinese residents. In terms of the proportions of disease mortality among urban and rural residents in China, CVD has persistently ranked first. In 2021, CVD accounted for 48.98% and 47.35% of deaths in rural and urban areas, respectively. Two out of every five deaths can be attributed to CVD. To implement a national policy ""focusing on the primary health institute and emphasizing prevention"" and truly achieve a shift of CVD prevention and treatment from hospitals to communities, the National Center for Cardiovascular Diseases has organized experts from relevant fields across China to compile the ""Report on Cardiovascular Health and Diseases in China"" annually since 2005. The 2024 report is established based on representative, published, and high-quality big-data research results from cross-sectional and cohort population epidemiological surveys, randomized controlled clinical trials, large sample registry studies, and typical community prevention and treatment cases, along with data from some projects undertaken by the National Center for Cardiovascular Diseases. These firsthand data not only enrich the content of the current report but also provide a more timely and comprehensive reflection of the status of CVD prevention and treatment in China.",2024,"[{'authorId': None, 'name': 'National Center For Cardiovascular Diseases The Writing Com'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3967/bes2024.162?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3967/bes2024.162, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","since 1990, china has made considerable progress in resolving the problem of ""treatment difficulty"" of cardiovascular diseases (cvd). the prevalent unhealthy lifestyle among chinese residents has exposed a massive proportion of the population to cvd risk factors, and this situation is further worsened due to the accelerated aging population in china. cvd remains one of the greatest threats to the health of chinese residents. in terms of the proportions of disease mortality among urban and rural residents in china, cvd has persistently ranked first. in 2021, cvd accounted for 48.98% and 47.35% of deaths in rural and urban areas, respectively. two out of every five deaths can be attributed to cvd. to implement a national policy ""focusing on the primary health institute and emphasizing prevention"" and truly achieve a shift of cvd prevention and treatment from hospitals to communities, the national center for cardiovascular diseases has organized experts from relevant fields across china to compile the ""report on cardiovascular health and diseases in china"" annually since 2005. the 2024 report is established based on representative, published, and high-quality big-data research results from cross-sectional and cohort population epidemiological surveys, randomized controlled clinical trials, large sample registry studies, and typical community prevention and treatment cases, along with data from some projects undertaken by the national center for cardiovascular diseases. these firsthand data not only enrich the content of the current report but also provide a more timely and comprehensive reflection of the status of cvd prevention and treatment in china.",
1fcbe5e076aa255d6c0f82126765960bcc8bcee5,Role of Endothelial Dysfunction in Cardiovascular Diseases: The Link Between Inflammation and Hydrogen Sulfide,"Endothelial cells are important constituents of blood vessels that play critical roles in cardiovascular homeostasis by regulating blood fluidity and fibrinolysis, vascular tone, angiogenesis, monocyte/leukocyte adhesion, and platelet aggregation. The normal vascular endothelium is taken as a gatekeeper of cardiovascular health, whereas abnormality of vascular endothelium is a major contributor to a plethora of cardiovascular ailments, such as atherosclerosis, aging, hypertension, obesity, and diabetes. Endothelial dysfunction is characterized by imbalanced vasodilation and vasoconstriction, elevated reactive oxygen species (ROS), and proinflammatory factors, as well as deficiency of nitric oxide (NO) bioavailability. The occurrence of endothelial dysfunction disrupts the endothelial barrier permeability that is a part of inflammatory response in the development of cardiovascular diseases. As such, abrogation of endothelial cell activation/inflammation is of clinical relevance. Recently, hydrogen sulfide (H2S), an entry as a gasotransmitter, exerts diverse biological effects through acting on various targeted signaling pathways. Within the cardiovascular system, the formation of H2S is detected in smooth muscle cells, vascular endothelial cells, and cardiomyocytes. Disrupted H2S bioavailability is postulated to be a new indicator for endothelial cell inflammation and its associated endothelial dysfunction. In this review, we will summarize recent advances about the roles of H2S in endothelial cell homeostasis, especially under pathological conditions, and discuss its putative therapeutic applications in endothelial inflammation-associated cardiovascular disorders.",2020,"[{'authorId': '2433182', 'name': 'Hai-Jian Sun'}, {'authorId': '7806591', 'name': 'Zhi-yuan Wu'}, {'authorId': '151490113', 'name': 'Xiaowei Nie'}, {'authorId': '5354106', 'name': 'J. Bian'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fphar.2019.01568/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6985156, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","endothelial cells are important constituents of blood vessels that play critical roles in cardiovascular homeostasis by regulating blood fluidity and fibrinolysis, vascular tone, angiogenesis, monocyte/leukocyte adhesion, and platelet aggregation. the normal vascular endothelium is taken as a gatekeeper of cardiovascular health, whereas abnormality of vascular endothelium is a major contributor to a plethora of cardiovascular ailments, such as atherosclerosis, aging, hypertension, obesity, and diabetes. endothelial dysfunction is characterized by imbalanced vasodilation and vasoconstriction, elevated reactive oxygen species (ros), and proinflammatory factors, as well as deficiency of nitric oxide (no) bioavailability. the occurrence of endothelial dysfunction disrupts the endothelial barrier permeability that is a part of inflammatory response in the development of cardiovascular diseases. as such, abrogation of endothelial cell activation/inflammation is of clinical relevance. recently, hydrogen sulfide (h2s), an entry as a gasotransmitter, exerts diverse biological effects through acting on various targeted signaling pathways. within the cardiovascular system, the formation of h2s is detected in smooth muscle cells, vascular endothelial cells, and cardiomyocytes. disrupted h2s bioavailability is postulated to be a new indicator for endothelial cell inflammation and its associated endothelial dysfunction. in this review, we will summarize recent advances about the roles of h2s in endothelial cell homeostasis, especially under pathological conditions, and discuss its putative therapeutic applications in endothelial inflammation-associated cardiovascular disorders.",https://www.frontiersin.org/articles/10.3389/fphar.2019.01568/pdf
213711ee5e08f9dc35bd2d3e661a3c4a98a0a9a1,Biomarkers of endothelial activation and dysfunction in cardiovascular diseases.,"Endothelial activation and dysfunction is an important contributor to atherosclerosis, cardiovascular diseases and cardiorenal syndrome. Endothelial dysfunction is also linked with metabolic syndrome and type II diabetes. The search for specific and sensitive biomarkers of endothelial activation and dysfunction may have important clinical implications. This review pinpoints the differences in biomarkers between endothelial activation and endothelial dysfunction in cardiovascular diseases, and then briefly describes the most relevant biomarkers of endothelial activation. Biomarkers of endothelial activation include endothelial adhesion molecules, cytokines, C-reactive protein, CD62E+/E-selectin activated endothelial microparticles, oxidation of low density lipoproteins, asymmetric dimethylarginine and endocan. This review also presents an update on the novel biomarkers of endothelial dysfunction, such as matrix metalloproteinases (e.g., MMP-7, MMP-9), ANGPTL2, endogdlin, annexin V+ endothelial apoptotic microparticles, and serum homocysteine. Finally, this review emphasizes the limitations of biomarkers of endothelial activation and dysfunction in clinical setting.",2022,"[{'authorId': '2155662669', 'name': 'Jun Zhang'}]","{'url': 'https://www.imrpress.com/journal/RCM/23/2/10.31083/j.rcm2302073/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.31083/j.rcm2302073?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.31083/j.rcm2302073, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","endothelial activation and dysfunction is an important contributor to atherosclerosis, cardiovascular diseases and cardiorenal syndrome. endothelial dysfunction is also linked with metabolic syndrome and type ii diabetes. the search for specific and sensitive biomarkers of endothelial activation and dysfunction may have important clinical implications. this review pinpoints the differences in biomarkers between endothelial activation and endothelial dysfunction in cardiovascular diseases, and then briefly describes the most relevant biomarkers of endothelial activation. biomarkers of endothelial activation include endothelial adhesion molecules, cytokines, c-reactive protein, cd62e+/e-selectin activated endothelial microparticles, oxidation of low density lipoproteins, asymmetric dimethylarginine and endocan. this review also presents an update on the novel biomarkers of endothelial dysfunction, such as matrix metalloproteinases (e.g., mmp-7, mmp-9), angptl2, endogdlin, annexin v+ endothelial apoptotic microparticles, and serum homocysteine. finally, this review emphasizes the limitations of biomarkers of endothelial activation and dysfunction in clinical setting.",https://www.imrpress.com/journal/RCM/23/2/10.31083/j.rcm2302073/pdf
53ea977693c5f66cc9c66dd5bd1674966ec17db4,Prevalence and impact of cardiovascular metabolic diseases on COVID-19 in China,"Background Studies have reminded that cardiovascular metabolic comorbidities made patients more susceptible to suffer 2019 novel corona virus (2019-nCoV) disease (COVID-19), and exacerbated the infection. The aim of this analysis is to determine the association of cardiovascular metabolic diseases with the development of COVID-19. Methods A meta-analysis of eligible studies that summarized the prevalence of cardiovascular metabolic diseases in COVID-19 and compared the incidences of the comorbidities in ICU/severe and non-ICU/severe patients was performed. Embase and PubMed were searched for relevant studies. Results A total of six studies with 1527 patients were included in this analysis. The proportions of hypertension, cardia-cerebrovascular disease and diabetes in patients with COVID-19 were 17.1%, 16.4% and 9.7%, respectively. The incidences of hypertension, cardia-cerebrovascular diseases and diabetes were about twofolds, threefolds and twofolds, respectively, higher in ICU/severe cases than in their non-ICU/severe counterparts. At least 8.0% patients with COVID-19 suffered the acute cardiac injury. The incidence of acute cardiac injury was about 13 folds higher in ICU/severe patients compared with the non-ICU/severe patients. Conclusion Patients with previous cardiovascular metabolic diseases may face a greater risk of developing into the severe condition and the comorbidities can also greatly affect the prognosis of the COVID-19. On the other hand, COVID-19 can, in turn, aggravate the damage to the heart.",2020,"[{'authorId': '2155882731', 'name': 'Bo Li'}, {'authorId': '2143852743', 'name': 'Jing Yang'}, {'authorId': '1716215559', 'name': 'Faming Zhao'}, {'authorId': '2071032597', 'name': 'L. Zhi'}, {'authorId': '2155142063', 'name': 'Xiqian Wang'}, {'authorId': '2146017434', 'name': 'Lin Liu'}, {'authorId': '1561525885', 'name': 'Zhaohui Bi'}, {'authorId': '2155133035', 'name': 'Yunhe Zhao'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s00392-020-01626-9.pdf', 'status': 'HYBRID', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7087935, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","background studies have reminded that cardiovascular metabolic comorbidities made patients more susceptible to suffer 2019 novel corona virus (2019-ncov) disease (covid-19), and exacerbated the infection. the aim of this analysis is to determine the association of cardiovascular metabolic diseases with the development of covid-19. methods a meta-analysis of eligible studies that summarized the prevalence of cardiovascular metabolic diseases in covid-19 and compared the incidences of the comorbidities in icu/severe and non-icu/severe patients was performed. embase and pubmed were searched for relevant studies. results a total of six studies with 1527 patients were included in this analysis. the proportions of hypertension, cardia-cerebrovascular disease and diabetes in patients with covid-19 were 17.1%, 16.4% and 9.7%, respectively. the incidences of hypertension, cardia-cerebrovascular diseases and diabetes were about twofolds, threefolds and twofolds, respectively, higher in icu/severe cases than in their non-icu/severe counterparts. at least 8.0% patients with covid-19 suffered the acute cardiac injury. the incidence of acute cardiac injury was about 13 folds higher in icu/severe patients compared with the non-icu/severe patients. conclusion patients with previous cardiovascular metabolic diseases may face a greater risk of developing into the severe condition and the comorbidities can also greatly affect the prognosis of the covid-19. on the other hand, covid-19 can, in turn, aggravate the damage to the heart.",https://link.springer.com/content/pdf/10.1007/s00392-020-01626-9.pdf
a683527ba35b5e5ef5561d24ec5ec4173d53958b,Development of Innovative Biomaterials and Devices for the Treatment of Cardiovascular Diseases,"Cardiovascular diseases have become the leading cause of death worldwide. The increasing burden of cardiovascular diseases has become a major public health problem and how to carry out efficient and reliable treatment of cardiovascular diseases has become an urgent global problem to be solved. Recently, implantable biomaterials and devices, especially minimally invasive interventional ones, such as vascular stents, artificial heart valves, bioprosthetic cardiac occluders, artificial graft cardiac patches, atrial shunts, and injectable hydrogels against heart failure, have become the most effective means in the treatment of cardiovascular diseases. Herein, an overview of the challenges and research frontier of innovative biomaterials and devices for the treatment of cardiovascular diseases is provided, and their future development directions are discussed.",2022,"[{'authorId': '7708450', 'name': 'Yunbing Wang'}, {'authorId': '11369359', 'name': 'Gaocan Li'}, {'authorId': '1810705893', 'name': 'Li Yang'}, {'authorId': '5535906', 'name': 'Rifang Luo'}, {'authorId': '47447527', 'name': 'Gaoyang Guo'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/adma.202201971?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/adma.202201971, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases have become the leading cause of death worldwide. the increasing burden of cardiovascular diseases has become a major public health problem and how to carry out efficient and reliable treatment of cardiovascular diseases has become an urgent global problem to be solved. recently, implantable biomaterials and devices, especially minimally invasive interventional ones, such as vascular stents, artificial heart valves, bioprosthetic cardiac occluders, artificial graft cardiac patches, atrial shunts, and injectable hydrogels against heart failure, have become the most effective means in the treatment of cardiovascular diseases. herein, an overview of the challenges and research frontier of innovative biomaterials and devices for the treatment of cardiovascular diseases is provided, and their future development directions are discussed.",
252982f8f76238023dde12cd9b3d3d2cfc45c649,Cellular Senescence in Cardiovascular Diseases: A Systematic Review,"Aging is a prominent risk factor for cardiovascular diseases, which is the leading cause of death around the world. Recently, cellular senescence has received potential attention as a promising target in preventing cardiovascular diseases, including acute myocardial infarction, atherosclerosis, cardiac aging, pressure overload-induced hypertrophy, heart regeneration, hypertension, and abdominal aortic aneurysm. Here, we discuss the mechanisms underlying cellular senescence and describe the involvement of senescent cardiovascular cells (including cardiomyocytes, endothelial cells, vascular smooth muscle cells, fibroblasts/myofibroblasts and T cells) in age-related cardiovascular diseases. Then, we highlight the targets (SIRT1 and mTOR) that regulating cellular senescence in cardiovascular disorders. Furthermore, we review the evidence that senescent cells can exert both beneficial and detrimental implications in cardiovascular diseases on a context-dependent manner. Finally, we summarize the emerging pro-senescent or anti-senescent interventions and discuss their therapeutic potential in preventing cardiovascular diseases.",2022,"[{'authorId': '46622726', 'name': 'Can Hu'}, {'authorId': '2149171687', 'name': 'Xin Zhang'}, {'authorId': '2061263018', 'name': 'Teng Teng'}, {'authorId': '2449605', 'name': 'Zhen-Guo Ma'}, {'authorId': '3389289', 'name': 'Q. Tang'}]","{'url': 'https://www.aginganddisease.org/EN/PDF/10.14336/AD.2021.0927', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8782554, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","aging is a prominent risk factor for cardiovascular diseases, which is the leading cause of death around the world. recently, cellular senescence has received potential attention as a promising target in preventing cardiovascular diseases, including acute myocardial infarction, atherosclerosis, cardiac aging, pressure overload-induced hypertrophy, heart regeneration, hypertension, and abdominal aortic aneurysm. here, we discuss the mechanisms underlying cellular senescence and describe the involvement of senescent cardiovascular cells (including cardiomyocytes, endothelial cells, vascular smooth muscle cells, fibroblasts/myofibroblasts and t cells) in age-related cardiovascular diseases. then, we highlight the targets (sirt1 and mtor) that regulating cellular senescence in cardiovascular disorders. furthermore, we review the evidence that senescent cells can exert both beneficial and detrimental implications in cardiovascular diseases on a context-dependent manner. finally, we summarize the emerging pro-senescent or anti-senescent interventions and discuss their therapeutic potential in preventing cardiovascular diseases.",https://www.aginganddisease.org/EN/PDF/10.14336/AD.2021.0927
cb493a53bdbb7f909387f0c67a3e855f096abcfa,The Role of Interleukin-6 Family Members in Cardiovascular Diseases,"Cardiovascular disease is one of the main causes of human mortality. Cytokines play crucial roles in the development of cardiovascular disease. Interleukin (IL)-6 family members are a series of cytokines, including IL-6, IL-11, IL-30, IL-31, OSM, LIF, CNTF, CT-1, CT-2, and CLC, that regulate multiple biological effects. Experimental and clinical evidence shows that IL-6 family members are closely related to cardiovascular diseases such as atherosclerosis, hypertension, aortic dissection, cardiac fibrosis, and cardiomyopathy. This review mainly discusses the role of IL-6 family members in cardiovascular disease for the sake of identifying possible intervention targets for cardiovascular disease prevention and treatment.",2022,"[{'authorId': '2048483822', 'name': 'Yongqi Feng'}, {'authorId': '2383665', 'name': 'Di Ye'}, {'authorId': '2118452969', 'name': 'Zhen Wang'}, {'authorId': '2113794155', 'name': 'H. Pan'}, {'authorId': '24335163', 'name': 'Xiyi Lu'}, {'authorId': '5635528', 'name': 'Menglong Wang'}, {'authorId': '50125598', 'name': 'Yao Xu'}, {'authorId': '46380651', 'name': 'Junping Yu'}, {'authorId': '1519052221', 'name': 'Jishou Zhang'}, {'authorId': '48886620', 'name': 'Mengmeng Zhao'}, {'authorId': '2051949925', 'name': 'Shuwan Xu'}, {'authorId': '2075363102', 'name': 'Wei Pan'}, {'authorId': '2069534442', 'name': 'Zheng Yin'}, {'authorId': '94722736', 'name': 'Jing Ye'}, {'authorId': '145121531', 'name': 'J. Wan'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fcvm.2022.818890/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8983865, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular disease is one of the main causes of human mortality. cytokines play crucial roles in the development of cardiovascular disease. interleukin (il)-6 family members are a series of cytokines, including il-6, il-11, il-30, il-31, osm, lif, cntf, ct-1, ct-2, and clc, that regulate multiple biological effects. experimental and clinical evidence shows that il-6 family members are closely related to cardiovascular diseases such as atherosclerosis, hypertension, aortic dissection, cardiac fibrosis, and cardiomyopathy. this review mainly discusses the role of il-6 family members in cardiovascular disease for the sake of identifying possible intervention targets for cardiovascular disease prevention and treatment.",https://www.frontiersin.org/articles/10.3389/fcvm.2022.818890/pdf
eaec0094a43117e7ddcfb3745d5ac17a99230530,NAFLD and cardiovascular diseases: a clinical review,"Non-alcoholic fatty liver DISEASE (NAFLD) is the most common chronic liver disease in Western countries and affects approximately 25% of the adult population. Since NAFLD is frequently associated with further metabolic comorbidities such as obesity, type 2 diabetes mellitus, or dyslipidemia, it is generally considered as the hepatic manifestation of the metabolic syndrome. In addition to its potential to cause liver-related morbidity and mortality, NAFLD is also associated with subclinical and clinical cardiovascular disease (CVD). Growing evidence indicates that patients with NAFLD are at substantial risk for the development of hypertension, coronary heart disease, cardiomyopathy, and cardiac arrhythmias, which clinically result in increased cardiovascular morbidity and mortality. The natural history of NAFLD is variable and the vast majority of patients will not progress from simple steatosis to fibrosis and end stage liver disease. However, patients with progressive forms of NAFLD, including non-alcoholic steatohepatitis (NASH) and/or advanced fibrosis, as well as NAFLD patients with concomitant types 2 diabetes are at highest risk for CVD. This review describes the underlying pathophysiological mechanisms linking NAFLD and CVD, discusses the role of NAFLD as a metabolic dysfunction associated cardiovascular risk factor, and focuses on common cardiovascular manifestations in NAFLD patients.",2020,"[{'authorId': '48828321', 'name': 'P. Kasper'}, {'authorId': '2111202337', 'name': 'Anna Martin'}, {'authorId': '2149915483', 'name': 'S. Lang'}, {'authorId': '4402910', 'name': 'F. Kütting'}, {'authorId': '4864726', 'name': 'T. Goeser'}, {'authorId': '1900121', 'name': 'M. Demir'}, {'authorId': '89778772', 'name': 'H. Steffen'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s00392-020-01709-7.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8238775, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","non-alcoholic fatty liver disease (nafld) is the most common chronic liver disease in western countries and affects approximately 25% of the adult population. since nafld is frequently associated with further metabolic comorbidities such as obesity, type 2 diabetes mellitus, or dyslipidemia, it is generally considered as the hepatic manifestation of the metabolic syndrome. in addition to its potential to cause liver-related morbidity and mortality, nafld is also associated with subclinical and clinical cardiovascular disease (cvd). growing evidence indicates that patients with nafld are at substantial risk for the development of hypertension, coronary heart disease, cardiomyopathy, and cardiac arrhythmias, which clinically result in increased cardiovascular morbidity and mortality. the natural history of nafld is variable and the vast majority of patients will not progress from simple steatosis to fibrosis and end stage liver disease. however, patients with progressive forms of nafld, including non-alcoholic steatohepatitis (nash) and/or advanced fibrosis, as well as nafld patients with concomitant types 2 diabetes are at highest risk for cvd. this review describes the underlying pathophysiological mechanisms linking nafld and cvd, discusses the role of nafld as a metabolic dysfunction associated cardiovascular risk factor, and focuses on common cardiovascular manifestations in nafld patients.",https://link.springer.com/content/pdf/10.1007/s00392-020-01709-7.pdf
b6ef8dc54644d1d04623936d68864aeb484289bf,Machine learning prediction in cardiovascular diseases: a meta-analysis,"Several machine learning (ML) algorithms have been increasingly utilized for cardiovascular disease prediction. We aim to assess and summarize the overall predictive ability of ML algorithms in cardiovascular diseases. A comprehensive search strategy was designed and executed within the MEDLINE, Embase, and Scopus databases from database inception through March 15, 2019. The primary outcome was a composite of the predictive ability of ML algorithms of coronary artery disease, heart failure, stroke, and cardiac arrhythmias. Of 344 total studies identified, 103 cohorts, with a total of 3,377,318 individuals, met our inclusion criteria. For the prediction of coronary artery disease, boosting algorithms had a pooled area under the curve (AUC) of 0.88 (95% CI 0.84–0.91), and custom-built algorithms had a pooled AUC of 0.93 (95% CI 0.85–0.97). For the prediction of stroke, support vector machine (SVM) algorithms had a pooled AUC of 0.92 (95% CI 0.81–0.97), boosting algorithms had a pooled AUC of 0.91 (95% CI 0.81–0.96), and convolutional neural network (CNN) algorithms had a pooled AUC of 0.90 (95% CI 0.83–0.95). Although inadequate studies for each algorithm for meta-analytic methodology for both heart failure and cardiac arrhythmias because the confidence intervals overlap between different methods, showing no difference, SVM may outperform other algorithms in these areas. The predictive ability of ML algorithms in cardiovascular diseases is promising, particularly SVM and boosting algorithms. However, there is heterogeneity among ML algorithms in terms of multiple parameters. This information may assist clinicians in how to interpret data and implement optimal algorithms for their dataset.",2020,"[{'authorId': '8633608', 'name': 'Chayakrit Krittanawong'}, {'authorId': '8633608', 'name': 'Chayakrit Krittanawong'}, {'authorId': '2073655551', 'name': 'H. H. Virk'}, {'authorId': '1697130', 'name': 'S. Bangalore'}, {'authorId': '2118452583', 'name': 'Zhen Wang'}, {'authorId': '2118452583', 'name': 'Zhen Wang'}, {'authorId': '10776200', 'name': 'Kipp W. Johnson'}, {'authorId': '71241485', 'name': 'R. Pinotti'}, {'authorId': '46702423', 'name': 'Hongju Zhang'}, {'authorId': '66470869', 'name': 'Scott L. Kaplin'}, {'authorId': '146287382', 'name': 'B. Narasimhan'}, {'authorId': '65754217', 'name': 'T. Kitai'}, {'authorId': '153543987', 'name': 'U. Baber'}, {'authorId': '1949072', 'name': 'J. Halperin'}, {'authorId': '1434920526', 'name': 'W. Tang'}]","{'url': 'https://www.nature.com/articles/s41598-020-72685-1.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7525515, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","several machine learning (ml) algorithms have been increasingly utilized for cardiovascular disease prediction. we aim to assess and summarize the overall predictive ability of ml algorithms in cardiovascular diseases. a comprehensive search strategy was designed and executed within the medline, embase, and scopus databases from database inception through march 15, 2019. the primary outcome was a composite of the predictive ability of ml algorithms of coronary artery disease, heart failure, stroke, and cardiac arrhythmias. of 344 total studies identified, 103 cohorts, with a total of 3,377,318 individuals, met our inclusion criteria. for the prediction of coronary artery disease, boosting algorithms had a pooled area under the curve (auc) of 0.88 (95% ci 0.84–0.91), and custom-built algorithms had a pooled auc of 0.93 (95% ci 0.85–0.97). for the prediction of stroke, support vector machine (svm) algorithms had a pooled auc of 0.92 (95% ci 0.81–0.97), boosting algorithms had a pooled auc of 0.91 (95% ci 0.81–0.96), and convolutional neural network (cnn) algorithms had a pooled auc of 0.90 (95% ci 0.83–0.95). although inadequate studies for each algorithm for meta-analytic methodology for both heart failure and cardiac arrhythmias because the confidence intervals overlap between different methods, showing no difference, svm may outperform other algorithms in these areas. the predictive ability of ml algorithms in cardiovascular diseases is promising, particularly svm and boosting algorithms. however, there is heterogeneity among ml algorithms in terms of multiple parameters. this information may assist clinicians in how to interpret data and implement optimal algorithms for their dataset.",https://www.nature.com/articles/s41598-020-72685-1.pdf
a167010d6f829205a073f88d61a95a55b851ed20,"Herbal Medicine for Cardiovascular Diseases: Efficacy, Mechanisms, and Safety","Cardiovascular diseases (CVDs) are a significant health burden with an ever-increasing prevalence. They remain the leading causes of morbidity and mortality worldwide. The use of medicinal herbs continues to be an alternative treatment approach for several diseases including CVDs. Currently, there is an unprecedented drive for the use of herbal preparations in modern medicinal systems. This drive is powered by several aspects, prime among which are their cost-effective therapeutic promise compared to standard modern therapies and the general belief that they are safe. Nonetheless, the claimed safety of herbal preparations yet remains to be properly tested. Consequently, public awareness should be raised regarding medicinal herbs safety, toxicity, potentially life-threatening adverse effects, and possible herb–drug interactions. Over the years, laboratory data have shown that medicinal herbs may have therapeutic value in CVDs as they can interfere with several CVD risk factors. Accordingly, there have been many attempts to move studies on medicinal herbs from the bench to the bedside, in order to effectively employ herbs in CVD treatments. In this review, we introduce CVDs and their risk factors. Then we overview the use of herbs for disease treatment in general and CVDs in particular. Further, data on the ethnopharmacological therapeutic potentials and medicinal properties against CVDs of four widely used plants, namely Ginseng, Ginkgo biloba, Ganoderma lucidum, and Gynostemma pentaphyllum, are gathered and reviewed. In particular, the employment of these four plants in the context of CVDs, such as myocardial infarction, hypertension, peripheral vascular diseases, coronary heart disease, cardiomyopathies, and dyslipidemias has been reviewed, analyzed, and critically discussed. We also endeavor to document the recent studies aimed to dissect the cellular and molecular cardio-protective mechanisms of the four plants, using recently reported in vitro and in vivo studies. Finally, we reviewed and reported the results of the recent clinical trials that have been conducted using these four medicinal herbs with special emphasis on their efficacy, safety, and toxicity.",2020,"[{'authorId': '4969458', 'name': 'Abdullah A. Shaito'}, {'authorId': '14040675', 'name': 'D. T. Thuan'}, {'authorId': '11306857', 'name': 'H. T. Phu'}, {'authorId': '2118936910', 'name': 'Thi Hieu Dung Nguyen'}, {'authorId': '1577416910', 'name': 'Hiba Hasan'}, {'authorId': '1484923944', 'name': 'S. Halabi'}, {'authorId': '1383475204', 'name': 'Samar Abdelhady'}, {'authorId': '5099925', 'name': 'Gheyath K Nasrallah'}, {'authorId': '6396195', 'name': 'A. Eid'}, {'authorId': '145352619', 'name': 'G. Pintus'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fphar.2020.00422/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7155419, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases (cvds) are a significant health burden with an ever-increasing prevalence. they remain the leading causes of morbidity and mortality worldwide. the use of medicinal herbs continues to be an alternative treatment approach for several diseases including cvds. currently, there is an unprecedented drive for the use of herbal preparations in modern medicinal systems. this drive is powered by several aspects, prime among which are their cost-effective therapeutic promise compared to standard modern therapies and the general belief that they are safe. nonetheless, the claimed safety of herbal preparations yet remains to be properly tested. consequently, public awareness should be raised regarding medicinal herbs safety, toxicity, potentially life-threatening adverse effects, and possible herb–drug interactions. over the years, laboratory data have shown that medicinal herbs may have therapeutic value in cvds as they can interfere with several cvd risk factors. accordingly, there have been many attempts to move studies on medicinal herbs from the bench to the bedside, in order to effectively employ herbs in cvd treatments. in this review, we introduce cvds and their risk factors. then we overview the use of herbs for disease treatment in general and cvds in particular. further, data on the ethnopharmacological therapeutic potentials and medicinal properties against cvds of four widely used plants, namely ginseng, ginkgo biloba, ganoderma lucidum, and gynostemma pentaphyllum, are gathered and reviewed. in particular, the employment of these four plants in the context of cvds, such as myocardial infarction, hypertension, peripheral vascular diseases, coronary heart disease, cardiomyopathies, and dyslipidemias has been reviewed, analyzed, and critically discussed. we also endeavor to document the recent studies aimed to dissect the cellular and molecular cardio-protective mechanisms of the four plants, using recently reported in vitro and in vivo studies. finally, we reviewed and reported the results of the recent clinical trials that have been conducted using these four medicinal herbs with special emphasis on their efficacy, safety, and toxicity.",https://www.frontiersin.org/articles/10.3389/fphar.2020.00422/pdf
5e412d9d7909b7039ea780068f5a7ea4b91e1a15,Cardiovascular Risk Factors and Physical Activity for the Prevention of Cardiovascular Diseases in the Elderly,"Cardiovascular diseases create an important burden on the public health systems, especially in the elderly, mostly because this group of patients frequently suffer from multiple comorbidities. Accumulating cardiovascular risk factors during their lifetime has a detrimental effect on an older adult‘s health status. The modifiable and non-modifiable cardiovascular risk factors are very diverse, and are frequently in a close relationship with the metabolic comorbidities of the elderly, mainly obesity and Diabetes Mellitus. In this review, we aim to present the most important cardiovascular risk factors which link aging and cardiovascular diseases, starting from the pathophysiological links between these factors and the aging process. Next, we will further review the main interconnections between obesity and Diabetes Mellitus and cardiovascular diseases of the elderly. Lastly, we consider the most important aspects related to prevention through lifestyle changes and physical activity on the occurrence of cardiovascular diseases in the elderly.",2021,"[{'authorId': '5634118', 'name': 'L. Ciumărnean'}, {'authorId': '23545594', 'name': 'M. Milaciu'}, {'authorId': '4160430', 'name': 'V. Negrean'}, {'authorId': '5965418', 'name': 'O. Orășan'}, {'authorId': '3048177', 'name': 'Ș. Vesa'}, {'authorId': '2147461844', 'name': 'Octavia Sălăgean'}, {'authorId': '26895466', 'name': 'S. Iluț'}, {'authorId': '6126750', 'name': 'S. Vlaicu'}]","{'url': 'https://www.mdpi.com/1660-4601/19/1/207/pdf?version=1640423673', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8751147, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases create an important burden on the public health systems, especially in the elderly, mostly because this group of patients frequently suffer from multiple comorbidities. accumulating cardiovascular risk factors during their lifetime has a detrimental effect on an older adult‘s health status. the modifiable and non-modifiable cardiovascular risk factors are very diverse, and are frequently in a close relationship with the metabolic comorbidities of the elderly, mainly obesity and diabetes mellitus. in this review, we aim to present the most important cardiovascular risk factors which link aging and cardiovascular diseases, starting from the pathophysiological links between these factors and the aging process. next, we will further review the main interconnections between obesity and diabetes mellitus and cardiovascular diseases of the elderly. lastly, we consider the most important aspects related to prevention through lifestyle changes and physical activity on the occurrence of cardiovascular diseases in the elderly.",https://www.mdpi.com/1660-4601/19/1/207/pdf?version=1640423673
8db848183320ec4754f01cfa80822193dba4d7c4,Genetic Testing for Inherited Cardiovascular Diseases: A Scientific Statement From the American Heart Association.,"Advances in human genetics are improving the understanding of a variety of inherited cardiovascular diseases, including cardiomyopathies, arrhythmic disorders, vascular disorders, and lipid disorders such as familial hypercholesterolemia. However, not all cardiovascular practitioners are fully aware of the utility and potential pitfalls of incorporating genetic test results into the care of patients and their families. This statement summarizes current best practices with respect to genetic testing and its implications for the management of inherited cardiovascular diseases.",2020,"[{'authorId': '117290206', 'name': 'K. Musunuru'}, {'authorId': '4960982', 'name': 'R. Hershberger'}, {'authorId': '2253398427', 'name': 'S. Day'}, {'authorId': '2259526952', 'name': 'N. J. Klinedinst'}, {'authorId': '4231194', 'name': 'A. Landstrom'}, {'authorId': '143705689', 'name': 'V. Parikh'}, {'authorId': '35171429', 'name': 'Siddharth K. Prakash'}, {'authorId': '145729547', 'name': 'C. Semsarian'}, {'authorId': '31246491', 'name': 'A. Sturm'}]","{'url': 'https://www.ahajournals.org/doi/pdf/10.1161/HCG.0000000000000067', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1161/HCG.0000000000000067?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1161/HCG.0000000000000067, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","advances in human genetics are improving the understanding of a variety of inherited cardiovascular diseases, including cardiomyopathies, arrhythmic disorders, vascular disorders, and lipid disorders such as familial hypercholesterolemia. however, not all cardiovascular practitioners are fully aware of the utility and potential pitfalls of incorporating genetic test results into the care of patients and their families. this statement summarizes current best practices with respect to genetic testing and its implications for the management of inherited cardiovascular diseases.",https://www.ahajournals.org/doi/pdf/10.1161/HCG.0000000000000067
1c842191bb9d94b11f2e2c6d071c220ccc45033e,Oxidative Stress in Cardiovascular Diseases,"Reactive oxygen species (ROS) are subcellular messengers in signal transductions pathways with both beneficial and deleterious roles. ROS are generated as a by-product of mitochondrial respiration or metabolism or by specific enzymes such as superoxide dismutases, glutathione peroxidase, catalase, peroxiredoxins, and myeloperoxidases. Under physiological conditions, the low levels of ROS production are equivalent to their detoxification, playing a major role in cellular signaling and function. In pathological situations, particularly atherosclerosis or hypertension, the release of ROS exceeds endogenous antioxidant capacity, leading to cell death. At cardiovascular levels, oxidative stress is highly implicated in myocardial infarction, ischemia/reperfusion, or heart failure. Here, we will first detail the physiological role of low ROS production in the heart and the vessels. Indeed, ROS are able to regulate multiple cardiovascular functions, such as cell proliferation, migration, and death. Second, we will investigate the implication of oxidative stress in cardiovascular diseases. Then, we will focus on ROS produced by NAPDH oxidase or during endothelial or mitochondrial dysfunction. Given the importance of oxidative stress at the cardiovascular level, antioxidant therapies could be a real benefit. In the last part of this review, we will detail the new therapeutic strategies potentially involved in cardiovascular protection and currently under study.",2020,"[{'authorId': '1398313508', 'name': 'E. Dubois-Deruy'}, {'authorId': '89064638', 'name': 'V. Peugnet'}, {'authorId': '50427615', 'name': 'A. Turkieh'}, {'authorId': '2050294571', 'name': 'F. Pinet'}]","{'url': 'https://www.mdpi.com/2076-3921/9/9/864/pdf?version=1600158335', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7554855, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","reactive oxygen species (ros) are subcellular messengers in signal transductions pathways with both beneficial and deleterious roles. ros are generated as a by-product of mitochondrial respiration or metabolism or by specific enzymes such as superoxide dismutases, glutathione peroxidase, catalase, peroxiredoxins, and myeloperoxidases. under physiological conditions, the low levels of ros production are equivalent to their detoxification, playing a major role in cellular signaling and function. in pathological situations, particularly atherosclerosis or hypertension, the release of ros exceeds endogenous antioxidant capacity, leading to cell death. at cardiovascular levels, oxidative stress is highly implicated in myocardial infarction, ischemia/reperfusion, or heart failure. here, we will first detail the physiological role of low ros production in the heart and the vessels. indeed, ros are able to regulate multiple cardiovascular functions, such as cell proliferation, migration, and death. second, we will investigate the implication of oxidative stress in cardiovascular diseases. then, we will focus on ros produced by napdh oxidase or during endothelial or mitochondrial dysfunction. given the importance of oxidative stress at the cardiovascular level, antioxidant therapies could be a real benefit. in the last part of this review, we will detail the new therapeutic strategies potentially involved in cardiovascular protection and currently under study.",https://www.mdpi.com/2076-3921/9/9/864/pdf?version=1600158335
d616ac5e2320e0392f91e3d9f483c25d838647f9,The therapeutic potential of mesenchymal stem cells for cardiovascular diseases,"Mesenchymal stem cells (MSCs) are derived from a wide range of sources and easily isolated and cultured. MSCs have the capacity for in vitro amplification and self-renewal, low immunogenicity and immunomodulatory properties, and under certain conditions, MSCs can be differentiated into a variety of cells. In the cardiovascular system, MSCs can protect the myocardium by reducing the level of inflammation, promoting the differentiation of myocardial cells around infarct areas and angiogenesis, increasing apoptosis resistance, and inhibiting fibrosis, which are ideal qualities for cardiovascular repair. Preclinical studies have shown that MSCs can be transplanted and improve cardiac repair, but challenges, such as their low rate of migration to the ischemic myocardium, low tissue retention, and low survival rate after transplantation, remain. This article reviews the potential and methods of MSC transplantation in the treatment of cardiovascular diseases (CVDs) and the challenges of the clinical use of MSCs.",2020,"[{'authorId': '1692124112', 'name': 'Yajun Guo'}, {'authorId': '2166756162', 'name': 'Yun-sheng Yu'}, {'authorId': '6555268', 'name': 'Shijun Hu'}, {'authorId': '6073048', 'name': 'Yueqiu Chen'}, {'authorId': '52191835', 'name': 'Zhenya Shen'}]","{'url': 'https://www.nature.com/articles/s41419-020-2542-9.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7214402, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mesenchymal stem cells (mscs) are derived from a wide range of sources and easily isolated and cultured. mscs have the capacity for in vitro amplification and self-renewal, low immunogenicity and immunomodulatory properties, and under certain conditions, mscs can be differentiated into a variety of cells. in the cardiovascular system, mscs can protect the myocardium by reducing the level of inflammation, promoting the differentiation of myocardial cells around infarct areas and angiogenesis, increasing apoptosis resistance, and inhibiting fibrosis, which are ideal qualities for cardiovascular repair. preclinical studies have shown that mscs can be transplanted and improve cardiac repair, but challenges, such as their low rate of migration to the ischemic myocardium, low tissue retention, and low survival rate after transplantation, remain. this article reviews the potential and methods of msc transplantation in the treatment of cardiovascular diseases (cvds) and the challenges of the clinical use of mscs.",https://www.nature.com/articles/s41419-020-2542-9.pdf
f49d4b3b78db200007862f370d7f1d07a58ea57a,The Role of Oxidative Stress in Cardiovascular Aging and Cardiovascular Diseases,"Aging can be seen as process characterized by accumulation of oxidative stress induced damage. Oxidative stress derives from different endogenous and exogenous processes, all of which ultimately lead to progressive loss in tissue and organ structure and functions. The oxidative stress theory of aging expresses itself in age-related diseases. Aging is in fact a primary risk factor for many diseases and in particular for cardiovascular diseases and its derived morbidity and mortality. Here we highlight the role of oxidative stress in age-related cardiovascular aging and diseases. We take into consideration the molecular mechanisms, the structural and functional alterations, and the diseases accompanied to the cardiovascular aging process.",2021,"[{'authorId': '47910649', 'name': 'C. Izzo'}, {'authorId': '1965942741', 'name': 'Paolo Vitillo'}, {'authorId': '46465501', 'name': 'P. Di Pietro'}, {'authorId': '22232572', 'name': 'V. Visco'}, {'authorId': '1500585358', 'name': 'A. Strianese'}, {'authorId': '6221819', 'name': 'N. Virtuoso'}, {'authorId': '12736306', 'name': 'M. Ciccarelli'}, {'authorId': '4923934', 'name': 'G. Galasso'}, {'authorId': '3561658', 'name': 'A. Carrizzo'}, {'authorId': '5377587', 'name': 'C. Vecchione'}]","{'url': 'https://www.mdpi.com/2075-1729/11/1/60/pdf?version=1610710795', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7829951, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","aging can be seen as process characterized by accumulation of oxidative stress induced damage. oxidative stress derives from different endogenous and exogenous processes, all of which ultimately lead to progressive loss in tissue and organ structure and functions. the oxidative stress theory of aging expresses itself in age-related diseases. aging is in fact a primary risk factor for many diseases and in particular for cardiovascular diseases and its derived morbidity and mortality. here we highlight the role of oxidative stress in age-related cardiovascular aging and diseases. we take into consideration the molecular mechanisms, the structural and functional alterations, and the diseases accompanied to the cardiovascular aging process.",https://www.mdpi.com/2075-1729/11/1/60/pdf?version=1610710795
006ecbaa37f7925f86617c1c00fbbdd2b31d0b44,Oxidative Stress in Cardiovascular Diseases: Still a Therapeutic Target?,"Cardiovascular diseases (CVD) are complex entities with heterogenous pathophysiologic mechanisms and increased oxidative stress has been viewed as one of the potential common etiologies. A fine balance between the presence of reactive oxygen species (ROS) and antioxidants is essential for the proper normal functioning of the cell. A basal concentration of ROS is indispensable for the manifestation of cellular functions, whereas excessive levels of ROS cause damage to cellular macromolecules such as DNA, lipids and proteins, eventually leading to necrosis and apoptotic cell death. CVD is the main cause of death worldwide with several conditions being affected by oxidative stress. Increased ROS lead to decreased nitric oxide availability and vasoconstriction, promoting arterial hypertension. ROS also negatively influence myocardial calcium handling, causing arrhythmia, and augment cardiac remodeling by inducing hypertrophic signaling and apoptosis. Finally, ROS have also been shown to promote atherosclerotic plaque formation. This review aims at giving an introduction into oxidative stress in CVD, with special focus on endothelial dysfunction, and then examining in detail the role of oxidative stress in the most prevalent of these diseases. Finally, potential nutraceuticals and diets that might be beneficial in diminishing the burden of oxidative stress in CVD are presented.",2019,"[{'authorId': '40860718', 'name': 'T. Senoner'}, {'authorId': '3767004', 'name': 'W. Dichtl'}]","{'url': 'https://www.mdpi.com/2072-6643/11/9/2090/pdf?version=1567581274', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6769522, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases (cvd) are complex entities with heterogenous pathophysiologic mechanisms and increased oxidative stress has been viewed as one of the potential common etiologies. a fine balance between the presence of reactive oxygen species (ros) and antioxidants is essential for the proper normal functioning of the cell. a basal concentration of ros is indispensable for the manifestation of cellular functions, whereas excessive levels of ros cause damage to cellular macromolecules such as dna, lipids and proteins, eventually leading to necrosis and apoptotic cell death. cvd is the main cause of death worldwide with several conditions being affected by oxidative stress. increased ros lead to decreased nitric oxide availability and vasoconstriction, promoting arterial hypertension. ros also negatively influence myocardial calcium handling, causing arrhythmia, and augment cardiac remodeling by inducing hypertrophic signaling and apoptosis. finally, ros have also been shown to promote atherosclerotic plaque formation. this review aims at giving an introduction into oxidative stress in cvd, with special focus on endothelial dysfunction, and then examining in detail the role of oxidative stress in the most prevalent of these diseases. finally, potential nutraceuticals and diets that might be beneficial in diminishing the burden of oxidative stress in cvd are presented.",https://www.mdpi.com/2072-6643/11/9/2090/pdf?version=1567581274
b5fe59f1b2144f3d6afafc72b2521dc951b519d3,Glutathione Participation in the Prevention of Cardiovascular Diseases,"Cardiovascular diseases (CVD) (such as occlusion of the coronary arteries, hypertensive heart diseases and strokes) are diseases that generate thousands of patients with a high mortality rate worldwide. Many of these cardiovascular pathologies, during their development, generate a state of oxidative stress that leads to a deterioration in the patient’s conditions associated with the generation of reactive oxygen species (ROS) and reactive nitrogen species (RNS). Within these reactive species we find superoxide anion (O2•–), hydroxyl radical (•OH), nitric oxide (NO•), as well as other species of non-free radicals such as hydrogen peroxide (H2O2), hypochlorous acid (HClO) and peroxynitrite (ONOO–). A molecule that actively participates in counteracting the oxidizing effect of reactive species is reduced glutathione (GSH), a tripeptide that is present in all tissues and that its synthesis and/or regeneration is very important to be able to respond to the increase in oxidizing agents. In this review, we will address the role of glutathione, its synthesis in both the heart and the liver, and its importance in preventing or reducing deleterious ROS effects in cardiovascular diseases.",2021,"[{'authorId': '1398942806', 'name': 'D. Matuz-Mares'}, {'authorId': '1398082788', 'name': 'Héctor Riveros-Rosas'}, {'authorId': '2351134639', 'name': 'María Magdalena Vilchis-Landeros'}, {'authorId': '1405415340', 'name': 'H. Vázquez-Meza'}]","{'url': 'https://www.mdpi.com/2076-3921/10/8/1220/pdf?version=1627554157', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8389000, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases (cvd) (such as occlusion of the coronary arteries, hypertensive heart diseases and strokes) are diseases that generate thousands of patients with a high mortality rate worldwide. many of these cardiovascular pathologies, during their development, generate a state of oxidative stress that leads to a deterioration in the patient’s conditions associated with the generation of reactive oxygen species (ros) and reactive nitrogen species (rns). within these reactive species we find superoxide anion (o2•–), hydroxyl radical (•oh), nitric oxide (no•), as well as other species of non-free radicals such as hydrogen peroxide (h2o2), hypochlorous acid (hclo) and peroxynitrite (onoo–). a molecule that actively participates in counteracting the oxidizing effect of reactive species is reduced glutathione (gsh), a tripeptide that is present in all tissues and that its synthesis and/or regeneration is very important to be able to respond to the increase in oxidizing agents. in this review, we will address the role of glutathione, its synthesis in both the heart and the liver, and its importance in preventing or reducing deleterious ros effects in cardiovascular diseases.",https://www.mdpi.com/2076-3921/10/8/1220/pdf?version=1627554157
6180069b974cacde85903551fb00893f05847eea,The role of mitochondrial dynamics in cardiovascular diseases,"The process of mitochondrial dynamics is emerging as a core player in cardiovascular homeostasis. This process refers to the co‐ordinated cycles of biogenesis, fusion, fission and degradation to which mitochondria constantly undergo to maintain their integrity, distribution and size. These mechanisms represent an early response to mitochondrial stress, confining organelle portions that are irreversibly damaged and preserving mitochondrial function. Accumulating evidence demonstrates that impairment in mitochondrial dynamics leads to myocardial damage and cardiac disease progression in a variety of disease models, including pressure overload, ischaemia/reperfusion and metabolic disturbance. These findings suggest that modulation of mitochondrial dynamics may be considered as a valid therapeutic strategy in cardiovascular diseases. In this review, we discuss the current evidence about the role of mitochondrial dynamics in cardiac pathophysiology, with a particular focus on the mechanisms underlying the development of cardiac hypertrophy and heart failure, metabolic and genetic cardiomyopathies, ischaemia/reperfusion injury, atherosclerosis and ischaemic stroke.",2020,"[{'authorId': '17522545', 'name': 'Maurizio Forte'}, {'authorId': '50263908', 'name': 'L. Schirone'}, {'authorId': '5190927', 'name': 'P. Ameri'}, {'authorId': '14336506', 'name': 'C. Basso'}, {'authorId': '4729196', 'name': 'D. Catalucci'}, {'authorId': '36773512', 'name': 'Jessica Modica'}, {'authorId': '38377354', 'name': 'C. Chimenti'}, {'authorId': '3121550', 'name': 'L. Crotti'}, {'authorId': '5583012', 'name': 'G. Frati'}, {'authorId': '4274992', 'name': 'S. Rubattu'}, {'authorId': '7996447', 'name': 'G. Schiattarella'}, {'authorId': '6047779', 'name': 'D. Torella'}, {'authorId': '145177725', 'name': 'C. Perrino'}, {'authorId': '1709144', 'name': 'C. Indolfi'}, {'authorId': '2882329', 'name': 'S. Sciarretta'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bph.15068', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/bph.15068?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/bph.15068, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the process of mitochondrial dynamics is emerging as a core player in cardiovascular homeostasis. this process refers to the co‐ordinated cycles of biogenesis, fusion, fission and degradation to which mitochondria constantly undergo to maintain their integrity, distribution and size. these mechanisms represent an early response to mitochondrial stress, confining organelle portions that are irreversibly damaged and preserving mitochondrial function. accumulating evidence demonstrates that impairment in mitochondrial dynamics leads to myocardial damage and cardiac disease progression in a variety of disease models, including pressure overload, ischaemia/reperfusion and metabolic disturbance. these findings suggest that modulation of mitochondrial dynamics may be considered as a valid therapeutic strategy in cardiovascular diseases. in this review, we discuss the current evidence about the role of mitochondrial dynamics in cardiac pathophysiology, with a particular focus on the mechanisms underlying the development of cardiac hypertrophy and heart failure, metabolic and genetic cardiomyopathies, ischaemia/reperfusion injury, atherosclerosis and ischaemic stroke.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bph.15068
4dbd1d52a91c7afdb24c9841db598fa124efd951,"miRNAS in cardiovascular diseases: potential biomarkers, therapeutic targets and challenges","Cardiovascular diseases (CVD) are the leading cause of morbidity and mortality in the world. Although considerable progress has been made in the diagnosis, treatment and prognosis of CVD, there is still a critical need for novel diagnostic biomarkers and new therapeutic interventions to decrease the incidence of this disease. Recently, there is increasing evidence that circulating miRNAs (miRNAs), i.e. endogenous, stable, single-stranded, short, non-coding RNAs, can be used as diagnostic biomarkers for CVD. Furthermore, miRNAs represent potential novel therapeutic targets for several cardiovascular disorders. In this review we provides an overview of the effects of several CVD; including heart failure, acute myocardial infarction, arrhythmias and pulmonary hypertension; on levels of circulating miRNAs. In addition, the use of miRNA as therapeutic targets is also discussed, as well as challenges and recommendations in their use in the diagnosis of CVD.",2018,"[{'authorId': '2111056500', 'name': 'Shanshan Zhou'}, {'authorId': '2115758684', 'name': 'Jing-peng Jin'}, {'authorId': '2145270736', 'name': 'Ji-qun Wang'}, {'authorId': '2116219803', 'name': 'Zhiguo Zhang'}, {'authorId': '3518017', 'name': 'J. Freedman'}, {'authorId': '1683589', 'name': 'Yang Zheng'}, {'authorId': '9324229', 'name': 'L. Cai'}]","{'url': 'https://www.nature.com/articles/aps201830.pdf', 'status': 'HYBRID', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6289363, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases (cvd) are the leading cause of morbidity and mortality in the world. although considerable progress has been made in the diagnosis, treatment and prognosis of cvd, there is still a critical need for novel diagnostic biomarkers and new therapeutic interventions to decrease the incidence of this disease. recently, there is increasing evidence that circulating mirnas (mirnas), i.e. endogenous, stable, single-stranded, short, non-coding rnas, can be used as diagnostic biomarkers for cvd. furthermore, mirnas represent potential novel therapeutic targets for several cardiovascular disorders. in this review we provides an overview of the effects of several cvd; including heart failure, acute myocardial infarction, arrhythmias and pulmonary hypertension; on levels of circulating mirnas. in addition, the use of mirna as therapeutic targets is also discussed, as well as challenges and recommendations in their use in the diagnosis of cvd.",https://www.nature.com/articles/aps201830.pdf
b79b09892277864248cdf9ca446f5d2a2db122cf,The Effects of Flavonoids in Cardiovascular Diseases,"Flavonoids are metabolites of plants and fungus. Flavonoid research has been paid special attention to in recent times after the observation of their beneficial effects on the cardiovascular system. These favorable effects are exerted by flavonoids mainly due to their antioxidant properties, which result from the ability to decrease the oxidation of low-density lipoproteins, thus improving the lipid profiles. The other positive effect exerted on the cardiovascular system is the ability of flavonoids to produce vasodilation and regulate the apoptotic processes in the endothelium. Researchers suggested that these effects, including their anti-inflammatory function, are consequences of flavonoids’ potent antioxidant properties, but recent studies have shown multiple signaling pathways linked to them, thus suggesting that there are more mechanisms involved in the beneficial effect of the flavonoids on the human body. This review aims to present the latest data on the classification of these substances, their main mechanisms of action in the human body, and the beneficial effects on the physiological and pathological status of the cardiovascular system.",2020,"[{'authorId': '5634118', 'name': 'L. Ciumărnean'}, {'authorId': '23545594', 'name': 'M. Milaciu'}, {'authorId': '1965131908', 'name': 'Octavia Runcan'}, {'authorId': '3048177', 'name': 'Ș. Vesa'}, {'authorId': '4927447', 'name': 'A. Rãchişan'}, {'authorId': '4160430', 'name': 'V. Negrean'}, {'authorId': '121439627', 'name': 'M. Perne'}, {'authorId': '5395555', 'name': 'V. Donca'}, {'authorId': '8284676', 'name': 'T. Alexescu'}, {'authorId': '153929376', 'name': 'Ioana Para'}, {'authorId': '24399367', 'name': 'G. Dogaru'}]","{'url': 'https://www.mdpi.com/1420-3049/25/18/4320/pdf?version=1600672518', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7571023, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","flavonoids are metabolites of plants and fungus. flavonoid research has been paid special attention to in recent times after the observation of their beneficial effects on the cardiovascular system. these favorable effects are exerted by flavonoids mainly due to their antioxidant properties, which result from the ability to decrease the oxidation of low-density lipoproteins, thus improving the lipid profiles. the other positive effect exerted on the cardiovascular system is the ability of flavonoids to produce vasodilation and regulate the apoptotic processes in the endothelium. researchers suggested that these effects, including their anti-inflammatory function, are consequences of flavonoids’ potent antioxidant properties, but recent studies have shown multiple signaling pathways linked to them, thus suggesting that there are more mechanisms involved in the beneficial effect of the flavonoids on the human body. this review aims to present the latest data on the classification of these substances, their main mechanisms of action in the human body, and the beneficial effects on the physiological and pathological status of the cardiovascular system.",https://www.mdpi.com/1420-3049/25/18/4320/pdf?version=1600672518
35d59dabc6bd80ba8f58129b4ad2b54ad2e7b4bd,Oxidative Stress and Antioxidant Treatments in Cardiovascular Diseases,"Oxidative stress plays a key role in many physiological and pathological conditions. The intracellular oxidative homeostasis is tightly regulated by the reactive oxygen species production and the intracellular defense mechanisms. Increased oxidative stress could alter lipid, DNA, and protein, resulting in cellular inflammation and programmed cell death. Evidences show that oxidative stress plays an important role in the progression of various cardiovascular diseases, such as atherosclerosis, heart failure, cardiac arrhythmia, and ischemia-reperfusion injury. There are a number of therapeutic options to treat oxidative stress-associated cardiovascular diseases. Well known antioxidants, such as nutritional supplements, as well as more novel antioxidants have been studied. In addition, novel therapeutic strategies using miRNA and nanomedicine are also being developed to treat various cardiovascular diseases. In this article, we provide a detailed description of oxidative stress. Then, we will introduce the relationship between oxidative stress and several cardiovascular diseases. Finally, we will focus on the clinical implications of oxidative stress in cardiovascular diseases.",2020,"[{'authorId': '2117832935', 'name': 'Wenjun Wang'}, {'authorId': '2302010', 'name': 'P. Kang'}]","{'url': 'https://www.mdpi.com/2076-3921/9/12/1292/pdf?version=1608187634', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7766219, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","oxidative stress plays a key role in many physiological and pathological conditions. the intracellular oxidative homeostasis is tightly regulated by the reactive oxygen species production and the intracellular defense mechanisms. increased oxidative stress could alter lipid, dna, and protein, resulting in cellular inflammation and programmed cell death. evidences show that oxidative stress plays an important role in the progression of various cardiovascular diseases, such as atherosclerosis, heart failure, cardiac arrhythmia, and ischemia-reperfusion injury. there are a number of therapeutic options to treat oxidative stress-associated cardiovascular diseases. well known antioxidants, such as nutritional supplements, as well as more novel antioxidants have been studied. in addition, novel therapeutic strategies using mirna and nanomedicine are also being developed to treat various cardiovascular diseases. in this article, we provide a detailed description of oxidative stress. then, we will introduce the relationship between oxidative stress and several cardiovascular diseases. finally, we will focus on the clinical implications of oxidative stress in cardiovascular diseases.",https://www.mdpi.com/2076-3921/9/12/1292/pdf?version=1608187634
ae6ef839bc697e364b93357b09a91ac0465326cc,Galectin-3 in Cardiovascular Diseases,"Galectin-3 (Gal-3) is a β-galactoside-binding protein belonging to the lectin family with pleiotropic regulatory activities and several physiological cellular functions, such as cellular growth, proliferation, apoptosis, differentiation, cellular adhesion, and tissue repair. Inflammation, tissue fibrosis and angiogenesis are the main processes in which Gal-3 is involved. It is implicated in the pathogenesis of several diseases, including organ fibrosis, chronic inflammation, cancer, atherosclerosis and other cardiovascular diseases (CVDs). This review aims to explore the connections of Gal-3 with cardiovascular diseases since they represent a major cause of morbidity and mortality. We herein discuss the evidence on the pro-inflammatory role of Gal-3 in the atherogenic process as well as the association with plaque features linked to lesion stability. We report the biological role and molecular mechanisms of Gal-3 in other CVDs, highlighting its involvement in the development of cardiac fibrosis and impaired myocardium remodelling, resulting in heart failure and atrial fibrillation. The role of Gal-3 as a prognostic marker of heart failure is described together with possible diagnostic applications to other CVDs. Finally, we report the tentative use of Gal-3 inhibition as a therapeutic approach to prevent cardiac inflammation and fibrosis.",2020,"[{'authorId': '4141168', 'name': 'V. Blanda'}, {'authorId': '6009197', 'name': 'U. Bracale'}, {'authorId': '2922245', 'name': 'M. D. Di Taranto'}, {'authorId': '39144807', 'name': 'G. Fortunato'}]","{'url': 'https://www.mdpi.com/1422-0067/21/23/9232/pdf?version=1607005120', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7731136, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","galectin-3 (gal-3) is a β-galactoside-binding protein belonging to the lectin family with pleiotropic regulatory activities and several physiological cellular functions, such as cellular growth, proliferation, apoptosis, differentiation, cellular adhesion, and tissue repair. inflammation, tissue fibrosis and angiogenesis are the main processes in which gal-3 is involved. it is implicated in the pathogenesis of several diseases, including organ fibrosis, chronic inflammation, cancer, atherosclerosis and other cardiovascular diseases (cvds). this review aims to explore the connections of gal-3 with cardiovascular diseases since they represent a major cause of morbidity and mortality. we herein discuss the evidence on the pro-inflammatory role of gal-3 in the atherogenic process as well as the association with plaque features linked to lesion stability. we report the biological role and molecular mechanisms of gal-3 in other cvds, highlighting its involvement in the development of cardiac fibrosis and impaired myocardium remodelling, resulting in heart failure and atrial fibrillation. the role of gal-3 as a prognostic marker of heart failure is described together with possible diagnostic applications to other cvds. finally, we report the tentative use of gal-3 inhibition as a therapeutic approach to prevent cardiac inflammation and fibrosis.",https://www.mdpi.com/1422-0067/21/23/9232/pdf?version=1607005120
786a80b8a1b0296b876773724af860bf5a91dc83,Mitophagy in Cardiovascular Diseases,"Cardiovascular diseases are one of the leading causes of death. Increasing evidence has shown that pharmacological or genetic targeting of mitochondria can ameliorate each stage of these pathologies, which are strongly associated with mitochondrial dysfunction. Removal of inefficient and dysfunctional mitochondria through the process of mitophagy has been reported to be essential for meeting the energetic requirements and maintaining the biochemical homeostasis of cells. This process is useful for counteracting the negative phenotypic changes that occur during cardiovascular diseases, and understanding the molecular players involved might be crucial for the development of potential therapies. Here, we summarize the current knowledge on mitophagy (and autophagy) mechanisms in the context of heart disease with an important focus on atherosclerosis, ischemic heart disease, cardiomyopathies, heart failure, hypertension, arrhythmia, congenital heart disease and peripheral vascular disease. We aim to provide a complete background on the mechanisms of action of this mitochondrial quality control process in cardiology and in cardiac surgery by also reviewing studies on the use of known compounds able to modulate mitophagy for cardioprotective purposes.",2020,"[{'authorId': '3769607', 'name': 'G. Morciano'}, {'authorId': '5872212', 'name': 'S. Patergnani'}, {'authorId': '35921596', 'name': 'M. Bonora'}, {'authorId': '13817435', 'name': 'G. Pedriali'}, {'authorId': '5639505', 'name': 'Anna Tarocco'}, {'authorId': '1596720078', 'name': 'Esmaa Bouhamida'}, {'authorId': '34477304', 'name': 'Saverio Marchi'}, {'authorId': '6340064', 'name': 'G. Ancora'}, {'authorId': '5642290', 'name': 'G. Anania'}, {'authorId': '3783855', 'name': 'M. Wieckowski'}, {'authorId': '3571606', 'name': 'C. Giorgi'}, {'authorId': '3936492', 'name': 'P. Pinton'}]","{'url': 'https://www.mdpi.com/2077-0383/9/3/892/pdf?version=1585214716', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7141512, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases are one of the leading causes of death. increasing evidence has shown that pharmacological or genetic targeting of mitochondria can ameliorate each stage of these pathologies, which are strongly associated with mitochondrial dysfunction. removal of inefficient and dysfunctional mitochondria through the process of mitophagy has been reported to be essential for meeting the energetic requirements and maintaining the biochemical homeostasis of cells. this process is useful for counteracting the negative phenotypic changes that occur during cardiovascular diseases, and understanding the molecular players involved might be crucial for the development of potential therapies. here, we summarize the current knowledge on mitophagy (and autophagy) mechanisms in the context of heart disease with an important focus on atherosclerosis, ischemic heart disease, cardiomyopathies, heart failure, hypertension, arrhythmia, congenital heart disease and peripheral vascular disease. we aim to provide a complete background on the mechanisms of action of this mitochondrial quality control process in cardiology and in cardiac surgery by also reviewing studies on the use of known compounds able to modulate mitophagy for cardioprotective purposes.",https://www.mdpi.com/2077-0383/9/3/892/pdf?version=1585214716
8850e87ba35c81bd0ddc95f0da25456924e2d7ec,Mitochondria-Associated Endoplasmic Reticulum Membranes in Cardiovascular Diseases,"The endoplasmic reticulum (ER) and mitochondria are physically connected to form dedicated structural domains known as mitochondria-associated ER membranes (MAMs), which participate in fundamental biological processes, including lipid and calcium (Ca2+) homeostasis, mitochondrial dynamics and other related cellular behaviors such as autophagy, ER stress, inflammation and apoptosis. Many studies have proved the importance of MAMs in maintaining the normal function of both organelles, and the abnormal amount, structure or function of MAMs is related to the occurrence of cardiovascular diseases. Here, we review the knowledge regarding the components of MAMs according to their different functions and the specific roles of MAMs in cardiovascular physiology and pathophysiology, focusing on some highly prevalent cardiovascular diseases, including ischemia-reperfusion, diabetic cardiomyopathy, heart failure, pulmonary arterial hypertension and systemic vascular diseases. Finally, we summarize the possible mechanisms of MAM in cardiovascular diseases and put forward some obstacles in the understanding of MAM function we may encounter.",2020,"[{'authorId': '49224569', 'name': 'Peng Gao'}, {'authorId': '4784344', 'name': 'Zhencheng Yan'}, {'authorId': '46637628', 'name': 'Zhiming Zhu'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fcell.2020.604240/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7680862, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the endoplasmic reticulum (er) and mitochondria are physically connected to form dedicated structural domains known as mitochondria-associated er membranes (mams), which participate in fundamental biological processes, including lipid and calcium (ca2+) homeostasis, mitochondrial dynamics and other related cellular behaviors such as autophagy, er stress, inflammation and apoptosis. many studies have proved the importance of mams in maintaining the normal function of both organelles, and the abnormal amount, structure or function of mams is related to the occurrence of cardiovascular diseases. here, we review the knowledge regarding the components of mams according to their different functions and the specific roles of mams in cardiovascular physiology and pathophysiology, focusing on some highly prevalent cardiovascular diseases, including ischemia-reperfusion, diabetic cardiomyopathy, heart failure, pulmonary arterial hypertension and systemic vascular diseases. finally, we summarize the possible mechanisms of mam in cardiovascular diseases and put forward some obstacles in the understanding of mam function we may encounter.",https://www.frontiersin.org/articles/10.3389/fcell.2020.604240/pdf
c7d1f64fefba63ffef3206defd4b485644a58456,COVID-19 and cardiovascular diseases,"Abstract The coronavirus disease 2019 (COVID-19) remains a global public health emergency. Despite being caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), besides the lung, this infectious disease also has severe implications in the cardiovascular system. In this review, we summarize diverse clinical complications of the heart and vascular system, as well as the relevant high mortality, in COVID-19 patients. Systemic inflammation and angiotensin-converting enzyme 2-involved signaling networking in SARS-CoV-2 infection and the cardiovascular system may contribute to the manifestations of cardiovascular diseases. Therefore, integration of clinical observations and experimental findings can promote our understanding of the underlying mechanisms, which would aid in identifying and treating cardiovascular injury in patients with COVID-19 appropriately.",2020,"[{'authorId': '2170731881', 'name': 'Fan Liu'}, {'authorId': '2152942971', 'name': 'Feng Liu'}, {'authorId': '2153512814', 'name': 'Lu Wang'}]","{'url': 'https://academic.oup.com/jmcb/article-pdf/13/3/161/38874809/mjaa064.pdf', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7717280, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract the coronavirus disease 2019 (covid-19) remains a global public health emergency. despite being caused by severe acute respiratory syndrome coronavirus 2 (sars-cov-2), besides the lung, this infectious disease also has severe implications in the cardiovascular system. in this review, we summarize diverse clinical complications of the heart and vascular system, as well as the relevant high mortality, in covid-19 patients. systemic inflammation and angiotensin-converting enzyme 2-involved signaling networking in sars-cov-2 infection and the cardiovascular system may contribute to the manifestations of cardiovascular diseases. therefore, integration of clinical observations and experimental findings can promote our understanding of the underlying mechanisms, which would aid in identifying and treating cardiovascular injury in patients with covid-19 appropriately.",https://academic.oup.com/jmcb/article-pdf/13/3/161/38874809/mjaa064.pdf
71fabec79a2a596a13f87e9f34f5c8062bbce832,Role of Leptin in Cardiovascular Diseases,"The adipocyte-derived adipokine leptin exerts pleiotropic effects, which are essential for the regulation of energy balance and cell metabolism, for controlling inflammatory and immune responses, and for the maintenance of homeostasis of the cardiovascular system. Leptin resistance in obese or type 2 diabetes mellitus (T2DM) patients is defined as a decrease in tissue response to leptin. In the cardiovascular system, leptin resistance exhibits the adverse effect on the heart's response to stress conditions and promoting cardiac remodeling due to impaired cardiac metabolism, increased fibrosis, vascular dysfunction, and enhanced inflammation. Leptin resistance or leptin signaling deficiency results in the risk increase of cardiac dysfunction and heart failure, which is a leading cause of obesity- and T2DM-related morbidity and mortality. Animal studies using leptin- and leptin receptor- (Lepr) deficient rodents have provided many useful insights into the underlying molecular and pathophysiological mechanisms of obese- and T2DM-associated metabolic and cardiovascular diseases. However, none of the animal models used so far can fully recapitulate the phenotypes of patients with obese or T2DM. Therefore, the role of leptin in the human cardiovascular system, and whether leptin affects cardiac function directly or acts through a leptin-regulated neurohumoral pathway, remain elusive. As the prevalence of obesity and diabetes is continuously increasing, strategies are needed to develop and apply human cell-based models to better understand the precise role of leptin directly in different cardiac cell types and to overcome the existing translational barriers. The purpose of this review is to discuss the mechanisms associated with leptin signaling deficiency or leptin resistance in the development of metabolic and cardiovascular diseases. We analyzed and comprehensively addressed substantial findings in pathophysiological mechanisms in commonly used leptin- or Lepr-deficient rodent models and highlighted the differences between rodents and humans. This may open up new strategies to develop directly and reliably applicable models, which resemble the human pathophysiology in order to advance health care management of obesity- and T2DM-related cardiovascular complications.",2020,"[{'authorId': '113799575', 'name': 'M. Poetsch'}, {'authorId': '1750919266', 'name': 'A. Strano'}, {'authorId': '34640290', 'name': 'K. Guan'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fendo.2020.00354/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7325922, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the adipocyte-derived adipokine leptin exerts pleiotropic effects, which are essential for the regulation of energy balance and cell metabolism, for controlling inflammatory and immune responses, and for the maintenance of homeostasis of the cardiovascular system. leptin resistance in obese or type 2 diabetes mellitus (t2dm) patients is defined as a decrease in tissue response to leptin. in the cardiovascular system, leptin resistance exhibits the adverse effect on the heart's response to stress conditions and promoting cardiac remodeling due to impaired cardiac metabolism, increased fibrosis, vascular dysfunction, and enhanced inflammation. leptin resistance or leptin signaling deficiency results in the risk increase of cardiac dysfunction and heart failure, which is a leading cause of obesity- and t2dm-related morbidity and mortality. animal studies using leptin- and leptin receptor- (lepr) deficient rodents have provided many useful insights into the underlying molecular and pathophysiological mechanisms of obese- and t2dm-associated metabolic and cardiovascular diseases. however, none of the animal models used so far can fully recapitulate the phenotypes of patients with obese or t2dm. therefore, the role of leptin in the human cardiovascular system, and whether leptin affects cardiac function directly or acts through a leptin-regulated neurohumoral pathway, remain elusive. as the prevalence of obesity and diabetes is continuously increasing, strategies are needed to develop and apply human cell-based models to better understand the precise role of leptin directly in different cardiac cell types and to overcome the existing translational barriers. the purpose of this review is to discuss the mechanisms associated with leptin signaling deficiency or leptin resistance in the development of metabolic and cardiovascular diseases. we analyzed and comprehensively addressed substantial findings in pathophysiological mechanisms in commonly used leptin- or lepr-deficient rodent models and highlighted the differences between rodents and humans. this may open up new strategies to develop directly and reliably applicable models, which resemble the human pathophysiology in order to advance health care management of obesity- and t2dm-related cardiovascular complications.",https://www.frontiersin.org/articles/10.3389/fendo.2020.00354/pdf
7df98696b117b0cb1ca01e1ed09322972414046d,Adipokines and Inflammation: Focus on Cardiovascular Diseases,"It is well established that adipose tissue, apart from its energy storage function, acts as an endocrine organ that produces and secretes a number of bioactive substances, including hormones commonly known as adipokines. Obesity is a major risk factor for the development of cardiovascular diseases, mainly due to a low grade of inflammation and the excessive fat accumulation produced in this state. The adipose tissue dysfunction in obesity leads to an aberrant release of adipokines, some of them with direct cardiovascular and inflammatory regulatory functions. Inflammation is a common link between obesity and cardiovascular diseases, so this review will summarise the role of the main adipokines implicated in the regulation of the inflammatory processes occurring under the scenario of cardiovascular diseases.",2020,"[{'authorId': '1387465359', 'name': 'S. Feijóo-Bandín'}, {'authorId': '1387465357', 'name': 'A. Aragón-Herrera'}, {'authorId': '2003141780', 'name': 'S. Moraña-Fernández'}, {'authorId': '2003142393', 'name': 'L. Anido-Varela'}, {'authorId': '6800635', 'name': 'E. Tarazón'}, {'authorId': '1387465342', 'name': 'E. Roselló-Lletí'}, {'authorId': '4469756', 'name': 'M. Portolés'}, {'authorId': '40228461', 'name': 'I. Moscoso'}, {'authorId': '5142759', 'name': 'O. Gualillo'}, {'authorId': '1390166364', 'name': 'J. González-Juanatey'}, {'authorId': '5872176', 'name': 'F. Lago'}]","{'url': 'https://www.mdpi.com/1422-0067/21/20/7711/pdf?version=1603185246', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7589803, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","it is well established that adipose tissue, apart from its energy storage function, acts as an endocrine organ that produces and secretes a number of bioactive substances, including hormones commonly known as adipokines. obesity is a major risk factor for the development of cardiovascular diseases, mainly due to a low grade of inflammation and the excessive fat accumulation produced in this state. the adipose tissue dysfunction in obesity leads to an aberrant release of adipokines, some of them with direct cardiovascular and inflammatory regulatory functions. inflammation is a common link between obesity and cardiovascular diseases, so this review will summarise the role of the main adipokines implicated in the regulation of the inflammatory processes occurring under the scenario of cardiovascular diseases.",https://www.mdpi.com/1422-0067/21/20/7711/pdf?version=1603185246
f170d02f94c355b6a4d5f8fec6366663a27a9e8d,NLRP3 Inflammasome and Its Central Role in the Cardiovascular Diseases,"Materials The NLRP3 inflammasome controls the activation of the proteolytic enzyme caspase-1. Caspase-1 in turn regulates the maturation of the proinflammasome cytokines IL-1β and IL-18, which leads to an inflammatory response. We made a mini-review on the association of regulatory mechanisms of NLRP3 inflammasome with the development of cardiovascular diseases systematically based on the recent research studies. Discussion. The inflammasome plays an indispensable role in the development of atherosclerosis, coronary heart diseases (CHD), and heart ischemia-reperfusion (I/R) injury, and NLRP3 inflammasome may become a new target for the prevention and treatment of cardiovascular diseases. Effective regulation of NLRP3 may help prevent or even treat cardiovascular diseases. Conclusion This mini-review focuses on the association of regulatory mechanisms of NLRP3 inflammasome with the development of cardiovascular diseases, which may supply some important clues for future therapies and novel drug targets for cardiovascular diseases.",2020,"[{'authorId': '4800546', 'name': 'Y. Tong'}, {'authorId': '2108347144', 'name': 'Zhihong Wang'}, {'authorId': '2112830951', 'name': 'Li Cai'}, {'authorId': '5018423', 'name': 'Liangqiang Lin'}, {'authorId': '46700861', 'name': 'Jiafa Liu'}, {'authorId': '2219776389', 'name': 'Jinquan Cheng'}]","{'url': 'http://downloads.hindawi.com/journals/omcl/2020/4293206.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7180412, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","materials the nlrp3 inflammasome controls the activation of the proteolytic enzyme caspase-1. caspase-1 in turn regulates the maturation of the proinflammasome cytokines il-1β and il-18, which leads to an inflammatory response. we made a mini-review on the association of regulatory mechanisms of nlrp3 inflammasome with the development of cardiovascular diseases systematically based on the recent research studies. discussion. the inflammasome plays an indispensable role in the development of atherosclerosis, coronary heart diseases (chd), and heart ischemia-reperfusion (i/r) injury, and nlrp3 inflammasome may become a new target for the prevention and treatment of cardiovascular diseases. effective regulation of nlrp3 may help prevent or even treat cardiovascular diseases. conclusion this mini-review focuses on the association of regulatory mechanisms of nlrp3 inflammasome with the development of cardiovascular diseases, which may supply some important clues for future therapies and novel drug targets for cardiovascular diseases.",http://downloads.hindawi.com/journals/omcl/2020/4293206.pdf
732a1f6be18053e586e73e69ca4ce292bc587814,Role of Pyroptosis in Cardiovascular Diseases and its Therapeutic Implications,"Pyroptotic cell death or pyroptosis is characterized by caspase-1-dependent formation of plasma membrane pores, leading to the release of pro-inflammatory cytokines and cell lysis. Pyroptosis tightly controls the inflammatory responses and coordinates antimicrobial host defenses by releasing pro-inflammatory cellular contents, such as interleukin (IL)-1β and IL-18, and consequently expands or sustains inflammation. It is recognized as an important innate immune effector mechanism against intracellular pathogens. The induction of pyroptosis is closely associated with the activation of the NOD-like receptor 3 (NLRP3) inflammasome which has been linked to key cardiovascular risk factors including hyperlipidemia, diabetes, hypertension, obesity, and hyperhomocysteinemia. Emerging evidence has indicated pyroptosis as an important trigger and endogenous regulator of cardiovascular inflammation. Thus, pyroptosis may play an important role in the pathogenesis of cardiovascular diseases. Design of therapeutic strategies targeting the activation of NLRP3 inflammasome and pyroptosis holds promise for the treatment of cardiovascular diseases.",2019,"[{'authorId': '2055608921', 'name': 'C. Zeng'}, {'authorId': '2117985337', 'name': 'Renqing Wang'}, {'authorId': '48812202', 'name': 'Hongmei Tan'}]","{'url': 'https://www.ijbs.com/v15p1345.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6643148, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","pyroptotic cell death or pyroptosis is characterized by caspase-1-dependent formation of plasma membrane pores, leading to the release of pro-inflammatory cytokines and cell lysis. pyroptosis tightly controls the inflammatory responses and coordinates antimicrobial host defenses by releasing pro-inflammatory cellular contents, such as interleukin (il)-1β and il-18, and consequently expands or sustains inflammation. it is recognized as an important innate immune effector mechanism against intracellular pathogens. the induction of pyroptosis is closely associated with the activation of the nod-like receptor 3 (nlrp3) inflammasome which has been linked to key cardiovascular risk factors including hyperlipidemia, diabetes, hypertension, obesity, and hyperhomocysteinemia. emerging evidence has indicated pyroptosis as an important trigger and endogenous regulator of cardiovascular inflammation. thus, pyroptosis may play an important role in the pathogenesis of cardiovascular diseases. design of therapeutic strategies targeting the activation of nlrp3 inflammasome and pyroptosis holds promise for the treatment of cardiovascular diseases.",https://www.ijbs.com/v15p1345.pdf
34b2bc86ab904ab2f5d44eefdc393715e352a948,NFkappaB is a Key Player in the Crosstalk between Inflammation and Cardiovascular Diseases,"Inflammation is a key mechanism of cardiovascular diseases. It is an essential component of atherosclerosis and a significant risk factor for the development of cardiovascular events. In the crosstalk between inflammation and cardiovascular diseases, the transcription factor NFκB seems to be a key player since it is involved in the development and progression of both inflammation and cardiac and vascular damage. In this review, we deal with the recent findings of the role of inflammation in cardiac diseases, focusing, in particular, on NFκB as a functional link. We describe strategies for the therapeutic targeting of NFκB as a potential strategy for the failing heart.",2019,"[{'authorId': '4715191', 'name': 'A. Fiordelisi'}, {'authorId': '1771955', 'name': 'Guido Iaccarino'}, {'authorId': '7319482', 'name': 'C. Morisco'}, {'authorId': '3854456', 'name': 'E. Coscioni'}, {'authorId': '6190969', 'name': 'D. Sorriento'}]","{'url': 'https://www.mdpi.com/1422-0067/20/7/1599/pdf?version=1553939132', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6480579, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","inflammation is a key mechanism of cardiovascular diseases. it is an essential component of atherosclerosis and a significant risk factor for the development of cardiovascular events. in the crosstalk between inflammation and cardiovascular diseases, the transcription factor nfκb seems to be a key player since it is involved in the development and progression of both inflammation and cardiac and vascular damage. in this review, we deal with the recent findings of the role of inflammation in cardiac diseases, focusing, in particular, on nfκb as a functional link. we describe strategies for the therapeutic targeting of nfκb as a potential strategy for the failing heart.",https://www.mdpi.com/1422-0067/20/7/1599/pdf?version=1553939132
b1cabbcbdeb04bdd807cf779c37c6799d3c6d3f0,Salvia miltiorrhiza in Treating Cardiovascular Diseases: A Review on Its Pharmacological and Clinical Applications,"Bioactive chemical constitutes from the root of Salvia miltiorrhiza classified in two major groups, viz., liposoluble tanshinones and water-soluble phenolics. Tanshinone IIA is a major lipid-soluble compound having promising health benefits. The in vivo and in vitro studies showed that the tanshinone IIA and salvianolate have a wide range of cardiovascular and other pharmacological effects, including antioxidative, anti-inflammatory, endothelial protective, myocardial protective, anticoagulation, vasodilation, and anti-atherosclerosis, as well as significantly help to reduce proliferation and migration of vascular smooth muscle cells. In addition, some of the clinical studies reported that the S. miltiorrhiza preparations in combination with Western medicine were more effective for treatment of various cardiovascular diseases including angina pectoris, myocardial infarction, hypertension, hyperlipidemia, and pulmonary heart diseases. In this review, we demonstrated the potential applications of S. miltiorrhiza, including pharmacological effects of salvianolate, tanshinone IIA, and its water-soluble derivative, like sodium tanshinone IIA sulfonate. Moreover, we also provided details about the clinical applications of S. miltiorrhiza preparations in controlling the cardiovascular diseases.",2019,"[{'authorId': '40252787', 'name': 'Jie Ren'}, {'authorId': '81504271', 'name': 'Li Fu'}, {'authorId': '3652924', 'name': 'S. Nile'}, {'authorId': '2155662591', 'name': 'Jun Zhang'}, {'authorId': '5620642', 'name': 'G. Kai'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fphar.2019.00753/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6626924, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","bioactive chemical constitutes from the root of salvia miltiorrhiza classified in two major groups, viz., liposoluble tanshinones and water-soluble phenolics. tanshinone iia is a major lipid-soluble compound having promising health benefits. the in vivo and in vitro studies showed that the tanshinone iia and salvianolate have a wide range of cardiovascular and other pharmacological effects, including antioxidative, anti-inflammatory, endothelial protective, myocardial protective, anticoagulation, vasodilation, and anti-atherosclerosis, as well as significantly help to reduce proliferation and migration of vascular smooth muscle cells. in addition, some of the clinical studies reported that the s. miltiorrhiza preparations in combination with western medicine were more effective for treatment of various cardiovascular diseases including angina pectoris, myocardial infarction, hypertension, hyperlipidemia, and pulmonary heart diseases. in this review, we demonstrated the potential applications of s. miltiorrhiza, including pharmacological effects of salvianolate, tanshinone iia, and its water-soluble derivative, like sodium tanshinone iia sulfonate. moreover, we also provided details about the clinical applications of s. miltiorrhiza preparations in controlling the cardiovascular diseases.",https://www.frontiersin.org/articles/10.3389/fphar.2019.00753/pdf
461dde2512bc50e0492d242f64afeb3a77432d10,Zinc deficiency and cellular oxidative stress: prognostic implications in cardiovascular diseases,"Zinc is an essential nutrient for human health and has anti-oxidative stress and anti-inflammatory functions. The association between zinc deficiency and the development of cardiovascular diseases (CVDs) has been supported by numerous studies. Supplementing zinc can reduce the risk of atherosclerosis and protect against myocardial infarction and ischemia/reperfusion injury. In this review we summarize the evidence in the literature, to consolidate the current knowledge on the dysregulation of zinc homeostasis in CVDs, and to explore the significant roles of the zinc homeostasis-regulatory proteins in cardiac physiology and pathophysiology. Moreover, this review also deliberates on the potential diagnostic and prognostic implications of zinc/zinc homeostasis-associated molecules (ZIP, ZnT, and MTs) in CVDs.",2018,"[{'authorId': '12478179', 'name': 'Sangyong Choi'}, {'authorId': '2335085300', 'name': 'Xian Liu'}, {'authorId': '6505997', 'name': 'Zui Pan'}]","{'url': 'https://www.nature.com/articles/aps201825.pdf', 'status': 'HYBRID', 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6289396, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","zinc is an essential nutrient for human health and has anti-oxidative stress and anti-inflammatory functions. the association between zinc deficiency and the development of cardiovascular diseases (cvds) has been supported by numerous studies. supplementing zinc can reduce the risk of atherosclerosis and protect against myocardial infarction and ischemia/reperfusion injury. in this review we summarize the evidence in the literature, to consolidate the current knowledge on the dysregulation of zinc homeostasis in cvds, and to explore the significant roles of the zinc homeostasis-regulatory proteins in cardiac physiology and pathophysiology. moreover, this review also deliberates on the potential diagnostic and prognostic implications of zinc/zinc homeostasis-associated molecules (zip, znt, and mts) in cvds.",https://www.nature.com/articles/aps201825.pdf
06947c66a7ce61e8b42d9426421263bc8a978f31,"Inflammation: a common contributor to cancer, aging, and cardiovascular diseases—expanding the concept of cardio-oncology","Inflammation participates in the pathogenesis of both cancer and cardiovascular disease. This review examines the mechanistic commonalities between these two scourges of humanity through the lens of inflammation biology. Inflammatory pathways contribute to the initiation, the progression, and the complication of both malignant tumours and atherosclerotic plaques. Modulation of inflammatory pathways have proven transformative in the treatment of cancers and have crossed the threshold of clinical reality as treatments to reduce the risk of cardiovascular events. The finding that clonal haematopoiesis drives both leukaemia and cardiovascular events provides yet another link between these two seemingly disparate diseases. The nascent specialty of cardio-oncology has initially focused on the cardiovascular complications of cancer therapies. The recognition of a more profound pathophysiologic connection between cancer and cardiovascular diseases should expand the concept of cardio-oncology. Embracing the mechanistic connection and transcending traditional barriers between disciplines offers immense opportunities for speeding innovative research that can address the growing burden of both cancer and cardiovascular disease.",2019,"[{'authorId': '145096401', 'name': 'P. Libby'}, {'authorId': '5694991', 'name': 'S. Kobold'}]","{'url': 'https://europepmc.org/articles/pmc6452304?pdf=render', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/cvr/cvz058?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/cvr/cvz058, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","inflammation participates in the pathogenesis of both cancer and cardiovascular disease. this review examines the mechanistic commonalities between these two scourges of humanity through the lens of inflammation biology. inflammatory pathways contribute to the initiation, the progression, and the complication of both malignant tumours and atherosclerotic plaques. modulation of inflammatory pathways have proven transformative in the treatment of cancers and have crossed the threshold of clinical reality as treatments to reduce the risk of cardiovascular events. the finding that clonal haematopoiesis drives both leukaemia and cardiovascular events provides yet another link between these two seemingly disparate diseases. the nascent specialty of cardio-oncology has initially focused on the cardiovascular complications of cancer therapies. the recognition of a more profound pathophysiologic connection between cancer and cardiovascular diseases should expand the concept of cardio-oncology. embracing the mechanistic connection and transcending traditional barriers between disciplines offers immense opportunities for speeding innovative research that can address the growing burden of both cancer and cardiovascular disease.",https://europepmc.org/articles/pmc6452304?pdf=render
cb0f1e54ce66c0802cf4cb8591eb1074c4e26d2b,Inflammation and Cardiovascular Diseases: The Most Recent Findings,"The series of reactive biological events that we identify as inflammation has been investigated in recent years and unveiled as an important mechanism for regeneration. The study of the underlying complexity has been boosted by new technological innovation in research and allowed the identification of inflammatory responses as the basis of diseases that were considered degenerative rather than regenerative in nature. This is the case for cardiovascular diseases, from the organ damage that follows an acute event to the damage of target organs exposed to chronic risk factors. This editorial explores innovative aspects of inflammation in the setup of cardiovascular risk factors and diseases.",2019,"[{'authorId': '6190969', 'name': 'D. Sorriento'}, {'authorId': '1771955', 'name': 'Guido Iaccarino'}]","{'url': 'https://www.mdpi.com/1422-0067/20/16/3879/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6719998, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the series of reactive biological events that we identify as inflammation has been investigated in recent years and unveiled as an important mechanism for regeneration. the study of the underlying complexity has been boosted by new technological innovation in research and allowed the identification of inflammatory responses as the basis of diseases that were considered degenerative rather than regenerative in nature. this is the case for cardiovascular diseases, from the organ damage that follows an acute event to the damage of target organs exposed to chronic risk factors. this editorial explores innovative aspects of inflammation in the setup of cardiovascular risk factors and diseases.",https://www.mdpi.com/1422-0067/20/16/3879/pdf
89c3e527bc945615daa1a07c702084bd468a7dd6,Relevance of Multi-Omics Studies in Cardiovascular Diseases,"Cardiovascular diseases are the leading cause of death around the world. Despite the larger number of genes and loci identified, the precise mechanisms by which these genes influence risk of cardiovascular disease is not well understood. Recent advances in the development and optimization of high-throughput technologies for the generation of “omics data” have provided a deeper understanding of the processes and dynamic interactions involved in human diseases. However, the integrative analysis of “omics” data is not straightforward and represents several logistic and computational challenges. In spite of these difficulties, several studies have successfully applied integrative genomics approaches for the investigation of novel mechanisms and plasma biomarkers involved in cardiovascular diseases. In this review, we summarized recent studies aimed to understand the molecular framework of these diseases using multi-omics data from mice and humans. We discuss examples of omics studies for cardiovascular diseases focused on the integration of genomics, epigenomics, transcriptomics, and proteomics. This review also describes current gaps in the study of complex diseases using systems genetics approaches as well as potential limitations and future directions of this emerging field.",2019,"[{'authorId': '1403801926', 'name': 'P. León-Mimila'}, {'authorId': '46583893', 'name': 'Jessica J Wang'}, {'authorId': '1398553286', 'name': 'A. Huertas-Vazquez'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fcvm.2019.00091/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6656333, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases are the leading cause of death around the world. despite the larger number of genes and loci identified, the precise mechanisms by which these genes influence risk of cardiovascular disease is not well understood. recent advances in the development and optimization of high-throughput technologies for the generation of “omics data” have provided a deeper understanding of the processes and dynamic interactions involved in human diseases. however, the integrative analysis of “omics” data is not straightforward and represents several logistic and computational challenges. in spite of these difficulties, several studies have successfully applied integrative genomics approaches for the investigation of novel mechanisms and plasma biomarkers involved in cardiovascular diseases. in this review, we summarized recent studies aimed to understand the molecular framework of these diseases using multi-omics data from mice and humans. we discuss examples of omics studies for cardiovascular diseases focused on the integration of genomics, epigenomics, transcriptomics, and proteomics. this review also describes current gaps in the study of complex diseases using systems genetics approaches as well as potential limitations and future directions of this emerging field.",https://www.frontiersin.org/articles/10.3389/fcvm.2019.00091/pdf
44801420c093f49ad354110af5a6878bb3307a2b,Exosome in Cardiovascular Diseases: A Complex World Full of Hope,"Exosomes are a subgroup of extracellular vesicles containing a huge number of bioactive molecules. They represent an important means of cell communication, mostly between different cell populations, with the purpose of maintaining tissue homeostasis and coordinating the adaptive response to stress. This type of intercellular communication is important in the cardiovascular field, mainly due to the fact that the heart is a complex multicellular system. Given the growing interest in the role of exosomes in cardiovascular diseases and the numerous studies published in the last few decades, we focused on the most relevant results about exosomes in the cardiovascular filed starting from their characterization, passing through the study of their function, and ending with perspectives for their use in cardiovascular therapies.",2019,"[{'authorId': '10774156', 'name': 'Gloria Bellin'}, {'authorId': '3554135', 'name': 'C. Gardin'}, {'authorId': '4112196', 'name': 'L. Ferroni'}, {'authorId': '6527068', 'name': 'J. Chachques'}, {'authorId': '47051915', 'name': 'M. Rogante'}, {'authorId': '4005945', 'name': 'D. Mitrečić'}, {'authorId': '144661050', 'name': 'R. Ferrari'}, {'authorId': '4213131', 'name': 'B. Zavan'}]","{'url': 'https://www.mdpi.com/2073-4409/8/2/166/pdf?version=1550384662', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6406975, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","exosomes are a subgroup of extracellular vesicles containing a huge number of bioactive molecules. they represent an important means of cell communication, mostly between different cell populations, with the purpose of maintaining tissue homeostasis and coordinating the adaptive response to stress. this type of intercellular communication is important in the cardiovascular field, mainly due to the fact that the heart is a complex multicellular system. given the growing interest in the role of exosomes in cardiovascular diseases and the numerous studies published in the last few decades, we focused on the most relevant results about exosomes in the cardiovascular filed starting from their characterization, passing through the study of their function, and ending with perspectives for their use in cardiovascular therapies.",https://www.mdpi.com/2073-4409/8/2/166/pdf?version=1550384662
c17736a89bbebd3497a6a813150bdd91fb91e91c,Roles of Exosomes Derived From Immune Cells in Cardiovascular Diseases,"Therapies aimed at minimizing adverse remodeling in cardiovascular diseases on a molecular and cellular basis are urgently needed. Exosomes are nanosized lipid vesicles released from various cells that are able to mediate intercellular signaling and communication via their cargos. It has been increasingly demonstrated that exosomes from cardiomyocytes or stem/progenitor cells can promote cardiac repair and regeneration, but their mechanism has not been fully explained. Immune responses mediated by immune cells also play important and complicated roles in the progression of various cardiovascular diseases such as myocardial infarction and atherosclerosis. Exosomes derived from immune cells have shown pleiotropic effects on these pathological states, whether similar to or different from their parent cells. However, the underlying mechanism remains obscure. In this review, we first describe the biological characteristics and biogenesis of exosomes. Then we critically examine the emerging roles of exosomes in cardiovascular disease; the exosomes we focus on are derived from immune cells such as dendritic cells, macrophages, B cells, T cells, as well as neutrophils and mast cells. Among the cardiovascular diseases we discuss, we mainly focus on myocardial infarction and atherosclerosis. As active intercellular communicators, exosomes from immune cells may offer prospective diagnostic and therapeutic value in cardiovascular disease.",2019,"[{'authorId': '90528519', 'name': 'Runda Wu'}, {'authorId': '2153577734', 'name': 'Wei Gao'}, {'authorId': '144948435', 'name': 'K. Yao'}, {'authorId': '144008900', 'name': 'J. Ge'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fimmu.2019.00648/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6449434, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","therapies aimed at minimizing adverse remodeling in cardiovascular diseases on a molecular and cellular basis are urgently needed. exosomes are nanosized lipid vesicles released from various cells that are able to mediate intercellular signaling and communication via their cargos. it has been increasingly demonstrated that exosomes from cardiomyocytes or stem/progenitor cells can promote cardiac repair and regeneration, but their mechanism has not been fully explained. immune responses mediated by immune cells also play important and complicated roles in the progression of various cardiovascular diseases such as myocardial infarction and atherosclerosis. exosomes derived from immune cells have shown pleiotropic effects on these pathological states, whether similar to or different from their parent cells. however, the underlying mechanism remains obscure. in this review, we first describe the biological characteristics and biogenesis of exosomes. then we critically examine the emerging roles of exosomes in cardiovascular disease; the exosomes we focus on are derived from immune cells such as dendritic cells, macrophages, b cells, t cells, as well as neutrophils and mast cells. among the cardiovascular diseases we discuss, we mainly focus on myocardial infarction and atherosclerosis. as active intercellular communicators, exosomes from immune cells may offer prospective diagnostic and therapeutic value in cardiovascular disease.",https://www.frontiersin.org/articles/10.3389/fimmu.2019.00648/pdf
2adfb00a09c651137fd1fd37e828f6f71a62454d,Epigenetic Biomarkers in Cardiovascular Diseases,"Cardiovascular diseases are the number one cause of death worldwide and greatly impact quality of life and medical costs. Enormous effort has been made in research to obtain new tools for efficient and quick diagnosis and predicting the prognosis of these diseases. Discoveries of epigenetic mechanisms have related several pathologies, including cardiovascular diseases, to epigenetic dysregulation. This has implications on disease progression and is the basis for new preventive strategies. Advances in methodology and big data analysis have identified novel mechanisms and targets involved in numerous diseases, allowing more individualized epigenetic maps for personalized diagnosis and treatment. This paves the way for what is called pharmacoepigenetics, which predicts the drug response and develops a tailored therapy based on differences in the epigenetic basis of each patient. Similarly, epigenetic biomarkers have emerged as a promising instrument for the consistent diagnosis and prognosis of cardiovascular diseases. Their good accessibility and feasible methods of detection make them suitable for use in clinical practice. However, multicenter studies with a large sample population are required to determine with certainty which epigenetic biomarkers are reliable for clinical routine. Therefore, this review focuses on current discoveries regarding epigenetic biomarkers and its controversy aiming to improve the diagnosis, prognosis, and therapy in cardiovascular patients.",2019,"[{'authorId': '1397866451', 'name': 'C. Soler-Botija'}, {'authorId': '1397866470', 'name': 'C. Gálvez-Montón'}, {'authorId': '1387455899', 'name': 'A. Bayés‐Genís'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fgene.2019.00950/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6795132, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases are the number one cause of death worldwide and greatly impact quality of life and medical costs. enormous effort has been made in research to obtain new tools for efficient and quick diagnosis and predicting the prognosis of these diseases. discoveries of epigenetic mechanisms have related several pathologies, including cardiovascular diseases, to epigenetic dysregulation. this has implications on disease progression and is the basis for new preventive strategies. advances in methodology and big data analysis have identified novel mechanisms and targets involved in numerous diseases, allowing more individualized epigenetic maps for personalized diagnosis and treatment. this paves the way for what is called pharmacoepigenetics, which predicts the drug response and develops a tailored therapy based on differences in the epigenetic basis of each patient. similarly, epigenetic biomarkers have emerged as a promising instrument for the consistent diagnosis and prognosis of cardiovascular diseases. their good accessibility and feasible methods of detection make them suitable for use in clinical practice. however, multicenter studies with a large sample population are required to determine with certainty which epigenetic biomarkers are reliable for clinical routine. therefore, this review focuses on current discoveries regarding epigenetic biomarkers and its controversy aiming to improve the diagnosis, prognosis, and therapy in cardiovascular patients.",https://www.frontiersin.org/articles/10.3389/fgene.2019.00950/pdf
f3cc352ca8a5ea165912159010316b0ace4a7cf8,Oxidative Stress in Cell Death and Cardiovascular Diseases,"ROS functions as a second messenger and modulates multiple signaling pathways under the physiological conditions. However, excessive intracellular ROS causes damage to the molecular components of the cell, which promotes the pathogenesis of various human diseases. Cardiovascular diseases are serious threats to human health with extremely high rates of morbidity and mortality. Dysregulation of cell death promotes the pathogenesis of cardiovascular diseases and is the clinical target during the disease treatment. Numerous studies show that ROS production is closely linked to the cell death process and promotes the occurrence and development of the cardiovascular diseases. In this review, we summarize the regulation of intracellular ROS, the roles of ROS played in the development of cardiovascular diseases, and the programmed cell death induced by intracellular ROS. We also focus on anti-ROS system and the potential application of anti-ROS strategy in the treatment of cardiovascular diseases.",2019,"[{'authorId': '2118716411', 'name': 'Tao Xu'}, {'authorId': '2113831448', 'name': 'W. Ding'}, {'authorId': '1879022217', 'name': 'Xiaoyu Ji'}, {'authorId': '6289570', 'name': 'X. Ao'}, {'authorId': '46618642', 'name': 'Y. Liu'}, {'authorId': '4392369', 'name': 'Wanpeng Yu'}, {'authorId': '35301946', 'name': 'Jianxun Wang'}]","{'url': 'https://downloads.hindawi.com/journals/omcl/2019/9030563.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6875219, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ros functions as a second messenger and modulates multiple signaling pathways under the physiological conditions. however, excessive intracellular ros causes damage to the molecular components of the cell, which promotes the pathogenesis of various human diseases. cardiovascular diseases are serious threats to human health with extremely high rates of morbidity and mortality. dysregulation of cell death promotes the pathogenesis of cardiovascular diseases and is the clinical target during the disease treatment. numerous studies show that ros production is closely linked to the cell death process and promotes the occurrence and development of the cardiovascular diseases. in this review, we summarize the regulation of intracellular ros, the roles of ros played in the development of cardiovascular diseases, and the programmed cell death induced by intracellular ros. we also focus on anti-ros system and the potential application of anti-ros strategy in the treatment of cardiovascular diseases.",https://downloads.hindawi.com/journals/omcl/2019/9030563.pdf
f7c9354900f42d48fd91c7f7d2c87ea3fbcefbed,Non-coding RNAs in cardiovascular diseases: diagnostic and therapeutic perspectives.,"Recent research has demonstrated that the non-coding genome plays a key role in genetic programming and gene regulation during development as well as in health and cardiovascular disease. About 99% of the human genome do not encode proteins, but are transcriptionally active representing a broad spectrum of non-coding RNAs (ncRNAs) with important regulatory and structural functions. Non-coding RNAs have been identified as critical novel regulators of cardiovascular risk factors and cell functions and are thus important candidates to improve diagnostics and prognosis assessment. Beyond this, ncRNAs are rapidly emgerging as fundamentally novel therapeutics. On a first level, ncRNAs provide novel therapeutic targets some of which are entering assessment in clinical trials. On a second level, new therapeutic tools were developed from endogenous ncRNAs serving as blueprints. Particularly advanced is the development of RNA interference (RNAi) drugs which use recently discovered pathways of endogenous short interfering RNAs and are becoming versatile tools for efficient silencing of protein expression. Pioneering clinical studies include RNAi drugs targeting liver synthesis of PCSK9 resulting in highly significant lowering of LDL cholesterol or targeting liver transthyretin (TTR) synthesis for treatment of cardiac TTR amyloidosis. Further novel drugs mimicking actions of endogenous ncRNAs may arise from exploitation of molecular interactions not accessible to conventional pharmacology. We provide an update on recent developments and perspectives for diagnostic and therapeutic use of ncRNAs in cardiovascular diseases, including atherosclerosis/coronary disease, post-myocardial infarction remodelling, and heart failure.",2018,"[{'authorId': '2101024', 'name': 'W. Poller'}, {'authorId': '1839913', 'name': 'S. Dimmeler'}, {'authorId': '1758400', 'name': 'S. Heymans'}, {'authorId': '35368853', 'name': 'T. Zeller'}, {'authorId': '143674022', 'name': 'J. Haas'}, {'authorId': '78404412', 'name': 'M. Karakas'}, {'authorId': '6130711', 'name': 'D. Leistner'}, {'authorId': '5244539', 'name': 'P. Jakob'}, {'authorId': '47097815', 'name': 'S. Nakagawa'}, {'authorId': '48471844', 'name': 'S. Blankenberg'}, {'authorId': '1964811', 'name': 'S. Engelhardt'}, {'authorId': '78620074', 'name': 'T. Thum'}, {'authorId': '145533894', 'name': 'C. Weber'}, {'authorId': '2077016', 'name': 'B. Meder'}, {'authorId': '144224921', 'name': 'R. Hajjar'}, {'authorId': '145813140', 'name': 'U. Landmesser'}]","{'url': 'https://academic.oup.com/eurheartj/article-pdf/39/29/2704/25416080/ehx165.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/eurheartj/ehx165?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/eurheartj/ehx165, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent research has demonstrated that the non-coding genome plays a key role in genetic programming and gene regulation during development as well as in health and cardiovascular disease. about 99% of the human genome do not encode proteins, but are transcriptionally active representing a broad spectrum of non-coding rnas (ncrnas) with important regulatory and structural functions. non-coding rnas have been identified as critical novel regulators of cardiovascular risk factors and cell functions and are thus important candidates to improve diagnostics and prognosis assessment. beyond this, ncrnas are rapidly emgerging as fundamentally novel therapeutics. on a first level, ncrnas provide novel therapeutic targets some of which are entering assessment in clinical trials. on a second level, new therapeutic tools were developed from endogenous ncrnas serving as blueprints. particularly advanced is the development of rna interference (rnai) drugs which use recently discovered pathways of endogenous short interfering rnas and are becoming versatile tools for efficient silencing of protein expression. pioneering clinical studies include rnai drugs targeting liver synthesis of pcsk9 resulting in highly significant lowering of ldl cholesterol or targeting liver transthyretin (ttr) synthesis for treatment of cardiac ttr amyloidosis. further novel drugs mimicking actions of endogenous ncrnas may arise from exploitation of molecular interactions not accessible to conventional pharmacology. we provide an update on recent developments and perspectives for diagnostic and therapeutic use of ncrnas in cardiovascular diseases, including atherosclerosis/coronary disease, post-myocardial infarction remodelling, and heart failure.",https://academic.oup.com/eurheartj/article-pdf/39/29/2704/25416080/ehx165.pdf
9ee2ab3655ac1683b4b4a6c192e8433dcc122f68,Gut Microbiome and Cardiovascular Diseases,"Recent evidence has suggested that the gut microbiome is involved in human health and diseases, such as inflammatory bowel disease, liver cirrhosis, rheumatoid arthritis, and type 2 diabetes. Cardiovascular diseases, which are associated with high morbidity and mortality across the world, are no exception. Increasing evidence has suggested a strong relationship between the gut microbiome and the progression of cardiovascular diseases. We first reported such a relationship with coronary artery disease two years ago. Next-generation sequencing techniques, together with bioinformatics technology, constantly and dramatically expand our knowledge of the complex human gut bacterial ecosystem and reveal the exact role of this bacterial ecosystem in cardiovascular diseases via the functional analysis of the gut microbiome. Such knowledge may pave the way for the development of further diagnostics and therapeutics for prevention and management of cardiovascular diseases. The aim of the current review is to highlight the relationship between the gut microbiome and their metabolites, and the development of cardiovascular diseases by fostering an understanding of recent studies.",2018,"[{'authorId': '49442034', 'name': 'N. Yoshida'}, {'authorId': '2326828', 'name': 'T. Yamashita'}, {'authorId': '144071881', 'name': 'K. Hirata'}]","{'url': 'https://www.mdpi.com/2079-9721/6/3/56/pdf?version=1530263966', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC6164700, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent evidence has suggested that the gut microbiome is involved in human health and diseases, such as inflammatory bowel disease, liver cirrhosis, rheumatoid arthritis, and type 2 diabetes. cardiovascular diseases, which are associated with high morbidity and mortality across the world, are no exception. increasing evidence has suggested a strong relationship between the gut microbiome and the progression of cardiovascular diseases. we first reported such a relationship with coronary artery disease two years ago. next-generation sequencing techniques, together with bioinformatics technology, constantly and dramatically expand our knowledge of the complex human gut bacterial ecosystem and reveal the exact role of this bacterial ecosystem in cardiovascular diseases via the functional analysis of the gut microbiome. such knowledge may pave the way for the development of further diagnostics and therapeutics for prevention and management of cardiovascular diseases. the aim of the current review is to highlight the relationship between the gut microbiome and their metabolites, and the development of cardiovascular diseases by fostering an understanding of recent studies.",https://www.mdpi.com/2079-9721/6/3/56/pdf?version=1530263966
618f09ad45170060d4239ac2751ed42fbf972a19,SIRT3: A New Regulator of Cardiovascular Diseases,"Cardiovascular diseases (CVDs) are the leading causes of death worldwide, and defects in mitochondrial function contribute largely to the occurrence of CVDs. Recent studies suggest that sirtuin 3 (SIRT3), the mitochondrial NAD+-dependent deacetylase, may regulate mitochondrial function and biosynthetic pathways such as glucose and fatty acid metabolism and the tricarboxylic acid (TCA) cycle, oxidative stress, and apoptosis by reversible protein lysine deacetylation. SIRT3 regulates glucose and lipid metabolism and maintains myocardial ATP levels, which protects the heart from metabolic disturbances. SIRT3 can also protect cardiomyocytes from oxidative stress-mediated cell damage and block the development of cardiac hypertrophy. Recent reports show that SIRT3 is involved in the protection of several heart diseases. This review discusses the progress in SIRT3-related research and the role of SIRT3 in the prevention and treatment of CVDs.",2018,"[{'authorId': '2153198621', 'name': 'Wei Sun'}, {'authorId': '2116166', 'name': 'Caixia Liu'}, {'authorId': '2109625624', 'name': 'Qiu-hui Chen'}, {'authorId': '2152353983', 'name': 'Ningning Liu'}, {'authorId': '34315484', 'name': 'Youyou Yan'}, {'authorId': '50678118', 'name': 'B. Liu'}]","{'url': 'http://downloads.hindawi.com/journals/omcl/2018/7293861.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC5831850, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","cardiovascular diseases (cvds) are the leading causes of death worldwide, and defects in mitochondrial function contribute largely to the occurrence of cvds. recent studies suggest that sirtuin 3 (sirt3), the mitochondrial nad+-dependent deacetylase, may regulate mitochondrial function and biosynthetic pathways such as glucose and fatty acid metabolism and the tricarboxylic acid (tca) cycle, oxidative stress, and apoptosis by reversible protein lysine deacetylation. sirt3 regulates glucose and lipid metabolism and maintains myocardial atp levels, which protects the heart from metabolic disturbances. sirt3 can also protect cardiomyocytes from oxidative stress-mediated cell damage and block the development of cardiac hypertrophy. recent reports show that sirt3 is involved in the protection of several heart diseases. this review discusses the progress in sirt3-related research and the role of sirt3 in the prevention and treatment of cvds.",http://downloads.hindawi.com/journals/omcl/2018/7293861.pdf
9e272424be7880e723c5b2d750c78f267c0bfbdf,Assessing the accuracy of OpenET satellite-based evapotranspiration data to support water resource and land management applications,"Remotely sensed evapotranspiration (ET) data offer strong potential to support data-driven approaches for sustainable water management. However, practitioners require robust and rigorous accuracy assessments of such data. The OpenET system, which includes an ensemble of six remote sensing models, was developed to increase access to field-scale (30 m) ET data for the contiguous United States. Here we compare OpenET outputs against data from 152 in situ stations, primarily eddy covariance flux towers, deployed across the contiguous United States. Mean absolute error at cropland sites for the OpenET ensemble value is 15.8 mm per month (17% of mean observed ET), mean bias error is −5.3 mm per month (6%) and r2 is 0.9. Results for shrublands and forested sites show higher inter-model variability and lower accuracy relative to croplands. High accuracy and multi-model convergence across croplands demonstrate the utility of a model ensemble approach, and enhance confidence among ET data practitioners, including the agricultural water resource management community.",2024,"[{'authorId': '2275296605', 'name': 'John M. Volk'}, {'authorId': '25546609', 'name': 'J. Huntington'}, {'authorId': '2252036604', 'name': 'Forrest Melton'}, {'authorId': '2291226564', 'name': 'Richard G. Allen'}, {'authorId': '2275769896', 'name': 'Martha Anderson'}, {'authorId': '2242883446', 'name': 'Joshua B. Fisher'}, {'authorId': '2280253451', 'name': 'Ayse Kilic'}, {'authorId': '2079428507', 'name': 'A. Ruhoff'}, {'authorId': '1694043', 'name': 'G. Senay'}, {'authorId': '2136338372', 'name': 'B. Minor'}, {'authorId': '2271887801', 'name': 'Charles Morton'}, {'authorId': '2280212673', 'name': 'Thomas Ott'}, {'authorId': '2147113387', 'name': 'Lee Johnson'}, {'authorId': '2273217663', 'name': 'Bruno Comini de Andrade'}, {'authorId': '2138752076', 'name': 'Will Carrara'}, {'authorId': '2280248493', 'name': 'Conor T. Doherty'}, {'authorId': '2080890427', 'name': 'C. Dunkerly'}, {'authorId': '107842662', 'name': 'M. Friedrichs'}, {'authorId': '122677046', 'name': 'A. Guzman'}, {'authorId': '2277655821', 'name': 'Christopher Hain'}, {'authorId': '48065542', 'name': 'G. Halverson'}, {'authorId': '9703544', 'name': 'Yanghui Kang'}, {'authorId': '9730649', 'name': 'K. Knipper'}, {'authorId': '1659378183', 'name': 'L. Laipelt'}, {'authorId': '1422701566', 'name': 'S. Ortega-Salazar'}, {'authorId': '2280253894', 'name': 'Christopher Pearson'}, {'authorId': '107610674', 'name': 'Gabriel E. L. Parrish'}, {'authorId': '19328988', 'name': 'A. Purdy'}, {'authorId': '71595925', 'name': 'P. ReVelle'}, {'authorId': '2280184646', 'name': 'Tianxin Wang'}, {'authorId': '2275128211', 'name': 'Yun Yang'}]","{'url': 'https://www.nature.com/articles/s44221-023-00181-7.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1038/s44221-023-00181-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s44221-023-00181-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","remotely sensed evapotranspiration (et) data offer strong potential to support data-driven approaches for sustainable water management. however, practitioners require robust and rigorous accuracy assessments of such data. the openet system, which includes an ensemble of six remote sensing models, was developed to increase access to field-scale (30 m) et data for the contiguous united states. here we compare openet outputs against data from 152 in situ stations, primarily eddy covariance flux towers, deployed across the contiguous united states. mean absolute error at cropland sites for the openet ensemble value is 15.8 mm per month (17% of mean observed et), mean bias error is −5.3 mm per month (6%) and r2 is 0.9. results for shrublands and forested sites show higher inter-model variability and lower accuracy relative to croplands. high accuracy and multi-model convergence across croplands demonstrate the utility of a model ensemble approach, and enhance confidence among et data practitioners, including the agricultural water resource management community.",https://www.nature.com/articles/s44221-023-00181-7.pdf
37aa76b76301899bfaaa4fe6a1b0e5c4c9b58f65,Water Resource Management,"Water is an essential component for the survival of mankind and for balancing the ecosystem and livelihood. The world is experiencing a scarcity of water, both in terms of quality and quantity. Although there are several in-situ measurement techniques, they seem insufficient for large areas involving several parameters. Analysis of satellite images for estimating the quality and quantity of natural water has become an accepted tool for better spatial planning. With the increase in variety, volume, and velocity of satellite image, a tool for faster and accurate processing of the data is needed. Google Earth Engine (GEE) is one such cloud-based geo-big data platform. This chapter reviews the work of several researchers worldwide who have used and demonstrated the capability of satellite images with other geo-big data such as elevation, landcover, etc. for water resource management on the GEE platform. It can be concluded from the review work that GEE can help in estimating the water quality parameters with reasonable accuracy, comparable to the in-situ measurement, albeit quickly.",2022,"[{'authorId': '2070101258', 'name': 'Satya Prakash'}, {'authorId': '2113885597', 'name': 'P. S. Deepak'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1201/b16814-205?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1201/b16814-205, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","water is an essential component for the survival of mankind and for balancing the ecosystem and livelihood. the world is experiencing a scarcity of water, both in terms of quality and quantity. although there are several in-situ measurement techniques, they seem insufficient for large areas involving several parameters. analysis of satellite images for estimating the quality and quantity of natural water has become an accepted tool for better spatial planning. with the increase in variety, volume, and velocity of satellite image, a tool for faster and accurate processing of the data is needed. google earth engine (gee) is one such cloud-based geo-big data platform. this chapter reviews the work of several researchers worldwide who have used and demonstrated the capability of satellite images with other geo-big data such as elevation, landcover, etc. for water resource management on the gee platform. it can be concluded from the review work that gee can help in estimating the water quality parameters with reasonable accuracy, comparable to the in-situ measurement, albeit quickly.",
50f430338340ddcb9cc8572e51dbc60f3001bbce,Smart Water Resource Management Using Artificial Intelligence—A Review,"Water management is one of the crucial topics discussed in most of the international forums. Water harvesting and recycling are the major requirements to meet the global upcoming demand of the water crisis, which is prevalent. To achieve this, we need more emphasis on water management techniques that are applied across various categories of the applications. Keeping in mind the population density index, there is a dire need to implement intelligent water management mechanisms for effective distribution, conservation and to maintain the water quality standards for various purposes. The prescribed work discusses about few major areas of applications that are required for efficient water management. Those are recent trends in wastewater recycle, water distribution, rainwater harvesting and irrigation management using various Artificial Intelligence (AI) models. The data acquired for these applications are purely unique and also differs by type. Hence, there is a dire need to use a model or algorithm that can be applied to provide solutions across all these applications. Artificial Intelligence (AI) and Deep Learning (DL) techniques along with the Internet of things (IoT) framework can facilitate in designing a smart water management system for sustainable water usage from natural resources. This work surveys various water management techniques and the use of AI/DL along with the IoT network and case studies, sample statistical analysis to develop an efficient water management framework.",2022,"[{'authorId': '143808569', 'name': 'S. Krishnan'}, {'authorId': '2243313754', 'name': 'M. K. Nallakaruppan'}, {'authorId': '2174374615', 'name': 'Rajeswari Chengoden'}, {'authorId': '35723448', 'name': 'Srinivas Koppu'}, {'authorId': '71316288', 'name': 'M. Iyapparaja'}, {'authorId': '3066496', 'name': 'Jayakumar Sadhasivam'}, {'authorId': '2188300673', 'name': 'Sankaran Sethuraman'}]","{'url': 'https://www.mdpi.com/2071-1050/14/20/13384/pdf?version=1666668672', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su142013384?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su142013384, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","water management is one of the crucial topics discussed in most of the international forums. water harvesting and recycling are the major requirements to meet the global upcoming demand of the water crisis, which is prevalent. to achieve this, we need more emphasis on water management techniques that are applied across various categories of the applications. keeping in mind the population density index, there is a dire need to implement intelligent water management mechanisms for effective distribution, conservation and to maintain the water quality standards for various purposes. the prescribed work discusses about few major areas of applications that are required for efficient water management. those are recent trends in wastewater recycle, water distribution, rainwater harvesting and irrigation management using various artificial intelligence (ai) models. the data acquired for these applications are purely unique and also differs by type. hence, there is a dire need to use a model or algorithm that can be applied to provide solutions across all these applications. artificial intelligence (ai) and deep learning (dl) techniques along with the internet of things (iot) framework can facilitate in designing a smart water management system for sustainable water usage from natural resources. this work surveys various water management techniques and the use of ai/dl along with the iot network and case studies, sample statistical analysis to develop an efficient water management framework.",https://www.mdpi.com/2071-1050/14/20/13384/pdf?version=1666668672
54b06beb6fc129000bbe16358019958ebf9570f5,Hydrological Intensification Will Increase the Complexity of Water Resource Management,"Global warming intensifies the hydrological cycle by altering the rate of water fluxes to and from the terrestrial surface, resulting in an increase in extreme precipitation events and longer dry spells. Prior hydrological intensification work has largely focused on precipitation without joint consideration of evaporative demand changes and how plants respond to these changes. Informed by state‐of‐the‐art climate models, we examine projected changes in hydrological intensification and its role in complicating water resources management using a framework that accounts for precipitation surplus and evaporative demand. Using a metric that combines the difference between daily precipitation and daily evaporative demand (surplus events) and consecutive days when evaporative demand exceeds precipitation (deficit time), we show that, globally, surplus events will become larger (+11.5% and +18.5% for moderate and high emission scenarios, respectively) and the duration between them longer (+5.1%; +9.6%) by the end of the century, with the largest changes in the northern latitudes. The intra‐annual occurrence of these extremes will stress existing water management infrastructure in major river basins, where over one third of years during 2070–2100 under a moderate emissions scenario will be hydrologically intense (large intra‐annual increases in surplus intensity and deficit time), tripling that of the historical baseline. Larger increases in hydrologically intense years are found in basins with large reservoir capacity (e.g., Amazon, Congo, and Danube River Basins), which have significant populations, irrigate considerable farmland, and support threatened and endangered aquatic species. Incorporating flexibility into water resource infrastructure and management will be paramount with continued hydrological intensification.",2022,"[{'authorId': '1877904', 'name': 'D. Ficklin'}, {'authorId': '4688157', 'name': 'S. Null'}, {'authorId': '6088474', 'name': 'J. Abatzoglou'}, {'authorId': '40527811', 'name': 'K. Novick'}, {'authorId': '1810720654', 'name': 'Daniel T. L. Myers'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1029/2021EF002487?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1029/2021EF002487, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","global warming intensifies the hydrological cycle by altering the rate of water fluxes to and from the terrestrial surface, resulting in an increase in extreme precipitation events and longer dry spells. prior hydrological intensification work has largely focused on precipitation without joint consideration of evaporative demand changes and how plants respond to these changes. informed by state‐of‐the‐art climate models, we examine projected changes in hydrological intensification and its role in complicating water resources management using a framework that accounts for precipitation surplus and evaporative demand. using a metric that combines the difference between daily precipitation and daily evaporative demand (surplus events) and consecutive days when evaporative demand exceeds precipitation (deficit time), we show that, globally, surplus events will become larger (+11.5% and +18.5% for moderate and high emission scenarios, respectively) and the duration between them longer (+5.1%; +9.6%) by the end of the century, with the largest changes in the northern latitudes. the intra‐annual occurrence of these extremes will stress existing water management infrastructure in major river basins, where over one third of years during 2070–2100 under a moderate emissions scenario will be hydrologically intense (large intra‐annual increases in surplus intensity and deficit time), tripling that of the historical baseline. larger increases in hydrologically intense years are found in basins with large reservoir capacity (e.g., amazon, congo, and danube river basins), which have significant populations, irrigate considerable farmland, and support threatened and endangered aquatic species. incorporating flexibility into water resource infrastructure and management will be paramount with continued hydrological intensification.",
1e41942f9c06e1ee889641837f068457394dd058,"Assessment of groundwater potential zone for sustainable water resource management in south-western part of Birbhum District, West Bengal","Water is an indispensable natural resource for survival of any species in the globe. For centuries, civilization has flourished on the bank of river based on the easy availability of water. Groundwater is one of the prime sources of freshwater supply, but, its occurrence and spatial distribution are highly uneven and affected by several surface and subsurface features. Development of several geospatial tool based on the remote sensing and GIS in recent time helps immensely for delineation and management of this precious resource. The present study has been undertaken in south-western part of Birbhum district, West Bengal with an objective to delineate groundwater potential zone using multiple criteria decision analysis and GIS. Seven thematic layers concerning with geology, geomorphology, hydrology, land use land cover and edhaphic factor have been employed in this study with proper weightage depending on their role in groundwater formation to identify the groundwater potential zone. By using analytical hierarchy process, whole study area has been classified into four zones ranging from excellent to poor. Primary field data and secondary data about depth of groundwater have been compared with the result to make it authentic. The result shows that the southern part composed of alluvial plain has the excellent potential compared to the northern lateritic and pediment part where groundwater potential is moderate. Eventually, few recommendation and suggestion have been framed for sustainable water resource management that will help the researchers, planners and other decision-makers for judicious exploration and management of the groundwater resource in the study area.",2022,"[{'authorId': '66842768', 'name': 'S. Chatterjee'}, {'authorId': '49247182', 'name': 'Shyamal Dutta'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s13201-021-01549-4.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13201-021-01549-4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13201-021-01549-4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","water is an indispensable natural resource for survival of any species in the globe. for centuries, civilization has flourished on the bank of river based on the easy availability of water. groundwater is one of the prime sources of freshwater supply, but, its occurrence and spatial distribution are highly uneven and affected by several surface and subsurface features. development of several geospatial tool based on the remote sensing and gis in recent time helps immensely for delineation and management of this precious resource. the present study has been undertaken in south-western part of birbhum district, west bengal with an objective to delineate groundwater potential zone using multiple criteria decision analysis and gis. seven thematic layers concerning with geology, geomorphology, hydrology, land use land cover and edhaphic factor have been employed in this study with proper weightage depending on their role in groundwater formation to identify the groundwater potential zone. by using analytical hierarchy process, whole study area has been classified into four zones ranging from excellent to poor. primary field data and secondary data about depth of groundwater have been compared with the result to make it authentic. the result shows that the southern part composed of alluvial plain has the excellent potential compared to the northern lateritic and pediment part where groundwater potential is moderate. eventually, few recommendation and suggestion have been framed for sustainable water resource management that will help the researchers, planners and other decision-makers for judicious exploration and management of the groundwater resource in the study area.",https://link.springer.com/content/pdf/10.1007/s13201-021-01549-4.pdf
0b1490376db950a676ea367e1ef5d7aa20846632,Smart Technologies for Water Resource Management: An Overview,"The latest progress in information and communication technology (ICT) and the Internet of Things (IoT) have opened up new opportunities for real-time monitoring and controlling of cities’ structures, infrastructures, and services. In this context, smart water management technology provides the data and tools to help users more effectively manage water usage. Data collected with smart water devices are being integrated with building management systems to show how much water is used by occupants as well as to identify the consumption areas to use water more efficiently. By this approach, smart buildings represent an innovative solution that enhances a city’s sustainability and contributes to overcoming environmental challenges due to increasing population and climate change. One of the main challenges is resource-saving and recovery. Water is an all-important need of all living beings, and the concerns of its scarcity impose a transition to innovative and sustainable management starting from the building scale. Thus, this manuscript aims to provide an updated and valuable overview for researchers, consumers, and stakeholders regarding implementing smart and sustainable technologies for water resource management, primarily for building-scale uses.",2022,"[{'authorId': '94259480', 'name': 'S. A. Palermo'}, {'authorId': '51500374', 'name': 'M. Maiolo'}, {'authorId': '2004203522', 'name': 'A. C. Brusco'}, {'authorId': '50038937', 'name': 'M. Turco'}, {'authorId': '101114422', 'name': 'B. Pirouz'}, {'authorId': '2056332210', 'name': 'E. Greco'}, {'authorId': '2743420', 'name': 'G. Spezzano'}, {'authorId': '39993787', 'name': 'P. Piro'}]","{'url': 'https://www.mdpi.com/1424-8220/22/16/6225/pdf?version=1660899114', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9414186, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the latest progress in information and communication technology (ict) and the internet of things (iot) have opened up new opportunities for real-time monitoring and controlling of cities’ structures, infrastructures, and services. in this context, smart water management technology provides the data and tools to help users more effectively manage water usage. data collected with smart water devices are being integrated with building management systems to show how much water is used by occupants as well as to identify the consumption areas to use water more efficiently. by this approach, smart buildings represent an innovative solution that enhances a city’s sustainability and contributes to overcoming environmental challenges due to increasing population and climate change. one of the main challenges is resource-saving and recovery. water is an all-important need of all living beings, and the concerns of its scarcity impose a transition to innovative and sustainable management starting from the building scale. thus, this manuscript aims to provide an updated and valuable overview for researchers, consumers, and stakeholders regarding implementing smart and sustainable technologies for water resource management, primarily for building-scale uses.",https://www.mdpi.com/1424-8220/22/16/6225/pdf?version=1660899114
a81127d1bad7d09ec18369b1a035f5cba0f24919,"System Dynamics-Multiple Objective Optimization Model for Water Resource Management: A Case Study in Jiaxing City, China","Predicting and allocating water resources have become important tasks in water resource management. System dynamics and optimal planning models are widely applied to solve individual problems, but are seldom combined in studies. In this work, we developed a framework involving a system dynamics-multiple objective optimization (SD-MOO) model, which integrated the functions of simulation, policy control, and water allocation, and applied it to a case study of water management in Jiaxing, China to demonstrate the modeling. The predicted results of the case study showed that water shortage would not occur at a high-inflow level during 2018–2035 but would appear at mid- and low-inflow levels in 2025 and 2022, respectively. After we made dynamic adjustments to water use efficiency, economic growth, population growth, and water resource utilization, the predicted water shortage rates decreased by approximately 69–70% at the mid- and low-inflow levels in 2025 and 2035 compared to the scenarios without any adjustment strategies. Water allocation schemes obtained from the “prediction + dynamic regulation + optimization” framework were competitive in terms of social, economic and environmental benefits and flexibly satisfied the water demands. The case study demonstrated that the SD-MOO model framework could be an effective tool in achieving sustainable water resource management.",2021,"[{'authorId': '47155167', 'name': 'Xiaoying Zhou'}, {'authorId': '14807100', 'name': 'Feier Wang'}, {'authorId': '2112706629', 'name': 'Kuan Huang'}, {'authorId': '2108925116', 'name': 'Huichun Zhang'}, {'authorId': '46380855', 'name': 'Jie-Ru Yu'}, {'authorId': '2088529232', 'name': 'Alan Y. Han'}]","{'url': 'https://www.mdpi.com/2073-4441/13/5/671/pdf?version=1614852628', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/W13050671?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/W13050671, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","predicting and allocating water resources have become important tasks in water resource management. system dynamics and optimal planning models are widely applied to solve individual problems, but are seldom combined in studies. in this work, we developed a framework involving a system dynamics-multiple objective optimization (sd-moo) model, which integrated the functions of simulation, policy control, and water allocation, and applied it to a case study of water management in jiaxing, china to demonstrate the modeling. the predicted results of the case study showed that water shortage would not occur at a high-inflow level during 2018–2035 but would appear at mid- and low-inflow levels in 2025 and 2022, respectively. after we made dynamic adjustments to water use efficiency, economic growth, population growth, and water resource utilization, the predicted water shortage rates decreased by approximately 69–70% at the mid- and low-inflow levels in 2025 and 2035 compared to the scenarios without any adjustment strategies. water allocation schemes obtained from the “prediction + dynamic regulation + optimization” framework were competitive in terms of social, economic and environmental benefits and flexibly satisfied the water demands. the case study demonstrated that the sd-moo model framework could be an effective tool in achieving sustainable water resource management.",https://www.mdpi.com/2073-4441/13/5/671/pdf?version=1614852628
7b094e67f809c4007a22150d46f15b89d20b519f,"A Conceptual Framework for Social, Behavioral, and Environmental Change through Stakeholder Engagement in Water Resource Management","Abstract Incorporating stakeholder engagement into environmental management may help in the pursuit of novel approaches for addressing complex water resource problems. However, evidence about how and under what circumstances stakeholder engagement enables desirable changes remains elusive. In this paper, we develop a conceptual framework for studying social and environmental changes possible through stakeholder engagement in water resource management, from inception to outcomes. We synthesize concepts from multiple literatures to provide a framework for tracing linkages from contextual conditions, through engagement process design features, to social learning, community capacity building, and behavioral change at individual, group, and group network levels, and ultimately to environmental change. We discuss opportunities to enhance the framework including through empirical applications to delineate scalar and temporal dimensions of social, behavioral, and environmental changes resulting from stakeholder engagement, and the potential for negative outcomes thus far glossed over in research on change through engagement.",2021,"[{'authorId': '50506319', 'name': 'Weston M. Eaton'}, {'authorId': '11474433', 'name': 'Kathryn J. Brasier'}, {'authorId': '3204473', 'name': 'M. Burbach'}, {'authorId': '119280663', 'name': 'Walt Whitmer'}, {'authorId': '66922401', 'name': 'E. Engle'}, {'authorId': '36786446', 'name': 'M. Burnham'}, {'authorId': '145471114', 'name': 'Barbara Quimby'}, {'authorId': '1490516747', 'name': 'Anil Kumar Chaudhary'}, {'authorId': '153312949', 'name': 'Hannah T. Whitley'}, {'authorId': '134151801', 'name': 'Jodi L. Delozier'}, {'authorId': '144982011', 'name': 'L. Fowler'}, {'authorId': '6928746', 'name': 'Amber Wutich'}, {'authorId': '108419140', 'name': 'Julia C. Bausch'}, {'authorId': '66729646', 'name': 'M. Beresford'}, {'authorId': '51932584', 'name': 'C. Hinrichs'}, {'authorId': '1405482269', 'name': 'C. Burkhart-Kriesel'}, {'authorId': '1994684688', 'name': 'H. Preisendanz'}, {'authorId': '48592962', 'name': 'Clinton Williams'}, {'authorId': '2113388982', 'name': 'J. Watson'}, {'authorId': '98823121', 'name': 'J. Weigle'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/08941920.2021.1936717?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/08941920.2021.1936717, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract incorporating stakeholder engagement into environmental management may help in the pursuit of novel approaches for addressing complex water resource problems. however, evidence about how and under what circumstances stakeholder engagement enables desirable changes remains elusive. in this paper, we develop a conceptual framework for studying social and environmental changes possible through stakeholder engagement in water resource management, from inception to outcomes. we synthesize concepts from multiple literatures to provide a framework for tracing linkages from contextual conditions, through engagement process design features, to social learning, community capacity building, and behavioral change at individual, group, and group network levels, and ultimately to environmental change. we discuss opportunities to enhance the framework including through empirical applications to delineate scalar and temporal dimensions of social, behavioral, and environmental changes resulting from stakeholder engagement, and the potential for negative outcomes thus far glossed over in research on change through engagement.",
c6995877e6ec64315ed84bfe848774e455e1c7e2,Integrated Water Resource Management: Rethinking the Contribution of Rainwater Harvesting,"Rainwater harvesting (RWH) is generally perceived as a promising cost-effective alternative water resource for potable and non-potable uses (water augmentation) and for reducing flood risks. The performance of RWH systems has been evaluated for various purposes over the past few decades. These systems certainly provide economic, environmental, and technological benefits of water uses. However, regarding RWH just as an effective alternative water supply to deal with the water scarcity is a mistake. The present communication advocates for a systematic RWH and partial infiltration wherever and whenever rain falls. By doing so, the detrimental effects of flooding are reduced, groundwater is recharged, water for agriculture and livestock is stored, and conventional water sources are saved. In other words, RWH should be at the heart of water management worldwide. The realization of this goal is easy even under low-resource situations, as infiltration pits and small dams can be constructed with local skills and materials.",2021,"[{'authorId': '2151325121', 'name': 'Zhe Huang'}, {'authorId': '2091627259', 'name': 'Esther Laurentine Nya'}, {'authorId': '50743613', 'name': 'M. Rahman'}, {'authorId': '93366479', 'name': 'T. Mwamila'}, {'authorId': '117655284', 'name': 'Viêt Cao'}, {'authorId': '13222435', 'name': 'W. Gwenzi'}, {'authorId': '3971803', 'name': 'C. Noubactep'}]","{'url': 'https://www.mdpi.com/2071-1050/13/15/8338/pdf?version=1627454303', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/su13158338?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su13158338, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","rainwater harvesting (rwh) is generally perceived as a promising cost-effective alternative water resource for potable and non-potable uses (water augmentation) and for reducing flood risks. the performance of rwh systems has been evaluated for various purposes over the past few decades. these systems certainly provide economic, environmental, and technological benefits of water uses. however, regarding rwh just as an effective alternative water supply to deal with the water scarcity is a mistake. the present communication advocates for a systematic rwh and partial infiltration wherever and whenever rain falls. by doing so, the detrimental effects of flooding are reduced, groundwater is recharged, water for agriculture and livestock is stored, and conventional water sources are saved. in other words, rwh should be at the heart of water management worldwide. the realization of this goal is easy even under low-resource situations, as infiltration pits and small dams can be constructed with local skills and materials.",https://www.mdpi.com/2071-1050/13/15/8338/pdf?version=1627454303
fa5b8486060709e0015e74642fa51833a4d7f12f,Computation of Evapotranspiration with Artificial Intelligence for Precision Water Resource Management,"Accurate estimation of reference evapotranspiration (ETo) provides useful information for water resource management and sustainable agriculture. This study estimates ETo with recurrent neural networks (RNNs), namely long short-term memory (LSTM) and bidirectional LSTM. Four representative meteorological sites (North Cape, Summerside, Harrington, and Saint Peters) were selected across Prince Edward Island (PEI), Canada to form a PEI dataset from mean values of the four sites’ climatic variables for capturing climatic variability from all parts of the province. Based on subset regression analysis, the highest contributing climatic variables, namely maximum air temperature and relative humidity, were selected as input variables for RNNs’ training (2011–2015) and testing (2016–2017) runs. The results suggested that the LSTM and bidirectional LSTM are suitable methods to accurately (R2 > 0.90) estimate ETo for all sites except Harrington. Testing period (2016–2017) root mean square errors were recorded in range of 0.38–0.58 mm/day for all sites. No major differences were observed in accuracy of LSTM and bidirectional LSTM. Another objective of this study was to highlight the potential gap between ETO and rainfall for assessing agriculture sustainability in Prince Edward Island. Analyses of the data highlighted that the cumulative ETo surpassed the cumulative rainfall potentially affecting yield of major crops in the island. Therefore, agriculture sustainability requires viable options such as supplemental irrigation to replenish the crop water requirements as and when needed.",2020,"[{'authorId': '1581309941', 'name': 'Hassan Afzaal'}, {'authorId': '98093387', 'name': 'A. Farooque'}, {'authorId': '49143558', 'name': 'F. Abbas'}, {'authorId': '50307249', 'name': 'B. Acharya'}, {'authorId': '6430336', 'name': 'T. Esau'}]","{'url': 'https://www.mdpi.com/2076-3417/10/5/1621/pdf?version=1583400469', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app10051621?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app10051621, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","accurate estimation of reference evapotranspiration (eto) provides useful information for water resource management and sustainable agriculture. this study estimates eto with recurrent neural networks (rnns), namely long short-term memory (lstm) and bidirectional lstm. four representative meteorological sites (north cape, summerside, harrington, and saint peters) were selected across prince edward island (pei), canada to form a pei dataset from mean values of the four sites’ climatic variables for capturing climatic variability from all parts of the province. based on subset regression analysis, the highest contributing climatic variables, namely maximum air temperature and relative humidity, were selected as input variables for rnns’ training (2011–2015) and testing (2016–2017) runs. the results suggested that the lstm and bidirectional lstm are suitable methods to accurately (r2 > 0.90) estimate eto for all sites except harrington. testing period (2016–2017) root mean square errors were recorded in range of 0.38–0.58 mm/day for all sites. no major differences were observed in accuracy of lstm and bidirectional lstm. another objective of this study was to highlight the potential gap between eto and rainfall for assessing agriculture sustainability in prince edward island. analyses of the data highlighted that the cumulative eto surpassed the cumulative rainfall potentially affecting yield of major crops in the island. therefore, agriculture sustainability requires viable options such as supplemental irrigation to replenish the crop water requirements as and when needed.",https://www.mdpi.com/2076-3417/10/5/1621/pdf?version=1583400469
2b9d120ba7f49b77c7ab5369a55896e60a5c4202,Watershed Modelling of the Mindanao River Basin in the Philippines Using the SWAT for Water Resource Management,"This study aims to simulate the watershed of the Mindanao River Basin (MRB) to enhance water resource management for potential hydropower applications to meet the power demand in Mindanao with an average growth of 3.8% annually. The soil and water assessment tool (SWAT) model was used with inputs for geospatial datasets and weather records at four meteorological stations from DOST-PAGASA. To overcome the lack of precipitation data in the MRB, the precipitation records were investigated by comparing the records with the global gridded precipitation datasets from the NCDC-CPC and the GPCC. Then, the SWAT simulated discharges with the three precipitation data were calibrated with river discharge records at three stations in the Nituan, Libungan and Pulangi rivers. Due to limited records for the river discharges, the model results were, then, validated using the proxy basin principle along the same rivers in the Nituan, Libungan, and Pulangi areas. The R 2  values from the validation are 0.61, 0.50 and 0.33, respectively, with the DOST-PAGASA precipitation; 0.64, 0.46 and 0.40, respectively, with the NCDC-CPC precipitation; and 0.57, 0.48 and 0.21, respectively, with the GPCC precipitation. The relatively low model performances in Libungan and Pulangi rivers are mainly due to the lack of datasets on the dam and water withdrawal in the MRB. Therefore, this study also addresses the issue of data quality for precipitation and data scarcity for river discharge, dam, and water withdrawal for water resource management in the MRB and show how to overcome the data quality and scarcity.",2020,"[{'authorId': '1659304218', 'name': 'Ismail Adal Guiamel'}, {'authorId': '4352515', 'name': 'Han Soo Lee'}]","{'url': 'https://www.civilejournal.org/index.php/cej/article/download/2060/pdf', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.28991/cej-2020-03091496?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.28991/cej-2020-03091496, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study aims to simulate the watershed of the mindanao river basin (mrb) to enhance water resource management for potential hydropower applications to meet the power demand in mindanao with an average growth of 3.8% annually. the soil and water assessment tool (swat) model was used with inputs for geospatial datasets and weather records at four meteorological stations from dost-pagasa. to overcome the lack of precipitation data in the mrb, the precipitation records were investigated by comparing the records with the global gridded precipitation datasets from the ncdc-cpc and the gpcc. then, the swat simulated discharges with the three precipitation data were calibrated with river discharge records at three stations in the nituan, libungan and pulangi rivers. due to limited records for the river discharges, the model results were, then, validated using the proxy basin principle along the same rivers in the nituan, libungan, and pulangi areas. the r 2 values from the validation are 0.61, 0.50 and 0.33, respectively, with the dost-pagasa precipitation; 0.64, 0.46 and 0.40, respectively, with the ncdc-cpc precipitation; and 0.57, 0.48 and 0.21, respectively, with the gpcc precipitation. the relatively low model performances in libungan and pulangi rivers are mainly due to the lack of datasets on the dam and water withdrawal in the mrb. therefore, this study also addresses the issue of data quality for precipitation and data scarcity for river discharge, dam, and water withdrawal for water resource management in the mrb and show how to overcome the data quality and scarcity.",https://www.civilejournal.org/index.php/cej/article/download/2060/pdf
af863294454eca8268e6d1ff8044ffaaf7736d55,Multiobjective Optimization for Water Resource Management in Low-Flow Areas Based on a Coupled Surface Water–Groundwater Model,"AbstractOptimal operation of water resource systems requires understanding the interaction between the surface water and groundwater in the region of interest. Furthermore, model parameters as well...",2020,"[{'authorId': '1473250230', 'name': 'Masoomeh Zeinali'}, {'authorId': '98164697', 'name': 'A. Azari'}, {'authorId': '2075159867', 'name': 'Mohammad Mehdi Heidari'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1061/(asce)wr.1943-5452.0001189?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1061/(asce)wr.1943-5452.0001189, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",multiobjective optimization for water resource management in low-flow areas based on a coupled surface water–groundwater model,
babed1147dce00091ecb1ac7c47b38fb6561ecd5,Smart Water Technology for Efficient Water Resource Management: A Review,"According to the United Nation’s World Water Development Report, by 2050 more than 50% of the world’s population will be under high water scarcity. To avoid water stress, water resources are needed to be managed more securely. Smart water technology (SWT) has evolved for proper management and saving of water resources. Smart water system (SWS) uses sensor, information, and communication technology (ICT) to provide real-time monitoring of data such as pressure, water ow, water quality, moisture, etc. with the capability to detect any abnormalities such as non-revenue water (NRW) losses, water contamination in the water distribution system (WDS). It makes water and energy utilization more efficient in the water treatment plant and agriculture. In addition, the standardization of data format i.e., use of Water Mark UP language 2.0 has made data exchange easier for between different water authorities. This review research exhibits the current state-of-the-art of the on-going SWT along with present challenges and future scope on the mentioned technologies. A conclusion is drawn that smart technologies can lead to better water resource management, which can lead to the reduction of water scarcity worldwide. High implementation cost may act as a barrier to the implementation of SWT in developing countries, whereas data security and its reliability along with system ability to give accurate results are some of the key challenges in its field implementation.",2020,"[{'authorId': '145830956', 'name': 'Aditya Gupta'}, {'authorId': '50162080', 'name': 'Prerna Pandey'}, {'authorId': '145549004', 'name': 'A. Feijóo'}, {'authorId': '3419747', 'name': 'Z. Yaseen'}, {'authorId': '3430682', 'name': 'N. Bokde'}]","{'url': 'https://www.mdpi.com/1996-1073/13/23/6268/pdf?version=1606990746', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/en13236268?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/en13236268, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","according to the united nation’s world water development report, by 2050 more than 50% of the world’s population will be under high water scarcity. to avoid water stress, water resources are needed to be managed more securely. smart water technology (swt) has evolved for proper management and saving of water resources. smart water system (sws) uses sensor, information, and communication technology (ict) to provide real-time monitoring of data such as pressure, water ow, water quality, moisture, etc. with the capability to detect any abnormalities such as non-revenue water (nrw) losses, water contamination in the water distribution system (wds). it makes water and energy utilization more efficient in the water treatment plant and agriculture. in addition, the standardization of data format i.e., use of water mark up language 2.0 has made data exchange easier for between different water authorities. this review research exhibits the current state-of-the-art of the on-going swt along with present challenges and future scope on the mentioned technologies. a conclusion is drawn that smart technologies can lead to better water resource management, which can lead to the reduction of water scarcity worldwide. high implementation cost may act as a barrier to the implementation of swt in developing countries, whereas data security and its reliability along with system ability to give accurate results are some of the key challenges in its field implementation.",https://www.mdpi.com/1996-1073/13/23/6268/pdf?version=1606990746
607ec4fb17534fdb3dbbcddee68844252aa8cc75,Applications of Bayesian Networks as Decision Support Tools for Water Resource Management under Climate Change and Socio-Economic Stressors: A Critical Appraisal,"Bayesian networks (BNs) are widely implemented as graphical decision support tools which use probability inferences to generate “what if?” and “which is best?” analyses of potential management options for water resource management, under climate change and socio-economic stressors. This paper presents a systematic quantitative literature review of applications of BNs for decision support in water resource management. The review quantifies to what extent different types of data (quantitative and/or qualitative) are used, to what extent optimization-based and/or scenario-based approaches are adopted for decision support, and to what extent different categories of adaptation measures are evaluated. Most reviewed publications applied scenario-based approaches (68%) to evaluate the performance of management measures, whilst relatively few studies (18%) applied optimization-based approaches to optimize management measures. Institutional and social measures (62%) were mostly applied to the management of water-related concerns, followed by technological and engineered measures (47%), and ecosystem-based measures (37%). There was no significant difference in the use of quantitative and/or qualitative data across different decision support approaches (p = 0.54), or in the evaluation of different categories of management measures (p = 0.25). However, there was significant dependence (p = 0.076) between the types of management measure(s) evaluated, and the decision support approaches used for that evaluation. The potential and limitations of BN applications as decision support systems are discussed along with solutions and recommendations, thereby further facilitating the application of this promising decision support tool for future research priorities and challenges surrounding uncertain and complex water resource systems driven by multiple interactions amongst climatic and non-climatic changes.",2019,"[{'authorId': '3490655', 'name': 'Thuc D. Phan'}, {'authorId': '144509173', 'name': 'J. Smart'}, {'authorId': '1403795450', 'name': 'B. Stewart‐Koster'}, {'authorId': '31467820', 'name': 'O. Sahin'}, {'authorId': '3490757', 'name': 'W. Hadwen'}, {'authorId': '49595106', 'name': 'L. T. Dinh'}, {'authorId': '16064193', 'name': 'Iman Tahmasbian'}, {'authorId': '3490832', 'name': 'S. Capon'}]","{'url': 'https://www.mdpi.com/2073-4441/11/12/2642/pdf?version=1576310955', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/w11122642?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/w11122642, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","bayesian networks (bns) are widely implemented as graphical decision support tools which use probability inferences to generate “what if?” and “which is best?” analyses of potential management options for water resource management, under climate change and socio-economic stressors. this paper presents a systematic quantitative literature review of applications of bns for decision support in water resource management. the review quantifies to what extent different types of data (quantitative and/or qualitative) are used, to what extent optimization-based and/or scenario-based approaches are adopted for decision support, and to what extent different categories of adaptation measures are evaluated. most reviewed publications applied scenario-based approaches (68%) to evaluate the performance of management measures, whilst relatively few studies (18%) applied optimization-based approaches to optimize management measures. institutional and social measures (62%) were mostly applied to the management of water-related concerns, followed by technological and engineered measures (47%), and ecosystem-based measures (37%). there was no significant difference in the use of quantitative and/or qualitative data across different decision support approaches (p = 0.54), or in the evaluation of different categories of management measures (p = 0.25). however, there was significant dependence (p = 0.076) between the types of management measure(s) evaluated, and the decision support approaches used for that evaluation. the potential and limitations of bn applications as decision support systems are discussed along with solutions and recommendations, thereby further facilitating the application of this promising decision support tool for future research priorities and challenges surrounding uncertain and complex water resource systems driven by multiple interactions amongst climatic and non-climatic changes.",https://www.mdpi.com/2073-4441/11/12/2642/pdf?version=1576310955
7db8bac4dac742c68282bd48dab7c222d516152e,Shifting the paradigm in community-based water resource management in North-West Cameroon: A search for an alternative management approach,"ABSTRACT This paper examines practical approaches for Community-Based Water Resource Management in North-West Region, Cameroon. Empirical data collected through participatory learning and action revealed that a lesser degree of community involvement and more centralized systems of Natural Resource Management (NRM), is a major cause of unsustainable water management. A fundamental challenge in NRM is how to effectively engage and stimulate public, private and local institutions in policymaking to address resource use conflicts and improve governance. Part of the problem in developing effective management models has been identified through the nature of approaches that inform contemporary methodologies of NRM. Many of these methods have largely been influenced by top-down systems of management that have played a major role in disenfranchising those for whom development is meant for. It is, therefore, imperative to rethink contemporary management approaches and develop more pragmatic models that will promote effective systems of NRM. A focus on and applying a rational System Thinking Analysis could potentially produce reinforcing and self-reinforcing effects to enhance rural water systems and promote sustainable water management in the North-West Region, Cameroon.",2020,"[{'authorId': '108595486', 'name': 'H. B. Tantoh'}, {'authorId': '117933536', 'name': 'M. Simatele'}, {'authorId': '32288767', 'name': 'Eromose E. Ebhuoma'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/15575330.2019.1659382?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/15575330.2019.1659382, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract this paper examines practical approaches for community-based water resource management in north-west region, cameroon. empirical data collected through participatory learning and action revealed that a lesser degree of community involvement and more centralized systems of natural resource management (nrm), is a major cause of unsustainable water management. a fundamental challenge in nrm is how to effectively engage and stimulate public, private and local institutions in policymaking to address resource use conflicts and improve governance. part of the problem in developing effective management models has been identified through the nature of approaches that inform contemporary methodologies of nrm. many of these methods have largely been influenced by top-down systems of management that have played a major role in disenfranchising those for whom development is meant for. it is, therefore, imperative to rethink contemporary management approaches and develop more pragmatic models that will promote effective systems of nrm. a focus on and applying a rational system thinking analysis could potentially produce reinforcing and self-reinforcing effects to enhance rural water systems and promote sustainable water management in the north-west region, cameroon.",
6d67f6d04261a7cf4abc579cbdf5307281f58581,An Integrated Multicriteria Analysis Tool for Evaluating Water Resource Management Strategies,"Water is involved, directly or indirectly, with many activities and needs that have to be met. The large scale and importance of water projects, the investments needed, the difficulty in predicting the results, and the irreversible character of the decisions have made decision making a complex scientific process. This paper presents a multicriteria analysis (MCA) tool for evaluating water resource management (WRM) strategies and selecting the most appropriate among them, using as an example a Greek area based on agricultural economy, which faces water scarcity problems. Seven alternative strategies were evaluated under hydrological and economic criteria. Four techniques were used—multi attribute utility theory (MAUT), analytic hierarchy process (AHP), elimination and choice expressing reality (ELECTRE), and technique for order of preference by similarity to ideal solution (TOPSIS)—based on the main MCA techniques (utility theory, analytical hierarchy, outranking theory, and classification theory, respectively), to compare their performance, and to reach the most appropriate and ‘fitting’ method for the examined problem. The weightings extracted from two samples, (i) a sample of decision makers/stakeholders and (ii) a group of WRM experts, were used to compare the results. The process was carried out for each questionnaire, and thus the model shows the uncertainty of each sample group and of each method, as well as the overall uncertainty. The results illustrate the reality of the WRM problems of the watershed, enlighten their roots, and have further strengthened our conviction that the cooperation between the scientific community and the authorities is vital for more sustainable and efficient WRM.",2018,"[{'authorId': '108539859', 'name': 'A. Alamanos'}, {'authorId': '37182783', 'name': 'N. Mylopoulos'}, {'authorId': '2775694', 'name': 'A. Loukas'}, {'authorId': '108445027', 'name': 'Dimitrios Gaitanaros'}]","{'url': 'https://www.mdpi.com/2073-4441/10/12/1795/pdf?version=1544164255', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/W10121795?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/W10121795, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","water is involved, directly or indirectly, with many activities and needs that have to be met. the large scale and importance of water projects, the investments needed, the difficulty in predicting the results, and the irreversible character of the decisions have made decision making a complex scientific process. this paper presents a multicriteria analysis (mca) tool for evaluating water resource management (wrm) strategies and selecting the most appropriate among them, using as an example a greek area based on agricultural economy, which faces water scarcity problems. seven alternative strategies were evaluated under hydrological and economic criteria. four techniques were used—multi attribute utility theory (maut), analytic hierarchy process (ahp), elimination and choice expressing reality (electre), and technique for order of preference by similarity to ideal solution (topsis)—based on the main mca techniques (utility theory, analytical hierarchy, outranking theory, and classification theory, respectively), to compare their performance, and to reach the most appropriate and ‘fitting’ method for the examined problem. the weightings extracted from two samples, (i) a sample of decision makers/stakeholders and (ii) a group of wrm experts, were used to compare the results. the process was carried out for each questionnaire, and thus the model shows the uncertainty of each sample group and of each method, as well as the overall uncertainty. the results illustrate the reality of the wrm problems of the watershed, enlighten their roots, and have further strengthened our conviction that the cooperation between the scientific community and the authorities is vital for more sustainable and efficient wrm.",https://www.mdpi.com/2073-4441/10/12/1795/pdf?version=1544164255
fec995ea80fd6b9f588d032a7364fc9b18f95d70,Integrated Water Resource Management: Principles and Applications,"
 The concept of Integrated Water Resource Management (IWRM) was established, back in the 1930s, to address “optimal” water management, mainly from a technical perspective, but also taking into account social goals, such as the fulfillment of basic needs and the total welfare of the population. The chapter provides a comprehensive overview of issues related to IWRM. After a discussion of the various economic dimensions of water, we establish a basic model to analyze the value of water under different social welfare objective functions, including the human right to water. The technical-economic model also addresses questions of eco-hydrology, water recycling, groundwater management, and water quality management. The chapter also addresses water allocation along rivers and water transfers between watersheds. The chapter includes exercises and suggestions for further reading.",2020,"[{'authorId': '94168592', 'name': 'G. Meran'}, {'authorId': '107997831', 'name': 'Markus Siehlow'}, {'authorId': '75018176', 'name': 'C. Hirschhausen'}]","{'url': 'https://link.springer.com/content/pdf/10.1007%2F978-3-030-48485-9_3.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-030-48485-9_3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-030-48485-9_3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the concept of integrated water resource management (iwrm) was established, back in the 1930s, to address “optimal” water management, mainly from a technical perspective, but also taking into account social goals, such as the fulfillment of basic needs and the total welfare of the population. the chapter provides a comprehensive overview of issues related to iwrm. after a discussion of the various economic dimensions of water, we establish a basic model to analyze the value of water under different social welfare objective functions, including the human right to water. the technical-economic model also addresses questions of eco-hydrology, water recycling, groundwater management, and water quality management. the chapter also addresses water allocation along rivers and water transfers between watersheds. the chapter includes exercises and suggestions for further reading.",https://link.springer.com/content/pdf/10.1007%2F978-3-030-48485-9_3.pdf
f70ec62ebf0c19b7759b4ec69600f36789b3cbd2,An Assessment of Surface Water Detection Methods for Water Resource Management in the Nigerien Sahel,"Water is a scarce, but essential resource in the Sahel. Rainfed ephemeral ponds and lakes that dot the landscape are necessary to the livelihoods of smallholder farmers and pastoralists who rely on these resources to irrigate crops and hydrate cattle. The remote location and dispersed nature of these water bodies limits typical methods of monitoring, such as with gauges; fortunately, remote sensing offers a quick and cost-effective means of regularly measuring surface water extent in these isolated regions. Dozens of operational methods exist to use remote sensing to identify waterbodies, however, their performance when identifying surface water in the semi-arid Sahel has not been well-documented and the limitations of these methods for the region are not well understood. Here, we evaluate two global dynamic surface water datasets, fifteen spectral indices developed to classify surface water extent, and three simple decision tree methods created specifically to identify surface water in semi-arid environments. We find that the existing global surface water datasets effectively minimize false positives, but greatly underestimate the presence and extent of smaller, more turbid water bodies that are essential to local livelihoods, an important limitation in their use for monitoring water availability. Three of fifteen spectral indices exhibited both high accuracy and threshold stability when evaluated over different areas and seasons. The three simple decision tree methods had mixed performance, with only one having an overall accuracy that compared to the best performing spectral indices. We find that while global surface water datasets may be appropriate for analysis at the global scale, other methods calibrated to the local environment may provide improved performance for more localized water monitoring needs.",2020,"[{'authorId': '82376507', 'name': 'Kelsey E. Herndon'}, {'authorId': '51162416', 'name': 'R. Muench'}, {'authorId': '16760663', 'name': 'E. Cherrington'}, {'authorId': '144736709', 'name': 'R. Griffin'}]","{'url': 'https://www.mdpi.com/1424-8220/20/2/431/pdf?version=1578823532', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7014253, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","water is a scarce, but essential resource in the sahel. rainfed ephemeral ponds and lakes that dot the landscape are necessary to the livelihoods of smallholder farmers and pastoralists who rely on these resources to irrigate crops and hydrate cattle. the remote location and dispersed nature of these water bodies limits typical methods of monitoring, such as with gauges; fortunately, remote sensing offers a quick and cost-effective means of regularly measuring surface water extent in these isolated regions. dozens of operational methods exist to use remote sensing to identify waterbodies, however, their performance when identifying surface water in the semi-arid sahel has not been well-documented and the limitations of these methods for the region are not well understood. here, we evaluate two global dynamic surface water datasets, fifteen spectral indices developed to classify surface water extent, and three simple decision tree methods created specifically to identify surface water in semi-arid environments. we find that the existing global surface water datasets effectively minimize false positives, but greatly underestimate the presence and extent of smaller, more turbid water bodies that are essential to local livelihoods, an important limitation in their use for monitoring water availability. three of fifteen spectral indices exhibited both high accuracy and threshold stability when evaluated over different areas and seasons. the three simple decision tree methods had mixed performance, with only one having an overall accuracy that compared to the best performing spectral indices. we find that while global surface water datasets may be appropriate for analysis at the global scale, other methods calibrated to the local environment may provide improved performance for more localized water monitoring needs.",https://www.mdpi.com/1424-8220/20/2/431/pdf?version=1578823532
a1a732e114a6f94496d02aa7ee031a9e7c679bfa,Water–Energy Nexus for Multi-Criteria Decision Making in Water Resource Management: A Case Study of Choshui River Basin in Taiwan,"The Choshui river basin, the mother river in Taiwan, suffers from severe water shortage from extensive water use in irrigation as well as land subsidence from over-pumping of groundwater. To address these challenges, several water-related strategies and actions, including enhancement of water-use efficiency, development of alternative water sources, and improvement in effective water management, were proposed in this study to support sustainable water resource management in the watershed. Management of water resources in Taiwan is expected to confront not only freshwater resource but also energy source constraints. Multi-criteria decision analysis (MCDA), an approach for ranking overall performances of decision options, was then used to prioritize the water resource management strategies. The analysis considered economic (economic feasibility) and environmental (stability from the influence of climate change) criteria in the context of water–energy nexus (water supply/conservation potential and systemic energy efficiency). Our results indicated that, while economic feasibility was considered as the most important factor in implementation of the practices, improvement in groundwater pumping control and management was ranked as a high-priority water resource management action, followed by initiating water conservation programs for residential sector and reducing leakage rate for agricultural irrigation canals. The results from this study are expected to provide direction for future decision making in water resource management.",2018,"[{'authorId': '4325885', 'name': 'Mengshan Lee'}, {'authorId': '82737526', 'name': 'Chia-Yii Yu'}, {'authorId': '2585485', 'name': 'P. Chiang'}, {'authorId': '49641913', 'name': 'Chia-Hung Hou'}]","{'url': 'https://www.mdpi.com/2073-4441/10/12/1740/pdf?version=1543316645', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/W10121740?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/W10121740, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the choshui river basin, the mother river in taiwan, suffers from severe water shortage from extensive water use in irrigation as well as land subsidence from over-pumping of groundwater. to address these challenges, several water-related strategies and actions, including enhancement of water-use efficiency, development of alternative water sources, and improvement in effective water management, were proposed in this study to support sustainable water resource management in the watershed. management of water resources in taiwan is expected to confront not only freshwater resource but also energy source constraints. multi-criteria decision analysis (mcda), an approach for ranking overall performances of decision options, was then used to prioritize the water resource management strategies. the analysis considered economic (economic feasibility) and environmental (stability from the influence of climate change) criteria in the context of water–energy nexus (water supply/conservation potential and systemic energy efficiency). our results indicated that, while economic feasibility was considered as the most important factor in implementation of the practices, improvement in groundwater pumping control and management was ranked as a high-priority water resource management action, followed by initiating water conservation programs for residential sector and reducing leakage rate for agricultural irrigation canals. the results from this study are expected to provide direction for future decision making in water resource management.",https://www.mdpi.com/2073-4441/10/12/1740/pdf?version=1543316645
13cdd60fcab9d19e69b9068be3e148689f00ae6a,Bibliometric Analysis of Water Resource Management,"ABSTRACT Li, Q.; Guo, X., and Zhang, L., 2020. Bibliometric analysis of water resource management. In: Hu, C. and Cai, M. (eds.), Geo-informatics and Oceanography. Journal of Coastal Research, Special Issue No. 105, pp. 210–214. Coconut Creek (Florida), ISSN 0749-0208. Based on the Web of Science database, this paper systematically reveals a general trend of publication, country or region, and organization distribution; source publication distribution; frequently cited papers; co-occurring keywords; and time zone analysis of keywords in the field of water resource management (WRM) from multiple perspectives by using bibliometric analysis and visualization software. A corresponding visualization knowledge graph is obtained that clearly and intuitively shows the current situation and research hot spots of WRM research from a specific perspective. The results show that in the past 21 years, research in WRM has been increasing continuously. China's research on WRM is in the leading position, and “water resource management,” “management,” and “integrated water resource management” are the top 3 high-frequency keywords. These findings provide a knowledge basis for further research on WRM.",2020,"[{'authorId': '2117767224', 'name': 'Qingjun Li'}, {'authorId': '2042657117', 'name': 'Xiaoxia Guo'}, {'authorId': '2146645778', 'name': 'Lianhe Zhang'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2112/JCR-SI105-044.1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2112/JCR-SI105-044.1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract li, q.; guo, x., and zhang, l., 2020. bibliometric analysis of water resource management. in: hu, c. and cai, m. (eds.), geo-informatics and oceanography. journal of coastal research, special issue no. 105, pp. 210–214. coconut creek (florida), issn 0749-0208. based on the web of science database, this paper systematically reveals a general trend of publication, country or region, and organization distribution; source publication distribution; frequently cited papers; co-occurring keywords; and time zone analysis of keywords in the field of water resource management (wrm) from multiple perspectives by using bibliometric analysis and visualization software. a corresponding visualization knowledge graph is obtained that clearly and intuitively shows the current situation and research hot spots of wrm research from a specific perspective. the results show that in the past 21 years, research in wrm has been increasing continuously. china's research on wrm is in the leading position, and “water resource management,” “management,” and “integrated water resource management” are the top 3 high-frequency keywords. these findings provide a knowledge basis for further research on wrm.",
b057854609067d735cd8b93be0e784dd4a1867e0,Sociohydrology modeling for complex urban environments in support of integrated land and water resource management practices,"This paper argues that a systems' thinking and explicit modeling approach is needed to address noted weaknesses (in terms of practicality and usefulness) in integrated water resource management. A process of coupling complex regional land use, economy, and water system interactions in integrated modeling is demonstrated with proof‐of‐concept applications to two urban cases (Chicago and Stockholm). In this uniquely coupled systems model, urban land use scenarios are considered a complex urban system represented by dynamic systems models of land use, economics, and water with a focus on urban environments that include drivers and system feedbacks with implications focused on urban water systems. The integrated model results reveal that the physical availability of land for economic activities (forecasted via a bottom‐up land use change model) and their locations differ sharply from top‐down sectoral‐based economic forecasts. This shows that both human systems (economic and land use planning) and natural systems (land use limitations and associated water implications) need to be considered in order to accurately account for system(s) impacts. For example, flood zone regulations divert land use to other locations, whereas land cover changes can greatly affect the water infiltration characteristics of land surfaces and thereby alter hydrological outcomes. Our results indicate that modeling social and natural processes using a systems approach can provide a more comprehensive understanding of coupled causal mechanisms, impacts, and feedbacks in applications of integrated water resource management.",2018,"[{'authorId': '2434266', 'name': 'Haozhi Pan'}, {'authorId': '29890066', 'name': 'B. Deal'}, {'authorId': '2069499', 'name': 'G. Destouni'}, {'authorId': '48379545', 'name': 'Yalei Zhang'}, {'authorId': '11600104', 'name': 'Z. Kalantari'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/ldr.3106', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/ldr.3106?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/ldr.3106, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper argues that a systems' thinking and explicit modeling approach is needed to address noted weaknesses (in terms of practicality and usefulness) in integrated water resource management. a process of coupling complex regional land use, economy, and water system interactions in integrated modeling is demonstrated with proof‐of‐concept applications to two urban cases (chicago and stockholm). in this uniquely coupled systems model, urban land use scenarios are considered a complex urban system represented by dynamic systems models of land use, economics, and water with a focus on urban environments that include drivers and system feedbacks with implications focused on urban water systems. the integrated model results reveal that the physical availability of land for economic activities (forecasted via a bottom‐up land use change model) and their locations differ sharply from top‐down sectoral‐based economic forecasts. this shows that both human systems (economic and land use planning) and natural systems (land use limitations and associated water implications) need to be considered in order to accurately account for system(s) impacts. for example, flood zone regulations divert land use to other locations, whereas land cover changes can greatly affect the water infiltration characteristics of land surfaces and thereby alter hydrological outcomes. our results indicate that modeling social and natural processes using a systems approach can provide a more comprehensive understanding of coupled causal mechanisms, impacts, and feedbacks in applications of integrated water resource management.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/ldr.3106
b1cba6f1ea3f7adfdc157a73cdd42aedd1a519c7,Hydrological inferences through morphometric analysis of lower Kosi river basin of India for water resource management based on remote sensing data,"Satellite based remote sensing technology has proven to be an effectual tool in analysis of drainage networks, study of surface morphological features and their correlation with groundwater management prospect at basin level. The present study highlights the effectiveness and advantage of remote sensing and GIS-based analysis for quantitative and qualitative assessment of flood plain region of lower Kosi river basin based on morphometric analysis. In this study, ASTER DEM is used to extract the vital hydrological parameters of lower Kosi river basin in ARC GIS software. Morphometric parameters, e.g., stream order, stream length, bifurcation ratio, drainage density, drainage frequency, drainage texture, form factor, circularity ratio, elongation ratio, etc., have been calculated for the Kosi basin and their hydrological inferences were discussed. Most of the morphometric parameters such as bifurcation ratio, drainage density, drainage frequency, drainage texture concluded that basin has good prospect for water management program for various purposes and also generated data base that can provide scientific information for site selection of water-harvesting structures and flood management activities in the basin. Land use land cover (LULC) of the basin were also prepared from Landsat data of 2005, 2010 and 2015 to assess the change in dynamic of the basin and these layers are very noteworthy for further watershed prioritization.",2018,"[{'authorId': '40635483', 'name': 'P. Rai'}, {'authorId': '39504305', 'name': 'Rajeev Singh Chandel'}, {'authorId': '2045235', 'name': 'V. Mishra'}, {'authorId': '151495223', 'name': 'Prafull Singh'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s13201-018-0660-7.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13201-018-0660-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13201-018-0660-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","satellite based remote sensing technology has proven to be an effectual tool in analysis of drainage networks, study of surface morphological features and their correlation with groundwater management prospect at basin level. the present study highlights the effectiveness and advantage of remote sensing and gis-based analysis for quantitative and qualitative assessment of flood plain region of lower kosi river basin based on morphometric analysis. in this study, aster dem is used to extract the vital hydrological parameters of lower kosi river basin in arc gis software. morphometric parameters, e.g., stream order, stream length, bifurcation ratio, drainage density, drainage frequency, drainage texture, form factor, circularity ratio, elongation ratio, etc., have been calculated for the kosi basin and their hydrological inferences were discussed. most of the morphometric parameters such as bifurcation ratio, drainage density, drainage frequency, drainage texture concluded that basin has good prospect for water management program for various purposes and also generated data base that can provide scientific information for site selection of water-harvesting structures and flood management activities in the basin. land use land cover (lulc) of the basin were also prepared from landsat data of 2005, 2010 and 2015 to assess the change in dynamic of the basin and these layers are very noteworthy for further watershed prioritization.",https://link.springer.com/content/pdf/10.1007/s13201-018-0660-7.pdf
56ac00c21e10a58d645aa859eda020545473447f,Review of Mathematical Programming Applications in Water Resource Management Under Uncertainty,"Economic development, variation in weather patterns and natural disasters focus attention on the management of water resources. This paper reviews the literature on the development of mathematical programming models for water resource management under uncertainty between 2010 and 2017. A systematic search of the academic literature identified 448 journal articles on water resource management for examination. Bibliometric analysis is employed to investigate the methods that researchers are currently using to address this problem and to identify recent trends in research in the area. The research reveals that stochastic dynamic programming and multistage stochastic programming are the methods most commonly applied. Water resource allocation, climate change, water quality and agricultural irrigation are amongst the most frequently discussed topics in the literature. A more detailed examination of the literature on each of these topics is included. The findings suggest that there is a need for mathematical programming models of large-scale water systems that deal with uncertainty and multiobjectives in an effective and computationally efficient way.",2018,"[{'authorId': '70168532', 'name': 'T. Archibald'}, {'authorId': '1978803890', 'name': 'Sarah E. Marshall'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s10666-018-9628-0.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10666-018-9628-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10666-018-9628-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","economic development, variation in weather patterns and natural disasters focus attention on the management of water resources. this paper reviews the literature on the development of mathematical programming models for water resource management under uncertainty between 2010 and 2017. a systematic search of the academic literature identified 448 journal articles on water resource management for examination. bibliometric analysis is employed to investigate the methods that researchers are currently using to address this problem and to identify recent trends in research in the area. the research reveals that stochastic dynamic programming and multistage stochastic programming are the methods most commonly applied. water resource allocation, climate change, water quality and agricultural irrigation are amongst the most frequently discussed topics in the literature. a more detailed examination of the literature on each of these topics is included. the findings suggest that there is a need for mathematical programming models of large-scale water systems that deal with uncertainty and multiobjectives in an effective and computationally efficient way.",https://link.springer.com/content/pdf/10.1007/s10666-018-9628-0.pdf
5e9c2f3ee6abcee8f54509b047678771661ffbd6,Integrated water resource management in complex systems: How the catchment management strategies seek to achieve sustainability and equity in water resources in South Africa,"It is increasingly evident amongst practitioners and academics alike that the management approaches of the past have failed to deal adequately with the challenges posed by complex and rapidly changing systems. Indeed the call for integrated approaches such as those embodied in integrated water resource management (IWRM) reflects such concerns. This is because these systems are characterised by complexity in which an understanding of linkages, multiple drivers and unpredictable outcomes is critical. It is also widely recognised that the management of such systems requires an iterative, 'learning-by-doing' approach that is reflexive in nature and builds learning into the next management cycle. We suggest that any attempt to define and implement viable and effective governance of water resources, as well as rehabilitation measures, requires understanding that catchments are complex systems showing the aforementioned characteristics. As a corollary, an adaptive management approach appears best suited to such conditions.
In this paper we argue that South Africa's highly-acclaimed National Water Act and associated policy documents such as the National Water Resource Strategy is an example of a policy document that reflects this thinking, as is evident in the guidelines for the development of catchment management strategies which are introduced and described. These offer a framework for the development of a holistic, systems understanding which is strategic and adaptive. In particular, under such a framework, we select the two cornerstones of the Act - sustainability and equity - to explore this theme. We show that under such a framework ensuring that both these principles are achieved is not through one simplistic management action but through an integrated, systems approach. The development of strategies is driven by principles which help one to navigate issues that emerge in complex systems in a flexible way. Visioning and scenarios offer important management tools for establishing a hierarchy of actions that can achieve the overarching principles and that can accommodating change. In complex systems, the users must be part of deriving management solutions since this is where and how they learn. Self-organisation, identity and embeddedness are all essential characteristics of building resilience in a catchment system.",2019,"[{'authorId': '2926053', 'name': 'S. Pollard'}, {'authorId': '93475586', 'name': 'D. D. Toit'}]","{'url': 'https://www.ajol.info/index.php/wsa/article/download/183668/173025', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4314/WSA.V34I6.183668?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4314/WSA.V34I6.183668, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","it is increasingly evident amongst practitioners and academics alike that the management approaches of the past have failed to deal adequately with the challenges posed by complex and rapidly changing systems. indeed the call for integrated approaches such as those embodied in integrated water resource management (iwrm) reflects such concerns. this is because these systems are characterised by complexity in which an understanding of linkages, multiple drivers and unpredictable outcomes is critical. it is also widely recognised that the management of such systems requires an iterative, 'learning-by-doing' approach that is reflexive in nature and builds learning into the next management cycle. we suggest that any attempt to define and implement viable and effective governance of water resources, as well as rehabilitation measures, requires understanding that catchments are complex systems showing the aforementioned characteristics. as a corollary, an adaptive management approach appears best suited to such conditions. in this paper we argue that south africa's highly-acclaimed national water act and associated policy documents such as the national water resource strategy is an example of a policy document that reflects this thinking, as is evident in the guidelines for the development of catchment management strategies which are introduced and described. these offer a framework for the development of a holistic, systems understanding which is strategic and adaptive. in particular, under such a framework, we select the two cornerstones of the act - sustainability and equity - to explore this theme. we show that under such a framework ensuring that both these principles are achieved is not through one simplistic management action but through an integrated, systems approach. the development of strategies is driven by principles which help one to navigate issues that emerge in complex systems in a flexible way. visioning and scenarios offer important management tools for establishing a hierarchy of actions that can achieve the overarching principles and that can accommodating change. in complex systems, the users must be part of deriving management solutions since this is where and how they learn. self-organisation, identity and embeddedness are all essential characteristics of building resilience in a catchment system.",https://www.ajol.info/index.php/wsa/article/download/183668/173025
b1898033442fc91881e581439132e331f2a547ba,Review of River Basin Water Resource Management in China,"Water resources are the basis for supporting the entire life system of the Earth. However, with the frequent global water crises—especially in the river basins of China—the issue of water resources has become a bottleneck that limits its development. Therefore, it is necessary to carry out relevant research. In this paper, we systematically analyzed different classification methods of the service functions of water ecosystems as well as factors that affect it. Results showed that climate, land cover, human activities, and their own endowment conditions were the main factors affecting the service functions of water ecosystems. Based on these, water resource management in China river basins was expounded from three aspects: water resources protection, allocation, and utilization. At the same time, the impacts of water resource management on land use in China were also summarized. Finally, the key trends of the next study were summarized as follows: improvement of the classification system of basin water ecosystem service functions, improvement of the mechanism of the basin water market; comprehensive tradeoff of water resource exploitation and protection in basins; and basin water resource management from the perspective of multidisciplinary crossing.",2018,"[{'authorId': '46702169', 'name': 'Hong Zhang'}, {'authorId': '2107013465', 'name': 'Gui Jin'}, {'authorId': '83360165', 'name': 'Yanc Yu'}]","{'url': 'https://www.mdpi.com/2073-4441/10/4/425/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/W10040425?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/W10040425, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","water resources are the basis for supporting the entire life system of the earth. however, with the frequent global water crises—especially in the river basins of china—the issue of water resources has become a bottleneck that limits its development. therefore, it is necessary to carry out relevant research. in this paper, we systematically analyzed different classification methods of the service functions of water ecosystems as well as factors that affect it. results showed that climate, land cover, human activities, and their own endowment conditions were the main factors affecting the service functions of water ecosystems. based on these, water resource management in china river basins was expounded from three aspects: water resources protection, allocation, and utilization. at the same time, the impacts of water resource management on land use in china were also summarized. finally, the key trends of the next study were summarized as follows: improvement of the classification system of basin water ecosystem service functions, improvement of the mechanism of the basin water market; comprehensive tradeoff of water resource exploitation and protection in basins; and basin water resource management from the perspective of multidisciplinary crossing.",https://www.mdpi.com/2073-4441/10/4/425/pdf
10b44589ea4c14ca1d15ef277de2174e301c326d,"Water resource management: IWRM strategies for improved water management. A systematic review of case studies of East, West and Southern Africa","Objective The analytical study systematically reviewed the evidence about the IWRM water strategy model. The study analysed the IWRM strategy advances and practical implications it had, since inception on effective water management in East, West and Southern Africa. Methods The study adopted the Preferred Reporting Items for Systematic Review and Meta-analysis Protocols (PRISMA-P) and the scoping literature review approach. The study searched selected databases for peer-reviewed articles, books, and grey literature. DistillerSR software was used for article screening. A constructionist thematic analysis was employed to extract recurring themes amongst the regions. Results The systematic literature review detailed the adoption, policy revisions and growing/emerging policy trends and issues (or considerations) on IWRM in East, West and Southern Africa. Thematic analysis derived four cross-cutting themes that contributed to IWRM strategy implementation and adoption. The identified four themes were donor effect, water scarcity, transboundary water resources, and policy approach. The output further posited questions on the prospects, including whether IWRM has been a success or failure with the African water resource management fraternity. Graphical Abstract",2020,"[{'authorId': '113898835', 'name': 'T. Dirwai'}, {'authorId': '96864694', 'name': 'E. Kanda'}, {'authorId': '79994426', 'name': 'A. Senzanje'}, {'authorId': '1825246673', 'name': 'T. I. Busari'}]","{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0236903&type=printable', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8148310, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","objective the analytical study systematically reviewed the evidence about the iwrm water strategy model. the study analysed the iwrm strategy advances and practical implications it had, since inception on effective water management in east, west and southern africa. methods the study adopted the preferred reporting items for systematic review and meta-analysis protocols (prisma-p) and the scoping literature review approach. the study searched selected databases for peer-reviewed articles, books, and grey literature. distillersr software was used for article screening. a constructionist thematic analysis was employed to extract recurring themes amongst the regions. results the systematic literature review detailed the adoption, policy revisions and growing/emerging policy trends and issues (or considerations) on iwrm in east, west and southern africa. thematic analysis derived four cross-cutting themes that contributed to iwrm strategy implementation and adoption. the identified four themes were donor effect, water scarcity, transboundary water resources, and policy approach. the output further posited questions on the prospects, including whether iwrm has been a success or failure with the african water resource management fraternity. graphical abstract",https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0236903&type=printable
01057598cc17decd60b1841ecac6f3ac02ded1b5,"Trans-boundary variations of urban drought vulnerability and its impact on water resource management in Singapore and Johor, Malaysia","Low-latitude areas generally experience relatively large precipitation totals, but droughts/dry spells do occur periodically and are potentially hazardous in these regions - especially within rapidly developing urban settlements. These areas typically have high water demand and therefore may potentially be subjected to water scarcity. Effective local water resource management lowering risks and vulnerabilities to drought is thus paramount, and these policies may be affected in regions with national borders sharing a common transboundary water resource. In this study, we (a) quantify and identify drought episodes using the Palmer Drought Severity Index in the neighbouring equatorial regions of Singapore and Johor, Malaysia, and (b) qualitatively examine each region’s drought impacts and consequent responses through archival research over the past fifty years. The data indicate that both frequencies and intensities of drought episodes in both Singapore and Johor have increased over time, suggesting greater exposure to this hazard. However, there are distinct variations in drought impacts in Singapore and Johor, and how each region addresses water resource management to drought with varying degrees of success. Despite the close geographical proximity, significant variations in regional adaptive capacities suggest that different drought vulnerabilities exist. We discuss the efficacy of drought responses over different time scales, and suggest that a combination of demand- and supply-side policies, especially in the long-term, should be considered to reduce vulnerability to this hazard.",2018,"[{'authorId': '2262733733', 'name': 'Joon Chuah'}, {'authorId': '2262737370', 'name': 'HO BeatriceH.'}, {'authorId': '9904645', 'name': 'W. Chow'}]","{'url': 'https://doi.org/10.1088/1748-9326/aacad8', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1088/1748-9326/aacad8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/1748-9326/aacad8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","low-latitude areas generally experience relatively large precipitation totals, but droughts/dry spells do occur periodically and are potentially hazardous in these regions - especially within rapidly developing urban settlements. these areas typically have high water demand and therefore may potentially be subjected to water scarcity. effective local water resource management lowering risks and vulnerabilities to drought is thus paramount, and these policies may be affected in regions with national borders sharing a common transboundary water resource. in this study, we (a) quantify and identify drought episodes using the palmer drought severity index in the neighbouring equatorial regions of singapore and johor, malaysia, and (b) qualitatively examine each region’s drought impacts and consequent responses through archival research over the past fifty years. the data indicate that both frequencies and intensities of drought episodes in both singapore and johor have increased over time, suggesting greater exposure to this hazard. however, there are distinct variations in drought impacts in singapore and johor, and how each region addresses water resource management to drought with varying degrees of success. despite the close geographical proximity, significant variations in regional adaptive capacities suggest that different drought vulnerabilities exist. we discuss the efficacy of drought responses over different time scales, and suggest that a combination of demand- and supply-side policies, especially in the long-term, should be considered to reduce vulnerability to this hazard.",https://doi.org/10.1088/1748-9326/aacad8
b80bc8ccffa59da9d3ff0c27e03e70001e2f5ebb,A review of Ghana’s water resource management and the future prospect,"Abstract Water covers about 70% of the earth’s surface and it exists naturally in the earth in all the three physical states of matter and it is always moving around because the water flows with the current. Out of the earth’s percentage of water covering the surface, only about 2.5% is fresh water and due to the fact that most are stored in deep groundwater, a small amount is readily available for human use. Water scarcity is becoming a major concern for people around the world and the need to protect the existing ones and find ways or means to provide safe water for individuals around the globe in adequate quantities with keeping the needs of future generations in mind. Water is life, and it is linked with lots of services either directly or indirectly, such as; human health and welfare and social and economic development of a community or country. The need to delve into Ghana’s water resources management is essential. The study reviewed existing literature on the various members of the Water Resource Commission (WRC) in Ghana; the various basins in the country; the existing measures that the WRC authorities have in place to deal with water resources management issues; the challenges that hinder the progress of their achievements and some suggestions that if considered can improve the current water resources management situations in Ghana.",2016,"[{'authorId': '11570110', 'name': 'P. A. Owusu'}, {'authorId': '1403449788', 'name': 'Samuel Asumadu-Sarkodie'}, {'authorId': '113762768', 'name': 'Polycarp Ameyo'}]","{'url': 'https://doi.org/10.1080/23311916.2016.1164275', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/23311916.2016.1164275?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/23311916.2016.1164275, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract water covers about 70% of the earth’s surface and it exists naturally in the earth in all the three physical states of matter and it is always moving around because the water flows with the current. out of the earth’s percentage of water covering the surface, only about 2.5% is fresh water and due to the fact that most are stored in deep groundwater, a small amount is readily available for human use. water scarcity is becoming a major concern for people around the world and the need to protect the existing ones and find ways or means to provide safe water for individuals around the globe in adequate quantities with keeping the needs of future generations in mind. water is life, and it is linked with lots of services either directly or indirectly, such as; human health and welfare and social and economic development of a community or country. the need to delve into ghana’s water resources management is essential. the study reviewed existing literature on the various members of the water resource commission (wrc) in ghana; the various basins in the country; the existing measures that the wrc authorities have in place to deal with water resources management issues; the challenges that hinder the progress of their achievements and some suggestions that if considered can improve the current water resources management situations in ghana.",https://doi.org/10.1080/23311916.2016.1164275
95d3f97a5b3e9c27fdeea6e1b4336559f4a5cd8f,Water resource management at catchment scales using lightweight UAVs: current capabilities and future perspectives,"Lightweight, portable unmanned aerial vehicles (UAVs) or ‘drones’ are set to become a key component of a water resource management (WRM) toolkit, but are currently not widely used in this context. In practical WRM there is a growing need for fine-scale responsive data, which cannot be delivered from satellites or aircraft in a cost-effective way. Such a capability is needed where water supplies are located in spatially heterogeneous dynamic catchments. In this review, we demonstrate the step change in hydrological process understanding that could be delivered if WRM employed UAVs. The paper discusses a range of pragmatic concepts in UAV science for cost-effective and practical WRM, from choosing the right sensor and platform combination through to practical deployment and data processing challenges. The paper highlights that multi-sensor approaches, such as combining thermal imaging with fine-scale structure-from-motion topographic models, are currently best placed to assist in WRM decision-making because...",2016,"[{'authorId': '40805814', 'name': 'Leon DeBell'}, {'authorId': '143693504', 'name': 'K. Anderson'}, {'authorId': '8164537', 'name': 'R. Brazier'}, {'authorId': '2059812686', 'name': 'N. King'}, {'authorId': '90075177', 'name': 'L. Jones'}]","{'url': 'https://www.nrcresearchpress.com/doi/pdf/10.1139/juvs-2015-0026', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1139/JUVS-2015-0026?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1139/JUVS-2015-0026, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","lightweight, portable unmanned aerial vehicles (uavs) or ‘drones’ are set to become a key component of a water resource management (wrm) toolkit, but are currently not widely used in this context. in practical wrm there is a growing need for fine-scale responsive data, which cannot be delivered from satellites or aircraft in a cost-effective way. such a capability is needed where water supplies are located in spatially heterogeneous dynamic catchments. in this review, we demonstrate the step change in hydrological process understanding that could be delivered if wrm employed uavs. the paper discusses a range of pragmatic concepts in uav science for cost-effective and practical wrm, from choosing the right sensor and platform combination through to practical deployment and data processing challenges. the paper highlights that multi-sensor approaches, such as combining thermal imaging with fine-scale structure-from-motion topographic models, are currently best placed to assist in wrm decision-making because...",https://www.nrcresearchpress.com/doi/pdf/10.1139/juvs-2015-0026
14094184e556f636b01abb92a3f070df4e2347d0,Comparison of Robust Optimization and Info-Gap Methods for Water Resource Management under Deep Uncertainty,"This paper evaluates two established decision-making methods and analyzes their performance and suitability within a water resources management (WRM) problem. The methods under assessment are info-gap (IG) decision theory and robust optimization (RO). The methods have been selected primarily to investigate a contrasting local versus global method of assessing water system robustness to deep uncertainty, but also to compare a robustness model approach (IG) with a robustness algorithm approach (RO), whereby the former selects and analyzes a set of prespecified strategies and the latter uses optimization algorithms to automatically generate and evaluate solutions. The study presents a novel area-based method for IG robustness modeling and assesses the applicability of utilizing the future flows climate change projections in scenario generation for water resource adaptation planning. The methods were applied to a case study resembling the Sussex North Water Resource Zone in England, assessing their applicability at improving a risk-based WRM problem and highlighting the strengths and weaknesses of each method at selecting suitable adaptation strategies under climate change and future demand uncertainties. Pareto sets of robustness to cost are produced for both methods and highlight RO as producing the lower cost strategies for the full range of varying target robustness levels. IG produced the more expensive Pareto strategies due to its more selective and stringent robustness analysis, resulting from the more complex scenario ordering process.",2016,"[{'authorId': '144794752', 'name': 'T. Roach'}, {'authorId': '2664127', 'name': 'Z. Kapelan'}, {'authorId': '98733685', 'name': 'R. Ledbetter'}, {'authorId': '144577397', 'name': 'Michelle Ledbetter'}]","{'url': 'https://ore.exeter.ac.uk/repository/bitstream/10871/25286/1/WR2143_Roach%20et%20al%20final.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1061/(ASCE)WR.1943-5452.0000660?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1061/(ASCE)WR.1943-5452.0000660, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper evaluates two established decision-making methods and analyzes their performance and suitability within a water resources management (wrm) problem. the methods under assessment are info-gap (ig) decision theory and robust optimization (ro). the methods have been selected primarily to investigate a contrasting local versus global method of assessing water system robustness to deep uncertainty, but also to compare a robustness model approach (ig) with a robustness algorithm approach (ro), whereby the former selects and analyzes a set of prespecified strategies and the latter uses optimization algorithms to automatically generate and evaluate solutions. the study presents a novel area-based method for ig robustness modeling and assesses the applicability of utilizing the future flows climate change projections in scenario generation for water resource adaptation planning. the methods were applied to a case study resembling the sussex north water resource zone in england, assessing their applicability at improving a risk-based wrm problem and highlighting the strengths and weaknesses of each method at selecting suitable adaptation strategies under climate change and future demand uncertainties. pareto sets of robustness to cost are produced for both methods and highlight ro as producing the lower cost strategies for the full range of varying target robustness levels. ig produced the more expensive pareto strategies due to its more selective and stringent robustness analysis, resulting from the more complex scenario ordering process.",https://ore.exeter.ac.uk/repository/bitstream/10871/25286/1/WR2143_Roach%20et%20al%20final.pdf
c53fafae8cf6e7c8ea992133a7a1f10257385941,Water Resource Management,"IPIECA IPIECA, the International Petroleum Industry Environmental Conservation Association, was established in 1974. It is a voluntary non-profit organization whose membership includes both petroleum companies and associations at the national, regional and international levels. Separate working groups within IPIECA address global environmental and social issues related to the petroleum industry: oil spill preparedness and response, global climate change, biodiversity, social responsibility, fuel quality and vehicle emissions, and human health. IPIECA also helps members identify new global issues and assesses their potential impact on the oil industry. IPIECA holds formal United Nations status, which allows it access as a Non-Governmental Organization (NGO) to all UN negotiations. The Association represents the views of its members in public fora and provides an interface between the petroleum industry and the United Nations Agencies. IPIECA's goals are to promote good practices and industry consensus through: • Arranging international workshops • Publishing authoritative reports • Providing a channel of communication with the UN • Providing a forum for open dialogue • Facilitating stakeholder engagement • Promoting partnerships",2020,"[{'authorId': '2288545545', 'name': 'David N. Wilcock'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4324/9781003058960-14?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4324/9781003058960-14, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","ipieca ipieca, the international petroleum industry environmental conservation association, was established in 1974. it is a voluntary non-profit organization whose membership includes both petroleum companies and associations at the national, regional and international levels. separate working groups within ipieca address global environmental and social issues related to the petroleum industry: oil spill preparedness and response, global climate change, biodiversity, social responsibility, fuel quality and vehicle emissions, and human health. ipieca also helps members identify new global issues and assesses their potential impact on the oil industry. ipieca holds formal united nations status, which allows it access as a non-governmental organization (ngo) to all un negotiations. the association represents the views of its members in public fora and provides an interface between the petroleum industry and the united nations agencies. ipieca's goals are to promote good practices and industry consensus through: • arranging international workshops • publishing authoritative reports • providing a channel of communication with the un • providing a forum for open dialogue • facilitating stakeholder engagement • promoting partnerships",
7fc825684cb48bef6596b68499e69b9b6be6971f,Involving stakeholders in transboundary water resource management: The Mesta/Nestos ‘HELP’ basin,"Alternative options for new private and public investment projects in the transboundary Mesta/Nestos River catchment between Bulgaria and Greece involve new dams and water storage reservoirs, agricultural irrigation systems, new tourist resorts and various water-related facilities for urban and industrial water supply. These developments are designed to be implemented in both parts of the basin (in Greece and Bulgaria), where different socio-economic conditions prevail, resulting in each country having different preferences and objectives. Alternative options should consider environmental consequences, to the impact on ecosystems and human health, and also financial and social risks. Any negative impacts on the environment, and whether these negative impacts can be prevented, should be weighted against the economic and social benefits foreseen. Sustainable implementation of private or public utility projects cannot be achieved without public participation and a clear consensus between stakeholders. The UNESCO HELP (Hydrology for the Environment, Life and Policy) initiative provides a rationale for breaking the 'paradigm lock' existing between the most recent scientific findings on the one side and the public, stakeholders and decision makers on the other. In this paper stakeholder involvement in the decision making process is promoted firstly by communicating the results of integrated modelling of water resource management at the basin scale, and secondly by suggesting alternative models and software in order to facilitate negotiations and final decision making processes in transboundary water resource management These models help to rank alternative projects according to the attributes of stakeholders in each country; the aggregated attributes of the stakeholders in both countries; and the aggregated goals of each country.",2019,"[{'authorId': '48367026', 'name': 'J. Ganoulis'}, {'authorId': '116578405', 'name': 'H. Skoulikaris'}, {'authorId': '90257996', 'name': 'J. Monget'}]","{'url': 'https://www.ajol.info/index.php/wsa/article/download/183657/173014', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4314/WSA.V34I4.183657?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4314/WSA.V34I4.183657, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","alternative options for new private and public investment projects in the transboundary mesta/nestos river catchment between bulgaria and greece involve new dams and water storage reservoirs, agricultural irrigation systems, new tourist resorts and various water-related facilities for urban and industrial water supply. these developments are designed to be implemented in both parts of the basin (in greece and bulgaria), where different socio-economic conditions prevail, resulting in each country having different preferences and objectives. alternative options should consider environmental consequences, to the impact on ecosystems and human health, and also financial and social risks. any negative impacts on the environment, and whether these negative impacts can be prevented, should be weighted against the economic and social benefits foreseen. sustainable implementation of private or public utility projects cannot be achieved without public participation and a clear consensus between stakeholders. the unesco help (hydrology for the environment, life and policy) initiative provides a rationale for breaking the 'paradigm lock' existing between the most recent scientific findings on the one side and the public, stakeholders and decision makers on the other. in this paper stakeholder involvement in the decision making process is promoted firstly by communicating the results of integrated modelling of water resource management at the basin scale, and secondly by suggesting alternative models and software in order to facilitate negotiations and final decision making processes in transboundary water resource management these models help to rank alternative projects according to the attributes of stakeholders in each country; the aggregated attributes of the stakeholders in both countries; and the aggregated goals of each country.",https://www.ajol.info/index.php/wsa/article/download/183657/173014
2ed22538811c8f7dafbed30290924563221ba581,The Assessment of Sustainability Indexes and Climate Change Impacts on Integrated Water Resource Management,"Integrated water resource management (IWRM) is facing great challenges due to growing uncertainties caused by climate change (CC), rapid socio-economic and technological changes, and population growth. In the present study, we have developed different indices to assess the availability of water using an IWRM approach. These indices evaluate supply to demands, surface availability, groundwater availability, reservoirs, and environmental flow. Moreover, reliability, resilience, and vulnerability were determined. Sustainability index (SI) and sustainability index by groups (SG) were determined based on the five indices (all indices vary from 0 to 1). The impacts of climate change affect surface and groundwater availability, as do the agricultural, urban, and industrial requirements on the different supplies. We used the generalized AQUATOOL Decision Support System Shell (DSSS) to evaluate the IWRM in the Rio Grande Basin (Morelia, Mexico). Various emission scenarios from representative concentration pathways (RCPs) were applied to the basin for the years 2015–2039 and 2075–2099. The results indicate increases in agricultural and urban demand, and decreases in surface runoff, as well as groundwater recharge. The proposed indices are useful for different approaches (decision-makers, water policy, and drought risks, among others). CC significantly affects the different proposed indices and indicates a decrease of the SI, SG1, and SG2 (i.e., less availability). For example, we found that SG2 decreased from 0.812 to 0.195 under the RCP 8.5 2075–2099 scenario, and SG2 equal to 0.252 and 0.326 for the RCP 6.0 2075–2099 and RCP 4.5 2070–2099 scenarios, respectively (values close to 0 indicate worst drought conditions).",2017,"[{'authorId': '1423438669', 'name': 'Joel Hernández-Bedolla'}, {'authorId': '145182320', 'name': 'A. Solera'}, {'authorId': '1402549686', 'name': 'J. Paredes-Arquiola'}, {'authorId': '1404049040', 'name': 'M. Pedro-Monzonís'}, {'authorId': '143741088', 'name': 'J. Andréu'}, {'authorId': '1415344024', 'name': 'S. T. Sánchez-Quispe'}]","{'url': 'https://www.mdpi.com/2073-4441/9/3/213/pdf?version=1489463796', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/W9030213?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/W9030213, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","integrated water resource management (iwrm) is facing great challenges due to growing uncertainties caused by climate change (cc), rapid socio-economic and technological changes, and population growth. in the present study, we have developed different indices to assess the availability of water using an iwrm approach. these indices evaluate supply to demands, surface availability, groundwater availability, reservoirs, and environmental flow. moreover, reliability, resilience, and vulnerability were determined. sustainability index (si) and sustainability index by groups (sg) were determined based on the five indices (all indices vary from 0 to 1). the impacts of climate change affect surface and groundwater availability, as do the agricultural, urban, and industrial requirements on the different supplies. we used the generalized aquatool decision support system shell (dsss) to evaluate the iwrm in the rio grande basin (morelia, mexico). various emission scenarios from representative concentration pathways (rcps) were applied to the basin for the years 2015–2039 and 2075–2099. the results indicate increases in agricultural and urban demand, and decreases in surface runoff, as well as groundwater recharge. the proposed indices are useful for different approaches (decision-makers, water policy, and drought risks, among others). cc significantly affects the different proposed indices and indicates a decrease of the si, sg1, and sg2 (i.e., less availability). for example, we found that sg2 decreased from 0.812 to 0.195 under the rcp 8.5 2075–2099 scenario, and sg2 equal to 0.252 and 0.326 for the rcp 6.0 2075–2099 and rcp 4.5 2070–2099 scenarios, respectively (values close to 0 indicate worst drought conditions).",https://www.mdpi.com/2073-4441/9/3/213/pdf?version=1489463796
b26ead01c413bb194e33c31fffe6cc5bd097d079,A review of methods for monitoring streamflow for sustainable water resource management,"Monitoring of streamflow may help to determine the optimum levels of its use for sustainable water management in the face of climate change. We reviewed available methods for monitoring streamflow on the basis of six criteria viz. their applicability across different terrains and size of the streams, operational ease, time effectiveness, accuracy, environmental impact that they may cause and cost involve in it. On the basis of the strengths and weaknesses of each of the methods reviewed, we conclude that the timed volume method is apt for hilly terrain having smaller streams due to its operational ease and accuracy of results. Although comparatively expensive, the weir and flume methods are suitable for long term studies of small hill streams, since once the structure is put in place, it yields accurate results. In flat terrain, the float method is best suited for smaller streams for its operational ease and cost effectiveness, whereas, for larger streams, the particle image velocimetry may be used for its accuracy. Our review suggests that the selection of a method for monitoring streamflow may be based on volume of the stream, accuracy of the method, accessibility of the terrain and financial and physical resources available.",2017,"[{'authorId': '144164200', 'name': 'Pariva Dobriyal'}, {'authorId': '39169579', 'name': 'R. Badola'}, {'authorId': '51938802', 'name': 'Chongpi Tuboi'}, {'authorId': '46592790', 'name': 'S. A. Hussain'}]","{'url': 'https://link.springer.com/content/pdf/10.1007%2Fs13201-016-0488-y.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13201-016-0488-y?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13201-016-0488-y, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","monitoring of streamflow may help to determine the optimum levels of its use for sustainable water management in the face of climate change. we reviewed available methods for monitoring streamflow on the basis of six criteria viz. their applicability across different terrains and size of the streams, operational ease, time effectiveness, accuracy, environmental impact that they may cause and cost involve in it. on the basis of the strengths and weaknesses of each of the methods reviewed, we conclude that the timed volume method is apt for hilly terrain having smaller streams due to its operational ease and accuracy of results. although comparatively expensive, the weir and flume methods are suitable for long term studies of small hill streams, since once the structure is put in place, it yields accurate results. in flat terrain, the float method is best suited for smaller streams for its operational ease and cost effectiveness, whereas, for larger streams, the particle image velocimetry may be used for its accuracy. our review suggests that the selection of a method for monitoring streamflow may be based on volume of the stream, accuracy of the method, accessibility of the terrain and financial and physical resources available.",https://link.springer.com/content/pdf/10.1007%2Fs13201-016-0488-y.pdf
2a0bbd445be375b27976f87a9d3ddb598ea4d6c3,Essentials of Endorheic Basins and Lakes: A Review in the Context of Current and Future Water Resource Management and Mitigation Activities in Central Asia,"Endorheic basins (i.e., land-locked drainage networks) and their lakes can be highly sensitive to variations in climate and adverse anthropogenic activities, such as overexploitation of water resources. In this review paper, we provide a brief overview of one major endorheic basin on each continent, plus a number of endorheic basins in Central Asia (CA), a region where a large proportion of the land area is within this type of basin. We summarize the effects of (changing) climate drivers and land surface–atmosphere feedbacks on the water balance. For the CA region, we also discuss key anthropogenic activities, related water management approaches and their complex relationship with political and policy issues. In CA a substantial increase in irrigated agriculture coupled with negative climate change impacts have disrupted the fragile water balance for many endorheic basins and their lakes. Transboundary integrated land and water management approaches must be developed to facilitate adequate climate change adaptation and possible mitigation of the adverse anthropogenic influence on endorheic basins in CA. Suitable climate adaptation, mitigation and efficient natural resource management technologies and methods are available, and are developing fast. A number of these are discussed in the paper, but these technologies alone are not sufficient to address pressing water resource issues in CA. Food–water–energy nexus analyses demonstrate that transboundary endorheic basin management requires transformational changes with involvement of all key stakeholders. Regional programs, supported by local governments and international donors, which incorporate advanced adaptation technologies, water resource research and management capacity development, are essential for successful climate change adaptation efforts in CA. However, there is a need for an accelerated uptake of such programs, with an emphasis on unification of approaches, as the pressures resulting from climate change and aggravated by human mismanagement of natural water resources leave very little time for hesitation.",2017,"[{'authorId': '51934340', 'name': 'V. Yapiyev'}, {'authorId': '91191844', 'name': 'Zhanay Sagintayev'}, {'authorId': '13189765', 'name': 'V. Inglezakis'}, {'authorId': '91325201', 'name': 'K. Samarkhanov'}, {'authorId': '144772483', 'name': 'A. Verhoef'}]","{'url': 'https://www.mdpi.com/2073-4441/9/10/798/pdf?version=1508556943', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/W9100798?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/W9100798, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","endorheic basins (i.e., land-locked drainage networks) and their lakes can be highly sensitive to variations in climate and adverse anthropogenic activities, such as overexploitation of water resources. in this review paper, we provide a brief overview of one major endorheic basin on each continent, plus a number of endorheic basins in central asia (ca), a region where a large proportion of the land area is within this type of basin. we summarize the effects of (changing) climate drivers and land surface–atmosphere feedbacks on the water balance. for the ca region, we also discuss key anthropogenic activities, related water management approaches and their complex relationship with political and policy issues. in ca a substantial increase in irrigated agriculture coupled with negative climate change impacts have disrupted the fragile water balance for many endorheic basins and their lakes. transboundary integrated land and water management approaches must be developed to facilitate adequate climate change adaptation and possible mitigation of the adverse anthropogenic influence on endorheic basins in ca. suitable climate adaptation, mitigation and efficient natural resource management technologies and methods are available, and are developing fast. a number of these are discussed in the paper, but these technologies alone are not sufficient to address pressing water resource issues in ca. food–water–energy nexus analyses demonstrate that transboundary endorheic basin management requires transformational changes with involvement of all key stakeholders. regional programs, supported by local governments and international donors, which incorporate advanced adaptation technologies, water resource research and management capacity development, are essential for successful climate change adaptation efforts in ca. however, there is a need for an accelerated uptake of such programs, with an emphasis on unification of approaches, as the pressures resulting from climate change and aggravated by human mismanagement of natural water resources leave very little time for hesitation.",https://www.mdpi.com/2073-4441/9/10/798/pdf?version=1508556943
7015779747f0d04593daf864a7e7a4509ed36ce0,Dispute over Water Resource Management—Iraq and Turkey,"As a downstream region, Iraq was ranked among the richest Middle Eastern countries with regards to water resources. The world witnessed the emergence of a magnificent ancient civilization that largely relied on agriculture with extraordinary irrigation systems. However, during the last decade, Iraq began to suffer dramatically from inadequate water shares, desertification, and several other environmental issues due to the absence of proper resource management and, not least, various political conflicts. Numerous global water wars, particularly ones involving developing countries, reflect the importance of water shares and potential demand for water. Iraq, Turkey, and Syria, riparian watercourse countries, have engaged in a long-term water dispute that continues to yield no end through mutual agreement. This present work highlights the major events of this dispute, evaluates the causes and current water challenges, and provides a comprehensive solution through the establishment of the Iraqi Water Security Council.",2016,"[{'authorId': '1405157047', 'name': 'Sameh W. H. Al-Muqdadi'}, {'authorId': '47680646', 'name': 'Mohammed Omer'}, {'authorId': '94238837', 'name': 'Rudy K. Abo'}, {'authorId': '49363977', 'name': 'A. Naghshineh'}]","{'url': 'http://www.scirp.org/journal/PaperDownload.aspx?paperID=68078', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.4236/JEP.2016.78098?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4236/JEP.2016.78098, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","as a downstream region, iraq was ranked among the richest middle eastern countries with regards to water resources. the world witnessed the emergence of a magnificent ancient civilization that largely relied on agriculture with extraordinary irrigation systems. however, during the last decade, iraq began to suffer dramatically from inadequate water shares, desertification, and several other environmental issues due to the absence of proper resource management and, not least, various political conflicts. numerous global water wars, particularly ones involving developing countries, reflect the importance of water shares and potential demand for water. iraq, turkey, and syria, riparian watercourse countries, have engaged in a long-term water dispute that continues to yield no end through mutual agreement. this present work highlights the major events of this dispute, evaluates the causes and current water challenges, and provides a comprehensive solution through the establishment of the iraqi water security council.",http://www.scirp.org/journal/PaperDownload.aspx?paperID=68078
27f8d5292786bc0395069eebd5543be5a0a4a23b,The application of a drought reconstruction in water resource management,"This study uses extended (1880s–2012) rainfall series to examine the implications of historical droughts on water supply yield calculations used in water resource management and drought planning across the English Midlands and Central Wales. UK guidance to water companies is to use climate data from the 1920s to present where possible in modelling to inform water resource management and drought plans; but this period excludes several significant droughts of the late nineteenth century. This study uses the standardised precipitation index and hydrological modelling (HYSIM and AQUATOR) to investigate the implications of pre-1920s droughts on water resource management. Although drought characterisation identifies two significant droughts in the pre-1920 period, the impact of these events on reservoir storage is less severe than droughts identified in the post-1920 period, indicating that the use of long climate series in water resource modelling is a valuable tool in assessing the robustness of current water resource modelling used in the water resource sector.",2016,"[{'authorId': '51233941', 'name': 'A. T. Lennard'}, {'authorId': '32588717', 'name': 'N. Macdonald'}, {'authorId': '2074161627', 'name': 'S. Clark'}, {'authorId': '97855770', 'name': 'J. Hooke'}]","{'url': 'https://iwaponline.com/hr/article-pdf/47/3/646/368002/nh0470646.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2166/NH.2015.090?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2166/NH.2015.090, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this study uses extended (1880s–2012) rainfall series to examine the implications of historical droughts on water supply yield calculations used in water resource management and drought planning across the english midlands and central wales. uk guidance to water companies is to use climate data from the 1920s to present where possible in modelling to inform water resource management and drought plans; but this period excludes several significant droughts of the late nineteenth century. this study uses the standardised precipitation index and hydrological modelling (hysim and aquator) to investigate the implications of pre-1920s droughts on water resource management. although drought characterisation identifies two significant droughts in the pre-1920 period, the impact of these events on reservoir storage is less severe than droughts identified in the post-1920 period, indicating that the use of long climate series in water resource modelling is a valuable tool in assessing the robustness of current water resource modelling used in the water resource sector.",https://iwaponline.com/hr/article-pdf/47/3/646/368002/nh0470646.pdf
deb088ce2366a6bc975a00cf83368433a189fb31,Dynamic simulation of water resource management focused on water allocation and water reclamation in Chinese mining cities,"Mining cities have undergone the process of extensive exploitation, which always results in a series of water issues. Integrated water resource management is necessary in improving water supply, allocation and quality without damaging economic development. This article constructs a linear optimization model including a ‘Top-Down’ socio-economic mode, and ‘Bottom-Up’ water quality control and water supply–demand modes with integrated water resource management focused on water allocation and water reclamation. Based on computer simulation, the model can propose a water resource management under the constraints of water supply–demand and water quality control, and the model can precisely predict the influences of water resource management on economic development, water utilization and water quality. Taking Ordos, a Chinese national resource city, as a case study, this model addresses a detailed water resource management, including a water allocation plan among industries and water reclamation plan with technologies, selection, arrangement and subsidies. The implementation of water resource management can fulfill multiple objectives on water quantity, water quality and sustainable economic development. This study indicates that water resource management with a comprehensive dynamic model can be a maneuverable approach to realize the sustainable development of economic growth and water resource utilization, as well as formulate the regional development plan.",2016,"[{'authorId': '121982426', 'name': 'Wenlan Ke'}, {'authorId': '2171336', 'name': 'Yalin Lei'}, {'authorId': '115102317', 'name': 'J. Sha'}, {'authorId': '49288459', 'name': 'Guofeng Zhang'}, {'authorId': '46758637', 'name': 'Jingjing Yan'}, {'authorId': '2117691912', 'name': 'Xiaoyu Lin'}, {'authorId': '2115623162', 'name': 'Xiping Pan'}]","{'url': 'https://iwaponline.com/wp/article-pdf/18/4/844/404179/018040844.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2166/WP.2016.085?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2166/WP.2016.085, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","mining cities have undergone the process of extensive exploitation, which always results in a series of water issues. integrated water resource management is necessary in improving water supply, allocation and quality without damaging economic development. this article constructs a linear optimization model including a ‘top-down’ socio-economic mode, and ‘bottom-up’ water quality control and water supply–demand modes with integrated water resource management focused on water allocation and water reclamation. based on computer simulation, the model can propose a water resource management under the constraints of water supply–demand and water quality control, and the model can precisely predict the influences of water resource management on economic development, water utilization and water quality. taking ordos, a chinese national resource city, as a case study, this model addresses a detailed water resource management, including a water allocation plan among industries and water reclamation plan with technologies, selection, arrangement and subsidies. the implementation of water resource management can fulfill multiple objectives on water quantity, water quality and sustainable economic development. this study indicates that water resource management with a comprehensive dynamic model can be a maneuverable approach to realize the sustainable development of economic growth and water resource utilization, as well as formulate the regional development plan.",https://iwaponline.com/wp/article-pdf/18/4/844/404179/018040844.pdf
1f88a349640bbc6028330ea0c8a75a7222828381,Managed Aquifer Recharge in Integrated Water Resource Management,"Managed aquifer recharge (MAR) is one tool in integrated water resources management which can restore over-allocated or brackish aquifers, protect groundwater-dependent ecosystems, enhance urban and rural water supplies, reduce evaporation losses and improve water supply security. This chapter describes the ways in which MAR is used around the world and presents two Australian case studies, with a focus on economics. Aquifer storage and recovery of urban stormwater via a confined limestone aquifer is shown to provide a viable alternative to use of existing mains water or desalinated seawater for public open space irrigation. The second case study is a desk-top evaluation of the potential for recharge of harvested floodwater via infiltration basins for irrigation of cotton and faba bean crops. Based on assumptions about scale of operations, component and maintenance costs, and evaporation losses, the net benefits of infiltration basins for a range of infiltration rates were compared with those of surface water storage and of aquifer storage and recovery wells. Infiltration basins with moderate to high rates of infiltration (>0.15 m/d) had the highest net benefits and warrant testing in a pilot program. Water treatment costs make ASR with flood waters unattractive for crop irrigation, in comparison with both basin infiltration and surface storage. Selection of the most economic method of storage depends on availability of an aquifer, soil and subsurface hydraulic characteristics, available quantity and quality of surface water, land value and end use of the water. MAR is shown to offer a range of options that warrant investigation in comparison with conventional supply alternatives to enable the most effective water resources management to be implemented.",2016,"[{'authorId': '144860306', 'name': 'P. Dillon'}, {'authorId': '145114385', 'name': 'M. Arshad'}]","{'url': 'https://link.springer.com/content/pdf/10.1007%2F978-3-319-23576-9_17.pdf', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-319-23576-9_17?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-319-23576-9_17, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","managed aquifer recharge (mar) is one tool in integrated water resources management which can restore over-allocated or brackish aquifers, protect groundwater-dependent ecosystems, enhance urban and rural water supplies, reduce evaporation losses and improve water supply security. this chapter describes the ways in which mar is used around the world and presents two australian case studies, with a focus on economics. aquifer storage and recovery of urban stormwater via a confined limestone aquifer is shown to provide a viable alternative to use of existing mains water or desalinated seawater for public open space irrigation. the second case study is a desk-top evaluation of the potential for recharge of harvested floodwater via infiltration basins for irrigation of cotton and faba bean crops. based on assumptions about scale of operations, component and maintenance costs, and evaporation losses, the net benefits of infiltration basins for a range of infiltration rates were compared with those of surface water storage and of aquifer storage and recovery wells. infiltration basins with moderate to high rates of infiltration (>0.15 m/d) had the highest net benefits and warrant testing in a pilot program. water treatment costs make asr with flood waters unattractive for crop irrigation, in comparison with both basin infiltration and surface storage. selection of the most economic method of storage depends on availability of an aquifer, soil and subsurface hydraulic characteristics, available quantity and quality of surface water, land value and end use of the water. mar is shown to offer a range of options that warrant investigation in comparison with conventional supply alternatives to enable the most effective water resources management to be implemented.",https://link.springer.com/content/pdf/10.1007%2F978-3-319-23576-9_17.pdf
b30ad4ff75554129b489817521308bc519522bee,Land Use/Cover Change in the Middle Reaches of the Heihe River Basin over 2000-2011 and Its Implications for Sustainable Water Resource Management,"The Heihe River Basin (HRB) is a typical arid inland river basin in northwestern China. From the 1960s to the 1990s, the downstream flow in the HRB declined as a result of large, artificial changes in the distribution of water and land and a lack of effective water resource management. Consequently, the ecosystems of the lower reaches of the basin substantially deteriorated. To restore these degraded ecosystems, the Ecological Water Diversion Project (EWDP) was initiated by the Chinese government in 2000. The project led to agricultural and ecological changes in the middle reaches of the basin. In this study, we present three datasets of land use/cover in the middle reaches of the HRB derived from Landsat TM/ETM+ images in 2000, 2007 and 2011. We used these data to investigate changes in land use/cover between 2000 and 2011 and the implications for sustainable water resource management. The results show that the most significant land use/cover change in the middle reaches of the HRB was the continuous expansion of farmland for economic interests. From 2000 to 2011, the farmland area increased by 12.01%. The farmland expansion increased the water resource stress; thus, groundwater was over-extracted and the ecosystem was degraded in particular areas. Both consequences are negative and potentially threaten the sustainability of the middle reaches of the HRB and the entire river basin. Local governments should therefore improve the management of water resources, particularly groundwater management, and should strictly control farmland reclamation. Then, water resources could be ecologically and socioeconomically sustained, and the balance between upstream and downstream water demands could be ensured. The results of this study can also serve as a reference for the sustainable management of water resources in other arid inland river basins.",2015,"[{'authorId': '2109753194', 'name': 'Xiaoli Hu'}, {'authorId': '49196321', 'name': 'L. Lu'}, {'authorId': '48568466', 'name': 'Xin Li'}, {'authorId': '2144538023', 'name': 'Jianhua Wang'}, {'authorId': '107956326', 'name': 'M. Guo'}]","{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0128960&type=printable', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4482701, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the heihe river basin (hrb) is a typical arid inland river basin in northwestern china. from the 1960s to the 1990s, the downstream flow in the hrb declined as a result of large, artificial changes in the distribution of water and land and a lack of effective water resource management. consequently, the ecosystems of the lower reaches of the basin substantially deteriorated. to restore these degraded ecosystems, the ecological water diversion project (ewdp) was initiated by the chinese government in 2000. the project led to agricultural and ecological changes in the middle reaches of the basin. in this study, we present three datasets of land use/cover in the middle reaches of the hrb derived from landsat tm/etm+ images in 2000, 2007 and 2011. we used these data to investigate changes in land use/cover between 2000 and 2011 and the implications for sustainable water resource management. the results show that the most significant land use/cover change in the middle reaches of the hrb was the continuous expansion of farmland for economic interests. from 2000 to 2011, the farmland area increased by 12.01%. the farmland expansion increased the water resource stress; thus, groundwater was over-extracted and the ecosystem was degraded in particular areas. both consequences are negative and potentially threaten the sustainability of the middle reaches of the hrb and the entire river basin. local governments should therefore improve the management of water resources, particularly groundwater management, and should strictly control farmland reclamation. then, water resources could be ecologically and socioeconomically sustained, and the balance between upstream and downstream water demands could be ensured. the results of this study can also serve as a reference for the sustainable management of water resources in other arid inland river basins.",https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0128960&type=printable
cf7cdd371ebdb4302b36d9c99a2cff6c10c52064,Challenges for the Integration of Water Resource and Drought-Risk Management in Spain,"Droughts are risks characterized by their complexity, uncertainty, and a series of other features, which differentiate them from other natural disasters and affect the strategies designed to manage them. These characteristics highlight the close relationship between drought management and water resources management. The following hypothesis is raised in this study—unsatisfactory integration of a drought-risk and water resources management strategies, increases the vulnerability to drought. To corroborate this hypothesis, the Spanish case was analyzed, where droughts are a recurrent phenomenon, due to the Mediterranean climate. Starting from the Intergovernmental Panel on Climate Change (IPCC) framework, which has been proposed to characterize vulnerability as a function of exposure, sensitivity, and adaptive capacity, this study analyzed the vulnerability in the Spanish River Basin Districts, through—(i) the integration of the predictable effects of climate change and the increased risk of exposure in hydrologic planning; (ii) the pressure on water resources that determines the sensitivity of the systems; and (iii) the development and implementation of drought management plans as a fundamental tool, in order to adapt before these events occur. The results showed that despite important advances in the process of conceiving and managing droughts, in Spain, there are still important gaps for an adequate integration of droughts risk into the water resource strategies. Therefore, despite the improvements, drought-risk vulnerability of the systems remained high.",2019,"[{'authorId': '121126419', 'name': 'Jesús Vargas'}, {'authorId': '11249720', 'name': 'Pilar Paneque'}]","{'url': 'https://www.mdpi.com/2071-1050/11/2/308/pdf?version=1547029065', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/SU11020308?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/SU11020308, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","droughts are risks characterized by their complexity, uncertainty, and a series of other features, which differentiate them from other natural disasters and affect the strategies designed to manage them. these characteristics highlight the close relationship between drought management and water resources management. the following hypothesis is raised in this study—unsatisfactory integration of a drought-risk and water resources management strategies, increases the vulnerability to drought. to corroborate this hypothesis, the spanish case was analyzed, where droughts are a recurrent phenomenon, due to the mediterranean climate. starting from the intergovernmental panel on climate change (ipcc) framework, which has been proposed to characterize vulnerability as a function of exposure, sensitivity, and adaptive capacity, this study analyzed the vulnerability in the spanish river basin districts, through—(i) the integration of the predictable effects of climate change and the increased risk of exposure in hydrologic planning; (ii) the pressure on water resources that determines the sensitivity of the systems; and (iii) the development and implementation of drought management plans as a fundamental tool, in order to adapt before these events occur. the results showed that despite important advances in the process of conceiving and managing droughts, in spain, there are still important gaps for an adequate integration of droughts risk into the water resource strategies. therefore, despite the improvements, drought-risk vulnerability of the systems remained high.",https://www.mdpi.com/2071-1050/11/2/308/pdf?version=1547029065
4bf86ed83a9f73228b42bf4a3982ca410966ce12,FREEWAT: FREE and open source software tools for WATer resource management,"FREEWAT is an HORIZON 2020 project financed by the EU Commission under the call WATER INNOVATION: BOOSTING ITS VALUE FOR EUROPE. FREEWAT main result will be an open source and public domain GIS integrated modelling environment for the simulation of water quantity and quality in surface water and groundwater with an integrated water management and planning module. FREEWAT aims at promoting water resource management by simplifying the application of the Water Framework Directive and other EU water related Directives. Specific objectives of the FREEWAT project are: to coordinate previous EU and national funded research to integrate existing software modules for water management in a single environment into the GIS based FREEWAT; to support the FREEWAT application in an innovative participatory approach gathering technical staff and relevant stakeholders (in primis policy and decision makers) in designing scenarios for the proper application of water policies.The open source characteristics of the platform allow to consider this an initiative ad includendum (looking for inclusion of other entities), as further research institutions, private developers etc. may contribute to the platform development.Through creating a common environment among water research/professionals, policy makers and implementers, FREEWAT main impact will be on enhancing science- and participatory approach and evidence-based decision making in water resource management, hence producing relevant and appropriate outcomes for policy implementation. The Consortium is constituted by partners from various water sectors from 10 EU countries, plus Turkey and Ukraine. Synergies with the UNESCO HOPE initiative on free and open source software in water management greatly boost the value of the project. Large stakeholders involvement is thought to guarantee results dissemination and exploitation.",2015,"[{'authorId': '3430971', 'name': 'R. Rossetto'}, {'authorId': '144415767', 'name': 'I. Borsi'}, {'authorId': '50724515', 'name': 'L. Foglia'}]","{'url': 'http://pdfs.semanticscholar.org/3b87/0795d9ffc2bc50ff5840a11746f44c4fe2c7.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3301/ROL.2015.113?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3301/ROL.2015.113, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","freewat is an horizon 2020 project financed by the eu commission under the call water innovation: boosting its value for europe. freewat main result will be an open source and public domain gis integrated modelling environment for the simulation of water quantity and quality in surface water and groundwater with an integrated water management and planning module. freewat aims at promoting water resource management by simplifying the application of the water framework directive and other eu water related directives. specific objectives of the freewat project are: to coordinate previous eu and national funded research to integrate existing software modules for water management in a single environment into the gis based freewat; to support the freewat application in an innovative participatory approach gathering technical staff and relevant stakeholders (in primis policy and decision makers) in designing scenarios for the proper application of water policies.the open source characteristics of the platform allow to consider this an initiative ad includendum (looking for inclusion of other entities), as further research institutions, private developers etc. may contribute to the platform development.through creating a common environment among water research/professionals, policy makers and implementers, freewat main impact will be on enhancing science- and participatory approach and evidence-based decision making in water resource management, hence producing relevant and appropriate outcomes for policy implementation. the consortium is constituted by partners from various water sectors from 10 eu countries, plus turkey and ukraine. synergies with the unesco hope initiative on free and open source software in water management greatly boost the value of the project. large stakeholders involvement is thought to guarantee results dissemination and exploitation.",http://pdfs.semanticscholar.org/3b87/0795d9ffc2bc50ff5840a11746f44c4fe2c7.pdf
2243892d6ea6e2451498370348f78dfdf31547d6,Biological Integrity: A Long-Neglected Aspect of Water Resource Management.,"Water of sufficient quality and quantity is critical to all life. Increasing human population and growth of technology require human society to devote more and more attention to protection of adequate supplies of water. Although perception of biological degradation stimulated current state and federal legislation on the quality of water resources, that biological focus was lost in the search for easily measured physical and chemical surrogates. The ""fishable and swimmable"" goal of the Water Pollution Control Act of 1972 (PL 92-500) and its charge to ""restore and maintain"" biotic integrity illustrate that law's biological underpinning. Further, the need for operational definitions of terms like ""biological integrity"" and ""unreasonable degradation"" and for ecologically sound tools to measure divergence from societal goals have increased interest in biological monitoring. Assessment of water resource quality by sampling biological communities in the field (ambient biological monitoring) is a promising approach that requires expanded use of ecological expertise. One such approach, the Index of Biotic Integrity (IBI), provides a broadly based, multiparameter tool for the assessment of biotic integrity in running waters. IBI based on fish community attributes has now been applied widely in North America. The success of IBI has stimulated the development of similar approaches using other aquatic taxa. Expanded use of ecological expertise in ambient biological monitoring is essential to the protection of water resources. Ecologists have the expertise to contribute significantly to those programs.",1991,"[{'authorId': '90199140', 'name': 'J. Karr'}]","{'url': 'https://vtechworks.lib.vt.edu/bitstreams/8a297186-5f71-463e-9471-3356a0632a57/download', 'status': 'GREEN', 'license': 'mit', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2307/1941848?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2307/1941848, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","water of sufficient quality and quantity is critical to all life. increasing human population and growth of technology require human society to devote more and more attention to protection of adequate supplies of water. although perception of biological degradation stimulated current state and federal legislation on the quality of water resources, that biological focus was lost in the search for easily measured physical and chemical surrogates. the ""fishable and swimmable"" goal of the water pollution control act of 1972 (pl 92-500) and its charge to ""restore and maintain"" biotic integrity illustrate that law's biological underpinning. further, the need for operational definitions of terms like ""biological integrity"" and ""unreasonable degradation"" and for ecologically sound tools to measure divergence from societal goals have increased interest in biological monitoring. assessment of water resource quality by sampling biological communities in the field (ambient biological monitoring) is a promising approach that requires expanded use of ecological expertise. one such approach, the index of biotic integrity (ibi), provides a broadly based, multiparameter tool for the assessment of biotic integrity in running waters. ibi based on fish community attributes has now been applied widely in north america. the success of ibi has stimulated the development of similar approaches using other aquatic taxa. expanded use of ecological expertise in ambient biological monitoring is essential to the protection of water resources. ecologists have the expertise to contribute significantly to those programs.",https://vtechworks.lib.vt.edu/bitstreams/8a297186-5f71-463e-9471-3356a0632a57/download
a346fbe2209c52e60adaafcc9e91645ce442cfa9,A Review of the Analytical Hierarchy Process (AHP): An Approach to Water Resource Management in Thailand,"The analytical hierarchy process (AHP) is an approach for decision making with complex problems that can be applied in water resources management. This paper reviews the literature on application of AHP in water resource management from 2009-2013 in 46 peer reviewed journal articles, analyzes the strengths and limitations of the technique using SWOT analysis, and then focuses on its utility when integrated with other methods for water resource management in Thailand. The findings indicate that AHP can be utilized for all types of water resource management focused on criteria concerning social, economic and environmental factors. Furthermore, the efficacy of AHP can be enhanced when integrated with other techniques. Application of AHP in Thailand could be combined with the Delphi technique to identify key criteria for resolving bias problems regarding goal and criteria.",2015,"[{'authorId': '97857717', 'name': 'Jirattinart Thungngern'}, {'authorId': '94229658', 'name': 'Saowanee Wijitkosum'}, {'authorId': '2850193', 'name': 'T. Sriburi'}, {'authorId': '98734020', 'name': 'Chaiyuth Sukhsri'}]","{'url': 'https://www.tci-thaijo.org/index.php/aer/article/download/41250/34122', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.35762/AER.2015.37.3.2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.35762/AER.2015.37.3.2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the analytical hierarchy process (ahp) is an approach for decision making with complex problems that can be applied in water resources management. this paper reviews the literature on application of ahp in water resource management from 2009-2013 in 46 peer reviewed journal articles, analyzes the strengths and limitations of the technique using swot analysis, and then focuses on its utility when integrated with other methods for water resource management in thailand. the findings indicate that ahp can be utilized for all types of water resource management focused on criteria concerning social, economic and environmental factors. furthermore, the efficacy of ahp can be enhanced when integrated with other techniques. application of ahp in thailand could be combined with the delphi technique to identify key criteria for resolving bias problems regarding goal and criteria.",https://www.tci-thaijo.org/index.php/aer/article/download/41250/34122
0d1c8b41c6c3322672cc9c77c30c33a2d5101e45,On inclusion of water resource management in Earth system models – Part 1: Problem definition and representation of water demand,"Human activities have caused various changes to the Earth system, and hence the interconnections between human activities and the Earth system should be recognized and reflected in models that simulate Earth system processes. One key anthropogenic activity is water resource management, which determines the dynamics of human–water interactions in time and space and controls human livelihoods and economy, including energy and food production. There are immediate needs to include water resource management in Earth system models. First, the extent of human water requirements is increasing rapidly at the global scale and it is crucial to analyze the possible imbalance between water demands and supply under various scenarios of climate change and across various temporal and spatial scales. Second, recent observations show that human–water interactions, manifested through water resource management, can substantially alter the terrestrial water cycle, affect land–atmospheric feedbacks and may further interact with climate and contribute to sea-level change. Due to the importance of water resource management in determining the future of the global water and climate cycles, the World Climate Research Program's Global Energy and Water Exchanges project (WRCP-GEWEX) has recently identified gaps in describing human–water interactions as one of the grand challenges in Earth system modeling (GEWEX, 2012). Here, we divide water resource management into two interdependent elements, related firstly to water demand and secondly to water supply and allocation. In this paper, we survey the current literature on how various components of water demand have been included in large-scale models, in particular land surface and global hydrological models. Issues of water supply and allocation are addressed in a companion paper. The available algorithms to represent the dominant demands are classified based on the demand type, mode of simulation and underlying modeling assumptions. We discuss the pros and cons of available algorithms, address various sources of uncertainty and highlight limitations in current applications. We conclude that current capability of large-scale models to represent human water demands is rather limited, particularly with respect to future projections and coupled land–atmospheric simulations. To fill these gaps, the available models, algorithms and data for representing various water demands should be systematically tested, intercompared and improved. In particular, human water demands should be considered in conjunction with water supply and allocation, particularly in the face of water scarcity and unknown future climate.",2014,"[{'authorId': '2064284876', 'name': 'A. Nazemi'}, {'authorId': '73236103', 'name': 'H. Wheater'}]","{'url': 'https://hess.copernicus.org/articles/19/33/2015/hess-19-33-2015.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5194/HESS-19-33-2015?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5194/HESS-19-33-2015, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","human activities have caused various changes to the earth system, and hence the interconnections between human activities and the earth system should be recognized and reflected in models that simulate earth system processes. one key anthropogenic activity is water resource management, which determines the dynamics of human–water interactions in time and space and controls human livelihoods and economy, including energy and food production. there are immediate needs to include water resource management in earth system models. first, the extent of human water requirements is increasing rapidly at the global scale and it is crucial to analyze the possible imbalance between water demands and supply under various scenarios of climate change and across various temporal and spatial scales. second, recent observations show that human–water interactions, manifested through water resource management, can substantially alter the terrestrial water cycle, affect land–atmospheric feedbacks and may further interact with climate and contribute to sea-level change. due to the importance of water resource management in determining the future of the global water and climate cycles, the world climate research program's global energy and water exchanges project (wrcp-gewex) has recently identified gaps in describing human–water interactions as one of the grand challenges in earth system modeling (gewex, 2012). here, we divide water resource management into two interdependent elements, related firstly to water demand and secondly to water supply and allocation. in this paper, we survey the current literature on how various components of water demand have been included in large-scale models, in particular land surface and global hydrological models. issues of water supply and allocation are addressed in a companion paper. the available algorithms to represent the dominant demands are classified based on the demand type, mode of simulation and underlying modeling assumptions. we discuss the pros and cons of available algorithms, address various sources of uncertainty and highlight limitations in current applications. we conclude that current capability of large-scale models to represent human water demands is rather limited, particularly with respect to future projections and coupled land–atmospheric simulations. to fill these gaps, the available models, algorithms and data for representing various water demands should be systematically tested, intercompared and improved. in particular, human water demands should be considered in conjunction with water supply and allocation, particularly in the face of water scarcity and unknown future climate.",https://hess.copernicus.org/articles/19/33/2015/hess-19-33-2015.pdf
69744395bf14864285d52651305aa6019215416e,Why Eastern Himalayan countries should cooperate in transboundary water resource management,"Bangladesh, Bhutan, India, and Nepal in the Eastern Himalayas are interconnected by the common river systems of the Ganges, Brahmaputra, and Meghna (GBM). The GBM basin is home to approximately 700 million people, comprising over 10% of the world’s population. The economy and environment of the region depend on water, but while the need for water is increasing, poor management and climate-related effects are making water supplies erratic. Upstream–downstream interdependencies necessitate developing a shared river system in an integrated manner through collaboration of the riparian countries. This paper examines the opportunities for, and potential benefits of, regional cooperation in water resource management. It suggests that the benefits can increase considerably when a regional (river basin) perspective is adopted that promotes optimum use of water resources for consumptive and non-consumptive use. Regional cooperation can bring additional economic, environmental, social, and political benefits through multi-purpose river projects, which help by storing monsoon water, mitigating the effects of floods and droughts, augmenting dry season river flows, expanding irrigation and navigation facilities, generating hydropower, and enhancing energy and environmental security. A broader framework to facilitate regional cooperation in transboundary rivers in the Eastern Himalayan region is suggested.",2014,"[{'authorId': '88652453', 'name': 'G. Rasul'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2166/WP.2013.190?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2166/WP.2013.190, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","bangladesh, bhutan, india, and nepal in the eastern himalayas are interconnected by the common river systems of the ganges, brahmaputra, and meghna (gbm). the gbm basin is home to approximately 700 million people, comprising over 10% of the world’s population. the economy and environment of the region depend on water, but while the need for water is increasing, poor management and climate-related effects are making water supplies erratic. upstream–downstream interdependencies necessitate developing a shared river system in an integrated manner through collaboration of the riparian countries. this paper examines the opportunities for, and potential benefits of, regional cooperation in water resource management. it suggests that the benefits can increase considerably when a regional (river basin) perspective is adopted that promotes optimum use of water resources for consumptive and non-consumptive use. regional cooperation can bring additional economic, environmental, social, and political benefits through multi-purpose river projects, which help by storing monsoon water, mitigating the effects of floods and droughts, augmenting dry season river flows, expanding irrigation and navigation facilities, generating hydropower, and enhancing energy and environmental security. a broader framework to facilitate regional cooperation in transboundary rivers in the eastern himalayan region is suggested.",
cb50bc86ee09a5eed3f0f391022068904f0ae6d4,"Water Resource Management in Dry Zonal Paddy Cultivation in Mahaweli River Basin, Sri Lanka: An Analysis of Spatial and Temporal Climate Change Impacts and Traditional Knowledge","Lack of attention to spatial and temporal cross-scale dynamics and effects could be understood as one of the lacunas in scholarship on river basin management. Within the water-climate-food-energy nexus, an integrated and inclusive approach that recognizes traditional knowledge about and experiences of climate change and water resource management can provide crucial assistance in confronting problems in megaprojects and multipurpose river basin management projects. The Mahaweli Development Program (MDP), a megaproject and multipurpose river basin management project, is demonstrating substantial failures with regards to the spatial and temporal impacts of climate change and socioeconomic demands for water allocation and distribution for paddy cultivation in the dry zone area, which was one of the driving goals of the project at the initial stage. This interdisciplinary study explores how spatial and temporal climatic changes and uncertainty in weather conditions impact paddy cultivation in dry zonal areas with competing stakeholders’ interest in the Mahaweli River Basin. In the framework of embedded design in the mixed methods research approach, qualitative data is the primary source while quantitative analyses are used as supportive data. The key findings from the research analysis are as follows: close and in-depth consideration of spatial and temporal changes in climate systems and paddy farmers’ socioeconomic demands altered by seasonal changes are important factors. These factors should be considered in the future modification of water allocation, application of distribution technologies, and decision-making with regards to water resource management in the dry zonal paddy cultivation of Sri Lanka.",2014,"[{'authorId': '40832232', 'name': 'S. Withanachchi'}, {'authorId': '82891685', 'name': 'Sören Köpke'}, {'authorId': '51095198', 'name': 'C. R. Withanachchi'}, {'authorId': '108066664', 'name': 'R. Pathiranage'}, {'authorId': '31633806', 'name': 'A. Ploeger'}]","{'url': 'https://www.mdpi.com/2225-1154/2/4/329/pdf?version=1416324122', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/CLI2040329?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/CLI2040329, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","lack of attention to spatial and temporal cross-scale dynamics and effects could be understood as one of the lacunas in scholarship on river basin management. within the water-climate-food-energy nexus, an integrated and inclusive approach that recognizes traditional knowledge about and experiences of climate change and water resource management can provide crucial assistance in confronting problems in megaprojects and multipurpose river basin management projects. the mahaweli development program (mdp), a megaproject and multipurpose river basin management project, is demonstrating substantial failures with regards to the spatial and temporal impacts of climate change and socioeconomic demands for water allocation and distribution for paddy cultivation in the dry zone area, which was one of the driving goals of the project at the initial stage. this interdisciplinary study explores how spatial and temporal climatic changes and uncertainty in weather conditions impact paddy cultivation in dry zonal areas with competing stakeholders’ interest in the mahaweli river basin. in the framework of embedded design in the mixed methods research approach, qualitative data is the primary source while quantitative analyses are used as supportive data. the key findings from the research analysis are as follows: close and in-depth consideration of spatial and temporal changes in climate systems and paddy farmers’ socioeconomic demands altered by seasonal changes are important factors. these factors should be considered in the future modification of water allocation, application of distribution technologies, and decision-making with regards to water resource management in the dry zonal paddy cultivation of sri lanka.",https://www.mdpi.com/2225-1154/2/4/329/pdf?version=1416324122
1f6158d8eaeb007ca2712c4ccf7ba9761f550805,"Integrated Water Resource Management and Energy Requirements for Water Supply in the Copiapó River Basin, Chile","Population and industry growth in dry climates are fully tied to significant increase in water and energy demands. Because water affects many economic, social and environmental aspects, an interdisciplinary approach is needed to solve current and future water scarcity problems, and to minimize energy requirements in water production. Such a task requires integrated water modeling tools able to couple surface water and groundwater, which allow for managing complex basins where multiple stakeholders and water users face an intense competition for limited freshwater resources. This work develops an integrated water resource management model to investigate the water-energy nexus in reducing water stress in the Copiapo River basin, an arid, highly vulnerable basin in northern Chile. The model was utilized to characterize groundwater and surface water resources, and water demand and uses. Different management scenarios were evaluated to estimate future resource availability, and compared in terms of energy requirements and costs for desalinating seawater to eliminate the corresponding water deficit. Results show a basin facing a very complex future unless measures are adopted. When a 30% uniform reduction of water consumption is achieved, 70 GWh over the next 30 years are required to provide the energy needed to increase the available water through seawater desalination. In arid basins, this energy could be supplied by solar energy, thus addressing water shortage problems through integrated water resource management combined with new technologies of water production driven by renewable energy sources.",2014,"[{'authorId': '144999894', 'name': 'F. Suárez'}, {'authorId': '144109812', 'name': 'J. Muñoz'}, {'authorId': '145834757', 'name': 'B. Fernández'}, {'authorId': '2049997855', 'name': 'J. Dorsaz'}, {'authorId': '39433175', 'name': 'Christian Hunter'}, {'authorId': '25878209', 'name': 'C. Karavitis'}, {'authorId': '50702079', 'name': 'J. Gironás'}]","{'url': 'https://www.mdpi.com/2073-4441/6/9/2590/pdf?version=1433836908', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/W6092590?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/W6092590, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","population and industry growth in dry climates are fully tied to significant increase in water and energy demands. because water affects many economic, social and environmental aspects, an interdisciplinary approach is needed to solve current and future water scarcity problems, and to minimize energy requirements in water production. such a task requires integrated water modeling tools able to couple surface water and groundwater, which allow for managing complex basins where multiple stakeholders and water users face an intense competition for limited freshwater resources. this work develops an integrated water resource management model to investigate the water-energy nexus in reducing water stress in the copiapo river basin, an arid, highly vulnerable basin in northern chile. the model was utilized to characterize groundwater and surface water resources, and water demand and uses. different management scenarios were evaluated to estimate future resource availability, and compared in terms of energy requirements and costs for desalinating seawater to eliminate the corresponding water deficit. results show a basin facing a very complex future unless measures are adopted. when a 30% uniform reduction of water consumption is achieved, 70 gwh over the next 30 years are required to provide the energy needed to increase the available water through seawater desalination. in arid basins, this energy could be supplied by solar energy, thus addressing water shortage problems through integrated water resource management combined with new technologies of water production driven by renewable energy sources.",https://www.mdpi.com/2073-4441/6/9/2590/pdf?version=1433836908
820bb06693da90afb79276b3bf885ce5bc23e1c1,Community Water Governance on Mount Kenya: An Assessment Based on Ostrom’s Design Principles of Natural Resource Management,"Kenyan river basin governance underwent a pioneering reform in the Water Act of 2002, which established new community water-management institutions. This article focuses on community water projects in the Likii Water Resource Users Association in the Upper Ewaso Ng’iro River basin on Mount Kenya, and the extent to which their features are consistent with Ostrom’s design principles of natural resource management. Although the projects have developed solid institutional structures, pressures such as hydroclimatic change, population growth, and water inequality challenge their ability to manage their water resources. Institutional homogeneity across the different water projects and congruence with the design principles is not necessarily a positive factor. Strong differences in household water flows within and among the projects point to the disconnection between apparently successful institutions and their objectives, such as fair and equitable water allocation.",2016,"[{'authorId': '1403795280', 'name': 'J. Dell’Angelo'}, {'authorId': '40453028', 'name': 'P. McCord'}, {'authorId': '123063902', 'name': 'Drew Gower'}, {'authorId': '51458591', 'name': 'Stefan Carpenter'}, {'authorId': '2277507', 'name': 'Kelly K. Caylor'}, {'authorId': '25567482', 'name': 'T. Evans'}]","{'url': 'https://bioone.org/journals/Mountain-Research-and-Development/volume-36/issue-1/MRD-JOURNAL-D-15-00040.1/Community-Water-Governance-on-Mount-Kenya--An-Assessment-Based/10.1659/MRD-JOURNAL-D-15-00040.1.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1659/MRD-JOURNAL-D-15-00040.1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1659/MRD-JOURNAL-D-15-00040.1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","kenyan river basin governance underwent a pioneering reform in the water act of 2002, which established new community water-management institutions. this article focuses on community water projects in the likii water resource users association in the upper ewaso ng’iro river basin on mount kenya, and the extent to which their features are consistent with ostrom’s design principles of natural resource management. although the projects have developed solid institutional structures, pressures such as hydroclimatic change, population growth, and water inequality challenge their ability to manage their water resources. institutional homogeneity across the different water projects and congruence with the design principles is not necessarily a positive factor. strong differences in household water flows within and among the projects point to the disconnection between apparently successful institutions and their objectives, such as fair and equitable water allocation.",https://bioone.org/journals/Mountain-Research-and-Development/volume-36/issue-1/MRD-JOURNAL-D-15-00040.1/Community-Water-Governance-on-Mount-Kenya--An-Assessment-Based/10.1659/MRD-JOURNAL-D-15-00040.1.pdf
5078fef5822c550016e98e754ab51c1f54449ec2,Enabling the Use of Earth Observation Data for Integrated Water Resource Management in Africa with the Water Observation and Information System,"The Water Observation and Information System (WOIS) is an open source software tool for monitoring, assessing and inventorying water resources in a cost-effective manner using Earth Observation (EO) data. The WOIS has been developed by, among others, the authors of this paper under the TIGER-NET project, which is a major component of the TIGER initiative of the European Space Agency (ESA) and whose main goal is to support the African Earth Observation Capacity for Water Resource Monitoring. TIGER-NET aims to support the satellite-based assessment and monitoring of water resources from watershed to cross-border basin levels through the provision of a free and powerful software package, with associated capacity building, to African authorities. More than 28 EO data processing solutions for water resource management tasks have been developed, in correspondence with the requirements of the participating key African water authorities, and demonstrated with dedicated case studies utilizing the software in operational scenarios. They cover a wide range of themes and information products, including basin-wide characterization of land and water resources, lake water quality monitoring, hydrological modeling and flood forecasting and mapping. For each monitoring task, step-by-step workflows were developed, which can either be adjusted by the user or largely automatized to feed into existing data streams and reporting schemes. The WOIS enables African water authorities to fully exploit the increasing EO capacity offered by current and upcoming generations of satellites, including the Sentinel missions.",2014,"[{'authorId': '5970661', 'name': 'R. Guzinski'}, {'authorId': '28052439', 'name': 'S. Kass'}, {'authorId': '38015179', 'name': 'S. Huber'}, {'authorId': '1397424702', 'name': 'P. Bauer‐Gottwein'}, {'authorId': '48423291', 'name': 'Iris Hedegaard Jensen'}, {'authorId': '2792834', 'name': 'V. Naeimi'}, {'authorId': '3146368', 'name': 'M. Doubková'}, {'authorId': '34862794', 'name': 'Andreas Walli'}, {'authorId': '2824535', 'name': 'C. Tøttrup'}]","{'url': 'https://www.mdpi.com/2072-4292/6/8/7819/pdf?version=1408614946', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/RS6087819?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/RS6087819, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the water observation and information system (wois) is an open source software tool for monitoring, assessing and inventorying water resources in a cost-effective manner using earth observation (eo) data. the wois has been developed by, among others, the authors of this paper under the tiger-net project, which is a major component of the tiger initiative of the european space agency (esa) and whose main goal is to support the african earth observation capacity for water resource monitoring. tiger-net aims to support the satellite-based assessment and monitoring of water resources from watershed to cross-border basin levels through the provision of a free and powerful software package, with associated capacity building, to african authorities. more than 28 eo data processing solutions for water resource management tasks have been developed, in correspondence with the requirements of the participating key african water authorities, and demonstrated with dedicated case studies utilizing the software in operational scenarios. they cover a wide range of themes and information products, including basin-wide characterization of land and water resources, lake water quality monitoring, hydrological modeling and flood forecasting and mapping. for each monitoring task, step-by-step workflows were developed, which can either be adjusted by the user or largely automatized to feed into existing data streams and reporting schemes. the wois enables african water authorities to fully exploit the increasing eo capacity offered by current and upcoming generations of satellites, including the sentinel missions.",https://www.mdpi.com/2072-4292/6/8/7819/pdf?version=1408614946
50abc9cb7c15663ecf5d0c10e2c90123e93f6e1b,"Intelligent robotics in manufacturing, service, and rehabilitation: an overview","Advances in intelligent robotics are resulting in a new generation of programmable, sensory-interactive, computer-controlled machines capable of operating with human supervision or autonomously from sensed information. The design and integration of these machines require knowledge of actuators, control, mechanisms, mobility, programming, and sensors. The application of intelligent robotic technologies can increase the productivity, safety, and the quality of life for people in a wide range of tasks for land, space, and undersea environments. This paper provides an overview of developments of intelligent robotics to manufacturing systems, robotic aids for the disabled, and service. The references highlight advances in robot control, sensor integration, mechanical hands, manufacturing automation, walking machines, and powered prostheses. >",1994,"[{'authorId': '2398614', 'name': 'W. Gruver'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/41.281602?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/41.281602, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","advances in intelligent robotics are resulting in a new generation of programmable, sensory-interactive, computer-controlled machines capable of operating with human supervision or autonomously from sensed information. the design and integration of these machines require knowledge of actuators, control, mechanisms, mobility, programming, and sensors. the application of intelligent robotic technologies can increase the productivity, safety, and the quality of life for people in a wide range of tasks for land, space, and undersea environments. this paper provides an overview of developments of intelligent robotics to manufacturing systems, robotic aids for the disabled, and service. the references highlight advances in robot control, sensor integration, mechanical hands, manufacturing automation, walking machines, and powered prostheses. >",
469459e511b274bc6b296927380fb4a82a415aaf,"Advancements in materials, manufacturing, propulsion and localization: propelling soft robotics for medical applications","Soft robotics is an emerging field showing immense potential for biomedical applications. This review summarizes recent advancements in soft robotics for in vitro and in vivo medical contexts. Their inherent flexibility, adaptability, and biocompatibility enable diverse capabilities from surgical assistance to minimally invasive diagnosis and therapy. Intelligent stimuli-responsive materials and bioinspired designs are enhancing functionality while improving biocompatibility. Additive manufacturing techniques facilitate rapid prototyping and customization. Untethered chemical, biological, and wireless propulsion methods are overcoming previous constraints to access new sites. Meanwhile, advances in tracking modalities like computed tomography, fluorescence and ultrasound imaging enable precision localization and control enable in vivo applications. While still maturing, soft robotics promises more intelligent, less invasive technologies to improve patient care. Continuing research into biocompatibility, power supplies, biomimetics, and seamless localization will help translate soft robots into widespread clinical practice.",2024,"[{'authorId': '2278709992', 'name': 'Yunwen Bo'}, {'authorId': '2278798220', 'name': 'Haochen Wang'}, {'authorId': '2278669261', 'name': 'Hui Niu'}, {'authorId': '2278800826', 'name': 'Xinyang He'}, {'authorId': '2278658056', 'name': 'Quhao Xue'}, {'authorId': '2278650433', 'name': 'Zexi Li'}, {'authorId': '2145059026', 'name': 'Hao Yang'}, {'authorId': '2278769038', 'name': 'Fuzhou Niu'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fbioe.2023.1327441/pdf?isPublishedV2=False', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10800571, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","soft robotics is an emerging field showing immense potential for biomedical applications. this review summarizes recent advancements in soft robotics for in vitro and in vivo medical contexts. their inherent flexibility, adaptability, and biocompatibility enable diverse capabilities from surgical assistance to minimally invasive diagnosis and therapy. intelligent stimuli-responsive materials and bioinspired designs are enhancing functionality while improving biocompatibility. additive manufacturing techniques facilitate rapid prototyping and customization. untethered chemical, biological, and wireless propulsion methods are overcoming previous constraints to access new sites. meanwhile, advances in tracking modalities like computed tomography, fluorescence and ultrasound imaging enable precision localization and control enable in vivo applications. while still maturing, soft robotics promises more intelligent, less invasive technologies to improve patient care. continuing research into biocompatibility, power supplies, biomimetics, and seamless localization will help translate soft robots into widespread clinical practice.",https://www.frontiersin.org/articles/10.3389/fbioe.2023.1327441/pdf?isPublishedV2=False
8e76c41f4df07fdc512cb13f8e9b14e1692577ed,A Survey on AI-Driven Digital Twins in Industry 4.0: Smart Manufacturing and Advanced Robotics,"Digital twin (DT) and artificial intelligence (AI) technologies have grown rapidly in recent years and are considered by both academia and industry to be key enablers for Industry 4.0. As a digital replica of a physical entity, the basis of DT is the infrastructure and data, the core is the algorithm and model, and the application is the software and service. The grounding of DT and AI in industrial sectors is even more dependent on the systematic and in-depth integration of domain-specific expertise. This survey comprehensively reviews over 300 manuscripts on AI-driven DT technologies of Industry 4.0 used over the past five years and summarizes their general developments and the current state of AI-integration in the fields of smart manufacturing and advanced robotics. These cover conventional sophisticated metal machining and industrial automation as well as emerging techniques, such as 3D printing and human–robot interaction/cooperation. Furthermore, advantages of AI-driven DTs in the context of sustainable development are elaborated. Practical challenges and development prospects of AI-driven DTs are discussed with a respective focus on different levels. A route for AI-integration in multiscale/fidelity DTs with multiscale/fidelity data sources in Industry 4.0 is outlined.",2021,"[{'authorId': '2135733543', 'name': 'Ziqi Huang'}, {'authorId': '2115437436', 'name': 'Yang Shen'}, {'authorId': '2109010648', 'name': 'Jiayi Li'}, {'authorId': '2065798014', 'name': 'M. Fey'}, {'authorId': '1735841', 'name': 'C. Brecher'}]","{'url': 'https://www.mdpi.com/1424-8220/21/19/6340/pdf?version=1632809060', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8512418, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","digital twin (dt) and artificial intelligence (ai) technologies have grown rapidly in recent years and are considered by both academia and industry to be key enablers for industry 4.0. as a digital replica of a physical entity, the basis of dt is the infrastructure and data, the core is the algorithm and model, and the application is the software and service. the grounding of dt and ai in industrial sectors is even more dependent on the systematic and in-depth integration of domain-specific expertise. this survey comprehensively reviews over 300 manuscripts on ai-driven dt technologies of industry 4.0 used over the past five years and summarizes their general developments and the current state of ai-integration in the fields of smart manufacturing and advanced robotics. these cover conventional sophisticated metal machining and industrial automation as well as emerging techniques, such as 3d printing and human–robot interaction/cooperation. furthermore, advantages of ai-driven dts in the context of sustainable development are elaborated. practical challenges and development prospects of ai-driven dts are discussed with a respective focus on different levels. a route for ai-integration in multiscale/fidelity dts with multiscale/fidelity data sources in industry 4.0 is outlined.",https://www.mdpi.com/1424-8220/21/19/6340/pdf?version=1632809060
25ffaf5ce33c13812e29c0c28dba03521e9e0245,Advanced robotics and additive manufacturing of composites: towards a new era in Industry 4.0,"ABSTRACT In recent years, new revolutionary paradigms generally indicated using the term Industry 4.0, have been conceived and are progressively applied in several manufacturing systems to achieve a smarter, more effective, and sustainable production. This article aims to depict the present and future scenarios related to the application of Industry 4.0 concepts to polymer composites manufacturing. To provide a view on future potential, and open new research frontiers, the article attempts to address through elaborate discussions two major questions: What is the future of fiber-reinforced polymer composites manufacturing in the Industry 4.0 context? What are the recent and potential developments in robotic and additive manufacturing of advanced fiber-reinforced composites? The article, in addition, connects new avenues in additive manufacturing, for instance, incorporating topology optimization, design opportunities, recent industrial developments in machines and patent disclosures, and defect detection/mitigation during manufacture. Similarly, recent developments concerning robotic Automated Fiber/Tape Placement have been provided, discussing state-of-the-art research trends and future opportunities.",2021,"[{'authorId': '1450747553', 'name': 'Het Parmar'}, {'authorId': '150320623', 'name': 'T. Khan'}, {'authorId': '101664553', 'name': 'F. Tucci'}, {'authorId': '46203550', 'name': 'R. Umer'}, {'authorId': '3253369', 'name': 'P. Carlone'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/10426914.2020.1866195?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/10426914.2020.1866195, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract in recent years, new revolutionary paradigms generally indicated using the term industry 4.0, have been conceived and are progressively applied in several manufacturing systems to achieve a smarter, more effective, and sustainable production. this article aims to depict the present and future scenarios related to the application of industry 4.0 concepts to polymer composites manufacturing. to provide a view on future potential, and open new research frontiers, the article attempts to address through elaborate discussions two major questions: what is the future of fiber-reinforced polymer composites manufacturing in the industry 4.0 context? what are the recent and potential developments in robotic and additive manufacturing of advanced fiber-reinforced composites? the article, in addition, connects new avenues in additive manufacturing, for instance, incorporating topology optimization, design opportunities, recent industrial developments in machines and patent disclosures, and defect detection/mitigation during manufacture. similarly, recent developments concerning robotic automated fiber/tape placement have been provided, discussing state-of-the-art research trends and future opportunities.",
afe37ce002ae1272625f09c51c01ee317979b632,Action recognition for the robotics and manufacturing automation using 3-D binary micro-block difference,"Vision-based control systems play an important role in modern robotics systems. An important task in implementing such a system is developing an effective algorithm for recognizing human actions and the working environment and the design of intuitive gesture commands. This paper proposes an action recognition algorithm for robotics and manufacturing automation. The key contributions are (1) fusion of multimodal information obtained by depth sensors and cameras of the visible range, (2) modified Gabor-based and 3-D binary-based descriptor using micro-block difference, (3) efficient skeleton-based descriptor, and (4) recognition algorithm using the combined descriptor. The proposed binary micro-block difference representation of 3-D patches from video with a complex background in several scales and orientations leads to an informative description of the scene action. The experimental results showed the effectiveness of the proposed algorithm on datasets.",2021,"[{'authorId': '51162043', 'name': 'V. Voronin'}, {'authorId': '101405063', 'name': 'M. Zhdanova'}, {'authorId': '51504102', 'name': 'E. Semenishchev'}, {'authorId': '1391796879', 'name': 'A. Zelenskii'}, {'authorId': '2337096', 'name': 'Yigang Cen'}, {'authorId': '8973902', 'name': 'S. Agaian'}]","{'url': 'https://www.researchsquare.com/article/rs-189925/latest.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s00170-021-07613-2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s00170-021-07613-2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","vision-based control systems play an important role in modern robotics systems. an important task in implementing such a system is developing an effective algorithm for recognizing human actions and the working environment and the design of intuitive gesture commands. this paper proposes an action recognition algorithm for robotics and manufacturing automation. the key contributions are (1) fusion of multimodal information obtained by depth sensors and cameras of the visible range, (2) modified gabor-based and 3-d binary-based descriptor using micro-block difference, (3) efficient skeleton-based descriptor, and (4) recognition algorithm using the combined descriptor. the proposed binary micro-block difference representation of 3-d patches from video with a complex background in several scales and orientations leads to an informative description of the scene action. the experimental results showed the effectiveness of the proposed algorithm on datasets.",https://www.researchsquare.com/article/rs-189925/latest.pdf
871a81929071a133df8b839510713eaa6174b129,Modelling and quantification of industry 4.0 manufacturing complexity based on information theory: a robotics case study,"The new industrial revolution called Industry 4.0 imposes new challenges to the research community. One of the main issues in Industry 4.0 is the management of the huge amount of information exchanged among its different integrated systems. The present work demonstrates how the traditional manufacturing system is transformed to the Industry 4.0 manufacturing system and proposes a modelling and quantification approach, which includes metrics from the Information Theory estimating the complexity and the capacity of the Industry 4.0, from the perspective of the communication among the systems. The application impact of the proposed Industry 4.0 system and the comparison of these metrics before and after shifting to Industry 4.0 is also analysed and validated in a case study from the Robotics Industry.",2019,"[{'authorId': '3246153', 'name': 'D. Mourtzis'}, {'authorId': '2894802', 'name': 'Sophia Fotia'}, {'authorId': '24367563', 'name': 'Nikoletta Boli'}, {'authorId': '9648386', 'name': 'Ekaterini Vlachou'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/00207543.2019.1571686?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/00207543.2019.1571686, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the new industrial revolution called industry 4.0 imposes new challenges to the research community. one of the main issues in industry 4.0 is the management of the huge amount of information exchanged among its different integrated systems. the present work demonstrates how the traditional manufacturing system is transformed to the industry 4.0 manufacturing system and proposes a modelling and quantification approach, which includes metrics from the information theory estimating the complexity and the capacity of the industry 4.0, from the perspective of the communication among the systems. the application impact of the proposed industry 4.0 system and the comparison of these metrics before and after shifting to industry 4.0 is also analysed and validated in a case study from the robotics industry.",
5aa597a12543bf333fb98db8cae823e141ebfe2a,Flexible skill-based control for robot cells in manufacturing,"Decreasing batch sizes lead to an increasing demand for flexible automation systems in manufacturing industries. Robot cells are one solution for automating manufacturing tasks more flexibly. Besides the ongoing unifications in the hardware components, the controllers are still programmed application specifically and non-uniform. Only specialized experts can reconfigure and reprogram the controllers when process changes occur. To provide a more flexible control, this paper presents a new method for programming flexible skill-based controls for robot cells. In comparison to the common programming in logic controllers, operators independently adapt and expand the automated process sequence without modifying the controller code. For a high flexibility, the paper summarizes the software requirements in terms of an extensibility, flexible usability, configurability, and reusability of the control. Therefore, the skill-based control introduces a modularization of the assets in the control and parameterizable skills as abstract template class methodically. An orchestration system is used to call the skills with the corresponding parameter set and combine them into automated process sequences. A mobile flexible robot cell is used for the validation of the skill-based control architecture. Finally, the main benefits and limitations of the concept are discussed and future challenges of flexible skill-based controls for robot cells are provided.",2022,"[{'authorId': '1380894459', 'name': 'T. Wiese'}, {'authorId': '1990662741', 'name': 'J. Abicht'}, {'authorId': '144080899', 'name': 'C. Friedrich'}, {'authorId': '11772720', 'name': 'A. Hellmich'}, {'authorId': '2295665', 'name': 'S. Ihlenfeldt'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/frobt.2022.1014476/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9557093, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","decreasing batch sizes lead to an increasing demand for flexible automation systems in manufacturing industries. robot cells are one solution for automating manufacturing tasks more flexibly. besides the ongoing unifications in the hardware components, the controllers are still programmed application specifically and non-uniform. only specialized experts can reconfigure and reprogram the controllers when process changes occur. to provide a more flexible control, this paper presents a new method for programming flexible skill-based controls for robot cells. in comparison to the common programming in logic controllers, operators independently adapt and expand the automated process sequence without modifying the controller code. for a high flexibility, the paper summarizes the software requirements in terms of an extensibility, flexible usability, configurability, and reusability of the control. therefore, the skill-based control introduces a modularization of the assets in the control and parameterizable skills as abstract template class methodically. an orchestration system is used to call the skills with the corresponding parameter set and combine them into automated process sequences. a mobile flexible robot cell is used for the validation of the skill-based control architecture. finally, the main benefits and limitations of the concept are discussed and future challenges of flexible skill-based controls for robot cells are provided.",https://www.frontiersin.org/articles/10.3389/frobt.2022.1014476/pdf
6ba1fba4837dc015c733ed4c38491ab6eba8e7d8,Advanced Manufacturing in Industry 5.0: A Survey of Key Enabling Technologies and Future Trends,"A revolution in advanced manufacturing has been driven by digital technology in the fourth industrial revolution, also known as Industry 4.0, and has resulted in a substantial increase in profits for the industry. In a new paradigm of Industry 5.0, advanced manufacturing will step further and be capable of offering customized products and a better user experience. A number of key enabling technologies are expected to play crucial roles in assisting Industry 5.0 in meeting higher demands of data acquisition and processing, communications, and collaborative robots in the advanced manufacturing process. The aim of this survey is to provide novel insights into advanced manufacturing in Industry 5.0 by summarizing the latest progress of key enabling technologies, such as artificial intelligence of things (AIoT), beyond 5G communications, and collaborative robotics. Finally, key directions for future research to enable this vision to become a reality, such as the industrial metaverse, are outlined.",2024,"[{'authorId': '46595133', 'name': 'Wei Xian'}, {'authorId': '47841301', 'name': 'K. Yu'}, {'authorId': '145390330', 'name': 'Fengling Han'}, {'authorId': '123299986', 'name': 'L. Fang'}, {'authorId': '97757342', 'name': 'D. He'}, {'authorId': '47837643', 'name': 'Qing‐Long Han'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TII.2023.3274224?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TII.2023.3274224, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a revolution in advanced manufacturing has been driven by digital technology in the fourth industrial revolution, also known as industry 4.0, and has resulted in a substantial increase in profits for the industry. in a new paradigm of industry 5.0, advanced manufacturing will step further and be capable of offering customized products and a better user experience. a number of key enabling technologies are expected to play crucial roles in assisting industry 5.0 in meeting higher demands of data acquisition and processing, communications, and collaborative robots in the advanced manufacturing process. the aim of this survey is to provide novel insights into advanced manufacturing in industry 5.0 by summarizing the latest progress of key enabling technologies, such as artificial intelligence of things (aiot), beyond 5g communications, and collaborative robotics. finally, key directions for future research to enable this vision to become a reality, such as the industrial metaverse, are outlined.",
1ff66ae366fbfc915aa8059f8d7ea1fd33db0c07,Intelligent Robotics—A Systematic Review of Emerging Technologies and Trends,"Intelligent robotics has the potential to revolutionize various industries by amplifying output, streamlining operations, and enriching customer interactions. This systematic literature review aims to analyze emerging technologies and trends in intelligent robotics, addressing key research questions, identifying challenges and opportunities, and proposing the best practices for responsible and beneficial integration into various sectors. Our research uncovers the significant improvements brought by intelligent robotics across industries such as manufacturing, logistics, tourism, agriculture, healthcare, and construction. The main results indicate the importance of focusing on human–robot collaboration, ethical considerations, sustainable practices, and addressing industry-specific challenges to harness the opportunities presented by intelligent robotics fully. The implications and future directions of intelligent robotics involve addressing both challenges and potential risks, maximizing benefits, and ensuring responsible implementation. The continuous improvement and refinement of existing technology will shape human life and industries, driving innovation and advancements in intelligent robotics.",2024,"[{'authorId': '2282835082', 'name': 'Josip Tomo Licardo'}, {'authorId': '2282842135', 'name': 'Mihael Domjan'}, {'authorId': '2467164', 'name': 'T. Orehovački'}]","{'url': 'https://www.mdpi.com/2079-9292/13/3/542/pdf?version=1706537048', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/electronics13030542?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/electronics13030542, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","intelligent robotics has the potential to revolutionize various industries by amplifying output, streamlining operations, and enriching customer interactions. this systematic literature review aims to analyze emerging technologies and trends in intelligent robotics, addressing key research questions, identifying challenges and opportunities, and proposing the best practices for responsible and beneficial integration into various sectors. our research uncovers the significant improvements brought by intelligent robotics across industries such as manufacturing, logistics, tourism, agriculture, healthcare, and construction. the main results indicate the importance of focusing on human–robot collaboration, ethical considerations, sustainable practices, and addressing industry-specific challenges to harness the opportunities presented by intelligent robotics fully. the implications and future directions of intelligent robotics involve addressing both challenges and potential risks, maximizing benefits, and ensuring responsible implementation. the continuous improvement and refinement of existing technology will shape human life and industries, driving innovation and advancements in intelligent robotics.",https://www.mdpi.com/2079-9292/13/3/542/pdf?version=1706537048
1c86ef34bf1a2ab2cea2fd79c29852d21d75e060,Human-Robot Collaboration in Manufacturing Applications: A Review,"This paper provides an overview of collaborative robotics towards manufacturing applications. Over the last decade, the market has seen the introduction of a new category of robots—collaborative robots (or “cobots”)—designed to physically interact with humans in a shared environment, without the typical barriers or protective cages used in traditional robotics systems. Their potential is undisputed, especially regarding their flexible ability to make simple, quick, and cheap layout changes; however, it is necessary to have adequate knowledge of their correct uses and characteristics to obtain the advantages of this form of robotics, which can be a barrier for industry uptake. The paper starts with an introduction of human–robot collaboration, presenting the related standards and modes of operation. An extensive literature review of works published in this area is undertaken, with particular attention to the main industrial cases of application. The paper concludes with an analysis of the future trends in human–robot collaboration as determined by the authors.",2019,"[{'authorId': '143733190', 'name': 'E. Matheson'}, {'authorId': '1381043701', 'name': 'R. Minto'}, {'authorId': '153613559', 'name': 'Emanuele G. G. Zampieri'}, {'authorId': '49711808', 'name': 'M. Faccio'}, {'authorId': '24105360', 'name': 'G. Rosati'}]","{'url': 'https://www.mdpi.com/2218-6581/8/4/100/pdf?version=1576300399', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/robotics8040100?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/robotics8040100, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper provides an overview of collaborative robotics towards manufacturing applications. over the last decade, the market has seen the introduction of a new category of robots—collaborative robots (or “cobots”)—designed to physically interact with humans in a shared environment, without the typical barriers or protective cages used in traditional robotics systems. their potential is undisputed, especially regarding their flexible ability to make simple, quick, and cheap layout changes; however, it is necessary to have adequate knowledge of their correct uses and characteristics to obtain the advantages of this form of robotics, which can be a barrier for industry uptake. the paper starts with an introduction of human–robot collaboration, presenting the related standards and modes of operation. an extensive literature review of works published in this area is undertaken, with particular attention to the main industrial cases of application. the paper concludes with an analysis of the future trends in human–robot collaboration as determined by the authors.",https://www.mdpi.com/2218-6581/8/4/100/pdf?version=1576300399
5b9504641f00c7850e299da1f08b3cea2790223c,Consider the Human Work Experience When Integrating Robotics in the Workplace,"Worldwide, manufacturers are reimagining the future of their workforce and its connection to technology. Rather than replacing humans, Industry 5.0 explores how humans and robots can best complement one another's unique strengths. However, realizing this vision requires an in-depth understanding of how workers view the positive and negative attributes of their jobs, and the place of robots within it. In this paper, we explore the relationship between work attributes and automation goals by engaging in field research at a manufacturing plant. We conducted 50 face-to-face interviews with assembly-line workers $(\mathrm{n}=50)$, which we analyzed using discourse analysis and social constructivist methods. We found that the work attributes deemed most positive by participants include social interaction, movement and exercise, (human) autonomy, problem solving, task variety, and building with their hands. The main negative work attributes included health and safety issues, feeling rushed, and repetitive work. We identified several ways robots could help reduce negative work attributes and enhance positive ones, such as reducing work interruptions and cultivating physical and psychological well-being. Based on our findings, we created a set of integration considerations for organizations planning to deploy robotics technology, and discuss how the manufacturing and HRI communities can explore these ideas in the future.",2019,"[{'authorId': '88726030', 'name': 'Katherine S. Welfare'}, {'authorId': '3911801', 'name': 'Matthew R. Hallowell'}, {'authorId': '143873972', 'name': 'J. Shah'}, {'authorId': '144786679', 'name': 'L. Riek'}]","{'url': 'https://dspace.mit.edu/bitstream/1721.1/125902/2/welfare-hallowell-shah-riek-HRI19.pdf', 'status': 'GREEN', 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/HRI.2019.8673139?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/HRI.2019.8673139, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","worldwide, manufacturers are reimagining the future of their workforce and its connection to technology. rather than replacing humans, industry 5.0 explores how humans and robots can best complement one another's unique strengths. however, realizing this vision requires an in-depth understanding of how workers view the positive and negative attributes of their jobs, and the place of robots within it. in this paper, we explore the relationship between work attributes and automation goals by engaging in field research at a manufacturing plant. we conducted 50 face-to-face interviews with assembly-line workers $(\mathrm{n}=50)$, which we analyzed using discourse analysis and social constructivist methods. we found that the work attributes deemed most positive by participants include social interaction, movement and exercise, (human) autonomy, problem solving, task variety, and building with their hands. the main negative work attributes included health and safety issues, feeling rushed, and repetitive work. we identified several ways robots could help reduce negative work attributes and enhance positive ones, such as reducing work interruptions and cultivating physical and psychological well-being. based on our findings, we created a set of integration considerations for organizations planning to deploy robotics technology, and discuss how the manufacturing and hri communities can explore these ideas in the future.",https://dspace.mit.edu/bitstream/1721.1/125902/2/welfare-hallowell-shah-riek-HRI19.pdf
85b04c8bc2e4d513b21eb1d73f9b096fef90bb8f,Activity recognition in manufacturing: The roles of motion capture and sEMG+inertial wearables in detecting fine vs. gross motion,"In safety-critical environments, robots need to reliably recognize human activity to be effective and trust-worthy partners. Since most human activity recognition (HAR) approaches rely on unimodal sensor data (e.g. motion capture or wearable sensors), it is unclear how the relationship between the sensor modality and motion granularity (e.g. gross or fine) of the activities impacts classification accuracy. To our knowledge, we are the first to investigate the efficacy of using motion capture as compared to wearable sensor data for recognizing human motion in manufacturing settings. We introduce the UCSD-MIT Human Motion dataset, composed of two assembly tasks that entail either gross or fine-grained motion. For both tasks, we compared the accuracy of a Vicon motion capture system to a Myo armband using three widely used HAR algorithms. We found that motion capture yielded higher accuracy than the wearable sensor for gross motion recognition (up to 36.95%), while the wearable sensor yielded higher accuracy for fine-grained motion (up to 28.06%). These results suggest that these sensor modalities are complementary, and that robots may benefit from systems that utilize multiple modalities to simultaneously, but independently, detect gross and fine-grained motion. Our findings will help guide researchers in numerous fields of robotics including learning from demonstration and grasping to effectively choose sensor modalities that are most suitable for their applications.",2019,"[{'authorId': '153446415', 'name': 'A. Kubota'}, {'authorId': '47800331', 'name': 'T. Iqbal'}, {'authorId': '143873972', 'name': 'J. Shah'}, {'authorId': '144786679', 'name': 'L. Riek'}]","{'url': 'https://dspace.mit.edu/bitstream/1721.1/125890/2/kubtoa-iqbal-shah-riek-ICRA19.pdf', 'status': 'GREEN', 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICRA.2019.8793954?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICRA.2019.8793954, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in safety-critical environments, robots need to reliably recognize human activity to be effective and trust-worthy partners. since most human activity recognition (har) approaches rely on unimodal sensor data (e.g. motion capture or wearable sensors), it is unclear how the relationship between the sensor modality and motion granularity (e.g. gross or fine) of the activities impacts classification accuracy. to our knowledge, we are the first to investigate the efficacy of using motion capture as compared to wearable sensor data for recognizing human motion in manufacturing settings. we introduce the ucsd-mit human motion dataset, composed of two assembly tasks that entail either gross or fine-grained motion. for both tasks, we compared the accuracy of a vicon motion capture system to a myo armband using three widely used har algorithms. we found that motion capture yielded higher accuracy than the wearable sensor for gross motion recognition (up to 36.95%), while the wearable sensor yielded higher accuracy for fine-grained motion (up to 28.06%). these results suggest that these sensor modalities are complementary, and that robots may benefit from systems that utilize multiple modalities to simultaneously, but independently, detect gross and fine-grained motion. our findings will help guide researchers in numerous fields of robotics including learning from demonstration and grasping to effectively choose sensor modalities that are most suitable for their applications.",https://dspace.mit.edu/bitstream/1721.1/125890/2/kubtoa-iqbal-shah-riek-ICRA19.pdf
16ecb8570b40663cac5a139907368fc46afb59ae,3D Knitting for Pneumatic Soft Robotics,"Soft robots adapt passively to complex environments due to their inherent compliance, allowing them to interact safely with fragile or irregular objects and traverse uneven terrain. The vast tunability and ubiquity of textiles has enabled new soft robotic capabilities, especially in the field of wearable robots, but existing textile processing techniques (e.g., cut‐and‐sew, thermal bonding) are limited in terms of rapid, additive, accessible, and waste‐free manufacturing. While 3D knitting has the potential to address these limitations, an incomplete understanding of the impact of structure and material on knit‐scale mechanical properties and macro‐scale device performance has precluded the widespread adoption of knitted robots. In this work, the roles of knit structure and yarn material properties on textile mechanics spanning three regimes–unfolding, geometric rearrangement, and yarn stretching–are elucidated and shown to be tailorable across unique knit architectures and yarn materials. Based on this understanding, 3D knit soft actuators for extension, contraction, and bending are constructed. Combining these actuation primitives enables the monolithic fabrication of entire soft grippers and robots in a single‐step additive manufacturing procedure suitable for a variety of applications. This approach represents a first step in seamlessly “printing” conformal, low‐cost, customizable textile‐based soft robots on‐demand.",2023,"[{'authorId': '153618881', 'name': 'Vanessa Sanchez'}, {'authorId': '1474867496', 'name': 'K. Mahadevan'}, {'authorId': '2215315974', 'name': 'Gabrielle Ohlson'}, {'authorId': '3414266', 'name': 'M. Graule'}, {'authorId': '29363034', 'name': 'Michelle C. Yuen'}, {'authorId': '23558820', 'name': 'Clark B. Teeple'}, {'authorId': '2105928472', 'name': 'James C. Weaver'}, {'authorId': '144589722', 'name': 'J. McCann'}, {'authorId': '3145841', 'name': 'K. Bertoldi'}, {'authorId': '2204742847', 'name': 'Robert J. Wood'}]","{'url': 'https://doi.org/10.1002/adfm.202212541', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/adfm.202212541?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/adfm.202212541, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","soft robots adapt passively to complex environments due to their inherent compliance, allowing them to interact safely with fragile or irregular objects and traverse uneven terrain. the vast tunability and ubiquity of textiles has enabled new soft robotic capabilities, especially in the field of wearable robots, but existing textile processing techniques (e.g., cut‐and‐sew, thermal bonding) are limited in terms of rapid, additive, accessible, and waste‐free manufacturing. while 3d knitting has the potential to address these limitations, an incomplete understanding of the impact of structure and material on knit‐scale mechanical properties and macro‐scale device performance has precluded the widespread adoption of knitted robots. in this work, the roles of knit structure and yarn material properties on textile mechanics spanning three regimes–unfolding, geometric rearrangement, and yarn stretching–are elucidated and shown to be tailorable across unique knit architectures and yarn materials. based on this understanding, 3d knit soft actuators for extension, contraction, and bending are constructed. combining these actuation primitives enables the monolithic fabrication of entire soft grippers and robots in a single‐step additive manufacturing procedure suitable for a variety of applications. this approach represents a first step in seamlessly “printing” conformal, low‐cost, customizable textile‐based soft robots on‐demand.",https://doi.org/10.1002/adfm.202212541
ff4362f6f1a642bf8d54519137382c7fa5cebb6a,3D Printing Architectural Freeform Elements: Challenges and Opportunities in Manufacturing for Industry 4.0,"Three-dimensional (3D) printing, as one of the additive manufacturing (AM) technologies, is transforming the design and manufacture of products and components across a variety of disciplines, however, architectural design and the construction industry have only recently begun to adopt these technologies for construction purposes. AM is considered one of the core technological advances in the paradigm shift to Industry 4.0 (the fourth industrial revolution). This term used to describe digitization and automation of the manufacturing environment and is widely recognized as a disruptive technology that could transform architectural design and the construction industry. The potential advantages of 3D printing in the construction sector are significant. They include not only improved environmental and financial resource efficiencies, but also, the capacity to produce complex customized designs for aesthetic and structural applications. As the cost of building houses continues to rise, it is crucial to find innovative ways to build houses efficiently and cost effectively. The earliest records of 3D printing date back to the 1980’s and many industries—from manufacturing to medicine—were early adopters of the technologies resulting in many significant technological advances in those sectors from organ printing to aircraft fabrication. Currently available 3D printing technologies can be adopted for building construction and this paper discusses the applications, advantages, limitations and future directions of 3D printing as a viable solution for affordable house construction with a focus on printing architectural freeform elements. 3D printing offers a new and innovative method of house construction. For this study, an analytical, as well as a numerical model were specifically designed for 3D printing. Previous studies conducted found that the construction of a 3D printed truss-like roof in a cement mixture with high-density polyethylene (HDPE), spanning the entire structure, was structurally feasible in the absence of steel reinforcements. These results led us to investigate the feasibility of 3D printing an entire house without the use of reinforcements. Investigations were also performed on comparing flat-roof and arch-roof structures and found that whilst maximum tensile stresses within flat-roof would cause the concrete truss structure to fail, the HDPE cement mix in an arch-roof structure had reduced the maximum tensile stresses to an acceptable range to withstand loadings. At the time of writing this paper, several 3D printing techniques could be adopted for the purposes of 3D printing an entire house, and the team believes that future adaptations of existing technologies and printing materials could eliminate the current limitations of 3D printing and become common practice in house construction.",2019,"[{'authorId': '1658993400', 'name': 'M. Niemela'}, {'authorId': '2058459842', 'name': 'Anqi Shi'}, {'authorId': '90529039', 'name': 'S. Shirowzhan'}, {'authorId': '90426770', 'name': 'S. Sepasgozar'}, {'authorId': '2118485110', 'name': 'Chang Liu'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.22260/ISARC2019/0174?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.22260/ISARC2019/0174, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","three-dimensional (3d) printing, as one of the additive manufacturing (am) technologies, is transforming the design and manufacture of products and components across a variety of disciplines, however, architectural design and the construction industry have only recently begun to adopt these technologies for construction purposes. am is considered one of the core technological advances in the paradigm shift to industry 4.0 (the fourth industrial revolution). this term used to describe digitization and automation of the manufacturing environment and is widely recognized as a disruptive technology that could transform architectural design and the construction industry. the potential advantages of 3d printing in the construction sector are significant. they include not only improved environmental and financial resource efficiencies, but also, the capacity to produce complex customized designs for aesthetic and structural applications. as the cost of building houses continues to rise, it is crucial to find innovative ways to build houses efficiently and cost effectively. the earliest records of 3d printing date back to the 1980’s and many industries—from manufacturing to medicine—were early adopters of the technologies resulting in many significant technological advances in those sectors from organ printing to aircraft fabrication. currently available 3d printing technologies can be adopted for building construction and this paper discusses the applications, advantages, limitations and future directions of 3d printing as a viable solution for affordable house construction with a focus on printing architectural freeform elements. 3d printing offers a new and innovative method of house construction. for this study, an analytical, as well as a numerical model were specifically designed for 3d printing. previous studies conducted found that the construction of a 3d printed truss-like roof in a cement mixture with high-density polyethylene (hdpe), spanning the entire structure, was structurally feasible in the absence of steel reinforcements. these results led us to investigate the feasibility of 3d printing an entire house without the use of reinforcements. investigations were also performed on comparing flat-roof and arch-roof structures and found that whilst maximum tensile stresses within flat-roof would cause the concrete truss structure to fail, the hdpe cement mix in an arch-roof structure had reduced the maximum tensile stresses to an acceptable range to withstand loadings. at the time of writing this paper, several 3d printing techniques could be adopted for the purposes of 3d printing an entire house, and the team believes that future adaptations of existing technologies and printing materials could eliminate the current limitations of 3d printing and become common practice in house construction.",
a07a0407cdcfc58669791986c576ba7b078b70fc,Soft robotics towards sustainable development goals and climate actions,"Soft robotics technology can aid in achieving United Nations’ Sustainable Development Goals (SDGs) and the Paris Climate Agreement through development of autonomous, environmentally responsible machines powered by renewable energy. By utilizing soft robotics, we can mitigate the detrimental effects of climate change on human society and the natural world through fostering adaptation, restoration, and remediation. Moreover, the implementation of soft robotics can lead to groundbreaking discoveries in material science, biology, control systems, energy efficiency, and sustainable manufacturing processes. However, to achieve these goals, we need further improvements in understanding biological principles at the basis of embodied and physical intelligence, environment-friendly materials, and energy-saving strategies to design and manufacture self-piloting and field-ready soft robots. This paper provides insights on how soft robotics can address the pressing issue of environmental sustainability. Sustainable manufacturing of soft robots at a large scale, exploring the potential of biodegradable and bioinspired materials, and integrating onboard renewable energy sources to promote autonomy and intelligence are some of the urgent challenges of this field that we discuss in this paper. Specifically, we will present field-ready soft robots that address targeted productive applications in urban farming, healthcare, land and ocean preservation, disaster remediation, and clean and affordable energy, thus supporting some of the SDGs. By embracing soft robotics as a solution, we can concretely support economic growth and sustainable industry, drive solutions for environment protection and clean energy, and improve overall health and well-being.",2023,"[{'authorId': '51132455', 'name': 'Goffredo Giordano'}, {'authorId': '1685498671', 'name': 'Saravana Prashanth Murali Babu'}, {'authorId': '3345187', 'name': 'B. Mazzolai'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/frobt.2023.1116005/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2303.11931, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","soft robotics technology can aid in achieving united nations’ sustainable development goals (sdgs) and the paris climate agreement through development of autonomous, environmentally responsible machines powered by renewable energy. by utilizing soft robotics, we can mitigate the detrimental effects of climate change on human society and the natural world through fostering adaptation, restoration, and remediation. moreover, the implementation of soft robotics can lead to groundbreaking discoveries in material science, biology, control systems, energy efficiency, and sustainable manufacturing processes. however, to achieve these goals, we need further improvements in understanding biological principles at the basis of embodied and physical intelligence, environment-friendly materials, and energy-saving strategies to design and manufacture self-piloting and field-ready soft robots. this paper provides insights on how soft robotics can address the pressing issue of environmental sustainability. sustainable manufacturing of soft robots at a large scale, exploring the potential of biodegradable and bioinspired materials, and integrating onboard renewable energy sources to promote autonomy and intelligence are some of the urgent challenges of this field that we discuss in this paper. specifically, we will present field-ready soft robots that address targeted productive applications in urban farming, healthcare, land and ocean preservation, disaster remediation, and clean and affordable energy, thus supporting some of the sdgs. by embracing soft robotics as a solution, we can concretely support economic growth and sustainable industry, drive solutions for environment protection and clean energy, and improve overall health and well-being.",https://www.frontiersin.org/articles/10.3389/frobt.2023.1116005/pdf
5e49bb0d08d337bb10dc97d71a9b77237169bb37,Soft Actuators and Robots Enabled by Additive Manufacturing,"Soft robotic systems are human friendly and can mimic the complex motions of animals, which introduces promising potential in various applications, ranging from novel actuation and wearable electronics to bioinspired robots operating in unstructured environments. Due to the use of soft materials, the traditional fabrication and manufacturing methods for rigid materials are unavailable for soft robots. 3D printing is a promising fabrication method for the multifunctional and multimaterial demands of soft robots, as it enables the personalization and customization of the materials and structures. This review provides perspectives on the manufacturing methods for various types of soft robotic systems and discusses the challenges and prospects of future research, including in-depth discussion of pneumatic, electrically activated, magnetically driven, and 4D-printed soft actuators and integrated soft actuators and sensors. Finally, the challenges of realizing multimaterial, multiscale, and multifunctional 3D-printed soft robots are discussed. Expected final online publication date for the Annual Review of Control, Robotics, and Autonomous Systems, Volume 14 is May 2023. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.",2023,"[{'authorId': '2152687127', 'name': 'Dong Wang'}, {'authorId': '2044911178', 'name': 'Jinqiang Wang'}, {'authorId': '1708211535', 'name': 'Zequn Shen'}, {'authorId': '1409879877', 'name': 'Chengru Jiang'}, {'authorId': '50136825', 'name': 'J. Zou'}, {'authorId': '2153567785', 'name': 'Le Dong'}, {'authorId': '145841797', 'name': 'N. Fang'}, {'authorId': '2064491034', 'name': 'G. Gu'}]","{'url': 'https://www.annualreviews.org/doi/pdf/10.1146/annurev-control-061022-012035', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1146/annurev-control-061022-012035?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1146/annurev-control-061022-012035, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","soft robotic systems are human friendly and can mimic the complex motions of animals, which introduces promising potential in various applications, ranging from novel actuation and wearable electronics to bioinspired robots operating in unstructured environments. due to the use of soft materials, the traditional fabrication and manufacturing methods for rigid materials are unavailable for soft robots. 3d printing is a promising fabrication method for the multifunctional and multimaterial demands of soft robots, as it enables the personalization and customization of the materials and structures. this review provides perspectives on the manufacturing methods for various types of soft robotic systems and discusses the challenges and prospects of future research, including in-depth discussion of pneumatic, electrically activated, magnetically driven, and 4d-printed soft actuators and integrated soft actuators and sensors. finally, the challenges of realizing multimaterial, multiscale, and multifunctional 3d-printed soft robots are discussed. expected final online publication date for the annual review of control, robotics, and autonomous systems, volume 14 is may 2023. please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.",https://www.annualreviews.org/doi/pdf/10.1146/annurev-control-061022-012035
4e893c22c45e57b3c650d76f470bec71b09cdc98,Baxter's Homunculus: Virtual Reality Spaces for Teleoperation in Manufacturing,"We demonstrate a low-cost telerobotic system that leverages commercial virtual reality (VR) technology and integrates it with existing robotics control infrastructure. The system runs on a commercial gaming engine using off-the-shelf VR hardware and can be deployed on multiple network architectures. The system is based on the homunculus model of mind wherein we embed the user in a VR control room. The control room allows for multiple sensor displays, and dynamic mapping between the user and robot. This dynamic mapping allows for selective engagement between the user and the robot. We compared our system with state-of-the-art automation algorithms and standard VR-based telepresence systems by performing a user study. The study showed that new users were faster and more accurate than the automation or a direct telepresence system. We also demonstrate that our system can be used for pick and place, assembly, and manufacturing tasks.",2017,"[{'authorId': '9935836', 'name': 'J. Lipton'}, {'authorId': '9943899', 'name': 'Aidan J. Fay'}, {'authorId': '145944286', 'name': 'D. Rus'}]","{'url': 'http://arxiv.org/pdf/1703.01270', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1703.01270, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","we demonstrate a low-cost telerobotic system that leverages commercial virtual reality (vr) technology and integrates it with existing robotics control infrastructure. the system runs on a commercial gaming engine using off-the-shelf vr hardware and can be deployed on multiple network architectures. the system is based on the homunculus model of mind wherein we embed the user in a vr control room. the control room allows for multiple sensor displays, and dynamic mapping between the user and robot. this dynamic mapping allows for selective engagement between the user and the robot. we compared our system with state-of-the-art automation algorithms and standard vr-based telepresence systems by performing a user study. the study showed that new users were faster and more accurate than the automation or a direct telepresence system. we also demonstrate that our system can be used for pick and place, assembly, and manufacturing tasks.",http://arxiv.org/pdf/1703.01270
218803d6f7796b5fbe0990b558258ded267e4d23,Advanced manufacturing and digital twin technology for nuclear energy*,"Advanced manufacturing techniques and digital twin technology are rapidly transforming the nuclear industry, offering the potential to enhance productivity, safety, and cost-effectiveness. Customized parts are being produced using additive manufacturing, automation, and robotics, while digital twin technology enables the virtual modeling and optimization of complex systems. These advanced technologies can significantly improve operational efficiency, predict system behavior, and optimize maintenance schedules in the nuclear energy sector, leading to heightened safety and reduced downtime. However, the nuclear industry demands the highest levels of safety and security, as well as intricate manufacturing processes and operations. Thus, challenges such as data management and cybersecurity must be addressed to fully realize the potential of advanced manufacturing techniques and digital twin technology in the nuclear industry. This comprehensive review highlights the critical role of digital twin technology with advanced manufacturing toward nuclear energy to improve performance, minimize downtime, and heighten safety, ultimately contributing to the global energy mix by providing dependable and low-carbon electricity.",2024,"[{'authorId': '2284541766', 'name': 'Kunal Mondal'}, {'authorId': '2278950319', 'name': 'Oscar Martinez'}, {'authorId': '2284531148', 'name': 'Prashant Jain'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/fenrg.2024.1339836/pdf?isPublishedV2=False', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3389/fenrg.2024.1339836?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3389/fenrg.2024.1339836, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","advanced manufacturing techniques and digital twin technology are rapidly transforming the nuclear industry, offering the potential to enhance productivity, safety, and cost-effectiveness. customized parts are being produced using additive manufacturing, automation, and robotics, while digital twin technology enables the virtual modeling and optimization of complex systems. these advanced technologies can significantly improve operational efficiency, predict system behavior, and optimize maintenance schedules in the nuclear energy sector, leading to heightened safety and reduced downtime. however, the nuclear industry demands the highest levels of safety and security, as well as intricate manufacturing processes and operations. thus, challenges such as data management and cybersecurity must be addressed to fully realize the potential of advanced manufacturing techniques and digital twin technology in the nuclear industry. this comprehensive review highlights the critical role of digital twin technology with advanced manufacturing toward nuclear energy to improve performance, minimize downtime, and heighten safety, ultimately contributing to the global energy mix by providing dependable and low-carbon electricity.",https://www.frontiersin.org/articles/10.3389/fenrg.2024.1339836/pdf?isPublishedV2=False
ca28f866a3b4c76e72c1b072ad4a156e735e6162,Additive manufacturing by digital light processing: a review,"Additive manufacturing is a layer-by-layer strategy enabling the advanced design and fabrication of complex 3D objects and structures, overcoming geometry limitations and reducing waste production compared to conventional technologies. Among various additive manufacturing technologies, digital light processing (DLP), is an additive manufacturing technology used to print photopolymer parts, using a projected light source to cure an entire layer at once. Initially developed for pure resins, recent advances have demonstrated the potential of DLP in the polymerization of ceramic and metal-loaded suspensions, enabling the fabrication of ceramic and metal components after proper debinding and sintering. Such flexibility increases the potential of DLP for different applications, ranging from dental implants and bone scaffolds to smart biomaterials for soft robotics, smart wearables, and microfluidic devices. The review provides an overview of DLP technology and its recent advances; specifically, the review covers the photopolymer properties, the ceramic and metallic feedstock preparation, and the light-matter interaction mechanism underpinning the printing and post-processing steps. Finally, a description of the current application is provided and complemented with future perspectives.",2022,"[{'authorId': '94263721', 'name': 'R. Chaudhary'}, {'authorId': '39302394', 'name': 'P. Fabbri'}, {'authorId': '144081123', 'name': 'E. Leoni'}, {'authorId': '153321412', 'name': 'F. Mazzanti'}, {'authorId': '36496158', 'name': 'R. Akbari'}, {'authorId': '35264582', 'name': 'C. Antonini'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s40964-022-00336-0.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s40964-022-00336-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s40964-022-00336-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","additive manufacturing is a layer-by-layer strategy enabling the advanced design and fabrication of complex 3d objects and structures, overcoming geometry limitations and reducing waste production compared to conventional technologies. among various additive manufacturing technologies, digital light processing (dlp), is an additive manufacturing technology used to print photopolymer parts, using a projected light source to cure an entire layer at once. initially developed for pure resins, recent advances have demonstrated the potential of dlp in the polymerization of ceramic and metal-loaded suspensions, enabling the fabrication of ceramic and metal components after proper debinding and sintering. such flexibility increases the potential of dlp for different applications, ranging from dental implants and bone scaffolds to smart biomaterials for soft robotics, smart wearables, and microfluidic devices. the review provides an overview of dlp technology and its recent advances; specifically, the review covers the photopolymer properties, the ceramic and metallic feedstock preparation, and the light-matter interaction mechanism underpinning the printing and post-processing steps. finally, a description of the current application is provided and complemented with future perspectives.",https://link.springer.com/content/pdf/10.1007/s40964-022-00336-0.pdf
bb6503e4070a95cd2fa0f366071d491dbc224fab,Automation and Robotics in Industrialized Building System (IBS): The Potential Criteria for Measurement,"The problems of Industrialised Building System (IBS) associated with construction such as decreasing quality and productivity, unskilled labour, occupational safety, and inferior working conditions have hampered on the implementation of IBS in Malaysia but opened the possibility of more revolutionary solutions within the industry. One of the prospective options is the implementation of automation and robotics in IBS. Integrating automation and robotics into the design, manufacturing and construction processes of IBS offers not the only improvement in accuracy, consistency and efficiency, but also opportunity to improve the construction industry regarding productivity, safety, quality and increase the implementation rate of IBS in Malaysia. All the data and information gathered directly from libraries, books, articles and other printed materials searched in the international and national journals, proceeding and bulletin. This paper aims to identify the potential criteria for measurement of automation and robotics in IBS.",2019,"[{'authorId': '101564713', 'name': 'M. Rashid'}, {'authorId': '98761316', 'name': 'Mohd Rofdzi Abdullah'}, {'authorId': '15959536', 'name': 'Dzulkarnaen Ismail'}, {'authorId': '72392070', 'name': 'Mohd Hafiz Saberi'}]","{'url': 'https://hrmars.com/papers_submitted/6201/Automation_and_Robotics_in_Industrialized_Building_System_(IBS)_The_Potential_Criteria_for_Measurement.pdf', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.6007/ijarbss/v9-i7/6201?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.6007/ijarbss/v9-i7/6201, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the problems of industrialised building system (ibs) associated with construction such as decreasing quality and productivity, unskilled labour, occupational safety, and inferior working conditions have hampered on the implementation of ibs in malaysia but opened the possibility of more revolutionary solutions within the industry. one of the prospective options is the implementation of automation and robotics in ibs. integrating automation and robotics into the design, manufacturing and construction processes of ibs offers not the only improvement in accuracy, consistency and efficiency, but also opportunity to improve the construction industry regarding productivity, safety, quality and increase the implementation rate of ibs in malaysia. all the data and information gathered directly from libraries, books, articles and other printed materials searched in the international and national journals, proceeding and bulletin. this paper aims to identify the potential criteria for measurement of automation and robotics in ibs.",https://hrmars.com/papers_submitted/6201/Automation_and_Robotics_in_Industrialized_Building_System_(IBS)_The_Potential_Criteria_for_Measurement.pdf
f1f4cf16a0c37e9ae127c57443099b49e5afca5a,A Review of Recent Manufacturing Technologies for Sustainable Soft Actuators,"Soft actuators have brought significant advancements to robotics, allowing robots to perform a diverse range of tasks across various domains. However, the increased use of soft actuators has resulted in negative environmental impacts, including material consumption, waste generation, and energy consumption. To address these challenges, research is increasingly focused on developing sustainable soft actuators (SSAs) that can provide high performance while minimizing environmental harm. This review article aims to explore the development and manufacturing of SSAs and their potential to reduce material waste and energy consumption promoting sustainability. The article examines various categories of soft actuators, such as multi-responsive ones, shape-locking variants, and biological water-responsive models, as well as their implementation through multi-material printing and, 3D and 4D printing techniques. The article also highlights the potential applications of these SSAs, including manufacturing, human–machine interaction, locomotion, and manipulation. Furthermore, the review explores various methods for reducing energy consumption and material waste in soft actuators, such as using recycled materials and eco-friendly manufacturing processes for a circular economy. Finally, the study provides a comprehensive analysis of SSAs and their potential to steer the evolution of robotics towards a more sustainable future and a circular economy.",2023,"[{'authorId': '1742519638', 'name': 'M. Lalegani Dezaki'}, {'authorId': '117078976', 'name': 'M. Bodaghi'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s40684-023-00533-4.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s40684-023-00533-4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s40684-023-00533-4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","soft actuators have brought significant advancements to robotics, allowing robots to perform a diverse range of tasks across various domains. however, the increased use of soft actuators has resulted in negative environmental impacts, including material consumption, waste generation, and energy consumption. to address these challenges, research is increasingly focused on developing sustainable soft actuators (ssas) that can provide high performance while minimizing environmental harm. this review article aims to explore the development and manufacturing of ssas and their potential to reduce material waste and energy consumption promoting sustainability. the article examines various categories of soft actuators, such as multi-responsive ones, shape-locking variants, and biological water-responsive models, as well as their implementation through multi-material printing and, 3d and 4d printing techniques. the article also highlights the potential applications of these ssas, including manufacturing, human–machine interaction, locomotion, and manipulation. furthermore, the review explores various methods for reducing energy consumption and material waste in soft actuators, such as using recycled materials and eco-friendly manufacturing processes for a circular economy. finally, the study provides a comprehensive analysis of ssas and their potential to steer the evolution of robotics towards a more sustainable future and a circular economy.",https://link.springer.com/content/pdf/10.1007/s40684-023-00533-4.pdf
f4135bc3b724f700f35fde7d185c2b99950c235e,Early career scientists converse on the future of soft robotics,"During the recent decade, we have witnessed an extraordinary flourishing of soft robotics. Rekindled interest in soft robots is partially associated with the advances in manufacturing techniques that enable the fabrication of sophisticated multi-material robotic bodies with dimensions ranging across multiple length scales. In recent manuscripts, a reader might find peculiar-looking soft robots capable of grasping, walking, or swimming. However, the growth in publication numbers does not always reflect the real progress in the field since many manuscripts employ very similar ideas and just tweak soft body geometries. Therefore, we unreservedly agree with the sentiment that future research must move beyond “soft for soft’s sake.” Soft robotics is an undoubtedly fascinating field, but it requires a critical assessment of the limitations and challenges, enabling us to spotlight the areas and directions where soft robots will have the best leverage over their traditional counterparts. In this perspective paper, we discuss the current state of robotic research related to such important aspects as energy autonomy, electronic-free logic, and sustainability. The goal is to critically look at perspectives of soft robotics from two opposite points of view provided by early career researchers and highlight the most promising future direction, that is, in our opinion, the employment of soft robotic technologies for soft bio-inspired artificial organs.",2023,"[{'authorId': '15909499', 'name': 'F. Tauber'}, {'authorId': '14053343', 'name': 'V. Slesarenko'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/frobt.2023.1129827/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9994530, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","during the recent decade, we have witnessed an extraordinary flourishing of soft robotics. rekindled interest in soft robots is partially associated with the advances in manufacturing techniques that enable the fabrication of sophisticated multi-material robotic bodies with dimensions ranging across multiple length scales. in recent manuscripts, a reader might find peculiar-looking soft robots capable of grasping, walking, or swimming. however, the growth in publication numbers does not always reflect the real progress in the field since many manuscripts employ very similar ideas and just tweak soft body geometries. therefore, we unreservedly agree with the sentiment that future research must move beyond “soft for soft’s sake.” soft robotics is an undoubtedly fascinating field, but it requires a critical assessment of the limitations and challenges, enabling us to spotlight the areas and directions where soft robots will have the best leverage over their traditional counterparts. in this perspective paper, we discuss the current state of robotic research related to such important aspects as energy autonomy, electronic-free logic, and sustainability. the goal is to critically look at perspectives of soft robotics from two opposite points of view provided by early career researchers and highlight the most promising future direction, that is, in our opinion, the employment of soft robotic technologies for soft bio-inspired artificial organs.",https://www.frontiersin.org/articles/10.3389/frobt.2023.1129827/pdf
1090e77f5b623ac946dcca372332e4fbf7216a78,Human–robot interaction in industrial collaborative robotics: a literature review of the decade 2008–2017,"ABSTRACT Currently, a large number of industrial robots have been deployed to replace or assist humans to perform various repetitive and dangerous manufacturing tasks. However, based on current technological capabilities, such robotics field is rapidly evolving so that humans are not only sharing the same workspace with robots, but also are using robots as useful assistants. Consequently, due to this new type of emerging robotic systems, industrial collaborative robots or cobots, human and robot co-workers have been able to work side-by-side as collaborators to accomplish tasks in industrial environments. Therefore, new human–robot interaction systems have been developed for such systems to be able to utilize the capabilities of both humans and robots. Accordingly, this article presents a literature review of major recent works on human–robot interactions in industrial collaborative robots, conducted during the last decade (between 2008 and 2017). Additionally, the article proposes a tentative classification of the content of these works into several categories and sub-categories. Finally, this paper addresses some challenges of industrial collaborative robotics and explores future research issues. GRAPHICAL ABSTRACT",2019,"[{'authorId': '3355377', 'name': 'A. Hentout'}, {'authorId': '38043518', 'name': 'Aouache Mustapha'}, {'authorId': '2079089202', 'name': 'Abderraouf Maoudj'}, {'authorId': '2228145', 'name': 'I. Akli'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/01691864.2019.1636714?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/01691864.2019.1636714, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract currently, a large number of industrial robots have been deployed to replace or assist humans to perform various repetitive and dangerous manufacturing tasks. however, based on current technological capabilities, such robotics field is rapidly evolving so that humans are not only sharing the same workspace with robots, but also are using robots as useful assistants. consequently, due to this new type of emerging robotic systems, industrial collaborative robots or cobots, human and robot co-workers have been able to work side-by-side as collaborators to accomplish tasks in industrial environments. therefore, new human–robot interaction systems have been developed for such systems to be able to utilize the capabilities of both humans and robots. accordingly, this article presents a literature review of major recent works on human–robot interactions in industrial collaborative robots, conducted during the last decade (between 2008 and 2017). additionally, the article proposes a tentative classification of the content of these works into several categories and sub-categories. finally, this paper addresses some challenges of industrial collaborative robotics and explores future research issues. graphical abstract",
625c4cdf9336ac3865e71f5c939350ce3c2832a4,Soft Robotics: A Review of Recent Developments of Pneumatic Soft Actuators,"This paper focuses on the recent development of soft pneumatic actuators for soft robotics over the past few years, concentrating on the following four categories: control systems, material and construction, modeling, and sensors. This review work seeks to provide an accelerated entrance to new researchers in the field to encourage research and innovation. Advances in methods to accurately model soft robotic actuators have been researched, optimizing and making numerous soft robotic designs applicable to medical, manufacturing, and electronics applications. Multi-material 3D printed and fiber optic soft pneumatic actuators have been developed, which will allow for more accurate positioning and tactile feedback for soft robotic systems. Also, a variety of research teams have made improvements to soft robot control systems to utilize soft pneumatic actuators to allow for operations to move more effectively. This review work provides an accessible repository of recent information and comparisons between similar works. Future issues facing soft robotic actuators include portable and flexible power supplies, circuit boards, and drive components.",2020,"[{'authorId': '2110484888', 'name': 'James Walker'}, {'authorId': '4983020', 'name': 'T. Zidek'}, {'authorId': '1583111711', 'name': 'Cory Harbel'}, {'authorId': '2268182994', 'name': 'Sanghyun Yoon'}, {'authorId': '2083891046', 'name': 'F. S. Strickland'}, {'authorId': '2109544328', 'name': 'Srinivas Kumar'}, {'authorId': '50975706', 'name': 'Minchul Shin'}]","{'url': 'https://www.mdpi.com/2076-0825/9/1/3/pdf?version=1584169618', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/act9010003?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/act9010003, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper focuses on the recent development of soft pneumatic actuators for soft robotics over the past few years, concentrating on the following four categories: control systems, material and construction, modeling, and sensors. this review work seeks to provide an accelerated entrance to new researchers in the field to encourage research and innovation. advances in methods to accurately model soft robotic actuators have been researched, optimizing and making numerous soft robotic designs applicable to medical, manufacturing, and electronics applications. multi-material 3d printed and fiber optic soft pneumatic actuators have been developed, which will allow for more accurate positioning and tactile feedback for soft robotic systems. also, a variety of research teams have made improvements to soft robot control systems to utilize soft pneumatic actuators to allow for operations to move more effectively. this review work provides an accessible repository of recent information and comparisons between similar works. future issues facing soft robotic actuators include portable and flexible power supplies, circuit boards, and drive components.",https://www.mdpi.com/2076-0825/9/1/3/pdf?version=1584169618
6b93122f3050782f063b00c6fb001766227cc917,Processing of Self‐Healing Polymers for Soft Robotics,"Soft robots are, due to their softness, inherently safe and adapt well to unstructured environments. However, they are prone to various damage types. Self‐healing polymers address this vulnerability. Self‐healing soft robots can recover completely from macroscopic damage, extending their lifetime. For developing healable soft robots, various formative and additive manufacturing methods have been exploited to shape self‐healing polymers into complex structures. Additionally, several novel manufacturing techniques, noted as (re)assembly binding techniques that are specific to self‐healing polymers, have been created. Herein, the wide variety of processing techniques of self‐healing polymers for robotics available in the literature is reviewed, and limitations and opportunities discussed thoroughly. Based on defined requirements for soft robots, these techniques are critically compared and validated. A strong focus is drawn to the reversible covalent and (physico)chemical cross‐links present in the self‐healing polymers that do not only endow healability to the resulting soft robotic components, but are also beneficial in many manufacturing techniques. They solve current obstacles in soft robots, including the formation of robust multi‐material parts, recyclability, and stress relaxation. This review bridges two promising research fields, and guides the reader toward selecting a suitable processing method based on a self‐healing polymer and the intended soft robotics application.",2021,"[{'authorId': '1562764813', 'name': 'Ellen Roels'}, {'authorId': '2097914', 'name': 'Seppe Terryn'}, {'authorId': '34567297', 'name': 'F. Iida'}, {'authorId': '38135936', 'name': 'A. Bosman'}, {'authorId': '15369812', 'name': 'S. Norvez'}, {'authorId': '123462124', 'name': 'F. Clemens'}, {'authorId': '6185170', 'name': 'G. van Assche'}, {'authorId': '1687831', 'name': 'B. Vanderborght'}, {'authorId': '2899443', 'name': 'J. Brancart'}]","{'url': 'https://biblio.vub.ac.be/vubirfiles/96218649/revised_manuscript.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/adma.202104798?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/adma.202104798, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","soft robots are, due to their softness, inherently safe and adapt well to unstructured environments. however, they are prone to various damage types. self‐healing polymers address this vulnerability. self‐healing soft robots can recover completely from macroscopic damage, extending their lifetime. for developing healable soft robots, various formative and additive manufacturing methods have been exploited to shape self‐healing polymers into complex structures. additionally, several novel manufacturing techniques, noted as (re)assembly binding techniques that are specific to self‐healing polymers, have been created. herein, the wide variety of processing techniques of self‐healing polymers for robotics available in the literature is reviewed, and limitations and opportunities discussed thoroughly. based on defined requirements for soft robots, these techniques are critically compared and validated. a strong focus is drawn to the reversible covalent and (physico)chemical cross‐links present in the self‐healing polymers that do not only endow healability to the resulting soft robotic components, but are also beneficial in many manufacturing techniques. they solve current obstacles in soft robots, including the formation of robust multi‐material parts, recyclability, and stress relaxation. this review bridges two promising research fields, and guides the reader toward selecting a suitable processing method based on a self‐healing polymer and the intended soft robotics application.",https://biblio.vub.ac.be/vubirfiles/96218649/revised_manuscript.pdf
3587941e0a98260679bab5dc2379db179537d437,Robot-Oriented Design: Design and Management Tools for the Deployment of Automation and Robotics in Construction,"1. Advanced construction and building technology 2. The structure of this volume 3. The role of complementarity of products, organization, information, and machine technology 4. Introduction of relevant terms, concepts, and technologies 5. Complex products in other industries and relevance of fixed-site/ONM technology 6. Synchronization of organization, building structure, and manufacturing technology by robot-oriented design 7. Utilizing innovation science to develop and deploy automated/robotic systems in construction 8. Competitive advantage by coadapting and taking products and manufacturing systems further.",2015,"[{'authorId': '144032311', 'name': 'T. Bock'}, {'authorId': '2939000', 'name': 'T. Linner'}]","{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/9B4F3257C3DEA1555C67CE28647137A7/9781139924146c1_p1-17_CBO.pdf/advanced_construction_and_building_technology.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1017/cbo9781139924146?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1017/cbo9781139924146, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","1. advanced construction and building technology 2. the structure of this volume 3. the role of complementarity of products, organization, information, and machine technology 4. introduction of relevant terms, concepts, and technologies 5. complex products in other industries and relevance of fixed-site/onm technology 6. synchronization of organization, building structure, and manufacturing technology by robot-oriented design 7. utilizing innovation science to develop and deploy automated/robotic systems in construction 8. competitive advantage by coadapting and taking products and manufacturing systems further.",https://www.cambridge.org/core/services/aop-cambridge-core/content/view/9B4F3257C3DEA1555C67CE28647137A7/9781139924146c1_p1-17_CBO.pdf/advanced_construction_and_building_technology.pdf
55da1a01f353cbf7b0d0a91bf505cec20ca8bc34,A Methodology for Flexible Implementation of Collaborative Robots in Smart Manufacturing Systems,"Small-scale production is relying more and more on personalization and flexibility as an innovation key for success in response to market needs such as diversification of consumer preferences and/or greater regulatory pressure. This can be possible thanks to assembly lines dynamically adaptable to new production requirements, easily reconfigurable and reprogrammable to any change in the production line. In such new automated production lines, where traditional automation is not applicable, human and robot collaboration can be established, giving birth to a kind of industrial craftsmanship. The idea at the base of this work is to take advantage of collaborative robotics by using the robots as other generic industrial tools. To overcome the need of complex programming, identified in the literature as one of the main issues preventing cobot diffusion into industrial environments, the paper proposes an approach for simplifying the programming process while still maintaining high flexibility through a pyramidal parametrized approach exploiting cobot collaborative features. An Interactive Refinement Programming procedure is described and validated through a real test case performed as a pilot in the Building Automation department of ABB in Vittuone (Milan, Italy). The key novel ingredients in this approach are a first translation phase, carried out by engineers of production processes who convert the sequence of assembly operations into a preliminary code built as a sequence of robot operations, followed by an on-line correction carried out by non-expert users who can interact with the machine to define the input parameters to make the robotic code runnable. The users in this second step do not need any competence in programming robotic code. Moreover, from an economic point of view, a standardized way of assessing the convenience of the robotic investment is proposed. Both economic and technical results highlight improvements in comparison to the traditional automation approach, demonstrating the possibility to open new further opportunities for collaborative robots when small/medium batch sizes are involved.",2022,"[{'authorId': '3127418', 'name': 'H. Giberti'}, {'authorId': '2149603458', 'name': 'Tommaso Abbattista'}, {'authorId': '40799057', 'name': 'M. Carnevale'}, {'authorId': '2149601282', 'name': 'Luca Giagu'}, {'authorId': '2149603490', 'name': 'Fabio Cristini'}]","{'url': 'https://www.mdpi.com/2218-6581/11/1/9/pdf?version=1641288078', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/robotics11010009?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/robotics11010009, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","small-scale production is relying more and more on personalization and flexibility as an innovation key for success in response to market needs such as diversification of consumer preferences and/or greater regulatory pressure. this can be possible thanks to assembly lines dynamically adaptable to new production requirements, easily reconfigurable and reprogrammable to any change in the production line. in such new automated production lines, where traditional automation is not applicable, human and robot collaboration can be established, giving birth to a kind of industrial craftsmanship. the idea at the base of this work is to take advantage of collaborative robotics by using the robots as other generic industrial tools. to overcome the need of complex programming, identified in the literature as one of the main issues preventing cobot diffusion into industrial environments, the paper proposes an approach for simplifying the programming process while still maintaining high flexibility through a pyramidal parametrized approach exploiting cobot collaborative features. an interactive refinement programming procedure is described and validated through a real test case performed as a pilot in the building automation department of abb in vittuone (milan, italy). the key novel ingredients in this approach are a first translation phase, carried out by engineers of production processes who convert the sequence of assembly operations into a preliminary code built as a sequence of robot operations, followed by an on-line correction carried out by non-expert users who can interact with the machine to define the input parameters to make the robotic code runnable. the users in this second step do not need any competence in programming robotic code. moreover, from an economic point of view, a standardized way of assessing the convenience of the robotic investment is proposed. both economic and technical results highlight improvements in comparison to the traditional automation approach, demonstrating the possibility to open new further opportunities for collaborative robots when small/medium batch sizes are involved.",https://www.mdpi.com/2218-6581/11/1/9/pdf?version=1641288078
2db2548558837db00ff9002a464f596f89ee0bf3,Transparent Soft Actuators/Sensors and Camouflage Skins for Imperceptible Soft Robotics,"The advent of soft robotics has led to great advancements in robots, wearables, and even manufacturing processes by employing entirely soft‐bodied systems that interact safely with any random surfaces while providing great mechanical compliance. Moreover, recent developments in soft robotics involve advances in transparent soft actuators and sensors that have made it possible to construct robots that can function in a visually and mechanically unobstructed manner, assisting the operations of robots and creating more applications in various fields. In this aspect, imperceptible soft robotics that mainly consist of optically transparent imperceptible hardware components is expected to constitute a new research focus in the forthcoming era of soft robotics. Here, the recent progress regarding extended imperceptible soft robotics is provided, including imperceptible transparent soft robotics (transparent soft actuators/sensors) and imperceptible nontransparent camouflage skins. Their principles, materials selections, and working mechanisms are discussed so that key challenges and perspectives in imperceptible soft robotic systems can be explored.",2020,"[{'authorId': '5858726', 'name': 'P. Won'}, {'authorId': '2110628143', 'name': 'K. Kim'}, {'authorId': '120799353', 'name': 'Hyeonseok Kim'}, {'authorId': '15437719', 'name': 'J. Park'}, {'authorId': '8861592', 'name': 'Inho Ha'}, {'authorId': '40387975', 'name': 'Jaeho Shin'}, {'authorId': '50590135', 'name': 'Jinwook Jung'}, {'authorId': '50785936', 'name': 'Hyunmin Cho'}, {'authorId': '4883772', 'name': 'Jinhyeong Kwon'}, {'authorId': '5293469', 'name': 'Habeom Lee'}, {'authorId': '1943879', 'name': 'S. Ko'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/adma.202002397?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/adma.202002397, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the advent of soft robotics has led to great advancements in robots, wearables, and even manufacturing processes by employing entirely soft‐bodied systems that interact safely with any random surfaces while providing great mechanical compliance. moreover, recent developments in soft robotics involve advances in transparent soft actuators and sensors that have made it possible to construct robots that can function in a visually and mechanically unobstructed manner, assisting the operations of robots and creating more applications in various fields. in this aspect, imperceptible soft robotics that mainly consist of optically transparent imperceptible hardware components is expected to constitute a new research focus in the forthcoming era of soft robotics. here, the recent progress regarding extended imperceptible soft robotics is provided, including imperceptible transparent soft robotics (transparent soft actuators/sensors) and imperceptible nontransparent camouflage skins. their principles, materials selections, and working mechanisms are discussed so that key challenges and perspectives in imperceptible soft robotic systems can be explored.",
13f3f6f1cb4e08570c28ada8b2a7e8c0f2734342,A review of 3D printing processes and materials for soft robotics,"PurposeSoft robotics is currently a rapidly growing new field of robotics whereby the robots are fundamentally soft and elastically deformable. Fabrication of soft robots is currently challenging and highly time- and labor-intensive. Recent advancements in three-dimensional (3D) printing of soft materials and multi-materials have become the key to enable direct manufacturing of soft robots with sophisticated designs and functions. Hence, this paper aims to review the current 3D printing processes and materials for soft robotics applications, as well as the potentials of 3D printing technologies on 3D printed soft robotics.Design/methodology/approachThe paper reviews the polymer 3D printing techniques and materials that have been used for the development of soft robotics. Current challenges to adopting 3D printing for soft robotics are also discussed. Next, the potentials of 3D printing technologies and the future outlooks of 3D printed soft robotics are presented.FindingsThis paper reviews five different 3D printing techniques and commonly used materials. The advantages and disadvantages of each technique for the soft robotic application are evaluated. The typical designs and geometries used by each technique are also summarized. There is an increasing trend of printing shape memory polymers, as well as multiple materials simultaneously using direct ink writing and material jetting techniques to produce robotics with varying stiffness values that range from intrinsically soft and highly compliant to rigid polymers. Although the recent work is done is still limited to experimentation and prototyping of 3D printed soft robotics, additive manufacturing could ultimately be used for the end-use and production of soft robotics.Originality/valueThe paper provides the current trend of how 3D printing techniques and materials are used particularly in the soft robotics application. The potentials of 3D printing technology on the soft robotic applications and the future outlooks of 3D printed soft robotics are also presented.",2020,"[{'authorId': '32792899', 'name': 'Y. L. Yap'}, {'authorId': '15234894', 'name': 'S. Sing'}, {'authorId': '7188406', 'name': 'W. Yeong'}]","{'url': 'https://dr.ntu.edu.sg/bitstream/10356/143753/2/Yap%20Yee%20Ling_RPJ_Soft%20Robotics.PDF', 'status': 'GREEN', 'license': 'mit', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1108/rpj-11-2019-0302?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1108/rpj-11-2019-0302, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","purposesoft robotics is currently a rapidly growing new field of robotics whereby the robots are fundamentally soft and elastically deformable. fabrication of soft robots is currently challenging and highly time- and labor-intensive. recent advancements in three-dimensional (3d) printing of soft materials and multi-materials have become the key to enable direct manufacturing of soft robots with sophisticated designs and functions. hence, this paper aims to review the current 3d printing processes and materials for soft robotics applications, as well as the potentials of 3d printing technologies on 3d printed soft robotics.design/methodology/approachthe paper reviews the polymer 3d printing techniques and materials that have been used for the development of soft robotics. current challenges to adopting 3d printing for soft robotics are also discussed. next, the potentials of 3d printing technologies and the future outlooks of 3d printed soft robotics are presented.findingsthis paper reviews five different 3d printing techniques and commonly used materials. the advantages and disadvantages of each technique for the soft robotic application are evaluated. the typical designs and geometries used by each technique are also summarized. there is an increasing trend of printing shape memory polymers, as well as multiple materials simultaneously using direct ink writing and material jetting techniques to produce robotics with varying stiffness values that range from intrinsically soft and highly compliant to rigid polymers. although the recent work is done is still limited to experimentation and prototyping of 3d printed soft robotics, additive manufacturing could ultimately be used for the end-use and production of soft robotics.originality/valuethe paper provides the current trend of how 3d printing techniques and materials are used particularly in the soft robotics application. the potentials of 3d printing technology on the soft robotic applications and the future outlooks of 3d printed soft robotics are also presented.",https://dr.ntu.edu.sg/bitstream/10356/143753/2/Yap%20Yee%20Ling_RPJ_Soft%20Robotics.PDF
c4160e1dd9dd6aafbec4893bfac985d21c57e4c4,3D-printed programmable tensegrity for soft robotics,"Additive manufacturing enables the integration of smart materials into tensegrity metamaterials for functional soft systems. Tensegrity structures provide both structural integrity and flexibility through the combination of stiff struts and a network of flexible tendons. These structures exhibit useful properties: high stiffness-to-mass ratio, controllability, reliability, structural flexibility, and large deployment. The integration of smart materials into tensegrity structures would provide additional functionality and may improve existing properties. However, manufacturing approaches that generate multimaterial parts with intricate three-dimensional (3D) shapes suitable for such tensegrities are rare. Furthermore, the structural complexity of tensegrity systems fabricated through conventional means is generally limited because these systems often require manual assembly. Here, we report a simple approach to fabricate tensegrity structures made of smart materials using 3D printing combined with sacrificial molding. Tensegrity structures consisting of monolithic tendon networks based on smart materials supported by struts could be realized without an additional post-assembly process using our approach. By printing tensegrity with coordinated soft and stiff elements, we could use design parameters (such as geometry, topology, density, coordination number, and complexity) to program system-level mechanics in a soft structure. Last, we demonstrated a tensegrity robot capable of walking in any direction and several tensegrity actuators by leveraging smart tendons with magnetic functionality and the programmed mechanics of tensegrity structures. The physical realization of complex tensegrity metamaterials with programmable mechanical components can pave the way toward more algorithmic designs of 3D soft machines.",2020,"[{'authorId': '2117939113', 'name': 'Hajun Lee'}, {'authorId': '2072584079', 'name': 'Yeonwoo Jang'}, {'authorId': '1740583659', 'name': 'Jun Kyu Choe'}, {'authorId': '30979260', 'name': 'Suwoo Lee'}, {'authorId': '2112926938', 'name': 'Hyeonseok Song'}, {'authorId': '13348100', 'name': 'Jin Pyo Lee'}, {'authorId': '2321811954', 'name': 'Nasreena Lone'}, {'authorId': '47963890', 'name': 'Jiyun Kim'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1126/scirobotics.aay9024?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1126/scirobotics.aay9024, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","additive manufacturing enables the integration of smart materials into tensegrity metamaterials for functional soft systems. tensegrity structures provide both structural integrity and flexibility through the combination of stiff struts and a network of flexible tendons. these structures exhibit useful properties: high stiffness-to-mass ratio, controllability, reliability, structural flexibility, and large deployment. the integration of smart materials into tensegrity structures would provide additional functionality and may improve existing properties. however, manufacturing approaches that generate multimaterial parts with intricate three-dimensional (3d) shapes suitable for such tensegrities are rare. furthermore, the structural complexity of tensegrity systems fabricated through conventional means is generally limited because these systems often require manual assembly. here, we report a simple approach to fabricate tensegrity structures made of smart materials using 3d printing combined with sacrificial molding. tensegrity structures consisting of monolithic tendon networks based on smart materials supported by struts could be realized without an additional post-assembly process using our approach. by printing tensegrity with coordinated soft and stiff elements, we could use design parameters (such as geometry, topology, density, coordination number, and complexity) to program system-level mechanics in a soft structure. last, we demonstrated a tensegrity robot capable of walking in any direction and several tensegrity actuators by leveraging smart tendons with magnetic functionality and the programmed mechanics of tensegrity structures. the physical realization of complex tensegrity metamaterials with programmable mechanical components can pave the way toward more algorithmic designs of 3d soft machines.",
4f2baf4301e719a38ec1dbb86b9766ef25650c4c,Agricultural Robotics: The Future of Robotic Agriculture,"Agri-Food is the largest manufacturing sector in the UK. It supports a food chain that generates over £108bn p.a., with 3.9m employees in a truly international industry and exports £20bn of UK manufactured goods. However, the global food chain is under pressure from population growth, climate change, political pressures affecting migration, population drift from rural to urban regions and the demographics of an aging global population. These challenges are recognised in the UK Industrial Strategy white paper and backed by significant investment via a Wave 2 Industrial Challenge Fund Investment (""Transforming Food Production: from Farm to Fork""). Robotics and Autonomous Systems (RAS) and associated digital technologies are now seen as enablers of this critical food chain transformation. To meet these challenges, this white paper reviews the state of the art in the application of RAS in Agri-Food production and explores research and innovation needs to ensure these technologies reach their full potential and deliver the necessary impacts in the Agri-Food sector.",2018,"[{'authorId': '1793716', 'name': 'T. Duckett'}, {'authorId': '145802955', 'name': 'S. Pearson'}, {'authorId': '89252337', 'name': 'S. Blackmore'}, {'authorId': '144939787', 'name': 'B. Grieve'}]","{'url': 'https://arxiv.org/pdf/1806.06762', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/1806.06762, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","agri-food is the largest manufacturing sector in the uk. it supports a food chain that generates over £108bn p.a., with 3.9m employees in a truly international industry and exports £20bn of uk manufactured goods. however, the global food chain is under pressure from population growth, climate change, political pressures affecting migration, population drift from rural to urban regions and the demographics of an aging global population. these challenges are recognised in the uk industrial strategy white paper and backed by significant investment via a wave 2 industrial challenge fund investment (""transforming food production: from farm to fork""). robotics and autonomous systems (ras) and associated digital technologies are now seen as enablers of this critical food chain transformation. to meet these challenges, this white paper reviews the state of the art in the application of ras in agri-food production and explores research and innovation needs to ensure these technologies reach their full potential and deliver the necessary impacts in the agri-food sector.",https://arxiv.org/pdf/1806.06762
7d830c83ad73256accc58d110b61755825e7ad8e,Trends in Smart Manufacturing: Role of Humans and Industrial Robots in Smart Factories,"This paper provides an overview of the role of humans and robots in smart factories, their connection to Industry 4.0, and which progress they make when it comes to related technologies. The current study shows that a decade was not enough to provide a reference implementation or application of Industry 4.0, like smart factories. In 2011, Industry 4.0 was mentioned for the first time in the scientific community. Industry 4.0 arrived with many new enabling technologies and buzzwords, e.g., Internet of Things (IoT), Cyber-Physical Systems (CPS), and Digital Twins (DT). This paper first defines smart factories and smart manufacturing in relation to the role of humans and robots. Followed by an overview of selected technologies in smart factories. Concluded by future prospects and its’ relation to smart manufacturing.",2020,"[{'authorId': '32670165', 'name': 'L. Evjemo'}, {'authorId': '3380184', 'name': 'T. Gjerstad'}, {'authorId': '30580449', 'name': 'E. Grøtli'}, {'authorId': '2323614', 'name': 'G. Sziebig'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s43154-020-00006-5.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s43154-020-00006-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s43154-020-00006-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper provides an overview of the role of humans and robots in smart factories, their connection to industry 4.0, and which progress they make when it comes to related technologies. the current study shows that a decade was not enough to provide a reference implementation or application of industry 4.0, like smart factories. in 2011, industry 4.0 was mentioned for the first time in the scientific community. industry 4.0 arrived with many new enabling technologies and buzzwords, e.g., internet of things (iot), cyber-physical systems (cps), and digital twins (dt). this paper first defines smart factories and smart manufacturing in relation to the role of humans and robots. followed by an overview of selected technologies in smart factories. concluded by future prospects and its’ relation to smart manufacturing.",https://link.springer.com/content/pdf/10.1007/s43154-020-00006-5.pdf
2658b5651cf69702b5b71763be7abb1be071796a,"Performance measures to benchmark the grasping, manipulation, and assembly of deformable objects typical to manufacturing applications","The National Institute of Standards and Technology is developing performance tests and associated artifacts to benchmark research in the area of robotic assembly. Sets of components consistent with mechanical assemblies including screws, gears, electrical connectors, wires, and belts are configured for assembly or disassembly using a task board concept. Test protocols accompany the task boards and are designed to mimic low-volume, high-mixture assembly challenges typical to small and medium sized manufacturers. In addition to the typical rigid components found in assembled products, the task boards include many non-rigid component operations representative of wire harness and belt drive assemblies to support research in the area of grasping and manipulation of deformable objects, an area still considered to be an emerging research problem in robotics. A set of four primary task boards as well as competition task boards are presented as benchmarks along with scoring metrics and a method to compare robot system assembly times with human performance. Competitions are used to raise awareness to these benchmarks. Tools to progress and compare research are described along with emphasis placed on system competition-based solutions to grasp and manipulate deformable task board components.",2022,"[{'authorId': '51933492', 'name': 'K. Kimble'}, {'authorId': '2189238534', 'name': 'Justin Albrecht'}, {'authorId': '144535142', 'name': 'M. Zimmerman'}, {'authorId': '40159870', 'name': 'J. Falco'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/frobt.2022.999348/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9720326, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the national institute of standards and technology is developing performance tests and associated artifacts to benchmark research in the area of robotic assembly. sets of components consistent with mechanical assemblies including screws, gears, electrical connectors, wires, and belts are configured for assembly or disassembly using a task board concept. test protocols accompany the task boards and are designed to mimic low-volume, high-mixture assembly challenges typical to small and medium sized manufacturers. in addition to the typical rigid components found in assembled products, the task boards include many non-rigid component operations representative of wire harness and belt drive assemblies to support research in the area of grasping and manipulation of deformable objects, an area still considered to be an emerging research problem in robotics. a set of four primary task boards as well as competition task boards are presented as benchmarks along with scoring metrics and a method to compare robot system assembly times with human performance. competitions are used to raise awareness to these benchmarks. tools to progress and compare research are described along with emphasis placed on system competition-based solutions to grasp and manipulate deformable task board components.",https://www.frontiersin.org/articles/10.3389/frobt.2022.999348/pdf
6ec55440b8068074ea55d1c15725eae17f5b6f10,Two-Way and Multiple-Way Shape Memory Polymers for Soft Robotics: An Overview,"Shape memory polymers (SMPs) are smart materials capable of changing their shapes in a predefined manner under a proper applied stimulus and have gained considerable interest in several application fields. Particularly, two-way and multiple-way SMPs offer unique opportunities to realize untethered soft robots with programmable morphology and/or properties, repeatable actuation, and advanced multi-functionalities. This review presents the recent progress of soft robots based on two-way and multiple-way thermo-responsive SMPs. All the building blocks important for the design of such robots, i.e., the base materials, manufacturing processes, working mechanisms, and modeling and simulation tools, are covered. Moreover, examples of real-world applications of soft robots and related actuators, challenges, and future directions are discussed.",2020,"[{'authorId': '5397092', 'name': 'G. Scalet'}]","{'url': 'https://www.mdpi.com/2076-0825/9/1/10/pdf?version=1581760404', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/act9010010?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/act9010010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","shape memory polymers (smps) are smart materials capable of changing their shapes in a predefined manner under a proper applied stimulus and have gained considerable interest in several application fields. particularly, two-way and multiple-way smps offer unique opportunities to realize untethered soft robots with programmable morphology and/or properties, repeatable actuation, and advanced multi-functionalities. this review presents the recent progress of soft robots based on two-way and multiple-way thermo-responsive smps. all the building blocks important for the design of such robots, i.e., the base materials, manufacturing processes, working mechanisms, and modeling and simulation tools, are covered. moreover, examples of real-world applications of soft robots and related actuators, challenges, and future directions are discussed.",https://www.mdpi.com/2076-0825/9/1/10/pdf?version=1581760404
1beef71f5a9b5f0b62f6f145e7d713a6bc120de1,Soft‐Matter Engineering for Soft Robotics,"Since its inception, the field of robotics has aimed to create machines that mimic the extraordinary capabilities of the human body. From as early as the 1940s, this has included efforts to engineer actuators and electronics out of elastomers, textiles, and other soft materials in order to mimic the compliance and deformability of natural biological tissue. In the decades since, there is extraordinary progress in the subdomain of soft robotics, with recent efforts focused on novel methods of actuation, sensing, and manufacturing. In this progress report, recent advancements within this field from the perspective of materials and mechanics are highlighted. Wherever possible, efforts in soft robotics are connected to progress in the broader field of soft‐matter engineering, which relates to the application of principles and practices in the soft‐matter sciences to create machines, electronics, and robotic systems out of fluids, elastomers, gels, and other soft materials. To close, the current challenges and future opportunities within the field of robotics are briefly discussed, with special attention toward the eventual goal of autonomous soft robots that are capable of operating without dependency on external hardware, tethers, or manual intervention.",2018,"[{'authorId': '2292027', 'name': 'C. Majidi'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/admt.201800477?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/admt.201800477, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","since its inception, the field of robotics has aimed to create machines that mimic the extraordinary capabilities of the human body. from as early as the 1940s, this has included efforts to engineer actuators and electronics out of elastomers, textiles, and other soft materials in order to mimic the compliance and deformability of natural biological tissue. in the decades since, there is extraordinary progress in the subdomain of soft robotics, with recent efforts focused on novel methods of actuation, sensing, and manufacturing. in this progress report, recent advancements within this field from the perspective of materials and mechanics are highlighted. wherever possible, efforts in soft robotics are connected to progress in the broader field of soft‐matter engineering, which relates to the application of principles and practices in the soft‐matter sciences to create machines, electronics, and robotic systems out of fluids, elastomers, gels, and other soft materials. to close, the current challenges and future opportunities within the field of robotics are briefly discussed, with special attention toward the eventual goal of autonomous soft robots that are capable of operating without dependency on external hardware, tethers, or manual intervention.",
a1709d83adf0ccfa5e3a6182bd2eddabac4a4a08,A Modular Digital Twinning Framework for Safety Assurance of Collaborative Robotics,"Digital twins offer a unique opportunity to design, test, deploy, monitor, and control real-world robotic processes. In this paper we present a novel, modular digital twinning framework developed for the investigation of safety within collaborative robotic manufacturing processes. The modular architecture supports scalable representations of user-defined cyber-physical environments, and tools for safety analysis and control. This versatile research tool facilitates the creation of mixed environments of Digital Models, Digital Shadows, and Digital Twins, whilst standardising communication and physical system representation across different hardware platforms. The framework is demonstrated as applied to an industrial case-study focused on the safety assurance of a collaborative robotic manufacturing process. We describe the creation of a digital twin scenario, consisting of individual digital twins of entities in the manufacturing case study, and the application of a synthesised safety controller from our wider work. We show how the framework is able to provide adequate evidence to virtually assess safety claims made against the safety controller using a supporting validation module and testing strategy. The implementation, evidence and safety investigation is presented and discussed, raising exciting possibilities for the use of digital twins in robotic safety assurance.",2021,"[{'authorId': '40074781', 'name': 'James A. Douthwaite'}, {'authorId': '1852538', 'name': 'Benjamin Lesage'}, {'authorId': '1859476', 'name': 'Mario Gleirscher'}, {'authorId': '143665272', 'name': 'R. Calinescu'}, {'authorId': '40035385', 'name': 'Jonathan M. Aitken'}, {'authorId': '2802461', 'name': 'R. Alexander'}, {'authorId': '2057766865', 'name': 'James Law'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/frobt.2021.758099/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8719333, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","digital twins offer a unique opportunity to design, test, deploy, monitor, and control real-world robotic processes. in this paper we present a novel, modular digital twinning framework developed for the investigation of safety within collaborative robotic manufacturing processes. the modular architecture supports scalable representations of user-defined cyber-physical environments, and tools for safety analysis and control. this versatile research tool facilitates the creation of mixed environments of digital models, digital shadows, and digital twins, whilst standardising communication and physical system representation across different hardware platforms. the framework is demonstrated as applied to an industrial case-study focused on the safety assurance of a collaborative robotic manufacturing process. we describe the creation of a digital twin scenario, consisting of individual digital twins of entities in the manufacturing case study, and the application of a synthesised safety controller from our wider work. we show how the framework is able to provide adequate evidence to virtually assess safety claims made against the safety controller using a supporting validation module and testing strategy. the implementation, evidence and safety investigation is presented and discussed, raising exciting possibilities for the use of digital twins in robotic safety assurance.",https://www.frontiersin.org/articles/10.3389/frobt.2021.758099/pdf
ffd550fe9f1d9ca15a0a53e0b2ac1d4ede04159a,Digital Twin and Virtual Reality Based Methodology for Multi-Robot Manufacturing Cell Commissioning,"Intelligent automation, including robotics, is one of the current trends in the manufacturing industry in the context of “Industry 4.0”, where cyber-physical systems control the production at automated or semi-automated factories. Robots are perfect substitutes for a skilled workforce for some repeatable, general, and strategically-important tasks. However, this transformation is not always feasible and immediate, since certain technologies do not provide the required degree of flexibility. The introduction of collaborative robots in the industry permits the combination of the advantages of manual and automated production. In some processes, it is necessary to incorporate robots from different manufacturers, thus the design of these multi-robot systems is crucial to guarantee the maximum quality and efficiency. In this context, this paper presents a novel methodology for process automation design, enhanced implementation, and real-time monitoring in operation based on creating a digital twin of the manufacturing process with an immersive virtual reality interface to be used as a virtual testbed before the physical implementation. Moreover, it can be efficiently used for operator training, real-time monitoring, and feasibility studies of future optimizations. It has been validated in a use case which provides a solution for an assembly manufacturing process.",2020,"[{'authorId': '2069060904', 'name': 'Luis Pérez'}, {'authorId': '1401875121', 'name': 'Silvia Rodríguez-Jiménez'}, {'authorId': '144842977', 'name': 'Nuria Rodríguez'}, {'authorId': '8306548', 'name': 'R. Usamentiaga'}, {'authorId': '144176373', 'name': 'D. García'}]","{'url': 'https://www.mdpi.com/2076-3417/10/10/3633/pdf?version=1590545956', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app10103633?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app10103633, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","intelligent automation, including robotics, is one of the current trends in the manufacturing industry in the context of “industry 4.0”, where cyber-physical systems control the production at automated or semi-automated factories. robots are perfect substitutes for a skilled workforce for some repeatable, general, and strategically-important tasks. however, this transformation is not always feasible and immediate, since certain technologies do not provide the required degree of flexibility. the introduction of collaborative robots in the industry permits the combination of the advantages of manual and automated production. in some processes, it is necessary to incorporate robots from different manufacturers, thus the design of these multi-robot systems is crucial to guarantee the maximum quality and efficiency. in this context, this paper presents a novel methodology for process automation design, enhanced implementation, and real-time monitoring in operation based on creating a digital twin of the manufacturing process with an immersive virtual reality interface to be used as a virtual testbed before the physical implementation. moreover, it can be efficiently used for operator training, real-time monitoring, and feasibility studies of future optimizations. it has been validated in a use case which provides a solution for an assembly manufacturing process.",https://www.mdpi.com/2076-3417/10/10/3633/pdf?version=1590545956
35e9c7dbadaa50e70cf21c4b383ac82e50e0bc8b,Fabrication of a Soft Robotic Gripper With Integrated Strain Sensing Elements Using Multi-Material Additive Manufacturing,"With the purpose of making soft robotic structures with embedded sensors, additive manufacturing techniques like fused deposition modeling (FDM) are popular. Thermoplastic polyurethane (TPU) filaments, with and without conductive fillers, are now commercially available. However, conventional FDM still has some limitations because of the marginal compatibility with soft materials. Material selection criteria for the available material options for FDM have not been established. In this study, an open-source soft robotic gripper design has been used to evaluate the FDM printing of TPU structures with integrated strain sensing elements in order to provide some guidelines for the material selection when an elastomer and a soft piezoresistive sensor are combined. Such soft grippers, with integrated strain sensing elements, were successfully printed using a multi-material FDM 3D printer. Characterization of the integrated piezoresistive sensor function, using dynamic tensile testing, revealed that the sensors exhibited good linearity up to 30% strain, which was sufficient for the deformation range of the selected gripper structure. Grippers produced using four different TPU materials were used to investigate the effect of the Shore hardness of the TPU on the piezoresistive sensor properties. The results indicated that the in situ printed strain sensing elements on the soft gripper were able to detect the deformation of the structure when the tentacles of the gripper were open or closed. The sensor signal could differentiate between the picking of small or big objects and when an obstacle prevented the tentacles from opening. Interestingly, the sensors embedded in the tentacles exhibited good reproducibility and linearity, and the sensitivity of the sensor response changed with the Shore hardness of the gripper. Correlation between TPU Shore hardness, used for the gripper body and sensitivity of the integrated in situ strain sensing elements, showed that material selection affects the sensor signal significantly.",2021,"[{'authorId': '1661046525', 'name': 'A. Georgopoulou'}, {'authorId': '1687831', 'name': 'B. Vanderborght'}, {'authorId': '123462124', 'name': 'F. Clemens'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/frobt.2021.615991/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC8965514, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","with the purpose of making soft robotic structures with embedded sensors, additive manufacturing techniques like fused deposition modeling (fdm) are popular. thermoplastic polyurethane (tpu) filaments, with and without conductive fillers, are now commercially available. however, conventional fdm still has some limitations because of the marginal compatibility with soft materials. material selection criteria for the available material options for fdm have not been established. in this study, an open-source soft robotic gripper design has been used to evaluate the fdm printing of tpu structures with integrated strain sensing elements in order to provide some guidelines for the material selection when an elastomer and a soft piezoresistive sensor are combined. such soft grippers, with integrated strain sensing elements, were successfully printed using a multi-material fdm 3d printer. characterization of the integrated piezoresistive sensor function, using dynamic tensile testing, revealed that the sensors exhibited good linearity up to 30% strain, which was sufficient for the deformation range of the selected gripper structure. grippers produced using four different tpu materials were used to investigate the effect of the shore hardness of the tpu on the piezoresistive sensor properties. the results indicated that the in situ printed strain sensing elements on the soft gripper were able to detect the deformation of the structure when the tentacles of the gripper were open or closed. the sensor signal could differentiate between the picking of small or big objects and when an obstacle prevented the tentacles from opening. interestingly, the sensors embedded in the tentacles exhibited good reproducibility and linearity, and the sensitivity of the sensor response changed with the shore hardness of the gripper. correlation between tpu shore hardness, used for the gripper body and sensitivity of the integrated in situ strain sensing elements, showed that material selection affects the sensor signal significantly.",https://www.frontiersin.org/articles/10.3389/frobt.2021.615991/pdf
d12260882b1a0131c4cc51bb4b88879085f4649f,Sustainable Materials and Chemical Processes for Additive Manufacturing,"Additive manufacturing (AM) is energizing the fields of chemistry and materials science to develop new inks for new applications within fields such as aerospace, robotics, and healthcare. AM enable...",2020,"[{'authorId': '1401306508', 'name': 'Eva Sanchez-Rexach'}, {'authorId': '1401306508', 'name': 'Eva Sanchez-Rexach'}, {'authorId': '50420674', 'name': 'Trevor G. Johnston'}, {'authorId': '93466392', 'name': 'Coralie Jehanno'}, {'authorId': '143726686', 'name': 'H. Sardón'}, {'authorId': '48058511', 'name': 'Alshakim Nelson'}]","{'url': 'http://addi.ehu.es/bitstream/10810/57816/3/Chem%20Mater%20Revised.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1021/acs.chemmater.0c02008?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1021/acs.chemmater.0c02008, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",sustainable materials and chemical processes for additive manufacturing,http://addi.ehu.es/bitstream/10810/57816/3/Chem%20Mater%20Revised.pdf
7d6b48259105c72834e681d80205c4f4804a0e50,Soft Robots Manufacturing: A Review,"The growing interest in soft robots comes from the new possibilities offered by these systems to cope with problems that cannot be addressed by robots built from rigid bodies. Many innovative solutions have been developed in recent years to design soft components and systems. They all demonstrate how soft robotics development is closely dependent on advanced manufacturing processes. This review aims at giving an insight on the current state of the art in soft robotics manufacturing. It first puts in light the elementary components that can be used to develop soft actuators, whether they use fluids, shape memory alloys, electro-active polymers or stimuli-responsive materials. Other types of elementary components, such as soft smart structures or soft-rigid hybrid systems, are then presented. The second part of this review deals with the manufacturing methods used to build complete soft structures. It includes molding, with possibly reinforcements and inclusions, additive manufacturing, thin-film manufacturing, shape deposition manufacturing, and bonding. The paper conclusions sums up the pros and cons of the presented techniques, and open to developing topics such as design methods for soft robotics and sensing technologies.",2018,"[{'authorId': '50115121', 'name': 'F. Schmitt'}, {'authorId': '39538806', 'name': 'O. Piccin'}, {'authorId': '39395637', 'name': 'L. Barbé'}, {'authorId': '2631607', 'name': 'B. Bayle'}]","{'url': 'https://www.frontiersin.org/articles/10.3389/frobt.2018.00084/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC7805834, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the growing interest in soft robots comes from the new possibilities offered by these systems to cope with problems that cannot be addressed by robots built from rigid bodies. many innovative solutions have been developed in recent years to design soft components and systems. they all demonstrate how soft robotics development is closely dependent on advanced manufacturing processes. this review aims at giving an insight on the current state of the art in soft robotics manufacturing. it first puts in light the elementary components that can be used to develop soft actuators, whether they use fluids, shape memory alloys, electro-active polymers or stimuli-responsive materials. other types of elementary components, such as soft smart structures or soft-rigid hybrid systems, are then presented. the second part of this review deals with the manufacturing methods used to build complete soft structures. it includes molding, with possibly reinforcements and inclusions, additive manufacturing, thin-film manufacturing, shape deposition manufacturing, and bonding. the paper conclusions sums up the pros and cons of the presented techniques, and open to developing topics such as design methods for soft robotics and sensing technologies.",https://www.frontiersin.org/articles/10.3389/frobt.2018.00084/pdf
e236b17ad13a06b7ec721cf3c59479cd09ddc1f0,"Liquid Metal Based Soft Robotics: Materials, Designs, and Applications","Emerging classes of soft robotics with flexible actuation, intelligent sensibility, and biomimetic functionality are driving significant advances in academic researches and commercial applications. Such new generation robotics relies heavily on important breakthroughs in soft matter engineering and flexible actuation systems. Unlike conventional rigid robots, soft robots generally have unique sporting styles and manufacturing strategies. Recently, a series of newly developed soft materials—gallium‐based liquid metals (LMs) are found to display dramatical roles in making soft machines and robotics with their unusual properties in soft robotic actuation and self‐driven field. With superior merits of both high stretchability and electroconductivity over conventional soft materials, LM is increasingly innovated as flexible sensors and actuators in constructing intelligent soft robots. Typical advances in LM enabled soft machines and robotics are summarized and interpreted, herein, with special focus on the driving principles of the LM objects, the preparation methods of LM flexible electronics for making soft robots, and the applications of LM in biomedicines and intelligent robots, together with the consideration of key challenges facing LM‐based soft robotics and its future prospects.",2018,"[{'authorId': '2191370556', 'name': 'Xuelin Wang'}, {'authorId': '2007721262', 'name': 'Rui Guo'}, {'authorId': '102551224', 'name': 'Jing Liu'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdf/10.1002/admt.201800549', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/admt.201800549?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/admt.201800549, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","emerging classes of soft robotics with flexible actuation, intelligent sensibility, and biomimetic functionality are driving significant advances in academic researches and commercial applications. such new generation robotics relies heavily on important breakthroughs in soft matter engineering and flexible actuation systems. unlike conventional rigid robots, soft robots generally have unique sporting styles and manufacturing strategies. recently, a series of newly developed soft materials—gallium‐based liquid metals (lms) are found to display dramatical roles in making soft machines and robotics with their unusual properties in soft robotic actuation and self‐driven field. with superior merits of both high stretchability and electroconductivity over conventional soft materials, lm is increasingly innovated as flexible sensors and actuators in constructing intelligent soft robots. typical advances in lm enabled soft machines and robotics are summarized and interpreted, herein, with special focus on the driving principles of the lm objects, the preparation methods of lm flexible electronics for making soft robots, and the applications of lm in biomedicines and intelligent robots, together with the consideration of key challenges facing lm‐based soft robotics and its future prospects.",https://onlinelibrary.wiley.com/doi/pdf/10.1002/admt.201800549
0b847aac260ddf9df5309653a2a6fc92258ec68b,"Exoskeleton robots for lower limb assistance: A review of materials, actuation, and manufacturing methods","The field of robot-assisted physical rehabilitation and robotics technology for providing support to the elderly population is rapidly evolving. Lower limb robot aided rehabilitation and assistive technology have been a focus for the engineering community during the last three decades as several robotic lower limb exoskeletons have been proposed in the literature as well as some being commercially available. Numerous manufacturing techniques and materials have been developed for lower limb exoskeletons during the last two decades, resulting in the design of a variety of robot exoskeletons for gait assistance for elderly and disabled people. One of the most important aspects of developing exoskeletons is the selection of the most appropriate proper material. The material selection strongly influences the overall weight and performance of the exoskeleton robot. The most suitable fabrication method for material is also an important parameter for the development of lower limb robot exoskeletons. In addition to the materials and manufacturing methods, the actuation method plays a vital role in the development of these robot exoskeletons. Even though various materials, manufacturing methods and actuators are reported in the literature for these lower limb robot exoskeletons, there are still avenues of improvement in these three domains. In this review, we have examined various lower limb robotic exoskeletons, concentrating on the three main aspects of material, manufacturing, and actuation. We have focused on the advantages and drawbacks of various materials and manufacturing practices as well as actuation methods. A discussion on future directions of research is provided for the engineering community covering the material, manufacturing and actuation methods.",2021,"[{'authorId': '2119093880', 'name': 'Fahad Hussain'}, {'authorId': '2026749552', 'name': 'R. Goecke'}, {'authorId': '1699092', 'name': 'M. Mohammadian'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/09544119211032010?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/09544119211032010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the field of robot-assisted physical rehabilitation and robotics technology for providing support to the elderly population is rapidly evolving. lower limb robot aided rehabilitation and assistive technology have been a focus for the engineering community during the last three decades as several robotic lower limb exoskeletons have been proposed in the literature as well as some being commercially available. numerous manufacturing techniques and materials have been developed for lower limb exoskeletons during the last two decades, resulting in the design of a variety of robot exoskeletons for gait assistance for elderly and disabled people. one of the most important aspects of developing exoskeletons is the selection of the most appropriate proper material. the material selection strongly influences the overall weight and performance of the exoskeleton robot. the most suitable fabrication method for material is also an important parameter for the development of lower limb robot exoskeletons. in addition to the materials and manufacturing methods, the actuation method plays a vital role in the development of these robot exoskeletons. even though various materials, manufacturing methods and actuators are reported in the literature for these lower limb robot exoskeletons, there are still avenues of improvement in these three domains. in this review, we have examined various lower limb robotic exoskeletons, concentrating on the three main aspects of material, manufacturing, and actuation. we have focused on the advantages and drawbacks of various materials and manufacturing practices as well as actuation methods. a discussion on future directions of research is provided for the engineering community covering the material, manufacturing and actuation methods.",
7c7c6204e219b41bc1daf3d6cc4333a8375cacc0,Optimization of the cycle time of robotics resistance spot welding for automotive applications,"In the automobile manufacturing industry, resistance spot welding (RSW) is widely used, especially to build the car's body. The RSW is a standard and wide‐ranging joining technique in several assembling ventures, showing a wide range of possibilities for a competent procedure. Robots are commonly used for spot welding in various industrial applications. After completing assembling design, interest increases to improve the designed processes, cost‐reduction, environmental impact, and increase time productivity when all is said to be done. In this paper, the robot movement between two welding points, a path followed while spotting, gripping and payload‐carrying activities, numbers of holds, moves, and a possibility to enhance interaction between four Robots were analyzed using an offline Robot simulation software 'DELMIA‐V5'. The body shop assembly line of the SML ISUZU plant has four robots that perform about 209 welding spots in 532 sec. The optimal model reduced the whole welding cycle time by 68 sec, and after modification and proper sequencing, a12.7% reduction in cycle time was achieved. The offline Robot simulation software 'DELMIA‐V5' has good potential to produce optimal algorithms while saving precious time. It enables an organization to promote higher quality and to encourage meaningful creativity by reducing design flaws.",2021,"[{'authorId': '83178001', 'name': 'H. Banga'}, {'authorId': '145239841', 'name': 'P. Kalra'}, {'authorId': '1988730999', 'name': 'Raman Kumar'}, {'authorId': '46529344', 'name': 'Sunpreet Singh'}, {'authorId': '8612503', 'name': 'C. Pruncu'}]","{'url': 'https://strathprints.strath.ac.uk/76051/7/Banga_etal_JAMP_2021_Optimization_of_the_cycle_time_of_robotics_resistance_spot_welding.pdf', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/AMP2.10084?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/AMP2.10084, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the automobile manufacturing industry, resistance spot welding (rsw) is widely used, especially to build the car's body. the rsw is a standard and wide‐ranging joining technique in several assembling ventures, showing a wide range of possibilities for a competent procedure. robots are commonly used for spot welding in various industrial applications. after completing assembling design, interest increases to improve the designed processes, cost‐reduction, environmental impact, and increase time productivity when all is said to be done. in this paper, the robot movement between two welding points, a path followed while spotting, gripping and payload‐carrying activities, numbers of holds, moves, and a possibility to enhance interaction between four robots were analyzed using an offline robot simulation software 'delmia‐v5'. the body shop assembly line of the sml isuzu plant has four robots that perform about 209 welding spots in 532 sec. the optimal model reduced the whole welding cycle time by 68 sec, and after modification and proper sequencing, a12.7% reduction in cycle time was achieved. the offline robot simulation software 'delmia‐v5' has good potential to produce optimal algorithms while saving precious time. it enables an organization to promote higher quality and to encourage meaningful creativity by reducing design flaws.",https://strathprints.strath.ac.uk/76051/7/Banga_etal_JAMP_2021_Optimization_of_the_cycle_time_of_robotics_resistance_spot_welding.pdf
3e4bd7c1237061ab2ff052189b1f1058657446c8,The use of robotics in surgery: a review,"There is an ever‐increasing drive to improve surgical patient outcomes. Given the benefits which robotics has bestowed upon a wide range of industries, from vehicle manufacturing to space exploration, robots have been highlighted by many as essential for continued improvements in surgery.",2014,"[{'authorId': '2082387591', 'name': 'A. Hussain'}, {'authorId': '2114083557', 'name': 'A. Malik'}, {'authorId': '2272001434', 'name': 'M. U. Halim'}, {'authorId': '2273275875', 'name': 'Abdel-Hamid A. M. Ali'}, {'authorId': '2273275875', 'name': 'Abdel-Hamid A. M. Ali'}]","{'url': 'https://doi.org/10.1111/ijcp.12492', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1111/ijcp.12492?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1111/ijcp.12492, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",the use of robotics in surgery: a review,https://doi.org/10.1111/ijcp.12492
a95b784abf3802e2c65e367e5335be3bf5364185,"The State of Industrial Robotics: Emerging Technologies, Challenges, and Key Research Directions","Robotics and related technologies are central to the ongoing digitization and advancement of manufacturing. In recent years, a variety of strategic initiatives around the world including ""Industry 4.0"", introduced in Germany in 2011 have aimed to improve and connect manufacturing technologies in order to optimize production processes. In this work, we study the changing technological landscape of robotics and ""internet-of-things"" (IoT)-based connective technologies over the last 7-10 years in the wake of Industry 4.0. We interviewed key players within the European robotics ecosystem, including robotics manufacturers and integrators, original equipment manufacturers (OEMs), and applied industrial research institutions and synthesize our findings in this paper. We first detail the state-of-the-art robotics and IoT technologies we observed and that the companies discussed during our interviews. We then describe the processes the companies follow when deciding whether and how to integrate new technologies, the challenges they face when integrating these technologies, and some immediate future technological avenues they are exploring in robotics and IoT. Finally, based on our findings, we highlight key research directions for the robotics community that can enable improved capabilities in the context of manufacturing.",2020,"[{'authorId': '49134546', 'name': 'Lindsay M. Sanneman'}, {'authorId': '2057543044', 'name': 'Christopher K. Fourie'}, {'authorId': '143873972', 'name': 'J. Shah'}]","{'url': 'https://arxiv.org/pdf/2010.14537', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2010.14537, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","robotics and related technologies are central to the ongoing digitization and advancement of manufacturing. in recent years, a variety of strategic initiatives around the world including ""industry 4.0"", introduced in germany in 2011 have aimed to improve and connect manufacturing technologies in order to optimize production processes. in this work, we study the changing technological landscape of robotics and ""internet-of-things"" (iot)-based connective technologies over the last 7-10 years in the wake of industry 4.0. we interviewed key players within the european robotics ecosystem, including robotics manufacturers and integrators, original equipment manufacturers (oems), and applied industrial research institutions and synthesize our findings in this paper. we first detail the state-of-the-art robotics and iot technologies we observed and that the companies discussed during our interviews. we then describe the processes the companies follow when deciding whether and how to integrate new technologies, the challenges they face when integrating these technologies, and some immediate future technological avenues they are exploring in robotics and iot. finally, based on our findings, we highlight key research directions for the robotics community that can enable improved capabilities in the context of manufacturing.",https://arxiv.org/pdf/2010.14537
37db5c946899b08292022a19dc38bdb22441ce9e,Trouble in the Making?: The Future of Manufacturing-Led Development,"In the past, manufacturing-led development typically delivered both productivity gains and job creation for unskilled labor. Looking ahead, changing technologies and shifting globalization patterns call the feasibility of manufacturing-led development strategies into question. Things, advanced robotics, and 3-D printing are shifting the criteria that make locations attractive for production and are threatening significant disruptions in employment, particularly for low-skilled labor. These trends raise fears that manufacturing will no longer offer an accessible pathway for low-income countries to develop and, even if feasible, will no longer provide the same dual benefits of productivity gains and job creation for unskilled labor. As a result, the potential risk of growing inequality across and within countries warrants closer attention to the implications of changing technology and globalization patterns. This book looks at changing technology and globalization from the perspective of low- and middle income countries (LMICs) - with an emphasis on analyzing differences across manufacturing subsectors and identifying policy priorities with an eye toward making the most of new opportunities. The book will answer the following questions: how has the global manufacturing landscape changed, and why does this matter for development opportunities?; how are emerging trends in technology and globalization likely to shape the feasibility and desirability of manufacturing-led development in the future?; and if low wages are going to be less important in determining competitiveness, how can less industrialized countries make the most of new opportunities that shifting technologies and globalization patterns may bring?",2017,"[{'authorId': '1400901227', 'name': 'Mary C. Hallward-Driemeier'}, {'authorId': '8209163', 'name': 'Gaurav Nayyar'}]","{'url': 'https://openknowledge.worldbank.org/bitstreams/6769c791-d1ab-5286-b7c9-a5bae1338222/download', 'status': 'GREEN', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1596/978-1-4648-1174-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1596/978-1-4648-1174-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the past, manufacturing-led development typically delivered both productivity gains and job creation for unskilled labor. looking ahead, changing technologies and shifting globalization patterns call the feasibility of manufacturing-led development strategies into question. things, advanced robotics, and 3-d printing are shifting the criteria that make locations attractive for production and are threatening significant disruptions in employment, particularly for low-skilled labor. these trends raise fears that manufacturing will no longer offer an accessible pathway for low-income countries to develop and, even if feasible, will no longer provide the same dual benefits of productivity gains and job creation for unskilled labor. as a result, the potential risk of growing inequality across and within countries warrants closer attention to the implications of changing technology and globalization patterns. this book looks at changing technology and globalization from the perspective of low- and middle income countries (lmics) - with an emphasis on analyzing differences across manufacturing subsectors and identifying policy priorities with an eye toward making the most of new opportunities. the book will answer the following questions: how has the global manufacturing landscape changed, and why does this matter for development opportunities?; how are emerging trends in technology and globalization likely to shape the feasibility and desirability of manufacturing-led development in the future?; and if low wages are going to be less important in determining competitiveness, how can less industrialized countries make the most of new opportunities that shifting technologies and globalization patterns may bring?",https://openknowledge.worldbank.org/bitstreams/6769c791-d1ab-5286-b7c9-a5bae1338222/download
af66e4e7597b59d27fa71888faba718706d9173d,Flexible Actuators for Soft Robotics,"Rigid robots have taken on a variety of automated manufacturing tasks and have made a huge contribution to industrial development; however, they are not suitable for further wearable applications due to their rigid and bulky structure, poor environmental adaptability, and low safety. Soft robots, which are mainly fabricated with ﬂexible or elastomeric materials, can easily adjust to environmental changes and accomplish complex tasks, offering a new paradigm to achieve human–machine compliance. Soft robots do not replace rigid robots but add diverse features for softer robotic applications. In particular, the use of flexible actuators in robotic systems can realize certain intelligent functions, enrich soft robotic systems and migrate academic research to engineering applications. Currently, the application of flexible actuators in soft robotic fields is still at the embryonic stage. However, tremendous application spaces can be envisaged when combining flexible actuators with soft wearable robotics. Therefore, the current flexible actuators that rely on different external stimuli are addressed herein, and their materials, designs, and approaches suitable for soft robotic applications are highlighted. The application advancement and future perspective of flexible actuator prototypes toward various soft robotics are also discussed.",2019,"[{'authorId': '2146417875', 'name': 'Ying Yang'}, {'authorId': '2048447748', 'name': 'Yanxiao Wu'}, {'authorId': '2133091908', 'name': 'Cheng Li'}, {'authorId': '2128189156', 'name': 'Xiaoming Yang'}, {'authorId': '2154939385', 'name': 'Wei Chen'}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aisy.201900077', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/aisy.201900077?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/aisy.201900077, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","rigid robots have taken on a variety of automated manufacturing tasks and have made a huge contribution to industrial development; however, they are not suitable for further wearable applications due to their rigid and bulky structure, poor environmental adaptability, and low safety. soft robots, which are mainly fabricated with ﬂexible or elastomeric materials, can easily adjust to environmental changes and accomplish complex tasks, offering a new paradigm to achieve human–machine compliance. soft robots do not replace rigid robots but add diverse features for softer robotic applications. in particular, the use of flexible actuators in robotic systems can realize certain intelligent functions, enrich soft robotic systems and migrate academic research to engineering applications. currently, the application of flexible actuators in soft robotic fields is still at the embryonic stage. however, tremendous application spaces can be envisaged when combining flexible actuators with soft wearable robotics. therefore, the current flexible actuators that rely on different external stimuli are addressed herein, and their materials, designs, and approaches suitable for soft robotic applications are highlighted. the application advancement and future perspective of flexible actuator prototypes toward various soft robotics are also discussed.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aisy.201900077
33634243c92de962b582a612b23f49379710d3bc,"Soft Robotics: Research, Challenges, and Prospects","The soft robot is a kind of continuum robot, which is mainly made of soft elastic material or malleable material. It can be continuously deformed in a limited space, and can obtain energy in large bending or high curvature distortion. It has obvious advantages such as high security of human-computer interaction, strong adaptability of unstructured environment, high driving efficiency, low maintenance cost, etc. It has wide application prospects in the fields of industrial production, defense military, medical rehabilitation, exploration, and so on. From the perspective of the bionic mechanism, this paper introduces the soft robots corresponding to insect crawling, snake crawling, fish swimming, elephant trunk, arm, etc. According to different driving modes, the soft robots can be classified into pneumatic-hydraulic driven, intelligent material driven, chemical reaction driven, and so on. The mechanical modeling, control strategy, material, and manufacturing methods of soft robot are summarized, and the application fields of soft robot are introduced. This paper analyzes the main challenges faced by the research on the key technologies of soft robots, summarizes and analyzes them, and puts forward the prospects for the future research of soft robots. The development trend of the future is to develop the soft robot with the characteristics of micro-scale, rigid-flexible coupling, variable stiffness, multi-functional, high integration, and intelligence of driving sensor control.",2021,"[{'authorId': '2027136801', 'name': 'Wenchuan Zhao'}, {'authorId': '2153636475', 'name': 'Yu Zhang'}, {'authorId': '2152169435', 'name': 'Ning Wang'}]","{'url': 'https://doi.org/10.20965/jrm.2021.p0045', 'status': 'GOLD', 'license': 'CCBYND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.20965/jrm.2021.p0045?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.20965/jrm.2021.p0045, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the soft robot is a kind of continuum robot, which is mainly made of soft elastic material or malleable material. it can be continuously deformed in a limited space, and can obtain energy in large bending or high curvature distortion. it has obvious advantages such as high security of human-computer interaction, strong adaptability of unstructured environment, high driving efficiency, low maintenance cost, etc. it has wide application prospects in the fields of industrial production, defense military, medical rehabilitation, exploration, and so on. from the perspective of the bionic mechanism, this paper introduces the soft robots corresponding to insect crawling, snake crawling, fish swimming, elephant trunk, arm, etc. according to different driving modes, the soft robots can be classified into pneumatic-hydraulic driven, intelligent material driven, chemical reaction driven, and so on. the mechanical modeling, control strategy, material, and manufacturing methods of soft robot are summarized, and the application fields of soft robot are introduced. this paper analyzes the main challenges faced by the research on the key technologies of soft robots, summarizes and analyzes them, and puts forward the prospects for the future research of soft robots. the development trend of the future is to develop the soft robot with the characteristics of micro-scale, rigid-flexible coupling, variable stiffness, multi-functional, high integration, and intelligence of driving sensor control.",https://doi.org/10.20965/jrm.2021.p0045
9f7889c3f642f67f29f37ea2915a1c5839da6bb8,Context-Aware Cloud Robotics for Material Handling in Cognitive Industrial Internet of Things,"In the context of Industry 4.0, industrial robotics such as automated guided vehicles have drawn increased attention due to their automation capabilities and low cost. With the support of cognitive technologies for industrial Internet of Things (IoT), production processes can be significantly optimized and more intelligent manufacturing can be implemented for smart factories. In this paper, for advanced material handling, a cognitive industrial entity called context-aware cloud robotics (CACR) are introduced and analyzed. Compared with the one-time on-demand delivery, CACR is characterized by two features: 1) context-aware services and 2) effective load balancing. First, the system architecture, advantages, challenges, and applications for CACR are introduced. Then, fundamental functions for material handling are articulated, namely, decision-making mechanisms and cloud-enabled simultaneous localization and mapping. Finally, a CACR case study is performed to highlight its energy-efficient and cost-saving material handling capabilities. Simulations indicate the superiority of cognitive industrial IoT and show that using CACR for material handling can significantly improve energy efficiency and save cost.",2018,"[{'authorId': '70985296', 'name': 'J. Wan'}, {'authorId': '3427818', 'name': 'Shenglong Tang'}, {'authorId': '2066175519', 'name': 'Qingsong Hua'}, {'authorId': '46599370', 'name': 'Di Li'}, {'authorId': '1699591', 'name': 'Chengliang Liu'}, {'authorId': '144484046', 'name': 'Jaime Lloret'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JIOT.2017.2728722?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JIOT.2017.2728722, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the context of industry 4.0, industrial robotics such as automated guided vehicles have drawn increased attention due to their automation capabilities and low cost. with the support of cognitive technologies for industrial internet of things (iot), production processes can be significantly optimized and more intelligent manufacturing can be implemented for smart factories. in this paper, for advanced material handling, a cognitive industrial entity called context-aware cloud robotics (cacr) are introduced and analyzed. compared with the one-time on-demand delivery, cacr is characterized by two features: 1) context-aware services and 2) effective load balancing. first, the system architecture, advantages, challenges, and applications for cacr are introduced. then, fundamental functions for material handling are articulated, namely, decision-making mechanisms and cloud-enabled simultaneous localization and mapping. finally, a cacr case study is performed to highlight its energy-efficient and cost-saving material handling capabilities. simulations indicate the superiority of cognitive industrial iot and show that using cacr for material handling can significantly improve energy efficiency and save cost.",
c83ee792d165f8b70e4c87c5c5afa405cdfbe5f0,Human movement and ergonomics: An industry-oriented dataset for collaborative robotics,"Improving work conditions in industry is a major challenge that can be addressed with new emerging technologies such as collaborative robots. Machine learning techniques can improve the performance of those robots, by endowing them with a degree of awareness of the human state and ergonomics condition. The availability of appropriate datasets to learn models and test prediction and control algorithms, however, remains an issue. This article presents a dataset of human motions in industry-like activities, fully labeled according to the ergonomics assessment worksheet EAWS, widely used in industries such as car manufacturing. Thirteen participants performed several series of activities, such as screwing and manipulating loads under different conditions, resulting in more than 5 hours of data. The dataset contains the participants’ whole-body kinematics recorded both with wearable inertial sensors and marker-based optical motion capture, finger pressure force, video recordings, and annotations by three independent annotators of the performed action and the adopted posture following the EAWS postural grid. Sensor data are available in different formats to facilitate their reuse. The dataset is intended for use by researchers developing algorithms for classifying, predicting, or evaluating human motion in industrial settings, as well as researchers developing collaborative robotics solutions that aim at improving the workers’ ergonomics. The annotation of the whole dataset following an ergonomics standard makes it valuable for ergonomics-related applications, but we expect its use to be broader in the robotics, machine learning, and human movement communities.",2019,"[{'authorId': '31636143', 'name': 'Pauline Maurice'}, {'authorId': '3471188', 'name': 'Adrien Malaisé'}, {'authorId': '1388149790', 'name': 'Clélie Amiot'}, {'authorId': '2065651269', 'name': 'Nicolas Paris'}, {'authorId': '1379919501', 'name': 'Guy-Junior Richard'}, {'authorId': '2921405', 'name': 'Olivier Rochel'}, {'authorId': '1763452', 'name': 'S. Ivaldi'}]","{'url': 'https://hal.archives-ouvertes.fr/hal-02289107/file/datapaper_ergonomics.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/0278364919882089?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/0278364919882089, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","improving work conditions in industry is a major challenge that can be addressed with new emerging technologies such as collaborative robots. machine learning techniques can improve the performance of those robots, by endowing them with a degree of awareness of the human state and ergonomics condition. the availability of appropriate datasets to learn models and test prediction and control algorithms, however, remains an issue. this article presents a dataset of human motions in industry-like activities, fully labeled according to the ergonomics assessment worksheet eaws, widely used in industries such as car manufacturing. thirteen participants performed several series of activities, such as screwing and manipulating loads under different conditions, resulting in more than 5 hours of data. the dataset contains the participants’ whole-body kinematics recorded both with wearable inertial sensors and marker-based optical motion capture, finger pressure force, video recordings, and annotations by three independent annotators of the performed action and the adopted posture following the eaws postural grid. sensor data are available in different formats to facilitate their reuse. the dataset is intended for use by researchers developing algorithms for classifying, predicting, or evaluating human motion in industrial settings, as well as researchers developing collaborative robotics solutions that aim at improving the workers’ ergonomics. the annotation of the whole dataset following an ergonomics standard makes it valuable for ergonomics-related applications, but we expect its use to be broader in the robotics, machine learning, and human movement communities.",https://hal.archives-ouvertes.fr/hal-02289107/file/datapaper_ergonomics.pdf
7158277c0361f15a7c67621f5940c4208c9c46ce,Optimizing renewable energy systems through artificial intelligence: Review and future prospects,"The global transition toward sustainable energy sources has prompted a surge in the integration of renewable energy systems (RES) into existing power grids. To improve the efficiency, reliability, and economic viability of these systems, the synergistic application of artificial intelligence (AI) methods has emerged as a promising avenue. This study presents a comprehensive review of the current state of research at the intersection of renewable energy and AI, highlighting key methodologies, challenges, and achievements. It covers a spectrum of AI utilizations in optimizing different facets of RES, including resource assessment, energy forecasting, system monitoring, control strategies, and grid integration. Machine learning algorithms, neural networks, and optimization techniques are explored for their role in complex data sets, enhancing predictive capabilities, and dynamically adapting RES. Furthermore, the study discusses the challenges faced in the implementation of AI in RES, such as data variability, model interpretability, and real-time adaptability. The potential benefits of overcoming these challenges include increased energy yield, reduced operational costs, and improved grid stability. The review concludes with an exploration of prospects and emerging trends in the field. Anticipated advancements in AI, such as explainable AI, reinforcement learning, and edge computing, are discussed in the context of their potential impact on optimizing RES. Additionally, the paper envisions the integration of AI-driven solutions into smart grids, decentralized energy systems, and the development of autonomous energy management systems. This investigation provides important insights into the current landscape of AI applications in RES.",2024,"[{'authorId': '93830238', 'name': 'K. Ukoba'}, {'authorId': '94902798', 'name': 'Kehinde Oladoke Olatunji'}, {'authorId': '2303217984', 'name': 'Eyitayo Adeoye'}, {'authorId': '2282725138', 'name': 'T. Jen'}, {'authorId': '10680191', 'name': 'D. Madyira'}]","{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/0958305X241256293', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1177/0958305x241256293?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1177/0958305x241256293, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the global transition toward sustainable energy sources has prompted a surge in the integration of renewable energy systems (res) into existing power grids. to improve the efficiency, reliability, and economic viability of these systems, the synergistic application of artificial intelligence (ai) methods has emerged as a promising avenue. this study presents a comprehensive review of the current state of research at the intersection of renewable energy and ai, highlighting key methodologies, challenges, and achievements. it covers a spectrum of ai utilizations in optimizing different facets of res, including resource assessment, energy forecasting, system monitoring, control strategies, and grid integration. machine learning algorithms, neural networks, and optimization techniques are explored for their role in complex data sets, enhancing predictive capabilities, and dynamically adapting res. furthermore, the study discusses the challenges faced in the implementation of ai in res, such as data variability, model interpretability, and real-time adaptability. the potential benefits of overcoming these challenges include increased energy yield, reduced operational costs, and improved grid stability. the review concludes with an exploration of prospects and emerging trends in the field. anticipated advancements in ai, such as explainable ai, reinforcement learning, and edge computing, are discussed in the context of their potential impact on optimizing res. additionally, the paper envisions the integration of ai-driven solutions into smart grids, decentralized energy systems, and the development of autonomous energy management systems. this investigation provides important insights into the current landscape of ai applications in res.",https://journals.sagepub.com/doi/pdf/10.1177/0958305X241256293
5343d7e2c3a6604be28743e3f33a1ce0486a477f,ELECTRICAL ENGINEERING IN RENEWABLE ENERGY SYSTEMS: A REVIEW OF DESIGN AND INTEGRATION CHALLENGES,"As the global pursuit of sustainable energy intensifies, the integration of renewable energy sources into existing power systems has become a critical focal point for electrical engineers. This review explores the challenges and advancements in the field of Electrical Engineering concerning the design and integration of renewable energy systems. The transition from traditional fossil fuels to renewable sources, such as solar, wind, and hydroelectric power, necessitates a comprehensive understanding of the intricate engineering aspects involved. The first section of the review delves into the design challenges faced by electrical engineers when developing efficient and reliable renewable energy systems. This encompasses the optimization of power generation from intermittent sources, the enhancement of energy conversion technologies, and the development of energy storage solutions to mitigate the inherent variability of renewables. Cutting-edge design methodologies and innovative materials are discussed to highlight the ongoing efforts to improve the performance and reliability of renewable energy systems. The second section focuses on the integration challenges encountered during the incorporation of renewable energy into existing power grids. Grid stability, power quality, and the management of decentralized energy sources pose significant hurdles. Electrical engineers are addressing these challenges through the implementation of advanced control systems, smart grid technologies, and energy management strategies. The review also explores the role of energy storage systems and the potential of emerging technologies like microgrids in facilitating seamless integration. Furthermore, the review examines the interdisciplinary nature of electrical engineering in the context of renewable energy, emphasizing the collaboration between electrical engineers, environmental scientists, and policymakers. The synergy between these disciplines is crucial for developing holistic solutions that address not only technical challenges but also environmental and regulatory considerations. This review provides a comprehensive overview of the design and integration challenges faced by electrical engineers in the realm of renewable energy systems. By understanding and overcoming these challenges, the global community can accelerate the transition towards a sustainable and resilient energy future. 
Keywords: Renewable energy, Energy Integration, Challenges, Electrical, Engineering, Review.",2024,"[{'authorId': '2280216891', 'name': 'Emmanuel Augustine Etukudoh'}, {'authorId': '2281222394', 'name': 'Adefunke Fabuyide'}, {'authorId': '2280217254', 'name': 'Kenneth Ifeanyi Ibekwe'}, {'authorId': '2281222410', 'name': 'Sedat Sonko'}, {'authorId': '2276660225', 'name': 'Valentine Ikenna Ilojianya'}]","{'url': 'https://fepbl.com/index.php/estj/article/download/746/937', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.51594/estj.v5i1.746?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.51594/estj.v5i1.746, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","as the global pursuit of sustainable energy intensifies, the integration of renewable energy sources into existing power systems has become a critical focal point for electrical engineers. this review explores the challenges and advancements in the field of electrical engineering concerning the design and integration of renewable energy systems. the transition from traditional fossil fuels to renewable sources, such as solar, wind, and hydroelectric power, necessitates a comprehensive understanding of the intricate engineering aspects involved. the first section of the review delves into the design challenges faced by electrical engineers when developing efficient and reliable renewable energy systems. this encompasses the optimization of power generation from intermittent sources, the enhancement of energy conversion technologies, and the development of energy storage solutions to mitigate the inherent variability of renewables. cutting-edge design methodologies and innovative materials are discussed to highlight the ongoing efforts to improve the performance and reliability of renewable energy systems. the second section focuses on the integration challenges encountered during the incorporation of renewable energy into existing power grids. grid stability, power quality, and the management of decentralized energy sources pose significant hurdles. electrical engineers are addressing these challenges through the implementation of advanced control systems, smart grid technologies, and energy management strategies. the review also explores the role of energy storage systems and the potential of emerging technologies like microgrids in facilitating seamless integration. furthermore, the review examines the interdisciplinary nature of electrical engineering in the context of renewable energy, emphasizing the collaboration between electrical engineers, environmental scientists, and policymakers. the synergy between these disciplines is crucial for developing holistic solutions that address not only technical challenges but also environmental and regulatory considerations. this review provides a comprehensive overview of the design and integration challenges faced by electrical engineers in the realm of renewable energy systems. by understanding and overcoming these challenges, the global community can accelerate the transition towards a sustainable and resilient energy future. keywords: renewable energy, energy integration, challenges, electrical, engineering, review.",https://fepbl.com/index.php/estj/article/download/746/937
e7ab0ea1932af23d06203d7407164d4fc5b25b95,Estimation of useful-stage energy returns on investment for fossil fuels and implications for renewable energy systems,"The net energy implications of the energy transition have so far been analysed at best at the final energy stage. Here we argue that expanding the analysis to the useful stage is crucial. We estimate fossil fuelsʼ useful-stage energy returns on investment (EROIs) over the period 1971–2020, globally and nationally, and disaggregate EROIs by end use. We find that fossil fuelsʼ useful-stage EROIs (~3.5:1) are considerably lower than at the final stage (~8.5:1), due to low final-to-useful efficiencies. Further, we estimate the final-stage EROI for which electricity-yielding renewable energy would deliver the same net useful energy as fossil fuels (EROI equivalent) to be approximately 4.6:1. The EROIs of electricity-yielding renewable energy systems, based on published estimations, are found to be higher than the determined EROI equivalent, even considering the effects of intermittency under a range of energy transition scenarios. Results suggest that the energy transition may happen without a decline in net useful energy, countering the view that renewable energy systems cannot replace fossil fuels without incurring a substantial energy penalty.",2024,"[{'authorId': '1582451631', 'name': 'E. Aramendia'}, {'authorId': '11816248', 'name': 'P. Brockway'}, {'authorId': '2268595936', 'name': 'Peter G. Taylor'}, {'authorId': '2267132566', 'name': 'Jonathan B. Norman'}, {'authorId': '50768366', 'name': 'M. Heun'}, {'authorId': '1815914969', 'name': 'Zeke Marshall'}]","{'url': 'https://www.nature.com/articles/s41560-024-01518-6.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41560-024-01518-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41560-024-01518-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the net energy implications of the energy transition have so far been analysed at best at the final energy stage. here we argue that expanding the analysis to the useful stage is crucial. we estimate fossil fuelsʼ useful-stage energy returns on investment (erois) over the period 1971–2020, globally and nationally, and disaggregate erois by end use. we find that fossil fuelsʼ useful-stage erois (~3.5:1) are considerably lower than at the final stage (~8.5:1), due to low final-to-useful efficiencies. further, we estimate the final-stage eroi for which electricity-yielding renewable energy would deliver the same net useful energy as fossil fuels (eroi equivalent) to be approximately 4.6:1. the erois of electricity-yielding renewable energy systems, based on published estimations, are found to be higher than the determined eroi equivalent, even considering the effects of intermittency under a range of energy transition scenarios. results suggest that the energy transition may happen without a decline in net useful energy, countering the view that renewable energy systems cannot replace fossil fuels without incurring a substantial energy penalty.",https://www.nature.com/articles/s41560-024-01518-6.pdf
f6a8a26e503830bfb1abc38ba4f90f65065f632b,AI-Enhanced lifecycle assessment of renewable energy systems,"As the global push towards renewable energy intensifies, it becomes imperative to comprehensively assess the environmental impacts and sustainability of renewable energy systems throughout their operational lifecycle. Traditional lifecycle assessment (LCA) methods, while useful, often fall short in handling the complex, dynamic data associated with renewable energy systems. This study explores the application of artificial intelligence (AI) and machine learning (ML) techniques to enhance lifecycle assessments of wind, solar, and green hydrogen energy systems, aiming to provide more accurate, efficient, and comprehensive evaluations. AI-driven LCA models leverage extensive datasets from various stages of the lifecycle of renewable energy systems, including raw material extraction, manufacturing, installation, operation, maintenance, and decommissioning. By employing ML algorithms, these models can identify patterns and relationships within the data, predict potential environmental impacts, and provide insights into sustainability performance over time. The research focuses on developing and validating ML models that incorporate diverse data inputs such as material usage, energy consumption, emissions, and waste generation. These models are trained using historical data from multiple renewable energy projects and are capable of adapting to new data inputs, ensuring continuous improvement in assessment accuracy. Key findings demonstrate that AI-enhanced LCA models significantly improve the precision and depth of environmental impact assessments. For wind energy systems, ML models help in predicting turbine lifespan and maintenance needs, thereby optimizing resource use and minimizing environmental footprints. In solar energy systems, AI techniques assist in forecasting degradation rates and energy yield, contributing to more sustainable design and operation. For green hydrogen production, ML models optimize the electrolysis process and assess the overall sustainability of hydrogen supply chains. The integration of AI in LCA facilitates real-time monitoring and dynamic adjustments, ensuring that renewable energy systems operate at peak sustainability. This approach not only enhances the environmental performance of individual systems but also supports strategic decision-making in renewable energy deployment and policy development. In conclusion, the application of AI and ML techniques in lifecycle assessment offers a transformative approach to evaluating the environmental impact and sustainability of renewable energy systems. This research underscores the critical role of advanced analytics in advancing the global transition to sustainable energy and calls for further exploration and adoption of AI-driven LCA methodologies. 
Keywords: Machine Learning, Renewable Energy Systems, Environmental Impact, Sustainability, AI-Enhanced Lifecycle.",2024,"[{'authorId': '2309373253', 'name': 'Kelvin Edem Bassey'}, {'authorId': '2309374488', 'name': 'Ayanwunmi Rebecca Juliet'}, {'authorId': '2309374324', 'name': 'Akindipe O. Stephen'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.51594/estj.v5i7.1254?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.51594/estj.v5i7.1254, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","as the global push towards renewable energy intensifies, it becomes imperative to comprehensively assess the environmental impacts and sustainability of renewable energy systems throughout their operational lifecycle. traditional lifecycle assessment (lca) methods, while useful, often fall short in handling the complex, dynamic data associated with renewable energy systems. this study explores the application of artificial intelligence (ai) and machine learning (ml) techniques to enhance lifecycle assessments of wind, solar, and green hydrogen energy systems, aiming to provide more accurate, efficient, and comprehensive evaluations. ai-driven lca models leverage extensive datasets from various stages of the lifecycle of renewable energy systems, including raw material extraction, manufacturing, installation, operation, maintenance, and decommissioning. by employing ml algorithms, these models can identify patterns and relationships within the data, predict potential environmental impacts, and provide insights into sustainability performance over time. the research focuses on developing and validating ml models that incorporate diverse data inputs such as material usage, energy consumption, emissions, and waste generation. these models are trained using historical data from multiple renewable energy projects and are capable of adapting to new data inputs, ensuring continuous improvement in assessment accuracy. key findings demonstrate that ai-enhanced lca models significantly improve the precision and depth of environmental impact assessments. for wind energy systems, ml models help in predicting turbine lifespan and maintenance needs, thereby optimizing resource use and minimizing environmental footprints. in solar energy systems, ai techniques assist in forecasting degradation rates and energy yield, contributing to more sustainable design and operation. for green hydrogen production, ml models optimize the electrolysis process and assess the overall sustainability of hydrogen supply chains. the integration of ai in lca facilitates real-time monitoring and dynamic adjustments, ensuring that renewable energy systems operate at peak sustainability. this approach not only enhances the environmental performance of individual systems but also supports strategic decision-making in renewable energy deployment and policy development. in conclusion, the application of ai and ml techniques in lifecycle assessment offers a transformative approach to evaluating the environmental impact and sustainability of renewable energy systems. this research underscores the critical role of advanced analytics in advancing the global transition to sustainable energy and calls for further exploration and adoption of ai-driven lca methodologies. keywords: machine learning, renewable energy systems, environmental impact, sustainability, ai-enhanced lifecycle.",
e6f64424257bf031cdcb0ebe1e942482c33e7e3c,Designing diversified renewable energy systems to balance multisector performance,"Renewable energy system development and improved operation can mitigate climate change. In many regions, hydropower is called to counterbalance the temporal variability of intermittent renewables like solar and wind. However, using hydropower to integrate these renewables can affect aquatic ecosystems and increase cross-sectoral water conflicts. We develop and apply an artificial intelligence-assisted multisector design framework in Ghana, which shows how hydropower’s flexibility alone could enable expanding intermittent renewables by 38% but would increase sub-daily Volta River flow variability by up to 22 times compared to historical baseload hydropower operations. This would damage river ecosystems and reduce agricultural sector revenues by US$169 million per year. A diversified investment strategy identified using the proposed framework, including intermittent renewables, bioenergy, transmission lines and strategic hydropower re-operation could reduce sub-daily flow variability and enhance agricultural performance while meeting future national energy service goals and reducing CO_2 emissions. The tool supports national climate planning instruments such as nationally determined contributions (NDCs) by steering towards diversified and efficient power systems and highlighting their sectoral and emission trade-offs and synergies. Diversified renewable energy sources can enable the sustainable operation of multisector resource systems. An artificial intelligence-assisted multi-objective design framework, applied in Ghana, explores optimized management and investment strategies balancing hydropower, bioenergy, solar and wind energies, and their impacts.",2023,"[{'authorId': '2119114597', 'name': 'Jose M. Gonzalez'}, {'authorId': '2068330941', 'name': 'J. Tomlinson'}, {'authorId': '30814750', 'name': 'E. A. Martínez Ceseña'}, {'authorId': '31464982', 'name': 'M. Basheer'}, {'authorId': '3498341', 'name': 'E. Obuobie'}, {'authorId': '104837236', 'name': 'P. T. Padi'}, {'authorId': '2099871599', 'name': 'Salifu Addo'}, {'authorId': '31321970', 'name': 'R. Baisie'}, {'authorId': '2003345048', 'name': 'Mikiyas Etichia'}, {'authorId': '100788660', 'name': 'A. Hurford'}, {'authorId': '1403036567', 'name': 'A. Bottacin‐Busolin'}, {'authorId': '46620870', 'name': 'J. Matthews'}, {'authorId': '114360180', 'name': 'J. Dalton'}, {'authorId': '91657757', 'name': 'D. M. Smith'}, {'authorId': '11014738', 'name': 'J. Sheffield'}, {'authorId': '145424929', 'name': 'M. Panteli'}, {'authorId': '2590882', 'name': 'J. Harou'}]","{'url': 'https://www.nature.com/articles/s41893-022-01033-0.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1038/s41893-022-01033-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s41893-022-01033-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","renewable energy system development and improved operation can mitigate climate change. in many regions, hydropower is called to counterbalance the temporal variability of intermittent renewables like solar and wind. however, using hydropower to integrate these renewables can affect aquatic ecosystems and increase cross-sectoral water conflicts. we develop and apply an artificial intelligence-assisted multisector design framework in ghana, which shows how hydropower’s flexibility alone could enable expanding intermittent renewables by 38% but would increase sub-daily volta river flow variability by up to 22 times compared to historical baseload hydropower operations. this would damage river ecosystems and reduce agricultural sector revenues by us$169 million per year. a diversified investment strategy identified using the proposed framework, including intermittent renewables, bioenergy, transmission lines and strategic hydropower re-operation could reduce sub-daily flow variability and enhance agricultural performance while meeting future national energy service goals and reducing co_2 emissions. the tool supports national climate planning instruments such as nationally determined contributions (ndcs) by steering towards diversified and efficient power systems and highlighting their sectoral and emission trade-offs and synergies. diversified renewable energy sources can enable the sustainable operation of multisector resource systems. an artificial intelligence-assisted multi-objective design framework, applied in ghana, explores optimized management and investment strategies balancing hydropower, bioenergy, solar and wind energies, and their impacts.",https://www.nature.com/articles/s41893-022-01033-0.pdf
a319e41bc83936fe3f03ff96e01a7c1f0a3cd0ee,"A Review of Hybrid Renewable Energy Systems: Architectures, Battery Systems, and Optimization Techniques","This paper aims to perform a literature review and statistical analysis based on data extracted from 38 articles published between 2018 and 2023 that address hybrid renewable energy systems. The main objective of this review has been to create a bibliographic database that organizes the content of the articles in different categories, such as system architecture, energy storage systems, auxiliary generation components used, and software employed, in addition to showing the algorithms and economic and reliability criteria for the optimization of these systems. In total, 38 articles have been analyzed, compared, and classified to provide an overview of the current status of simulation and optimization projects for hybrid renewable energy systems, highlighting clearly and appropriately the relevant trends and conclusions. A list of review articles has also been provided, which cover the aspects required for understanding HRESs.",2023,"[{'authorId': '2219121537', 'name': 'Juan Carlos León Gómez'}, {'authorId': '9099146', 'name': 'Susana Estefany de León Aldaco'}, {'authorId': '30608369', 'name': 'Jesus Aguayo Aguayo Alquicira'}]","{'url': 'https://www.mdpi.com/2673-4117/4/2/84/pdf?version=1684923785', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/eng4020084?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/eng4020084, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper aims to perform a literature review and statistical analysis based on data extracted from 38 articles published between 2018 and 2023 that address hybrid renewable energy systems. the main objective of this review has been to create a bibliographic database that organizes the content of the articles in different categories, such as system architecture, energy storage systems, auxiliary generation components used, and software employed, in addition to showing the algorithms and economic and reliability criteria for the optimization of these systems. in total, 38 articles have been analyzed, compared, and classified to provide an overview of the current status of simulation and optimization projects for hybrid renewable energy systems, highlighting clearly and appropriately the relevant trends and conclusions. a list of review articles has also been provided, which cover the aspects required for understanding hress.",https://www.mdpi.com/2673-4117/4/2/84/pdf?version=1684923785
222ce04b417b80d5927bb444d77631e1f5ead8cc,HYBRID RENEWABLE ENERGY SYSTEMS MODELING,"The growing demand for sustainable energy solutions has spurred the development of hybrid renewable energy systems (HRES), which combine multiple renewable sources like solar and wind to enhance energy reliability and efficiency. However, optimizing the performance of HRES and managing energy storage remain significant challenges. This study explores the application of machine learning (ML) techniques to model hybrid renewable energy systems, integrating data from solar and wind sources to predict system performance and improve energy storage solutions. Machine learning algorithms are employed to analyze large datasets generated from solar panels and wind turbines, including variables such as solar irradiance, wind speed, temperature, and historical power output. By identifying patterns and correlations within these datasets, ML models can predict the performance of the hybrid system under various environmental conditions, enabling more efficient management and utilization of renewable resources. The research focuses on the development of various ML models, including regression analysis, neural networks, and ensemble methods, to enhance the predictive accuracy of HRES performance. These models are trained on extensive historical data from multiple renewable energy installations, ensuring robustness and reliability. Feature selection techniques are used to identify the most significant factors affecting system performance. Key findings demonstrate that ML-driven modelling significantly improves the accuracy of performance predictions for hybrid renewable energy systems. This improved predictive capability allows for better planning and optimization of energy storage solutions, ensuring that surplus energy generated during peak periods can be effectively stored and utilized during low production periods. The integration of ML models with energy management systems also facilitates real-time adjustments to optimize the balance between energy production, storage, and consumption. Furthermore, the study highlights the potential of ML in enhancing the scalability and adaptability of HRES. By continuously learning from new data, ML models can adapt to changing environmental conditions and evolving system configurations, ensuring sustained efficiency and reliability. The application of machine learning to hybrid renewable energy systems modelling offers a transformative approach to optimizing system performance and improving energy storage solutions. This research underscores the importance of leveraging advanced ML techniques to enhance the integration and management of renewable energy sources, supporting the transition to a more sustainable and resilient energy future. 
Keywords: Energy Storage Solutions, ML, System Performance, Wind Energy Sources, Hybrid Renewable Energy System.",2023,"[{'authorId': '2309373253', 'name': 'Kelvin Edem Bassey'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.51594/estj.v4i6.1255?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.51594/estj.v4i6.1255, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the growing demand for sustainable energy solutions has spurred the development of hybrid renewable energy systems (hres), which combine multiple renewable sources like solar and wind to enhance energy reliability and efficiency. however, optimizing the performance of hres and managing energy storage remain significant challenges. this study explores the application of machine learning (ml) techniques to model hybrid renewable energy systems, integrating data from solar and wind sources to predict system performance and improve energy storage solutions. machine learning algorithms are employed to analyze large datasets generated from solar panels and wind turbines, including variables such as solar irradiance, wind speed, temperature, and historical power output. by identifying patterns and correlations within these datasets, ml models can predict the performance of the hybrid system under various environmental conditions, enabling more efficient management and utilization of renewable resources. the research focuses on the development of various ml models, including regression analysis, neural networks, and ensemble methods, to enhance the predictive accuracy of hres performance. these models are trained on extensive historical data from multiple renewable energy installations, ensuring robustness and reliability. feature selection techniques are used to identify the most significant factors affecting system performance. key findings demonstrate that ml-driven modelling significantly improves the accuracy of performance predictions for hybrid renewable energy systems. this improved predictive capability allows for better planning and optimization of energy storage solutions, ensuring that surplus energy generated during peak periods can be effectively stored and utilized during low production periods. the integration of ml models with energy management systems also facilitates real-time adjustments to optimize the balance between energy production, storage, and consumption. furthermore, the study highlights the potential of ml in enhancing the scalability and adaptability of hres. by continuously learning from new data, ml models can adapt to changing environmental conditions and evolving system configurations, ensuring sustained efficiency and reliability. the application of machine learning to hybrid renewable energy systems modelling offers a transformative approach to optimizing system performance and improving energy storage solutions. this research underscores the importance of leveraging advanced ml techniques to enhance the integration and management of renewable energy sources, supporting the transition to a more sustainable and resilient energy future. keywords: energy storage solutions, ml, system performance, wind energy sources, hybrid renewable energy system.",
bd5a7496e4ace17aec3ccdc5606f6094b5cd3d7c,Progress in Energy Storage Technologies and Methods for Renewable Energy Systems Application,"This paper provides a comprehensive review of the research progress, current state-of-the-art, and future research directions of energy storage systems. With the widespread adoption of renewable energy sources such as wind and solar power, the discourse around energy storage is primarily focused on three main aspects: battery storage technology, electricity-to-gas technology for increasing renewable energy consumption, and optimal configuration technology. The paper employs a visualization tool (CiteSpace) to analyze the existing works of literature and conducts an in-depth examination of the energy storage research hotspots in areas such as electrochemical energy storage, hydrogen storage, and optimal system configuration. It presents a detailed overview of common energy storage models and configuration methods. Based on the reviewed articles, the future development of energy storage will be more oriented toward the study of power characteristics and frequency characteristics, with more focus on the stability effects brought by transient shocks. This review article compiles and assesses various energy storage technologies for reference and future research.",2023,"[{'authorId': '1739806159', 'name': 'Pengyu Wei'}, {'authorId': '2065745664', 'name': 'M. Abid'}, {'authorId': '30948613', 'name': 'H. Adun'}, {'authorId': '2216388540', 'name': 'Desire Kemena Awoh'}, {'authorId': '8179802', 'name': 'Dongsheng Cai'}, {'authorId': '93460402', 'name': 'J. Zaini'}, {'authorId': '2138186560', 'name': 'Olusola Bamisile'}]","{'url': 'https://www.mdpi.com/2076-3417/13/9/5626/pdf?version=1683104700', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app13095626?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app13095626, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper provides a comprehensive review of the research progress, current state-of-the-art, and future research directions of energy storage systems. with the widespread adoption of renewable energy sources such as wind and solar power, the discourse around energy storage is primarily focused on three main aspects: battery storage technology, electricity-to-gas technology for increasing renewable energy consumption, and optimal configuration technology. the paper employs a visualization tool (citespace) to analyze the existing works of literature and conducts an in-depth examination of the energy storage research hotspots in areas such as electrochemical energy storage, hydrogen storage, and optimal system configuration. it presents a detailed overview of common energy storage models and configuration methods. based on the reviewed articles, the future development of energy storage will be more oriented toward the study of power characteristics and frequency characteristics, with more focus on the stability effects brought by transient shocks. this review article compiles and assesses various energy storage technologies for reference and future research.",https://www.mdpi.com/2076-3417/13/9/5626/pdf?version=1683104700
78b98fee996ca7d55aac93d10ce26b140529cf86,Renewable Energy Systems,"“The world is at a critical juncture in its energy journey. As concerns about climate change, energy security, and sustainability continue to grow, the need for renewable energy solutions has never been more pressing. This book, “Renewable Energy Systems”, aims to provide a comprehensive guide to the technologies, policies, and applications of renewable energy. From solar and wind power to hydro and geothermal energy, we explore the diverse range of options available to us. With a focus on practical applications, real-world examples, and cutting-edge research, this book seeks to equip readers with the knowledge and tools needed to navigate the transition to a more sustainable energy future. Whether you are a student, researcher, or practitioner in the field, we hope this book will inspire and empower you to be part of the solution to one of humanity’s greatest challenges.”",2024,"[{'authorId': '2315422511', 'name': 'Mr. Sachin Kumar Godara'}, {'authorId': '2315422517', 'name': 'Dr. Abdellatif M. Sadeq'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.59646/dm/244?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.59646/dm/244, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","“the world is at a critical juncture in its energy journey. as concerns about climate change, energy security, and sustainability continue to grow, the need for renewable energy solutions has never been more pressing. this book, “renewable energy systems”, aims to provide a comprehensive guide to the technologies, policies, and applications of renewable energy. from solar and wind power to hydro and geothermal energy, we explore the diverse range of options available to us. with a focus on practical applications, real-world examples, and cutting-edge research, this book seeks to equip readers with the knowledge and tools needed to navigate the transition to a more sustainable energy future. whether you are a student, researcher, or practitioner in the field, we hope this book will inspire and empower you to be part of the solution to one of humanity’s greatest challenges.”",
b09ffb4c6788fcf3441843be25f989963faaab8f,Renewable Energy Systems,"This book “Renewable Energy Systems” investigates the cutting-edge developments in renewable energy that offers broad coverage of all major renewable energy systems, resources, and related topics, such as wind turbines, solar energy, biomass, geothermal energy, water related power generation, fuel cells and generators. Students, researchers, and professionals in the subject may find this book beneficial for its detailed explanations of renewable energy technology and their uses. To improve understanding and practical application, the book provides many examples, numerical data that is up-to-date, and extensive explanations.",2024,"[{'authorId': '2313803271', 'name': 'Dr. R. Maheswaran'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.59646/res/234?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.59646/res/234, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this book “renewable energy systems” investigates the cutting-edge developments in renewable energy that offers broad coverage of all major renewable energy systems, resources, and related topics, such as wind turbines, solar energy, biomass, geothermal energy, water related power generation, fuel cells and generators. students, researchers, and professionals in the subject may find this book beneficial for its detailed explanations of renewable energy technology and their uses. to improve understanding and practical application, the book provides many examples, numerical data that is up-to-date, and extensive explanations.",
3f9eba003d1906ae0bbdf542fb75782d351cfbe9,Recent Advances of Wind-Solar Hybrid Renewable Energy Systems for Power Generation: A Review,"A hybrid renewable energy source (HRES) consists of two or more renewable energy sources, suchas wind turbines and photovoltaic systems, utilized together to provide increased system efficiency and improved stability in energy supply to a certain degree. The objective of this study is to present a comprehensive review of wind-solar HRES from the perspectives of power architectures, mathematical modeling, power electronic converter topologies, and design optimization algorithms. Since the uncertainty of HRES can be reduced further by including an energy storage system, this paper presents several hybrid energy storage system coupling technologies, highlighting their major advantages and disadvantages. Various HRES power converters and control strategies from the state-of-the-art have been discussed. Different types of energy source combinations, modeling, power converter architectures, sizing, and optimization techniques used in the existing HRES are reviewed in this work, which intends to serve as a comprehensive reference for researchers, engineers, and policymakers in this field. This article also discusses the technical challenges associated with HRES as well as the scope of future advances and research on HRES.",2022,"[{'authorId': '2008300191', 'name': 'Pranoy Roy'}, {'authorId': '145244924', 'name': 'Jiangbiao He'}, {'authorId': '2610769', 'name': 'Tiefu Zhao'}, {'authorId': '47723986', 'name': 'Y. Singh'}]","{'url': 'https://ieeexplore.ieee.org/ielx7/8782706/9667159/09684974.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ojies.2022.3144093?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ojies.2022.3144093, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a hybrid renewable energy source (hres) consists of two or more renewable energy sources, suchas wind turbines and photovoltaic systems, utilized together to provide increased system efficiency and improved stability in energy supply to a certain degree. the objective of this study is to present a comprehensive review of wind-solar hres from the perspectives of power architectures, mathematical modeling, power electronic converter topologies, and design optimization algorithms. since the uncertainty of hres can be reduced further by including an energy storage system, this paper presents several hybrid energy storage system coupling technologies, highlighting their major advantages and disadvantages. various hres power converters and control strategies from the state-of-the-art have been discussed. different types of energy source combinations, modeling, power converter architectures, sizing, and optimization techniques used in the existing hres are reviewed in this work, which intends to serve as a comprehensive reference for researchers, engineers, and policymakers in this field. this article also discusses the technical challenges associated with hres as well as the scope of future advances and research on hres.",https://ieeexplore.ieee.org/ielx7/8782706/9667159/09684974.pdf
ee7d327cbd9b8e3751b0fbd917151f7a197c169e,Planning of distributed renewable energy systems under uncertainty based on statistical machine learning,"The development of distributed renewable energy, such as photovoltaic power and wind power generation, makes the energy system cleaner, and is of great significance in reducing carbon emissions. However, weather can affect distributed renewable energy power generation, and the uncertainty of output brings challenges to uncertainty planning for distributed renewable energy. Energy systems with high penetration of distributed renewable energy involve the high-dimensional, nonlinear dynamics of large-scale complex systems, and the optimal solution of the uncertainty model is a difficult problem. From the perspective of statistical machine learning, the theory of planning of distributed renewable energy systems under uncertainty is reviewed and some key technologies are put forward for applying advanced artificial intelligence to distributed renewable power uncertainty planning.",2022,"[{'authorId': '47012496', 'name': 'Xueqian Fu'}, {'authorId': '2108404586', 'name': 'Xianping Wu'}, {'authorId': '2124626906', 'name': 'Chunyu Zhang'}, {'authorId': '2181923488', 'name': 'Shaoqian Fan'}, {'authorId': '2152355455', 'name': 'Nian Liu'}]","{'url': 'https://pcmp.springeropen.com/counter/pdf/10.1186/s41601-022-00262-x', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1186/s41601-022-00262-x?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/s41601-022-00262-x, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the development of distributed renewable energy, such as photovoltaic power and wind power generation, makes the energy system cleaner, and is of great significance in reducing carbon emissions. however, weather can affect distributed renewable energy power generation, and the uncertainty of output brings challenges to uncertainty planning for distributed renewable energy. energy systems with high penetration of distributed renewable energy involve the high-dimensional, nonlinear dynamics of large-scale complex systems, and the optimal solution of the uncertainty model is a difficult problem. from the perspective of statistical machine learning, the theory of planning of distributed renewable energy systems under uncertainty is reviewed and some key technologies are put forward for applying advanced artificial intelligence to distributed renewable power uncertainty planning.",https://pcmp.springeropen.com/counter/pdf/10.1186/s41601-022-00262-x
819e3d2139d0817c868c87e0500bda18a8528d01,System Impact Studies for Near 100% Renewable Energy Systems Dominated by Inverter Based Variable Generation,"The demand for low carbon energy calls for close to 100% renewable power systems, with decarbonization of other energy sectors adding to the anticipated paradigm shift. Rising levels of variable inverter-based renewable energy sources (VIBRES) are prompting questions about how such systems will be planned and operated when variable renewable generation becomes the dominant technology. Here, we examine the implications of this paradigm shift with respect to planning, operation and system stability, also addressing the need for integration with other energy vectors, including heat, transport and Power-to-X. We highlight the knowledge gaps and provide recommendations for improved methods and models needed as power systems transform towards 100% VIBRES.",2022,"[{'authorId': '1861743', 'name': 'H. Holttinen'}, {'authorId': '10357469', 'name': 'J. Kiviluoma'}, {'authorId': '48305861', 'name': 'D. Flynn'}, {'authorId': '2265239547', 'name': 'Charles Smith'}, {'authorId': '48738559', 'name': 'A. Orths'}, {'authorId': '49419393', 'name': 'P. B. Eriksen'}, {'authorId': '31769145', 'name': 'N. Cutululis'}, {'authorId': '2059451317', 'name': 'Lennart Soder'}, {'authorId': '3449979', 'name': 'M. Korpås'}, {'authorId': '3407747', 'name': 'A. Estanqueiro'}, {'authorId': '50296904', 'name': 'J. MacDowell'}, {'authorId': '46766914', 'name': 'A. Tuohy'}, {'authorId': '30775377', 'name': 'T. Vrana'}, {'authorId': '1400612963', 'name': 'M. O’Malley'}]","{'url': 'https://doi.org/10.1109/tpwrs.2020.3034924', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/tpwrs.2020.3034924?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/tpwrs.2020.3034924, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the demand for low carbon energy calls for close to 100% renewable power systems, with decarbonization of other energy sectors adding to the anticipated paradigm shift. rising levels of variable inverter-based renewable energy sources (vibres) are prompting questions about how such systems will be planned and operated when variable renewable generation becomes the dominant technology. here, we examine the implications of this paradigm shift with respect to planning, operation and system stability, also addressing the need for integration with other energy vectors, including heat, transport and power-to-x. we highlight the knowledge gaps and provide recommendations for improved methods and models needed as power systems transform towards 100% vibres.",https://doi.org/10.1109/tpwrs.2020.3034924
91f8ab24c05b91aa86dd860a7ade3fb909a48504,The integration of renewable energy systems in green buildings: challenges and opportunities,"The integration of renewable energy systems in green buildings represents a critical step towards achieving sustainability and reducing carbon emissions in the built environment. This paper explores the challenges and opportunities associated with incorporating renewable energy sources, such as solar, wind, geothermal, and biomass, into green building designs. While renewable energy systems offer significant environmental benefits, their implementation in green buildings faces several technical, economic, and regulatory challenges. One of the primary challenges is the high upfront cost of renewable energy technologies, which can be a barrier to adoption, particularly for small-scale projects. Additionally, the variability and intermittency of renewable energy sources, such as solar and wind, pose reliability issues, requiring effective energy storage solutions and grid integration strategies. The integration process also demands advanced technical expertise, which can be scarce in some regions, further complicating the adoption of renewable energy systems. On the other hand, the opportunities presented by the integration of renewable energy in green buildings are substantial. Renewable energy systems can drastically reduce a building’s operational carbon footprint and energy costs over time, contributing to long-term economic and environmental sustainability. The use of solar panels, wind turbines, and geothermal heat pumps in green buildings not only supports energy self-sufficiency but also aligns with global climate goals by reducing dependence on fossil fuels. Moreover, the rapid advancements in renewable energy technologies and decreasing costs are making these systems more accessible and viable for a broader range of projects. Governments and international organizations are increasingly offering incentives, subsidies, and favorable policies to encourage the adoption of renewable energy in the construction industry, further enhancing its appeal. This review highlights the dual nature of integrating renewable energy systems in green buildings, acknowledging the challenges that need to be addressed while emphasizing the immense opportunities for advancing sustainable architecture. As technology continues to evolve, the successful integration of renewable energy systems will play a pivotal role in the future of green building design, helping to achieve energy-efficient and environmentally responsible built environments. 
Keywords: Green Buildings, Opportunities, Challenges, Renewable Energy Systems, Integration.",2022,"[{'authorId': '2312809028', 'name': 'Obinna Iwuanyanwu'}, {'authorId': '2317321836', 'name': 'Ifechukwu Gil-Ozoudeh'}, {'authorId': '2312808934', 'name': 'Azubuike Chukwudi Okwandu'}, {'authorId': '2317321805', 'name': 'Chidiebere Somadina Ike'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.51594/ijarss.v4i10.1479?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.51594/ijarss.v4i10.1479, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the integration of renewable energy systems in green buildings represents a critical step towards achieving sustainability and reducing carbon emissions in the built environment. this paper explores the challenges and opportunities associated with incorporating renewable energy sources, such as solar, wind, geothermal, and biomass, into green building designs. while renewable energy systems offer significant environmental benefits, their implementation in green buildings faces several technical, economic, and regulatory challenges. one of the primary challenges is the high upfront cost of renewable energy technologies, which can be a barrier to adoption, particularly for small-scale projects. additionally, the variability and intermittency of renewable energy sources, such as solar and wind, pose reliability issues, requiring effective energy storage solutions and grid integration strategies. the integration process also demands advanced technical expertise, which can be scarce in some regions, further complicating the adoption of renewable energy systems. on the other hand, the opportunities presented by the integration of renewable energy in green buildings are substantial. renewable energy systems can drastically reduce a building’s operational carbon footprint and energy costs over time, contributing to long-term economic and environmental sustainability. the use of solar panels, wind turbines, and geothermal heat pumps in green buildings not only supports energy self-sufficiency but also aligns with global climate goals by reducing dependence on fossil fuels. moreover, the rapid advancements in renewable energy technologies and decreasing costs are making these systems more accessible and viable for a broader range of projects. governments and international organizations are increasingly offering incentives, subsidies, and favorable policies to encourage the adoption of renewable energy in the construction industry, further enhancing its appeal. this review highlights the dual nature of integrating renewable energy systems in green buildings, acknowledging the challenges that need to be addressed while emphasizing the immense opportunities for advancing sustainable architecture. as technology continues to evolve, the successful integration of renewable energy systems will play a pivotal role in the future of green building design, helping to achieve energy-efficient and environmentally responsible built environments. keywords: green buildings, opportunities, challenges, renewable energy systems, integration.",
800e0676e0450868e86703f7e301693d1bca449a,Coordinating Flexible Demand Response and Renewable Uncertainties for Scheduling of Community Integrated Energy Systems With an Electric Vehicle Charging Station: A Bi-Level Approach,"A community integrated energy system (CIES) with an electric vehicle charging station (EVCS) provides a new way for tackling growing concerns of energy efficiency and environmental pollution, it is a critical task to coordinate flexible demand response and multiple renewable uncertainties. To this end, a novel bi-level optimal dispatching model for the CIES with an EVCS in multi-stakeholder scenarios is established in this paper. In this model, an integrated demand response program is designed to promote a balance between energy supply and demand while maintaining a user comprehensive satisfaction within an acceptable range. To further tap the potential of demand response through flexibly guiding users energy consumption and electric vehicles behaviors (charging, discharging and providing spinning reserves), a dynamic pricing mechanism combining time-of-use and real-time pricing is put forward. In the solution phase, by using sequence operation theory (SOT), the original chance-constrained programming (CCP) model is converted into a readily solvable mixed-integer linear programming (MILP) formulation and finally solved by CPLEX solver. The simulation results on a practical CIES located in North China demonstrate that the presented method manages to balance the interests between CIES and EVCS via the coordination of flexible demand response and uncertain renewables.",2021,"[{'authorId': '2154901277', 'name': 'Yang Li'}, {'authorId': '2107596569', 'name': 'M. Han'}, {'authorId': '2149233646', 'name': 'Zhen Yang'}, {'authorId': '49461394', 'name': 'Guoqing Li'}]","{'url': 'http://arxiv.org/pdf/2107.07772', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2107.07772, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a community integrated energy system (cies) with an electric vehicle charging station (evcs) provides a new way for tackling growing concerns of energy efficiency and environmental pollution, it is a critical task to coordinate flexible demand response and multiple renewable uncertainties. to this end, a novel bi-level optimal dispatching model for the cies with an evcs in multi-stakeholder scenarios is established in this paper. in this model, an integrated demand response program is designed to promote a balance between energy supply and demand while maintaining a user comprehensive satisfaction within an acceptable range. to further tap the potential of demand response through flexibly guiding users energy consumption and electric vehicles behaviors (charging, discharging and providing spinning reserves), a dynamic pricing mechanism combining time-of-use and real-time pricing is put forward. in the solution phase, by using sequence operation theory (sot), the original chance-constrained programming (ccp) model is converted into a readily solvable mixed-integer linear programming (milp) formulation and finally solved by cplex solver. the simulation results on a practical cies located in north china demonstrate that the presented method manages to balance the interests between cies and evcs via the coordination of flexible demand response and uncertain renewables.",http://arxiv.org/pdf/2107.07772
01d6171fc7b0f8c25ed763235b87dfb72e189abc,Prospective Methodologies in Hybrid Renewable Energy Systems for Energy Prediction Using Artificial Neural Networks,"This paper presents a comprehensive review of machine learning (ML) based approaches, especially artificial neural networks (ANNs) in time series data prediction problems. According to literature, around 80% of the world’s total energy demand is supplied either through fuel-based sources such as oil, gas, and coal or through nuclear-based sources. Literature also shows that a shortage of fossil fuels is inevitable and the world will face this problem sooner or later. Moreover, the remote and rural areas that suffer from not being able to reach traditional grid power electricity need alternative sources of energy. A “hybrid-renewable-energy system” (HRES) involving different renewable resources can be used to supply sustainable power in these areas. The uncertain nature of renewable energy resources and the intelligent ability of the neural network approach to process complex time series inputs have inspired the use of ANN methods in renewable energy forecasting. Thus, this study aims to study the different data driven models of ANN approaches that can provide accurate predictions of renewable energy, like solar, wind, or hydro-power generation. Various refinement architectures of neural networks, such as “multi-layer perception” (MLP), “recurrent-neural network” (RNN), and “convolutional-neural network” (CNN), as well as “long-short-term memory” (LSTM) models, have been offered in the applications of renewable energy forecasting. These models are able to perform short-term time-series prediction in renewable energy sources and to use prior information that influences its value in future prediction.",2021,"[{'authorId': '2157547291', 'name': 'Mijanur Rahman'}, {'authorId': '143687273', 'name': 'Mohammad Shakeri'}, {'authorId': '46706980', 'name': 'S. Tiong'}, {'authorId': '2695459', 'name': 'F. Khatun'}, {'authorId': '145703942', 'name': 'N. Amin'}, {'authorId': '34791113', 'name': 'J. Pasupuleti'}, {'authorId': '2078333608', 'name': 'M. K. Hasan'}]","{'url': 'https://www.mdpi.com/2071-1050/13/4/2393/pdf?version=1614082617', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/SU13042393?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/SU13042393, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper presents a comprehensive review of machine learning (ml) based approaches, especially artificial neural networks (anns) in time series data prediction problems. according to literature, around 80% of the world’s total energy demand is supplied either through fuel-based sources such as oil, gas, and coal or through nuclear-based sources. literature also shows that a shortage of fossil fuels is inevitable and the world will face this problem sooner or later. moreover, the remote and rural areas that suffer from not being able to reach traditional grid power electricity need alternative sources of energy. a “hybrid-renewable-energy system” (hres) involving different renewable resources can be used to supply sustainable power in these areas. the uncertain nature of renewable energy resources and the intelligent ability of the neural network approach to process complex time series inputs have inspired the use of ann methods in renewable energy forecasting. thus, this study aims to study the different data driven models of ann approaches that can provide accurate predictions of renewable energy, like solar, wind, or hydro-power generation. various refinement architectures of neural networks, such as “multi-layer perception” (mlp), “recurrent-neural network” (rnn), and “convolutional-neural network” (cnn), as well as “long-short-term memory” (lstm) models, have been offered in the applications of renewable energy forecasting. these models are able to perform short-term time-series prediction in renewable energy sources and to use prior information that influences its value in future prediction.",https://www.mdpi.com/2071-1050/13/4/2393/pdf?version=1614082617
6a0bdeaffc7ae249faa4d698abc2078b93927cce,Optimization of the Operation and Maintenance of Renewable Energy Systems by Deep Reinforcement Learning,"Equipment of renewable energy systems are being supported by Prognostics & Health Management (PHM) capabilities to estimate their current health state and predict their Remaining Useful Life (RUL). The PHM health state estimates and RUL predictions can be used for the optimization of the systems Operation and Maintenance (O&M). This is an ambitious and challenging task, which requires to consider many factors, including the availability of maintenance crews, the variability of energy demand and production, the influence of the operating conditions on equipment performance and degradation and the long time horizons of renewable energy systems usage. We develop a novel formulation of the O&M optimization as a sequential decision problem and we resort to Deep Reinforcement Learning (DRL) to solve it. The proposed solution approach combines Proximal Policy Optimization, Imitation Learning , for pre-training the learning agent, and a model of the environment which describes the renewable energy system behavior. The solution approach is tested by its application to a wind farm O&M problem. The optimal solution found is shown to outperform those provided by other DRL algorithms. Also, the approach does not require to select a-priori a maintenance strategy, but, rather, it discovers the best performing policy by itself.",2021,"[{'authorId': '14488495', 'name': 'L. Pinciroli'}, {'authorId': '12385923', 'name': 'P. Baraldi'}, {'authorId': '2101175434', 'name': 'Guido Ballabio'}, {'authorId': '2250069', 'name': 'M. Compare'}, {'authorId': '144027144', 'name': 'E. Zio'}]","{'url': 'https://re.public.polimi.it/bitstream/11311/1195626/4/11311-1195626_Zio.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.2139/ssrn.3875191?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.2139/ssrn.3875191, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","equipment of renewable energy systems are being supported by prognostics & health management (phm) capabilities to estimate their current health state and predict their remaining useful life (rul). the phm health state estimates and rul predictions can be used for the optimization of the systems operation and maintenance (o&m). this is an ambitious and challenging task, which requires to consider many factors, including the availability of maintenance crews, the variability of energy demand and production, the influence of the operating conditions on equipment performance and degradation and the long time horizons of renewable energy systems usage. we develop a novel formulation of the o&m optimization as a sequential decision problem and we resort to deep reinforcement learning (drl) to solve it. the proposed solution approach combines proximal policy optimization, imitation learning , for pre-training the learning agent, and a model of the environment which describes the renewable energy system behavior. the solution approach is tested by its application to a wind farm o&m problem. the optimal solution found is shown to outperform those provided by other drl algorithms. also, the approach does not require to select a-priori a maintenance strategy, but, rather, it discovers the best performing policy by itself.",https://re.public.polimi.it/bitstream/11311/1195626/4/11311-1195626_Zio.pdf
6a468753932b727ddcb72212aff5e8840f4a7ac8,Hybrid Renewable Energy Systems’ Optimisation. A Review and Extended Comparison of the Most-Used Software Tools,"To help stakeholders plan, research, and develop Hybrid Renewable Energy Systems (HRES), the elaboration of numerous modelling techniques and software simulation tools has been reported. The thorough analysis of these undoubtedly complex systems is strongly correlated with the efficient utilisation of the potential of renewable energy and the meticulous development of pertinent designs. In this context, various optimisation constraints/targets have also been utilised. This specific work initially carries out a thorough review of the modelling techniques and simulation software developed in an attempt to define a commonly accepted categorisation methodology for the various existing HRES simulation methods. Moreover, the widely utilised optimisation targets are analysed in detail. Finally, it identifies the sensitivity of two commercial software tools (HOMER Pro and iHOGA) by examining nine case studies based on different wind and solar potential combinations. The results obtained by the two commercial tools are compared with the ESA Microgrid Simulator, a software developed by the Soft Energy Applications and Environmental Protection Laboratory of the Mechanical Engineering Department of the University of West Attica. The evaluation of the results, based on the diversification of the renewable energy potential used as input, has led to an in-depth assessment of the deviances detected in the software tools selected.",2021,"[{'authorId': '20807471', 'name': 'K. Kavadias'}, {'authorId': '2099347981', 'name': 'Panagiotis Triantafyllou'}]","{'url': 'https://www.mdpi.com/1996-1073/14/24/8268/pdf?version=1638967141', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/en14248268?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/en14248268, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","to help stakeholders plan, research, and develop hybrid renewable energy systems (hres), the elaboration of numerous modelling techniques and software simulation tools has been reported. the thorough analysis of these undoubtedly complex systems is strongly correlated with the efficient utilisation of the potential of renewable energy and the meticulous development of pertinent designs. in this context, various optimisation constraints/targets have also been utilised. this specific work initially carries out a thorough review of the modelling techniques and simulation software developed in an attempt to define a commonly accepted categorisation methodology for the various existing hres simulation methods. moreover, the widely utilised optimisation targets are analysed in detail. finally, it identifies the sensitivity of two commercial software tools (homer pro and ihoga) by examining nine case studies based on different wind and solar potential combinations. the results obtained by the two commercial tools are compared with the esa microgrid simulator, a software developed by the soft energy applications and environmental protection laboratory of the mechanical engineering department of the university of west attica. the evaluation of the results, based on the diversification of the renewable energy potential used as input, has led to an in-depth assessment of the deviances detected in the software tools selected.",https://www.mdpi.com/1996-1073/14/24/8268/pdf?version=1638967141
0d1e20aef4c9bce1532baedaaf0318e94463d82f,An Overview on Functional Integration of Hybrid Renewable Energy Systems in Multi-Energy Buildings,"Buildings are responsible for over 30% of global final energy consumption and nearly 40% of total CO2 emissions. Thus, rapid penetration of renewable energy technologies (RETs) in this sector is required. Integration of renewable energy sources (RESs) into residential buildings should not only guarantee an overall neutral energy balance over long term horizon (nZEB concept), but also provide a higher flexibility, a real-time monitoring and a real time interaction with end-users (smart-building concept). Thus, increasing interest is being given to the concepts of Hybrid Renewable Energy Systems (HRES) and Multi-Energy Buildings, in which several renewable and nonrenewable energy systems, the energy networks and the energy demand optimally interact with each other at various levels, exploring all possible interactions between systems and vectors (electricity, heat, cooling, fuels, transport) without them being treated separately. In this context, the present paper gives an overview of functional integration of HRES in Multi-Energy Buildings evidencing the numerous problems and potentialities related to the application of HRESs in the residential building sector. Building-integrated HRESs with at least two RESs (i.e., wind–solar, solar–geothermal and solar–biomass) are considered. The most applied HRES solutions in the residential sector are presented, and integration of HRES with thermal and electrical loads in residential buildings connected to external multiple energy grids is investigated. Attention is focused on the potentialities that functional integration can offer in terms of flexibility services to the energy grids. New holistic approaches to the management problems and more complex architectures for the optimal control are described.",2021,"[{'authorId': '80520142', 'name': 'L. Canale'}, {'authorId': '50099131', 'name': 'A. D. Di Fazio'}, {'authorId': '153404626', 'name': 'M. Russo'}, {'authorId': '40213285', 'name': 'A. Frattolillo'}, {'authorId': '1411755865', 'name': 'M. Dell’Isola'}]","{'url': 'https://www.mdpi.com/1996-1073/14/4/1078/pdf?version=1614223488', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/EN14041078?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/EN14041078, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","buildings are responsible for over 30% of global final energy consumption and nearly 40% of total co2 emissions. thus, rapid penetration of renewable energy technologies (rets) in this sector is required. integration of renewable energy sources (ress) into residential buildings should not only guarantee an overall neutral energy balance over long term horizon (nzeb concept), but also provide a higher flexibility, a real-time monitoring and a real time interaction with end-users (smart-building concept). thus, increasing interest is being given to the concepts of hybrid renewable energy systems (hres) and multi-energy buildings, in which several renewable and nonrenewable energy systems, the energy networks and the energy demand optimally interact with each other at various levels, exploring all possible interactions between systems and vectors (electricity, heat, cooling, fuels, transport) without them being treated separately. in this context, the present paper gives an overview of functional integration of hres in multi-energy buildings evidencing the numerous problems and potentialities related to the application of hress in the residential building sector. building-integrated hress with at least two ress (i.e., wind–solar, solar–geothermal and solar–biomass) are considered. the most applied hres solutions in the residential sector are presented, and integration of hres with thermal and electrical loads in residential buildings connected to external multiple energy grids is investigated. attention is focused on the potentialities that functional integration can offer in terms of flexibility services to the energy grids. new holistic approaches to the management problems and more complex architectures for the optimal control are described.",https://www.mdpi.com/1996-1073/14/4/1078/pdf?version=1614223488
eaa8c3d85346e6c8f86584e03c9c67c0d620b88d,Hybrid renewable energy systems for desalination,"Water and energy are two key factors in human life that always control the growth and development of human societies. Climate changes, increasing the population in urban areas and industrialization, have increased the demands for freshwater around the world. Estimates show that a small percentage of all freshwater produced in the world is from renewable sources. By developing the technology, lowering equipment prices and increasing attention to the environmental problems of fossil fuels, utilizing renewable energy is growing. By providing a wide variety of conventional desalination methods driven by various types of renewable energy technologies in the world, water and energy legislators should choose different methods to meet the needs based on the local potentials by paying attention to the desalination processes and power systems. In some cases, concentrated solar power for thermal desalination or electricity generated by the photovoltaic plants for membrane desalination systems can be used in arid areas. Definitely, the most problem of using renewable sources is their unsteady natures, which using storage systems or combining with other renewable sources can solve this problem. This chapter provides extensive information about renewables, desalination and performance analysis of power systems. Reverse osmosis technique is a practical process in desalination which 69% of desalination plants use this system. Solar energy is an important source of energy for hybrid systems. The geothermal has a steady performance at a specified depth. Ultimately, obtained results from energy and exergy analysis would have provided a better insight.",2020,"[{'authorId': '2106032301', 'name': 'Farbod Esmaeilion'}]","{'url': 'https://link.springer.com/content/pdf/10.1007/s13201-020-1168-5.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13201-020-1168-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13201-020-1168-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","water and energy are two key factors in human life that always control the growth and development of human societies. climate changes, increasing the population in urban areas and industrialization, have increased the demands for freshwater around the world. estimates show that a small percentage of all freshwater produced in the world is from renewable sources. by developing the technology, lowering equipment prices and increasing attention to the environmental problems of fossil fuels, utilizing renewable energy is growing. by providing a wide variety of conventional desalination methods driven by various types of renewable energy technologies in the world, water and energy legislators should choose different methods to meet the needs based on the local potentials by paying attention to the desalination processes and power systems. in some cases, concentrated solar power for thermal desalination or electricity generated by the photovoltaic plants for membrane desalination systems can be used in arid areas. definitely, the most problem of using renewable sources is their unsteady natures, which using storage systems or combining with other renewable sources can solve this problem. this chapter provides extensive information about renewables, desalination and performance analysis of power systems. reverse osmosis technique is a practical process in desalination which 69% of desalination plants use this system. solar energy is an important source of energy for hybrid systems. the geothermal has a steady performance at a specified depth. ultimately, obtained results from energy and exergy analysis would have provided a better insight.",https://link.springer.com/content/pdf/10.1007/s13201-020-1168-5.pdf
2ef7a2a33708f08ce4fbe2e076bc3e6ddfa209b0,Life Cycle Analysis of a Geothermal Power Plant: Comparison of the Environmental Performance with Other Renewable Energy Systems,"A life cycle analysis was performed for the assessment of the environmental performances of three existing Italian power plants of comparable nominal power operating with different sources of renewable energy: Geothermal, solar, and wind. Primary data were used for building the life cycle inventories. The results are characterized by employing a wide portfolio of environmental indicators employing the ReCiPe 2016 and the ILCD 2011 Midpoint+ methods; normalization and weighting are also applied using the ReCiPe 2016 method at the endpoint level. The midpoint results demonstrate a good eco-profile of the geothermal power plant compared to other renewable energy systems and a definite step forward over the performance of the national energy mix. The Eco-Point single score calculation showed that wind energy is the best technology with a value of 0.0012 Eco-points/kWh, a result in line with previously documented life cycle analysis studies. Nevertheless, the geothermal power plant achieved a value of 0.0177 Eco-points/kWh which is close to that calculated for the photovoltaic plant (0.0087 Eco-points/kWh) and much lower than the national energy mix one (0.1240 Eco-points/kWh). Also, a scenario analysis allowed for a critical discussion about potential improvements to the environmental performance of the geothermal power plant.",2020,"[{'authorId': '3169225', 'name': 'R. Basosi'}, {'authorId': '2239405829', 'name': 'Roberto Bonciani'}, {'authorId': '1658991431', 'name': 'Dario Frosali'}, {'authorId': '2703435', 'name': 'G. Manfrida'}, {'authorId': '37398998', 'name': 'M. Parisi'}, {'authorId': '48715172', 'name': 'F. Sansone'}]","{'url': 'https://www.mdpi.com/2071-1050/12/7/2786/pdf?version=1586777389', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.20944/preprints202002.0413.v1?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.20944/preprints202002.0413.v1, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a life cycle analysis was performed for the assessment of the environmental performances of three existing italian power plants of comparable nominal power operating with different sources of renewable energy: geothermal, solar, and wind. primary data were used for building the life cycle inventories. the results are characterized by employing a wide portfolio of environmental indicators employing the recipe 2016 and the ilcd 2011 midpoint+ methods; normalization and weighting are also applied using the recipe 2016 method at the endpoint level. the midpoint results demonstrate a good eco-profile of the geothermal power plant compared to other renewable energy systems and a definite step forward over the performance of the national energy mix. the eco-point single score calculation showed that wind energy is the best technology with a value of 0.0012 eco-points/kwh, a result in line with previously documented life cycle analysis studies. nevertheless, the geothermal power plant achieved a value of 0.0177 eco-points/kwh which is close to that calculated for the photovoltaic plant (0.0087 eco-points/kwh) and much lower than the national energy mix one (0.1240 eco-points/kwh). also, a scenario analysis allowed for a critical discussion about potential improvements to the environmental performance of the geothermal power plant.",https://www.mdpi.com/2071-1050/12/7/2786/pdf?version=1586777389
5d6dd1c9998356e42435247744f4315be2b338de,Ukraine Energy Sector Management Using Hybrid Renewable Energy Systems,"The Ukrainian energy sector is one of the most inflexible energy sectors in the world as a result of the almost complete depreciation of the equipment of the main sources of power supply: nuclear, thermal, and hydropower. In connection with existing problems, there is a need to develop and use new energy-saving technologies based on renewable energy sources. In this proposed research, a regression model of renewable energy growth in the energy sector of Ukraine was developed. The studied literature reveals that the independent use of individual functioning elements of renewable energy sources function as the primary power source that is not an optimal solution for stable energy supply. This study proposes the use of hybrid renewable energy systems, namely a combination of two or more renewable energy sources that will help each other to achieve higher energy efficiency, accelerate the growth of renewable energy in the share of the Ukrainian energy sector and/or improve functioning with battery energy storages. Moreover, the use of hybrid renewable energy systems in Ukraine will reduce the human impact on the environment, realize the potential of local renewable energy resources and also increase the share of electricity generation from renewable energy sources. Therefore, mechanisms for managing state regulation of stimulating the development of hybrid renewable energy systems have been developed.",2020,"[{'authorId': '1659353272', 'name': 'Oleksandr Sabishchenko'}, {'authorId': '122568243', 'name': 'Rafał Rębilas'}, {'authorId': '2725756', 'name': 'N. Sczygiol'}, {'authorId': '2024203729', 'name': 'M. Urbański'}]","{'url': 'https://www.mdpi.com/1996-1073/13/7/1776/pdf?version=1586596249', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/en13071776?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/en13071776, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the ukrainian energy sector is one of the most inflexible energy sectors in the world as a result of the almost complete depreciation of the equipment of the main sources of power supply: nuclear, thermal, and hydropower. in connection with existing problems, there is a need to develop and use new energy-saving technologies based on renewable energy sources. in this proposed research, a regression model of renewable energy growth in the energy sector of ukraine was developed. the studied literature reveals that the independent use of individual functioning elements of renewable energy sources function as the primary power source that is not an optimal solution for stable energy supply. this study proposes the use of hybrid renewable energy systems, namely a combination of two or more renewable energy sources that will help each other to achieve higher energy efficiency, accelerate the growth of renewable energy in the share of the ukrainian energy sector and/or improve functioning with battery energy storages. moreover, the use of hybrid renewable energy systems in ukraine will reduce the human impact on the environment, realize the potential of local renewable energy resources and also increase the share of electricity generation from renewable energy sources. therefore, mechanisms for managing state regulation of stimulating the development of hybrid renewable energy systems have been developed.",https://www.mdpi.com/1996-1073/13/7/1776/pdf?version=1586596249
4958b9b799c4c701414a0ccde1c1ce8a2a6b34c3,Stationary Hybrid Renewable Energy Systems for Railway Electrification: A Review,"This article provides an overview of modern technologies and implemented projects in the field of renewable energy systems for the electrification of railway transport. In the first part, the relevance of the use of renewable energy on the railways is discussed. Various types of power-generating systems in railway stations and platforms along the track, as well as in separate areas, are considered. The focus is on wind and solar energy conversion systems. The second part is devoted to the analysis of various types of energy storage devices used in projects for the electrification of railway transport since the energy storage system is one of the key elements in a hybrid renewable energy system. Systems with kinetic storage, electrochemical storage batteries, supercapacitors, hydrogen energy storage are considered. Particular attention is paid to technologies for accumulating and converting hydrogen into electrical energy, as well as hybrid systems that combine several types of storage devices with different ranges of charge/discharge rates. A comparative analysis of various hybrid electric power plant configurations, depending on the functions they perform in the electrification systems of railway transport, has been carried out.",2021,"[{'authorId': '98773659', 'name': 'S. Mitrofanov'}, {'authorId': '27099559', 'name': 'N. Kiryanova'}, {'authorId': '144642273', 'name': 'A. Gorlova'}]","{'url': 'https://www.mdpi.com/1996-1073/14/18/5946/pdf?version=1631966864', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/en14185946?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/en14185946, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this article provides an overview of modern technologies and implemented projects in the field of renewable energy systems for the electrification of railway transport. in the first part, the relevance of the use of renewable energy on the railways is discussed. various types of power-generating systems in railway stations and platforms along the track, as well as in separate areas, are considered. the focus is on wind and solar energy conversion systems. the second part is devoted to the analysis of various types of energy storage devices used in projects for the electrification of railway transport since the energy storage system is one of the key elements in a hybrid renewable energy system. systems with kinetic storage, electrochemical storage batteries, supercapacitors, hydrogen energy storage are considered. particular attention is paid to technologies for accumulating and converting hydrogen into electrical energy, as well as hybrid systems that combine several types of storage devices with different ranges of charge/discharge rates. a comparative analysis of various hybrid electric power plant configurations, depending on the functions they perform in the electrification systems of railway transport, has been carried out.",https://www.mdpi.com/1996-1073/14/18/5946/pdf?version=1631966864
bfb32c773bdffa95513bed697a7f016185ab71d6,A review of artificial intelligence-based optimization techniques for the sizing of integrated renewable energy systems in smart cities,"ABSTRACT In the Smart City, the Integrated Renewable Energy System (IRES) is playing a crucial role. Integrating the available renewable energy sources is useful in solving energy supply and demand-related issues. For a stable state of energy supply and energy demand, their proper size is needed to adapt to integrated renewable energy sources in the future. To address technical, economic and sizing problems, different algorithms needed to implement the integrated renewable energy scheme, as suggested by various authors. This paper provides a comprehensive review of various topics related to power generation for Smart City based on Integrated Renewable Energy System (IRES). It discusses in detail issues related to the integration of different energy sources, use of smart grids for integration, methods of IRES sizing using software followed by methods of sizing using artificial intelligence algorithms. This article reviews different AI algorithms that focus on the sizing of integrated renewable energy systems in smart cities. GRAPHICAL ABSTRACT",2020,"[{'authorId': '1448462628', 'name': 'Amarsingh Kanase-Patil'}, {'authorId': '9075293', 'name': 'Avinash P. Kaldate'}, {'authorId': '144546670', 'name': 'S. Lokhande'}, {'authorId': '144361482', 'name': 'H. Panchal'}, {'authorId': '145721297', 'name': 'M. Suresh'}, {'authorId': '121078632', 'name': 'V. Priya'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/21622515.2020.1836035?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/21622515.2020.1836035, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract in the smart city, the integrated renewable energy system (ires) is playing a crucial role. integrating the available renewable energy sources is useful in solving energy supply and demand-related issues. for a stable state of energy supply and energy demand, their proper size is needed to adapt to integrated renewable energy sources in the future. to address technical, economic and sizing problems, different algorithms needed to implement the integrated renewable energy scheme, as suggested by various authors. this paper provides a comprehensive review of various topics related to power generation for smart city based on integrated renewable energy system (ires). it discusses in detail issues related to the integration of different energy sources, use of smart grids for integration, methods of ires sizing using software followed by methods of sizing using artificial intelligence algorithms. this article reviews different ai algorithms that focus on the sizing of integrated renewable energy systems in smart cities. graphical abstract",
b9d8d77aa88822a667a953c4bb9dca7bd02f6187,Integrated Modelling and Enhanced Utilization of Power-to-Ammonia for High Renewable Penetrated Multi-Energy Systems,"This paper proposes an integrated model of power-to-ammonia (P2A) to exploit the inherent operational dispatchability of nitrogen-ammonia (N2-NH3) cycles for high-renewable multi-energy systems. In this model, the steady-state electrolytic processis mathematically formulated into a thermodynamic system based on thermo-electrochemical effects, and the long-term degradation process of P2A is transformed as the short-term degradation cost to characterize its cost-efficiency. Furthermore, the enhanced utilization of P2A is explored to form a renewable energy hubfor coupled multi-energy supplies, and a coupling matrix is formulated for the optimal synergies of electrical, ammonia and thermal energy carriers. An iterative solution approach is furtherdeveloped to schedule the hub-internal multi-energy conversion and storage devices for high-efficiency utilization of available hybrid solar-wind renewables. Numerical studies on a stand-alone microgrid over a 24-hour scheduling periods are presented to confirm the effectiveness and superiority of the proposed methodology over regularbattery and power-to-gas (P2G) storages on system operational economy and renewable energy accommodation.",2020,"[{'authorId': '144226816', 'name': 'Da Xu'}, {'authorId': '1740033', 'name': 'Bin Zhou'}, {'authorId': '145685218', 'name': 'Qiuwei Wu'}, {'authorId': '144746327', 'name': 'C. Chung'}, {'authorId': '38184885', 'name': 'Canbing Li'}, {'authorId': '1563750939', 'name': 'Sheng Huang'}, {'authorId': '2118528553', 'name': 'She Chen'}]","{'url': 'https://backend.orbit.dtu.dk/ws/files/210448886/TPWRS_01889_2019_FINAL_VERSION.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TPWRS.2020.2989533?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TPWRS.2020.2989533, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper proposes an integrated model of power-to-ammonia (p2a) to exploit the inherent operational dispatchability of nitrogen-ammonia (n2-nh3) cycles for high-renewable multi-energy systems. in this model, the steady-state electrolytic processis mathematically formulated into a thermodynamic system based on thermo-electrochemical effects, and the long-term degradation process of p2a is transformed as the short-term degradation cost to characterize its cost-efficiency. furthermore, the enhanced utilization of p2a is explored to form a renewable energy hubfor coupled multi-energy supplies, and a coupling matrix is formulated for the optimal synergies of electrical, ammonia and thermal energy carriers. an iterative solution approach is furtherdeveloped to schedule the hub-internal multi-energy conversion and storage devices for high-efficiency utilization of available hybrid solar-wind renewables. numerical studies on a stand-alone microgrid over a 24-hour scheduling periods are presented to confirm the effectiveness and superiority of the proposed methodology over regularbattery and power-to-gas (p2g) storages on system operational economy and renewable energy accommodation.",https://backend.orbit.dtu.dk/ws/files/210448886/TPWRS_01889_2019_FINAL_VERSION.pdf
7305846ce26f6e105be00d66fa3bfe2b3d519cbe,Optimal Configuration Planning of Multi-Energy Systems Considering Distributed Renewable Energy,"Multi-energy systems (MESs) contribute to increasing energy utilization efficiency and renewable energy accommodation by coupling multiple energy sectors. The preferable characteristic of MESs raises the need for optimizing the configuration of MESs across multiple energy sectors at the planning stage. Based on the energy hub (EH) model, this research presents a two-stage mixed-integer linear programming approach for district level MES planning considering distributed renewable energy integration. The approach models an MES as a directed acyclic graph with multiple layers. The proposed EH configuration planning procedure includes two stages: 1) optimizing what equipment (e.g., energy converters, distributed renewable energy sources and storages) should be invested in for each layer and 2) optimizing the connection relationships between the invested equipment in each two adjacent layers. The proposed approach is able to optimize both the equipment selection and the MES configuration. It can be applied to both expansion planning and initial planning of MESs from scratch. An illustrative example of planning a typical MES is given. A sensitivity analysis is performed to show the impacts of load profiles, energy prices and equipment parameters on the optimal MES configuration. A case study based on the MES in Beijing's new subsidiary administrative center is conducted using the proposed approach.",2019,"[{'authorId': '9393379', 'name': 'Wujing Huang'}, {'authorId': '46389006', 'name': 'Ning Zhang'}, {'authorId': '2121258902', 'name': 'Jingwei Yang'}, {'authorId': '2154457922', 'name': 'Yi Wang'}, {'authorId': '144437283', 'name': 'C. Kang'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/PESGM40551.2019.8973885?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/PESGM40551.2019.8973885, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","multi-energy systems (mess) contribute to increasing energy utilization efficiency and renewable energy accommodation by coupling multiple energy sectors. the preferable characteristic of mess raises the need for optimizing the configuration of mess across multiple energy sectors at the planning stage. based on the energy hub (eh) model, this research presents a two-stage mixed-integer linear programming approach for district level mes planning considering distributed renewable energy integration. the approach models an mes as a directed acyclic graph with multiple layers. the proposed eh configuration planning procedure includes two stages: 1) optimizing what equipment (e.g., energy converters, distributed renewable energy sources and storages) should be invested in for each layer and 2) optimizing the connection relationships between the invested equipment in each two adjacent layers. the proposed approach is able to optimize both the equipment selection and the mes configuration. it can be applied to both expansion planning and initial planning of mess from scratch. an illustrative example of planning a typical mes is given. a sensitivity analysis is performed to show the impacts of load profiles, energy prices and equipment parameters on the optimal mes configuration. a case study based on the mes in beijing's new subsidiary administrative center is conducted using the proposed approach.",
9ee99e491c9bf4731a0c96a49bb280875491d877,Reimagining future energy systems: Overview of the US program to maximize energy utilization via integrated nuclear‐renewable energy systems,"A sustainable, balanced energy portfolio is necessary for a country's continued economic growth. This portfolio must collectively be able to provide reliable, resilient electricity at stable, affordable prices. Nuclear energy is an important contributor to global clean energy supply, both as a primary source and by complementing and enabling other clean energy sources. As we look to the design and operation of future energy systems, we see an increasing need to think differently about how we utilize our energy resources to meet all of our energy needs—not just electricity but also industrial and transportation demands. Resource utilization in light of a broader desire to reduce environmental impacts leads us to consider transforming how we use nuclear energy, which currently provides more than half of the nonemitting electricity generated in the United States. A paradigm shift is required to develop optimal energy generation and use configurations that embrace novel approaches to system integration and process design. The US Department of Energy (DOE) Office of Nuclear Energy (NE) program on Integrated Energy Systems (IES)—formerly the Nuclear‐Renewable Hybrid Energy Systems (N‐R HES) program—was established to evaluate potential options for the coordinated use of nuclear and renewable energy generators to meet energy demands across the electricity, industrial, and transportation sectors. These formerly independent sectors are becoming increasingly linked through technology advances in data acquisition, communications, demand response approaches, and control technologies. Advanced modeling and simulation tools can be employed to design systems that better coordinate across these sectors. Implementation of integrated multi‐input, multi‐output energy systems will allow for expanded use of nuclear energy beyond the grid in a manner that complements the increased build‐out of variable renewable energy generation. These integrated systems would provide enhanced flexibility while also providing energy services and supporting the production of additional, nonelectric commodities (eg, potable water, hydrogen, and liquid fuels) via excess thermal and electrical energy from the nuclear system. Increased flexibility of traditionally baseload nuclear systems will support energy security, grid reliability, and grid resilience while maximizing the use of clean energy technologies. This paper provides an overview of current efforts in the United States that assess the potential to increase utilization of nuclear energy systems, in concert with renewable energy generation, via the IES program. Analysis tools and approaches and preliminary analysis results are summarized, and planned experimental activities to demonstrate integrated system performance are introduced.",2020,"[{'authorId': '1403654009', 'name': 'S. Bragg‐Sitton'}, {'authorId': '47962089', 'name': 'R. Boardman'}, {'authorId': '3397946', 'name': 'C. Rabiti'}, {'authorId': '1394768091', 'name': ""J. O'Brien""}]","{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/er.5207', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/er.5207?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/er.5207, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","a sustainable, balanced energy portfolio is necessary for a country's continued economic growth. this portfolio must collectively be able to provide reliable, resilient electricity at stable, affordable prices. nuclear energy is an important contributor to global clean energy supply, both as a primary source and by complementing and enabling other clean energy sources. as we look to the design and operation of future energy systems, we see an increasing need to think differently about how we utilize our energy resources to meet all of our energy needs—not just electricity but also industrial and transportation demands. resource utilization in light of a broader desire to reduce environmental impacts leads us to consider transforming how we use nuclear energy, which currently provides more than half of the nonemitting electricity generated in the united states. a paradigm shift is required to develop optimal energy generation and use configurations that embrace novel approaches to system integration and process design. the us department of energy (doe) office of nuclear energy (ne) program on integrated energy systems (ies)—formerly the nuclear‐renewable hybrid energy systems (n‐r hes) program—was established to evaluate potential options for the coordinated use of nuclear and renewable energy generators to meet energy demands across the electricity, industrial, and transportation sectors. these formerly independent sectors are becoming increasingly linked through technology advances in data acquisition, communications, demand response approaches, and control technologies. advanced modeling and simulation tools can be employed to design systems that better coordinate across these sectors. implementation of integrated multi‐input, multi‐output energy systems will allow for expanded use of nuclear energy beyond the grid in a manner that complements the increased build‐out of variable renewable energy generation. these integrated systems would provide enhanced flexibility while also providing energy services and supporting the production of additional, nonelectric commodities (eg, potable water, hydrogen, and liquid fuels) via excess thermal and electrical energy from the nuclear system. increased flexibility of traditionally baseload nuclear systems will support energy security, grid reliability, and grid resilience while maximizing the use of clean energy technologies. this paper provides an overview of current efforts in the united states that assess the potential to increase utilization of nuclear energy systems, in concert with renewable energy generation, via the ies program. analysis tools and approaches and preliminary analysis results are summarized, and planned experimental activities to demonstrate integrated system performance are introduced.",https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/er.5207
02762ac9d01501c74f2ffae631e729df0ac1b347,Sustainable Development using renewable energy systems,"This editorial introduces the main findings from the 29th Volume of the International Journal of Sustainable Energy Planning and Management. The issue includes both contributions to the 2019 Sustainable Development of Energy Water and Environmental Systems conference and ordinary journal submissions. In either case, the research is centred on sustainable development using renewable energy systems – with particular attention to technology assessment, pricing & regulation and systems analyses. Case studies and model development from Austria, Cape Verde, Columbia, and Iran are presented – with varying focal points. Different drive trains for the electrification of the transportation sector are assessed. Lastly, pricing regimes for evolving district heating systems as well as consumer involvement in 4th generation district heating and social factors for implementing building energy conservation policy are considered",2020,"[{'authorId': '67052766', 'name': 'P. A. Østergaard'}, {'authorId': '1573577010', 'name': 'R. Johannsen'}, {'authorId': '13151895', 'name': 'N. Duić'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.5278/IJSEPM.4302?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5278/IJSEPM.4302, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this editorial introduces the main findings from the 29th volume of the international journal of sustainable energy planning and management. the issue includes both contributions to the 2019 sustainable development of energy water and environmental systems conference and ordinary journal submissions. in either case, the research is centred on sustainable development using renewable energy systems – with particular attention to technology assessment, pricing & regulation and systems analyses. case studies and model development from austria, cape verde, columbia, and iran are presented – with varying focal points. different drive trains for the electrification of the transportation sector are assessed. lastly, pricing regimes for evolving district heating systems as well as consumer involvement in 4th generation district heating and social factors for implementing building energy conservation policy are considered",
7a834d88fa81f0da2dd8c31709a08c1b68339774,A new perspective on global renewable energy systems: why trade in energy carriers matters,"Recent global modelling studies suggest a decline of long-distance trade in energy carriers in future global renewable energy systems, compared to today’s fossil fuel energy system. In contrast, we identified four crucial drivers that enable trade of renewable energy carriers. These drivers could make trade remain at current levels or even increase during the transition to an energy system with very high shares of renewables. First, new land-efficient technologies for renewable fuel production become increasingly available and technically allow for long-distance trade in renewables. Second, regional differences in social acceptance and land availability for energy infrastructure support the development of renewable fuel import and export streams. Third, the economics of renewable energy systems, i.e. the different production conditions globally and the high costs of fully renewable regional electricity systems, will create opportunities for spatial arbitrage. Fourth, the reduction of stranded investments in the fossil fuel sector is possible by switching from fossil fuel to renewable fuel trade in exporting regions.The impact of these drivers on trade in energy carriers is currently under-investigated by the global energy research community. Therefore, we call for a major research effort in this field, in particular as trade can redistribute profits and losses of climate change mitigation and may hence support finding new partners in climate change mitigation negotiations.",2019,"[{'authorId': '2149995834', 'name': 'Johannes Schmidt'}, {'authorId': '47387874', 'name': 'Katharina Gruber'}, {'authorId': '47277202', 'name': 'M. Klingler'}, {'authorId': '101607429', 'name': 'Claude Klöckl'}, {'authorId': '134327408', 'name': 'L. Ramirez Camargo'}, {'authorId': '3351462', 'name': 'P. Regner'}, {'authorId': '8382510', 'name': 'O. Turkovska'}, {'authorId': '12380136', 'name': 'Sebastian Wehrle'}, {'authorId': '13273204', 'name': 'Elisabeth Wetterlund'}]","{'url': 'https://pubs.rsc.org/en/content/articlepdf/2019/ee/c9ee00223e', 'status': 'GREEN', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1039/C9EE00223E?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1039/C9EE00223E, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","recent global modelling studies suggest a decline of long-distance trade in energy carriers in future global renewable energy systems, compared to today’s fossil fuel energy system. in contrast, we identified four crucial drivers that enable trade of renewable energy carriers. these drivers could make trade remain at current levels or even increase during the transition to an energy system with very high shares of renewables. first, new land-efficient technologies for renewable fuel production become increasingly available and technically allow for long-distance trade in renewables. second, regional differences in social acceptance and land availability for energy infrastructure support the development of renewable fuel import and export streams. third, the economics of renewable energy systems, i.e. the different production conditions globally and the high costs of fully renewable regional electricity systems, will create opportunities for spatial arbitrage. fourth, the reduction of stranded investments in the fossil fuel sector is possible by switching from fossil fuel to renewable fuel trade in exporting regions.the impact of these drivers on trade in energy carriers is currently under-investigated by the global energy research community. therefore, we call for a major research effort in this field, in particular as trade can redistribute profits and losses of climate change mitigation and may hence support finding new partners in climate change mitigation negotiations.",https://pubs.rsc.org/en/content/articlepdf/2019/ee/c9ee00223e
902c9d193ca70ff3f82c9f956f3d514ebafbdf04,Power Semiconductor Devices for Smart Grid and Renewable Energy Systems,"Modern civilization is related to the increased use of electric energy for industry production, human mobility, and comfortable living. Highly efficient and reliable power electronic systems, which convert and process electric energy from one form to the other, are critical for smart grid and renewable energy systems. The power semiconductor device, as the cornerstone technology in a power electronics system, plays a pivotal role in determining the system efficiency, size, and cost. Starting from the invention and commercialization of silicon bipolar junction transistor 60 years ago, a whole array of silicon power semiconductor devices have been developed and commercialized. These devices enable power electronics systems to reach ultrahigh efficiency and high-power capacity needed for various smart grid and renewable energy system applications such as photovoltaic (PV), wind, energy storage, electric vehicle (EV), flexible ac transmission system (FACTS), and high voltage dc (HVDC) transmission. In the last two decades, newer generations of power semiconductor devices based on wide bandgap (WBG) materials, such as SiC and GaN, were developed and commercialized further pushing the boundary of power semiconductor devices to higher voltages, higher frequencies, and higher temperatures. This paper reviews some of the major power semiconductor devices technologies and their potential impacts and roadmaps.",2017,"[{'authorId': '2826163', 'name': 'A. Huang'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JPROC.2017.2687701?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JPROC.2017.2687701, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","modern civilization is related to the increased use of electric energy for industry production, human mobility, and comfortable living. highly efficient and reliable power electronic systems, which convert and process electric energy from one form to the other, are critical for smart grid and renewable energy systems. the power semiconductor device, as the cornerstone technology in a power electronics system, plays a pivotal role in determining the system efficiency, size, and cost. starting from the invention and commercialization of silicon bipolar junction transistor 60 years ago, a whole array of silicon power semiconductor devices have been developed and commercialized. these devices enable power electronics systems to reach ultrahigh efficiency and high-power capacity needed for various smart grid and renewable energy system applications such as photovoltaic (pv), wind, energy storage, electric vehicle (ev), flexible ac transmission system (facts), and high voltage dc (hvdc) transmission. in the last two decades, newer generations of power semiconductor devices based on wide bandgap (wbg) materials, such as sic and gan, were developed and commercialized further pushing the boundary of power semiconductor devices to higher voltages, higher frequencies, and higher temperatures. this paper reviews some of the major power semiconductor devices technologies and their potential impacts and roadmaps.",
c237ff07dd5fee335df0ebf9a362d5b7baa0ca2e,"Multi-criteria optimal sizing of hybrid renewable energy systems including wind, photovoltaic, battery, and hydrogen storage with ɛ-constraint method","Hybrid renewable energy systems (HRES) should be designed appropriately with an adequate combination of different renewable sources and various energy storage methods to overcome the problem of intermittency of renewable energy resources. A multi-criteria approach is proposed in this study to design an HRES including wind turbine, photovoltaic panels, fuel cell, electrolyser, hydrogen tank, and battery storage unit with an intermittent load. Three design criteria including loss of power supply probability, total energy loss (TEL), and the power difference between generation and storing capacity (as TELSUB) are taken into account in minimising the total cost of the system considering the interest rate and lifetime. The justifications and advantages of using these criteria are thoroughly discussed along with appropriate presentation of the results. The purpose of considering TEL and TELSUB is discussed thoroughly. The e-constraint method is used to handle practical constraints of the proposed multi-criteria problem to construct a multi-objective fitness function. Shuffled frog leaping algorithm is implemented to achieve better optimal results. The proposed approach is implemented using real wind speed and solar irradiance data for a specific location with an intermittent load demand. The results verify performance of the proposed multi-criteria design procedure.",2018,"[{'authorId': '32508401', 'name': 'H. Bakhtiari'}, {'authorId': '3323909', 'name': 'R. Naghizadeh'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1049/IET-RPG.2017.0706?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1049/IET-RPG.2017.0706, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","hybrid renewable energy systems (hres) should be designed appropriately with an adequate combination of different renewable sources and various energy storage methods to overcome the problem of intermittency of renewable energy resources. a multi-criteria approach is proposed in this study to design an hres including wind turbine, photovoltaic panels, fuel cell, electrolyser, hydrogen tank, and battery storage unit with an intermittent load. three design criteria including loss of power supply probability, total energy loss (tel), and the power difference between generation and storing capacity (as telsub) are taken into account in minimising the total cost of the system considering the interest rate and lifetime. the justifications and advantages of using these criteria are thoroughly discussed along with appropriate presentation of the results. the purpose of considering tel and telsub is discussed thoroughly. the e-constraint method is used to handle practical constraints of the proposed multi-criteria problem to construct a multi-objective fitness function. shuffled frog leaping algorithm is implemented to achieve better optimal results. the proposed approach is implemented using real wind speed and solar irradiance data for a specific location with an intermittent load demand. the results verify performance of the proposed multi-criteria design procedure.",
0a7a84bddb48aec20ac647b0ea4688df441fee47,A Review on Battery Charging and Discharging Control Strategies: Application to Renewable Energy Systems,"Energy storage has become a fundamental component in renewable energy systems, especially those including batteries. However, in charging and discharging processes, some of the parameters are not controlled by the battery’s user. That uncontrolled working leads to aging of the batteries and a reduction of their life cycle. Therefore, it causes an early replacement. Development of control methods seeks battery protection and a longer life expectancy, thus the constant-current–constant-voltage method is mostly used. However, several studies show that charging time can be reduced by using fuzzy logic control or model predictive control. Another benefit is temperature control. This paper reviews the existing control methods used to control charging and discharging processes, focusing on their impacts on battery life. Classical and modern methods are studied together in order to find the best approach to real systems.",2018,"[{'authorId': '30533673', 'name': 'E. Banguero'}, {'authorId': '6459671', 'name': 'A. Correcher'}, {'authorId': '10709054', 'name': 'Á. Navarro'}, {'authorId': '145952862', 'name': 'F. Morant'}, {'authorId': '2261797541', 'name': 'Andrés Aristizabal'}]","{'url': 'https://www.mdpi.com/1996-1073/11/4/1021/pdf?version=1525349571', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/EN11041021?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/EN11041021, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","energy storage has become a fundamental component in renewable energy systems, especially those including batteries. however, in charging and discharging processes, some of the parameters are not controlled by the battery’s user. that uncontrolled working leads to aging of the batteries and a reduction of their life cycle. therefore, it causes an early replacement. development of control methods seeks battery protection and a longer life expectancy, thus the constant-current–constant-voltage method is mostly used. however, several studies show that charging time can be reduced by using fuzzy logic control or model predictive control. another benefit is temperature control. this paper reviews the existing control methods used to control charging and discharging processes, focusing on their impacts on battery life. classical and modern methods are studied together in order to find the best approach to real systems.",https://www.mdpi.com/1996-1073/11/4/1021/pdf?version=1525349571
ac6331fc990e6192dd35db5101b7c6a40f3c5d95,A novel framework-based cuckoo search algorithm for sizing and optimization of grid-independent hybrid renewable energy systems,"ABSTRACT Hybrid renewable energy systems (HRES) turned into an appealing choice for supplying loads in remote areas. The application of smart grid principals in HRES provides a communication between the load and generation from the HRES. Using smart grid in the HRES will optimally utilize the generating resources to reschedule the loads depending on its importance. This paper presents a new proposed design and optimization simulation program for techno-economic sizing of grid-independent hybrid PV/wind/diesel/battery energy system using Cuckoo search (CS) optimization algorithm. Using of CS will help to get the global minimum cost condition and prevent the simulation to be stuck around local minimum. A new proposed simulation program (NPSP) is acquainted using CS to determine the optimum size of each component of the HRES for the lowest cost of generated energy and the lowest value of dummy energy, at highest reliability. A detailed economic methodology to obtain the price of the generated energy has been introduced. Results showed that using CS reduced the time required to obtain the optimal size with higher accuracy than other techniques used iterative techniques, Genetic Algorithm (GA), and Particle Swarm Optimization (PSO). Numerous significant outcomes can be extracted from the proposed program that could help scientists and decision makers.",2018,"[{'authorId': '144816554', 'name': 'M. A. Mohamed'}, {'authorId': '144816554', 'name': 'M. A. Mohamed'}, {'authorId': '49264644', 'name': 'A. Eltamaly'}, {'authorId': '49264644', 'name': 'A. Eltamaly'}, {'authorId': '2104329', 'name': 'A. Alolah'}, {'authorId': '1411407389', 'name': 'A. Hatata'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1080/15435075.2018.1533837?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/15435075.2018.1533837, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","abstract hybrid renewable energy systems (hres) turned into an appealing choice for supplying loads in remote areas. the application of smart grid principals in hres provides a communication between the load and generation from the hres. using smart grid in the hres will optimally utilize the generating resources to reschedule the loads depending on its importance. this paper presents a new proposed design and optimization simulation program for techno-economic sizing of grid-independent hybrid pv/wind/diesel/battery energy system using cuckoo search (cs) optimization algorithm. using of cs will help to get the global minimum cost condition and prevent the simulation to be stuck around local minimum. a new proposed simulation program (npsp) is acquainted using cs to determine the optimum size of each component of the hres for the lowest cost of generated energy and the lowest value of dummy energy, at highest reliability. a detailed economic methodology to obtain the price of the generated energy has been introduced. results showed that using cs reduced the time required to obtain the optimal size with higher accuracy than other techniques used iterative techniques, genetic algorithm (ga), and particle swarm optimization (pso). numerous significant outcomes can be extracted from the proposed program that could help scientists and decision makers.",
bcfb2b49e94018d48d85217f17d6f0773ee5a930,Matching decentralized energy production and local consumption: A review of renewable energy systems with conversion and storage technologies,"The increasing share of decentralized intermittent renewable energy reinforces the necessity of balancing local production and consumption. Decentralized energy systems, powered by renewable energy technologies and incorporating storage and conversion technologies, are promising options to cope with this challenge. Many studies have evaluated their potential contributions, but an overview of the status‐quo in both academia and practice is missing. The extant literature lacks a comprehensive review of the scientific knowledge on decentralized energy systems, partially attributed to the lack of common terminology. Additionally, it remains unclear what kind of systems are already implemented today worldwide as they have not yet been thoroughly analyzed and described. However, pilot projects provide valuable insights into future applications and operational aspects. To fill these gaps, an extensive review of the current state of literature and practice is conducted. To do so, 64 publications and 56 projects were analyzed and an overview is provided using four criteria: terminology, scope/motivation, application, and technical configuration. These criteria facilitate the understanding of decentralized energy systems needed to spur their development and diffusion. Further advancements of research and practice are discussed. For example, technological learning hinges on a common terminology and on an identification of optimal technical configurations per application. There are both avenues for future research.",2019,"[{'authorId': '35454879', 'name': 'David Grosspietsch'}, {'authorId': '2066479676', 'name': 'M. Saenger'}, {'authorId': '35153964', 'name': 'B. Girod'}]","{'url': 'https://www.research-collection.ethz.ch/bitstream/20.500.11850/349190/5/AAM_Grosspietsch_et_al_2019.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/wene.336?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/wene.336, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the increasing share of decentralized intermittent renewable energy reinforces the necessity of balancing local production and consumption. decentralized energy systems, powered by renewable energy technologies and incorporating storage and conversion technologies, are promising options to cope with this challenge. many studies have evaluated their potential contributions, but an overview of the status‐quo in both academia and practice is missing. the extant literature lacks a comprehensive review of the scientific knowledge on decentralized energy systems, partially attributed to the lack of common terminology. additionally, it remains unclear what kind of systems are already implemented today worldwide as they have not yet been thoroughly analyzed and described. however, pilot projects provide valuable insights into future applications and operational aspects. to fill these gaps, an extensive review of the current state of literature and practice is conducted. to do so, 64 publications and 56 projects were analyzed and an overview is provided using four criteria: terminology, scope/motivation, application, and technical configuration. these criteria facilitate the understanding of decentralized energy systems needed to spur their development and diffusion. further advancements of research and practice are discussed. for example, technological learning hinges on a common terminology and on an identification of optimal technical configurations per application. there are both avenues for future research.",https://www.research-collection.ethz.ch/bitstream/20.500.11850/349190/5/AAM_Grosspietsch_et_al_2019.pdf
5b13fe4347fa4b06cd607fdc10ff3b08fe6d856a,Selection of a Hybrid Renewable Energy Systems for a Low-Income Household,"The use of a single criterion in the selection of the most suitable hybrid renewable energy system (HRES) has been reported to be inadequate in terms of sustainability. In order to fill this gap, this study presents a multi-criteria approach for the selection of HRES for a typical low-income household. The analysis is based on two energy demand scenarios viz: consumer demand based on energy efficient equipment (EET) and consumer energy demand without energy efficiency. The optimization of the HRES is performed using hybrid optimization of multiple energy renewables (HOMER) while the multi-criteria analysis is carried out using Criteria Importance Through Intercriteria Correlation (CRITIC) and the Technique for Order of Preference by Similarity to the Ideal Solution (TOPSIS). Results show that the optimal HRES alternative returned based on both energy demand scenarios is a PV/GEN/BAT system. The analysis further shows that a reduction of 44.6% in energy demand through EET leads to: 51.38% decrease in total net present cost, 11.90% decrease in cost of energy, 96.61% decrease in CO 2 emission and 193.94% increase in renewable fraction. Furthermore, the use of multi-criteria approach for HRES selection has an influence in the selection and ranking of the most suitable HRES alternatives. Overall, the application of EETs is environmentally and economically beneficial while the application of MCDM can help decision makers make a comprehensively informed decision on the selection of the most suitable HRES.",2019,"[{'authorId': '94982762', 'name': 'O. Babatunde'}, {'authorId': '3126927', 'name': 'J. Munda'}, {'authorId': '47675606', 'name': 'Y. Hamam'}]","{'url': 'https://www.mdpi.com/2071-1050/11/16/4282/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/SU11164282?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/SU11164282, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the use of a single criterion in the selection of the most suitable hybrid renewable energy system (hres) has been reported to be inadequate in terms of sustainability. in order to fill this gap, this study presents a multi-criteria approach for the selection of hres for a typical low-income household. the analysis is based on two energy demand scenarios viz: consumer demand based on energy efficient equipment (eet) and consumer energy demand without energy efficiency. the optimization of the hres is performed using hybrid optimization of multiple energy renewables (homer) while the multi-criteria analysis is carried out using criteria importance through intercriteria correlation (critic) and the technique for order of preference by similarity to the ideal solution (topsis). results show that the optimal hres alternative returned based on both energy demand scenarios is a pv/gen/bat system. the analysis further shows that a reduction of 44.6% in energy demand through eet leads to: 51.38% decrease in total net present cost, 11.90% decrease in cost of energy, 96.61% decrease in co 2 emission and 193.94% increase in renewable fraction. furthermore, the use of multi-criteria approach for hres selection has an influence in the selection and ranking of the most suitable hres alternatives. overall, the application of eets is environmentally and economically beneficial while the application of mcdm can help decision makers make a comprehensively informed decision on the selection of the most suitable hres.",https://www.mdpi.com/2071-1050/11/16/4282/pdf
0f81ec02787d8dc41c3d32e3aec0d15cfbe91dfb,A review of algorithms for control and optimization for energy management of hybrid renewable energy systems,"Hybrid renewable energy systems (HRESs) can alleviate the grid dependence for power in rural and distant locations. The intermittent nature of renewable energy sources acting alone does not make the system reliable; however, combining one or more sources (like solar, wind, diesel, biomass, micro-hydel, etc.) with adequate storage options or intelligent control of hybrid systems ensures power availability to the end user. As a result, it is imperative that the technical aspects of such a hybrid system can be analyzed with respect to optimal sizing of sources, proper control design and mechanism for energy management, and adequate backup via the storage option that ascertain reliable power supply to the consumer/end user or at the distributed generation end. This paper presents an overview of the applications of Genetic Algorithms, Fuzzy logic, Particle Swarm optimization, and similar other evolutionary and nature inspired algorithms that have been employed for the optimization, control, and power management strategies for renewable energy studies involving hybrid power generation schemes. Analysis of the algorithms and the potential applications of new improved algorithms for optimization, control, and power management of HRES is discussed and reported.Hybrid renewable energy systems (HRESs) can alleviate the grid dependence for power in rural and distant locations. The intermittent nature of renewable energy sources acting alone does not make the system reliable; however, combining one or more sources (like solar, wind, diesel, biomass, micro-hydel, etc.) with adequate storage options or intelligent control of hybrid systems ensures power availability to the end user. As a result, it is imperative that the technical aspects of such a hybrid system can be analyzed with respect to optimal sizing of sources, proper control design and mechanism for energy management, and adequate backup via the storage option that ascertain reliable power supply to the consumer/end user or at the distributed generation end. This paper presents an overview of the applications of Genetic Algorithms, Fuzzy logic, Particle Swarm optimization, and similar other evolutionary and nature inspired algorithms that have been employed for the optimization, control, and power managemen...",2018,"[{'authorId': '5864898', 'name': 'Barnam Jyoti Saharia'}, {'authorId': '82979234', 'name': 'H. Brahma'}, {'authorId': '39846036', 'name': 'N. Sarmah'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1063/1.5032146?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1063/1.5032146, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","hybrid renewable energy systems (hress) can alleviate the grid dependence for power in rural and distant locations. the intermittent nature of renewable energy sources acting alone does not make the system reliable; however, combining one or more sources (like solar, wind, diesel, biomass, micro-hydel, etc.) with adequate storage options or intelligent control of hybrid systems ensures power availability to the end user. as a result, it is imperative that the technical aspects of such a hybrid system can be analyzed with respect to optimal sizing of sources, proper control design and mechanism for energy management, and adequate backup via the storage option that ascertain reliable power supply to the consumer/end user or at the distributed generation end. this paper presents an overview of the applications of genetic algorithms, fuzzy logic, particle swarm optimization, and similar other evolutionary and nature inspired algorithms that have been employed for the optimization, control, and power management strategies for renewable energy studies involving hybrid power generation schemes. analysis of the algorithms and the potential applications of new improved algorithms for optimization, control, and power management of hres is discussed and reported.hybrid renewable energy systems (hress) can alleviate the grid dependence for power in rural and distant locations. the intermittent nature of renewable energy sources acting alone does not make the system reliable; however, combining one or more sources (like solar, wind, diesel, biomass, micro-hydel, etc.) with adequate storage options or intelligent control of hybrid systems ensures power availability to the end user. as a result, it is imperative that the technical aspects of such a hybrid system can be analyzed with respect to optimal sizing of sources, proper control design and mechanism for energy management, and adequate backup via the storage option that ascertain reliable power supply to the consumer/end user or at the distributed generation end. this paper presents an overview of the applications of genetic algorithms, fuzzy logic, particle swarm optimization, and similar other evolutionary and nature inspired algorithms that have been employed for the optimization, control, and power managemen...",
d4b4d64ae0b68406407606e6dfe36fc5b45538ab,Carbon Reduction Measures-Based LCA of Prefabricated Temporary Housing with Renewable Energy Systems,"Temporary housing plays an important role in providing secure, hygienic, private, and comfortable shelter in the aftermath of disaster (such as flood, fire, earthquake, etc.). Additionally, temporary housing can also be used as a sustainable form of on-site residences for construction workers. While most of the building components used in temporary housing can be manufactured in a plant, prefabrication technology improves the production efficiency of temporary housing; furthermore, integrated renewable energy systems, for example, solar photovoltaic (PV) system, offer benefits for temporary housing operations. In order to assess the environmental impacts of prefabricated temporary housing equipped with renewable energy systems, this study first divides the life cycle of temporary housing into six stages, and then establishes a life cycle assessment (LCA) model for each stage. Furthermore, with the aim of reducing the environmental impacts, life cycle carbon reduction measures are proposed for each stage of temporary housing. The proposed methodology is demonstrated using a case study in China. Based on the proposed carbon reduction measures, the LCA of a prefabricated temporary housing case study building equipped with renewable energy systems indicates a carbon emissions intensity of 35.7 kg/m2·per year, as well as a reduction in material embodied emissions of 18%, assembly emissions of 17.5%, and operational emissions of 91.5%. This research proposes a carbon reduction-driven LCA of temporary housing and contributes to promoting sustainable development of prefabricated temporary housing equipped with renewable energy systems.",2018,"[{'authorId': '2152287780', 'name': 'Ling Dong'}, {'authorId': '2153604614', 'name': 'Yu Wang'}, {'authorId': '2144342267', 'name': 'Hong Xian Li'}, {'authorId': '35516387', 'name': 'Boya Jiang'}, {'authorId': '1401396797', 'name': 'M. Al-Hussein'}]","{'url': 'https://www.mdpi.com/2071-1050/10/3/718/pdf?version=1520348532', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/SU10030718?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/SU10030718, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","temporary housing plays an important role in providing secure, hygienic, private, and comfortable shelter in the aftermath of disaster (such as flood, fire, earthquake, etc.). additionally, temporary housing can also be used as a sustainable form of on-site residences for construction workers. while most of the building components used in temporary housing can be manufactured in a plant, prefabrication technology improves the production efficiency of temporary housing; furthermore, integrated renewable energy systems, for example, solar photovoltaic (pv) system, offer benefits for temporary housing operations. in order to assess the environmental impacts of prefabricated temporary housing equipped with renewable energy systems, this study first divides the life cycle of temporary housing into six stages, and then establishes a life cycle assessment (lca) model for each stage. furthermore, with the aim of reducing the environmental impacts, life cycle carbon reduction measures are proposed for each stage of temporary housing. the proposed methodology is demonstrated using a case study in china. based on the proposed carbon reduction measures, the lca of a prefabricated temporary housing case study building equipped with renewable energy systems indicates a carbon emissions intensity of 35.7 kg/m2·per year, as well as a reduction in material embodied emissions of 18%, assembly emissions of 17.5%, and operational emissions of 91.5%. this research proposes a carbon reduction-driven lca of temporary housing and contributes to promoting sustainable development of prefabricated temporary housing equipped with renewable energy systems.",https://www.mdpi.com/2071-1050/10/3/718/pdf?version=1520348532
2abe93b7b901274599c2d824803a6857bef9fad9,"Performance analysis of various hybrid renewable energy systems using battery, hydrogen, and pumped hydro‐based storage units","The aim of this research is to analyze the techno‐economic performance of hybrid renewable energy system (HRES) using batteries, pumped hydro‐based, and hydrogen‐based storage units at Sharurah, Saudi Arabia. The simulations and optimization process are carried out for nine HRES scenarios to determine the optimum sizes of components for each scenario. The optimal sizing of components for each HRES scenario is determined based on the net present cost (NPC) optimization criterion. All of the nine optimized HRES scenarios are then evaluated based on NPC, levelized cost of energy, payback period, CO2 emissions, excess electricity, and renewable energy fraction. The simulation results show that the photovoltaic (PV)‐diesel‐battery scenario is economically the most viable system with the NPC of US$2.70 million and levelized cost of energy of US$0.178/kWh. Conversely, PV‐diesel‐fuel cell system is proved to be economically the least feasible system. Moreover, the wind‐diesel‐fuel cell is the most economical scenario in the hydrogen‐based storage category. PV‐wind‐diesel‐pumped hydro scenario has the highest renewable energy fraction of 89.8%. PV‐wind‐diesel‐pumped hydro scenario is the most environment‐friendly system, with an 89% reduction in CO2 emissions compared with the base‐case diesel only scenario. Overall, the systems with battery and pumped hydro storage options have shown better techno‐economic performance compared with the systems with hydrogen‐based storage.",2018,"[{'authorId': '9349615', 'name': 'A. Awan'}, {'authorId': '47622499', 'name': 'M. Zubair'}, {'authorId': '1724992', 'name': 'G. A. S. Sidhu'}, {'authorId': '24321473', 'name': 'A. R. Bhatti'}, {'authorId': '67170214', 'name': 'A. G. Abo-Khalil'}]","{'url': 'https://doi.org/10.1002/er.4343', 'status': 'GOLD', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/er.4343?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/er.4343, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the aim of this research is to analyze the techno‐economic performance of hybrid renewable energy system (hres) using batteries, pumped hydro‐based, and hydrogen‐based storage units at sharurah, saudi arabia. the simulations and optimization process are carried out for nine hres scenarios to determine the optimum sizes of components for each scenario. the optimal sizing of components for each hres scenario is determined based on the net present cost (npc) optimization criterion. all of the nine optimized hres scenarios are then evaluated based on npc, levelized cost of energy, payback period, co2 emissions, excess electricity, and renewable energy fraction. the simulation results show that the photovoltaic (pv)‐diesel‐battery scenario is economically the most viable system with the npc of us$2.70 million and levelized cost of energy of us$0.178/kwh. conversely, pv‐diesel‐fuel cell system is proved to be economically the least feasible system. moreover, the wind‐diesel‐fuel cell is the most economical scenario in the hydrogen‐based storage category. pv‐wind‐diesel‐pumped hydro scenario has the highest renewable energy fraction of 89.8%. pv‐wind‐diesel‐pumped hydro scenario is the most environment‐friendly system, with an 89% reduction in co2 emissions compared with the base‐case diesel only scenario. overall, the systems with battery and pumped hydro storage options have shown better techno‐economic performance compared with the systems with hydrogen‐based storage.",https://doi.org/10.1002/er.4343
570e0cc1a169b9a8ef7f6a1ed493a63e0c2ee6b4,"Renewable Energy Systems: Enhanced Resilience, Lower Costs","The enhanced resilience of today ’ s renewable energy systems, comprising solar photovoltaic and wind electricity generators, coupled with the storage of electricity in Li-ion batteries and solar hydrogen, is a key attribute of current clean energy technology. Referring to selected recent examples, it is shown how families, companies, and entire regions can now safely rely on renewable energy to meet their energy needs.",2019,"[{'authorId': '6694877', 'name': 'M. Pagliaro'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/ENTE.201900791?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/ENTE.201900791, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the enhanced resilience of today ’ s renewable energy systems, comprising solar photovoltaic and wind electricity generators, coupled with the storage of electricity in li-ion batteries and solar hydrogen, is a key attribute of current clean energy technology. referring to selected recent examples, it is shown how families, companies, and entire regions can now safely rely on renewable energy to meet their energy needs.",
a44dfa87b3f9fdb2ae2ecab01f32d588c66c2682,Medical and dental applications of renewable energy systems,"Due to environmental problems related to using fossil fuels and limitations in the sources of these types of fuels, renewable energies have sharply developed in recent decades. Renewable energy systems are applicable in various fields to provide clean energy. In the current study, medical and dental applications of renewable energies are reviewed. Based on the literature review, technologies based on renewable energy sources can be utilized in medical buildings and instruments. For instance, solar-based technologies can be applied in heating and cooling of hospitals and other healthcare facilities. In addition, the thermal energy of the sun is applicable in autoclaves and medical dryers. Although utilizing renewable energy systems for these applications requires more investment cost and probably more complicated structures, it would result in lower carbon dioxide emission which leads to sustainable development.",2018,"[{'authorId': '82582615', 'name': 'Yashar Haghighi Bardineh'}, {'authorId': '90678707', 'name': 'Fatemeh Mohamadian'}, {'authorId': '52161731', 'name': 'M. Ahmadi'}, {'authorId': '101598220', 'name': 'Nazila Akbarianrad'}]","{'url': 'https://academic.oup.com/ijlct/article-pdf/13/4/320/26338454/cty040.pdf', 'status': 'GOLD', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1093/IJLCT/CTY040?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1093/IJLCT/CTY040, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","due to environmental problems related to using fossil fuels and limitations in the sources of these types of fuels, renewable energies have sharply developed in recent decades. renewable energy systems are applicable in various fields to provide clean energy. in the current study, medical and dental applications of renewable energies are reviewed. based on the literature review, technologies based on renewable energy sources can be utilized in medical buildings and instruments. for instance, solar-based technologies can be applied in heating and cooling of hospitals and other healthcare facilities. in addition, the thermal energy of the sun is applicable in autoclaves and medical dryers. although utilizing renewable energy systems for these applications requires more investment cost and probably more complicated structures, it would result in lower carbon dioxide emission which leads to sustainable development.",https://academic.oup.com/ijlct/article-pdf/13/4/320/26338454/cty040.pdf
225bd50761f8c557f92f05e163eb6e60641b08bb,Power Flow Control of PV-Wind-Battery Hybrid Renewable Energy Systems for Stand-Alone Application,The main problem in renewable energy system is the variation in power generation from time to time due to the intermittent nature of the renewable sources. Miss matching between power generation and load power causes a deviation from the desired voltage and frequency in power supply. A power flow control of a standalone photovoltaic-wind-battery Hybrid Renewable Energy System (HRES) for stand-alone application is presented here to balance the power generation and load power. Photovoltaic (PV) and wind are the primary power sources and battery acts as backup source to balance the power generation and load power. In spite of sudden load changes and changes in the power generation from PV power and wind power the power balance between the supply and demand effectively maintained by the proposed fuzzy logic controller (FLC). All the renewable sources and backup source are linked to a DC bus through dc-dc converter and the DC bus is connected to AC load through a voltage source inverter. A control strategy is implemented with fuzzy logic controller for smoothing of the power fluctuation and at the same time to maintain the battery state of charge (SOC) with in allowable limits. The various components are modeled and simulated in MATLAB/Simulink. Simulation results justify the ability of proposed controller to balance the power generation and load power.,2018,"[{'authorId': '2109605823', 'name': 'Somnath Das'}, {'authorId': '144060869', 'name': 'A. K. Akella'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.20508/ijrer.v8i1.6534.g7278?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.20508/ijrer.v8i1.6534.g7278, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}",the main problem in renewable energy system is the variation in power generation from time to time due to the intermittent nature of the renewable sources. miss matching between power generation and load power causes a deviation from the desired voltage and frequency in power supply. a power flow control of a standalone photovoltaic-wind-battery hybrid renewable energy system (hres) for stand-alone application is presented here to balance the power generation and load power. photovoltaic (pv) and wind are the primary power sources and battery acts as backup source to balance the power generation and load power. in spite of sudden load changes and changes in the power generation from pv power and wind power the power balance between the supply and demand effectively maintained by the proposed fuzzy logic controller (flc). all the renewable sources and backup source are linked to a dc bus through dc-dc converter and the dc bus is connected to ac load through a voltage source inverter. a control strategy is implemented with fuzzy logic controller for smoothing of the power fluctuation and at the same time to maintain the battery state of charge (soc) with in allowable limits. the various components are modeled and simulated in matlab/simulink. simulation results justify the ability of proposed controller to balance the power generation and load power.,
818d657d14d4c2c8acfbcdadc5be04e034a4c87b,Smart Grid Integration of Renewable Energy Systems,"Smart grid is an evolution of existing power system with close interplay among energy, control and communication infrastructure. Power processing is done using both kinds of energy systems namely conventional remote power generation and non-conventional power generation in proximity with the loads and actuation is done using power electronic devices and systems. The realization of such type of interactive, resilient and sustainable model is a challenge. In this paper, a unique modeling and control prototype is presented for renewable energy sources integration into the smart grid. The model is scalable in nature which means more renewable energy sources can be added according to design requirements. Demonstration of transitory states, overall power conditioning and the transient response of the system indicate the usefulness of the proposed model.",2018,"[{'authorId': '1868949', 'name': 'A. Shahid'}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICRERA.2018.8566827?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICRERA.2018.8566827, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","smart grid is an evolution of existing power system with close interplay among energy, control and communication infrastructure. power processing is done using both kinds of energy systems namely conventional remote power generation and non-conventional power generation in proximity with the loads and actuation is done using power electronic devices and systems. the realization of such type of interactive, resilient and sustainable model is a challenge. in this paper, a unique modeling and control prototype is presented for renewable energy sources integration into the smart grid. the model is scalable in nature which means more renewable energy sources can be added according to design requirements. demonstration of transitory states, overall power conditioning and the transient response of the system indicate the usefulness of the proposed model.",
7fca24e988a3feff744136ba0dbd4f87c2775329,"Integration of renewable energy systems and challenges for dynamics, control, and automation of electrical power systems","This paper tackles the key challenges for dynamics, control, and automation of power systems that are imposed by the integration of renewable power plants. First, the current practice of automation and control in large‐scale power systems are reviewed. Then, dynamics and control of electrical transmission systems are discussed and the issues associated with the integration of large‐scale wind and solar power plants are exploited. The discussion carries on with a focus on control of electrical distribution systems and the key issues associated with the integration of distributed generation power plants. An emerging concern in power and energy industry is the dynamic interaction between transmission and distribution systems as a result of technological and topological changes in power systems that can put their control at risk. These topics are also covered in this paper. In terms of automation, the key challenges and opportunities for accommodation of higher penetration and share of renewable energy, as part of the vision for grid modernization, are explored in this paper. Throughout the discussion, some results from the recent studies are shown.",2018,"[{'authorId': '49681773', 'name': 'A. Sajadi'}, {'authorId': '31111017', 'name': 'L. Strezoski'}, {'authorId': '30701507', 'name': 'V. Strezoski'}, {'authorId': '48494811', 'name': 'M. Prica'}, {'authorId': '144538578', 'name': 'K. Loparo'}]","{'url': 'https://www.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wene.321', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/wene.321?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/wene.321, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper tackles the key challenges for dynamics, control, and automation of power systems that are imposed by the integration of renewable power plants. first, the current practice of automation and control in large‐scale power systems are reviewed. then, dynamics and control of electrical transmission systems are discussed and the issues associated with the integration of large‐scale wind and solar power plants are exploited. the discussion carries on with a focus on control of electrical distribution systems and the key issues associated with the integration of distributed generation power plants. an emerging concern in power and energy industry is the dynamic interaction between transmission and distribution systems as a result of technological and topological changes in power systems that can put their control at risk. these topics are also covered in this paper. in terms of automation, the key challenges and opportunities for accommodation of higher penetration and share of renewable energy, as part of the vision for grid modernization, are explored in this paper. throughout the discussion, some results from the recent studies are shown.",https://www.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wene.321
5bd7b52742418a218a5c6c1599c42b512831d21b,Using time series simulation tools for assessing the effects of variable renewable energy generation on power and energy systems,"The increasing share of variable renewable energy (VRE) generation poses challenges to power systems. Possible challenges include adequacy of reserves, planning and operation of power systems, and interconnection expansion studies in future power systems with very different generation patterns compared to today. To meet these challenges, there is a need to develop models and tools to analyze the variability and uncertainty in VRE generation. To address the varied needs, the tools should be versatile and applicable to different geographical and temporal scales. Time series simulation tools can be used to model both today and future scenarios with varying VRE installations. Correlations in Renewable Energy Sources (CorRES) is a simulation tool developed at Technical University of Denmark, Department of Wind Energy capable of simulating both wind and solar generation. It uses a unique combination of meteorological time series and stochastic simulations to provide consistent VRE generation and forecast error time series with temporal resolution in the minute scale. Such simulated VRE time series can be used in addressing the challenges posed by the increasing share of VRE generation. These capabilities will be demonstrated through three case studies: one about the use of large‐scale VRE generation simulations in energy system analysis, and two about the use of the simulations in power system operation, planning, and analysis.",2018,"[{'authorId': '34571915', 'name': 'M. Koivisto'}, {'authorId': '49105322', 'name': 'K. Das'}, {'authorId': '9409649', 'name': 'F. Guo'}, {'authorId': '32381975', 'name': 'P. Sørensen'}, {'authorId': '30997042', 'name': 'Edgar Nuño'}, {'authorId': '31769145', 'name': 'N. Cutululis'}, {'authorId': '2766790', 'name': 'Petr Maule'}]","{'url': 'https://backend.orbit.dtu.dk/ws/files/211179011/WIREs_PostPrint.pdf', 'status': 'GREEN', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1002/wene.329?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/wene.329, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the increasing share of variable renewable energy (vre) generation poses challenges to power systems. possible challenges include adequacy of reserves, planning and operation of power systems, and interconnection expansion studies in future power systems with very different generation patterns compared to today. to meet these challenges, there is a need to develop models and tools to analyze the variability and uncertainty in vre generation. to address the varied needs, the tools should be versatile and applicable to different geographical and temporal scales. time series simulation tools can be used to model both today and future scenarios with varying vre installations. correlations in renewable energy sources (corres) is a simulation tool developed at technical university of denmark, department of wind energy capable of simulating both wind and solar generation. it uses a unique combination of meteorological time series and stochastic simulations to provide consistent vre generation and forecast error time series with temporal resolution in the minute scale. such simulated vre time series can be used in addressing the challenges posed by the increasing share of vre generation. these capabilities will be demonstrated through three case studies: one about the use of large‐scale vre generation simulations in energy system analysis, and two about the use of the simulations in power system operation, planning, and analysis.",https://backend.orbit.dtu.dk/ws/files/211179011/WIREs_PostPrint.pdf
012b1598ec4e303c39ca9b876f2e66a652aed2dc,Towards fully renewable energy systems - Experience and trends in Denmark,"Deployment of renewable energy generation capacities and integration of their power production into existing power systems has become a global trend, with a common set of operational challenges stemming from variability and limited predictability of power generation from, e.g., wind and solar. Denmark is a country that invested early in wind energy, rapidly proposing very ambitious goals for the future of its energy system and global energy usage. While the case of Denmark is specific due to its limited size and good interconnections, there may still be a lot to learn from the way operational practice has evolved, also from shifting towards a liberalized electricity market environment, and more generally from going along with other technological and societal evolution. The aim of this paper is to give an overview of recent and current initiatives in Denmark that contributes towards a goal of reaching a fully renewable energy system.",2017,"[{'authorId': '2182322', 'name': 'P. Pinson'}, {'authorId': '30923144', 'name': 'Lesia Mitridati'}, {'authorId': '30618332', 'name': 'Christos Ordoudis'}, {'authorId': '143814330', 'name': 'J. Østergaard'}]","{'url': 'https://doi.org/10.17775/cseejpes.2017.0005', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.17775/CSEEJPES.2017.0005?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.17775/CSEEJPES.2017.0005, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","deployment of renewable energy generation capacities and integration of their power production into existing power systems has become a global trend, with a common set of operational challenges stemming from variability and limited predictability of power generation from, e.g., wind and solar. denmark is a country that invested early in wind energy, rapidly proposing very ambitious goals for the future of its energy system and global energy usage. while the case of denmark is specific due to its limited size and good interconnections, there may still be a lot to learn from the way operational practice has evolved, also from shifting towards a liberalized electricity market environment, and more generally from going along with other technological and societal evolution. the aim of this paper is to give an overview of recent and current initiatives in denmark that contributes towards a goal of reaching a fully renewable energy system.",https://doi.org/10.17775/cseejpes.2017.0005
cefdd9906064c199428645512eb6834dfed72ae3,Optimization of Renewable Energy Resources in Hybrid Energy Systems,"This paper proposes the optimization of renewable energy resources (RERs) in the hybrid energy systems in a sustainable hybrid energy system. The behavior of renewable energy is uncertain and it is difficult for static optimization methods to optimize the uncertain non-stationary distributed energy resources in the hybrid system. A multi-objective based on the stochastic technique for optimizing total system losses and operating cost is formulated for the hybrid energy system. The proposed objective function aims to minimize the system losses and the total operating cost of RERs in different locations of the grid. In this paper, a next generation of grid connected RERs and load demand is proposed by considering the variability and uncertainty. Here, a robust stochastic approach is proposed by using the various probability distribution functions to represent the statistics of RERs. The simulation results of this paper handle the system operations under uncertainty. The proposed approach is tested on IEEE 37 node distribution system. The simulation results show the effectiveness of the proposed optimization approach in the hybrid energy system.",2017,"[{'authorId': '144006876', 'name': 'S. S. Reddy'}]","{'url': 'https://riverpublishers.com/journal/journal_articles/RP_Journal_1904-4720_713.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.13052/JGE1904-4720.7123?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.13052/JGE1904-4720.7123, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper proposes the optimization of renewable energy resources (rers) in the hybrid energy systems in a sustainable hybrid energy system. the behavior of renewable energy is uncertain and it is difficult for static optimization methods to optimize the uncertain non-stationary distributed energy resources in the hybrid system. a multi-objective based on the stochastic technique for optimizing total system losses and operating cost is formulated for the hybrid energy system. the proposed objective function aims to minimize the system losses and the total operating cost of rers in different locations of the grid. in this paper, a next generation of grid connected rers and load demand is proposed by considering the variability and uncertainty. here, a robust stochastic approach is proposed by using the various probability distribution functions to represent the statistics of rers. the simulation results of this paper handle the system operations under uncertainty. the proposed approach is tested on ieee 37 node distribution system. the simulation results show the effectiveness of the proposed optimization approach in the hybrid energy system.",https://riverpublishers.com/journal/journal_articles/RP_Journal_1904-4720_713.pdf
a062fbd621a9821a695b9869630feb6bfb0cf585,PSO-Based Smart Grid Application for Sizing and Optimization of Hybrid Renewable Energy Systems,"This paper introduces an optimal sizing algorithm for a hybrid renewable energy system using smart grid load management application based on the available generation. This algorithm aims to maximize the system energy production and meet the load demand with minimum cost and highest reliability. This system is formed by photovoltaic array, wind turbines, storage batteries, and diesel generator as a backup source of energy. Demand profile shaping as one of the smart grid applications is introduced in this paper using load shifting-based load priority. Particle swarm optimization is used in this algorithm to determine the optimum size of the system components. The results obtained from this algorithm are compared with those from the iterative optimization technique to assess the adequacy of the proposed algorithm. The study in this paper is performed in some of the remote areas in Saudi Arabia and can be expanded to any similar regions around the world. Numerous valuable results are extracted from this study that could help researchers and decision makers.",2016,"[{'authorId': '144816554', 'name': 'M. A. Mohamed'}, {'authorId': '49264644', 'name': 'A. Eltamaly'}, {'authorId': '2104329', 'name': 'A. Alolah'}]","{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0159702&type=printable', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC4981409, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","this paper introduces an optimal sizing algorithm for a hybrid renewable energy system using smart grid load management application based on the available generation. this algorithm aims to maximize the system energy production and meet the load demand with minimum cost and highest reliability. this system is formed by photovoltaic array, wind turbines, storage batteries, and diesel generator as a backup source of energy. demand profile shaping as one of the smart grid applications is introduced in this paper using load shifting-based load priority. particle swarm optimization is used in this algorithm to determine the optimum size of the system components. the results obtained from this algorithm are compared with those from the iterative optimization technique to assess the adequacy of the proposed algorithm. the study in this paper is performed in some of the remote areas in saudi arabia and can be expanded to any similar regions around the world. numerous valuable results are extracted from this study that could help researchers and decision makers.",https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0159702&type=printable
61b8a96cf12e961628977066d4c4807dcb526879,Smart Integrated Renewable Energy Systems (SIRES): A Novel Approach for Sustainable Development,"Technical and economic aspects of the viability of SIRES (Smart Integrated Renewable Energy Systems) for sustainable development of remote and rural areas of the world are discussed. The hallmark of the proposed SIRES is the smart utilization of several renewable resources in an integrated fashion and matching of resources and needs a priori with the ultimate goal of “energization”, not just “electrification”. Historical background leading to this approach is succinctly presented along with a comprehensive schematic diagram. Modeling of various components and their collective use in optimizing SIRES with the aid of genetic algorithm are presented using a typical hypothetical example. SIRES is also compared with various approaches for rural development based on Annualized Cost of System (ACS) and installation costs. Implementation of SIRES will lead to overall sustainable development of rural communities.",2017,"[{'authorId': '30528974', 'name': 'Zeel Maheshwari'}, {'authorId': '1915461', 'name': 'R. Ramakumar'}]","{'url': 'https://www.mdpi.com/1996-1073/10/8/1145/pdf?version=1501850913', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/EN10081145?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/EN10081145, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","technical and economic aspects of the viability of sires (smart integrated renewable energy systems) for sustainable development of remote and rural areas of the world are discussed. the hallmark of the proposed sires is the smart utilization of several renewable resources in an integrated fashion and matching of resources and needs a priori with the ultimate goal of “energization”, not just “electrification”. historical background leading to this approach is succinctly presented along with a comprehensive schematic diagram. modeling of various components and their collective use in optimizing sires with the aid of genetic algorithm are presented using a typical hypothetical example. sires is also compared with various approaches for rural development based on annualized cost of system (acs) and installation costs. implementation of sires will lead to overall sustainable development of rural communities.",https://www.mdpi.com/1996-1073/10/8/1145/pdf?version=1501850913
76a6c339e61e04069a35610faee5a523b2509f03,Optimization of Renewable Energy Systems: A Review,"In the contrary of decrease of fossil energy nowadays, the demand of energy, the global warming, and continuous increase in oil prices have got attention all over the world. Since without energy life is an imaginary, the newly emerging renewable energy technologies are hope fully at least minimizing the problem that comes from the shortage of energy or an imbalance of distribution of energy among countries and within a country. To satisfy the need for power, hybrid renewable energy system is becoming an emerging and widely under application for electrification of remote rural areas where the grid extension is difficult and not economical in the past few decades all over the world. These systems incorporate a combination of one or more renewable energy sources such as solar photovoltaic, wind energy, micro-hydro, biomass energy, geothermal and may be conventional generators for backup. This survey paper compiles renewable energy systems with their advantages and limitations, hybrid wind and solar energy systems with different system components of hybrid energy system, provides detailed review of work done for optimization of renewable energy systems and give gap analysis to develop a general model to find an optimal combination of energy components for a typical rural community for minimizing the total net present cost of the system through the life time of the project. The highlights of the components and some simulation technique tools are also discussed.",2017,"[{'authorId': '112948910', 'name': 'Diriba Kajela'}, {'authorId': '9404920', 'name': 'M. S. Manshahia'}]","{'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.32628/IJSRST1738188?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.32628/IJSRST1738188, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","in the contrary of decrease of fossil energy nowadays, the demand of energy, the global warming, and continuous increase in oil prices have got attention all over the world. since without energy life is an imaginary, the newly emerging renewable energy technologies are hope fully at least minimizing the problem that comes from the shortage of energy or an imbalance of distribution of energy among countries and within a country. to satisfy the need for power, hybrid renewable energy system is becoming an emerging and widely under application for electrification of remote rural areas where the grid extension is difficult and not economical in the past few decades all over the world. these systems incorporate a combination of one or more renewable energy sources such as solar photovoltaic, wind energy, micro-hydro, biomass energy, geothermal and may be conventional generators for backup. this survey paper compiles renewable energy systems with their advantages and limitations, hybrid wind and solar energy systems with different system components of hybrid energy system, provides detailed review of work done for optimization of renewable energy systems and give gap analysis to develop a general model to find an optimal combination of energy components for a typical rural community for minimizing the total net present cost of the system through the life time of the project. the highlights of the components and some simulation technique tools are also discussed.",
ccb0ca74c441aa95d127d33f736827f4ff0ab761,Optimal configuration for isolated hybrid renewable energy systems,"The configuration of hybrid energy systems has a great influence on the cost of generated energy from the system. This paper introduces a design, simulation, assessment, and selection of optimum autonomous hybrid renewable energy configuration out of three different configurations. The proposed hybrid system contains photovoltaic (PV), wind, diesel, and battery energy systems. A new computer program has been designed to simulate different configurations of hybrid energy systems. A genetics optimization smart technique using a genetic algorithm has been used to calculate the optimum sizing for each component at different configurations of the hybrid system for minimum cost and highest reliability. The optimum penetration ratio of renewable energy systems (PV and wind) will be selected according to the lowest price. Actual data for one remote site in Saudi Arabia has been used in the input data of this computer program. Sensitivity analysis has been carried out to show the conditions for selecting any confi...",2016,"[{'authorId': '49264644', 'name': 'A. Eltamaly'}, {'authorId': '1410361907', 'name': ""A. A. Al‐Shamma'a""}]","{'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1063/1.4960407?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1063/1.4960407, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}","the configuration of hybrid energy systems has a great influence on the cost of generated energy from the system. this paper introduces a design, simulation, assessment, and selection of optimum autonomous hybrid renewable energy configuration out of three different configurations. the proposed hybrid system contains photovoltaic (pv), wind, diesel, and battery energy systems. a new computer program has been designed to simulate different configurations of hybrid energy systems. a genetics optimization smart technique using a genetic algorithm has been used to calculate the optimum sizing for each component at different configurations of the hybrid system for minimum cost and highest reliability. the optimum penetration ratio of renewable energy systems (pv and wind) will be selected according to the lowest price. actual data for one remote site in saudi arabia has been used in the input data of this computer program. sensitivity analysis has been carried out to show the conditions for selecting any confi...",
