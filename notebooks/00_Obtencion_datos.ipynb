{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063f8129",
   "metadata": {},
   "source": [
    "# Obtencion de datos de la API de Semantic Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ee06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf00152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constantes\n",
    "SEMANTIC_SCHOLAR_API_URL = \"https://api.semanticscholar.org/graph/v1\"\n",
    "FIELDS = \"paperId,title,abstract,year,authors.name,openAccessPdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12fe8354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directorios\n",
    "DATA_DIR = \"C:\\\\Users\\\\alvar\\\\OneDrive\\\\Escritorio\\\\TFM\\\\data\" \n",
    "EXISTING_CORPUS_FILENAME = \"initial_corpus.csv\"\n",
    "EXISTING_CORPUS_PATH = os.path.join(DATA_DIR,\"crudo\", EXISTING_CORPUS_FILENAME)\n",
    "\n",
    "EXPANDED_CORPUS_FILENAME = \"expanded_initial_corpus.csv\"\n",
    "EXPANDED_CORPUS_PATH = os.path.join(DATA_DIR,\"crudo\", EXPANDED_CORPUS_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Función get_papers Adaptada para este notebook ---\n",
    "def get_papers(query, limit_per_query=50, existing_ids_set=None):\n",
    "    \"\"\"\n",
    "    Obtiene artículos de Semantic Scholar para una consulta dada,\n",
    "    evitando IDs ya existentes y filtrando por aquellos con abstract.\n",
    "    Intenta obtener 'limit_per_query' artículos que cumplan los criterios.\n",
    "    \"\"\"\n",
    "    if existing_ids_set is None:\n",
    "        existing_ids_set = set()\n",
    "        \n",
    "    papers_data_for_query = []\n",
    "    current_offset = 0\n",
    "    # Para asegurar obtener 'limit_per_query' artículos después de filtrar,\n",
    "    # La API tiene un máximo de 10000 resultados por query (offset + limit <= 10000)\n",
    "    max_api_offset_limit = 9900 # No superar el límite de la API para offset+limit\n",
    "    \n",
    "    print(f\"\\nBuscando hasta {limit_per_query} artículos NUEVOS para: '{query}'...\")\n",
    "    \n",
    "    while len(papers_data_for_query) < limit_per_query and current_offset < max_api_offset_limit :\n",
    "        # Pedir en lotes de 100 (máximo de la API)\n",
    "        batch_api_limit = min(100, max_api_offset_limit - current_offset)\n",
    "        if batch_api_limit <=0: break\n",
    "\n",
    "        try:\n",
    "            params = {\n",
    "                'query': query,\n",
    "                'limit': batch_api_limit,\n",
    "                'offset': current_offset,\n",
    "                'fields': FIELDS\n",
    "            }\n",
    "            response = requests.get(f\"{SEMANTIC_SCHOLAR_API_URL}/paper/search\", params=params)\n",
    "            response.raise_for_status()\n",
    "            api_response_data = response.json()\n",
    "\n",
    "            if not api_response_data.get('data'):\n",
    "                print(\"  No se encontraron más datos de la API para esta consulta.\")\n",
    "                break\n",
    "\n",
    "            found_in_page = 0\n",
    "            added_this_page = 0\n",
    "            for paper_item in api_response_data['data']:\n",
    "                found_in_page +=1\n",
    "                paper_id = paper_item.get('paperId')\n",
    "                # Añadir solo si tiene abstract y el ID no es uno ya guardado\n",
    "                if paper_item.get('abstract') and paper_id and paper_id not in existing_ids_set:\n",
    "                    papers_data_for_query.append(paper_item)\n",
    "                    existing_ids_set.add(paper_id) # Marcar este ID como obtenido\n",
    "                    added_this_page += 1\n",
    "                    if len(papers_data_for_query) >= limit_per_query:\n",
    "                        break \n",
    "            \n",
    "            print(f\"  Página API: {found_in_page} artículos. Añadidos (nuevos con abstract): {added_this_page}.\")\n",
    "\n",
    "            current_offset += len(api_response_data['data']) \n",
    "\n",
    "            if len(papers_data_for_query) >= limit_per_query:\n",
    "                print(f\"  Alcanzado el límite de {limit_per_query} artículos deseados para '{query}'.\")\n",
    "                break\n",
    "            \n",
    "            # Si no hay 'next' o el offset es 0 (a veces la API lo devuelve así), parar\n",
    "            if api_response_data.get('next', 0) == 0 and current_offset == len(api_response_data['data']): \n",
    "                 pass \n",
    "            elif api_response_data.get('next', 0) == 0:\n",
    "                 print(\"  No hay 'next' página indicada por la API.\")\n",
    "                 break\n",
    "\n",
    "\n",
    "            # Esperar para respetar los límites de la API\n",
    "            print(f\"  Esperando 3 segundos... (Obtenidos para '{query}': {len(papers_data_for_query)}/{limit_per_query})\")\n",
    "            time.sleep(3) \n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 429: \n",
    "                print(f\"  Error 429 (Too Many Requests). Esperando 60 segundos...\")\n",
    "                time.sleep(60) # Espera más larga\n",
    "            else:\n",
    "                print(f\"  Error HTTP ({e.response.status_code}) en la petición a la API: {e.response.text}\")\n",
    "                print(\"  Esperando 10 segundos antes de continuar con la siguiente keyword (si hay)...\")\n",
    "                time.sleep(10)\n",
    "                break # Salir del bucle while para esta keyword\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  Error de red en la petición a la API: {e}\")\n",
    "            print(\"  Esperando 10 segundos antes de continuar con la siguiente keyword (si hay)...\")\n",
    "            time.sleep(10)\n",
    "            break \n",
    "        except Exception as e:\n",
    "            print(f\"  Error inesperado: {e}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Finalizada la búsqueda para '{query}'. Total de artículos NUEVOS con abstract obtenidos: {len(papers_data_for_query)}\")\n",
    "    return papers_data_for_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e1d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando corpus existente desde: C:\\Users\\alvar\\OneDrive\\Escritorio\\TFM\\data\\crudo\\initial_corpus.csv\n",
      "Cargados 204 artículos del corpus existente.\n",
      "Se encontraron 204 IDs únicos en el corpus existente.\n"
     ]
    }
   ],
   "source": [
    "df_existing_corpus = pd.DataFrame()\n",
    "existing_paper_ids = set() # set para busqueda rápida de IDs existentes\n",
    "\n",
    "if os.path.exists(EXISTING_CORPUS_PATH):\n",
    "    print(f\"Cargando corpus existente desde: {EXISTING_CORPUS_PATH}\")\n",
    "    try:\n",
    "        df_existing_corpus = pd.read_csv(EXISTING_CORPUS_PATH)\n",
    "        if 'paperId' in df_existing_corpus.columns:\n",
    "            # Asegurarse de que no haya NaNs en paperId antes de convertir a lista y luego a set\n",
    "            existing_paper_ids = set(df_existing_corpus['paperId'].dropna().astype(str).tolist())\n",
    "        print(f\"Cargados {len(df_existing_corpus)} artículos del corpus existente.\")\n",
    "        print(f\"Se encontraron {len(existing_paper_ids)} IDs únicos en el corpus existente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar o procesar el corpus existente: {e}\")\n",
    "        df_existing_corpus = pd.DataFrame() # Resetear si hay error\n",
    "else:\n",
    "    print(f\"No se encontró el archivo de corpus existente en '{EXISTING_CORPUS_PATH}'. Se creará un corpus nuevo/expandido.\")\n",
    "\n",
    "# Lista de columnas que esperamos tener basadas en la variable FIELDS\n",
    "expected_cols = [field.split('.')[0] for field in FIELDS.split(',')]\n",
    "\n",
    "# Si el df existente no está vacío, asegurar que tenga todas las columnas esperadas\n",
    "if not df_existing_corpus.empty:\n",
    "    for col in expected_cols:\n",
    "        if col not in df_existing_corpus.columns:\n",
    "            df_existing_corpus[col] = None # Añadir columnas faltantes con None\n",
    "    # Reordenar para que coincida con expected_cols si es necesario\n",
    "    df_existing_corpus = df_existing_corpus[expected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c81342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'economy business models'...\n",
      "  Página API: 100 artículos. Añadidos (nuevos con abstract): 49.\n",
      "  Esperando 3 segundos... (Obtenidos para 'economy business models': 49/50)\n",
      "  Página API: 2 artículos. Añadidos (nuevos con abstract): 1.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'economy business models'.\n",
      "Finalizada la búsqueda para 'economy business models'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'mental health support using chatbots'...\n",
      "  Página API: 52 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'mental health support using chatbots'.\n",
      "Finalizada la búsqueda para 'mental health support using chatbots'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'Generative AI in education'...\n",
      "  Página API: 80 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'Generative AI in education'.\n",
      "Finalizada la búsqueda para 'Generative AI in education'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'sports analytics using AI'...\n",
      "  Página API: 61 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'sports analytics using AI'.\n",
      "Finalizada la búsqueda para 'sports analytics using AI'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'sports'...\n",
      "  Página API: 68 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'sports'.\n",
      "Finalizada la búsqueda para 'sports'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'deep learning'...\n",
      "  Error 429 (Too Many Requests). Esperando 60 segundos...\n",
      "  Error 429 (Too Many Requests). Esperando 60 segundos...\n",
      "  Página API: 68 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'deep learning'.\n",
      "Finalizada la búsqueda para 'deep learning'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'computer vision'...\n",
      "  Página API: 74 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'computer vision'.\n",
      "Finalizada la búsqueda para 'computer vision'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'medical image analysis'...\n",
      "  Error 429 (Too Many Requests). Esperando 60 segundos...\n",
      "  Página API: 63 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'medical image analysis'.\n",
      "Finalizada la búsqueda para 'medical image analysis'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'genomics'...\n",
      "  Página API: 100 artículos. Añadidos (nuevos con abstract): 49.\n",
      "  Esperando 3 segundos... (Obtenidos para 'genomics': 49/50)\n",
      "  Error 429 (Too Many Requests). Esperando 60 segundos...\n",
      "  Página API: 4 artículos. Añadidos (nuevos con abstract): 1.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'genomics'.\n",
      "Finalizada la búsqueda para 'genomics'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'climate change'...\n",
      "  Error 429 (Too Many Requests). Esperando 60 segundos...\n",
      "  Página API: 100 artículos. Añadidos (nuevos con abstract): 48.\n",
      "  Esperando 3 segundos... (Obtenidos para 'climate change': 48/50)\n",
      "  Página API: 4 artículos. Añadidos (nuevos con abstract): 2.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'climate change'.\n",
      "Finalizada la búsqueda para 'climate change'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'renewable energy'...\n",
      "  Página API: 100 artículos. Añadidos (nuevos con abstract): 28.\n",
      "  Esperando 3 segundos... (Obtenidos para 'renewable energy': 28/50)\n",
      "  Error 429 (Too Many Requests). Esperando 60 segundos...\n",
      "  Error 429 (Too Many Requests). Esperando 60 segundos...\n",
      "  Error 429 (Too Many Requests). Esperando 60 segundos...\n",
      "  Página API: 39 artículos. Añadidos (nuevos con abstract): 22.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'renewable energy'.\n",
      "Finalizada la búsqueda para 'renewable energy'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'supply chain optimization'...\n",
      "  Página API: 94 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'supply chain optimization'.\n",
      "Finalizada la búsqueda para 'supply chain optimization'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'economic forecasting'...\n",
      "  Página API: 100 artículos. Añadidos (nuevos con abstract): 48.\n",
      "  Esperando 3 segundos... (Obtenidos para 'economic forecasting': 48/50)\n",
      "  Página API: 3 artículos. Añadidos (nuevos con abstract): 2.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'economic forecasting'.\n",
      "Finalizada la búsqueda para 'economic forecasting'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'oncology research'...\n",
      "  Página API: 74 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'oncology research'.\n",
      "Finalizada la búsqueda para 'oncology research'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'cardiovascular diseases'...\n",
      "  Error 429 (Too Many Requests). Esperando 60 segundos...\n",
      "  Página API: 58 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'cardiovascular diseases'.\n",
      "Finalizada la búsqueda para 'cardiovascular diseases'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'water resource management'...\n",
      "  Página API: 83 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'water resource management'.\n",
      "Finalizada la búsqueda para 'water resource management'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'robotics in manufacturing'...\n",
      "  Página API: 84 artículos. Añadidos (nuevos con abstract): 50.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'robotics in manufacturing'.\n",
      "Finalizada la búsqueda para 'robotics in manufacturing'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "--- Esperando 5 segundos antes de la siguiente keyword ---\n",
      "\n",
      "Buscando hasta 50 artículos NUEVOS para: 'renewable energy systems'...\n",
      "  Página API: 100 artículos. Añadidos (nuevos con abstract): 48.\n",
      "  Esperando 3 segundos... (Obtenidos para 'renewable energy systems': 48/50)\n",
      "  Página API: 7 artículos. Añadidos (nuevos con abstract): 2.\n",
      "  Alcanzado el límite de 50 artículos deseados para 'renewable energy systems'.\n",
      "Finalizada la búsqueda para 'renewable energy systems'. Total de artículos NUEVOS con abstract obtenidos: 50\n",
      "\n",
      "Proceso de obtención de nuevos artículos finalizado.\n",
      "Total de artículos nuevos potencialmente añadidos (antes de convertir a DF): 900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_search_keywords = [\n",
    "    \"economy business models\",\n",
    "    \"mental health support using chatbots\",\n",
    "    \"Generative AI in education\",\n",
    "    \"sports analytics using AI\",\n",
    "    \"sports\",\n",
    "    \"deep learning\",\n",
    "    \"computer vision\",\n",
    "    \"medical image analysis\",\n",
    "    \"genomics\",\n",
    "    \"climate change\",\n",
    "    \"renewable energy\",\n",
    "    \"supply chain optimization\",\n",
    "    \"economic forecasting\",\n",
    "    \"oncology research\",\n",
    "    \"cardiovascular diseases\",\n",
    "    \"water resource management\",\n",
    "    \"robotics in manufacturing\",\n",
    "    \"renewable energy systems\"\n",
    "]\n",
    "\n",
    "# Límite de artículos NUEVOS a intentar obtener por cada keyword\n",
    "# la función get_papers intentará alcanzar este número de artículos\n",
    "papers_to_fetch_per_keyword = 50 \n",
    "\n",
    "all_new_papers_list = []\n",
    "\n",
    "\n",
    "current_known_ids = existing_paper_ids.copy() # Copiar para no modificar el original \n",
    "\n",
    "for keyword in new_search_keywords:\n",
    "    new_papers_for_keyword = get_papers(keyword, \n",
    "                                        limit_per_query=papers_to_fetch_per_keyword, \n",
    "                                        existing_ids_set=current_known_ids)\n",
    "    all_new_papers_list.extend(new_papers_for_keyword)\n",
    "    \n",
    "    if keyword != new_search_keywords[-1]: # No esperar después de la última keyword\n",
    "        print(\"--- Esperando 5 segundos antes de la siguiente keyword ---\")\n",
    "        time.sleep(5)\n",
    "\n",
    "print(f\"\\nProceso de obtención de nuevos artículos finalizado.\")\n",
    "print(f\"Total de artículos nuevos potencialmente añadidos (antes de convertir a DF): {len(all_new_papers_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b50ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se crearon 900 filas a partir de los nuevos artículos recuperados.\n",
      "Tamaño del corpus combinado (antes de deduplicación final): 1104\n",
      "Se eliminaron 0 duplicados en la combinación final.\n",
      "Tamaño final del corpus expandido: 1104 artículos únicos.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>openAccessPdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4dc2617f15847af822d1f89c2e5cca39c8cdb7ad</td>\n",
       "      <td>Effect of a Machine Learning Recommender Syste...</td>\n",
       "      <td>This randomized clinical trial investigates th...</td>\n",
       "      <td>2023</td>\n",
       "      <td>[{'authorId': '39230104', 'name': 'Jamie M. Fa...</td>\n",
       "      <td>{'url': 'https://jamanetwork.com/journals/jama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9778a564510da05080f978fcff23928ead0f1db9</td>\n",
       "      <td>A Machine Learning Recommender System to Tailo...</td>\n",
       "      <td>Background and Objectives\\nNursing homes (NHs)...</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'authorId': '2509884', 'name': 'G. Gannod'},...</td>\n",
       "      <td>{'url': 'https://academic.oup.com/gerontologis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6a8a21cab225a428c41e3f8c38e18535f68ffacf</td>\n",
       "      <td>A Machine Learning Recommender System Based on...</td>\n",
       "      <td>Changing and moving toward online shopping has...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'authorId': '2172517066', 'name': 'Delshad M...</td>\n",
       "      <td>{'url': 'https://doi.org/10.22541/au.160897179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fc88d1692a0f53f2821499fa8b8f4d049775585f</td>\n",
       "      <td>Matrix Factorization Collaborative-Based Recom...</td>\n",
       "      <td>Saudi Arabia’s tourism sector has recently sta...</td>\n",
       "      <td>2023</td>\n",
       "      <td>[{'authorId': '2787898', 'name': 'Reham Alabdu...</td>\n",
       "      <td>{'url': 'https://www.mdpi.com/2076-3417/13/17/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9998dc44714a0721caa671243391c1ed5ecfa222</td>\n",
       "      <td>Smart Crop Recommender System-A Machine Learni...</td>\n",
       "      <td>Machine learning has proven its efficacy in so...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[{'authorId': '90015202', 'name': 'R. K. Ray'}...</td>\n",
       "      <td>{'url': '', 'status': None, 'license': None, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paperId  \\\n",
       "0  4dc2617f15847af822d1f89c2e5cca39c8cdb7ad   \n",
       "1  9778a564510da05080f978fcff23928ead0f1db9   \n",
       "2  6a8a21cab225a428c41e3f8c38e18535f68ffacf   \n",
       "3  fc88d1692a0f53f2821499fa8b8f4d049775585f   \n",
       "4  9998dc44714a0721caa671243391c1ed5ecfa222   \n",
       "\n",
       "                                               title  \\\n",
       "0  Effect of a Machine Learning Recommender Syste...   \n",
       "1  A Machine Learning Recommender System to Tailo...   \n",
       "2  A Machine Learning Recommender System Based on...   \n",
       "3  Matrix Factorization Collaborative-Based Recom...   \n",
       "4  Smart Crop Recommender System-A Machine Learni...   \n",
       "\n",
       "                                            abstract  year  \\\n",
       "0  This randomized clinical trial investigates th...  2023   \n",
       "1  Background and Objectives\\nNursing homes (NHs)...  2019   \n",
       "2  Changing and moving toward online shopping has...  2020   \n",
       "3  Saudi Arabia’s tourism sector has recently sta...  2023   \n",
       "4  Machine learning has proven its efficacy in so...  2022   \n",
       "\n",
       "                                             authors  \\\n",
       "0  [{'authorId': '39230104', 'name': 'Jamie M. Fa...   \n",
       "1  [{'authorId': '2509884', 'name': 'G. Gannod'},...   \n",
       "2  [{'authorId': '2172517066', 'name': 'Delshad M...   \n",
       "3  [{'authorId': '2787898', 'name': 'Reham Alabdu...   \n",
       "4  [{'authorId': '90015202', 'name': 'R. K. Ray'}...   \n",
       "\n",
       "                                       openAccessPdf  \n",
       "0  {'url': 'https://jamanetwork.com/journals/jama...  \n",
       "1  {'url': 'https://academic.oup.com/gerontologis...  \n",
       "2  {'url': 'https://doi.org/10.22541/au.160897179...  \n",
       "3  {'url': 'https://www.mdpi.com/2076-3417/13/17/...  \n",
       "4  {'url': '', 'status': None, 'license': None, '...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>openAccessPdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>cefdd9906064c199428645512eb6834dfed72ae3</td>\n",
       "      <td>Optimization of Renewable Energy Resources in ...</td>\n",
       "      <td>This paper proposes the optimization of renewa...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[{'authorId': '144006876', 'name': 'S. S. Redd...</td>\n",
       "      <td>{'url': 'https://riverpublishers.com/journal/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>a062fbd621a9821a695b9869630feb6bfb0cf585</td>\n",
       "      <td>PSO-Based Smart Grid Application for Sizing an...</td>\n",
       "      <td>This paper introduces an optimal sizing algori...</td>\n",
       "      <td>2016</td>\n",
       "      <td>[{'authorId': '144816554', 'name': 'M. A. Moha...</td>\n",
       "      <td>{'url': 'https://journals.plos.org/plosone/art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>61b8a96cf12e961628977066d4c4807dcb526879</td>\n",
       "      <td>Smart Integrated Renewable Energy Systems (SIR...</td>\n",
       "      <td>Technical and economic aspects of the viabilit...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[{'authorId': '30528974', 'name': 'Zeel Mahesh...</td>\n",
       "      <td>{'url': 'https://www.mdpi.com/1996-1073/10/8/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>76a6c339e61e04069a35610faee5a523b2509f03</td>\n",
       "      <td>Optimization of Renewable Energy Systems: A Re...</td>\n",
       "      <td>In the contrary of decrease of fossil energy n...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[{'authorId': '112948910', 'name': 'Diriba Kaj...</td>\n",
       "      <td>{'url': '', 'status': None, 'license': None, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>ccb0ca74c441aa95d127d33f736827f4ff0ab761</td>\n",
       "      <td>Optimal configuration for isolated hybrid rene...</td>\n",
       "      <td>The configuration of hybrid energy systems has...</td>\n",
       "      <td>2016</td>\n",
       "      <td>[{'authorId': '49264644', 'name': 'A. Eltamaly...</td>\n",
       "      <td>{'url': '', 'status': 'CLOSED', 'license': Non...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paperId  \\\n",
       "1099  cefdd9906064c199428645512eb6834dfed72ae3   \n",
       "1100  a062fbd621a9821a695b9869630feb6bfb0cf585   \n",
       "1101  61b8a96cf12e961628977066d4c4807dcb526879   \n",
       "1102  76a6c339e61e04069a35610faee5a523b2509f03   \n",
       "1103  ccb0ca74c441aa95d127d33f736827f4ff0ab761   \n",
       "\n",
       "                                                  title  \\\n",
       "1099  Optimization of Renewable Energy Resources in ...   \n",
       "1100  PSO-Based Smart Grid Application for Sizing an...   \n",
       "1101  Smart Integrated Renewable Energy Systems (SIR...   \n",
       "1102  Optimization of Renewable Energy Systems: A Re...   \n",
       "1103  Optimal configuration for isolated hybrid rene...   \n",
       "\n",
       "                                               abstract  year  \\\n",
       "1099  This paper proposes the optimization of renewa...  2017   \n",
       "1100  This paper introduces an optimal sizing algori...  2016   \n",
       "1101  Technical and economic aspects of the viabilit...  2017   \n",
       "1102  In the contrary of decrease of fossil energy n...  2017   \n",
       "1103  The configuration of hybrid energy systems has...  2016   \n",
       "\n",
       "                                                authors  \\\n",
       "1099  [{'authorId': '144006876', 'name': 'S. S. Redd...   \n",
       "1100  [{'authorId': '144816554', 'name': 'M. A. Moha...   \n",
       "1101  [{'authorId': '30528974', 'name': 'Zeel Mahesh...   \n",
       "1102  [{'authorId': '112948910', 'name': 'Diriba Kaj...   \n",
       "1103  [{'authorId': '49264644', 'name': 'A. Eltamaly...   \n",
       "\n",
       "                                          openAccessPdf  \n",
       "1099  {'url': 'https://riverpublishers.com/journal/j...  \n",
       "1100  {'url': 'https://journals.plos.org/plosone/art...  \n",
       "1101  {'url': 'https://www.mdpi.com/1996-1073/10/8/1...  \n",
       "1102  {'url': '', 'status': None, 'license': None, '...  \n",
       "1103  {'url': '', 'status': 'CLOSED', 'license': Non...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# crear dataframe con los nuevos articulos\n",
    "if all_new_papers_list:\n",
    "    df_new_papers = pd.DataFrame(all_new_papers_list)\n",
    "    \n",
    "    # Asegurar que df_new_papers tenga todas las columnas esperadas antes de concatenar\n",
    "    for col in expected_cols:\n",
    "        if col not in df_new_papers.columns:\n",
    "            df_new_papers[col] = None\n",
    "    df_new_papers = df_new_papers[expected_cols] \n",
    "\n",
    "    print(f\"Se crearon {len(df_new_papers)} filas a partir de los nuevos artículos recuperados.\")\n",
    "    \n",
    "    # Concatenar el DataFrame existente con los nuevos artículos\n",
    "    df_combined = pd.concat([df_existing_corpus, df_new_papers], ignore_index=True)\n",
    "    print(f\"Tamaño del corpus combinado (antes de deduplicación final): {len(df_combined)}\")\n",
    "else:\n",
    "    print(\"No se recuperaron artículos nuevos. El corpus combinado será igual al existente.\")\n",
    "    df_combined = df_existing_corpus.copy() # Trabajar con una copia si no hay nada que añadir\n",
    "\n",
    "# Verificación final de duplicados por 'paperId' en el DataFrame combinado\n",
    "if 'paperId' in df_combined.columns and not df_combined.empty:\n",
    "    initial_count = len(df_combined)\n",
    "    # Asegurarse de que paperId sea string para la deduplicación, por si hay mezclas de tipos\n",
    "    df_combined['paperId'] = df_combined['paperId'].astype(str)\n",
    "    df_combined.drop_duplicates(subset=['paperId'], keep='first', inplace=True)\n",
    "    df_combined.reset_index(drop=True, inplace=True)\n",
    "    final_count = len(df_combined)\n",
    "    print(f\"Se eliminaron {initial_count - final_count} duplicados en la combinación final.\")\n",
    "    print(f\"Tamaño final del corpus expandido: {final_count} artículos únicos.\")\n",
    "else:\n",
    "    print(\"El DataFrame combinado está vacío o no tiene 'paperId'. No se realizó deduplicación.\")\n",
    "\n",
    "display(df_combined.head())\n",
    "display(df_combined.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a249d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus expandido guardado exitosamente en: C:\\Users\\alvar\\OneDrive\\Escritorio\\TFM\\data\\crudo\\expanded_initial_corpus.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardo el corpus expandido en un csv\n",
    "\n",
    "if not df_combined.empty:\n",
    "    try:\n",
    "        # Asegurarse de que la carpeta de datos exista\n",
    "        os.makedirs(DATA_DIR, exist_ok=True) \n",
    "        \n",
    "        df_combined.to_csv(EXPANDED_CORPUS_PATH, index=False, encoding='utf-8')\n",
    "        print(f\"\\nCorpus expandido guardado exitosamente en: {EXPANDED_CORPUS_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar el corpus expandido: {e}\")\n",
    "else:\n",
    "    print(\"El DataFrame combinado está vacío. No se guardó ningún archivo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
